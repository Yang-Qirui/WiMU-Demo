Starting pre-training...
Pre-training Epoch 0:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 0:   0%|          | 1/367 [00:00<02:29,  2.44it/s]Pre-training Epoch 0:   5%|▍         | 18/367 [00:00<00:07, 45.64it/s]Pre-training Epoch 0:  10%|▉         | 36/367 [00:00<00:04, 81.38it/s]Pre-training Epoch 0:  15%|█▍        | 54/367 [00:00<00:02, 107.57it/s]Pre-training Epoch 0:  20%|█▉        | 72/367 [00:00<00:02, 127.71it/s]Pre-training Epoch 0:  25%|██▍       | 91/367 [00:00<00:01, 143.40it/s]Pre-training Epoch 0:  30%|██▉       | 109/367 [00:01<00:01, 152.88it/s]Pre-training Epoch 0:  35%|███▍      | 127/367 [00:01<00:01, 159.90it/s]recon_loss: 0.6796653270721436, dist_loss: 1.7857962846755981
recon_loss: 0.6765533089637756, dist_loss: 1.303330659866333
recon_loss: 0.6734405755996704, dist_loss: 1.1940783262252808
recon_loss: 0.6703270673751831, dist_loss: 2.3435206413269043
recon_loss: 0.667212188243866, dist_loss: 1.1110302209854126
recon_loss: 0.6640949845314026, dist_loss: 1.997076153755188
recon_loss: 0.6609748601913452, dist_loss: 1.3696959018707275
recon_loss: 0.6578503847122192, dist_loss: 1.5234854221343994
recon_loss: 0.654720664024353, dist_loss: 1.9228016138076782
recon_loss: 0.6515845060348511, dist_loss: 1.1969810724258423
recon_loss: 0.6484407186508179, dist_loss: 1.3749210834503174
recon_loss: 0.6452882885932922, dist_loss: 1.8946502208709717
recon_loss: 0.6421264410018921, dist_loss: 1.256575345993042
recon_loss: 0.6389535069465637, dist_loss: 1.6904959678649902
recon_loss: 0.6357679963111877, dist_loss: 1.5298616886138916
recon_loss: 0.6325685977935791, dist_loss: 1.9889568090438843
recon_loss: 0.6293538212776184, dist_loss: 1.6021640300750732
recon_loss: 0.626121997833252, dist_loss: 1.2414278984069824
recon_loss: 0.6228718161582947, dist_loss: 1.5876612663269043
recon_loss: 0.6196016669273376, dist_loss: 1.6355925798416138
recon_loss: 0.6163099408149719, dist_loss: 1.2538518905639648
recon_loss: 0.6129953861236572, dist_loss: 1.3344018459320068
recon_loss: 0.6096566915512085, dist_loss: 1.3722712993621826
recon_loss: 0.6062926054000854, dist_loss: 1.5901288986206055
recon_loss: 0.6029015779495239, dist_loss: 0.9971988797187805
recon_loss: 0.5994821786880493, dist_loss: 1.2138586044311523
recon_loss: 0.5960338115692139, dist_loss: 1.1786282062530518
recon_loss: 0.5925557613372803, dist_loss: 1.4817252159118652
recon_loss: 0.5890468955039978, dist_loss: 1.6368998289108276
recon_loss: 0.5855063796043396, dist_loss: 1.5237095355987549
recon_loss: 0.5819334387779236, dist_loss: 1.8350106477737427
recon_loss: 0.5783275961875916, dist_loss: 1.6196531057357788
recon_loss: 0.5746877789497375, dist_loss: 1.658726453781128
recon_loss: 0.5710139274597168, dist_loss: 1.025650143623352
recon_loss: 0.5673055648803711, dist_loss: 1.6301226615905762
recon_loss: 0.5635619163513184, dist_loss: 1.007715106010437
recon_loss: 0.5597824454307556, dist_loss: 1.5072011947631836
recon_loss: 0.5559670925140381, dist_loss: 1.2401323318481445
recon_loss: 0.5521153211593628, dist_loss: 1.2418806552886963
recon_loss: 0.5482273101806641, dist_loss: 1.5492223501205444
recon_loss: 0.5443026423454285, dist_loss: 1.5015842914581299
recon_loss: 0.5403414368629456, dist_loss: 1.2305796146392822
recon_loss: 0.5363433957099915, dist_loss: 1.7385698556900024
recon_loss: 0.5323088765144348, dist_loss: 0.938044548034668
recon_loss: 0.52823805809021, dist_loss: 1.2133605480194092
recon_loss: 0.5241310000419617, dist_loss: 0.8488777875900269
recon_loss: 0.5199878811836243, dist_loss: 1.6252115964889526
recon_loss: 0.5158094763755798, dist_loss: 1.269899845123291
recon_loss: 0.5115959048271179, dist_loss: 1.3582899570465088
recon_loss: 0.5073475241661072, dist_loss: 1.1601881980895996
recon_loss: 0.5030651092529297, dist_loss: 1.2629389762878418
recon_loss: 0.49874916672706604, dist_loss: 1.4908983707427979
recon_loss: 0.4944005310535431, dist_loss: 1.4694366455078125
recon_loss: 0.4900203347206116, dist_loss: 1.448882818222046
recon_loss: 0.4856092035770416, dist_loss: 1.2966423034667969
recon_loss: 0.4811680018901825, dist_loss: 0.9456057548522949
recon_loss: 0.4766979217529297, dist_loss: 1.4665281772613525
recon_loss: 0.47219952940940857, dist_loss: 2.379937171936035
recon_loss: 0.46767401695251465, dist_loss: 1.3644864559173584
recon_loss: 0.46312224864959717, dist_loss: 1.4940941333770752
recon_loss: 0.4585455358028412, dist_loss: 1.863350510597229
recon_loss: 0.4539450705051422, dist_loss: 1.5692262649536133
recon_loss: 0.4493218958377838, dist_loss: 2.3635706901550293
recon_loss: 0.4446769058704376, dist_loss: 1.5647163391113281
recon_loss: 0.4400117099285126, dist_loss: 1.4050109386444092
recon_loss: 0.43532752990722656, dist_loss: 2.0175468921661377
recon_loss: 0.4306260049343109, dist_loss: 1.4436509609222412
recon_loss: 0.4259084165096283, dist_loss: 1.5258543491363525
recon_loss: 0.4211762547492981, dist_loss: 1.332668423652649
recon_loss: 0.4164307713508606, dist_loss: 2.1647891998291016
recon_loss: 0.4116736948490143, dist_loss: 1.9566923379898071
recon_loss: 0.4069065749645233, dist_loss: 1.1084582805633545
recon_loss: 0.40213078260421753, dist_loss: 1.3171998262405396
recon_loss: 0.3973480761051178, dist_loss: 1.8016395568847656
recon_loss: 0.3925600051879883, dist_loss: 1.5251457691192627
recon_loss: 0.3877679109573364, dist_loss: 1.6288816928863525
recon_loss: 0.3829733729362488, dist_loss: 1.3088202476501465
recon_loss: 0.3781781494617462, dist_loss: 1.6073567867279053
recon_loss: 0.37338411808013916, dist_loss: 1.1460025310516357
recon_loss: 0.36859312653541565, dist_loss: 1.4811511039733887
recon_loss: 0.36380693316459656, dist_loss: 1.7090840339660645
recon_loss: 0.35902711749076843, dist_loss: 1.0206453800201416
recon_loss: 0.35425570607185364, dist_loss: 1.4979732036590576
recon_loss: 0.3494943678379059, dist_loss: 1.9500181674957275
recon_loss: 0.3447451889514923, dist_loss: 1.911391019821167
recon_loss: 0.3400099277496338, dist_loss: 1.9907170534133911
recon_loss: 0.3352903425693512, dist_loss: 1.0817030668258667
recon_loss: 0.33058837056159973, dist_loss: 1.6451730728149414
recon_loss: 0.325905442237854, dist_loss: 1.4366662502288818
recon_loss: 0.321243554353714, dist_loss: 1.5498158931732178
recon_loss: 0.3166045844554901, dist_loss: 1.2231523990631104
recon_loss: 0.311990350484848, dist_loss: 1.5329346656799316
recon_loss: 0.30740228295326233, dist_loss: 1.1586337089538574
recon_loss: 0.30284225940704346, dist_loss: 1.1071460247039795
recon_loss: 0.2983117699623108, dist_loss: 1.0837421417236328
recon_loss: 0.29381221532821655, dist_loss: 1.2296940088272095
recon_loss: 0.28934526443481445, dist_loss: 1.4401659965515137
recon_loss: 0.2849125266075134, dist_loss: 1.674177885055542
recon_loss: 0.28051528334617615, dist_loss: 1.9910781383514404
recon_loss: 0.2761552035808563, dist_loss: 1.650926113128662
recon_loss: 0.2718336880207062, dist_loss: 1.370347261428833
recon_loss: 0.2675519287586212, dist_loss: 1.5578221082687378
recon_loss: 0.26331138610839844, dist_loss: 1.5214173793792725
recon_loss: 0.25911298394203186, dist_loss: 1.9527826309204102
recon_loss: 0.254957914352417, dist_loss: 1.0866386890411377
recon_loss: 0.2508474290370941, dist_loss: 1.4096102714538574
recon_loss: 0.24678249657154083, dist_loss: 1.2481801509857178
recon_loss: 0.24276413023471832, dist_loss: 1.5001949071884155
recon_loss: 0.23879334330558777, dist_loss: 1.7008438110351562
recon_loss: 0.2348710596561432, dist_loss: 1.404834270477295
recon_loss: 0.23099778592586517, dist_loss: 2.2146475315093994
recon_loss: 0.2271745204925537, dist_loss: 2.1413397789001465
recon_loss: 0.22340194880962372, dist_loss: 1.3171852827072144
recon_loss: 0.21968069672584534, dist_loss: 1.7008572816848755
recon_loss: 0.21601134538650513, dist_loss: 2.3121094703674316
recon_loss: 0.21239463984966278, dist_loss: 1.9642595052719116
recon_loss: 0.20883092284202576, dist_loss: 2.398550033569336
recon_loss: 0.20532068610191345, dist_loss: 1.5343480110168457
recon_loss: 0.2018646001815796, dist_loss: 1.269149899482727
recon_loss: 0.19846291840076447, dist_loss: 2.1987504959106445
recon_loss: 0.1951155811548233, dist_loss: 1.4823689460754395
recon_loss: 0.19182312488555908, dist_loss: 1.9967811107635498
recon_loss: 0.18858571350574493, dist_loss: 0.8935389518737793
recon_loss: 0.18540354073047638, dist_loss: 2.0214366912841797
recon_loss: 0.18227648735046387, dist_loss: 1.5964512825012207
recon_loss: 0.17920462787151337, dist_loss: 1.2163968086242676
recon_loss: 0.17618806660175323, dist_loss: 1.8586052656173706
recon_loss: 0.17322678864002228, dist_loss: 0.8329647779464722
recon_loss: 0.17032068967819214, dist_loss: 1.6822311878204346
recon_loss: 0.16746942698955536, dist_loss: 1.6658883094787598
recon_loss: 0.16467291116714478, dist_loss: 0.9193718433380127
Pre-training Epoch 0:  40%|███▉      | 145/367 [00:01<00:01, 164.27it/s]Pre-training Epoch 0:  44%|████▍     | 163/367 [00:01<00:01, 167.64it/s]Pre-training Epoch 0:  49%|████▉     | 181/367 [00:01<00:01, 170.47it/s]Pre-training Epoch 0:  54%|█████▍    | 199/367 [00:01<00:00, 173.03it/s]Pre-training Epoch 0:  59%|█████▉    | 218/367 [00:01<00:00, 175.31it/s]Pre-training Epoch 0:  64%|██████▍   | 236/367 [00:01<00:00, 174.81it/s]Pre-training Epoch 0:  69%|██████▉   | 254/367 [00:01<00:00, 173.11it/s]recon_loss: 0.1619308888912201, dist_loss: 1.397341012954712
recon_loss: 0.15924304723739624, dist_loss: 1.761651873588562
recon_loss: 0.15660881996154785, dist_loss: 1.2754043340682983
recon_loss: 0.15402819216251373, dist_loss: 2.2940003871917725
recon_loss: 0.15150058269500732, dist_loss: 1.7949481010437012
recon_loss: 0.14902551472187042, dist_loss: 1.0038011074066162
recon_loss: 0.14660274982452393, dist_loss: 1.4079344272613525
recon_loss: 0.14423172175884247, dist_loss: 1.76145601272583
recon_loss: 0.14191177487373352, dist_loss: 2.5059096813201904
recon_loss: 0.13964234292507172, dist_loss: 1.2867467403411865
recon_loss: 0.13742263615131378, dist_loss: 1.5625982284545898
recon_loss: 0.13525235652923584, dist_loss: 0.915665864944458
recon_loss: 0.13313080370426178, dist_loss: 0.9919164776802063
recon_loss: 0.13105730712413788, dist_loss: 1.872615098953247
recon_loss: 0.12903086841106415, dist_loss: 1.3799331188201904
recon_loss: 0.12705068290233612, dist_loss: 2.2180309295654297
recon_loss: 0.1251162588596344, dist_loss: 1.9051399230957031
recon_loss: 0.12322685122489929, dist_loss: 1.3424501419067383
recon_loss: 0.12138158082962036, dist_loss: 1.2298026084899902
recon_loss: 0.11957987397909164, dist_loss: 1.2686095237731934
recon_loss: 0.1178208515048027, dist_loss: 1.0238314867019653
recon_loss: 0.11610382795333862, dist_loss: 1.3501229286193848
recon_loss: 0.11442787945270538, dist_loss: 1.8432481288909912
recon_loss: 0.11279217898845673, dist_loss: 1.215583324432373
recon_loss: 0.11119594424962997, dist_loss: 1.556828498840332
recon_loss: 0.1096382811665535, dist_loss: 1.2385468482971191
recon_loss: 0.10811839997768402, dist_loss: 1.5115597248077393
recon_loss: 0.10663554072380066, dist_loss: 2.0494847297668457
recon_loss: 0.10518896579742432, dist_loss: 1.9637386798858643
recon_loss: 0.10377789288759232, dist_loss: 1.128774881362915
recon_loss: 0.10240154713392258, dist_loss: 1.3515843152999878
recon_loss: 0.10105914622545242, dist_loss: 1.7821868658065796
recon_loss: 0.09974983334541321, dist_loss: 1.7499858140945435
recon_loss: 0.09847286343574524, dist_loss: 1.3957006931304932
recon_loss: 0.09722748398780823, dist_loss: 1.227293848991394
recon_loss: 0.09601307660341263, dist_loss: 1.6023797988891602
recon_loss: 0.09482874721288681, dist_loss: 0.7828078866004944
recon_loss: 0.09367392957210541, dist_loss: 0.9777911901473999
recon_loss: 0.09254782646894455, dist_loss: 0.9083355665206909
recon_loss: 0.09144970774650574, dist_loss: 1.2604928016662598
recon_loss: 0.09037888795137405, dist_loss: 1.1507596969604492
recon_loss: 0.08933474868535995, dist_loss: 1.6513442993164062
recon_loss: 0.08831650763750076, dist_loss: 1.2694021463394165
recon_loss: 0.08732348680496216, dist_loss: 1.4406378269195557
recon_loss: 0.08635514974594116, dist_loss: 1.0736656188964844
recon_loss: 0.08541098982095718, dist_loss: 1.1931201219558716
recon_loss: 0.08449040353298187, dist_loss: 1.7151838541030884
recon_loss: 0.08359267562627792, dist_loss: 1.2521229982376099
recon_loss: 0.08271732926368713, dist_loss: 1.2861441373825073
recon_loss: 0.08186375349760056, dist_loss: 1.209815502166748
recon_loss: 0.08103138208389282, dist_loss: 1.069464087486267
recon_loss: 0.08021961152553558, dist_loss: 2.119906425476074
recon_loss: 0.07942800223827362, dist_loss: 1.2982332706451416
recon_loss: 0.07865604758262634, dist_loss: 1.8560819625854492
recon_loss: 0.07790292054414749, dist_loss: 1.6132419109344482
recon_loss: 0.07716847211122513, dist_loss: 1.140428900718689
recon_loss: 0.07645200192928314, dist_loss: 1.597764015197754
recon_loss: 0.07575303316116333, dist_loss: 1.6032524108886719
recon_loss: 0.0750712975859642, dist_loss: 1.8873826265335083
recon_loss: 0.0744062215089798, dist_loss: 1.5798333883285522
recon_loss: 0.07375745475292206, dist_loss: 1.533612847328186
recon_loss: 0.07312442362308502, dist_loss: 1.2901197671890259
recon_loss: 0.07250675559043884, dist_loss: 1.4603935480117798
recon_loss: 0.07190407067537308, dist_loss: 0.9155113697052002
recon_loss: 0.0713159441947937, dist_loss: 0.9917240738868713
recon_loss: 0.07074201107025146, dist_loss: 0.969336986541748
recon_loss: 0.07018184661865234, dist_loss: 1.4815279245376587
recon_loss: 0.06963516026735306, dist_loss: 2.0730557441711426
recon_loss: 0.06910139322280884, dist_loss: 2.0016140937805176
recon_loss: 0.06858022511005402, dist_loss: 1.4573116302490234
recon_loss: 0.0680714026093483, dist_loss: 1.6375994682312012
recon_loss: 0.06757457554340363, dist_loss: 1.1807996034622192
recon_loss: 0.06708946824073792, dist_loss: 1.3144543170928955
recon_loss: 0.06661586463451385, dist_loss: 1.787900447845459
recon_loss: 0.06615336984395981, dist_loss: 1.4111409187316895
recon_loss: 0.06570164114236832, dist_loss: 1.0462654829025269
recon_loss: 0.06526055932044983, dist_loss: 1.318656325340271
recon_loss: 0.0648297369480133, dist_loss: 2.2682876586914062
recon_loss: 0.0644090324640274, dist_loss: 1.3698902130126953
recon_loss: 0.06399805843830109, dist_loss: 1.6442005634307861
recon_loss: 0.0635964646935463, dist_loss: 1.6955845355987549
recon_loss: 0.06320414692163467, dist_loss: 1.3515431880950928
recon_loss: 0.06282076984643936, dist_loss: 1.4591293334960938
recon_loss: 0.06244618073105812, dist_loss: 1.1427973508834839
recon_loss: 0.062080156058073044, dist_loss: 1.4443800449371338
recon_loss: 0.061722539365291595, dist_loss: 1.623488187789917
recon_loss: 0.06137297675013542, dist_loss: 1.6366266012191772
recon_loss: 0.061031464487314224, dist_loss: 1.2063531875610352
recon_loss: 0.06069761514663696, dist_loss: 1.5005004405975342
recon_loss: 0.06037118285894394, dist_loss: 1.9788891077041626
recon_loss: 0.06005198508501053, dist_loss: 1.7009668350219727
recon_loss: 0.059739936143159866, dist_loss: 0.978012204170227
recon_loss: 0.05943480506539345, dist_loss: 1.5012733936309814
recon_loss: 0.05913644656538963, dist_loss: 1.2199602127075195
recon_loss: 0.058844711631536484, dist_loss: 2.0919008255004883
recon_loss: 0.05855932459235191, dist_loss: 0.7837774753570557
recon_loss: 0.05828023701906204, dist_loss: 1.5811166763305664
recon_loss: 0.05800720676779747, dist_loss: 1.442476749420166
recon_loss: 0.057740144431591034, dist_loss: 1.479636311531067
recon_loss: 0.05747894197702408, dist_loss: 1.3589656352996826
recon_loss: 0.05722339451313019, dist_loss: 1.4245731830596924
recon_loss: 0.05697343870997429, dist_loss: 1.4845110177993774
recon_loss: 0.056728851050138474, dist_loss: 1.4451903104782104
recon_loss: 0.05648942291736603, dist_loss: 1.9247181415557861
recon_loss: 0.056255076080560684, dist_loss: 1.2298376560211182
recon_loss: 0.05602573975920677, dist_loss: 1.1161689758300781
recon_loss: 0.05580144375562668, dist_loss: 1.1158678531646729
recon_loss: 0.055581849068403244, dist_loss: 1.468610167503357
recon_loss: 0.055366817861795425, dist_loss: 1.4192793369293213
recon_loss: 0.05515623092651367, dist_loss: 1.087147831916809
recon_loss: 0.05495007708668709, dist_loss: 1.7561695575714111
recon_loss: 0.05474841222167015, dist_loss: 0.8670428395271301
recon_loss: 0.054550983011722565, dist_loss: 1.0089912414550781
recon_loss: 0.05435763671994209, dist_loss: 1.277280330657959
recon_loss: 0.05416829511523247, dist_loss: 1.4698214530944824
recon_loss: 0.05398290231823921, dist_loss: 1.0328571796417236
recon_loss: 0.053801391273736954, dist_loss: 1.7274341583251953
recon_loss: 0.05362359434366226, dist_loss: 2.4628913402557373
recon_loss: 0.053449321538209915, dist_loss: 0.9003041982650757
recon_loss: 0.05327865481376648, dist_loss: 1.5489585399627686
recon_loss: 0.05311153829097748, dist_loss: 1.741952896118164
recon_loss: 0.0529477633535862, dist_loss: 1.2125768661499023
recon_loss: 0.05278730392456055, dist_loss: 1.1671360731124878
recon_loss: 0.052630141377449036, dist_loss: 1.368859887123108
recon_loss: 0.05247621238231659, dist_loss: 1.7752554416656494
recon_loss: 0.052325453609228134, dist_loss: 1.7548199892044067
recon_loss: 0.05217768996953964, dist_loss: 0.7772632241249084
recon_loss: 0.05203289911150932, dist_loss: 1.2592227458953857
recon_loss: 0.05189099535346031, dist_loss: 1.0655641555786133
recon_loss: 0.05175192654132843, dist_loss: 1.9865918159484863
Pre-training Epoch 0:  74%|███████▍  | 272/367 [00:01<00:00, 173.56it/s]Pre-training Epoch 0:  79%|███████▉  | 290/367 [00:02<00:00, 173.85it/s]Pre-training Epoch 0:  84%|████████▍ | 308/367 [00:02<00:00, 173.42it/s]Pre-training Epoch 0:  89%|████████▉ | 326/367 [00:02<00:00, 174.36it/s]Pre-training Epoch 0:  94%|█████████▎| 344/367 [00:02<00:00, 171.63it/s]Pre-training Epoch 0:  99%|█████████▊| 362/367 [00:02<00:00, 143.45it/s]Pre-training Epoch 0: 100%|██████████| 367/367 [00:02<00:00, 142.43it/s]
recon_loss: 0.05161559581756592, dist_loss: 1.124594807624817
recon_loss: 0.051482055336236954, dist_loss: 1.2926924228668213
recon_loss: 0.05135107412934303, dist_loss: 1.4263439178466797
recon_loss: 0.051222749054431915, dist_loss: 1.2771012783050537
recon_loss: 0.05109698325395584, dist_loss: 0.8452510833740234
recon_loss: 0.050973739475011826, dist_loss: 1.3906588554382324
recon_loss: 0.05085300654172897, dist_loss: 0.7580841779708862
recon_loss: 0.050734713673591614, dist_loss: 1.2485822439193726
recon_loss: 0.05061870068311691, dist_loss: 1.2025794982910156
recon_loss: 0.05050491541624069, dist_loss: 1.4901909828186035
recon_loss: 0.050393350422382355, dist_loss: 1.5569229125976562
recon_loss: 0.05028398334980011, dist_loss: 1.3564164638519287
recon_loss: 0.05017678812146187, dist_loss: 0.7209277749061584
recon_loss: 0.05007166042923927, dist_loss: 1.1281754970550537
recon_loss: 0.04996853321790695, dist_loss: 1.1383209228515625
recon_loss: 0.049867402762174606, dist_loss: 1.5265717506408691
recon_loss: 0.04976823180913925, dist_loss: 1.283076286315918
recon_loss: 0.049671005457639694, dist_loss: 1.115709900856018
recon_loss: 0.049575645476579666, dist_loss: 1.0547736883163452
recon_loss: 0.049482136964797974, dist_loss: 1.185836672782898
recon_loss: 0.04939041659235954, dist_loss: 1.9460924863815308
recon_loss: 0.049300529062747955, dist_loss: 1.6149851083755493
recon_loss: 0.04921230673789978, dist_loss: 1.3608996868133545
recon_loss: 0.04912572726607323, dist_loss: 1.0734789371490479
recon_loss: 0.0490407720208168, dist_loss: 1.3863914012908936
recon_loss: 0.048957470804452896, dist_loss: 1.0179837942123413
recon_loss: 0.04887573421001434, dist_loss: 1.183483600616455
recon_loss: 0.04879552125930786, dist_loss: 1.836890697479248
recon_loss: 0.048716843128204346, dist_loss: 1.002744436264038
recon_loss: 0.04863964766263962, dist_loss: 1.3353519439697266
recon_loss: 0.04856389760971069, dist_loss: 1.770937204360962
recon_loss: 0.04848947003483772, dist_loss: 1.625205159187317
recon_loss: 0.048416443169116974, dist_loss: 1.4438260793685913
recon_loss: 0.04834471642971039, dist_loss: 1.4390180110931396
recon_loss: 0.04827429726719856, dist_loss: 0.9685043096542358
recon_loss: 0.04820524528622627, dist_loss: 1.6304287910461426
recon_loss: 0.04813745617866516, dist_loss: 0.9307217597961426
recon_loss: 0.048070911318063736, dist_loss: 1.78648841381073
recon_loss: 0.048005443066358566, dist_loss: 0.7667617201805115
recon_loss: 0.04794123396277428, dist_loss: 1.586822271347046
recon_loss: 0.04787827283143997, dist_loss: 1.077169418334961
recon_loss: 0.047816503793001175, dist_loss: 0.8607164621353149
recon_loss: 0.04775586724281311, dist_loss: 1.3626043796539307
recon_loss: 0.04769638553261757, dist_loss: 1.248507022857666
recon_loss: 0.047638021409511566, dist_loss: 1.2191424369812012
recon_loss: 0.047580718994140625, dist_loss: 1.5314772129058838
recon_loss: 0.047524403780698776, dist_loss: 1.3039369583129883
recon_loss: 0.04746917262673378, dist_loss: 1.6859135627746582
recon_loss: 0.04741493612527847, dist_loss: 1.3661394119262695
recon_loss: 0.04736170545220375, dist_loss: 1.5867682695388794
recon_loss: 0.047309428453445435, dist_loss: 1.1024456024169922
recon_loss: 0.04725818336009979, dist_loss: 1.1229479312896729
recon_loss: 0.04720790684223175, dist_loss: 1.4956529140472412
recon_loss: 0.04715856537222862, dist_loss: 1.215285301208496
recon_loss: 0.0471101775765419, dist_loss: 0.8913007974624634
recon_loss: 0.047062668949365616, dist_loss: 1.0829689502716064
recon_loss: 0.04701605066657066, dist_loss: 1.4289005994796753
recon_loss: 0.04697027429938316, dist_loss: 1.4187191724777222
recon_loss: 0.046925317496061325, dist_loss: 0.8617624044418335
recon_loss: 0.04688113555312157, dist_loss: 1.3546011447906494
recon_loss: 0.04683777317404747, dist_loss: 1.0251927375793457
recon_loss: 0.04679505527019501, dist_loss: 1.1839262247085571
recon_loss: 0.04675300419330597, dist_loss: 1.1151078939437866
recon_loss: 0.046711646020412445, dist_loss: 0.7684165239334106
recon_loss: 0.04667102172970772, dist_loss: 0.9929754137992859
recon_loss: 0.04663120210170746, dist_loss: 1.2089242935180664
recon_loss: 0.04659200459718704, dist_loss: 1.4410653114318848
recon_loss: 0.04655338078737259, dist_loss: 0.8130654096603394
recon_loss: 0.04651546850800514, dist_loss: 1.2131872177124023
recon_loss: 0.04647819697856903, dist_loss: 1.212016224861145
recon_loss: 0.046441614627838135, dist_loss: 1.4194397926330566
recon_loss: 0.04640563577413559, dist_loss: 1.1685580015182495
recon_loss: 0.046370331197977066, dist_loss: 1.6386730670928955
recon_loss: 0.04633563756942749, dist_loss: 1.127114176750183
recon_loss: 0.046301547437906265, dist_loss: 0.6897592544555664
recon_loss: 0.04626812785863876, dist_loss: 1.3893898725509644
recon_loss: 0.046235233545303345, dist_loss: 1.55846107006073
recon_loss: 0.04620290547609329, dist_loss: 1.5820704698562622
recon_loss: 0.046171221882104874, dist_loss: 1.0246076583862305
recon_loss: 0.04614003747701645, dist_loss: 0.9214959144592285
recon_loss: 0.0461093969643116, dist_loss: 1.539726734161377
recon_loss: 0.04607921838760376, dist_loss: 1.5211150646209717
recon_loss: 0.04604951664805412, dist_loss: 1.0542073249816895
recon_loss: 0.04602032154798508, dist_loss: 1.3841569423675537
recon_loss: 0.045991651713848114, dist_loss: 0.9960291385650635
recon_loss: 0.045963436365127563, dist_loss: 1.0298503637313843
recon_loss: 0.045935675501823425, dist_loss: 1.636128544807434
recon_loss: 0.045908372849226, dist_loss: 0.9513887166976929
recon_loss: 0.045881472527980804, dist_loss: 1.2355077266693115
recon_loss: 0.04585498943924904, dist_loss: 1.1229183673858643
recon_loss: 0.045829031616449356, dist_loss: 1.6508091688156128
recon_loss: 0.04580342024564743, dist_loss: 1.063185214996338
recon_loss: 0.045778289437294006, dist_loss: 1.1025357246398926
recon_loss: 0.04575357586145401, dist_loss: 1.238934874534607
recon_loss: 0.0457293763756752, dist_loss: 0.8396470546722412
recon_loss: 0.04570559784770012, dist_loss: 1.0300331115722656
recon_loss: 0.04568222165107727, dist_loss: 1.3579721450805664
recon_loss: 0.04565911367535591, dist_loss: 0.9559414982795715
recon_loss: 0.04563644528388977, dist_loss: 1.2758311033248901
recon_loss: 0.04561404138803482, dist_loss: 1.2251050472259521
recon_loss: 0.04559199884533882, dist_loss: 1.2619930505752563
recon_loss: 0.04557036608457565, dist_loss: 1.1643309593200684
recon_loss: 0.04554913938045502, dist_loss: 1.4301345348358154
recon_loss: 0.045528262853622437, dist_loss: 1.3097243309020996
recon_loss: 0.04550773277878761, dist_loss: 1.004493236541748
recon_loss: 0.04548751935362816, dist_loss: 0.7134154438972473
Pre-train Epoch: 0
Train - Total Loss: 0.3371, Recon Loss: 0.1957, Dist Loss: 1.4139, l1 regularization: 0.0000
Val - Total Loss: 0.1655, Recon Loss: 0.0455, Dist Loss: 1.2005, l1 regularization: 0.0000
Pre-training Epoch 1:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 1:   4%|▍         | 15/367 [00:00<00:02, 146.75it/s]Pre-training Epoch 1:   8%|▊         | 31/367 [00:00<00:02, 153.37it/s]Pre-training Epoch 1:  13%|█▎        | 49/367 [00:00<00:01, 163.16it/s]Pre-training Epoch 1:  19%|█▉        | 69/367 [00:00<00:01, 174.45it/s]Pre-training Epoch 1:  24%|██▍       | 89/367 [00:00<00:01, 180.31it/s]Pre-training Epoch 1:  30%|██▉       | 109/367 [00:00<00:01, 184.62it/s]Pre-training Epoch 1:  35%|███▌      | 129/367 [00:00<00:01, 187.36it/s]recon_loss: 0.04546769708395004, dist_loss: 1.4454673528671265
recon_loss: 0.04544799029827118, dist_loss: 0.7967821359634399
recon_loss: 0.04542854055762291, dist_loss: 1.1471949815750122
recon_loss: 0.045409414917230606, dist_loss: 1.9437553882598877
recon_loss: 0.04539046064019203, dist_loss: 1.671619176864624
recon_loss: 0.045371830463409424, dist_loss: 1.047229290008545
recon_loss: 0.045353494584560394, dist_loss: 0.9789791107177734
recon_loss: 0.0453355573117733, dist_loss: 1.6213874816894531
recon_loss: 0.04531799629330635, dist_loss: 0.9569076299667358
recon_loss: 0.04530065506696701, dist_loss: 1.288766622543335
recon_loss: 0.04528366029262543, dist_loss: 1.1888868808746338
recon_loss: 0.04526699334383011, dist_loss: 1.5702767372131348
recon_loss: 0.045250579714775085, dist_loss: 1.787594199180603
recon_loss: 0.04523447901010513, dist_loss: 1.2698829174041748
recon_loss: 0.04521864652633667, dist_loss: 0.8607288599014282
recon_loss: 0.04520304501056671, dist_loss: 0.8062876462936401
recon_loss: 0.04518776386976242, dist_loss: 0.978966474533081
recon_loss: 0.0451727993786335, dist_loss: 1.4076550006866455
recon_loss: 0.045157983899116516, dist_loss: 0.9300038814544678
recon_loss: 0.045143403112888336, dist_loss: 1.252942442893982
recon_loss: 0.04512915015220642, dist_loss: 0.8892115354537964
recon_loss: 0.045115113258361816, dist_loss: 1.450852870941162
recon_loss: 0.04510125145316124, dist_loss: 0.6551692485809326
recon_loss: 0.045087628066539764, dist_loss: 0.8428999185562134
recon_loss: 0.04507424682378769, dist_loss: 0.7303954362869263
recon_loss: 0.045061107724905014, dist_loss: 0.6253767609596252
recon_loss: 0.04504814371466637, dist_loss: 0.45628470182418823
recon_loss: 0.04503539204597473, dist_loss: 0.7191510796546936
recon_loss: 0.04502291977405548, dist_loss: 0.9558920860290527
recon_loss: 0.04501067474484444, dist_loss: 1.2845573425292969
recon_loss: 0.0449986606836319, dist_loss: 0.8730151653289795
recon_loss: 0.0449867770075798, dist_loss: 1.4701980352401733
recon_loss: 0.044975098222494125, dist_loss: 1.052164912223816
recon_loss: 0.044963594526052475, dist_loss: 1.6306670904159546
recon_loss: 0.04495217651128769, dist_loss: 1.1117713451385498
recon_loss: 0.044940829277038574, dist_loss: 0.9082134366035461
recon_loss: 0.044929713010787964, dist_loss: 1.4596366882324219
recon_loss: 0.04491870850324631, dist_loss: 0.9662874341011047
recon_loss: 0.044907912611961365, dist_loss: 1.205151081085205
recon_loss: 0.04489727318286896, dist_loss: 0.7291592359542847
recon_loss: 0.04488687589764595, dist_loss: 1.1388664245605469
recon_loss: 0.044876646250486374, dist_loss: 0.9580739736557007
recon_loss: 0.04486660286784172, dist_loss: 1.1787049770355225
recon_loss: 0.044856708496809006, dist_loss: 1.1135889291763306
recon_loss: 0.044847000390291214, dist_loss: 0.8039061427116394
recon_loss: 0.04483749717473984, dist_loss: 0.7510433793067932
recon_loss: 0.04482816159725189, dist_loss: 0.6806769967079163
recon_loss: 0.04481900855898857, dist_loss: 1.1841353178024292
recon_loss: 0.04481007158756256, dist_loss: 0.7686773538589478
recon_loss: 0.04480128362774849, dist_loss: 0.6583843231201172
recon_loss: 0.04479265585541725, dist_loss: 0.8525345921516418
recon_loss: 0.04478419944643974, dist_loss: 1.2474957704544067
recon_loss: 0.0447758324444294, dist_loss: 0.9097817540168762
recon_loss: 0.04476756229996681, dist_loss: 0.7446927428245544
recon_loss: 0.04475945234298706, dist_loss: 1.3384666442871094
recon_loss: 0.04475149139761925, dist_loss: 0.7221834659576416
recon_loss: 0.04474364593625069, dist_loss: 1.0713386535644531
recon_loss: 0.044735923409461975, dist_loss: 0.8258705139160156
recon_loss: 0.04472832381725311, dist_loss: 0.7345945835113525
recon_loss: 0.044720884412527084, dist_loss: 0.9925477504730225
recon_loss: 0.04471353814005852, dist_loss: 0.6784728765487671
recon_loss: 0.04470635578036308, dist_loss: 1.2142695188522339
recon_loss: 0.0446992926299572, dist_loss: 0.6575590372085571
recon_loss: 0.04469238221645355, dist_loss: 1.7028989791870117
recon_loss: 0.044685643166303635, dist_loss: 0.8904898166656494
recon_loss: 0.044679008424282074, dist_loss: 1.1528241634368896
recon_loss: 0.04467242583632469, dist_loss: 0.7934701442718506
recon_loss: 0.04466600343585014, dist_loss: 1.3568319082260132
recon_loss: 0.04465968906879425, dist_loss: 1.0794004201889038
recon_loss: 0.04465353116393089, dist_loss: 0.5372209548950195
recon_loss: 0.04464750736951828, dist_loss: 0.569710373878479
recon_loss: 0.04464160278439522, dist_loss: 0.85709547996521
recon_loss: 0.04463578760623932, dist_loss: 1.0609049797058105
recon_loss: 0.04463005065917969, dist_loss: 0.8828263282775879
recon_loss: 0.04462441802024841, dist_loss: 1.006007194519043
recon_loss: 0.044618844985961914, dist_loss: 0.8233911395072937
recon_loss: 0.044613417237997055, dist_loss: 0.723324716091156
recon_loss: 0.044608086347579956, dist_loss: 0.6158334612846375
recon_loss: 0.0446029007434845, dist_loss: 0.8958054780960083
recon_loss: 0.044597793370485306, dist_loss: 0.7608931064605713
recon_loss: 0.04459276795387268, dist_loss: 1.0402779579162598
recon_loss: 0.044587843120098114, dist_loss: 1.0045697689056396
recon_loss: 0.044583022594451904, dist_loss: 0.9579289555549622
recon_loss: 0.044578321278095245, dist_loss: 0.7603366374969482
recon_loss: 0.04457373544573784, dist_loss: 1.0147292613983154
recon_loss: 0.0445692241191864, dist_loss: 0.8650853633880615
recon_loss: 0.044564809650182724, dist_loss: 0.4346979558467865
recon_loss: 0.044560547918081284, dist_loss: 0.8663469552993774
recon_loss: 0.044556405395269394, dist_loss: 1.1902697086334229
recon_loss: 0.044552307575941086, dist_loss: 0.7694178819656372
recon_loss: 0.04454831779003143, dist_loss: 0.8888235092163086
recon_loss: 0.04454445838928223, dist_loss: 1.07053542137146
recon_loss: 0.044540684670209885, dist_loss: 1.14237642288208
recon_loss: 0.04453699290752411, dist_loss: 0.7743443846702576
recon_loss: 0.04453336447477341, dist_loss: 1.1279006004333496
recon_loss: 0.044529806822538376, dist_loss: 0.7993074655532837
recon_loss: 0.044526357203722, dist_loss: 1.466972827911377
recon_loss: 0.04452294483780861, dist_loss: 0.8289556503295898
recon_loss: 0.04451962187886238, dist_loss: 0.7664173245429993
recon_loss: 0.04451635479927063, dist_loss: 1.354034185409546
recon_loss: 0.044513072818517685, dist_loss: 0.4757954478263855
recon_loss: 0.044509850442409515, dist_loss: 0.722407877445221
recon_loss: 0.0445067435503006, dist_loss: 0.832111656665802
recon_loss: 0.04450368136167526, dist_loss: 0.7943680286407471
recon_loss: 0.0445006862282753, dist_loss: 1.0533137321472168
recon_loss: 0.0444977693259716, dist_loss: 1.0358147621154785
recon_loss: 0.04449491202831268, dist_loss: 0.7158353328704834
recon_loss: 0.044492121785879135, dist_loss: 0.790006160736084
recon_loss: 0.04448937252163887, dist_loss: 1.2750356197357178
recon_loss: 0.0444866381585598, dist_loss: 0.8702065944671631
recon_loss: 0.04448394477367401, dist_loss: 0.7742785215377808
recon_loss: 0.04448135197162628, dist_loss: 0.6915404796600342
recon_loss: 0.04447878152132034, dist_loss: 0.8668999671936035
recon_loss: 0.04447627440094948, dist_loss: 0.6542526483535767
recon_loss: 0.04447382315993309, dist_loss: 1.3482588529586792
recon_loss: 0.044471390545368195, dist_loss: 0.5022896528244019
recon_loss: 0.04446900635957718, dist_loss: 0.4922463297843933
recon_loss: 0.04446665942668915, dist_loss: 1.2196167707443237
recon_loss: 0.04446438327431679, dist_loss: 0.6183509230613708
recon_loss: 0.044462136924266815, dist_loss: 0.9925631284713745
recon_loss: 0.04445992410182953, dist_loss: 0.8327000141143799
recon_loss: 0.04445778951048851, dist_loss: 0.6728252172470093
recon_loss: 0.04445571452379227, dist_loss: 0.7532869577407837
recon_loss: 0.04445367678999901, dist_loss: 1.1137521266937256
recon_loss: 0.04445172846317291, dist_loss: 0.7244279980659485
recon_loss: 0.0444498173892498, dist_loss: 0.7255902290344238
recon_loss: 0.04444795474410057, dist_loss: 0.8967146277427673
recon_loss: 0.04444611072540283, dist_loss: 0.7642939686775208
recon_loss: 0.04444433003664017, dist_loss: 0.5049781799316406
recon_loss: 0.04444258287549019, dist_loss: 0.7769473791122437
Pre-training Epoch 1:  41%|████      | 149/367 [00:00<00:01, 189.05it/s]Pre-training Epoch 1:  46%|████▌     | 168/367 [00:00<00:01, 182.82it/s]Pre-training Epoch 1:  51%|█████     | 187/367 [00:01<00:01, 177.55it/s]Pre-training Epoch 1:  56%|█████▌    | 205/367 [00:01<00:00, 177.10it/s]Pre-training Epoch 1:  61%|██████    | 223/367 [00:01<00:00, 176.41it/s]Pre-training Epoch 1:  66%|██████▌   | 241/367 [00:01<00:00, 173.72it/s]Pre-training Epoch 1:  71%|███████   | 259/367 [00:01<00:00, 169.12it/s]recon_loss: 0.0444408543407917, dist_loss: 0.6344701051712036
recon_loss: 0.044439155608415604, dist_loss: 0.9611498713493347
recon_loss: 0.044437509030103683, dist_loss: 0.821064829826355
recon_loss: 0.04443591833114624, dist_loss: 0.9854353070259094
recon_loss: 0.0444343276321888, dist_loss: 0.8070796728134155
recon_loss: 0.04443276673555374, dist_loss: 0.8483837842941284
recon_loss: 0.04443121328949928, dist_loss: 0.6751216650009155
recon_loss: 0.04442974552512169, dist_loss: 0.939146876335144
recon_loss: 0.04442828148603439, dist_loss: 0.8439158201217651
recon_loss: 0.04442685842514038, dist_loss: 1.2361583709716797
recon_loss: 0.04442542791366577, dist_loss: 1.1516791582107544
recon_loss: 0.04442402347922325, dist_loss: 0.5572042465209961
recon_loss: 0.04442267119884491, dist_loss: 0.816220760345459
recon_loss: 0.04442136734724045, dist_loss: 0.779538631439209
recon_loss: 0.04442005604505539, dist_loss: 0.5829070806503296
recon_loss: 0.044418808072805405, dist_loss: 0.6198968291282654
recon_loss: 0.044417575001716614, dist_loss: 0.8624663352966309
recon_loss: 0.044416360557079315, dist_loss: 0.5818513035774231
recon_loss: 0.04441515728831291, dist_loss: 1.148912787437439
recon_loss: 0.04441399499773979, dist_loss: 1.2216187715530396
recon_loss: 0.04441284015774727, dist_loss: 0.8308920860290527
recon_loss: 0.04441170021891594, dist_loss: 0.5038046836853027
recon_loss: 0.04441060870885849, dist_loss: 0.8940039873123169
recon_loss: 0.04440952092409134, dist_loss: 1.4055900573730469
recon_loss: 0.04440843313932419, dist_loss: 1.0797607898712158
recon_loss: 0.04440736770629883, dist_loss: 1.7530007362365723
recon_loss: 0.044406380504369736, dist_loss: 0.4018239974975586
recon_loss: 0.044405411928892136, dist_loss: 0.5775763392448425
recon_loss: 0.044404469430446625, dist_loss: 1.1360359191894531
recon_loss: 0.0444035530090332, dist_loss: 1.107588529586792
recon_loss: 0.0444025881588459, dist_loss: 0.9188156127929688
recon_loss: 0.04440166801214218, dist_loss: 0.5337681770324707
recon_loss: 0.04440079256892204, dist_loss: 0.9095343351364136
recon_loss: 0.0443999245762825, dist_loss: 0.9090916514396667
recon_loss: 0.04439907148480415, dist_loss: 0.9478244781494141
recon_loss: 0.044398244470357895, dist_loss: 0.6503276824951172
recon_loss: 0.04439740628004074, dist_loss: 0.8700496554374695
recon_loss: 0.04439658671617508, dist_loss: 0.6458376049995422
recon_loss: 0.04439576715230942, dist_loss: 0.6482838988304138
recon_loss: 0.044394928961992264, dist_loss: 1.2954658269882202
recon_loss: 0.044394101947546005, dist_loss: 0.9203352928161621
recon_loss: 0.04439328983426094, dist_loss: 1.0199310779571533
recon_loss: 0.04439250007271767, dist_loss: 1.2130751609802246
recon_loss: 0.0443916954100132, dist_loss: 0.49623554944992065
recon_loss: 0.044390883296728134, dist_loss: 0.9869517087936401
recon_loss: 0.04439007118344307, dist_loss: 0.6376664638519287
recon_loss: 0.0443892627954483, dist_loss: 0.729000449180603
recon_loss: 0.04438849911093712, dist_loss: 1.000146746635437
recon_loss: 0.04438774287700653, dist_loss: 0.9333935976028442
recon_loss: 0.04438702389597893, dist_loss: 1.361429214477539
recon_loss: 0.04438633844256401, dist_loss: 0.7030253410339355
recon_loss: 0.04438566416501999, dist_loss: 0.8379750847816467
recon_loss: 0.04438498616218567, dist_loss: 0.8226602077484131
recon_loss: 0.04438433051109314, dist_loss: 0.670859694480896
recon_loss: 0.04438367858529091, dist_loss: 0.7861517667770386
recon_loss: 0.04438301548361778, dist_loss: 0.7417598366737366
recon_loss: 0.04438235983252525, dist_loss: 1.048020362854004
recon_loss: 0.04438171163201332, dist_loss: 0.3372120261192322
recon_loss: 0.044381048530340195, dist_loss: 1.1739163398742676
recon_loss: 0.044380370527505875, dist_loss: 1.56944739818573
recon_loss: 0.04437972605228424, dist_loss: 0.4595594108104706
recon_loss: 0.044379085302352905, dist_loss: 1.0834972858428955
recon_loss: 0.04437848553061485, dist_loss: 1.0970686674118042
recon_loss: 0.04437793418765068, dist_loss: 0.7932002544403076
recon_loss: 0.04437738284468651, dist_loss: 0.6737326383590698
recon_loss: 0.04437682032585144, dist_loss: 0.43173474073410034
recon_loss: 0.04437624290585518, dist_loss: 0.7441102266311646
recon_loss: 0.04437565803527832, dist_loss: 0.9832521677017212
recon_loss: 0.04437508434057236, dist_loss: 1.2058992385864258
recon_loss: 0.044374510645866394, dist_loss: 0.640510082244873
recon_loss: 0.044373948127031326, dist_loss: 0.9000220894813538
recon_loss: 0.044373396784067154, dist_loss: 0.9321027994155884
recon_loss: 0.044372860342264175, dist_loss: 0.8881891369819641
recon_loss: 0.04437236115336418, dist_loss: 0.9371082186698914
recon_loss: 0.044371843338012695, dist_loss: 0.8956153988838196
recon_loss: 0.04437132179737091, dist_loss: 0.6154079437255859
recon_loss: 0.04437075927853584, dist_loss: 0.8391817212104797
recon_loss: 0.044370200484991074, dist_loss: 0.4885807931423187
recon_loss: 0.0443696491420269, dist_loss: 1.1427439451217651
recon_loss: 0.044369105249643326, dist_loss: 0.4028407633304596
recon_loss: 0.04436855763196945, dist_loss: 0.9419950842857361
recon_loss: 0.044368013739585876, dist_loss: 1.0063252449035645
recon_loss: 0.04436752572655678, dist_loss: 0.3844088315963745
recon_loss: 0.04436705261468887, dist_loss: 0.6734800934791565
recon_loss: 0.04436656832695007, dist_loss: 0.7226512432098389
recon_loss: 0.04436606913805008, dist_loss: 0.5400387048721313
recon_loss: 0.0443655401468277, dist_loss: 1.0592701435089111
recon_loss: 0.04436502605676651, dist_loss: 0.8202776312828064
recon_loss: 0.04436454176902771, dist_loss: 0.5339291095733643
recon_loss: 0.04436403140425682, dist_loss: 0.617235004901886
recon_loss: 0.04436351731419563, dist_loss: 0.8154425024986267
recon_loss: 0.04436299577355385, dist_loss: 1.1022275686264038
recon_loss: 0.04436253011226654, dist_loss: 0.726168155670166
recon_loss: 0.044362057000398636, dist_loss: 1.0142996311187744
recon_loss: 0.04436158388853073, dist_loss: 0.43500494956970215
recon_loss: 0.04436107724905014, dist_loss: 0.663445234298706
recon_loss: 0.04436057060956955, dist_loss: 0.6185564994812012
recon_loss: 0.04436005279421806, dist_loss: 0.37045717239379883
recon_loss: 0.04435952380299568, dist_loss: 0.8156012296676636
recon_loss: 0.0443589985370636, dist_loss: 0.8728708624839783
recon_loss: 0.04435848444700241, dist_loss: 0.5516353249549866
recon_loss: 0.04435798525810242, dist_loss: 1.3204611539840698
recon_loss: 0.04435747489333153, dist_loss: 0.6028966903686523
recon_loss: 0.04435694217681885, dist_loss: 0.9124281406402588
recon_loss: 0.044356439262628555, dist_loss: 0.6967660188674927
recon_loss: 0.04435594007372856, dist_loss: 0.6038016080856323
recon_loss: 0.04435543715953827, dist_loss: 1.0157965421676636
recon_loss: 0.0443548820912838, dist_loss: 0.5861249566078186
recon_loss: 0.04435430467128754, dist_loss: 0.990447461605072
recon_loss: 0.044353749603033066, dist_loss: 0.8330920934677124
recon_loss: 0.04435319826006889, dist_loss: 1.0643401145935059
recon_loss: 0.04435265436768532, dist_loss: 0.6212171316146851
recon_loss: 0.044352106750011444, dist_loss: 1.0136321783065796
recon_loss: 0.04435155168175697, dist_loss: 0.5344103574752808
recon_loss: 0.0443510003387928, dist_loss: 1.539395809173584
recon_loss: 0.04435047134757042, dist_loss: 0.611517071723938
recon_loss: 0.04434993490576744, dist_loss: 0.6545497179031372
recon_loss: 0.04434937611222267, dist_loss: 0.8309539556503296
recon_loss: 0.04434883967041969, dist_loss: 0.6280559301376343
recon_loss: 0.044348280876874924, dist_loss: 1.146914005279541
recon_loss: 0.04434775933623314, dist_loss: 0.4641210734844208
recon_loss: 0.04434722661972046, dist_loss: 0.8033460378646851
recon_loss: 0.04434672370553017, dist_loss: 0.8158323168754578
recon_loss: 0.044346198439598083, dist_loss: 0.5001218914985657
recon_loss: 0.044345661997795105, dist_loss: 0.5395146012306213
recon_loss: 0.04434512183070183, dist_loss: 0.46828627586364746
recon_loss: 0.04434456676244736, dist_loss: 0.5709303617477417
recon_loss: 0.04434400796890259, dist_loss: 0.8668248653411865
recon_loss: 0.04434343799948692, dist_loss: 0.7945362329483032
recon_loss: 0.04434286057949066, dist_loss: 0.8707435131072998
Pre-training Epoch 1:  75%|███████▌  | 276/367 [00:01<00:00, 167.83it/s]Pre-training Epoch 1:  80%|███████▉  | 293/367 [00:01<00:00, 167.41it/s]Pre-training Epoch 1:  84%|████████▍ | 310/367 [00:01<00:00, 166.96it/s]Pre-training Epoch 1:  89%|████████▉ | 327/367 [00:01<00:00, 166.65it/s]Pre-training Epoch 1:  94%|█████████▎| 344/367 [00:01<00:00, 162.50it/s]Pre-training Epoch 1:  98%|█████████▊| 361/367 [00:02<00:00, 160.15it/s]Pre-training Epoch 1: 100%|██████████| 367/367 [00:02<00:00, 170.79it/s]
recon_loss: 0.04434232413768768, dist_loss: 0.37245237827301025
recon_loss: 0.04434176906943321, dist_loss: 0.6804155707359314
recon_loss: 0.044341202825307846, dist_loss: 0.44562679529190063
recon_loss: 0.044340625405311584, dist_loss: 1.0648679733276367
recon_loss: 0.04434005543589592, dist_loss: 1.0693511962890625
recon_loss: 0.04433946684002876, dist_loss: 0.7642554044723511
recon_loss: 0.044338881969451904, dist_loss: 0.8876973390579224
recon_loss: 0.04433828219771385, dist_loss: 0.5395139455795288
recon_loss: 0.0443376824259758, dist_loss: 1.0710715055465698
recon_loss: 0.04433706775307655, dist_loss: 0.7263438105583191
recon_loss: 0.04433645308017731, dist_loss: 0.6052761077880859
recon_loss: 0.04433584213256836, dist_loss: 0.6886699795722961
recon_loss: 0.04433521255850792, dist_loss: 1.0453778505325317
recon_loss: 0.04433456063270569, dist_loss: 0.7703167200088501
recon_loss: 0.04433389753103256, dist_loss: 1.1108267307281494
recon_loss: 0.04433325305581093, dist_loss: 0.6038729548454285
recon_loss: 0.0443325974047184, dist_loss: 0.49760958552360535
recon_loss: 0.04433196783065796, dist_loss: 0.5304702520370483
recon_loss: 0.044331301003694534, dist_loss: 1.2493820190429688
recon_loss: 0.044330645352602005, dist_loss: 0.2592600882053375
recon_loss: 0.044329963624477386, dist_loss: 0.45456576347351074
recon_loss: 0.04432929307222366, dist_loss: 0.48882541060447693
recon_loss: 0.04432862251996994, dist_loss: 0.7685402631759644
recon_loss: 0.04432796314358711, dist_loss: 1.152472972869873
recon_loss: 0.044327281415462494, dist_loss: 0.6590350866317749
recon_loss: 0.04432661831378937, dist_loss: 0.7296019792556763
recon_loss: 0.04432595521211624, dist_loss: 0.9667233824729919
recon_loss: 0.044325295835733414, dist_loss: 0.32055598497390747
recon_loss: 0.04432464763522148, dist_loss: 0.9705349206924438
recon_loss: 0.04432402178645134, dist_loss: 0.47404369711875916
recon_loss: 0.0443233996629715, dist_loss: 1.2183794975280762
recon_loss: 0.044322773814201355, dist_loss: 0.7316349744796753
recon_loss: 0.044322144240140915, dist_loss: 0.6910437941551208
recon_loss: 0.044321537017822266, dist_loss: 0.6367665529251099
recon_loss: 0.04432091861963272, dist_loss: 0.6678873300552368
recon_loss: 0.04432030767202377, dist_loss: 1.734034538269043
recon_loss: 0.04431973770260811, dist_loss: 1.2636399269104004
recon_loss: 0.04431919381022453, dist_loss: 0.7553215622901917
recon_loss: 0.04431861639022827, dist_loss: 1.0799500942230225
recon_loss: 0.0443180575966835, dist_loss: 1.1102924346923828
recon_loss: 0.04431748762726784, dist_loss: 1.0640411376953125
recon_loss: 0.04431690275669098, dist_loss: 1.169411063194275
recon_loss: 0.044316355139017105, dist_loss: 0.5381264686584473
recon_loss: 0.044315826147794724, dist_loss: 0.8812620639801025
recon_loss: 0.04431527853012085, dist_loss: 0.8138561248779297
recon_loss: 0.04431473836302757, dist_loss: 0.40885889530181885
recon_loss: 0.0443141795694828, dist_loss: 0.7109121084213257
recon_loss: 0.044313620775938034, dist_loss: 0.9719538688659668
recon_loss: 0.044313013553619385, dist_loss: 0.7765476107597351
recon_loss: 0.04431243985891342, dist_loss: 0.8720521926879883
recon_loss: 0.04431186988949776, dist_loss: 0.36730971932411194
recon_loss: 0.0443112812936306, dist_loss: 1.176155686378479
recon_loss: 0.04431068152189255, dist_loss: 1.0416574478149414
recon_loss: 0.04431004822254181, dist_loss: 0.7748715281486511
recon_loss: 0.04430941119790077, dist_loss: 0.7832375168800354
recon_loss: 0.04430881142616272, dist_loss: 0.8109405040740967
recon_loss: 0.044308193027973175, dist_loss: 0.6249121427536011
recon_loss: 0.04430755600333214, dist_loss: 1.117224931716919
recon_loss: 0.04430694133043289, dist_loss: 0.6575887203216553
recon_loss: 0.044306304305791855, dist_loss: 1.2002792358398438
recon_loss: 0.04430565983057022, dist_loss: 0.5507874488830566
recon_loss: 0.044305019080638885, dist_loss: 1.1325788497924805
recon_loss: 0.044304389506578445, dist_loss: 0.5923460721969604
recon_loss: 0.044303786009550095, dist_loss: 0.31035327911376953
recon_loss: 0.04430316388607025, dist_loss: 0.8455244898796082
recon_loss: 0.044302523136138916, dist_loss: 0.5290805697441101
recon_loss: 0.04430188611149788, dist_loss: 1.4291696548461914
recon_loss: 0.044301293790340424, dist_loss: 0.5613165497779846
recon_loss: 0.04430070519447327, dist_loss: 1.004478931427002
recon_loss: 0.04430011287331581, dist_loss: 1.0533335208892822
recon_loss: 0.04429950565099716, dist_loss: 1.1972239017486572
recon_loss: 0.044298894703388214, dist_loss: 0.8255741596221924
recon_loss: 0.044298313558101654, dist_loss: 0.5357903242111206
recon_loss: 0.044297732412815094, dist_loss: 1.0128370523452759
recon_loss: 0.044297147542238235, dist_loss: 1.125271201133728
recon_loss: 0.04429659619927406, dist_loss: 0.44440600275993347
recon_loss: 0.04429604113101959, dist_loss: 0.8109545707702637
recon_loss: 0.04429548978805542, dist_loss: 1.070096731185913
recon_loss: 0.04429493471980095, dist_loss: 0.5995501279830933
recon_loss: 0.04429437592625618, dist_loss: 0.6215164661407471
recon_loss: 0.04429381713271141, dist_loss: 0.7504953742027283
recon_loss: 0.04429323598742485, dist_loss: 0.46658653020858765
recon_loss: 0.0442926362156868, dist_loss: 0.6857906579971313
recon_loss: 0.04429201781749725, dist_loss: 0.8086804151535034
recon_loss: 0.044291406869888306, dist_loss: 0.734130859375
recon_loss: 0.04429081454873085, dist_loss: 0.8062088489532471
recon_loss: 0.044290266931056976, dist_loss: 0.8350151777267456
recon_loss: 0.04428970813751221, dist_loss: 0.7700971364974976
recon_loss: 0.044289130717515945, dist_loss: 0.7793070077896118
recon_loss: 0.04428854584693909, dist_loss: 0.7366589307785034
recon_loss: 0.044287972152233124, dist_loss: 0.5738997459411621
recon_loss: 0.04428740218281746, dist_loss: 0.8913686871528625
recon_loss: 0.0442868210375309, dist_loss: 0.9950641393661499
recon_loss: 0.04428624361753464, dist_loss: 0.7407817840576172
recon_loss: 0.04428565502166748, dist_loss: 0.7414572238922119
recon_loss: 0.044285114854574203, dist_loss: 0.9719753861427307
recon_loss: 0.044284556061029434, dist_loss: 0.8278412818908691
recon_loss: 0.044283971190452576, dist_loss: 0.6055448055267334
recon_loss: 0.04428337141871452, dist_loss: 1.0270476341247559
recon_loss: 0.04428275302052498, dist_loss: 0.4379156231880188
recon_loss: 0.04428212344646454, dist_loss: 1.338099479675293
recon_loss: 0.044281478971242905, dist_loss: 0.5637348890304565
recon_loss: 0.04428081214427948, dist_loss: 0.49687910079956055
recon_loss: 0.044280149042606354, dist_loss: 0.4612787961959839
recon_loss: 0.04427950829267502, dist_loss: 0.5176500678062439
recon_loss: 0.044278863817453384, dist_loss: 0.639896035194397
recon_loss: 0.04427822679281235, dist_loss: 0.43178048729896545
Pre-training Epoch 2:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 2:   5%|▌         | 19/367 [00:00<00:01, 189.08it/s]Pre-training Epoch 2:  10%|█         | 38/367 [00:00<00:01, 181.71it/s]Pre-training Epoch 2:  16%|█▌        | 58/367 [00:00<00:01, 184.53it/s]Pre-training Epoch 2:  21%|██▏       | 78/367 [00:00<00:01, 187.50it/s]Pre-training Epoch 2:  27%|██▋       | 98/367 [00:00<00:01, 189.28it/s]Pre-training Epoch 2:  32%|███▏      | 118/367 [00:00<00:01, 190.21it/s]recon_loss: 0.0442776121199131, dist_loss: 0.6653236150741577
recon_loss: 0.044276975095272064, dist_loss: 0.7796087265014648
recon_loss: 0.04427633807063103, dist_loss: 0.7160294055938721
recon_loss: 0.0442756749689579, dist_loss: 0.9408776164054871
recon_loss: 0.04427498206496239, dist_loss: 0.8634070158004761
recon_loss: 0.04427428916096687, dist_loss: 0.7235412001609802
recon_loss: 0.04427359253168106, dist_loss: 1.1224604845046997
recon_loss: 0.04427294060587883, dist_loss: 0.7086647152900696
recon_loss: 0.04427227005362511, dist_loss: 0.4638211131095886
recon_loss: 0.04427160322666168, dist_loss: 0.9521825313568115
recon_loss: 0.04427099972963333, dist_loss: 0.8517596125602722
recon_loss: 0.04427037760615349, dist_loss: 1.3334732055664062
recon_loss: 0.04426976665854454, dist_loss: 0.8168018460273743
recon_loss: 0.0442691370844841, dist_loss: 0.6820394396781921
recon_loss: 0.04426850378513336, dist_loss: 1.1721686124801636
recon_loss: 0.04426787421107292, dist_loss: 0.3598627746105194
recon_loss: 0.044267259538173676, dist_loss: 0.7386303544044495
recon_loss: 0.04426664486527443, dist_loss: 0.3973698616027832
recon_loss: 0.04426603391766548, dist_loss: 0.5620187520980835
recon_loss: 0.044265396893024445, dist_loss: 0.8454851508140564
recon_loss: 0.044264789670705795, dist_loss: 0.5563068985939026
recon_loss: 0.04426417127251625, dist_loss: 0.7103944420814514
recon_loss: 0.04426352307200432, dist_loss: 1.0144052505493164
recon_loss: 0.04426286742091179, dist_loss: 0.9076658487319946
recon_loss: 0.04426221176981926, dist_loss: 0.8703824877738953
recon_loss: 0.04426158592104912, dist_loss: 0.5844066143035889
recon_loss: 0.04426098242402077, dist_loss: 0.730678379535675
recon_loss: 0.04426038637757301, dist_loss: 0.8749591112136841
recon_loss: 0.044259801506996155, dist_loss: 0.29861336946487427
recon_loss: 0.0442592017352581, dist_loss: 1.100765347480774
recon_loss: 0.04425860196352005, dist_loss: 0.603884220123291
recon_loss: 0.04425801709294319, dist_loss: 0.925966739654541
recon_loss: 0.04425743967294693, dist_loss: 1.0060551166534424
recon_loss: 0.04425685852766037, dist_loss: 0.922616720199585
recon_loss: 0.0442563034594059, dist_loss: 1.2078652381896973
recon_loss: 0.044255759567022324, dist_loss: 0.5666661262512207
recon_loss: 0.04425524175167084, dist_loss: 0.7381730079650879
recon_loss: 0.04425470530986786, dist_loss: 1.0430903434753418
recon_loss: 0.04425419121980667, dist_loss: 0.7770841121673584
recon_loss: 0.04425371065735817, dist_loss: 0.6242518424987793
recon_loss: 0.04425324127078056, dist_loss: 0.8067537546157837
recon_loss: 0.04425279051065445, dist_loss: 0.6236354112625122
recon_loss: 0.04425233229994774, dist_loss: 0.7254787683486938
recon_loss: 0.04425187036395073, dist_loss: 0.7228010296821594
recon_loss: 0.04425141215324402, dist_loss: 1.1961960792541504
recon_loss: 0.04425095394253731, dist_loss: 0.9375784397125244
recon_loss: 0.0442504920065403, dist_loss: 0.6014204621315002
recon_loss: 0.0442500077188015, dist_loss: 0.7258767485618591
recon_loss: 0.044249504804611206, dist_loss: 0.8959033489227295
recon_loss: 0.044249020516872406, dist_loss: 0.7858742475509644
recon_loss: 0.044248539954423904, dist_loss: 0.778695821762085
recon_loss: 0.04424801841378212, dist_loss: 0.6048644185066223
recon_loss: 0.044247474521398544, dist_loss: 0.7216579914093018
recon_loss: 0.04424694553017616, dist_loss: 0.5797516703605652
recon_loss: 0.04424639791250229, dist_loss: 0.7661322355270386
recon_loss: 0.0442458838224411, dist_loss: 0.7386962175369263
recon_loss: 0.044245343655347824, dist_loss: 0.5935455560684204
recon_loss: 0.044244810938835144, dist_loss: 0.9425806403160095
recon_loss: 0.04424428194761276, dist_loss: 0.5204374194145203
recon_loss: 0.044243719428777695, dist_loss: 0.7590056657791138
recon_loss: 0.04424315318465233, dist_loss: 0.5840955972671509
recon_loss: 0.04424256086349487, dist_loss: 0.8666995763778687
recon_loss: 0.044241975992918015, dist_loss: 1.4366625547409058
recon_loss: 0.04424142837524414, dist_loss: 0.7763395309448242
recon_loss: 0.04424089565873146, dist_loss: 0.48566555976867676
recon_loss: 0.04424034059047699, dist_loss: 0.5369635820388794
recon_loss: 0.044239774346351624, dist_loss: 0.8396657705307007
recon_loss: 0.044239211827516556, dist_loss: 0.9177570343017578
recon_loss: 0.044238630682229996, dist_loss: 0.933258593082428
recon_loss: 0.04423805698752403, dist_loss: 0.5244731307029724
recon_loss: 0.04423747956752777, dist_loss: 0.7452197670936584
recon_loss: 0.044236887246370316, dist_loss: 0.5521396398544312
recon_loss: 0.04423628747463226, dist_loss: 0.8802833557128906
recon_loss: 0.0442357063293457, dist_loss: 0.9246776103973389
recon_loss: 0.04423515498638153, dist_loss: 0.8892358541488647
recon_loss: 0.044234588742256165, dist_loss: 0.9938656091690063
recon_loss: 0.044234007596969604, dist_loss: 0.5366091728210449
recon_loss: 0.04423340782523155, dist_loss: 0.6810911893844604
recon_loss: 0.04423283413052559, dist_loss: 0.7864875793457031
recon_loss: 0.04423227161169052, dist_loss: 0.6698375940322876
recon_loss: 0.04423170164227486, dist_loss: 1.127327799797058
recon_loss: 0.04423115402460098, dist_loss: 0.7791670560836792
recon_loss: 0.04423060640692711, dist_loss: 0.7248426675796509
recon_loss: 0.04423005133867264, dist_loss: 0.5446239709854126
recon_loss: 0.04422944784164429, dist_loss: 0.52374267578125
recon_loss: 0.044228844344615936, dist_loss: 0.6991949081420898
recon_loss: 0.044228244572877884, dist_loss: 1.411991834640503
recon_loss: 0.04422767832875252, dist_loss: 0.4816853702068329
recon_loss: 0.04422708973288536, dist_loss: 0.8106029033660889
recon_loss: 0.044226475059986115, dist_loss: 0.4840521216392517
recon_loss: 0.04422585666179657, dist_loss: 0.8895295858383179
recon_loss: 0.04422527179121971, dist_loss: 1.0386083126068115
recon_loss: 0.04422470182180405, dist_loss: 0.8072859048843384
recon_loss: 0.0442240871489048, dist_loss: 0.7219138145446777
recon_loss: 0.044223468750715256, dist_loss: 0.728840708732605
recon_loss: 0.0442228727042675, dist_loss: 0.5638636350631714
recon_loss: 0.04422224685549736, dist_loss: 0.847102165222168
recon_loss: 0.04422162100672722, dist_loss: 0.5887826681137085
recon_loss: 0.044221051037311554, dist_loss: 0.6385762691497803
recon_loss: 0.0442204587161541, dist_loss: 1.0838053226470947
recon_loss: 0.04421991482377052, dist_loss: 1.04102623462677
recon_loss: 0.04421941563487053, dist_loss: 0.891388475894928
recon_loss: 0.044218890368938446, dist_loss: 0.812292218208313
recon_loss: 0.04421836882829666, dist_loss: 1.2397582530975342
recon_loss: 0.04421788454055786, dist_loss: 1.2527859210968018
recon_loss: 0.04421745240688324, dist_loss: 0.5842981338500977
recon_loss: 0.04421700909733772, dist_loss: 0.6323530077934265
recon_loss: 0.04421653226017952, dist_loss: 0.5933250188827515
recon_loss: 0.04421604424715042, dist_loss: 0.6951842308044434
recon_loss: 0.04421556368470192, dist_loss: 0.4964487850666046
recon_loss: 0.04421505331993103, dist_loss: 0.8244113326072693
recon_loss: 0.044214509427547455, dist_loss: 0.8712602257728577
recon_loss: 0.04421391710639, dist_loss: 0.9470431208610535
recon_loss: 0.04421333223581314, dist_loss: 0.3654601573944092
recon_loss: 0.04421272501349449, dist_loss: 0.6986712217330933
recon_loss: 0.04421212896704674, dist_loss: 0.5243467092514038
recon_loss: 0.04421152547001839, dist_loss: 0.47812673449516296
recon_loss: 0.04421090707182884, dist_loss: 0.5329527854919434
recon_loss: 0.044210292398929596, dist_loss: 0.5443873405456543
recon_loss: 0.044209640473127365, dist_loss: 0.8969513177871704
recon_loss: 0.04420895874500275, dist_loss: 0.4058119058609009
recon_loss: 0.044208262115716934, dist_loss: 0.5442415475845337
recon_loss: 0.04420759156346321, dist_loss: 0.8778982758522034
recon_loss: 0.044206924736499786, dist_loss: 0.8111488819122314
recon_loss: 0.04420629143714905, dist_loss: 0.3782346844673157
recon_loss: 0.04420562833547592, dist_loss: 0.7247644066810608
recon_loss: 0.04420499876141548, dist_loss: 0.46570199728012085
recon_loss: 0.04420434311032295, dist_loss: 0.5830070972442627
recon_loss: 0.04420369490981102, dist_loss: 0.6238168478012085
Pre-training Epoch 2:  38%|███▊      | 138/367 [00:00<00:01, 190.86it/s]Pre-training Epoch 2:  43%|████▎     | 158/367 [00:00<00:01, 191.33it/s]Pre-training Epoch 2:  49%|████▊     | 178/367 [00:00<00:00, 191.82it/s]Pre-training Epoch 2:  54%|█████▍    | 198/367 [00:01<00:00, 192.19it/s]Pre-training Epoch 2:  59%|█████▉    | 218/367 [00:01<00:00, 192.49it/s]Pre-training Epoch 2:  65%|██████▍   | 238/367 [00:01<00:00, 190.67it/s]Pre-training Epoch 2:  70%|███████   | 258/367 [00:01<00:00, 191.31it/s]recon_loss: 0.044203050434589386, dist_loss: 0.7491360902786255
recon_loss: 0.04420239478349686, dist_loss: 1.020606517791748
recon_loss: 0.044201746582984924, dist_loss: 0.6230096817016602
recon_loss: 0.0442010834813118, dist_loss: 0.9129300117492676
recon_loss: 0.044200461357831955, dist_loss: 0.913644552230835
recon_loss: 0.04419983550906181, dist_loss: 1.0771434307098389
recon_loss: 0.04419923201203346, dist_loss: 1.1353445053100586
recon_loss: 0.044198621064424515, dist_loss: 0.7651886940002441
recon_loss: 0.04419804736971855, dist_loss: 0.4121150076389313
recon_loss: 0.044197458773851395, dist_loss: 0.9083338975906372
recon_loss: 0.044196873903274536, dist_loss: 0.7312150597572327
recon_loss: 0.04419630393385887, dist_loss: 0.5439349412918091
recon_loss: 0.04419571906328201, dist_loss: 0.5294928550720215
recon_loss: 0.04419515281915665, dist_loss: 1.091348648071289
recon_loss: 0.04419460520148277, dist_loss: 0.44979938864707947
recon_loss: 0.044194016605615616, dist_loss: 0.422075480222702
recon_loss: 0.04419342428445816, dist_loss: 0.8922079801559448
recon_loss: 0.044192835688591, dist_loss: 0.43177348375320435
recon_loss: 0.044192224740982056, dist_loss: 0.8539108037948608
recon_loss: 0.044191598892211914, dist_loss: 0.7640955448150635
recon_loss: 0.04419095441699028, dist_loss: 0.504588782787323
recon_loss: 0.04419030621647835, dist_loss: 0.44109058380126953
recon_loss: 0.04418966546654701, dist_loss: 0.7683478593826294
recon_loss: 0.04418902099132538, dist_loss: 0.5622416734695435
recon_loss: 0.04418833553791046, dist_loss: 0.7746544480323792
recon_loss: 0.04418768733739853, dist_loss: 0.4708554744720459
recon_loss: 0.04418700933456421, dist_loss: 0.5857840776443481
recon_loss: 0.04418633133172989, dist_loss: 0.8112739324569702
recon_loss: 0.04418565705418587, dist_loss: 0.8464993834495544
recon_loss: 0.04418504983186722, dist_loss: 1.4487887620925903
recon_loss: 0.04418446868658066, dist_loss: 0.6438030004501343
recon_loss: 0.04418390244245529, dist_loss: 1.0772572755813599
recon_loss: 0.04418335482478142, dist_loss: 0.9699716567993164
recon_loss: 0.044182781130075455, dist_loss: 1.0736794471740723
recon_loss: 0.04418223351240158, dist_loss: 0.7795208692550659
recon_loss: 0.04418165981769562, dist_loss: 0.9348283410072327
recon_loss: 0.04418109729886055, dist_loss: 0.4438624978065491
recon_loss: 0.04418054223060608, dist_loss: 0.49473780393600464
recon_loss: 0.04417995363473892, dist_loss: 0.5225275754928589
recon_loss: 0.044179338961839676, dist_loss: 0.5897256135940552
recon_loss: 0.04417873173952103, dist_loss: 1.0543642044067383
recon_loss: 0.044178154319524765, dist_loss: 0.5284203290939331
recon_loss: 0.044177569448947906, dist_loss: 0.9156877994537354
recon_loss: 0.04417700320482254, dist_loss: 0.7814170122146606
recon_loss: 0.044176433235406876, dist_loss: 0.4637371301651001
recon_loss: 0.04417583718895912, dist_loss: 0.7158668637275696
recon_loss: 0.044175248593091965, dist_loss: 1.3136502504348755
recon_loss: 0.044174689799547195, dist_loss: 0.7506387233734131
recon_loss: 0.04417414590716362, dist_loss: 1.0262190103530884
recon_loss: 0.044173553586006165, dist_loss: 0.7218071222305298
recon_loss: 0.0441729910671711, dist_loss: 0.8148510456085205
recon_loss: 0.04417239874601364, dist_loss: 0.6381921172142029
recon_loss: 0.04417182132601738, dist_loss: 0.5175332427024841
recon_loss: 0.04417121037840843, dist_loss: 0.6035579442977905
recon_loss: 0.0441705659031868, dist_loss: 1.465683937072754
recon_loss: 0.044169943779706955, dist_loss: 0.5097663998603821
recon_loss: 0.04416930302977562, dist_loss: 1.0362575054168701
recon_loss: 0.044168621301651, dist_loss: 0.575996994972229
recon_loss: 0.04416796192526817, dist_loss: 0.661440908908844
recon_loss: 0.044167306274175644, dist_loss: 1.0291177034378052
recon_loss: 0.04416666179895401, dist_loss: 0.718535304069519
recon_loss: 0.04416600614786148, dist_loss: 0.8001023530960083
recon_loss: 0.04416537284851074, dist_loss: 0.4355123043060303
recon_loss: 0.04416476562619209, dist_loss: 0.9011906385421753
recon_loss: 0.044164128601551056, dist_loss: 0.6029198169708252
recon_loss: 0.0441635400056839, dist_loss: 0.4063653349876404
recon_loss: 0.04416295140981674, dist_loss: 0.4832153916358948
recon_loss: 0.04416239634156227, dist_loss: 0.7352862358093262
recon_loss: 0.044161826372146606, dist_loss: 0.4261244237422943
recon_loss: 0.04416126012802124, dist_loss: 0.9322834014892578
recon_loss: 0.04416067525744438, dist_loss: 1.189224123954773
recon_loss: 0.044160109013319016, dist_loss: 0.5774316787719727
recon_loss: 0.044159550219774246, dist_loss: 0.6392050981521606
recon_loss: 0.04415896534919739, dist_loss: 0.9816238880157471
recon_loss: 0.04415839910507202, dist_loss: 0.5434509515762329
recon_loss: 0.04415785148739815, dist_loss: 0.8280237913131714
recon_loss: 0.044157300144433975, dist_loss: 0.9756064414978027
recon_loss: 0.0441567488014698, dist_loss: 0.3971303701400757
recon_loss: 0.04415617883205414, dist_loss: 0.907561182975769
recon_loss: 0.04415556788444519, dist_loss: 0.5436022877693176
recon_loss: 0.04415493831038475, dist_loss: 0.5756399035453796
recon_loss: 0.04415430873632431, dist_loss: 0.4460199475288391
recon_loss: 0.04415367916226387, dist_loss: 0.7004327774047852
recon_loss: 0.04415305703878403, dist_loss: 0.46478405594825745
recon_loss: 0.044152431190013885, dist_loss: 1.1543896198272705
recon_loss: 0.04415180906653404, dist_loss: 0.49838870763778687
recon_loss: 0.0441511906683445, dist_loss: 0.9855403304100037
recon_loss: 0.04415058717131615, dist_loss: 0.5204674005508423
recon_loss: 0.044149983674287796, dist_loss: 0.5005422830581665
recon_loss: 0.04414938762784004, dist_loss: 0.9398664236068726
recon_loss: 0.044148776680231094, dist_loss: 0.5204361081123352
recon_loss: 0.04414811357855797, dist_loss: 0.8761879205703735
recon_loss: 0.04414747282862663, dist_loss: 0.6070457696914673
recon_loss: 0.0441468209028244, dist_loss: 0.7998747229576111
recon_loss: 0.04414621368050575, dist_loss: 0.8165097832679749
recon_loss: 0.044145625084638596, dist_loss: 0.5030176639556885
recon_loss: 0.044145017862319946, dist_loss: 1.0182311534881592
recon_loss: 0.04414445161819458, dist_loss: 0.6376936435699463
recon_loss: 0.044143855571746826, dist_loss: 0.525863766670227
recon_loss: 0.044143300503492355, dist_loss: 0.5902717113494873
recon_loss: 0.04414274916052818, dist_loss: 0.7295509576797485
recon_loss: 0.044142186641693115, dist_loss: 1.148245096206665
recon_loss: 0.04414166882634163, dist_loss: 0.6396700143814087
recon_loss: 0.044141143560409546, dist_loss: 0.611061155796051
recon_loss: 0.04414059594273567, dist_loss: 0.6373786926269531
recon_loss: 0.044140059500932693, dist_loss: 0.9828816652297974
recon_loss: 0.044139474630355835, dist_loss: 0.7953824400901794
recon_loss: 0.044138893485069275, dist_loss: 1.1086153984069824
recon_loss: 0.04413828253746033, dist_loss: 0.5891844034194946
recon_loss: 0.04413764178752899, dist_loss: 0.808157742023468
recon_loss: 0.04413701221346855, dist_loss: 0.6730474829673767
recon_loss: 0.04413636401295662, dist_loss: 0.47409042716026306
recon_loss: 0.044135741889476776, dist_loss: 1.2201850414276123
recon_loss: 0.044135112315416336, dist_loss: 0.8697085380554199
recon_loss: 0.04413445666432381, dist_loss: 0.5616356134414673
recon_loss: 0.04413380101323128, dist_loss: 1.342985987663269
recon_loss: 0.044133126735687256, dist_loss: 0.8140076398849487
recon_loss: 0.044132474809885025, dist_loss: 0.7053638696670532
recon_loss: 0.044131841510534286, dist_loss: 0.6957271099090576
recon_loss: 0.04413120076060295, dist_loss: 0.6350436210632324
recon_loss: 0.04413054883480072, dist_loss: 0.7530475854873657
recon_loss: 0.04412988945841789, dist_loss: 0.49701136350631714
recon_loss: 0.04412924125790596, dist_loss: 0.5688263177871704
recon_loss: 0.04412863031029701, dist_loss: 0.45770418643951416
recon_loss: 0.04412802308797836, dist_loss: 0.7133479714393616
recon_loss: 0.04412741959095001, dist_loss: 1.0061789751052856
recon_loss: 0.04412681609392166, dist_loss: 0.33093512058258057
recon_loss: 0.044126179069280624, dist_loss: 0.5253516435623169
recon_loss: 0.04412553086876869, dist_loss: 0.7854875326156616
Pre-training Epoch 2:  76%|███████▌  | 278/367 [00:01<00:00, 191.78it/s]Pre-training Epoch 2:  81%|████████  | 298/367 [00:01<00:00, 192.04it/s]Pre-training Epoch 2:  87%|████████▋ | 318/367 [00:01<00:00, 192.26it/s]Pre-training Epoch 2:  92%|█████████▏| 338/367 [00:01<00:00, 192.47it/s]Pre-training Epoch 2:  98%|█████████▊| 358/367 [00:01<00:00, 192.72it/s]Pre-training Epoch 2: 100%|██████████| 367/367 [00:01<00:00, 190.93it/s]
recon_loss: 0.044124871492385864, dist_loss: 0.6169751882553101
recon_loss: 0.04412420466542244, dist_loss: 0.737518310546875
recon_loss: 0.044123560190200806, dist_loss: 0.3424794673919678
recon_loss: 0.044122956693172455, dist_loss: 0.4435569643974304
recon_loss: 0.0441223680973053, dist_loss: 0.8321741819381714
recon_loss: 0.044121794402599335, dist_loss: 0.49086257815361023
recon_loss: 0.04412121698260307, dist_loss: 0.7077406644821167
recon_loss: 0.04412061348557472, dist_loss: 0.5492067337036133
recon_loss: 0.04411996528506279, dist_loss: 0.8144344091415405
recon_loss: 0.04411934316158295, dist_loss: 0.8878516554832458
recon_loss: 0.044118739664554596, dist_loss: 0.7469637393951416
recon_loss: 0.044118162244558334, dist_loss: 0.6024601459503174
recon_loss: 0.04411763325333595, dist_loss: 0.45061543583869934
recon_loss: 0.04411712661385536, dist_loss: 1.0768784284591675
recon_loss: 0.04411669448018074, dist_loss: 0.9099516272544861
recon_loss: 0.044116273522377014, dist_loss: 0.5253349542617798
recon_loss: 0.04411584138870239, dist_loss: 0.4807063043117523
recon_loss: 0.04411539435386658, dist_loss: 0.8269662857055664
recon_loss: 0.04411492496728897, dist_loss: 0.8433519005775452
recon_loss: 0.04411444067955017, dist_loss: 0.5081596374511719
recon_loss: 0.04411393031477928, dist_loss: 0.43919751048088074
recon_loss: 0.044113364070653915, dist_loss: 0.7249028086662292
recon_loss: 0.04411281272768974, dist_loss: 0.801205039024353
recon_loss: 0.044112302362918854, dist_loss: 1.16007661819458
recon_loss: 0.04411176219582558, dist_loss: 0.6400091052055359
recon_loss: 0.0441112220287323, dist_loss: 0.851102352142334
recon_loss: 0.04411071166396141, dist_loss: 1.275746464729309
recon_loss: 0.04411019757390022, dist_loss: 0.6857268810272217
recon_loss: 0.04410964250564575, dist_loss: 0.7979222536087036
recon_loss: 0.044109102338552475, dist_loss: 0.9419286251068115
recon_loss: 0.04410858824849129, dist_loss: 0.49494248628616333
recon_loss: 0.04410805180668831, dist_loss: 0.539514422416687
recon_loss: 0.04410750791430473, dist_loss: 0.7958025932312012
recon_loss: 0.04410693794488907, dist_loss: 0.8893269300460815
recon_loss: 0.044106390327215195, dist_loss: 0.9829727411270142
recon_loss: 0.044105853885412216, dist_loss: 0.5723653435707092
recon_loss: 0.044105321168899536, dist_loss: 0.3593442738056183
recon_loss: 0.04410474747419357, dist_loss: 0.8113667964935303
recon_loss: 0.04410414770245552, dist_loss: 0.8129156827926636
recon_loss: 0.044103529304265976, dist_loss: 0.9554558992385864
recon_loss: 0.04410291463136673, dist_loss: 0.5425163507461548
recon_loss: 0.04410228505730629, dist_loss: 0.6595362424850464
recon_loss: 0.04410170763731003, dist_loss: 0.7910438776016235
recon_loss: 0.044101107865571976, dist_loss: 0.7650438547134399
recon_loss: 0.044100552797317505, dist_loss: 1.0301084518432617
recon_loss: 0.04409999027848244, dist_loss: 0.4283808469772339
recon_loss: 0.04409944638609886, dist_loss: 0.8981728553771973
recon_loss: 0.044098880141973495, dist_loss: 1.3539992570877075
recon_loss: 0.04409832879900932, dist_loss: 0.8932574987411499
recon_loss: 0.04409778118133545, dist_loss: 1.2679537534713745
recon_loss: 0.044097233563661575, dist_loss: 0.8090716004371643
recon_loss: 0.0440966822206974, dist_loss: 0.3510763347148895
recon_loss: 0.04409610852599144, dist_loss: 1.0047314167022705
recon_loss: 0.04409550875425339, dist_loss: 0.5688225030899048
recon_loss: 0.04409490525722504, dist_loss: 0.44415485858917236
recon_loss: 0.0440942756831646, dist_loss: 0.6846755743026733
recon_loss: 0.04409366101026535, dist_loss: 0.6373934745788574
recon_loss: 0.0440930612385273, dist_loss: 0.8835038542747498
recon_loss: 0.044092465192079544, dist_loss: 0.9314112663269043
recon_loss: 0.04409186542034149, dist_loss: 0.6588107347488403
recon_loss: 0.04409123212099075, dist_loss: 0.7955304384231567
recon_loss: 0.04409061372280121, dist_loss: 0.6805766224861145
recon_loss: 0.044089965522289276, dist_loss: 0.6780624389648438
recon_loss: 0.044089313596487045, dist_loss: 1.1129252910614014
recon_loss: 0.044088706374168396, dist_loss: 0.5787049531936646
recon_loss: 0.04408811405301094, dist_loss: 0.6745175123214722
recon_loss: 0.04408752918243408, dist_loss: 1.6346849203109741
recon_loss: 0.04408697038888931, dist_loss: 0.5120248198509216
recon_loss: 0.04408644139766693, dist_loss: 0.8759151101112366
recon_loss: 0.044085919857025146, dist_loss: 1.2690309286117554
recon_loss: 0.04408543184399605, dist_loss: 0.8969953060150146
recon_loss: 0.04408492520451546, dist_loss: 0.8477760553359985
recon_loss: 0.04408442974090576, dist_loss: 0.8854068517684937
recon_loss: 0.04408394545316696, dist_loss: 0.7216790318489075
recon_loss: 0.04408348724246025, dist_loss: 1.0491023063659668
recon_loss: 0.044083017855882645, dist_loss: 1.0212883949279785
recon_loss: 0.04408250376582146, dist_loss: 0.4152509570121765
recon_loss: 0.04408198967576027, dist_loss: 0.787540078163147
recon_loss: 0.044081415981054306, dist_loss: 0.8602676391601562
recon_loss: 0.044080860912799835, dist_loss: 0.8607473373413086
recon_loss: 0.044080302119255066, dist_loss: 0.7136462330818176
recon_loss: 0.044079795479774475, dist_loss: 0.828891396522522
recon_loss: 0.04407930001616478, dist_loss: 0.803389847278595
recon_loss: 0.04407879710197449, dist_loss: 0.6003918647766113
recon_loss: 0.044078290462493896, dist_loss: 0.7307423949241638
recon_loss: 0.04407774284482002, dist_loss: 0.6532018780708313
recon_loss: 0.044077228754758835, dist_loss: 0.5245416760444641
recon_loss: 0.04407668858766556, dist_loss: 0.672639787197113
recon_loss: 0.04407613351941109, dist_loss: 0.6671749353408813
recon_loss: 0.044075578451156616, dist_loss: 0.9228110313415527
recon_loss: 0.044075023382902145, dist_loss: 0.6709176301956177
recon_loss: 0.04407449811697006, dist_loss: 0.9176074266433716
recon_loss: 0.04407394677400589, dist_loss: 0.9978063106536865
recon_loss: 0.04407339170575142, dist_loss: 0.46737658977508545
recon_loss: 0.04407280310988426, dist_loss: 0.7739707231521606
recon_loss: 0.0440722219645977, dist_loss: 0.45952504873275757
recon_loss: 0.04407162219285965, dist_loss: 0.5706636309623718
recon_loss: 0.044071000069379807, dist_loss: 0.7532990574836731
recon_loss: 0.044070396572351456, dist_loss: 0.6276323199272156
recon_loss: 0.04406983032822609, dist_loss: 0.5234994292259216
recon_loss: 0.04406926408410072, dist_loss: 0.6179392337799072
recon_loss: 0.04406868666410446, dist_loss: 0.7996757626533508
recon_loss: 0.044068124145269394, dist_loss: 1.5943927764892578
recon_loss: 0.04406758025288582, dist_loss: 0.8944307565689087
recon_loss: 0.04406706988811493, dist_loss: 0.47714298963546753
recon_loss: 0.04406656697392464, dist_loss: 1.0197677612304688
recon_loss: 0.04406607896089554, dist_loss: 0.6213492155075073
recon_loss: 0.04406557232141495, dist_loss: 0.5830123424530029
recon_loss: 0.04406505450606346, dist_loss: 1.924020767211914
Pre-training Epoch 3:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 3:   5%|▌         | 19/367 [00:00<00:01, 189.05it/s]Pre-training Epoch 3:  10%|█         | 38/367 [00:00<00:01, 183.57it/s]Pre-training Epoch 3:  16%|█▌        | 57/367 [00:00<00:01, 181.48it/s]Pre-training Epoch 3:  21%|██        | 76/367 [00:00<00:01, 181.18it/s]Pre-training Epoch 3:  26%|██▌       | 95/367 [00:00<00:01, 181.22it/s]Pre-training Epoch 3:  31%|███       | 114/367 [00:00<00:01, 181.62it/s]recon_loss: 0.04406457766890526, dist_loss: 0.967626690864563
recon_loss: 0.04406408965587616, dist_loss: 0.530052125453949
recon_loss: 0.04406359791755676, dist_loss: 0.8394690752029419
recon_loss: 0.04406311362981796, dist_loss: 1.2593698501586914
recon_loss: 0.04406261816620827, dist_loss: 0.8232792615890503
recon_loss: 0.04406211897730827, dist_loss: 1.059808373451233
recon_loss: 0.044061608612537384, dist_loss: 0.628703236579895
recon_loss: 0.0440610870718956, dist_loss: 0.6888918876647949
recon_loss: 0.04406055435538292, dist_loss: 0.5547366738319397
recon_loss: 0.044060029089450836, dist_loss: 0.6347383856773376
recon_loss: 0.04405948147177696, dist_loss: 0.7569102048873901
recon_loss: 0.04405893385410309, dist_loss: 1.0529955625534058
recon_loss: 0.04405837878584862, dist_loss: 0.39925941824913025
recon_loss: 0.04405784234404564, dist_loss: 1.0706321001052856
recon_loss: 0.04405732825398445, dist_loss: 0.7114326357841492
recon_loss: 0.044056810438632965, dist_loss: 0.3833006024360657
recon_loss: 0.044056281447410583, dist_loss: 0.6617310047149658
recon_loss: 0.04405578598380089, dist_loss: 0.8776895999908447
recon_loss: 0.04405531659722328, dist_loss: 0.2718372344970703
recon_loss: 0.04405481368303299, dist_loss: 0.45243483781814575
recon_loss: 0.044054269790649414, dist_loss: 0.7150324583053589
recon_loss: 0.04405374079942703, dist_loss: 0.5072208642959595
recon_loss: 0.044053204357624054, dist_loss: 0.9682992696762085
recon_loss: 0.04405264928936958, dist_loss: 0.8911629915237427
recon_loss: 0.044052090495824814, dist_loss: 0.5951036810874939
recon_loss: 0.044051531702280045, dist_loss: 0.5155194997787476
recon_loss: 0.044050950556993484, dist_loss: 0.48597630858421326
recon_loss: 0.04405038431286812, dist_loss: 0.7842690944671631
recon_loss: 0.04404980316758156, dist_loss: 0.4295486807823181
recon_loss: 0.04404924809932709, dist_loss: 0.8083785772323608
recon_loss: 0.04404870793223381, dist_loss: 0.7537959218025208
recon_loss: 0.04404813423752785, dist_loss: 1.241434097290039
recon_loss: 0.044047582894563675, dist_loss: 1.2485322952270508
recon_loss: 0.044047050178050995, dist_loss: 1.2094290256500244
recon_loss: 0.04404645413160324, dist_loss: 0.41356369853019714
recon_loss: 0.044045839458703995, dist_loss: 0.7352660894393921
recon_loss: 0.04404521360993385, dist_loss: 0.3502348065376282
recon_loss: 0.044044554233551025, dist_loss: 0.6746170520782471
recon_loss: 0.044043928384780884, dist_loss: 0.516683042049408
recon_loss: 0.04404332861304283, dist_loss: 0.4704260528087616
recon_loss: 0.044042713940143585, dist_loss: 0.4267457127571106
recon_loss: 0.044042035937309265, dist_loss: 0.9154621958732605
recon_loss: 0.04404134303331375, dist_loss: 0.6485491991043091
recon_loss: 0.04404064267873764, dist_loss: 0.7846172451972961
recon_loss: 0.04403996095061302, dist_loss: 1.0211631059646606
recon_loss: 0.0440392903983593, dist_loss: 0.6803956627845764
recon_loss: 0.04403861612081528, dist_loss: 0.5304141640663147
recon_loss: 0.044037919491529465, dist_loss: 0.6531350612640381
recon_loss: 0.04403721168637276, dist_loss: 0.5979969501495361
recon_loss: 0.04403651878237724, dist_loss: 0.8106826543807983
recon_loss: 0.04403580725193024, dist_loss: 1.0618325471878052
recon_loss: 0.04403514042496681, dist_loss: 0.6572377681732178
recon_loss: 0.04403449594974518, dist_loss: 1.2578253746032715
recon_loss: 0.04403394088149071, dist_loss: 0.4986041784286499
recon_loss: 0.04403340816497803, dist_loss: 0.8337845206260681
recon_loss: 0.044032853096723557, dist_loss: 1.2644047737121582
recon_loss: 0.0440322682261467, dist_loss: 0.9248453378677368
recon_loss: 0.04403168708086014, dist_loss: 0.6097326278686523
recon_loss: 0.04403107613325119, dist_loss: 0.9754490852355957
recon_loss: 0.044030431658029556, dist_loss: 0.9628887176513672
recon_loss: 0.04402979463338852, dist_loss: 1.1170523166656494
recon_loss: 0.04402916878461838, dist_loss: 0.7466838955879211
recon_loss: 0.044028546661138535, dist_loss: 0.5111461281776428
recon_loss: 0.0440279096364975, dist_loss: 1.2591743469238281
recon_loss: 0.04402729496359825, dist_loss: 0.6330377459526062
recon_loss: 0.0440266877412796, dist_loss: 0.774479866027832
recon_loss: 0.04402609169483185, dist_loss: 0.6379837989807129
recon_loss: 0.044025491923093796, dist_loss: 0.7590049505233765
recon_loss: 0.04402486979961395, dist_loss: 0.5343930125236511
recon_loss: 0.0440242663025856, dist_loss: 0.6668820977210999
recon_loss: 0.044023651629686356, dist_loss: 0.7326135635375977
recon_loss: 0.0440230518579483, dist_loss: 0.40950489044189453
recon_loss: 0.04402245581150055, dist_loss: 0.5701615810394287
recon_loss: 0.0440218523144722, dist_loss: 1.025559663772583
recon_loss: 0.04402122274041176, dist_loss: 0.7696202397346497
recon_loss: 0.04402056708931923, dist_loss: 0.38300374150276184
recon_loss: 0.04401988536119461, dist_loss: 0.906165599822998
recon_loss: 0.0440191887319088, dist_loss: 0.4936998188495636
recon_loss: 0.044018492102622986, dist_loss: 1.3212103843688965
recon_loss: 0.04401782155036926, dist_loss: 0.741395115852356
recon_loss: 0.04401712119579315, dist_loss: 0.655672550201416
recon_loss: 0.04401646926999092, dist_loss: 0.5917261242866516
recon_loss: 0.04401582106947899, dist_loss: 0.9611382484436035
recon_loss: 0.04401516914367676, dist_loss: 0.6369002461433411
recon_loss: 0.04401453211903572, dist_loss: 0.9696443676948547
recon_loss: 0.044013891369104385, dist_loss: 0.6775615215301514
recon_loss: 0.044013235718011856, dist_loss: 1.1362890005111694
recon_loss: 0.044012587517499924, dist_loss: 0.591782808303833
recon_loss: 0.044011957943439484, dist_loss: 0.7493388652801514
recon_loss: 0.04401130974292755, dist_loss: 0.8383088707923889
recon_loss: 0.04401065781712532, dist_loss: 0.7650536894798279
recon_loss: 0.044010013341903687, dist_loss: 0.818781852722168
recon_loss: 0.04400938004255295, dist_loss: 0.48520374298095703
recon_loss: 0.04400870203971863, dist_loss: 0.4222721457481384
recon_loss: 0.04400797188282013, dist_loss: 0.5255644917488098
recon_loss: 0.04400722682476044, dist_loss: 0.8199952840805054
recon_loss: 0.04400653392076492, dist_loss: 0.5622109174728394
recon_loss: 0.044005874544382095, dist_loss: 0.85455322265625
recon_loss: 0.044005293399095535, dist_loss: 0.5520339012145996
recon_loss: 0.044004689902067184, dist_loss: 0.604148268699646
recon_loss: 0.04400407522916794, dist_loss: 0.573348879814148
recon_loss: 0.0440034419298172, dist_loss: 0.7600479125976562
recon_loss: 0.04400283470749855, dist_loss: 0.5009777545928955
recon_loss: 0.044002242386341095, dist_loss: 0.7840249538421631
recon_loss: 0.04400163143873215, dist_loss: 0.9059569835662842
recon_loss: 0.0440010167658329, dist_loss: 1.261030912399292
recon_loss: 0.04400041699409485, dist_loss: 0.7069501280784607
recon_loss: 0.043999865651130676, dist_loss: 0.9390926957130432
recon_loss: 0.04399934038519859, dist_loss: 0.741904616355896
recon_loss: 0.0439988374710083, dist_loss: 0.8198481798171997
recon_loss: 0.0439983569085598, dist_loss: 0.48433372378349304
recon_loss: 0.043997872620821, dist_loss: 0.42902711033821106
recon_loss: 0.0439973883330822, dist_loss: 0.7596907615661621
recon_loss: 0.043996959924697876, dist_loss: 0.6853919625282288
recon_loss: 0.04399648681282997, dist_loss: 0.8273266553878784
recon_loss: 0.043996043503284454, dist_loss: 0.6435036659240723
recon_loss: 0.04399562627077103, dist_loss: 0.9445772171020508
recon_loss: 0.04399517551064491, dist_loss: 0.3771178722381592
recon_loss: 0.043994709849357605, dist_loss: 0.8437303304672241
recon_loss: 0.04399421438574791, dist_loss: 1.0197105407714844
recon_loss: 0.043993670493364334, dist_loss: 0.828162670135498
recon_loss: 0.04399311542510986, dist_loss: 0.7236210703849792
recon_loss: 0.04399259388446808, dist_loss: 0.5634776949882507
recon_loss: 0.04399203881621361, dist_loss: 0.9113384485244751
recon_loss: 0.043991465121507645, dist_loss: 0.7582818269729614
recon_loss: 0.043990906327962875, dist_loss: 0.3895411789417267
recon_loss: 0.043990377336740494, dist_loss: 0.6843586564064026
recon_loss: 0.043989863246679306, dist_loss: 0.5876061320304871
recon_loss: 0.04398931935429573, dist_loss: 0.5101295709609985
Pre-training Epoch 3:  36%|███▌      | 133/367 [00:00<00:01, 176.51it/s]Pre-training Epoch 3:  42%|████▏     | 153/367 [00:00<00:01, 181.52it/s]Pre-training Epoch 3:  47%|████▋     | 172/367 [00:00<00:01, 181.81it/s]Pre-training Epoch 3:  52%|█████▏    | 191/367 [00:01<00:00, 181.38it/s]Pre-training Epoch 3:  57%|█████▋    | 211/367 [00:01<00:00, 184.92it/s]Pre-training Epoch 3:  63%|██████▎   | 231/367 [00:01<00:00, 187.21it/s]Pre-training Epoch 3:  68%|██████▊   | 251/367 [00:01<00:00, 189.15it/s]recon_loss: 0.043988775461912155, dist_loss: 0.6030337810516357
recon_loss: 0.04398823902010918, dist_loss: 0.5219013690948486
recon_loss: 0.04398772865533829, dist_loss: 1.2170453071594238
recon_loss: 0.04398725926876068, dist_loss: 0.5211576223373413
recon_loss: 0.04398676007986069, dist_loss: 0.9629509449005127
recon_loss: 0.0439862459897995, dist_loss: 0.8108904361724854
recon_loss: 0.043985720723867416, dist_loss: 0.6543693542480469
recon_loss: 0.043985191732645035, dist_loss: 0.892113447189331
recon_loss: 0.04398468881845474, dist_loss: 1.009385347366333
recon_loss: 0.043984122574329376, dist_loss: 0.5858790874481201
recon_loss: 0.04398354887962341, dist_loss: 0.3897102177143097
recon_loss: 0.04398294910788536, dist_loss: 0.4758272171020508
recon_loss: 0.043982382863759995, dist_loss: 0.7450677752494812
recon_loss: 0.043981827795505524, dist_loss: 1.4681897163391113
recon_loss: 0.04398125782608986, dist_loss: 0.8212155103683472
recon_loss: 0.043980687856674194, dist_loss: 0.5780767202377319
recon_loss: 0.04398011043667793, dist_loss: 0.634363055229187
recon_loss: 0.04397951439023018, dist_loss: 0.4869533181190491
recon_loss: 0.043978914618492126, dist_loss: 0.8035250902175903
recon_loss: 0.04397827386856079, dist_loss: 0.7934931516647339
recon_loss: 0.043977584689855576, dist_loss: 0.5309978723526001
recon_loss: 0.043976861983537674, dist_loss: 0.981368899345398
recon_loss: 0.043976183980703354, dist_loss: 1.2069740295410156
recon_loss: 0.04397553205490112, dist_loss: 0.7604538202285767
recon_loss: 0.0439748615026474, dist_loss: 0.7425203323364258
recon_loss: 0.043974194675683975, dist_loss: 0.5953731536865234
recon_loss: 0.04397357255220413, dist_loss: 0.7171930074691772
recon_loss: 0.043972957879304886, dist_loss: 0.43390172719955444
recon_loss: 0.043972354382276535, dist_loss: 0.7148524522781372
recon_loss: 0.04397175461053848, dist_loss: 0.4266648590564728
recon_loss: 0.04397113248705864, dist_loss: 0.5281038284301758
recon_loss: 0.043970536440610886, dist_loss: 0.5707476735115051
recon_loss: 0.043969959020614624, dist_loss: 0.6942572593688965
recon_loss: 0.04396936297416687, dist_loss: 1.2293425798416138
recon_loss: 0.04396875947713852, dist_loss: 0.49175772070884705
recon_loss: 0.043968185782432556, dist_loss: 0.8555198907852173
recon_loss: 0.04396761208772659, dist_loss: 1.0820657014846802
recon_loss: 0.04396701976656914, dist_loss: 0.59541255235672
recon_loss: 0.04396643117070198, dist_loss: 0.7964760065078735
recon_loss: 0.04396585375070572, dist_loss: 0.9453881978988647
recon_loss: 0.04396527633070946, dist_loss: 0.4386899471282959
recon_loss: 0.0439646877348423, dist_loss: 1.138761281967163
recon_loss: 0.04396414756774902, dist_loss: 0.43015146255493164
recon_loss: 0.043963588774204254, dist_loss: 1.1050571203231812
recon_loss: 0.04396304115653038, dist_loss: 0.673264741897583
recon_loss: 0.0439625047147274, dist_loss: 0.4924582839012146
recon_loss: 0.04396194964647293, dist_loss: 0.8367160558700562
recon_loss: 0.04396137222647667, dist_loss: 0.44119930267333984
recon_loss: 0.04396079480648041, dist_loss: 0.9800820350646973
recon_loss: 0.04396020993590355, dist_loss: 0.9328590631484985
recon_loss: 0.04395964369177818, dist_loss: 0.8487893342971802
recon_loss: 0.043959081172943115, dist_loss: 0.7931182384490967
recon_loss: 0.04395854473114014, dist_loss: 0.5726871490478516
recon_loss: 0.04395800828933716, dist_loss: 0.8661802411079407
recon_loss: 0.04395747184753418, dist_loss: 0.6725971698760986
recon_loss: 0.043956924229860306, dist_loss: 0.5871440172195435
recon_loss: 0.04395640268921852, dist_loss: 0.7793823480606079
recon_loss: 0.04395590350031853, dist_loss: 0.6668803691864014
recon_loss: 0.04395538941025734, dist_loss: 0.7719863653182983
recon_loss: 0.04395487904548645, dist_loss: 0.664188027381897
recon_loss: 0.04395439848303795, dist_loss: 1.0525329113006592
recon_loss: 0.043953947722911835, dist_loss: 0.5586621761322021
recon_loss: 0.04395349323749542, dist_loss: 0.3619764447212219
recon_loss: 0.04395302012562752, dist_loss: 0.9303607940673828
recon_loss: 0.04395252838730812, dist_loss: 0.638987123966217
recon_loss: 0.04395202919840813, dist_loss: 0.7818785905838013
recon_loss: 0.04395158588886261, dist_loss: 0.41312575340270996
recon_loss: 0.043951116502285004, dist_loss: 1.0363270044326782
recon_loss: 0.04395066574215889, dist_loss: 0.6985120177268982
recon_loss: 0.043950196355581284, dist_loss: 0.9948244690895081
recon_loss: 0.04394972324371338, dist_loss: 0.850264310836792
recon_loss: 0.04394929111003876, dist_loss: 0.5910457372665405
recon_loss: 0.04394886642694473, dist_loss: 1.1058993339538574
recon_loss: 0.0439484678208828, dist_loss: 0.5677895545959473
recon_loss: 0.04394805431365967, dist_loss: 0.6050170063972473
recon_loss: 0.04394765570759773, dist_loss: 0.6009417772293091
recon_loss: 0.043947260826826096, dist_loss: 0.23159188032150269
recon_loss: 0.04394686222076416, dist_loss: 0.7480608820915222
recon_loss: 0.04394640401005745, dist_loss: 0.6798708438873291
recon_loss: 0.04394594579935074, dist_loss: 1.3443636894226074
recon_loss: 0.043945468962192535, dist_loss: 0.7122709155082703
recon_loss: 0.04394502192735672, dist_loss: 0.5689176917076111
recon_loss: 0.043944600969552994, dist_loss: 0.7129874229431152
recon_loss: 0.04394415766000748, dist_loss: 0.9699462652206421
recon_loss: 0.04394372180104256, dist_loss: 0.6173133850097656
recon_loss: 0.04394328221678734, dist_loss: 0.714024543762207
recon_loss: 0.04394280165433884, dist_loss: 0.8012672662734985
recon_loss: 0.043942343443632126, dist_loss: 1.1146320104599
recon_loss: 0.043941929936409, dist_loss: 0.6421126127243042
recon_loss: 0.04394151270389557, dist_loss: 0.8305132985115051
recon_loss: 0.043941035866737366, dist_loss: 0.6836864948272705
recon_loss: 0.043940525501966476, dist_loss: 0.9463094472885132
recon_loss: 0.04394003003835678, dist_loss: 0.8156055212020874
recon_loss: 0.0439395010471344, dist_loss: 0.9347205758094788
recon_loss: 0.04393893480300903, dist_loss: 0.4574720561504364
recon_loss: 0.043938346207141876, dist_loss: 0.6581566333770752
recon_loss: 0.04393777996301651, dist_loss: 0.5607726573944092
recon_loss: 0.04393719509243965, dist_loss: 0.4021061658859253
recon_loss: 0.043936606496572495, dist_loss: 0.39774882793426514
recon_loss: 0.04393600672483444, dist_loss: 0.4315544366836548
recon_loss: 0.04393541440367699, dist_loss: 0.6325773000717163
recon_loss: 0.043934814631938934, dist_loss: 0.7353869080543518
recon_loss: 0.043934233486652374, dist_loss: 0.6910867691040039
recon_loss: 0.04393361881375313, dist_loss: 0.8469719886779785
recon_loss: 0.043933045119047165, dist_loss: 0.6687714457511902
recon_loss: 0.043932463973760605, dist_loss: 0.682548999786377
recon_loss: 0.04393187537789345, dist_loss: 0.5465198755264282
recon_loss: 0.04393128305673599, dist_loss: 0.9246277213096619
recon_loss: 0.04393067955970764, dist_loss: 0.707358181476593
recon_loss: 0.04393007978796959, dist_loss: 0.9437485337257385
recon_loss: 0.04392951726913452, dist_loss: 1.232908010482788
recon_loss: 0.04392898082733154, dist_loss: 0.9757012128829956
recon_loss: 0.04392843693494797, dist_loss: 0.7543594837188721
recon_loss: 0.043927911669015884, dist_loss: 0.8011937737464905
recon_loss: 0.0439273938536644, dist_loss: 1.1530998945236206
recon_loss: 0.04392685741186142, dist_loss: 0.9086072444915771
recon_loss: 0.04392629861831665, dist_loss: 0.8056508302688599
recon_loss: 0.04392575845122337, dist_loss: 0.7038091421127319
recon_loss: 0.04392522573471069, dist_loss: 0.43642136454582214
recon_loss: 0.04392470046877861, dist_loss: 0.4219639301300049
recon_loss: 0.043924182653427124, dist_loss: 0.8274496793746948
recon_loss: 0.04392366483807564, dist_loss: 0.5313592553138733
recon_loss: 0.04392315819859505, dist_loss: 0.5929254293441772
recon_loss: 0.04392264410853386, dist_loss: 0.4860132336616516
recon_loss: 0.04392213374376297, dist_loss: 0.9539682269096375
recon_loss: 0.04392164200544357, dist_loss: 0.494486004114151
recon_loss: 0.04392116144299507, dist_loss: 0.8151403069496155
recon_loss: 0.04392069950699806, dist_loss: 0.3989681899547577
recon_loss: 0.04392022639513016, dist_loss: 0.5042487382888794
Pre-training Epoch 3:  74%|███████▍  | 271/367 [00:01<00:00, 190.47it/s]Pre-training Epoch 3:  79%|███████▉  | 291/367 [00:01<00:00, 191.39it/s]Pre-training Epoch 3:  85%|████████▍ | 311/367 [00:01<00:00, 192.07it/s]Pre-training Epoch 3:  90%|█████████ | 331/367 [00:01<00:00, 190.89it/s]Pre-training Epoch 3:  96%|█████████▌| 351/367 [00:01<00:00, 191.62it/s]Pre-training Epoch 3: 100%|██████████| 367/367 [00:01<00:00, 186.58it/s]
recon_loss: 0.043919771909713745, dist_loss: 0.6184823513031006
recon_loss: 0.043919287621974945, dist_loss: 0.49341684579849243
recon_loss: 0.04391884058713913, dist_loss: 0.8597281575202942
recon_loss: 0.043918412178754807, dist_loss: 0.8756036162376404
recon_loss: 0.04391796886920929, dist_loss: 0.5437082052230835
recon_loss: 0.043917492032051086, dist_loss: 0.5659545063972473
recon_loss: 0.04391700401902199, dist_loss: 1.1832995414733887
recon_loss: 0.043916504830121994, dist_loss: 1.0003852844238281
recon_loss: 0.04391596093773842, dist_loss: 0.6366331577301025
recon_loss: 0.04391541704535484, dist_loss: 0.6321972608566284
recon_loss: 0.04391488432884216, dist_loss: 0.5685718655586243
recon_loss: 0.04391435161232948, dist_loss: 0.6387565732002258
recon_loss: 0.043913837522268295, dist_loss: 0.6002706289291382
recon_loss: 0.043913330882787704, dist_loss: 0.7252787351608276
recon_loss: 0.0439128652215004, dist_loss: 0.585476279258728
recon_loss: 0.04391239583492279, dist_loss: 0.6198325753211975
recon_loss: 0.04391193762421608, dist_loss: 1.0562893152236938
recon_loss: 0.04391144961118698, dist_loss: 0.42232027649879456
recon_loss: 0.04391096159815788, dist_loss: 0.7679790258407593
recon_loss: 0.04391048103570938, dist_loss: 0.5851150155067444
recon_loss: 0.043909959495067596, dist_loss: 0.9634586572647095
recon_loss: 0.04390944167971611, dist_loss: 0.6448739767074585
recon_loss: 0.04390891268849373, dist_loss: 1.2002497911453247
recon_loss: 0.04390839487314224, dist_loss: 0.9557278752326965
recon_loss: 0.04390789195895195, dist_loss: 0.493206262588501
recon_loss: 0.04390738904476166, dist_loss: 0.55881267786026
recon_loss: 0.04390690103173256, dist_loss: 0.47744593024253845
recon_loss: 0.04390641301870346, dist_loss: 0.545352578163147
recon_loss: 0.04390590637922287, dist_loss: 0.802166223526001
recon_loss: 0.043905410915613174, dist_loss: 0.7509335279464722
recon_loss: 0.04390496015548706, dist_loss: 0.6415234804153442
recon_loss: 0.04390450194478035, dist_loss: 0.59250807762146
recon_loss: 0.04390401393175125, dist_loss: 0.4205290675163269
recon_loss: 0.043903518468141556, dist_loss: 0.9807736277580261
recon_loss: 0.04390301927924156, dist_loss: 1.0882163047790527
recon_loss: 0.043902527540922165, dist_loss: 0.7784651517868042
recon_loss: 0.04390203580260277, dist_loss: 0.493973970413208
recon_loss: 0.04390152171254158, dist_loss: 0.9176790714263916
recon_loss: 0.0439009927213192, dist_loss: 1.2595875263214111
recon_loss: 0.04390048235654831, dist_loss: 1.0176377296447754
recon_loss: 0.04389994964003563, dist_loss: 1.0819143056869507
recon_loss: 0.04389944300055504, dist_loss: 0.7094540596008301
recon_loss: 0.043898943811655045, dist_loss: 0.7064998149871826
recon_loss: 0.04389844089746475, dist_loss: 0.4539788067340851
recon_loss: 0.04389793798327446, dist_loss: 0.6928282380104065
recon_loss: 0.043897416442632675, dist_loss: 0.8378171920776367
recon_loss: 0.04389693960547447, dist_loss: 0.7196884751319885
recon_loss: 0.04389643669128418, dist_loss: 1.1159601211547852
recon_loss: 0.04389595612883568, dist_loss: 0.991935133934021
recon_loss: 0.04389543458819389, dist_loss: 0.680488109588623
recon_loss: 0.0438949316740036, dist_loss: 0.9333246350288391
recon_loss: 0.043894439935684204, dist_loss: 0.6624929308891296
recon_loss: 0.04389400780200958, dist_loss: 1.059128761291504
recon_loss: 0.043893564492464066, dist_loss: 0.40853893756866455
recon_loss: 0.043893102556467056, dist_loss: 0.6494501829147339
recon_loss: 0.043892666697502136, dist_loss: 0.6966962814331055
recon_loss: 0.04389222711324692, dist_loss: 0.6711252331733704
recon_loss: 0.04389176890254021, dist_loss: 0.3534458577632904
recon_loss: 0.043891292065382004, dist_loss: 0.47846439480781555
recon_loss: 0.0438908115029335, dist_loss: 0.8917731642723083
recon_loss: 0.043890342116355896, dist_loss: 0.7058621048927307
recon_loss: 0.04388987645506859, dist_loss: 0.8785521984100342
recon_loss: 0.04388940706849098, dist_loss: 0.8578407764434814
recon_loss: 0.04388895630836487, dist_loss: 0.8941932916641235
recon_loss: 0.04388844594359398, dist_loss: 0.5674597024917603
recon_loss: 0.04388793185353279, dist_loss: 0.4422353208065033
recon_loss: 0.04388739913702011, dist_loss: 0.5099949240684509
recon_loss: 0.04388686642050743, dist_loss: 1.000922679901123
recon_loss: 0.04388636350631714, dist_loss: 1.013543725013733
recon_loss: 0.043885841965675354, dist_loss: 0.6468605995178223
recon_loss: 0.04388532042503357, dist_loss: 0.6526387333869934
recon_loss: 0.04388479143381119, dist_loss: 0.4207606315612793
recon_loss: 0.04388425871729851, dist_loss: 0.31263992190361023
recon_loss: 0.04388371855020523, dist_loss: 0.5279611349105835
recon_loss: 0.04388315975666046, dist_loss: 0.6147125363349915
recon_loss: 0.043882619589567184, dist_loss: 0.4451403319835663
recon_loss: 0.043882086873054504, dist_loss: 0.5759832262992859
recon_loss: 0.043881554156541824, dist_loss: 0.5120761394500732
recon_loss: 0.043881017714738846, dist_loss: 0.6350891590118408
recon_loss: 0.04388046637177467, dist_loss: 0.7625633478164673
recon_loss: 0.0438799150288105, dist_loss: 0.6480951309204102
recon_loss: 0.04387937858700752, dist_loss: 0.6006160974502563
recon_loss: 0.043878864496946335, dist_loss: 1.0505989789962769
recon_loss: 0.043878354132175446, dist_loss: 0.5634351968765259
recon_loss: 0.04387785494327545, dist_loss: 0.8854496479034424
recon_loss: 0.04387730732560158, dist_loss: 0.9810919165611267
recon_loss: 0.04387678951025009, dist_loss: 0.8289410471916199
recon_loss: 0.0438762791454792, dist_loss: 1.0491714477539062
recon_loss: 0.043875712901353836, dist_loss: 1.2019540071487427
recon_loss: 0.043875157833099365, dist_loss: 0.6075335741043091
recon_loss: 0.04387463629245758, dist_loss: 0.5297832489013672
recon_loss: 0.04387413710355759, dist_loss: 0.7356517314910889
recon_loss: 0.04387368634343147, dist_loss: 0.5979824066162109
recon_loss: 0.043873246759176254, dist_loss: 0.603417158126831
recon_loss: 0.04387284442782402, dist_loss: 0.6772096157073975
recon_loss: 0.0438724085688591, dist_loss: 0.6977837085723877
recon_loss: 0.04387196525931358, dist_loss: 1.0122525691986084
recon_loss: 0.04387148842215538, dist_loss: 0.670742392539978
recon_loss: 0.043871015310287476, dist_loss: 0.8283916711807251
recon_loss: 0.04387051612138748, dist_loss: 0.44092661142349243
recon_loss: 0.043870050460100174, dist_loss: 0.6017346382141113
recon_loss: 0.043869584798812866, dist_loss: 0.3195739984512329
recon_loss: 0.04386911913752556, dist_loss: 0.8147153854370117
recon_loss: 0.04386866092681885, dist_loss: 0.45541641116142273
recon_loss: 0.043868158012628555, dist_loss: 0.5931467413902283
recon_loss: 0.04386763647198677, dist_loss: 0.7420847415924072
recon_loss: 0.04386715590953827, dist_loss: 0.5062435269355774
recon_loss: 0.043866660445928574, dist_loss: 0.7098565101623535
recon_loss: 0.04386619105935097, dist_loss: 0.6570326685905457
Pre-training Epoch 4:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 4:   5%|▌         | 19/367 [00:00<00:01, 189.86it/s]Pre-training Epoch 4:  11%|█         | 39/367 [00:00<00:01, 191.88it/s]Pre-training Epoch 4:  16%|█▌        | 59/367 [00:00<00:01, 192.68it/s]Pre-training Epoch 4:  22%|██▏       | 79/367 [00:00<00:01, 193.01it/s]Pre-training Epoch 4:  27%|██▋       | 99/367 [00:00<00:01, 193.11it/s]Pre-training Epoch 4:  32%|███▏      | 119/367 [00:00<00:01, 193.24it/s]recon_loss: 0.04386570304632187, dist_loss: 0.7337602376937866
recon_loss: 0.04386520758271217, dist_loss: 1.0378104448318481
recon_loss: 0.043864697217941284, dist_loss: 0.7777241468429565
recon_loss: 0.0438641719520092, dist_loss: 0.47558608651161194
recon_loss: 0.043863650411367416, dist_loss: 1.9593331813812256
recon_loss: 0.04386314004659653, dist_loss: 0.40691399574279785
recon_loss: 0.04386265203356743, dist_loss: 0.35912203788757324
recon_loss: 0.04386214166879654, dist_loss: 1.4520795345306396
recon_loss: 0.04386164993047714, dist_loss: 0.44357436895370483
recon_loss: 0.04386114329099655, dist_loss: 1.028975248336792
recon_loss: 0.04386068508028984, dist_loss: 0.8536728620529175
recon_loss: 0.04386017844080925, dist_loss: 0.869355320930481
recon_loss: 0.04385969042778015, dist_loss: 1.086559534072876
recon_loss: 0.043859176337718964, dist_loss: 0.4948854446411133
recon_loss: 0.04385865852236748, dist_loss: 0.626310408115387
recon_loss: 0.0438581220805645, dist_loss: 0.582073986530304
recon_loss: 0.043857596814632416, dist_loss: 0.6431105136871338
recon_loss: 0.043857090175151825, dist_loss: 0.5454959273338318
recon_loss: 0.043856557458639145, dist_loss: 1.1282768249511719
recon_loss: 0.043856047093868256, dist_loss: 0.5958843231201172
recon_loss: 0.04385557025671005, dist_loss: 0.5943850874900818
recon_loss: 0.04385509341955185, dist_loss: 0.5804282426834106
recon_loss: 0.043854616582393646, dist_loss: 0.932056725025177
recon_loss: 0.04385412111878395, dist_loss: 0.6836752891540527
recon_loss: 0.04385361820459366, dist_loss: 0.6624611616134644
recon_loss: 0.04385310038924217, dist_loss: 0.8597129583358765
recon_loss: 0.043852582573890686, dist_loss: 0.6962886452674866
recon_loss: 0.0438520610332489, dist_loss: 0.6832676529884338
recon_loss: 0.04385155066847801, dist_loss: 0.5940446853637695
recon_loss: 0.04385104402899742, dist_loss: 0.6587860584259033
recon_loss: 0.04385054484009743, dist_loss: 0.717646598815918
recon_loss: 0.043850064277648926, dist_loss: 0.6829913854598999
recon_loss: 0.04384956881403923, dist_loss: 1.1463348865509033
recon_loss: 0.04384906589984894, dist_loss: 0.6111042499542236
recon_loss: 0.043848566710948944, dist_loss: 0.6761795878410339
recon_loss: 0.04384806007146835, dist_loss: 0.940381646156311
recon_loss: 0.04384758695960045, dist_loss: 1.255481243133545
recon_loss: 0.04384712502360344, dist_loss: 0.45844632387161255
recon_loss: 0.04384666308760643, dist_loss: 1.016347885131836
recon_loss: 0.04384618252515793, dist_loss: 0.33436694741249084
recon_loss: 0.04384571686387062, dist_loss: 0.7919355034828186
recon_loss: 0.043845225125551224, dist_loss: 0.7424609661102295
recon_loss: 0.04384472966194153, dist_loss: 0.36175596714019775
recon_loss: 0.04384421557188034, dist_loss: 0.3498716950416565
recon_loss: 0.04384368285536766, dist_loss: 0.7001008987426758
recon_loss: 0.04384315758943558, dist_loss: 0.7135461568832397
recon_loss: 0.043842613697052, dist_loss: 0.9456263780593872
recon_loss: 0.04384208843111992, dist_loss: 0.6782634854316711
recon_loss: 0.043841589242219925, dist_loss: 0.9062563180923462
recon_loss: 0.043841082602739334, dist_loss: 1.059029221534729
recon_loss: 0.043840549886226654, dist_loss: 0.7540066242218018
recon_loss: 0.04384000599384308, dist_loss: 0.7253934741020203
recon_loss: 0.043839458376169205, dist_loss: 0.3863447606563568
recon_loss: 0.04383893683552742, dist_loss: 0.867754340171814
recon_loss: 0.04383840039372444, dist_loss: 1.0550611019134521
recon_loss: 0.04383786395192146, dist_loss: 0.8569881916046143
recon_loss: 0.04383736848831177, dist_loss: 0.5912078619003296
recon_loss: 0.043836809694767, dist_loss: 0.6532894372940063
recon_loss: 0.04383628070354462, dist_loss: 0.7232798337936401
recon_loss: 0.04383576661348343, dist_loss: 0.6870939135551453
recon_loss: 0.04383523762226105, dist_loss: 0.6294519305229187
recon_loss: 0.04383469000458717, dist_loss: 1.1306240558624268
recon_loss: 0.04383418709039688, dist_loss: 0.6323695778846741
recon_loss: 0.04383363574743271, dist_loss: 0.8753665685653687
recon_loss: 0.04383305087685585, dist_loss: 0.5837531685829163
recon_loss: 0.04383249580860138, dist_loss: 0.793939471244812
recon_loss: 0.043831948190927505, dist_loss: 0.7812785506248474
recon_loss: 0.043831441551446915, dist_loss: 0.9546967148780823
recon_loss: 0.043831028044223785, dist_loss: 0.3360452353954315
recon_loss: 0.04383060336112976, dist_loss: 0.6779297590255737
recon_loss: 0.043830133974552155, dist_loss: 0.31459978222846985
recon_loss: 0.04382968321442604, dist_loss: 0.41072267293930054
recon_loss: 0.04382924735546112, dist_loss: 0.9872879385948181
recon_loss: 0.043828800320625305, dist_loss: 1.1950256824493408
recon_loss: 0.043828364461660385, dist_loss: 0.6218553185462952
recon_loss: 0.043827954679727554, dist_loss: 0.6982659697532654
recon_loss: 0.043827518820762634, dist_loss: 0.9045329689979553
recon_loss: 0.04382706061005592, dist_loss: 0.7385175228118896
recon_loss: 0.04382661357522011, dist_loss: 0.5246342420578003
recon_loss: 0.043826159089803696, dist_loss: 0.7797596454620361
recon_loss: 0.04382568225264549, dist_loss: 0.5351669788360596
recon_loss: 0.04382520169019699, dist_loss: 0.3843008577823639
recon_loss: 0.04382471740245819, dist_loss: 0.6513287425041199
recon_loss: 0.04382425174117088, dist_loss: 0.5480509996414185
recon_loss: 0.04382378235459328, dist_loss: 1.109144687652588
recon_loss: 0.04382334649562836, dist_loss: 0.9447001814842224
recon_loss: 0.04382287710905075, dist_loss: 0.43109846115112305
recon_loss: 0.04382237419486046, dist_loss: 0.8159372210502625
recon_loss: 0.043821804225444794, dist_loss: 0.9183052182197571
recon_loss: 0.04382121562957764, dist_loss: 0.5873648524284363
recon_loss: 0.04382060840725899, dist_loss: 0.9485260248184204
recon_loss: 0.04382001981139183, dist_loss: 0.4536072015762329
recon_loss: 0.04381944239139557, dist_loss: 0.7422033548355103
recon_loss: 0.0438188835978508, dist_loss: 0.9322093725204468
recon_loss: 0.04381836578249931, dist_loss: 0.5150694251060486
recon_loss: 0.04381783679127693, dist_loss: 1.3026862144470215
recon_loss: 0.043817341327667236, dist_loss: 0.7116832733154297
recon_loss: 0.043816860765218735, dist_loss: 0.9037255048751831
recon_loss: 0.04381634667515755, dist_loss: 0.6153975129127502
recon_loss: 0.04381585121154785, dist_loss: 0.5465198755264282
recon_loss: 0.043815381824970245, dist_loss: 0.7695784568786621
recon_loss: 0.04381493479013443, dist_loss: 0.8562465906143188
recon_loss: 0.04381449520587921, dist_loss: 0.710438072681427
recon_loss: 0.04381407052278519, dist_loss: 0.8874959349632263
recon_loss: 0.043813660740852356, dist_loss: 0.9328476190567017
recon_loss: 0.04381323233246803, dist_loss: 1.0005810260772705
recon_loss: 0.043812815099954605, dist_loss: 0.810305118560791
recon_loss: 0.04381238669157028, dist_loss: 0.5349501967430115
recon_loss: 0.04381197318434715, dist_loss: 0.7608793377876282
recon_loss: 0.043811552226543427, dist_loss: 0.5530474185943604
recon_loss: 0.0438111312687397, dist_loss: 0.4406803250312805
recon_loss: 0.04381073638796806, dist_loss: 0.8260995745658875
recon_loss: 0.04381031170487404, dist_loss: 0.5488182306289673
recon_loss: 0.04380987584590912, dist_loss: 0.525239109992981
recon_loss: 0.0438094288110733, dist_loss: 0.6137410998344421
recon_loss: 0.04380899295210838, dist_loss: 0.8187153339385986
recon_loss: 0.04380851984024048, dist_loss: 0.643933117389679
recon_loss: 0.04380801320075989, dist_loss: 1.0313864946365356
recon_loss: 0.04380752518773079, dist_loss: 0.5305805206298828
recon_loss: 0.04380706697702408, dist_loss: 0.8876877427101135
recon_loss: 0.043806567788124084, dist_loss: 0.9406402111053467
recon_loss: 0.043806079775094986, dist_loss: 1.0098367929458618
recon_loss: 0.043805595487356186, dist_loss: 0.9372704029083252
recon_loss: 0.0438050776720047, dist_loss: 0.7478418350219727
recon_loss: 0.043804556131362915, dist_loss: 0.9511009454727173
recon_loss: 0.043804023414850235, dist_loss: 0.6802769899368286
recon_loss: 0.04380348324775696, dist_loss: 0.9769042730331421
recon_loss: 0.043802931904792786, dist_loss: 0.5241224765777588
recon_loss: 0.04380238801240921, dist_loss: 0.7763980031013489
Pre-training Epoch 4:  38%|███▊      | 139/367 [00:00<00:01, 192.41it/s]Pre-training Epoch 4:  43%|████▎     | 159/367 [00:00<00:01, 192.81it/s]Pre-training Epoch 4:  49%|████▉     | 179/367 [00:00<00:00, 192.97it/s]Pre-training Epoch 4:  54%|█████▍    | 199/367 [00:01<00:00, 193.13it/s]Pre-training Epoch 4:  60%|█████▉    | 219/367 [00:01<00:00, 193.24it/s]Pre-training Epoch 4:  65%|██████▌   | 239/367 [00:01<00:00, 193.31it/s]recon_loss: 0.04380188509821892, dist_loss: 0.5073837041854858
recon_loss: 0.04380139335989952, dist_loss: 0.9169855713844299
recon_loss: 0.04380089417099953, dist_loss: 0.6090233325958252
recon_loss: 0.043800417333841324, dist_loss: 0.8881953954696655
recon_loss: 0.043799929320812225, dist_loss: 0.8692299127578735
recon_loss: 0.04379947856068611, dist_loss: 0.3464743196964264
recon_loss: 0.04379902780056, dist_loss: 0.7804633378982544
recon_loss: 0.04379858449101448, dist_loss: 1.0174343585968018
recon_loss: 0.04379813000559807, dist_loss: 0.8539619445800781
recon_loss: 0.04379769414663315, dist_loss: 0.3829180896282196
recon_loss: 0.043797269463539124, dist_loss: 0.8938040733337402
recon_loss: 0.04379682615399361, dist_loss: 0.7556752562522888
recon_loss: 0.04379637539386749, dist_loss: 0.616239070892334
recon_loss: 0.04379593953490257, dist_loss: 0.46401944756507874
recon_loss: 0.043795499950647354, dist_loss: 0.9211108684539795
recon_loss: 0.04379507154226303, dist_loss: 0.8965081572532654
recon_loss: 0.0437946580350399, dist_loss: 0.7025021314620972
recon_loss: 0.04379427805542946, dist_loss: 0.9895720481872559
recon_loss: 0.043793875724077225, dist_loss: 0.36602675914764404
recon_loss: 0.04379347711801529, dist_loss: 0.999059796333313
recon_loss: 0.04379309341311455, dist_loss: 0.6450867652893066
recon_loss: 0.0437927208840847, dist_loss: 0.7086188793182373
recon_loss: 0.04379230737686157, dist_loss: 0.3614896535873413
recon_loss: 0.04379188269376755, dist_loss: 0.5286911725997925
recon_loss: 0.04379139468073845, dist_loss: 0.6213692426681519
recon_loss: 0.04379089176654816, dist_loss: 1.0380533933639526
recon_loss: 0.043790366500616074, dist_loss: 0.6933448314666748
recon_loss: 0.04378984123468399, dist_loss: 0.551650881767273
recon_loss: 0.043789297342300415, dist_loss: 0.6789507269859314
recon_loss: 0.04378872364759445, dist_loss: 0.8492995500564575
recon_loss: 0.04378814622759819, dist_loss: 0.5111728310585022
recon_loss: 0.04378757253289223, dist_loss: 0.7183481454849243
recon_loss: 0.043787021189928055, dist_loss: 0.8085352182388306
recon_loss: 0.04378646984696388, dist_loss: 0.7965752482414246
recon_loss: 0.043785884976387024, dist_loss: 0.6855120658874512
recon_loss: 0.043785303831100464, dist_loss: 0.5797914266586304
recon_loss: 0.0437847301363945, dist_loss: 0.625747561454773
recon_loss: 0.043784189969301224, dist_loss: 1.2931153774261475
recon_loss: 0.04378372058272362, dist_loss: 0.4007806181907654
recon_loss: 0.043783240020275116, dist_loss: 0.916594386100769
recon_loss: 0.043782755732536316, dist_loss: 0.5692358016967773
recon_loss: 0.04378225654363632, dist_loss: 0.459595263004303
recon_loss: 0.04378176108002663, dist_loss: 0.707832396030426
recon_loss: 0.043781302869319916, dist_loss: 1.4122291803359985
recon_loss: 0.0437808483839035, dist_loss: 0.5568829774856567
recon_loss: 0.0437803640961647, dist_loss: 0.8072525262832642
recon_loss: 0.043779876083135605, dist_loss: 0.5769604444503784
recon_loss: 0.0437793955206871, dist_loss: 0.9939384460449219
recon_loss: 0.043778933584690094, dist_loss: 0.6348289251327515
recon_loss: 0.04377845674753189, dist_loss: 0.43603482842445374
recon_loss: 0.04377797245979309, dist_loss: 0.7078684568405151
recon_loss: 0.04377750679850578, dist_loss: 0.7268266677856445
recon_loss: 0.04377705231308937, dist_loss: 0.4287104606628418
recon_loss: 0.043776579201221466, dist_loss: 1.035853624343872
recon_loss: 0.043776120990514755, dist_loss: 0.42171257734298706
recon_loss: 0.04377567768096924, dist_loss: 0.9081898331642151
recon_loss: 0.04377526789903641, dist_loss: 0.552154541015625
recon_loss: 0.0437748096883297, dist_loss: 0.8252123594284058
recon_loss: 0.0437743179500103, dist_loss: 0.6564280986785889
recon_loss: 0.04377380758523941, dist_loss: 0.5884339809417725
recon_loss: 0.043773259967565536, dist_loss: 0.47379106283187866
recon_loss: 0.043772730976343155, dist_loss: 1.3475064039230347
recon_loss: 0.043772220611572266, dist_loss: 0.9608868360519409
recon_loss: 0.043771710246801376, dist_loss: 0.5688623785972595
recon_loss: 0.043771155178546906, dist_loss: 0.9491672515869141
recon_loss: 0.04377058148384094, dist_loss: 0.7308765649795532
recon_loss: 0.04377002641558647, dist_loss: 0.7969034910202026
recon_loss: 0.043769486248493195, dist_loss: 0.45007026195526123
recon_loss: 0.04376896098256111, dist_loss: 0.45420610904693604
recon_loss: 0.04376843944191933, dist_loss: 0.8253673315048218
recon_loss: 0.04376792162656784, dist_loss: 0.6075305938720703
recon_loss: 0.04376740753650665, dist_loss: 0.5577196478843689
recon_loss: 0.04376692697405815, dist_loss: 1.4420905113220215
recon_loss: 0.04376642033457756, dist_loss: 1.2462184429168701
recon_loss: 0.04376591742038727, dist_loss: 0.7879564762115479
recon_loss: 0.043765418231487274, dist_loss: 0.6008825302124023
recon_loss: 0.04376490041613579, dist_loss: 0.7346348166465759
recon_loss: 0.04376436024904251, dist_loss: 0.7189204692840576
recon_loss: 0.043763794004917145, dist_loss: 0.7834894061088562
recon_loss: 0.04376322031021118, dist_loss: 0.47613129019737244
recon_loss: 0.04376263543963432, dist_loss: 1.1047859191894531
recon_loss: 0.04376203939318657, dist_loss: 0.618972659111023
recon_loss: 0.04376143589615822, dist_loss: 0.47753220796585083
recon_loss: 0.043760813772678375, dist_loss: 1.3905518054962158
recon_loss: 0.043760161846876144, dist_loss: 0.8914233446121216
recon_loss: 0.04375949874520302, dist_loss: 0.43643802404403687
recon_loss: 0.04375884309411049, dist_loss: 0.9869433641433716
recon_loss: 0.043758172541856766, dist_loss: 0.7704787850379944
recon_loss: 0.04375751316547394, dist_loss: 1.059829592704773
recon_loss: 0.0437568835914135, dist_loss: 0.6054030656814575
recon_loss: 0.04375625029206276, dist_loss: 0.42999839782714844
recon_loss: 0.04375562444329262, dist_loss: 0.46723222732543945
recon_loss: 0.04375503212213516, dist_loss: 0.9364821910858154
recon_loss: 0.0437544547021389, dist_loss: 0.7106140851974487
recon_loss: 0.043753836303949356, dist_loss: 0.6802092790603638
recon_loss: 0.043753232806921005, dist_loss: 0.9030646085739136
recon_loss: 0.04375261068344116, dist_loss: 0.907394528388977
recon_loss: 0.04375195875763893, dist_loss: 0.5892825126647949
recon_loss: 0.043751310557127, dist_loss: 0.5892400741577148
recon_loss: 0.04375065863132477, dist_loss: 0.5152736902236938
recon_loss: 0.04375000670552254, dist_loss: 0.4984481930732727
recon_loss: 0.04374932497739792, dist_loss: 0.9313721060752869
recon_loss: 0.043748632073402405, dist_loss: 0.46460092067718506
recon_loss: 0.04374796897172928, dist_loss: 0.5513067245483398
recon_loss: 0.043747324496507645, dist_loss: 0.4917086362838745
recon_loss: 0.04374668002128601, dist_loss: 0.5812800526618958
recon_loss: 0.04374603554606438, dist_loss: 0.6037677526473999
recon_loss: 0.04374539479613304, dist_loss: 0.5641606450080872
recon_loss: 0.04374472051858902, dist_loss: 0.45863765478134155
recon_loss: 0.04374399036169052, dist_loss: 0.5022780299186707
recon_loss: 0.04374326393008232, dist_loss: 0.6245874166488647
recon_loss: 0.043742552399635315, dist_loss: 0.44328880310058594
recon_loss: 0.04374183341860771, dist_loss: 0.9209995269775391
recon_loss: 0.0437411293387413, dist_loss: 0.48702800273895264
recon_loss: 0.043740447610616684, dist_loss: 0.4123975932598114
recon_loss: 0.04373971000313759, dist_loss: 0.7931382656097412
recon_loss: 0.043738968670368195, dist_loss: 0.714603066444397
recon_loss: 0.04373824596405029, dist_loss: 0.7506532669067383
recon_loss: 0.0437375009059906, dist_loss: 1.0906364917755127
recon_loss: 0.043736785650253296, dist_loss: 1.1909239292144775
recon_loss: 0.04373607039451599, dist_loss: 0.6799664497375488
recon_loss: 0.04373534396290779, dist_loss: 0.6166248321533203
recon_loss: 0.043734606355428696, dist_loss: 0.6126186847686768
recon_loss: 0.0437338761985302, dist_loss: 0.5625622272491455
recon_loss: 0.0437331423163414, dist_loss: 0.5701744556427002
recon_loss: 0.0437324196100235, dist_loss: 0.8768470883369446
recon_loss: 0.04373171553015709, dist_loss: 0.7153657674789429
recon_loss: 0.04373100399971008, dist_loss: 0.8802540302276611
recon_loss: 0.04373030737042427, dist_loss: 0.2972862124443054
Pre-training Epoch 4:  71%|███████   | 259/367 [00:01<00:00, 193.28it/s]Pre-training Epoch 4:  76%|███████▌  | 279/367 [00:01<00:00, 193.34it/s]Pre-training Epoch 4:  81%|████████▏ | 299/367 [00:01<00:00, 192.95it/s]Pre-training Epoch 4:  87%|████████▋ | 319/367 [00:01<00:00, 193.06it/s]Pre-training Epoch 4:  92%|█████████▏| 339/367 [00:01<00:00, 192.95it/s]Pre-training Epoch 4:  98%|█████████▊| 359/367 [00:01<00:00, 193.13it/s]Pre-training Epoch 4: 100%|██████████| 367/367 [00:01<00:00, 192.94it/s]
recon_loss: 0.04372963309288025, dist_loss: 0.5007346272468567
recon_loss: 0.04372898116707802, dist_loss: 0.8594410419464111
recon_loss: 0.043728332966566086, dist_loss: 0.8371167182922363
recon_loss: 0.04372769594192505, dist_loss: 0.64056396484375
recon_loss: 0.04372703284025192, dist_loss: 0.8087755441665649
recon_loss: 0.04372634366154671, dist_loss: 0.3087463974952698
recon_loss: 0.04372560232877731, dist_loss: 0.47320494055747986
recon_loss: 0.04372486472129822, dist_loss: 0.4765603840351105
recon_loss: 0.04372411221265793, dist_loss: 0.9977816939353943
recon_loss: 0.04372338578104973, dist_loss: 0.625474750995636
recon_loss: 0.043722692877054214, dist_loss: 0.8480604887008667
recon_loss: 0.04372197389602661, dist_loss: 0.8234397768974304
recon_loss: 0.04372123256325722, dist_loss: 0.697350263595581
recon_loss: 0.04372052103281021, dist_loss: 0.4529806971549988
recon_loss: 0.04371986538171768, dist_loss: 0.6855279207229614
recon_loss: 0.04371922090649605, dist_loss: 0.5222575664520264
recon_loss: 0.0437186025083065, dist_loss: 0.7839607000350952
recon_loss: 0.04371797293424606, dist_loss: 0.4202685058116913
recon_loss: 0.04371735081076622, dist_loss: 1.0450412034988403
recon_loss: 0.04371669515967369, dist_loss: 0.7191905379295349
recon_loss: 0.04371601343154907, dist_loss: 0.8138377070426941
recon_loss: 0.04371534660458565, dist_loss: 0.8035441637039185
recon_loss: 0.043714724481105804, dist_loss: 0.7103885412216187
recon_loss: 0.04371413588523865, dist_loss: 1.1777987480163574
recon_loss: 0.04371355101466179, dist_loss: 0.3338698148727417
recon_loss: 0.04371294751763344, dist_loss: 0.6045793294906616
recon_loss: 0.04371232911944389, dist_loss: 0.5128063559532166
recon_loss: 0.04371174797415733, dist_loss: 0.5394074320793152
recon_loss: 0.04371120035648346, dist_loss: 1.3734338283538818
recon_loss: 0.043710656464099884, dist_loss: 0.9342994093894958
recon_loss: 0.0437101311981678, dist_loss: 1.2865713834762573
recon_loss: 0.043709646910429, dist_loss: 0.5006147623062134
recon_loss: 0.0437091700732708, dist_loss: 0.9192627668380737
recon_loss: 0.043708670884370804, dist_loss: 0.6974409222602844
recon_loss: 0.0437081940472126, dist_loss: 0.9930406808853149
recon_loss: 0.043707702308893204, dist_loss: 0.5078052282333374
recon_loss: 0.0437072329223156, dist_loss: 0.5929220914840698
recon_loss: 0.04370678961277008, dist_loss: 0.516514241695404
recon_loss: 0.04370635002851486, dist_loss: 0.7807167172431946
recon_loss: 0.04370589181780815, dist_loss: 0.5642076134681702
recon_loss: 0.04370545968413353, dist_loss: 0.6621986627578735
recon_loss: 0.043705061078071594, dist_loss: 0.6218088865280151
recon_loss: 0.043704669922590256, dist_loss: 1.1685036420822144
recon_loss: 0.04370425269007683, dist_loss: 0.6217570304870605
recon_loss: 0.04370388016104698, dist_loss: 0.5070295333862305
recon_loss: 0.04370349273085594, dist_loss: 0.7722474336624146
recon_loss: 0.04370301589369774, dist_loss: 0.6006743311882019
recon_loss: 0.04370252415537834, dist_loss: 0.7043906450271606
recon_loss: 0.04370203614234924, dist_loss: 0.574299693107605
recon_loss: 0.04370152950286865, dist_loss: 0.5654959678649902
recon_loss: 0.04370099678635597, dist_loss: 0.8525002598762512
recon_loss: 0.04370047152042389, dist_loss: 0.6910783648490906
recon_loss: 0.04369997978210449, dist_loss: 0.8733458518981934
recon_loss: 0.043699510395526886, dist_loss: 0.7311288118362427
recon_loss: 0.043699003756046295, dist_loss: 0.8227388858795166
recon_loss: 0.04369848221540451, dist_loss: 0.6607150435447693
recon_loss: 0.043697938323020935, dist_loss: 0.5063091516494751
recon_loss: 0.04369740188121796, dist_loss: 0.49158239364624023
recon_loss: 0.04369685426354408, dist_loss: 0.4538326859474182
recon_loss: 0.04369627311825752, dist_loss: 0.6966185569763184
recon_loss: 0.04369570314884186, dist_loss: 0.8828009963035583
recon_loss: 0.04369518905878067, dist_loss: 0.36316755414009094
recon_loss: 0.04369466006755829, dist_loss: 0.47771894931793213
recon_loss: 0.043694160878658295, dist_loss: 0.49900463223457336
recon_loss: 0.043693672865629196, dist_loss: 0.8818845748901367
recon_loss: 0.043693188577890396, dist_loss: 0.5884264707565308
recon_loss: 0.04369274526834488, dist_loss: 0.5673865079879761
recon_loss: 0.04369230195879936, dist_loss: 0.6571664810180664
recon_loss: 0.04369184002280235, dist_loss: 0.34243711829185486
recon_loss: 0.04369135573506355, dist_loss: 0.47831496596336365
recon_loss: 0.043690845370292664, dist_loss: 0.5171918869018555
recon_loss: 0.04369033873081207, dist_loss: 0.9030338525772095
recon_loss: 0.04368986561894417, dist_loss: 0.5228903889656067
recon_loss: 0.043689411133527756, dist_loss: 1.3052966594696045
recon_loss: 0.043688975274562836, dist_loss: 0.6620867252349854
recon_loss: 0.043688539415597916, dist_loss: 0.704309344291687
recon_loss: 0.043688107281923294, dist_loss: 0.3732684552669525
recon_loss: 0.043687671422958374, dist_loss: 0.6046756505966187
recon_loss: 0.04368729144334793, dist_loss: 0.7637032270431519
recon_loss: 0.043686866760253906, dist_loss: 0.788152813911438
recon_loss: 0.0436864010989666, dist_loss: 0.8980940580368042
recon_loss: 0.04368593171238899, dist_loss: 0.6888100504875183
recon_loss: 0.04368545487523079, dist_loss: 1.143855094909668
recon_loss: 0.043684955686330795, dist_loss: 0.7429524064064026
recon_loss: 0.0436844602227211, dist_loss: 0.8491406440734863
recon_loss: 0.04368399828672409, dist_loss: 0.8870903253555298
recon_loss: 0.04368354380130768, dist_loss: 0.43387556076049805
recon_loss: 0.043683070689439774, dist_loss: 0.6286725997924805
recon_loss: 0.04368256404995918, dist_loss: 0.6518261432647705
recon_loss: 0.0436820462346077, dist_loss: 0.5985100269317627
recon_loss: 0.04368152096867561, dist_loss: 0.4077443480491638
recon_loss: 0.043680980801582336, dist_loss: 0.4270312190055847
recon_loss: 0.04368043690919876, dist_loss: 0.8200662136077881
recon_loss: 0.04367982968688011, dist_loss: 0.9062222242355347
recon_loss: 0.04367920756340027, dist_loss: 0.22915050387382507
recon_loss: 0.043678585439920425, dist_loss: 0.47826632857322693
recon_loss: 0.04367798566818237, dist_loss: 0.6687377095222473
recon_loss: 0.043677374720573425, dist_loss: 0.46233469247817993
recon_loss: 0.04367678239941597, dist_loss: 0.918597936630249
recon_loss: 0.04367619752883911, dist_loss: 1.014940857887268
recon_loss: 0.04367559775710106, dist_loss: 0.6993342638015747
recon_loss: 0.04367496073246002, dist_loss: 1.1090091466903687
recon_loss: 0.04367433115839958, dist_loss: 0.49923884868621826
recon_loss: 0.04367370158433914, dist_loss: 0.5981509685516357
recon_loss: 0.043673075735569, dist_loss: 1.0447266101837158
recon_loss: 0.04367244243621826, dist_loss: 0.7169333696365356
recon_loss: 0.043671827763319016, dist_loss: 1.0090060234069824
recon_loss: 0.04367119446396828, dist_loss: 0.5763399600982666
recon_loss: 0.04367056488990784, dist_loss: 0.30042147636413574
Pre-training Epoch 5:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 5:   5%|▌         | 19/367 [00:00<00:01, 188.94it/s]Pre-training Epoch 5:  11%|█         | 39/367 [00:00<00:01, 191.47it/s]Pre-training Epoch 5:  16%|█▌        | 59/367 [00:00<00:01, 192.28it/s]Pre-training Epoch 5:  22%|██▏       | 79/367 [00:00<00:01, 192.67it/s]Pre-training Epoch 5:  27%|██▋       | 99/367 [00:00<00:01, 192.89it/s]Pre-training Epoch 5:  32%|███▏      | 119/367 [00:00<00:01, 192.98it/s]recon_loss: 0.0436699241399765, dist_loss: 0.4650183916091919
recon_loss: 0.04366927221417427, dist_loss: 0.876800537109375
recon_loss: 0.04366865009069443, dist_loss: 0.8393193483352661
recon_loss: 0.04366800934076309, dist_loss: 0.740458071231842
recon_loss: 0.043667376041412354, dist_loss: 0.479221373796463
recon_loss: 0.043666739016771317, dist_loss: 0.6849092245101929
recon_loss: 0.043666109442710876, dist_loss: 0.2567611634731293
recon_loss: 0.04366547614336014, dist_loss: 0.5577389001846313
recon_loss: 0.0436648428440094, dist_loss: 0.9319311380386353
recon_loss: 0.04366423562169075, dist_loss: 0.7586469650268555
recon_loss: 0.043663617223501205, dist_loss: 1.1779885292053223
recon_loss: 0.043662991374731064, dist_loss: 0.6684384346008301
recon_loss: 0.04366235062479973, dist_loss: 1.0728764533996582
recon_loss: 0.043661702424287796, dist_loss: 0.6369168758392334
recon_loss: 0.04366103559732437, dist_loss: 0.455943763256073
recon_loss: 0.04366036877036095, dist_loss: 0.8665720224380493
recon_loss: 0.043659694492816925, dist_loss: 0.7428883910179138
recon_loss: 0.043659012764692307, dist_loss: 1.233339548110962
recon_loss: 0.043658364564180374, dist_loss: 1.493532419204712
recon_loss: 0.04365774616599083, dist_loss: 0.8679378032684326
recon_loss: 0.04365714639425278, dist_loss: 0.8854212760925293
recon_loss: 0.04365656524896622, dist_loss: 0.638614296913147
recon_loss: 0.04365599900484085, dist_loss: 0.766618013381958
recon_loss: 0.04365542158484459, dist_loss: 1.2500133514404297
recon_loss: 0.04365486279129982, dist_loss: 1.0797810554504395
recon_loss: 0.04365430772304535, dist_loss: 0.39110371470451355
recon_loss: 0.04365374892950058, dist_loss: 0.5835872888565063
recon_loss: 0.0436532124876976, dist_loss: 0.5438872575759888
recon_loss: 0.04365270212292671, dist_loss: 0.48934096097946167
recon_loss: 0.04365216940641403, dist_loss: 0.7879477739334106
recon_loss: 0.043651606887578964, dist_loss: 0.5828849077224731
recon_loss: 0.043651044368743896, dist_loss: 0.6246079206466675
recon_loss: 0.04365049675107002, dist_loss: 0.7474933862686157
recon_loss: 0.04364991560578346, dist_loss: 0.4552061855792999
recon_loss: 0.04364935681223869, dist_loss: 0.673194169998169
recon_loss: 0.04364882782101631, dist_loss: 0.825166642665863
recon_loss: 0.04364832490682602, dist_loss: 0.8445794582366943
recon_loss: 0.04364781454205513, dist_loss: 0.44492271542549133
recon_loss: 0.04364731162786484, dist_loss: 0.7169469594955444
recon_loss: 0.04364682361483574, dist_loss: 0.7343822717666626
recon_loss: 0.04364628344774246, dist_loss: 0.9473810195922852
recon_loss: 0.04364573955535889, dist_loss: 0.6253871917724609
recon_loss: 0.043645188212394714, dist_loss: 0.707794189453125
recon_loss: 0.04364461824297905, dist_loss: 0.8571867346763611
recon_loss: 0.043644070625305176, dist_loss: 0.39096537232398987
recon_loss: 0.04364354535937309, dist_loss: 0.40027159452438354
recon_loss: 0.04364302381873131, dist_loss: 1.1186447143554688
recon_loss: 0.04364250600337982, dist_loss: 0.6843793988227844
recon_loss: 0.04364197701215744, dist_loss: 0.6036256551742554
recon_loss: 0.04364145174622536, dist_loss: 1.2374533414840698
recon_loss: 0.04364090412855148, dist_loss: 0.5292423367500305
recon_loss: 0.04364030063152313, dist_loss: 0.8293971419334412
recon_loss: 0.04363968223333359, dist_loss: 0.5236567854881287
recon_loss: 0.04363906756043434, dist_loss: 0.6299588680267334
recon_loss: 0.04363846406340599, dist_loss: 1.1531342267990112
recon_loss: 0.04363789036870003, dist_loss: 0.5716952085494995
recon_loss: 0.043637290596961975, dist_loss: 0.6239789724349976
recon_loss: 0.04363665357232094, dist_loss: 0.5878159999847412
recon_loss: 0.043636031448841095, dist_loss: 0.6976730227470398
recon_loss: 0.04363544285297394, dist_loss: 0.5319629311561584
recon_loss: 0.04363485798239708, dist_loss: 0.327073335647583
recon_loss: 0.0436343178153038, dist_loss: 0.5450562238693237
recon_loss: 0.04363380745053291, dist_loss: 0.7645115256309509
recon_loss: 0.04363333433866501, dist_loss: 0.37274056673049927
recon_loss: 0.0436328761279583, dist_loss: 0.7948904037475586
recon_loss: 0.04363232105970383, dist_loss: 0.608146607875824
recon_loss: 0.043631765991449356, dist_loss: 0.5085604786872864
recon_loss: 0.043631188571453094, dist_loss: 0.39235323667526245
recon_loss: 0.043630652129650116, dist_loss: 0.8153970241546631
recon_loss: 0.04363009333610535, dist_loss: 0.91109699010849
recon_loss: 0.04362954944372177, dist_loss: 0.5992777347564697
recon_loss: 0.04362896829843521, dist_loss: 0.6692409515380859
recon_loss: 0.04362839460372925, dist_loss: 1.1897640228271484
recon_loss: 0.043627820909023285, dist_loss: 1.098067045211792
recon_loss: 0.04362726956605911, dist_loss: 0.4211493134498596
recon_loss: 0.04362674430012703, dist_loss: 0.9027427434921265
recon_loss: 0.04362620785832405, dist_loss: 0.8427531123161316
recon_loss: 0.04362568259239197, dist_loss: 0.6746155023574829
recon_loss: 0.043625131249427795, dist_loss: 0.9479316473007202
recon_loss: 0.043624553829431534, dist_loss: 0.6102139949798584
recon_loss: 0.04362395405769348, dist_loss: 0.529363214969635
recon_loss: 0.04362339898943901, dist_loss: 0.40918177366256714
recon_loss: 0.04362286627292633, dist_loss: 0.4043508768081665
recon_loss: 0.04362228885293007, dist_loss: 0.5962741374969482
recon_loss: 0.0436217375099659, dist_loss: 0.4488067030906677
recon_loss: 0.04362116754055023, dist_loss: 0.5785093903541565
recon_loss: 0.043620649725198746, dist_loss: 0.5688416957855225
recon_loss: 0.04362012818455696, dist_loss: 0.5282058715820312
recon_loss: 0.04361958056688309, dist_loss: 0.4777757525444031
recon_loss: 0.04361903667449951, dist_loss: 1.3415043354034424
recon_loss: 0.043618492782115936, dist_loss: 0.6888883113861084
recon_loss: 0.043617963790893555, dist_loss: 0.9639174342155457
recon_loss: 0.043617334216833115, dist_loss: 0.9940930604934692
recon_loss: 0.04361668974161148, dist_loss: 0.7924344539642334
recon_loss: 0.04361603036522865, dist_loss: 0.8696495294570923
recon_loss: 0.043615374714136124, dist_loss: 0.6437738537788391
recon_loss: 0.043614696711301804, dist_loss: 0.40737971663475037
recon_loss: 0.04361402615904808, dist_loss: 0.6550374031066895
recon_loss: 0.04361340031027794, dist_loss: 0.6564866304397583
recon_loss: 0.04361281916499138, dist_loss: 1.3868247270584106
recon_loss: 0.04361223429441452, dist_loss: 0.5946030020713806
recon_loss: 0.04361164569854736, dist_loss: 0.7958052158355713
recon_loss: 0.04361109063029289, dist_loss: 0.927011251449585
recon_loss: 0.04361052066087723, dist_loss: 0.8797468543052673
recon_loss: 0.04360990971326828, dist_loss: 0.5838322639465332
recon_loss: 0.043609317392110825, dist_loss: 0.5366859436035156
recon_loss: 0.043608732521533966, dist_loss: 0.9406506419181824
recon_loss: 0.043608158826828, dist_loss: 0.7397036552429199
recon_loss: 0.043607596307992935, dist_loss: 0.6640794277191162
recon_loss: 0.04360705241560936, dist_loss: 0.5933475494384766
recon_loss: 0.043606530874967575, dist_loss: 0.7651962041854858
recon_loss: 0.0436059795320034, dist_loss: 0.9340800642967224
recon_loss: 0.04360542818903923, dist_loss: 0.5740073323249817
recon_loss: 0.043604929000139236, dist_loss: 0.6993231177330017
recon_loss: 0.04360442981123924, dist_loss: 0.4974587559700012
recon_loss: 0.043603941798210144, dist_loss: 0.7738102674484253
recon_loss: 0.04360343515872955, dist_loss: 0.3421950340270996
recon_loss: 0.04360288381576538, dist_loss: 0.7564183473587036
recon_loss: 0.043602291494607925, dist_loss: 0.7651300430297852
recon_loss: 0.043601684272289276, dist_loss: 0.6169655323028564
recon_loss: 0.043601080775260925, dist_loss: 0.9189292192459106
recon_loss: 0.04360053688287735, dist_loss: 1.1003916263580322
recon_loss: 0.043599966913461685, dist_loss: 0.6170365214347839
recon_loss: 0.04359939321875572, dist_loss: 0.7200124859809875
recon_loss: 0.04359878599643707, dist_loss: 1.0802797079086304
recon_loss: 0.04359816759824753, dist_loss: 0.2945045828819275
recon_loss: 0.043597567826509476, dist_loss: 0.9543838500976562
recon_loss: 0.043596915900707245, dist_loss: 1.2517017126083374
recon_loss: 0.04359624162316322, dist_loss: 0.6309047937393188
Pre-training Epoch 5:  38%|███▊      | 139/367 [00:00<00:01, 193.11it/s]Pre-training Epoch 5:  43%|████▎     | 159/367 [00:00<00:01, 193.19it/s]Pre-training Epoch 5:  49%|████▉     | 179/367 [00:00<00:00, 193.19it/s]Pre-training Epoch 5:  54%|█████▍    | 199/367 [00:01<00:00, 193.07it/s]Pre-training Epoch 5:  60%|█████▉    | 219/367 [00:01<00:00, 187.24it/s]Pre-training Epoch 5:  65%|██████▍   | 238/367 [00:01<00:00, 176.08it/s]Pre-training Epoch 5:  70%|██████▉   | 256/367 [00:01<00:00, 170.40it/s]recon_loss: 0.043595533818006516, dist_loss: 0.45347219705581665
recon_loss: 0.04359487071633339, dist_loss: 0.8691484928131104
recon_loss: 0.04359425604343414, dist_loss: 0.7704211473464966
recon_loss: 0.04359367489814758, dist_loss: 0.8769637942314148
recon_loss: 0.043593086302280426, dist_loss: 0.7450640797615051
recon_loss: 0.043592460453510284, dist_loss: 0.3453284502029419
recon_loss: 0.043591853231191635, dist_loss: 0.81529301404953
recon_loss: 0.043591294437646866, dist_loss: 0.433809757232666
recon_loss: 0.0435907319188118, dist_loss: 0.95988929271698
recon_loss: 0.04359017685055733, dist_loss: 0.4808577597141266
recon_loss: 0.043589651584625244, dist_loss: 0.46860116720199585
recon_loss: 0.04358912259340286, dist_loss: 0.6747423410415649
recon_loss: 0.04358859360218048, dist_loss: 0.5972866415977478
recon_loss: 0.04358811303973198, dist_loss: 0.6386074423789978
recon_loss: 0.043587639927864075, dist_loss: 0.6013790369033813
recon_loss: 0.04358712583780289, dist_loss: 1.1639404296875
recon_loss: 0.043586574494838715, dist_loss: 0.530512273311615
recon_loss: 0.04358600825071335, dist_loss: 1.012460708618164
recon_loss: 0.04358542338013649, dist_loss: 0.5331739187240601
recon_loss: 0.043584831058979034, dist_loss: 1.5351216793060303
recon_loss: 0.04358427971601486, dist_loss: 1.2049072980880737
recon_loss: 0.04358372837305069, dist_loss: 0.9515860080718994
recon_loss: 0.04358314350247383, dist_loss: 0.6591241359710693
recon_loss: 0.04358255863189697, dist_loss: 0.9799206852912903
recon_loss: 0.043581943958997726, dist_loss: 0.5484538674354553
recon_loss: 0.04358135163784027, dist_loss: 0.8117063045501709
recon_loss: 0.0435808040201664, dist_loss: 0.5805509090423584
recon_loss: 0.04358024522662163, dist_loss: 0.3847176134586334
recon_loss: 0.04357967525720596, dist_loss: 0.9963752031326294
recon_loss: 0.043579068034887314, dist_loss: 0.559866189956665
recon_loss: 0.043578505516052246, dist_loss: 0.901213526725769
recon_loss: 0.04357796907424927, dist_loss: 0.7878720760345459
recon_loss: 0.04357743263244629, dist_loss: 0.4953708052635193
recon_loss: 0.043576840311288834, dist_loss: 0.6494143605232239
recon_loss: 0.043576229363679886, dist_loss: 0.6807378530502319
recon_loss: 0.04357562214136124, dist_loss: 0.4583680033683777
recon_loss: 0.04357502982020378, dist_loss: 1.0463488101959229
recon_loss: 0.04357438534498215, dist_loss: 0.8923475742340088
recon_loss: 0.0435737706720829, dist_loss: 0.7554639577865601
recon_loss: 0.04357320815324783, dist_loss: 0.5990362763404846
recon_loss: 0.04357268661260605, dist_loss: 0.6278368830680847
recon_loss: 0.043572213500738144, dist_loss: 0.6085013151168823
recon_loss: 0.04357174411416054, dist_loss: 0.5431371927261353
recon_loss: 0.04357123747467995, dist_loss: 0.4425363540649414
recon_loss: 0.04357073828577995, dist_loss: 0.9670665264129639
recon_loss: 0.043570227921009064, dist_loss: 0.7046568989753723
recon_loss: 0.04356967657804489, dist_loss: 0.5230686664581299
recon_loss: 0.04356919974088669, dist_loss: 1.0591769218444824
recon_loss: 0.04356874153017998, dist_loss: 0.7892552614212036
recon_loss: 0.043568238615989685, dist_loss: 0.45479917526245117
recon_loss: 0.0435677096247673, dist_loss: 1.1212776899337769
recon_loss: 0.04356715828180313, dist_loss: 0.8252708315849304
recon_loss: 0.043566539883613586, dist_loss: 0.8355953097343445
recon_loss: 0.04356587305665016, dist_loss: 0.9259220361709595
recon_loss: 0.04356523975729942, dist_loss: 0.6856399178504944
recon_loss: 0.04356461390852928, dist_loss: 0.9619842767715454
recon_loss: 0.04356400668621063, dist_loss: 1.1648344993591309
recon_loss: 0.043563321232795715, dist_loss: 0.6080607175827026
recon_loss: 0.04356265440583229, dist_loss: 0.49392423033714294
recon_loss: 0.04356198012828827, dist_loss: 0.495479017496109
recon_loss: 0.04356134310364723, dist_loss: 0.4710935950279236
recon_loss: 0.043560732156038284, dist_loss: 0.8625291585922241
recon_loss: 0.04356016591191292, dist_loss: 0.5062057971954346
recon_loss: 0.043559588491916656, dist_loss: 0.4866432249546051
recon_loss: 0.0435589961707592, dist_loss: 0.6349813342094421
recon_loss: 0.04355844482779503, dist_loss: 1.0501325130462646
recon_loss: 0.04355783388018608, dist_loss: 0.6143103837966919
recon_loss: 0.04355725646018982, dist_loss: 0.4102480411529541
recon_loss: 0.04355667904019356, dist_loss: 0.9004510641098022
recon_loss: 0.043556105345487595, dist_loss: 0.53825443983078
recon_loss: 0.04355553910136223, dist_loss: 0.9480952620506287
recon_loss: 0.04355500638484955, dist_loss: 0.49156123399734497
recon_loss: 0.043554458767175674, dist_loss: 0.8920267820358276
recon_loss: 0.0435539074242115, dist_loss: 0.4900965690612793
recon_loss: 0.04355333745479584, dist_loss: 0.601823091506958
recon_loss: 0.043552786111831665, dist_loss: 0.9419100880622864
recon_loss: 0.0435522124171257, dist_loss: 0.5213955044746399
recon_loss: 0.04355167597532272, dist_loss: 0.9923160076141357
recon_loss: 0.043551161885261536, dist_loss: 0.6161620616912842
recon_loss: 0.04355063661932945, dist_loss: 0.8755578994750977
recon_loss: 0.043550122529268265, dist_loss: 0.8268686532974243
recon_loss: 0.043549638241529465, dist_loss: 0.7373390793800354
recon_loss: 0.04354914650321007, dist_loss: 0.9584305286407471
recon_loss: 0.04354863613843918, dist_loss: 1.5454331636428833
recon_loss: 0.0435480959713459, dist_loss: 0.8862360715866089
recon_loss: 0.043547600507736206, dist_loss: 0.679794430732727
recon_loss: 0.043547097593545914, dist_loss: 0.42543432116508484
recon_loss: 0.04354660212993622, dist_loss: 0.40417808294296265
recon_loss: 0.04354607313871384, dist_loss: 0.9447208046913147
recon_loss: 0.043545521795749664, dist_loss: 0.4354994297027588
recon_loss: 0.043544966727495193, dist_loss: 0.6600804328918457
recon_loss: 0.04354440048336983, dist_loss: 0.5955938100814819
recon_loss: 0.04354385286569595, dist_loss: 0.616018533706665
recon_loss: 0.04354332387447357, dist_loss: 0.6892849206924438
recon_loss: 0.04354280233383179, dist_loss: 0.8948256969451904
recon_loss: 0.043542277067899704, dist_loss: 0.7412987947463989
recon_loss: 0.04354173317551613, dist_loss: 0.49540242552757263
recon_loss: 0.04354117810726166, dist_loss: 0.466496080160141
recon_loss: 0.04354062303900719, dist_loss: 0.8153472542762756
recon_loss: 0.04354001209139824, dist_loss: 0.622412383556366
recon_loss: 0.04353940486907959, dist_loss: 0.740607500076294
recon_loss: 0.04353881999850273, dist_loss: 0.8070012331008911
recon_loss: 0.04353821277618408, dist_loss: 0.7575892210006714
recon_loss: 0.043537624180316925, dist_loss: 1.09232497215271
recon_loss: 0.04353702813386917, dist_loss: 0.6010838747024536
recon_loss: 0.04353642091155052, dist_loss: 0.7260823249816895
recon_loss: 0.043535832315683365, dist_loss: 0.3787705600261688
recon_loss: 0.04353524371981621, dist_loss: 1.3019890785217285
recon_loss: 0.043534666299819946, dist_loss: 0.8187206983566284
recon_loss: 0.04353409260511398, dist_loss: 0.6903138160705566
recon_loss: 0.04353351891040802, dist_loss: 0.6565635204315186
recon_loss: 0.04353296384215355, dist_loss: 0.39154690504074097
recon_loss: 0.043532393872737885, dist_loss: 0.7466455101966858
recon_loss: 0.04353184625506401, dist_loss: 0.778984785079956
recon_loss: 0.04353125020861626, dist_loss: 0.6391509771347046
recon_loss: 0.04353064298629761, dist_loss: 0.6485833525657654
recon_loss: 0.043530113995075226, dist_loss: 0.6931629180908203
recon_loss: 0.04352960363030434, dist_loss: 1.6621208190917969
recon_loss: 0.04352916032075882, dist_loss: 0.3698229193687439
recon_loss: 0.04352869465947151, dist_loss: 0.8782162666320801
recon_loss: 0.04352821409702301, dist_loss: 0.567346453666687
recon_loss: 0.04352770373225212, dist_loss: 0.7033642530441284
recon_loss: 0.04352717474102974, dist_loss: 0.3542448580265045
recon_loss: 0.04352667182683945, dist_loss: 0.34962084889411926
recon_loss: 0.04352618753910065, dist_loss: 0.8939356803894043
recon_loss: 0.0435258150100708, dist_loss: 1.5800957679748535
recon_loss: 0.04352542385458946, dist_loss: 0.5067611336708069
recon_loss: 0.04352501034736633, dist_loss: 0.6437894105911255
recon_loss: 0.04352455586194992, dist_loss: 0.40427082777023315
Pre-training Epoch 5:  75%|███████▍  | 274/367 [00:01<00:00, 165.49it/s]Pre-training Epoch 5:  79%|███████▉  | 291/367 [00:01<00:00, 161.70it/s]Pre-training Epoch 5:  84%|████████▍ | 308/367 [00:01<00:00, 155.96it/s]Pre-training Epoch 5:  88%|████████▊ | 324/367 [00:01<00:00, 155.20it/s]Pre-training Epoch 5:  93%|█████████▎| 340/367 [00:01<00:00, 154.97it/s]Pre-training Epoch 5:  97%|█████████▋| 356/367 [00:02<00:00, 155.33it/s]Pre-training Epoch 5: 100%|██████████| 367/367 [00:02<00:00, 173.62it/s]
recon_loss: 0.043524082750082016, dist_loss: 0.4180018901824951
recon_loss: 0.04352361336350441, dist_loss: 1.222107172012329
recon_loss: 0.043523162603378296, dist_loss: 0.8059524297714233
recon_loss: 0.0435226745903492, dist_loss: 1.1284058094024658
recon_loss: 0.043522149324417114, dist_loss: 0.3390195965766907
recon_loss: 0.043521586805582047, dist_loss: 0.6180022954940796
recon_loss: 0.04352100193500519, dist_loss: 0.5285806655883789
recon_loss: 0.04352036863565445, dist_loss: 0.6841328144073486
recon_loss: 0.043519746512174606, dist_loss: 0.9879515767097473
recon_loss: 0.043519068509340286, dist_loss: 0.5771059989929199
recon_loss: 0.043518371880054474, dist_loss: 0.49352893233299255
recon_loss: 0.04351774975657463, dist_loss: 0.7527741193771362
recon_loss: 0.043517135083675385, dist_loss: 0.676609992980957
recon_loss: 0.04351649805903435, dist_loss: 0.45570045709609985
recon_loss: 0.04351583868265152, dist_loss: 0.4626515507698059
recon_loss: 0.043515171855688095, dist_loss: 0.7597284317016602
recon_loss: 0.04351465404033661, dist_loss: 0.4305565655231476
recon_loss: 0.04351412132382393, dist_loss: 0.7959364652633667
recon_loss: 0.043513521552085876, dist_loss: 0.752066969871521
recon_loss: 0.04351285472512245, dist_loss: 0.5559400320053101
recon_loss: 0.04351218789815903, dist_loss: 0.4823148846626282
recon_loss: 0.04351157322525978, dist_loss: 0.5428791642189026
recon_loss: 0.04351086914539337, dist_loss: 0.6130194664001465
recon_loss: 0.04351016879081726, dist_loss: 1.1174637079238892
recon_loss: 0.043509501963853836, dist_loss: 0.5269792675971985
recon_loss: 0.04350882023572922, dist_loss: 0.662535548210144
recon_loss: 0.04350810870528221, dist_loss: 0.8585990071296692
recon_loss: 0.04350743815302849, dist_loss: 0.7734580039978027
recon_loss: 0.043506719172000885, dist_loss: 0.6374452114105225
recon_loss: 0.04350599646568298, dist_loss: 0.8600575923919678
recon_loss: 0.04350535199046135, dist_loss: 0.48588842153549194
recon_loss: 0.043504685163497925, dist_loss: 1.011001467704773
recon_loss: 0.043504029512405396, dist_loss: 0.5606410503387451
recon_loss: 0.04350338503718376, dist_loss: 0.5074010491371155
recon_loss: 0.043502744287252426, dist_loss: 0.5386154651641846
recon_loss: 0.0435020737349987, dist_loss: 0.6941677927970886
recon_loss: 0.04350147023797035, dist_loss: 0.6698639392852783
recon_loss: 0.043500885367393494, dist_loss: 0.6613515019416809
recon_loss: 0.04350028187036514, dist_loss: 0.7975042462348938
recon_loss: 0.043499696999788284, dist_loss: 0.34616678953170776
recon_loss: 0.04349910467863083, dist_loss: 0.856648862361908
recon_loss: 0.04349854588508606, dist_loss: 0.8155189156532288
recon_loss: 0.04349800571799278, dist_loss: 0.8617748022079468
recon_loss: 0.0434974767267704, dist_loss: 1.1760427951812744
recon_loss: 0.04349697381258011, dist_loss: 0.8227827548980713
recon_loss: 0.04349647834897041, dist_loss: 0.7943139672279358
recon_loss: 0.04349599778652191, dist_loss: 0.4955618977546692
recon_loss: 0.04349556937813759, dist_loss: 0.4874860942363739
recon_loss: 0.043495114892721176, dist_loss: 0.7870681285858154
recon_loss: 0.04349464178085327, dist_loss: 0.6666178703308105
recon_loss: 0.04349419102072716, dist_loss: 0.6867895126342773
recon_loss: 0.04349373281002045, dist_loss: 0.4991534948348999
recon_loss: 0.043493226170539856, dist_loss: 0.6830655336380005
recon_loss: 0.043492723256349564, dist_loss: 0.4095221757888794
recon_loss: 0.04349223151803017, dist_loss: 0.428419828414917
recon_loss: 0.043491728603839874, dist_loss: 0.9036364555358887
recon_loss: 0.04349125921726227, dist_loss: 1.1483696699142456
recon_loss: 0.04349072650074959, dist_loss: 0.7410539388656616
recon_loss: 0.04349019005894661, dist_loss: 0.5545904636383057
recon_loss: 0.04348962381482124, dist_loss: 0.6482058763504028
recon_loss: 0.04348902776837349, dist_loss: 0.9968597292900085
recon_loss: 0.04348841682076454, dist_loss: 0.6956712007522583
recon_loss: 0.04348781332373619, dist_loss: 0.659721851348877
recon_loss: 0.04348719120025635, dist_loss: 0.5333442687988281
recon_loss: 0.04348655790090561, dist_loss: 0.4468861222267151
recon_loss: 0.04348592087626457, dist_loss: 0.5297763347625732
recon_loss: 0.04348527267575264, dist_loss: 0.4487622082233429
recon_loss: 0.04348462074995041, dist_loss: 0.43516939878463745
recon_loss: 0.04348398745059967, dist_loss: 0.8836010098457336
recon_loss: 0.04348335042595863, dist_loss: 1.0899595022201538
recon_loss: 0.04348277300596237, dist_loss: 0.43292513489723206
recon_loss: 0.04348220303654671, dist_loss: 0.5529932975769043
recon_loss: 0.04348159581422806, dist_loss: 0.6388055086135864
recon_loss: 0.04348097741603851, dist_loss: 0.8777154684066772
recon_loss: 0.04348032921552658, dist_loss: 0.8958200812339783
recon_loss: 0.04347969591617584, dist_loss: 0.6508986949920654
recon_loss: 0.04347901791334152, dist_loss: 0.8357230424880981
recon_loss: 0.043478354811668396, dist_loss: 0.6561119556427002
recon_loss: 0.043477725237607956, dist_loss: 0.5813647508621216
recon_loss: 0.04347709193825722, dist_loss: 0.9043747186660767
recon_loss: 0.043476492166519165, dist_loss: 1.2207930088043213
recon_loss: 0.043475884944200516, dist_loss: 0.8377914428710938
recon_loss: 0.04347526282072067, dist_loss: 0.7579145431518555
recon_loss: 0.043474651873111725, dist_loss: 0.5301464200019836
recon_loss: 0.04347405210137367, dist_loss: 0.6175202131271362
recon_loss: 0.043473485857248306, dist_loss: 0.7091408371925354
recon_loss: 0.04347294941544533, dist_loss: 0.7887952327728271
recon_loss: 0.043472424149513245, dist_loss: 0.4303414821624756
recon_loss: 0.043471887707710266, dist_loss: 0.558447003364563
recon_loss: 0.0434713214635849, dist_loss: 1.1183420419692993
recon_loss: 0.04347074404358864, dist_loss: 0.5604287981987
recon_loss: 0.043470170348882675, dist_loss: 0.5997135043144226
recon_loss: 0.04346957802772522, dist_loss: 0.8542724251747131
recon_loss: 0.04346899688243866, dist_loss: 0.7700575590133667
recon_loss: 0.0434684157371521, dist_loss: 0.7051928043365479
recon_loss: 0.04346784949302673, dist_loss: 0.730409562587738
recon_loss: 0.04346727579832077, dist_loss: 1.145188331604004
recon_loss: 0.043466709554195404, dist_loss: 0.9125776290893555
recon_loss: 0.043466150760650635, dist_loss: 0.343225359916687
recon_loss: 0.04346560314297676, dist_loss: 0.6546009182929993
recon_loss: 0.04346507415175438, dist_loss: 0.6963425278663635
recon_loss: 0.043464530259370804, dist_loss: 0.6779741644859314
recon_loss: 0.043463997542858124, dist_loss: 0.5394135117530823
recon_loss: 0.04346345737576485, dist_loss: 0.7951983213424683
recon_loss: 0.04346292093396187, dist_loss: 0.537560224533081
recon_loss: 0.04346242919564247, dist_loss: 0.6959057450294495
recon_loss: 0.04346190392971039, dist_loss: 0.5458523631095886
recon_loss: 0.04346132650971413, dist_loss: 0.5579162836074829
recon_loss: 0.04346076026558876, dist_loss: 0.4755403697490692
Pre-training Epoch 6:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 6:   5%|▍         | 18/367 [00:00<00:02, 171.29it/s]Pre-training Epoch 6:  10%|▉         | 36/367 [00:00<00:01, 174.81it/s]Pre-training Epoch 6:  15%|█▍        | 54/367 [00:00<00:01, 173.76it/s]Pre-training Epoch 6:  20%|█▉        | 72/367 [00:00<00:01, 175.28it/s]Pre-training Epoch 6:  25%|██▍       | 90/367 [00:00<00:01, 173.89it/s]Pre-training Epoch 6:  29%|██▉       | 108/367 [00:00<00:01, 174.55it/s]Pre-training Epoch 6:  34%|███▍      | 126/367 [00:00<00:01, 174.73it/s]recon_loss: 0.043460212647914886, dist_loss: 0.689433217048645
recon_loss: 0.04345962405204773, dist_loss: 0.6178035736083984
recon_loss: 0.043459028005599976, dist_loss: 0.5497710704803467
recon_loss: 0.04345842823386192, dist_loss: 0.7125378251075745
recon_loss: 0.043457891792058945, dist_loss: 0.43223434686660767
recon_loss: 0.04345734417438507, dist_loss: 0.5723696947097778
recon_loss: 0.04345674812793732, dist_loss: 0.5236549973487854
recon_loss: 0.043456126004457474, dist_loss: 0.4581907093524933
recon_loss: 0.04345551133155823, dist_loss: 0.5898662209510803
recon_loss: 0.04345487803220749, dist_loss: 0.6169238090515137
recon_loss: 0.04345422238111496, dist_loss: 0.7563220262527466
recon_loss: 0.04345358535647392, dist_loss: 0.43493717908859253
recon_loss: 0.043452903628349304, dist_loss: 0.32982373237609863
recon_loss: 0.04345225915312767, dist_loss: 0.5291207432746887
recon_loss: 0.04345163330435753, dist_loss: 0.8610556721687317
recon_loss: 0.043450988829135895, dist_loss: 0.7723037600517273
recon_loss: 0.04345039650797844, dist_loss: 0.8657631874084473
recon_loss: 0.04344985634088516, dist_loss: 0.4456471800804138
recon_loss: 0.04344930127263069, dist_loss: 0.6159998178482056
recon_loss: 0.04344875365495682, dist_loss: 0.672593891620636
recon_loss: 0.04344824701547623, dist_loss: 0.5130250453948975
recon_loss: 0.043447718024253845, dist_loss: 0.4461071491241455
recon_loss: 0.04344720393419266, dist_loss: 0.6493968963623047
recon_loss: 0.04344673454761505, dist_loss: 0.4018438756465912
recon_loss: 0.043446291238069534, dist_loss: 0.8592876195907593
recon_loss: 0.043445806950330734, dist_loss: 0.8497374653816223
recon_loss: 0.04344528913497925, dist_loss: 0.7687784433364868
recon_loss: 0.04344474524259567, dist_loss: 0.8116267919540405
recon_loss: 0.04344417154788971, dist_loss: 0.5722726583480835
recon_loss: 0.04344356060028076, dist_loss: 0.859943687915802
recon_loss: 0.043442897498607635, dist_loss: 0.7624303698539734
recon_loss: 0.043442267924547195, dist_loss: 0.8141078352928162
recon_loss: 0.04344158247113228, dist_loss: 0.5733062624931335
recon_loss: 0.04344093054533005, dist_loss: 0.4268016219139099
recon_loss: 0.04344029352068901, dist_loss: 0.7014439105987549
recon_loss: 0.04343969747424126, dist_loss: 0.9460679292678833
recon_loss: 0.043439045548439026, dist_loss: 0.4268507957458496
recon_loss: 0.0434383898973465, dist_loss: 0.7244201898574829
recon_loss: 0.04343775659799576, dist_loss: 0.8228157758712769
recon_loss: 0.0434371680021286, dist_loss: 0.451560914516449
recon_loss: 0.043436579406261444, dist_loss: 0.9552038311958313
recon_loss: 0.043435994535684586, dist_loss: 0.6701551675796509
recon_loss: 0.04343542829155922, dist_loss: 0.48509129881858826
recon_loss: 0.043434854596853256, dist_loss: 0.7945847511291504
recon_loss: 0.04343430697917938, dist_loss: 0.5173298120498657
recon_loss: 0.043433777987957, dist_loss: 0.5732296705245972
recon_loss: 0.04343324154615402, dist_loss: 0.43216216564178467
recon_loss: 0.043432705104351044, dist_loss: 0.48360002040863037
recon_loss: 0.04343217611312866, dist_loss: 0.3296883702278137
recon_loss: 0.04343164339661598, dist_loss: 0.8642759323120117
recon_loss: 0.043431129306554794, dist_loss: 0.5027512311935425
recon_loss: 0.04343058168888092, dist_loss: 0.5829722881317139
recon_loss: 0.043430015444755554, dist_loss: 0.4893406629562378
recon_loss: 0.0434294156730175, dist_loss: 0.7421558499336243
recon_loss: 0.04342888668179512, dist_loss: 0.6142517328262329
recon_loss: 0.04342835023999214, dist_loss: 0.8155854940414429
recon_loss: 0.04342786222696304, dist_loss: 0.6724066734313965
recon_loss: 0.04342740401625633, dist_loss: 0.745779812335968
recon_loss: 0.04342694953083992, dist_loss: 0.963875412940979
recon_loss: 0.04342645779252052, dist_loss: 0.9449774622917175
recon_loss: 0.04342597350478172, dist_loss: 1.080636739730835
recon_loss: 0.043425552546978, dist_loss: 0.3623061776161194
recon_loss: 0.04342515766620636, dist_loss: 0.49847209453582764
recon_loss: 0.04342474415898323, dist_loss: 1.042148232460022
recon_loss: 0.04342444986104965, dist_loss: 0.7729182243347168
recon_loss: 0.043424081057310104, dist_loss: 0.6884609460830688
recon_loss: 0.04342365637421608, dist_loss: 0.7908094525337219
recon_loss: 0.04342323914170265, dist_loss: 0.8388800621032715
recon_loss: 0.04342284053564072, dist_loss: 0.5220942497253418
recon_loss: 0.04342247173190117, dist_loss: 0.8331016898155212
recon_loss: 0.043422114104032516, dist_loss: 0.5926921367645264
recon_loss: 0.04342173412442207, dist_loss: 0.9419237971305847
recon_loss: 0.04342127591371536, dist_loss: 0.7771843075752258
recon_loss: 0.043420836329460144, dist_loss: 0.8025383949279785
recon_loss: 0.043420419096946716, dist_loss: 0.6343975067138672
recon_loss: 0.043420080095529556, dist_loss: 0.6123822927474976
recon_loss: 0.04341968894004822, dist_loss: 0.3711223304271698
recon_loss: 0.043419260531663895, dist_loss: 0.45357954502105713
recon_loss: 0.04341883957386017, dist_loss: 0.6919914484024048
recon_loss: 0.04341837391257286, dist_loss: 0.7794438600540161
recon_loss: 0.04341793432831764, dist_loss: 0.7481933832168579
recon_loss: 0.043417464941740036, dist_loss: 0.6821637749671936
recon_loss: 0.04341699182987213, dist_loss: 0.8879536390304565
recon_loss: 0.043416578322649, dist_loss: 0.5675560235977173
recon_loss: 0.04341614991426468, dist_loss: 1.2745609283447266
recon_loss: 0.04341563582420349, dist_loss: 0.8699344396591187
recon_loss: 0.04341517388820648, dist_loss: 0.6791704893112183
recon_loss: 0.04341468960046768, dist_loss: 1.0280847549438477
recon_loss: 0.04341419041156769, dist_loss: 0.8732559084892273
recon_loss: 0.04341370612382889, dist_loss: 1.4028571844100952
recon_loss: 0.04341328516602516, dist_loss: 0.6461852788925171
recon_loss: 0.043412890285253525, dist_loss: 0.8137029409408569
recon_loss: 0.04341248422861099, dist_loss: 0.8354870080947876
recon_loss: 0.043412189930677414, dist_loss: 0.6601134538650513
recon_loss: 0.0434117391705513, dist_loss: 0.5286511182785034
recon_loss: 0.043411239981651306, dist_loss: 0.5545932054519653
recon_loss: 0.0434107631444931, dist_loss: 0.8846421241760254
recon_loss: 0.04341024532914162, dist_loss: 0.6619302034378052
recon_loss: 0.04340963438153267, dist_loss: 0.5374596118927002
recon_loss: 0.043408993631601334, dist_loss: 0.6080484390258789
recon_loss: 0.04340842366218567, dist_loss: 0.6007798910140991
recon_loss: 0.043407849967479706, dist_loss: 1.0340240001678467
recon_loss: 0.04340729862451553, dist_loss: 0.6288806200027466
recon_loss: 0.0434066504240036, dist_loss: 0.3846776783466339
recon_loss: 0.04340600222349167, dist_loss: 0.7088106870651245
recon_loss: 0.04340533912181854, dist_loss: 0.7190335392951965
recon_loss: 0.043404754251241684, dist_loss: 0.5348314046859741
recon_loss: 0.043404147028923035, dist_loss: 1.4772733449935913
recon_loss: 0.04340352490544319, dist_loss: 0.8841216564178467
recon_loss: 0.04340289533138275, dist_loss: 0.5698950290679932
recon_loss: 0.04340217262506485, dist_loss: 0.5795730352401733
recon_loss: 0.04340142011642456, dist_loss: 1.094101071357727
recon_loss: 0.04340074211359024, dist_loss: 0.7753359079360962
recon_loss: 0.043400079011917114, dist_loss: 0.5977301597595215
recon_loss: 0.04339941591024399, dist_loss: 0.5824573040008545
recon_loss: 0.04339876025915146, dist_loss: 0.818555474281311
recon_loss: 0.04339812695980072, dist_loss: 0.5158449411392212
recon_loss: 0.04339749366044998, dist_loss: 1.5156610012054443
recon_loss: 0.04339692369103432, dist_loss: 1.1177806854248047
recon_loss: 0.04339642450213432, dist_loss: 0.48279452323913574
recon_loss: 0.04339590296149254, dist_loss: 0.8578722476959229
recon_loss: 0.04339529573917389, dist_loss: 0.6797118186950684
recon_loss: 0.04339466989040375, dist_loss: 0.5687337517738342
recon_loss: 0.04339407756924629, dist_loss: 0.4884389042854309
recon_loss: 0.04339348152279854, dist_loss: 0.6005967855453491
recon_loss: 0.0433928444981575, dist_loss: 0.5860693454742432
recon_loss: 0.043392203748226166, dist_loss: 0.6542696356773376
recon_loss: 0.04339149221777916, dist_loss: 0.6324782371520996
recon_loss: 0.04339082911610603, dist_loss: 1.1116377115249634
Pre-training Epoch 6:  39%|███▉      | 144/367 [00:00<00:01, 173.94it/s]Pre-training Epoch 6:  44%|████▍     | 162/367 [00:00<00:01, 170.34it/s]Pre-training Epoch 6:  49%|████▉     | 180/367 [00:01<00:01, 172.29it/s]Pre-training Epoch 6:  54%|█████▍    | 198/367 [00:01<00:00, 173.66it/s]Pre-training Epoch 6:  59%|█████▉    | 216/367 [00:01<00:00, 171.63it/s]Pre-training Epoch 6:  64%|██████▍   | 234/367 [00:01<00:00, 169.92it/s]Pre-training Epoch 6:  69%|██████▊   | 252/367 [00:01<00:00, 172.00it/s]recon_loss: 0.0433901883661747, dist_loss: 0.5075663328170776
recon_loss: 0.043389566242694855, dist_loss: 0.452572226524353
recon_loss: 0.04338892921805382, dist_loss: 0.916825532913208
recon_loss: 0.04338836297392845, dist_loss: 0.4203903079032898
recon_loss: 0.043387774378061295, dist_loss: 0.5911505818367004
recon_loss: 0.043387189507484436, dist_loss: 0.47688770294189453
recon_loss: 0.04338664561510086, dist_loss: 0.7938096523284912
recon_loss: 0.04338608682155609, dist_loss: 0.7714941501617432
recon_loss: 0.04338550567626953, dist_loss: 0.7659524083137512
recon_loss: 0.043384939432144165, dist_loss: 0.9651668071746826
recon_loss: 0.04338441416621208, dist_loss: 0.5634142160415649
recon_loss: 0.04338385537266731, dist_loss: 0.46027934551239014
recon_loss: 0.04338332638144493, dist_loss: 0.7643915414810181
recon_loss: 0.043382808566093445, dist_loss: 0.6444560289382935
recon_loss: 0.04338229447603226, dist_loss: 0.7358813285827637
recon_loss: 0.04338182136416435, dist_loss: 0.5045265555381775
recon_loss: 0.043381381779909134, dist_loss: 0.6513772010803223
recon_loss: 0.04338090866804123, dist_loss: 1.2975404262542725
recon_loss: 0.043380383402109146, dist_loss: 0.9699452519416809
recon_loss: 0.043379899114370346, dist_loss: 0.8730877637863159
recon_loss: 0.04337941110134125, dist_loss: 1.1545591354370117
recon_loss: 0.043379027396440506, dist_loss: 0.5633206367492676
recon_loss: 0.04337861016392708, dist_loss: 0.37490004301071167
recon_loss: 0.043378204107284546, dist_loss: 0.9518296718597412
recon_loss: 0.04337776079773903, dist_loss: 0.5693650245666504
recon_loss: 0.04337730258703232, dist_loss: 0.6111360192298889
recon_loss: 0.043376822024583817, dist_loss: 0.6110967993736267
recon_loss: 0.04337630793452263, dist_loss: 0.5853708982467651
recon_loss: 0.04337581247091293, dist_loss: 0.9894997477531433
recon_loss: 0.04337535798549652, dist_loss: 0.45750677585601807
recon_loss: 0.04337484389543533, dist_loss: 0.6679205298423767
recon_loss: 0.04337428882718086, dist_loss: 0.7920105457305908
recon_loss: 0.04337378591299057, dist_loss: 0.7687380313873291
recon_loss: 0.04337324574589729, dist_loss: 0.73239666223526
recon_loss: 0.04337264597415924, dist_loss: 0.6015005707740784
recon_loss: 0.04337211325764656, dist_loss: 1.4910848140716553
recon_loss: 0.043371640145778656, dist_loss: 0.5174233317375183
recon_loss: 0.04337112233042717, dist_loss: 0.8018088340759277
recon_loss: 0.04337053745985031, dist_loss: 0.7724676132202148
recon_loss: 0.04336986690759659, dist_loss: 0.41330257058143616
recon_loss: 0.04336924850940704, dist_loss: 0.8951224684715271
recon_loss: 0.043368637561798096, dist_loss: 0.5676972270011902
recon_loss: 0.04336803779006004, dist_loss: 0.6005731821060181
recon_loss: 0.0433674082159996, dist_loss: 0.5322103500366211
recon_loss: 0.043366722762584686, dist_loss: 1.2749402523040771
recon_loss: 0.04336605221033096, dist_loss: 0.5386084914207458
recon_loss: 0.04336542263627052, dist_loss: 0.8814355134963989
recon_loss: 0.04336485266685486, dist_loss: 0.7331216931343079
recon_loss: 0.04336431249976158, dist_loss: 0.6088588237762451
recon_loss: 0.04336371272802353, dist_loss: 0.9334546327590942
recon_loss: 0.04336308687925339, dist_loss: 0.8632023334503174
recon_loss: 0.043362487107515335, dist_loss: 0.5283972024917603
recon_loss: 0.043361857533454895, dist_loss: 0.9385831356048584
recon_loss: 0.043361224234104156, dist_loss: 0.6718055009841919
recon_loss: 0.04336059093475342, dist_loss: 0.5395897030830383
recon_loss: 0.043359946459531784, dist_loss: 0.47375065088272095
recon_loss: 0.04335930570960045, dist_loss: 0.715061366558075
recon_loss: 0.04335872828960419, dist_loss: 0.6481783390045166
recon_loss: 0.04335818439722061, dist_loss: 0.4447000026702881
recon_loss: 0.04335766285657883, dist_loss: 0.827852725982666
recon_loss: 0.04335713014006615, dist_loss: 0.8464646339416504
recon_loss: 0.04335659742355347, dist_loss: 0.6276212930679321
recon_loss: 0.043356094509363174, dist_loss: 0.49924415349960327
recon_loss: 0.04335559532046318, dist_loss: 0.7886632084846497
recon_loss: 0.04335508868098259, dist_loss: 0.5942431688308716
recon_loss: 0.04335460439324379, dist_loss: 0.5176811218261719
recon_loss: 0.04335411265492439, dist_loss: 0.4128570556640625
recon_loss: 0.04335357993841171, dist_loss: 0.991814374923706
recon_loss: 0.04335302487015724, dist_loss: 0.6201126575469971
recon_loss: 0.043352507054805756, dist_loss: 0.6665690541267395
recon_loss: 0.04335204139351845, dist_loss: 0.5236543416976929
recon_loss: 0.04335150122642517, dist_loss: 0.6601470112800598
recon_loss: 0.04335087165236473, dist_loss: 0.5653104782104492
recon_loss: 0.04335024580359459, dist_loss: 0.6231375336647034
recon_loss: 0.043349672108888626, dist_loss: 0.8586903810501099
recon_loss: 0.043349139392375946, dist_loss: 0.9594513177871704
recon_loss: 0.04334864392876625, dist_loss: 0.938896656036377
recon_loss: 0.04334810748696327, dist_loss: 0.6993762850761414
recon_loss: 0.04334760457277298, dist_loss: 0.948028564453125
recon_loss: 0.04334704950451851, dist_loss: 0.4969676733016968
recon_loss: 0.04334644973278046, dist_loss: 0.8782708644866943
recon_loss: 0.043345857411623, dist_loss: 0.5221810936927795
recon_loss: 0.04334530606865883, dist_loss: 1.1464130878448486
recon_loss: 0.04334467649459839, dist_loss: 0.7204437255859375
recon_loss: 0.04334405064582825, dist_loss: 0.5578920841217041
recon_loss: 0.043343398720026016, dist_loss: 0.6093235015869141
recon_loss: 0.043342798948287964, dist_loss: 0.7265700697898865
recon_loss: 0.043342214077711105, dist_loss: 0.7143185138702393
recon_loss: 0.04334160313010216, dist_loss: 0.6003408432006836
recon_loss: 0.04334103688597679, dist_loss: 1.0244050025939941
recon_loss: 0.043340492993593216, dist_loss: 0.6391432881355286
recon_loss: 0.04334000498056412, dist_loss: 0.5096697211265564
recon_loss: 0.043339524418115616, dist_loss: 0.3067534267902374
recon_loss: 0.043339043855667114, dist_loss: 0.8864968419075012
recon_loss: 0.0433385856449604, dist_loss: 0.7286326885223389
recon_loss: 0.04333801940083504, dist_loss: 0.6644771099090576
recon_loss: 0.043337415903806686, dist_loss: 0.6890707015991211
recon_loss: 0.04333677887916565, dist_loss: 0.5567523837089539
recon_loss: 0.043336108326911926, dist_loss: 0.8492672443389893
recon_loss: 0.04333547502756119, dist_loss: 0.658178448677063
recon_loss: 0.043334852904081345, dist_loss: 0.717926561832428
recon_loss: 0.043334219604730606, dist_loss: 0.4407293200492859
recon_loss: 0.04333363473415375, dist_loss: 1.239567518234253
recon_loss: 0.0433330237865448, dist_loss: 0.9877904653549194
recon_loss: 0.04333236813545227, dist_loss: 1.1676902770996094
recon_loss: 0.04333164915442467, dist_loss: 0.6227014660835266
recon_loss: 0.04333101585507393, dist_loss: 0.42000651359558105
recon_loss: 0.043330371379852295, dist_loss: 0.86963951587677
recon_loss: 0.043329741805791855, dist_loss: 0.5228038430213928
recon_loss: 0.043329112231731415, dist_loss: 0.621327817440033
recon_loss: 0.04332849010825157, dist_loss: 0.5889769792556763
recon_loss: 0.04332789406180382, dist_loss: 0.48131969571113586
recon_loss: 0.04332732409238815, dist_loss: 0.6985407471656799
recon_loss: 0.04332675784826279, dist_loss: 1.033387541770935
recon_loss: 0.043326154351234436, dist_loss: 0.5916317701339722
recon_loss: 0.04332554712891579, dist_loss: 0.6156567931175232
recon_loss: 0.04332493245601654, dist_loss: 0.46778327226638794
recon_loss: 0.04332432895898819, dist_loss: 1.155073642730713
recon_loss: 0.04332375153899193, dist_loss: 1.0250608921051025
recon_loss: 0.04332318156957626, dist_loss: 0.7853567600250244
recon_loss: 0.0433226116001606, dist_loss: 0.8758277297019958
recon_loss: 0.04332206770777702, dist_loss: 0.5647743344306946
recon_loss: 0.043321531265974045, dist_loss: 1.1556227207183838
recon_loss: 0.04332101345062256, dist_loss: 0.4546286463737488
recon_loss: 0.04332047700881958, dist_loss: 0.6254069805145264
recon_loss: 0.043319884687662125, dist_loss: 0.4833507537841797
recon_loss: 0.04331929236650467, dist_loss: 0.9978298544883728
recon_loss: 0.04331868141889572, dist_loss: 0.5572763681411743
recon_loss: 0.04331808164715767, dist_loss: 0.9843251705169678
Pre-training Epoch 6:  74%|███████▎  | 270/367 [00:01<00:00, 173.99it/s]Pre-training Epoch 6:  78%|███████▊  | 288/367 [00:01<00:00, 175.43it/s]Pre-training Epoch 6:  83%|████████▎ | 306/367 [00:01<00:00, 176.33it/s]Pre-training Epoch 6:  88%|████████▊ | 324/367 [00:01<00:00, 174.94it/s]Pre-training Epoch 6:  93%|█████████▎| 342/367 [00:01<00:00, 166.37it/s]Pre-training Epoch 6:  98%|█████████▊| 359/367 [00:02<00:00, 164.00it/s]Pre-training Epoch 6: 100%|██████████| 367/367 [00:02<00:00, 171.11it/s]
recon_loss: 0.043317507952451706, dist_loss: 0.7275563478469849
recon_loss: 0.04331698641180992, dist_loss: 0.671855092048645
recon_loss: 0.04331648349761963, dist_loss: 1.425180435180664
recon_loss: 0.04331592097878456, dist_loss: 0.8502737283706665
recon_loss: 0.04331532493233681, dist_loss: 0.7483081221580505
recon_loss: 0.04331468045711517, dist_loss: 0.38581356406211853
recon_loss: 0.04331405833363533, dist_loss: 0.7307744026184082
recon_loss: 0.04331347718834877, dist_loss: 0.68487149477005
recon_loss: 0.04331284388899803, dist_loss: 1.2802608013153076
recon_loss: 0.043312180787324905, dist_loss: 0.4499073028564453
recon_loss: 0.043311506509780884, dist_loss: 0.5413742661476135
recon_loss: 0.043310798704624176, dist_loss: 0.71576327085495
recon_loss: 0.043310146778821945, dist_loss: 0.7035020589828491
recon_loss: 0.04330945387482643, dist_loss: 0.9336667656898499
recon_loss: 0.04330885037779808, dist_loss: 1.1157276630401611
recon_loss: 0.04330819472670555, dist_loss: 0.6066617965698242
recon_loss: 0.04330756515264511, dist_loss: 0.8517213463783264
recon_loss: 0.043306902050971985, dist_loss: 0.5739824771881104
recon_loss: 0.04330623149871826, dist_loss: 1.180437445640564
recon_loss: 0.043305546045303345, dist_loss: 1.122069001197815
recon_loss: 0.04330485686659813, dist_loss: 0.9012112021446228
recon_loss: 0.04330424219369888, dist_loss: 0.41083014011383057
recon_loss: 0.04330359771847725, dist_loss: 0.5114303231239319
recon_loss: 0.043302927166223526, dist_loss: 0.9774894714355469
recon_loss: 0.04330228641629219, dist_loss: 0.6308884024620056
recon_loss: 0.04330166429281235, dist_loss: 0.9113509654998779
recon_loss: 0.04330107942223549, dist_loss: 0.4724429249763489
recon_loss: 0.04330043867230415, dist_loss: 0.6872463226318359
recon_loss: 0.043299753218889236, dist_loss: 0.7897077798843384
recon_loss: 0.04329909384250641, dist_loss: 0.5871699452400208
recon_loss: 0.043298497796058655, dist_loss: 0.7267041206359863
recon_loss: 0.043297890573740005, dist_loss: 0.5615944862365723
recon_loss: 0.043297260999679565, dist_loss: 0.331413596868515
recon_loss: 0.04329662770032883, dist_loss: 0.7889455556869507
recon_loss: 0.04329603910446167, dist_loss: 0.426044225692749
recon_loss: 0.04329543933272362, dist_loss: 0.4246447682380676
recon_loss: 0.04329486936330795, dist_loss: 1.1184406280517578
recon_loss: 0.04329433664679527, dist_loss: 0.6268360614776611
recon_loss: 0.043293874710798264, dist_loss: 1.1143981218338013
recon_loss: 0.04329339414834976, dist_loss: 0.7037819027900696
recon_loss: 0.04329288378357887, dist_loss: 0.5897868275642395
recon_loss: 0.043292392045259476, dist_loss: 0.8756134510040283
recon_loss: 0.04329194128513336, dist_loss: 0.48043107986450195
recon_loss: 0.04329143837094307, dist_loss: 0.6616705656051636
recon_loss: 0.04329092055559158, dist_loss: 0.595304012298584
recon_loss: 0.0432903878390789, dist_loss: 0.8008102178573608
recon_loss: 0.04328984394669533, dist_loss: 0.5364459156990051
recon_loss: 0.04328932240605354, dist_loss: 0.6627014875411987
recon_loss: 0.04328880086541176, dist_loss: 0.9662452936172485
recon_loss: 0.043288230895996094, dist_loss: 0.6835993528366089
recon_loss: 0.043287623673677444, dist_loss: 0.7911244630813599
recon_loss: 0.04328707978129387, dist_loss: 0.2897678017616272
recon_loss: 0.04328650236129761, dist_loss: 0.6422852277755737
recon_loss: 0.04328595846891403, dist_loss: 0.5018622875213623
recon_loss: 0.04328541457653046, dist_loss: 0.519111156463623
recon_loss: 0.04328496381640434, dist_loss: 0.4833717346191406
recon_loss: 0.04328455403447151, dist_loss: 0.6263072490692139
recon_loss: 0.04328412935137749, dist_loss: 1.0259828567504883
recon_loss: 0.04328364133834839, dist_loss: 0.477314293384552
recon_loss: 0.04328314960002899, dist_loss: 0.9165328741073608
recon_loss: 0.043282583355903625, dist_loss: 0.7656240463256836
recon_loss: 0.04328206926584244, dist_loss: 0.9524454474449158
recon_loss: 0.043281588703393936, dist_loss: 0.5942941904067993
recon_loss: 0.04328102990984917, dist_loss: 0.5901613831520081
recon_loss: 0.04328049346804619, dist_loss: 0.9325870275497437
recon_loss: 0.043279923498630524, dist_loss: 0.883450448513031
recon_loss: 0.0432792529463768, dist_loss: 1.2235281467437744
recon_loss: 0.04327847808599472, dist_loss: 1.1100225448608398
recon_loss: 0.04327771067619324, dist_loss: 0.7958685159683228
recon_loss: 0.04327705129981041, dist_loss: 0.44839829206466675
recon_loss: 0.043276358395814896, dist_loss: 0.5123409032821655
recon_loss: 0.04327565059065819, dist_loss: 0.9689960479736328
recon_loss: 0.04327496886253357, dist_loss: 0.7571854591369629
recon_loss: 0.043274324387311935, dist_loss: 0.5973347425460815
recon_loss: 0.04327366501092911, dist_loss: 0.6140813827514648
recon_loss: 0.04327302798628807, dist_loss: 0.5282014012336731
recon_loss: 0.04327237978577614, dist_loss: 0.4968872368335724
recon_loss: 0.04327176511287689, dist_loss: 0.8246816992759705
recon_loss: 0.043271198868751526, dist_loss: 0.554872453212738
recon_loss: 0.04327067732810974, dist_loss: 0.4927433729171753
recon_loss: 0.043270133435726166, dist_loss: 0.7634468674659729
recon_loss: 0.043269626796245575, dist_loss: 0.7641819715499878
recon_loss: 0.04326901212334633, dist_loss: 0.7313715219497681
recon_loss: 0.0432683601975441, dist_loss: 0.7061482071876526
recon_loss: 0.043267760425806046, dist_loss: 0.6422029733657837
recon_loss: 0.043267033994197845, dist_loss: 0.9027729034423828
recon_loss: 0.043266333639621735, dist_loss: 0.5943639278411865
recon_loss: 0.04326565936207771, dist_loss: 0.8415051698684692
recon_loss: 0.04326505586504936, dist_loss: 0.8162453770637512
recon_loss: 0.043264470994472504, dist_loss: 0.8165686130523682
recon_loss: 0.04326391592621803, dist_loss: 0.5980098247528076
recon_loss: 0.043263308703899384, dist_loss: 0.5018786191940308
recon_loss: 0.043262723833322525, dist_loss: 1.0222218036651611
recon_loss: 0.04326210543513298, dist_loss: 0.773059070110321
recon_loss: 0.043261487036943436, dist_loss: 0.5504700541496277
recon_loss: 0.04326096922159195, dist_loss: 0.7931675910949707
recon_loss: 0.043260496109724045, dist_loss: 0.6088926792144775
recon_loss: 0.04325995594263077, dist_loss: 0.5328075289726257
recon_loss: 0.0432594008743763, dist_loss: 0.5937668085098267
recon_loss: 0.04325880855321884, dist_loss: 0.9810499548912048
recon_loss: 0.04325820133090019, dist_loss: 0.5907490849494934
recon_loss: 0.043257568031549454, dist_loss: 0.5436835885047913
recon_loss: 0.04325692355632782, dist_loss: 0.7806309461593628
recon_loss: 0.04325636476278305, dist_loss: 0.6318840980529785
recon_loss: 0.04325583577156067, dist_loss: 0.6306158304214478
recon_loss: 0.0432552807033062, dist_loss: 0.888656735420227
recon_loss: 0.043254707008600235, dist_loss: 0.4754645526409149
recon_loss: 0.04325411096215248, dist_loss: 0.9145166277885437
recon_loss: 0.043253522366285324, dist_loss: 1.2238305807113647
Pre-training Epoch 7:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 7:   4%|▍         | 16/367 [00:00<00:02, 155.44it/s]Pre-training Epoch 7:   9%|▉         | 34/367 [00:00<00:01, 168.65it/s]Pre-training Epoch 7:  14%|█▍        | 52/367 [00:00<00:01, 173.37it/s]Pre-training Epoch 7:  19%|█▉        | 70/367 [00:00<00:01, 175.52it/s]Pre-training Epoch 7:  24%|██▍       | 88/367 [00:00<00:01, 176.41it/s]Pre-training Epoch 7:  29%|██▉       | 106/367 [00:00<00:01, 177.27it/s]Pre-training Epoch 7:  34%|███▍      | 124/367 [00:00<00:01, 177.54it/s]recon_loss: 0.04325278475880623, dist_loss: 0.8074393272399902
recon_loss: 0.04325208440423012, dist_loss: 0.7563313245773315
recon_loss: 0.04325142130255699, dist_loss: 1.0766441822052002
recon_loss: 0.04325081408023834, dist_loss: 0.48208871483802795
recon_loss: 0.04325021058320999, dist_loss: 0.6412633657455444
recon_loss: 0.043249696493148804, dist_loss: 0.5638883709907532
recon_loss: 0.04324917495250702, dist_loss: 1.1302261352539062
recon_loss: 0.04324864596128464, dist_loss: 0.4124540090560913
recon_loss: 0.043248143047094345, dist_loss: 0.8297169804573059
recon_loss: 0.04324768856167793, dist_loss: 1.0410783290863037
recon_loss: 0.043247271329164505, dist_loss: 0.6368447542190552
recon_loss: 0.04324682429432869, dist_loss: 0.8462697863578796
recon_loss: 0.043246373534202576, dist_loss: 0.419854074716568
recon_loss: 0.043245866894721985, dist_loss: 0.6604474782943726
recon_loss: 0.0432453416287899, dist_loss: 1.0981934070587158
recon_loss: 0.043244849890470505, dist_loss: 1.1163444519042969
recon_loss: 0.04324433580040932, dist_loss: 1.0809303522109985
recon_loss: 0.04324379935860634, dist_loss: 0.7273820042610168
recon_loss: 0.04324321821331978, dist_loss: 0.7183558344841003
recon_loss: 0.04324265569448471, dist_loss: 0.4957452416419983
recon_loss: 0.04324213042855263, dist_loss: 0.38780590891838074
recon_loss: 0.043241582810878754, dist_loss: 0.6061266660690308
recon_loss: 0.04324105381965637, dist_loss: 0.508064866065979
recon_loss: 0.04324054718017578, dist_loss: 0.5967023372650146
recon_loss: 0.043240051716566086, dist_loss: 0.41863012313842773
recon_loss: 0.04323958978056908, dist_loss: 0.5535135269165039
recon_loss: 0.04323903098702431, dist_loss: 0.4810764789581299
recon_loss: 0.04323842003941536, dist_loss: 0.808117151260376
recon_loss: 0.043237797915935516, dist_loss: 1.028336763381958
recon_loss: 0.04323720932006836, dist_loss: 0.35420799255371094
recon_loss: 0.0432366207242012, dist_loss: 0.6528956890106201
recon_loss: 0.043236080557107925, dist_loss: 0.6268675327301025
recon_loss: 0.04323556646704674, dist_loss: 0.7239959836006165
recon_loss: 0.04323522746562958, dist_loss: 0.9652652144432068
recon_loss: 0.043234825134277344, dist_loss: 0.8211749792098999
recon_loss: 0.04323429986834526, dist_loss: 0.45919740200042725
recon_loss: 0.04323377087712288, dist_loss: 0.3792460560798645
recon_loss: 0.043233249336481094, dist_loss: 0.34631669521331787
recon_loss: 0.04323267191648483, dist_loss: 0.45575499534606934
recon_loss: 0.04323204234242439, dist_loss: 0.3345358967781067
recon_loss: 0.04323135316371918, dist_loss: 0.4290231764316559
recon_loss: 0.04323066398501396, dist_loss: 0.821104109287262
recon_loss: 0.04322998970746994, dist_loss: 1.083882212638855
recon_loss: 0.043229397386312485, dist_loss: 0.7934341430664062
recon_loss: 0.04322882369160652, dist_loss: 0.349872887134552
recon_loss: 0.043228209018707275, dist_loss: 0.6507236957550049
recon_loss: 0.043227631598711014, dist_loss: 0.759704053401947
recon_loss: 0.043227098882198334, dist_loss: 0.6405625939369202
recon_loss: 0.04322652891278267, dist_loss: 0.32210785150527954
recon_loss: 0.0432259663939476, dist_loss: 1.2399895191192627
recon_loss: 0.04322538524866104, dist_loss: 0.46517565846443176
recon_loss: 0.043224822729825974, dist_loss: 0.35557132959365845
recon_loss: 0.04322425648570061, dist_loss: 0.7985062003135681
recon_loss: 0.043223705142736435, dist_loss: 0.8318268060684204
recon_loss: 0.043223150074481964, dist_loss: 0.4002116620540619
recon_loss: 0.043222542852163315, dist_loss: 1.0372827053070068
recon_loss: 0.04322192817926407, dist_loss: 0.7694142460823059
recon_loss: 0.04322135075926781, dist_loss: 0.7241260409355164
recon_loss: 0.043220680207014084, dist_loss: 0.8795973062515259
recon_loss: 0.043220117688179016, dist_loss: 0.8037533760070801
recon_loss: 0.043219566345214844, dist_loss: 0.8487850427627563
recon_loss: 0.04321892186999321, dist_loss: 1.0144633054733276
recon_loss: 0.04321832209825516, dist_loss: 0.5192219614982605
recon_loss: 0.04321770370006561, dist_loss: 1.0540838241577148
recon_loss: 0.04321708902716637, dist_loss: 0.4235454797744751
recon_loss: 0.04321644827723503, dist_loss: 0.7202967405319214
recon_loss: 0.043215878307819366, dist_loss: 0.741712212562561
recon_loss: 0.0432153046131134, dist_loss: 0.47662824392318726
recon_loss: 0.04321473836898804, dist_loss: 0.689984142780304
recon_loss: 0.04321422055363655, dist_loss: 0.5512489080429077
recon_loss: 0.04321367293596268, dist_loss: 0.5256518125534058
recon_loss: 0.043213143944740295, dist_loss: 0.7106101512908936
recon_loss: 0.043212659657001495, dist_loss: 1.0792853832244873
recon_loss: 0.04321226850152016, dist_loss: 0.6683012843132019
recon_loss: 0.04321186989545822, dist_loss: 0.9236605167388916
recon_loss: 0.04321147873997688, dist_loss: 0.6968695521354675
recon_loss: 0.04321103170514107, dist_loss: 0.5840317010879517
recon_loss: 0.04321064427495003, dist_loss: 0.6514235734939575
recon_loss: 0.0432102344930172, dist_loss: 0.735339879989624
recon_loss: 0.04320976883172989, dist_loss: 0.5445625185966492
recon_loss: 0.04320929944515228, dist_loss: 0.5188314914703369
recon_loss: 0.04320885241031647, dist_loss: 0.5731171369552612
recon_loss: 0.043208375573158264, dist_loss: 1.0284643173217773
recon_loss: 0.043207887560129166, dist_loss: 0.5819172263145447
recon_loss: 0.043207358568906784, dist_loss: 0.5470074415206909
recon_loss: 0.04320681095123291, dist_loss: 0.9929153919219971
recon_loss: 0.0432061031460762, dist_loss: 0.6184475421905518
recon_loss: 0.043205372989177704, dist_loss: 0.3893545866012573
recon_loss: 0.043204620480537415, dist_loss: 0.9895009994506836
recon_loss: 0.043204016983509064, dist_loss: 0.6538162231445312
recon_loss: 0.04320332035422325, dist_loss: 0.304099977016449
recon_loss: 0.04320261627435684, dist_loss: 0.6410414576530457
recon_loss: 0.043201930820941925, dist_loss: 0.7884538769721985
recon_loss: 0.043201249092817307, dist_loss: 0.6576768159866333
recon_loss: 0.04320061206817627, dist_loss: 0.6112473011016846
recon_loss: 0.04319996014237404, dist_loss: 0.6904804110527039
recon_loss: 0.04319929704070091, dist_loss: 0.9104270935058594
recon_loss: 0.0431986004114151, dist_loss: 0.6655948758125305
recon_loss: 0.043197836726903915, dist_loss: 0.3397483229637146
recon_loss: 0.043197061866521835, dist_loss: 0.398451566696167
recon_loss: 0.04319630190730095, dist_loss: 0.6021308898925781
recon_loss: 0.04319559410214424, dist_loss: 0.6337002515792847
recon_loss: 0.043195001780986786, dist_loss: 0.42128485441207886
recon_loss: 0.04319444298744202, dist_loss: 0.9317210912704468
recon_loss: 0.04319390654563904, dist_loss: 0.3835662603378296
recon_loss: 0.04319334030151367, dist_loss: 0.7464959025382996
recon_loss: 0.04319275543093681, dist_loss: 0.8633167743682861
recon_loss: 0.04319214075803757, dist_loss: 0.49594542384147644
recon_loss: 0.04319153353571892, dist_loss: 0.43241047859191895
recon_loss: 0.043190907686948776, dist_loss: 0.6139106750488281
recon_loss: 0.04319025203585625, dist_loss: 0.887601375579834
recon_loss: 0.04318952560424805, dist_loss: 1.2175419330596924
recon_loss: 0.04318877309560776, dist_loss: 0.5351886749267578
recon_loss: 0.04318813234567642, dist_loss: 0.7871884107589722
recon_loss: 0.04318748787045479, dist_loss: 0.7059011459350586
recon_loss: 0.04318689554929733, dist_loss: 0.8941345810890198
recon_loss: 0.043186284601688385, dist_loss: 0.9073214530944824
recon_loss: 0.04318557307124138, dist_loss: 0.7313426733016968
recon_loss: 0.04318491742014885, dist_loss: 0.6709349155426025
recon_loss: 0.0431843101978302, dist_loss: 0.8710616230964661
recon_loss: 0.043183766305446625, dist_loss: 0.7264600992202759
recon_loss: 0.04318328574299812, dist_loss: 0.8452939987182617
recon_loss: 0.04318274185061455, dist_loss: 0.601662278175354
recon_loss: 0.043182242661714554, dist_loss: 0.5651378631591797
recon_loss: 0.043181732296943665, dist_loss: 0.4027528166770935
recon_loss: 0.043181199580430984, dist_loss: 0.5182706713676453
recon_loss: 0.043180666863918304, dist_loss: 0.5239816308021545
recon_loss: 0.04318011552095413, dist_loss: 0.5953470468521118
recon_loss: 0.04317958652973175, dist_loss: 0.6031320095062256
Pre-training Epoch 7:  39%|███▊      | 142/367 [00:00<00:01, 178.01it/s]Pre-training Epoch 7:  44%|████▎     | 160/367 [00:00<00:01, 177.64it/s]Pre-training Epoch 7:  49%|████▊     | 178/367 [00:01<00:01, 175.58it/s]Pre-training Epoch 7:  53%|█████▎    | 196/367 [00:01<00:00, 176.03it/s]Pre-training Epoch 7:  58%|█████▊    | 214/367 [00:01<00:00, 176.05it/s]Pre-training Epoch 7:  63%|██████▎   | 233/367 [00:01<00:00, 177.07it/s]Pre-training Epoch 7:  68%|██████▊   | 251/367 [00:01<00:00, 174.71it/s]recon_loss: 0.04317905753850937, dist_loss: 0.8112648725509644
recon_loss: 0.04317852482199669, dist_loss: 0.890706479549408
recon_loss: 0.0431780107319355, dist_loss: 0.5016284584999084
recon_loss: 0.04317747801542282, dist_loss: 0.2600005865097046
recon_loss: 0.04317692294716835, dist_loss: 0.7093887329101562
recon_loss: 0.043176423758268356, dist_loss: 0.3794211745262146
recon_loss: 0.04317594692111015, dist_loss: 0.8225782513618469
recon_loss: 0.043175410479307175, dist_loss: 1.0363858938217163
recon_loss: 0.04317484423518181, dist_loss: 0.9871333837509155
recon_loss: 0.043174225836992264, dist_loss: 1.1368812322616577
recon_loss: 0.04317360371351242, dist_loss: 1.1985352039337158
recon_loss: 0.04317300394177437, dist_loss: 0.9065090417861938
recon_loss: 0.04317236319184303, dist_loss: 0.6768382787704468
recon_loss: 0.043171703815460205, dist_loss: 0.6599959135055542
recon_loss: 0.04317105561494827, dist_loss: 0.6482874155044556
recon_loss: 0.04317038133740425, dist_loss: 0.4024348258972168
recon_loss: 0.04316967725753784, dist_loss: 0.7690516710281372
recon_loss: 0.0431690514087677, dist_loss: 1.06795072555542
recon_loss: 0.04316834732890129, dist_loss: 0.5879025459289551
recon_loss: 0.04316764324903488, dist_loss: 0.4305064082145691
recon_loss: 0.04316694661974907, dist_loss: 0.8243023753166199
recon_loss: 0.04316619783639908, dist_loss: 0.8066662549972534
recon_loss: 0.04316543787717819, dist_loss: 0.5015581846237183
recon_loss: 0.0431647002696991, dist_loss: 0.5563343167304993
recon_loss: 0.043164078146219254, dist_loss: 1.2768137454986572
recon_loss: 0.04316345974802971, dist_loss: 0.3956282138824463
recon_loss: 0.04316287115216255, dist_loss: 0.6351289749145508
recon_loss: 0.04316223785281181, dist_loss: 0.5907323360443115
recon_loss: 0.04316163435578346, dist_loss: 0.4532996416091919
recon_loss: 0.043161019682884216, dist_loss: 0.6359250545501709
recon_loss: 0.043160419911146164, dist_loss: 0.3819243311882019
recon_loss: 0.04315982758998871, dist_loss: 0.787774920463562
recon_loss: 0.04315919801592827, dist_loss: 0.7928454875946045
recon_loss: 0.04315865784883499, dist_loss: 0.49811384081840515
recon_loss: 0.043158143758773804, dist_loss: 1.2094917297363281
recon_loss: 0.04315780848264694, dist_loss: 0.39162546396255493
recon_loss: 0.04315744340419769, dist_loss: 1.005794644355774
recon_loss: 0.04315699636936188, dist_loss: 0.5041162967681885
recon_loss: 0.043156567960977554, dist_loss: 0.8622174859046936
recon_loss: 0.043156132102012634, dist_loss: 0.5946453213691711
recon_loss: 0.04315578565001488, dist_loss: 0.8466421365737915
recon_loss: 0.043155424296855927, dist_loss: 0.7254844903945923
recon_loss: 0.04315510019659996, dist_loss: 0.8776720762252808
recon_loss: 0.04315478354692459, dist_loss: 0.41963672637939453
recon_loss: 0.04315437376499176, dist_loss: 1.1531367301940918
recon_loss: 0.043154001235961914, dist_loss: 0.8059804439544678
recon_loss: 0.043153636157512665, dist_loss: 0.5272090435028076
recon_loss: 0.043153271079063416, dist_loss: 0.6195138692855835
recon_loss: 0.04315287619829178, dist_loss: 0.6622083187103271
recon_loss: 0.043152473866939545, dist_loss: 0.43997514247894287
recon_loss: 0.043152157217264175, dist_loss: 1.1356399059295654
recon_loss: 0.04315193369984627, dist_loss: 0.49361297488212585
recon_loss: 0.043151646852493286, dist_loss: 0.5433906316757202
recon_loss: 0.043151333928108215, dist_loss: 0.9246921539306641
recon_loss: 0.043150998651981354, dist_loss: 0.3558129072189331
recon_loss: 0.0431506484746933, dist_loss: 1.4346650838851929
recon_loss: 0.04315022751688957, dist_loss: 0.9945915937423706
recon_loss: 0.043149836361408234, dist_loss: 0.7174012064933777
recon_loss: 0.043149471282958984, dist_loss: 0.6281207799911499
recon_loss: 0.0431489534676075, dist_loss: 0.6748320460319519
recon_loss: 0.043148644268512726, dist_loss: 0.4432494640350342
recon_loss: 0.043148282915353775, dist_loss: 0.7185158729553223
recon_loss: 0.04314785823225975, dist_loss: 0.7273292541503906
recon_loss: 0.04314737394452095, dist_loss: 0.8104749917984009
recon_loss: 0.04314680024981499, dist_loss: 0.6984253525733948
recon_loss: 0.043146129697561264, dist_loss: 0.6540965437889099
recon_loss: 0.04314560070633888, dist_loss: 0.3760262429714203
recon_loss: 0.04314503073692322, dist_loss: 0.3706538677215576
recon_loss: 0.04314449429512024, dist_loss: 0.9948687553405762
recon_loss: 0.04314398765563965, dist_loss: 0.36952513456344604
recon_loss: 0.04314350336790085, dist_loss: 0.6283942461013794
recon_loss: 0.04314301162958145, dist_loss: 0.7103476524353027
recon_loss: 0.04314247518777847, dist_loss: 1.1798285245895386
recon_loss: 0.04314184933900833, dist_loss: 0.5595971345901489
recon_loss: 0.0431411936879158, dist_loss: 0.9222241640090942
recon_loss: 0.043140560388565063, dist_loss: 0.5992136001586914
recon_loss: 0.04313986748456955, dist_loss: 0.6312713623046875
recon_loss: 0.043139129877090454, dist_loss: 0.6872552633285522
recon_loss: 0.04313847795128822, dist_loss: 0.5822087526321411
recon_loss: 0.04313789680600166, dist_loss: 0.7584365606307983
recon_loss: 0.04313734173774719, dist_loss: 0.8432539701461792
recon_loss: 0.04313686117529869, dist_loss: 0.9815711379051208
recon_loss: 0.043136391788721085, dist_loss: 0.93869948387146
recon_loss: 0.04313596710562706, dist_loss: 0.6851285696029663
recon_loss: 0.04313553124666214, dist_loss: 0.7439612150192261
recon_loss: 0.043135080486536026, dist_loss: 0.6137012243270874
recon_loss: 0.043134577572345734, dist_loss: 0.7897653579711914
recon_loss: 0.04313410446047783, dist_loss: 0.47800296545028687
recon_loss: 0.04313362017273903, dist_loss: 0.8628637194633484
recon_loss: 0.04313310235738754, dist_loss: 0.48627081513404846
recon_loss: 0.04313259571790695, dist_loss: 1.006010890007019
recon_loss: 0.04313205927610397, dist_loss: 0.5447006821632385
recon_loss: 0.043131519109010696, dist_loss: 0.5251068472862244
recon_loss: 0.04313100129365921, dist_loss: 0.4237380921840668
recon_loss: 0.04313046857714653, dist_loss: 0.4869329631328583
recon_loss: 0.04312988370656967, dist_loss: 1.5797699689865112
recon_loss: 0.04312939941883087, dist_loss: 0.4931461811065674
recon_loss: 0.043128855526447296, dist_loss: 0.5019286870956421
recon_loss: 0.043128278106451035, dist_loss: 0.9634289741516113
recon_loss: 0.04312773793935776, dist_loss: 0.8712902069091797
recon_loss: 0.043127190321683884, dist_loss: 1.494323492050171
recon_loss: 0.04312675818800926, dist_loss: 0.6152797937393188
recon_loss: 0.04312632605433464, dist_loss: 0.814394474029541
recon_loss: 0.04312586784362793, dist_loss: 1.0647696256637573
recon_loss: 0.04312549903988838, dist_loss: 0.6426586508750916
recon_loss: 0.04312502220273018, dist_loss: 0.6896588206291199
recon_loss: 0.043124474585056305, dist_loss: 0.5217655897140503
recon_loss: 0.04312385991215706, dist_loss: 0.5630051493644714
recon_loss: 0.043123286217451096, dist_loss: 0.8397892117500305
recon_loss: 0.04312271997332573, dist_loss: 0.5686934590339661
recon_loss: 0.043122127652168274, dist_loss: 0.5878270864486694
recon_loss: 0.04312155023217201, dist_loss: 0.6927258968353271
recon_loss: 0.043120987713336945, dist_loss: 0.8394490480422974
recon_loss: 0.04312044382095337, dist_loss: 0.6791408061981201
recon_loss: 0.04311991482973099, dist_loss: 0.803739070892334
recon_loss: 0.043119337409734726, dist_loss: 0.35182419419288635
recon_loss: 0.043118756264448166, dist_loss: 0.947600245475769
recon_loss: 0.043118178844451904, dist_loss: 0.4483242630958557
recon_loss: 0.04311761632561684, dist_loss: 0.6930297613143921
recon_loss: 0.04311702027916908, dist_loss: 0.8036947250366211
recon_loss: 0.04311645030975342, dist_loss: 0.7753661870956421
recon_loss: 0.04311593994498253, dist_loss: 0.9111300110816956
recon_loss: 0.043115440756082535, dist_loss: 0.6801363825798035
recon_loss: 0.043115004897117615, dist_loss: 0.574424147605896
recon_loss: 0.04311453923583031, dist_loss: 0.5789003372192383
recon_loss: 0.04311404377222061, dist_loss: 0.6097084283828735
recon_loss: 0.043113499879837036, dist_loss: 0.7908145189285278
recon_loss: 0.043112948536872864, dist_loss: 0.9705771207809448
recon_loss: 0.0431123822927475, dist_loss: 0.7697433829307556
Pre-training Epoch 7:  73%|███████▎  | 269/367 [00:01<00:00, 174.80it/s]Pre-training Epoch 7:  78%|███████▊  | 288/367 [00:01<00:00, 176.56it/s]Pre-training Epoch 7:  83%|████████▎ | 306/367 [00:01<00:00, 177.45it/s]Pre-training Epoch 7:  88%|████████▊ | 324/367 [00:01<00:00, 177.74it/s]Pre-training Epoch 7:  93%|█████████▎| 342/367 [00:01<00:00, 177.69it/s]Pre-training Epoch 7:  98%|█████████▊| 360/367 [00:02<00:00, 170.75it/s]Pre-training Epoch 7: 100%|██████████| 367/367 [00:02<00:00, 174.54it/s]
recon_loss: 0.043111834675073624, dist_loss: 0.455683171749115
recon_loss: 0.043111223727464676, dist_loss: 0.6156184673309326
recon_loss: 0.04311060905456543, dist_loss: 0.5497719049453735
recon_loss: 0.04310993105173111, dist_loss: 0.8938289284706116
recon_loss: 0.043109230697155, dist_loss: 0.7630141973495483
recon_loss: 0.04310845956206322, dist_loss: 0.6604979634284973
recon_loss: 0.04310763627290726, dist_loss: 0.6539979577064514
recon_loss: 0.04310684651136398, dist_loss: 0.7508544921875
recon_loss: 0.043106019496917725, dist_loss: 0.33390331268310547
recon_loss: 0.04310526326298714, dist_loss: 0.2797639071941376
recon_loss: 0.04310453683137894, dist_loss: 0.5964292287826538
recon_loss: 0.04310380294919014, dist_loss: 0.6628423929214478
recon_loss: 0.043103113770484924, dist_loss: 0.35719579458236694
recon_loss: 0.04310240596532822, dist_loss: 0.9505897760391235
recon_loss: 0.04310169816017151, dist_loss: 0.7501682639122009
recon_loss: 0.04310097545385361, dist_loss: 0.7013858556747437
recon_loss: 0.043100323528051376, dist_loss: 0.7624624967575073
recon_loss: 0.043099671602249146, dist_loss: 0.6866825819015503
recon_loss: 0.04309891164302826, dist_loss: 0.6659850478172302
recon_loss: 0.043098244816064835, dist_loss: 0.603740930557251
recon_loss: 0.04309770464897156, dist_loss: 0.5172775983810425
recon_loss: 0.043097157031297684, dist_loss: 0.5942443609237671
recon_loss: 0.04309661313891411, dist_loss: 0.824391782283783
recon_loss: 0.04309600591659546, dist_loss: 0.5835673213005066
recon_loss: 0.0430954173207283, dist_loss: 0.6679003238677979
recon_loss: 0.04309483617544174, dist_loss: 0.7344917058944702
recon_loss: 0.043094128370285034, dist_loss: 0.9440187215805054
recon_loss: 0.04309346526861191, dist_loss: 1.0284240245819092
recon_loss: 0.04309282451868057, dist_loss: 1.1422216892242432
recon_loss: 0.043092139065265656, dist_loss: 0.8024871349334717
recon_loss: 0.043091461062431335, dist_loss: 0.7704563736915588
recon_loss: 0.04309076443314552, dist_loss: 0.5311889052391052
recon_loss: 0.04309011250734329, dist_loss: 0.7472873330116272
recon_loss: 0.04308952018618584, dist_loss: 1.4893712997436523
recon_loss: 0.04308890551328659, dist_loss: 0.369344025850296
recon_loss: 0.04308835789561272, dist_loss: 0.6449967622756958
recon_loss: 0.04308784008026123, dist_loss: 0.6774293184280396
recon_loss: 0.04308732971549034, dist_loss: 0.5100851058959961
recon_loss: 0.04308672994375229, dist_loss: 0.507586658000946
recon_loss: 0.0430862158536911, dist_loss: 0.5347089171409607
recon_loss: 0.043085645884275436, dist_loss: 0.45696645975112915
recon_loss: 0.04308512434363365, dist_loss: 1.112565517425537
recon_loss: 0.043084800243377686, dist_loss: 0.35060301423072815
recon_loss: 0.04308455437421799, dist_loss: 0.9436883926391602
recon_loss: 0.04308423772454262, dist_loss: 0.9016174077987671
recon_loss: 0.04308398440480232, dist_loss: 0.6868976354598999
recon_loss: 0.043083686381578445, dist_loss: 0.9710876941680908
recon_loss: 0.04308329150080681, dist_loss: 0.8312230110168457
recon_loss: 0.043082695454359055, dist_loss: 0.996593177318573
recon_loss: 0.043081946671009064, dist_loss: 0.4195544719696045
recon_loss: 0.043081264942884445, dist_loss: 0.9864388108253479
recon_loss: 0.04308058321475983, dist_loss: 1.0826596021652222
recon_loss: 0.04307984560728073, dist_loss: 0.5186341404914856
recon_loss: 0.04307916760444641, dist_loss: 0.614456295967102
recon_loss: 0.04307844117283821, dist_loss: 0.8070496320724487
recon_loss: 0.04307760298252106, dist_loss: 0.8582503199577332
recon_loss: 0.043076805770397186, dist_loss: 1.1182013750076294
recon_loss: 0.04307600483298302, dist_loss: 1.0107066631317139
recon_loss: 0.043075259774923325, dist_loss: 0.5450952053070068
recon_loss: 0.043074652552604675, dist_loss: 0.6340555548667908
recon_loss: 0.043074026703834534, dist_loss: 0.6563829183578491
recon_loss: 0.04307335987687111, dist_loss: 0.8134355545043945
recon_loss: 0.04307260364294052, dist_loss: 0.3115144968032837
recon_loss: 0.04307191073894501, dist_loss: 0.8333196640014648
recon_loss: 0.04307122901082039, dist_loss: 0.4159643054008484
recon_loss: 0.043070558458566666, dist_loss: 0.9829837083816528
recon_loss: 0.04306987300515175, dist_loss: 0.9085779190063477
recon_loss: 0.043069154024124146, dist_loss: 0.5564146041870117
recon_loss: 0.043068427592515945, dist_loss: 0.917008638381958
recon_loss: 0.043067727237939835, dist_loss: 0.34932300448417664
recon_loss: 0.0430670790374279, dist_loss: 0.5835050344467163
recon_loss: 0.04306642338633537, dist_loss: 1.1185977458953857
recon_loss: 0.04306580871343613, dist_loss: 0.5700953006744385
recon_loss: 0.04306509345769882, dist_loss: 0.7134100198745728
recon_loss: 0.04306432604789734, dist_loss: 0.5388885140419006
recon_loss: 0.04306356608867645, dist_loss: 0.47467660903930664
recon_loss: 0.043062809854745865, dist_loss: 0.537338137626648
recon_loss: 0.04306204989552498, dist_loss: 0.668241024017334
recon_loss: 0.04306122660636902, dist_loss: 1.0723904371261597
recon_loss: 0.043060362339019775, dist_loss: 0.6057673692703247
recon_loss: 0.043059445917606354, dist_loss: 0.6874862313270569
recon_loss: 0.0430586040019989, dist_loss: 1.3497583866119385
recon_loss: 0.04305781051516533, dist_loss: 1.160539150238037
recon_loss: 0.04305713623762131, dist_loss: 0.6148470044136047
recon_loss: 0.0430564321577549, dist_loss: 0.9489976167678833
recon_loss: 0.04305576905608177, dist_loss: 0.7618478536605835
recon_loss: 0.043055132031440735, dist_loss: 0.7449842691421509
recon_loss: 0.043054454028606415, dist_loss: 0.7600871920585632
recon_loss: 0.04305379092693329, dist_loss: 0.7268028259277344
recon_loss: 0.043053191155195236, dist_loss: 0.8558810949325562
recon_loss: 0.043052565306425095, dist_loss: 0.8724017143249512
recon_loss: 0.04305190593004227, dist_loss: 0.5567110776901245
recon_loss: 0.043051328510046005, dist_loss: 0.7542415857315063
recon_loss: 0.04305065795779228, dist_loss: 0.485462486743927
recon_loss: 0.04305002838373184, dist_loss: 0.5507277250289917
recon_loss: 0.04304947331547737, dist_loss: 0.7005250453948975
recon_loss: 0.04304893687367439, dist_loss: 1.2695651054382324
recon_loss: 0.04304835572838783, dist_loss: 0.8095844984054565
recon_loss: 0.04304767772555351, dist_loss: 0.5479481816291809
recon_loss: 0.0430469736456871, dist_loss: 0.5355718731880188
recon_loss: 0.04304630681872368, dist_loss: 1.0401535034179688
recon_loss: 0.04304556921124458, dist_loss: 0.8026676177978516
recon_loss: 0.04304485023021698, dist_loss: 0.6212777495384216
recon_loss: 0.04304422065615654, dist_loss: 0.746269941329956
recon_loss: 0.043043531477451324, dist_loss: 0.49444854259490967
recon_loss: 0.043042898178100586, dist_loss: 0.5835960507392883
recon_loss: 0.04304221272468567, dist_loss: 1.0157666206359863
recon_loss: 0.04304155334830284, dist_loss: 0.607450008392334
recon_loss: 0.04304094985127449, dist_loss: 0.24355681240558624
Pre-training Epoch 8:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 8:   4%|▍         | 16/367 [00:00<00:02, 151.07it/s]Pre-training Epoch 8:   9%|▊         | 32/367 [00:00<00:02, 155.34it/s]Pre-training Epoch 8:  13%|█▎        | 49/367 [00:00<00:01, 160.39it/s]Pre-training Epoch 8:  18%|█▊        | 67/367 [00:00<00:01, 164.97it/s]Pre-training Epoch 8:  23%|██▎       | 86/367 [00:00<00:01, 171.38it/s]Pre-training Epoch 8:  28%|██▊       | 104/367 [00:00<00:01, 173.78it/s]Pre-training Epoch 8:  34%|███▎      | 123/367 [00:00<00:01, 175.92it/s]recon_loss: 0.043040357530117035, dist_loss: 0.7703834176063538
recon_loss: 0.04303975775837898, dist_loss: 0.44535478949546814
recon_loss: 0.043039217591285706, dist_loss: 0.7684729695320129
recon_loss: 0.04303882643580437, dist_loss: 0.5285546183586121
recon_loss: 0.043038442730903625, dist_loss: 1.4782873392105103
recon_loss: 0.0430380180478096, dist_loss: 0.9064767360687256
recon_loss: 0.04303760826587677, dist_loss: 0.592475414276123
recon_loss: 0.04303721711039543, dist_loss: 0.5620660781860352
recon_loss: 0.04303679242730141, dist_loss: 0.8393687605857849
recon_loss: 0.04303627461194992, dist_loss: 0.4659205973148346
recon_loss: 0.04303581640124321, dist_loss: 0.40560662746429443
recon_loss: 0.0430353507399559, dist_loss: 1.025335669517517
recon_loss: 0.04303472861647606, dist_loss: 0.803512692451477
recon_loss: 0.04303410276770592, dist_loss: 0.6007546186447144
recon_loss: 0.04303355887532234, dist_loss: 0.6547062397003174
recon_loss: 0.0430329255759716, dist_loss: 0.5097789764404297
recon_loss: 0.04303234815597534, dist_loss: 0.6476312875747681
recon_loss: 0.04303187131881714, dist_loss: 0.8311501741409302
recon_loss: 0.04303138703107834, dist_loss: 0.5012392997741699
recon_loss: 0.043030768632888794, dist_loss: 0.6030031442642212
recon_loss: 0.043030209839344025, dist_loss: 0.6141533851623535
recon_loss: 0.04302968457341194, dist_loss: 1.0729241371154785
recon_loss: 0.04302907735109329, dist_loss: 0.7584737539291382
recon_loss: 0.043028417974710464, dist_loss: 0.5175507664680481
recon_loss: 0.04302775114774704, dist_loss: 0.9953810572624207
recon_loss: 0.0430271290242672, dist_loss: 0.6934813857078552
recon_loss: 0.04302660748362541, dist_loss: 0.8966153264045715
recon_loss: 0.04302592948079109, dist_loss: 0.9141049385070801
recon_loss: 0.0430251844227314, dist_loss: 0.5458636283874512
recon_loss: 0.04302452132105827, dist_loss: 0.7146714925765991
recon_loss: 0.043023914098739624, dist_loss: 0.6097227931022644
recon_loss: 0.04302334040403366, dist_loss: 0.7894502878189087
recon_loss: 0.04302278906106949, dist_loss: 0.6528663635253906
recon_loss: 0.04302230477333069, dist_loss: 0.8828175067901611
recon_loss: 0.043021880090236664, dist_loss: 0.5849770307540894
recon_loss: 0.04302145168185234, dist_loss: 0.5766798257827759
recon_loss: 0.043021004647016525, dist_loss: 0.6282006502151489
recon_loss: 0.043020378798246384, dist_loss: 0.3165815472602844
recon_loss: 0.04301978275179863, dist_loss: 0.6706807613372803
recon_loss: 0.04301918298006058, dist_loss: 0.7355833053588867
recon_loss: 0.043018732219934464, dist_loss: 0.5144186019897461
recon_loss: 0.04301837831735611, dist_loss: 0.5535893440246582
recon_loss: 0.04301784932613373, dist_loss: 0.585739254951477
recon_loss: 0.04301728680729866, dist_loss: 0.7240345478057861
recon_loss: 0.043016739189624786, dist_loss: 0.8072464466094971
recon_loss: 0.04301612824201584, dist_loss: 0.9598933458328247
recon_loss: 0.04301559180021286, dist_loss: 0.48058032989501953
recon_loss: 0.04301520064473152, dist_loss: 0.44131341576576233
recon_loss: 0.04301473870873451, dist_loss: 0.7176599502563477
recon_loss: 0.043014366179704666, dist_loss: 0.7684316039085388
recon_loss: 0.04301399737596512, dist_loss: 0.6100784540176392
recon_loss: 0.043013472110033035, dist_loss: 0.5752070546150208
recon_loss: 0.04301310330629349, dist_loss: 0.48155874013900757
recon_loss: 0.04301266744732857, dist_loss: 0.48630383610725403
recon_loss: 0.04301214963197708, dist_loss: 0.8410327434539795
recon_loss: 0.04301153123378754, dist_loss: 0.3564757704734802
recon_loss: 0.04301100969314575, dist_loss: 0.556972861289978
recon_loss: 0.04301054775714874, dist_loss: 0.6837003231048584
recon_loss: 0.04301001876592636, dist_loss: 0.752232551574707
recon_loss: 0.04300955310463905, dist_loss: 0.8884496688842773
recon_loss: 0.04300902783870697, dist_loss: 0.8077627420425415
recon_loss: 0.0430084653198719, dist_loss: 0.5948896408081055
recon_loss: 0.04300778731703758, dist_loss: 0.770989179611206
recon_loss: 0.04300718382000923, dist_loss: 0.6854955554008484
recon_loss: 0.043006423860788345, dist_loss: 1.0298289060592651
recon_loss: 0.04300563782453537, dist_loss: 0.5332850813865662
recon_loss: 0.04300478845834732, dist_loss: 0.4803352653980255
recon_loss: 0.04300395026803017, dist_loss: 0.8920629024505615
recon_loss: 0.04300317540764809, dist_loss: 0.6369405388832092
recon_loss: 0.04300237447023392, dist_loss: 0.510718584060669
recon_loss: 0.043001752346754074, dist_loss: 0.8077413439750671
recon_loss: 0.04300106316804886, dist_loss: 0.6045645475387573
recon_loss: 0.043000444769859314, dist_loss: 0.6131336688995361
recon_loss: 0.042999736964702606, dist_loss: 1.0145907402038574
recon_loss: 0.04299914464354515, dist_loss: 0.4197734594345093
recon_loss: 0.04299864545464516, dist_loss: 0.5271852016448975
recon_loss: 0.04299817979335785, dist_loss: 0.9019666910171509
recon_loss: 0.04299776628613472, dist_loss: 0.5106995105743408
recon_loss: 0.042997367680072784, dist_loss: 1.2674334049224854
recon_loss: 0.04299706965684891, dist_loss: 0.4260466396808624
recon_loss: 0.04299677163362503, dist_loss: 0.5968273878097534
recon_loss: 0.04299642890691757, dist_loss: 0.7499295473098755
recon_loss: 0.04299613833427429, dist_loss: 0.43571043014526367
recon_loss: 0.04299592599272728, dist_loss: 0.8756446838378906
recon_loss: 0.04299575090408325, dist_loss: 0.5473957061767578
recon_loss: 0.042995668947696686, dist_loss: 0.7211316823959351
recon_loss: 0.04299546778202057, dist_loss: 0.671795129776001
recon_loss: 0.042995207011699677, dist_loss: 0.347200870513916
recon_loss: 0.042994968593120575, dist_loss: 0.7897297739982605
recon_loss: 0.04299456626176834, dist_loss: 0.6391804218292236
recon_loss: 0.04299407824873924, dist_loss: 1.0126724243164062
recon_loss: 0.0429934561252594, dist_loss: 0.6600038409233093
recon_loss: 0.042992834001779556, dist_loss: 0.7115795016288757
recon_loss: 0.042992155998945236, dist_loss: 0.8129595518112183
recon_loss: 0.04299134761095047, dist_loss: 0.6654657125473022
recon_loss: 0.04299044981598854, dist_loss: 0.4916771650314331
recon_loss: 0.04298965260386467, dist_loss: 0.5589605569839478
recon_loss: 0.04298897460103035, dist_loss: 0.41618746519088745
recon_loss: 0.042988121509552, dist_loss: 0.5715652704238892
recon_loss: 0.04298712685704231, dist_loss: 0.5579922199249268
recon_loss: 0.042986102402210236, dist_loss: 1.0235555171966553
recon_loss: 0.04298492893576622, dist_loss: 0.8870840072631836
recon_loss: 0.04298386722803116, dist_loss: 0.8460411429405212
recon_loss: 0.04298289120197296, dist_loss: 0.29268425703048706
recon_loss: 0.04298200085759163, dist_loss: 0.6579787731170654
recon_loss: 0.04298107698559761, dist_loss: 0.9523789286613464
recon_loss: 0.04298027232289314, dist_loss: 0.8139001727104187
recon_loss: 0.042979348450899124, dist_loss: 0.5291101336479187
recon_loss: 0.04297839477658272, dist_loss: 0.4672016203403473
recon_loss: 0.04297743737697601, dist_loss: 0.6023725867271423
recon_loss: 0.042976509779691696, dist_loss: 0.8068858981132507
recon_loss: 0.042975638061761856, dist_loss: 0.6789765357971191
recon_loss: 0.04297483712434769, dist_loss: 0.7668794393539429
recon_loss: 0.042974237352609634, dist_loss: 0.971191942691803
recon_loss: 0.04297364875674248, dist_loss: 1.0019512176513672
recon_loss: 0.042973004281520844, dist_loss: 0.8143570423126221
recon_loss: 0.04297233000397682, dist_loss: 1.0637351274490356
recon_loss: 0.04297160729765892, dist_loss: 0.505774736404419
recon_loss: 0.042970817536115646, dist_loss: 0.5697504281997681
recon_loss: 0.04297010973095894, dist_loss: 1.277374505996704
recon_loss: 0.04296938329935074, dist_loss: 0.8028650283813477
recon_loss: 0.04296863451600075, dist_loss: 0.49602824449539185
recon_loss: 0.04296791926026344, dist_loss: 0.6368739604949951
recon_loss: 0.04296722635626793, dist_loss: 0.39186587929725647
recon_loss: 0.04296658933162689, dist_loss: 0.465847373008728
recon_loss: 0.04296599328517914, dist_loss: 0.9187180995941162
recon_loss: 0.042965393513441086, dist_loss: 0.8758061528205872
recon_loss: 0.042964689433574677, dist_loss: 0.8726984858512878
recon_loss: 0.04296404868364334, dist_loss: 0.7876302003860474
Pre-training Epoch 8:  38%|███▊      | 141/367 [00:00<00:01, 177.18it/s]Pre-training Epoch 8:  43%|████▎     | 159/367 [00:00<00:01, 175.24it/s]Pre-training Epoch 8:  48%|████▊     | 177/367 [00:01<00:01, 166.61it/s]Pre-training Epoch 8:  53%|█████▎    | 194/367 [00:01<00:01, 162.51it/s]Pre-training Epoch 8:  57%|█████▋    | 211/367 [00:01<00:00, 159.68it/s]Pre-training Epoch 8:  62%|██████▏   | 229/367 [00:01<00:00, 165.14it/s]Pre-training Epoch 8:  68%|██████▊   | 249/367 [00:01<00:00, 173.49it/s]recon_loss: 0.04296346381306648, dist_loss: 0.7017913460731506
recon_loss: 0.042962752282619476, dist_loss: 0.9774788618087769
recon_loss: 0.042961932718753815, dist_loss: 0.5873310565948486
recon_loss: 0.04296112805604935, dist_loss: 0.42532557249069214
recon_loss: 0.04296031594276428, dist_loss: 0.6128703355789185
recon_loss: 0.04295957460999489, dist_loss: 0.7647026777267456
recon_loss: 0.042958784848451614, dist_loss: 0.7175431251525879
recon_loss: 0.04295806586742401, dist_loss: 0.5655012726783752
recon_loss: 0.04295735061168671, dist_loss: 0.6899893879890442
recon_loss: 0.042956527322530746, dist_loss: 0.7879714965820312
recon_loss: 0.04295561462640762, dist_loss: 0.9130451083183289
recon_loss: 0.04295465722680092, dist_loss: 0.7649420499801636
recon_loss: 0.04295370355248451, dist_loss: 0.48903268575668335
recon_loss: 0.042952749878168106, dist_loss: 0.39285656809806824
recon_loss: 0.04295182228088379, dist_loss: 0.31838172674179077
recon_loss: 0.04295093193650246, dist_loss: 0.5438871383666992
recon_loss: 0.04294999688863754, dist_loss: 0.6901178359985352
recon_loss: 0.042949166148900986, dist_loss: 0.5632096529006958
recon_loss: 0.04294829070568085, dist_loss: 0.7726175785064697
recon_loss: 0.04294738918542862, dist_loss: 0.5994943380355835
recon_loss: 0.042946480214595795, dist_loss: 0.5724557638168335
recon_loss: 0.04294556379318237, dist_loss: 0.9698416590690613
recon_loss: 0.042944684624671936, dist_loss: 0.42240723967552185
recon_loss: 0.04294392094016075, dist_loss: 0.44637244939804077
recon_loss: 0.04294313117861748, dist_loss: 1.1441102027893066
recon_loss: 0.0429423451423645, dist_loss: 1.1636433601379395
recon_loss: 0.04294143244624138, dist_loss: 0.9454113245010376
recon_loss: 0.04294058308005333, dist_loss: 0.363107830286026
recon_loss: 0.042939744889736176, dist_loss: 1.2134268283843994
recon_loss: 0.04293892905116081, dist_loss: 0.8652984499931335
recon_loss: 0.04293820261955261, dist_loss: 1.2844722270965576
recon_loss: 0.0429374985396862, dist_loss: 0.774810791015625
recon_loss: 0.04293680936098099, dist_loss: 0.5711137652397156
recon_loss: 0.04293613135814667, dist_loss: 0.883254885673523
recon_loss: 0.04293544590473175, dist_loss: 0.5059863328933716
recon_loss: 0.042934853583574295, dist_loss: 0.6292814016342163
recon_loss: 0.04293426498770714, dist_loss: 0.6710813045501709
recon_loss: 0.04293367639183998, dist_loss: 0.6661790013313293
recon_loss: 0.042933158576488495, dist_loss: 0.7599622011184692
recon_loss: 0.042932599782943726, dist_loss: 0.8227952718734741
recon_loss: 0.04293203353881836, dist_loss: 0.9064633250236511
recon_loss: 0.04293162375688553, dist_loss: 0.5363610982894897
recon_loss: 0.042931243777275085, dist_loss: 0.8079924583435059
recon_loss: 0.04293100908398628, dist_loss: 0.7158873081207275
recon_loss: 0.04293091967701912, dist_loss: 0.7668596506118774
recon_loss: 0.04293077066540718, dist_loss: 0.819243848323822
recon_loss: 0.042930614203214645, dist_loss: 0.8731981515884399
recon_loss: 0.042930472642183304, dist_loss: 0.8818399906158447
recon_loss: 0.04293025657534599, dist_loss: 0.7313941717147827
recon_loss: 0.042930010706186295, dist_loss: 1.206810712814331
recon_loss: 0.04292956367135048, dist_loss: 0.9540645480155945
recon_loss: 0.0429292656481266, dist_loss: 0.8267462253570557
recon_loss: 0.042928844690322876, dist_loss: 0.8730685710906982
recon_loss: 0.04292834922671318, dist_loss: 0.4876342713832855
recon_loss: 0.042927760630846024, dist_loss: 0.7142864465713501
recon_loss: 0.04292722046375275, dist_loss: 0.8137727975845337
recon_loss: 0.04292667657136917, dist_loss: 0.8466123342514038
recon_loss: 0.04292607679963112, dist_loss: 0.4322342276573181
recon_loss: 0.042925670742988586, dist_loss: 0.8464152812957764
recon_loss: 0.042925067245960236, dist_loss: 0.9165070056915283
recon_loss: 0.04292449355125427, dist_loss: 0.5151996612548828
recon_loss: 0.04292386770248413, dist_loss: 0.4828171730041504
recon_loss: 0.04292327165603638, dist_loss: 0.7122637033462524
recon_loss: 0.04292280599474907, dist_loss: 0.5034512281417847
recon_loss: 0.042922407388687134, dist_loss: 0.9537504315376282
recon_loss: 0.04292190447449684, dist_loss: 0.5408695936203003
recon_loss: 0.042921386659145355, dist_loss: 0.9181452393531799
recon_loss: 0.042920853942632675, dist_loss: 0.7945282459259033
recon_loss: 0.04292048141360283, dist_loss: 0.47714763879776
recon_loss: 0.04292009770870209, dist_loss: 0.7566721439361572
recon_loss: 0.04291973635554314, dist_loss: 1.1691476106643677
recon_loss: 0.04291906952857971, dist_loss: 0.828885555267334
recon_loss: 0.04291841387748718, dist_loss: 0.5886980295181274
recon_loss: 0.04291779547929764, dist_loss: 0.5014160871505737
recon_loss: 0.042917218059301376, dist_loss: 0.5550734996795654
recon_loss: 0.04291670024394989, dist_loss: 0.8196521401405334
recon_loss: 0.04291628673672676, dist_loss: 0.468370258808136
recon_loss: 0.04291582107543945, dist_loss: 0.7452352046966553
recon_loss: 0.04291535168886185, dist_loss: 1.0044444799423218
recon_loss: 0.04291486367583275, dist_loss: 0.5586972236633301
recon_loss: 0.04291432723402977, dist_loss: 0.47766709327697754
recon_loss: 0.04291380196809769, dist_loss: 0.6144400835037231
recon_loss: 0.04291320592164993, dist_loss: 0.8940620422363281
recon_loss: 0.042912557721138, dist_loss: 1.011332392692566
recon_loss: 0.042911868542432785, dist_loss: 0.8719767928123474
recon_loss: 0.04291125014424324, dist_loss: 0.4676017761230469
recon_loss: 0.04291057214140892, dist_loss: 1.4280847311019897
recon_loss: 0.04290985316038132, dist_loss: 0.5243528485298157
recon_loss: 0.04290919378399849, dist_loss: 0.5177795886993408
recon_loss: 0.04290859028697014, dist_loss: 0.6824109554290771
recon_loss: 0.04290799796581268, dist_loss: 0.5596705079078674
recon_loss: 0.04290749505162239, dist_loss: 0.39020055532455444
recon_loss: 0.042906999588012695, dist_loss: 0.7521867752075195
recon_loss: 0.04290662705898285, dist_loss: 0.7943922281265259
recon_loss: 0.04290628805756569, dist_loss: 0.6194599270820618
recon_loss: 0.04290580376982689, dist_loss: 0.7540980577468872
recon_loss: 0.04290523752570152, dist_loss: 0.9474377632141113
recon_loss: 0.042904652655124664, dist_loss: 1.0044504404067993
recon_loss: 0.04290405288338661, dist_loss: 0.6828880906105042
recon_loss: 0.042903535068035126, dist_loss: 0.5994725823402405
recon_loss: 0.04290291666984558, dist_loss: 0.8511391878128052
recon_loss: 0.04290221631526947, dist_loss: 0.7204883098602295
recon_loss: 0.04290144890546799, dist_loss: 0.8512040376663208
recon_loss: 0.042900703847408295, dist_loss: 0.6284282803535461
recon_loss: 0.04290011525154114, dist_loss: 0.5540330410003662
recon_loss: 0.042899515479803085, dist_loss: 0.7463330030441284
recon_loss: 0.042898956686258316, dist_loss: 0.5946035981178284
recon_loss: 0.04289844259619713, dist_loss: 0.6134858131408691
recon_loss: 0.04289782792329788, dist_loss: 0.4300474226474762
recon_loss: 0.042897261679172516, dist_loss: 0.8392062783241272
recon_loss: 0.04289678856730461, dist_loss: 1.007887363433838
recon_loss: 0.04289620369672775, dist_loss: 0.5740923881530762
recon_loss: 0.0428956039249897, dist_loss: 0.5345203280448914
recon_loss: 0.04289497435092926, dist_loss: 0.667313277721405
recon_loss: 0.04289434105157852, dist_loss: 1.189420223236084
recon_loss: 0.04289352893829346, dist_loss: 0.5515791773796082
recon_loss: 0.042892638593912125, dist_loss: 0.38875603675842285
recon_loss: 0.042891811579465866, dist_loss: 0.8259913325309753
recon_loss: 0.04289112985134125, dist_loss: 0.517014741897583
recon_loss: 0.042890410870313644, dist_loss: 0.5175651907920837
recon_loss: 0.04288959130644798, dist_loss: 1.0174087285995483
recon_loss: 0.04288871958851814, dist_loss: 0.7044519186019897
recon_loss: 0.042887985706329346, dist_loss: 0.75770103931427
recon_loss: 0.042887233197689056, dist_loss: 1.3571975231170654
recon_loss: 0.04288644343614578, dist_loss: 1.1381932497024536
recon_loss: 0.04288575053215027, dist_loss: 0.6539351940155029
recon_loss: 0.04288508743047714, dist_loss: 0.6541972160339355
recon_loss: 0.0428842194378376, dist_loss: 0.6955772638320923
recon_loss: 0.042883217334747314, dist_loss: 0.6553193926811218
Pre-training Epoch 8:  73%|███████▎  | 269/367 [00:01<00:00, 179.40it/s]Pre-training Epoch 8:  79%|███████▊  | 289/367 [00:01<00:00, 183.71it/s]Pre-training Epoch 8:  84%|████████▍ | 309/367 [00:01<00:00, 186.73it/s]Pre-training Epoch 8:  90%|████████▉ | 329/367 [00:01<00:00, 188.40it/s]Pre-training Epoch 8:  95%|█████████▍| 348/367 [00:02<00:00, 176.26it/s]Pre-training Epoch 8: 100%|█████████▉| 366/367 [00:02<00:00, 170.46it/s]Pre-training Epoch 8: 100%|██████████| 367/367 [00:02<00:00, 171.93it/s]
recon_loss: 0.042882245033979416, dist_loss: 0.6274259090423584
recon_loss: 0.04288129135966301, dist_loss: 0.9594414830207825
recon_loss: 0.04288025200366974, dist_loss: 0.6369823217391968
recon_loss: 0.042879100888967514, dist_loss: 0.30120792984962463
recon_loss: 0.04287809878587723, dist_loss: 0.5557132959365845
recon_loss: 0.04287712648510933, dist_loss: 0.5734280347824097
recon_loss: 0.042876169085502625, dist_loss: 0.7228212356567383
recon_loss: 0.04287521541118622, dist_loss: 0.8189173936843872
recon_loss: 0.0428742915391922, dist_loss: 0.8081701397895813
recon_loss: 0.04287339746952057, dist_loss: 0.8184879422187805
recon_loss: 0.04287246987223625, dist_loss: 0.8923242688179016
recon_loss: 0.04287152737379074, dist_loss: 0.9476850032806396
recon_loss: 0.04287070780992508, dist_loss: 0.2931739389896393
recon_loss: 0.042869869619607925, dist_loss: 0.807793140411377
recon_loss: 0.04286908358335495, dist_loss: 0.7857764959335327
recon_loss: 0.04286820814013481, dist_loss: 1.0047852993011475
recon_loss: 0.042867355048656464, dist_loss: 0.7611727714538574
recon_loss: 0.04286651313304901, dist_loss: 0.7516137361526489
recon_loss: 0.04286571219563484, dist_loss: 0.6514021158218384
recon_loss: 0.04286490008234978, dist_loss: 0.7350952625274658
recon_loss: 0.04286408796906471, dist_loss: 0.4094228744506836
recon_loss: 0.04286336153745651, dist_loss: 0.6359685659408569
recon_loss: 0.04286269098520279, dist_loss: 0.8229754567146301
recon_loss: 0.04286198690533638, dist_loss: 0.5944681167602539
recon_loss: 0.04286123067140579, dist_loss: 0.9878976941108704
recon_loss: 0.04286041855812073, dist_loss: 0.6756759881973267
recon_loss: 0.04285956546664238, dist_loss: 0.5628280639648438
recon_loss: 0.04285872355103493, dist_loss: 0.5087325572967529
recon_loss: 0.04285797104239464, dist_loss: 0.9130407571792603
recon_loss: 0.0428573414683342, dist_loss: 0.49675363302230835
recon_loss: 0.04285673052072525, dist_loss: 0.6603690981864929
recon_loss: 0.042856089770793915, dist_loss: 1.1772513389587402
recon_loss: 0.04285542294383049, dist_loss: 0.6485716104507446
recon_loss: 0.042854707688093185, dist_loss: 0.4586114287376404
recon_loss: 0.042854081839323044, dist_loss: 0.38365423679351807
recon_loss: 0.04285347834229469, dist_loss: 1.0999503135681152
recon_loss: 0.04285288229584694, dist_loss: 0.8010718822479248
recon_loss: 0.042852338403463364, dist_loss: 0.5036677122116089
recon_loss: 0.04285193979740143, dist_loss: 0.6662125587463379
recon_loss: 0.0428515300154686, dist_loss: 0.8512264490127563
recon_loss: 0.042851097881793976, dist_loss: 0.4286273121833801
recon_loss: 0.04285067319869995, dist_loss: 0.4318123459815979
recon_loss: 0.042850226163864136, dist_loss: 0.559794008731842
recon_loss: 0.04284984618425369, dist_loss: 0.5934253931045532
recon_loss: 0.04284949600696564, dist_loss: 0.713249921798706
recon_loss: 0.042849183082580566, dist_loss: 0.6432245969772339
recon_loss: 0.04284892976284027, dist_loss: 0.6260908842086792
recon_loss: 0.04284869134426117, dist_loss: 1.087027907371521
recon_loss: 0.04284835606813431, dist_loss: 0.47147294878959656
recon_loss: 0.04284794256091118, dist_loss: 0.5420535802841187
recon_loss: 0.042847517877817154, dist_loss: 0.8015027642250061
recon_loss: 0.042846981436014175, dist_loss: 0.7333512306213379
recon_loss: 0.04284653812646866, dist_loss: 0.7544916868209839
recon_loss: 0.0428461991250515, dist_loss: 0.5856503844261169
recon_loss: 0.04284580424427986, dist_loss: 0.7729159593582153
recon_loss: 0.0428454726934433, dist_loss: 0.4175236225128174
recon_loss: 0.04284524545073509, dist_loss: 0.6907662153244019
recon_loss: 0.0428449921309948, dist_loss: 0.6919644474983215
recon_loss: 0.042844656854867935, dist_loss: 0.5786271095275879
recon_loss: 0.04284432902932167, dist_loss: 0.5861849784851074
recon_loss: 0.04284392669796944, dist_loss: 0.6605258584022522
recon_loss: 0.04284347593784332, dist_loss: 0.5813111662864685
recon_loss: 0.042842965573072433, dist_loss: 0.6711674928665161
recon_loss: 0.04284248128533363, dist_loss: 0.9618569016456604
recon_loss: 0.042841773480176926, dist_loss: 0.7913613319396973
recon_loss: 0.042841069400310516, dist_loss: 0.8790693283081055
recon_loss: 0.042840298265218735, dist_loss: 0.34390103816986084
recon_loss: 0.04283957555890083, dist_loss: 0.9912248849868774
recon_loss: 0.042838677763938904, dist_loss: 0.33251816034317017
recon_loss: 0.04283789172768593, dist_loss: 0.44344013929367065
recon_loss: 0.04283694177865982, dist_loss: 0.6991406679153442
recon_loss: 0.04283605143427849, dist_loss: 0.5174816846847534
recon_loss: 0.04283528029918671, dist_loss: 1.0197460651397705
recon_loss: 0.04283439368009567, dist_loss: 0.7351029515266418
recon_loss: 0.04283341392874718, dist_loss: 0.9180765748023987
recon_loss: 0.04283248260617256, dist_loss: 0.7652637958526611
recon_loss: 0.0428314246237278, dist_loss: 0.9054636359214783
recon_loss: 0.0428304448723793, dist_loss: 0.4737132787704468
recon_loss: 0.042829521000385284, dist_loss: 0.6343446969985962
recon_loss: 0.04282855615019798, dist_loss: 0.7514709234237671
recon_loss: 0.042827676981687546, dist_loss: 0.8243018984794617
recon_loss: 0.04282671585679054, dist_loss: 0.35754847526550293
recon_loss: 0.042825788259506226, dist_loss: 0.8930457830429077
recon_loss: 0.04282495751976967, dist_loss: 0.48213130235671997
recon_loss: 0.04282406345009804, dist_loss: 0.5168968439102173
recon_loss: 0.0428231917321682, dist_loss: 0.7110191583633423
recon_loss: 0.04282226040959358, dist_loss: 0.43964582681655884
recon_loss: 0.04282138869166374, dist_loss: 0.9528710246086121
recon_loss: 0.04282047972083092, dist_loss: 0.6432532072067261
recon_loss: 0.042819708585739136, dist_loss: 0.5053060054779053
recon_loss: 0.04281890392303467, dist_loss: 0.7558760046958923
recon_loss: 0.0428181067109108, dist_loss: 1.245651125907898
recon_loss: 0.04281731694936752, dist_loss: 0.44566333293914795
recon_loss: 0.04281660169363022, dist_loss: 0.8261398673057556
recon_loss: 0.042816027998924255, dist_loss: 0.5463157892227173
recon_loss: 0.042815376073122025, dist_loss: 0.7371320724487305
recon_loss: 0.04281473159790039, dist_loss: 0.7827600240707397
recon_loss: 0.042814090847969055, dist_loss: 0.9358552694320679
recon_loss: 0.042813293635845184, dist_loss: 0.6502664685249329
recon_loss: 0.04281242564320564, dist_loss: 0.5369361639022827
recon_loss: 0.0428115651011467, dist_loss: 0.7696875333786011
recon_loss: 0.04281068220734596, dist_loss: 0.38923734426498413
recon_loss: 0.04280984029173851, dist_loss: 0.7673381567001343
recon_loss: 0.04280891641974449, dist_loss: 0.8805949091911316
recon_loss: 0.042808134108781815, dist_loss: 0.4684898853302002
recon_loss: 0.04280741512775421, dist_loss: 1.1302483081817627
recon_loss: 0.04280677065253258, dist_loss: 0.657833456993103
recon_loss: 0.042806170880794525, dist_loss: 0.5764883160591125
recon_loss: 0.04280564934015274, dist_loss: 0.2770143449306488
Pre-training Epoch 9:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 9:   5%|▍         | 17/367 [00:00<00:02, 158.75it/s]Pre-training Epoch 9:  10%|▉         | 35/367 [00:00<00:01, 168.74it/s]Pre-training Epoch 9:  14%|█▍        | 53/367 [00:00<00:01, 172.30it/s]Pre-training Epoch 9:  20%|█▉        | 72/367 [00:00<00:01, 175.51it/s]Pre-training Epoch 9:  25%|██▍       | 90/367 [00:00<00:01, 166.63it/s]Pre-training Epoch 9:  29%|██▉       | 107/367 [00:00<00:01, 161.74it/s]Pre-training Epoch 9:  34%|███▍      | 124/367 [00:00<00:01, 158.88it/s]recon_loss: 0.04280497506260872, dist_loss: 0.8172072172164917
recon_loss: 0.04280419647693634, dist_loss: 0.6709167957305908
recon_loss: 0.04280347749590874, dist_loss: 0.6975207328796387
recon_loss: 0.04280271753668785, dist_loss: 0.5189996361732483
recon_loss: 0.0428018756210804, dist_loss: 1.1415948867797852
recon_loss: 0.042801182717084885, dist_loss: 0.38376134634017944
recon_loss: 0.042800504714250565, dist_loss: 0.33453479409217834
recon_loss: 0.04279995337128639, dist_loss: 0.4082719385623932
recon_loss: 0.042799510061740875, dist_loss: 0.7587771415710449
recon_loss: 0.042798928916454315, dist_loss: 0.5374019145965576
recon_loss: 0.042798325419425964, dist_loss: 0.7886985540390015
recon_loss: 0.04279761761426926, dist_loss: 0.37778598070144653
recon_loss: 0.042796920984983444, dist_loss: 0.6944811940193176
recon_loss: 0.04279622808098793, dist_loss: 0.5996384620666504
recon_loss: 0.04279560595750809, dist_loss: 0.6850738525390625
recon_loss: 0.042795129120349884, dist_loss: 0.4422406554222107
recon_loss: 0.04279476776719093, dist_loss: 0.8125197887420654
recon_loss: 0.04279429838061333, dist_loss: 0.42974501848220825
recon_loss: 0.04279373958706856, dist_loss: 1.002946138381958
recon_loss: 0.042793091386556625, dist_loss: 1.0858675241470337
recon_loss: 0.04279238358139992, dist_loss: 0.62007737159729
recon_loss: 0.04279166832566261, dist_loss: 0.6573612689971924
recon_loss: 0.04279104247689247, dist_loss: 0.7495057582855225
recon_loss: 0.042790330946445465, dist_loss: 0.5538243651390076
recon_loss: 0.04278982803225517, dist_loss: 0.5252578258514404
recon_loss: 0.042789310216903687, dist_loss: 0.9744046926498413
recon_loss: 0.04278885945677757, dist_loss: 0.8959933519363403
recon_loss: 0.04278847947716713, dist_loss: 0.4715081453323364
recon_loss: 0.04278796538710594, dist_loss: 0.4948367178440094
recon_loss: 0.042787350714206696, dist_loss: 0.4880262315273285
recon_loss: 0.04278678074479103, dist_loss: 0.8628430962562561
recon_loss: 0.04278618097305298, dist_loss: 0.5766608715057373
recon_loss: 0.042785611003637314, dist_loss: 0.9065390825271606
recon_loss: 0.042785100638866425, dist_loss: 0.660974383354187
recon_loss: 0.04278457909822464, dist_loss: 0.7813491821289062
recon_loss: 0.042784083634614944, dist_loss: 1.215522050857544
recon_loss: 0.042783647775650024, dist_loss: 0.606903076171875
recon_loss: 0.042783141136169434, dist_loss: 0.5243092775344849
recon_loss: 0.04278276488184929, dist_loss: 1.0979442596435547
recon_loss: 0.04278215020895004, dist_loss: 0.4448350965976715
recon_loss: 0.04278155788779259, dist_loss: 0.916841447353363
recon_loss: 0.04278099909424782, dist_loss: 0.3176772892475128
recon_loss: 0.04278046637773514, dist_loss: 0.45645976066589355
recon_loss: 0.042780034244060516, dist_loss: 0.6356619596481323
recon_loss: 0.042779579758644104, dist_loss: 0.511897087097168
recon_loss: 0.042779166251420975, dist_loss: 0.48007315397262573
recon_loss: 0.042778726667165756, dist_loss: 0.8434914350509644
recon_loss: 0.042778268456459045, dist_loss: 0.5152950286865234
recon_loss: 0.04277779161930084, dist_loss: 0.8100217580795288
recon_loss: 0.04277719557285309, dist_loss: 1.4430526494979858
recon_loss: 0.04277675971388817, dist_loss: 0.5972305536270142
recon_loss: 0.04277617111802101, dist_loss: 0.6738710403442383
recon_loss: 0.042775459587574005, dist_loss: 1.3988364934921265
recon_loss: 0.042774748057127, dist_loss: 1.0486156940460205
recon_loss: 0.04277373105287552, dist_loss: 0.6801334619522095
recon_loss: 0.04277277737855911, dist_loss: 0.7919503450393677
recon_loss: 0.04277169331908226, dist_loss: 0.5291932225227356
recon_loss: 0.04277053475379944, dist_loss: 0.7900843620300293
recon_loss: 0.04276932030916214, dist_loss: 0.7793238162994385
recon_loss: 0.04276810958981514, dist_loss: 0.6062020659446716
recon_loss: 0.042766887694597244, dist_loss: 0.42842164635658264
recon_loss: 0.04276568815112114, dist_loss: 0.5698168277740479
recon_loss: 0.042764533311128616, dist_loss: 0.6669062376022339
recon_loss: 0.04276328533887863, dist_loss: 1.8603591918945312
recon_loss: 0.04276210442185402, dist_loss: 0.6712818145751953
recon_loss: 0.04276105761528015, dist_loss: 0.6882832646369934
recon_loss: 0.04276001825928688, dist_loss: 1.0161104202270508
recon_loss: 0.042759038507938385, dist_loss: 0.8238193988800049
recon_loss: 0.04275820031762123, dist_loss: 0.6859448552131653
recon_loss: 0.04275742173194885, dist_loss: 0.3524167835712433
recon_loss: 0.04275671765208244, dist_loss: 0.5628013610839844
recon_loss: 0.04275600612163544, dist_loss: 1.1537935733795166
recon_loss: 0.042755354195833206, dist_loss: 0.4546085596084595
recon_loss: 0.042754799127578735, dist_loss: 0.5594509243965149
recon_loss: 0.04275422543287277, dist_loss: 0.4753352403640747
recon_loss: 0.0427536740899086, dist_loss: 0.9861575365066528
recon_loss: 0.04275309666991234, dist_loss: 0.6026047468185425
recon_loss: 0.04275243356823921, dist_loss: 0.44721880555152893
recon_loss: 0.04275178164243698, dist_loss: 0.5550857186317444
recon_loss: 0.04275112971663475, dist_loss: 0.7968188524246216
recon_loss: 0.04275039583444595, dist_loss: 0.3338510990142822
recon_loss: 0.04274969547986984, dist_loss: 0.9827759861946106
recon_loss: 0.042749036103487015, dist_loss: 0.9080681800842285
recon_loss: 0.042748644948005676, dist_loss: 0.5899472236633301
recon_loss: 0.042748261243104935, dist_loss: 0.6777552366256714
recon_loss: 0.042747803032398224, dist_loss: 0.9740283489227295
recon_loss: 0.04274730384349823, dist_loss: 0.6745889186859131
recon_loss: 0.042746830731630325, dist_loss: 0.64890456199646
recon_loss: 0.04274633899331093, dist_loss: 0.8696991801261902
recon_loss: 0.04274573549628258, dist_loss: 0.7841833233833313
recon_loss: 0.04274505376815796, dist_loss: 0.47272711992263794
recon_loss: 0.04274441674351692, dist_loss: 0.7367253303527832
recon_loss: 0.04274372756481171, dist_loss: 0.798721969127655
recon_loss: 0.04274315387010574, dist_loss: 0.7872868776321411
recon_loss: 0.04274258762598038, dist_loss: 0.5135597586631775
recon_loss: 0.042741939425468445, dist_loss: 0.7877769470214844
recon_loss: 0.04274122044444084, dist_loss: 0.564153254032135
recon_loss: 0.04274066537618637, dist_loss: 0.5395938158035278
recon_loss: 0.04274018853902817, dist_loss: 0.507738471031189
recon_loss: 0.04273959621787071, dist_loss: 0.5083115696907043
recon_loss: 0.042739007622003555, dist_loss: 0.6278255581855774
recon_loss: 0.042738497257232666, dist_loss: 0.5381828546524048
recon_loss: 0.04273802414536476, dist_loss: 0.86094731092453
recon_loss: 0.042737603187561035, dist_loss: 0.7738707661628723
recon_loss: 0.04273690655827522, dist_loss: 0.8653118014335632
recon_loss: 0.042736075818538666, dist_loss: 0.49722763895988464
recon_loss: 0.04273545369505882, dist_loss: 0.31285184621810913
recon_loss: 0.042734842747449875, dist_loss: 1.0513286590576172
recon_loss: 0.042734112590551376, dist_loss: 0.6112452745437622
recon_loss: 0.04273344576358795, dist_loss: 0.6981290578842163
recon_loss: 0.042732831090688705, dist_loss: 0.603736162185669
recon_loss: 0.04273219406604767, dist_loss: 0.9082915186882019
recon_loss: 0.042731527239084244, dist_loss: 0.6935092210769653
recon_loss: 0.04273083060979843, dist_loss: 1.3894286155700684
recon_loss: 0.042730119079351425, dist_loss: 1.0275540351867676
recon_loss: 0.04272943362593651, dist_loss: 0.9250863790512085
recon_loss: 0.04272884130477905, dist_loss: 0.5068631172180176
recon_loss: 0.04272839054465294, dist_loss: 0.794924259185791
recon_loss: 0.0427277497947216, dist_loss: 0.7075110673904419
recon_loss: 0.04272710531949997, dist_loss: 0.4413297772407532
recon_loss: 0.042726363986730576, dist_loss: 1.0779439210891724
recon_loss: 0.042725663632154465, dist_loss: 0.5559521913528442
recon_loss: 0.042725007981061935, dist_loss: 0.531705379486084
recon_loss: 0.04272448644042015, dist_loss: 0.5041524171829224
recon_loss: 0.04272392392158508, dist_loss: 0.8533992767333984
recon_loss: 0.04272352531552315, dist_loss: 0.46667033433914185
recon_loss: 0.04272299259901047, dist_loss: 0.8518093824386597
recon_loss: 0.0427224338054657, dist_loss: 0.408494234085083
recon_loss: 0.04272181913256645, dist_loss: 0.39842528104782104
Pre-training Epoch 9:  38%|███▊      | 140/367 [00:00<00:01, 158.00it/s]Pre-training Epoch 9:  43%|████▎     | 156/367 [00:00<00:01, 157.91it/s]Pre-training Epoch 9:  47%|████▋     | 172/367 [00:01<00:01, 157.02it/s]Pre-training Epoch 9:  51%|█████     | 188/367 [00:01<00:01, 153.87it/s]Pre-training Epoch 9:  56%|█████▌    | 206/367 [00:01<00:01, 160.91it/s]Pre-training Epoch 9:  61%|██████    | 224/367 [00:01<00:00, 165.70it/s]Pre-training Epoch 9:  66%|██████▌   | 242/367 [00:01<00:00, 168.22it/s]recon_loss: 0.04272114485502243, dist_loss: 0.8927346467971802
recon_loss: 0.042720358818769455, dist_loss: 0.5479429960250854
recon_loss: 0.0427195280790329, dist_loss: 0.8520959615707397
recon_loss: 0.04271848499774933, dist_loss: 0.48215344548225403
recon_loss: 0.04271744191646576, dist_loss: 1.4125449657440186
recon_loss: 0.0427163764834404, dist_loss: 0.8313162922859192
recon_loss: 0.04271530359983444, dist_loss: 0.27740857005119324
recon_loss: 0.04271427541971207, dist_loss: 0.8554185628890991
recon_loss: 0.04271309822797775, dist_loss: 0.45703616738319397
recon_loss: 0.04271211102604866, dist_loss: 0.5386732816696167
recon_loss: 0.04271114990115166, dist_loss: 0.9283279180526733
recon_loss: 0.04271017014980316, dist_loss: 0.9206602573394775
recon_loss: 0.042709145694971085, dist_loss: 0.3826274275779724
recon_loss: 0.04270821437239647, dist_loss: 0.7893015742301941
recon_loss: 0.042707327753305435, dist_loss: 0.5592767000198364
recon_loss: 0.042706508189439774, dist_loss: 0.6201491355895996
recon_loss: 0.04270578920841217, dist_loss: 0.4928298592567444
recon_loss: 0.04270508140325546, dist_loss: 0.5813168883323669
recon_loss: 0.04270445555448532, dist_loss: 0.5604183077812195
recon_loss: 0.042703740298748016, dist_loss: 0.7019636631011963
recon_loss: 0.042703185230493546, dist_loss: 0.9467196464538574
recon_loss: 0.04270247742533684, dist_loss: 1.0697309970855713
recon_loss: 0.04270181432366371, dist_loss: 0.6131632328033447
recon_loss: 0.042701199650764465, dist_loss: 0.4605005979537964
recon_loss: 0.04270050302147865, dist_loss: 0.3969777822494507
recon_loss: 0.04269983246922493, dist_loss: 0.6863168478012085
recon_loss: 0.042699068784713745, dist_loss: 0.7029826641082764
recon_loss: 0.04269847646355629, dist_loss: 0.6285655498504639
recon_loss: 0.042697858065366745, dist_loss: 0.9063727259635925
recon_loss: 0.042697254568338394, dist_loss: 1.124549150466919
recon_loss: 0.042696502059698105, dist_loss: 1.6290212869644165
recon_loss: 0.0426957793533802, dist_loss: 0.603840708732605
recon_loss: 0.04269503429532051, dist_loss: 0.8256891965866089
recon_loss: 0.042694341391325, dist_loss: 0.9852438569068909
recon_loss: 0.04269353672862053, dist_loss: 0.5657039880752563
recon_loss: 0.04269272834062576, dist_loss: 0.5647784471511841
recon_loss: 0.04269188269972801, dist_loss: 0.9210424423217773
recon_loss: 0.04269105941057205, dist_loss: 0.6164922714233398
recon_loss: 0.04269024729728699, dist_loss: 0.7035501599311829
recon_loss: 0.042689476162195206, dist_loss: 0.5756025314331055
recon_loss: 0.04268877953290939, dist_loss: 0.5019993782043457
recon_loss: 0.04268811643123627, dist_loss: 0.5017133355140686
recon_loss: 0.04268743842840195, dist_loss: 0.3978651762008667
recon_loss: 0.04268692433834076, dist_loss: 0.608046293258667
recon_loss: 0.04268637299537659, dist_loss: 0.5091870427131653
recon_loss: 0.042685750871896744, dist_loss: 0.554783046245575
recon_loss: 0.0426851324737072, dist_loss: 0.6369397640228271
recon_loss: 0.042684733867645264, dist_loss: 0.28837764263153076
recon_loss: 0.0426844097673893, dist_loss: 0.6893205642700195
recon_loss: 0.042684156447649, dist_loss: 1.0585583448410034
recon_loss: 0.04268382117152214, dist_loss: 0.8250908255577087
recon_loss: 0.042683303356170654, dist_loss: 0.6750866174697876
recon_loss: 0.04268280044198036, dist_loss: 0.42101430892944336
recon_loss: 0.042682208120822906, dist_loss: 0.5291855335235596
recon_loss: 0.042681723833084106, dist_loss: 0.7585554122924805
recon_loss: 0.04268136993050575, dist_loss: 0.7889527082443237
recon_loss: 0.04268103092908859, dist_loss: 0.4398747682571411
recon_loss: 0.042680662125349045, dist_loss: 0.5393351912498474
recon_loss: 0.042680270969867706, dist_loss: 0.9901688694953918
recon_loss: 0.04267987236380577, dist_loss: 0.8361161947250366
recon_loss: 0.04267945885658264, dist_loss: 1.1211802959442139
recon_loss: 0.04267901927232742, dist_loss: 0.9082334637641907
recon_loss: 0.04267842695116997, dist_loss: 0.30490174889564514
recon_loss: 0.042677849531173706, dist_loss: 1.0546884536743164
recon_loss: 0.04267719015479088, dist_loss: 1.1656639575958252
recon_loss: 0.04267645627260208, dist_loss: 0.7963685393333435
recon_loss: 0.042675942182540894, dist_loss: 0.5964699983596802
recon_loss: 0.042675428092479706, dist_loss: 0.755460262298584
recon_loss: 0.04267481714487076, dist_loss: 0.4333076477050781
recon_loss: 0.04267432913184166, dist_loss: 0.48606646060943604
recon_loss: 0.04267372190952301, dist_loss: 0.6965672373771667
recon_loss: 0.04267307370901108, dist_loss: 0.6136917471885681
recon_loss: 0.04267257824540138, dist_loss: 0.9220300912857056
recon_loss: 0.04267206788063049, dist_loss: 0.3385242819786072
recon_loss: 0.04267160966992378, dist_loss: 0.4988110363483429
recon_loss: 0.042671218514442444, dist_loss: 0.5698344707489014
recon_loss: 0.04267081245779991, dist_loss: 0.7247933745384216
recon_loss: 0.04267033562064171, dist_loss: 0.8641422390937805
recon_loss: 0.042669620364904404, dist_loss: 1.244667410850525
recon_loss: 0.04266885668039322, dist_loss: 0.6262747645378113
recon_loss: 0.04266798868775368, dist_loss: 0.7167714834213257
recon_loss: 0.0426672026515007, dist_loss: 1.096524953842163
recon_loss: 0.04266650974750519, dist_loss: 0.9787724614143372
recon_loss: 0.042665936052799225, dist_loss: 0.8925033807754517
recon_loss: 0.042665328830480576, dist_loss: 0.8690709471702576
recon_loss: 0.04266460984945297, dist_loss: 0.8037903904914856
recon_loss: 0.04266398772597313, dist_loss: 0.40166470408439636
recon_loss: 0.04266347363591194, dist_loss: 0.8266977667808533
recon_loss: 0.042662881314754486, dist_loss: 0.8285928964614868
recon_loss: 0.04266222566366196, dist_loss: 0.6032109260559082
recon_loss: 0.04266158863902092, dist_loss: 0.8028383255004883
recon_loss: 0.04266105964779854, dist_loss: 0.42712846398353577
recon_loss: 0.04266046732664108, dist_loss: 0.8982102274894714
recon_loss: 0.042659979313611984, dist_loss: 0.5002989768981934
recon_loss: 0.04265950620174408, dist_loss: 0.9023306369781494
recon_loss: 0.042658910155296326, dist_loss: 0.35691556334495544
recon_loss: 0.042658232152462006, dist_loss: 0.5587823390960693
recon_loss: 0.04265761747956276, dist_loss: 0.745909571647644
recon_loss: 0.04265701770782471, dist_loss: 1.08704674243927
recon_loss: 0.04265622794628143, dist_loss: 0.7415995597839355
recon_loss: 0.04265548661351204, dist_loss: 0.8648304343223572
recon_loss: 0.04265480116009712, dist_loss: 0.7387325763702393
recon_loss: 0.04265429824590683, dist_loss: 0.5901416540145874
recon_loss: 0.042653780430555344, dist_loss: 0.6116307973861694
recon_loss: 0.04265329986810684, dist_loss: 1.005222201347351
recon_loss: 0.04265288636088371, dist_loss: 0.5547606945037842
recon_loss: 0.042652420699596405, dist_loss: 0.5204626321792603
recon_loss: 0.04265196993947029, dist_loss: 0.5493557453155518
recon_loss: 0.04265140742063522, dist_loss: 0.699893057346344
recon_loss: 0.042650844901800156, dist_loss: 0.786423921585083
recon_loss: 0.04265005886554718, dist_loss: 0.6375683546066284
recon_loss: 0.04264943674206734, dist_loss: 0.33731579780578613
recon_loss: 0.042648810893297195, dist_loss: 0.5892999172210693
recon_loss: 0.042648158967494965, dist_loss: 1.118443489074707
recon_loss: 0.0426473543047905, dist_loss: 0.6285784244537354
recon_loss: 0.042646508663892746, dist_loss: 0.9778633117675781
recon_loss: 0.042645413428545, dist_loss: 0.6912313103675842
recon_loss: 0.04264417663216591, dist_loss: 0.4453175663948059
recon_loss: 0.04264296963810921, dist_loss: 0.7110316753387451
recon_loss: 0.042641617357730865, dist_loss: 0.5838367938995361
recon_loss: 0.04264044016599655, dist_loss: 0.8935620784759521
recon_loss: 0.04263908788561821, dist_loss: 0.8082926273345947
recon_loss: 0.04263777285814285, dist_loss: 0.6872962713241577
recon_loss: 0.042636528611183167, dist_loss: 0.5423361659049988
recon_loss: 0.04263525456190109, dist_loss: 0.892133355140686
recon_loss: 0.0426340289413929, dist_loss: 1.0207961797714233
recon_loss: 0.04263293370604515, dist_loss: 0.6941371560096741
recon_loss: 0.0426318384706974, dist_loss: 0.5872349739074707
recon_loss: 0.04263078793883324, dist_loss: 0.47310569882392883
Pre-training Epoch 9:  71%|███████   | 259/367 [00:01<00:00, 161.98it/s]Pre-training Epoch 9:  75%|███████▌  | 276/367 [00:01<00:00, 160.55it/s]Pre-training Epoch 9:  80%|████████  | 295/367 [00:01<00:00, 166.51it/s]Pre-training Epoch 9:  86%|████████▌ | 314/367 [00:01<00:00, 170.55it/s]Pre-training Epoch 9:  90%|█████████ | 332/367 [00:02<00:00, 172.67it/s]Pre-training Epoch 9:  95%|█████████▌| 350/367 [00:02<00:00, 170.78it/s]Pre-training Epoch 9: 100%|██████████| 367/367 [00:02<00:00, 165.55it/s]
recon_loss: 0.04262978211045265, dist_loss: 0.5530045032501221
recon_loss: 0.0426289364695549, dist_loss: 0.5381166934967041
recon_loss: 0.04262808337807655, dist_loss: 0.7801231145858765
recon_loss: 0.042627181857824326, dist_loss: 0.6003293395042419
recon_loss: 0.04262635111808777, dist_loss: 0.7788232564926147
recon_loss: 0.04262540861964226, dist_loss: 1.5871241092681885
recon_loss: 0.04262436553835869, dist_loss: 1.2162535190582275
recon_loss: 0.04262338578701019, dist_loss: 0.4564228355884552
recon_loss: 0.04262238368391991, dist_loss: 0.5844082236289978
recon_loss: 0.04262133315205574, dist_loss: 0.4675482511520386
recon_loss: 0.042620304971933365, dist_loss: 0.5807418823242188
recon_loss: 0.04261940345168114, dist_loss: 0.8110288381576538
recon_loss: 0.04261845722794533, dist_loss: 0.6029457449913025
recon_loss: 0.042617570608854294, dist_loss: 0.6570630669593811
recon_loss: 0.042616695165634155, dist_loss: 0.49696460366249084
recon_loss: 0.042615924030542374, dist_loss: 0.540449321269989
recon_loss: 0.042615171521902084, dist_loss: 0.835245668888092
recon_loss: 0.04261430725455284, dist_loss: 0.5243218541145325
recon_loss: 0.042613495141267776, dist_loss: 0.7809655666351318
recon_loss: 0.0426127053797245, dist_loss: 0.8668649196624756
recon_loss: 0.042611900717020035, dist_loss: 0.8140530586242676
recon_loss: 0.04261109232902527, dist_loss: 0.9635297656059265
recon_loss: 0.04261020943522453, dist_loss: 1.082922101020813
recon_loss: 0.04260919615626335, dist_loss: 0.7377439141273499
recon_loss: 0.042608048766851425, dist_loss: 0.608160138130188
recon_loss: 0.042606987059116364, dist_loss: 0.5973848700523376
recon_loss: 0.04260595887899399, dist_loss: 0.8474678993225098
recon_loss: 0.042605072259902954, dist_loss: 0.5414767861366272
recon_loss: 0.04260420426726341, dist_loss: 0.8893382549285889
recon_loss: 0.04260330647230148, dist_loss: 0.8473888635635376
recon_loss: 0.04260250926017761, dist_loss: 0.5122610330581665
recon_loss: 0.042601749300956726, dist_loss: 0.8356672525405884
recon_loss: 0.04260101169347763, dist_loss: 0.5631129741668701
recon_loss: 0.0426003560423851, dist_loss: 0.47364258766174316
recon_loss: 0.04259980097413063, dist_loss: 0.5850962400436401
recon_loss: 0.04259931296110153, dist_loss: 0.42936551570892334
recon_loss: 0.042598873376846313, dist_loss: 0.8105337619781494
recon_loss: 0.042598601430654526, dist_loss: 0.9491027593612671
recon_loss: 0.04259825125336647, dist_loss: 0.6811304688453674
recon_loss: 0.042597923427820206, dist_loss: 0.6741647124290466
recon_loss: 0.04259767755866051, dist_loss: 0.6899956464767456
recon_loss: 0.04259757325053215, dist_loss: 0.6902185678482056
recon_loss: 0.042597606778144836, dist_loss: 0.45993509888648987
recon_loss: 0.04259764775633812, dist_loss: 0.33642062544822693
recon_loss: 0.04259762540459633, dist_loss: 0.6599941253662109
recon_loss: 0.04259749874472618, dist_loss: 0.7226375937461853
recon_loss: 0.04259718582034111, dist_loss: 0.889339804649353
recon_loss: 0.04259658232331276, dist_loss: 1.2447588443756104
recon_loss: 0.042596060782670975, dist_loss: 0.6503318548202515
recon_loss: 0.042595457285642624, dist_loss: 0.5505957007408142
recon_loss: 0.04259488731622696, dist_loss: 0.5676668286323547
recon_loss: 0.042594294995069504, dist_loss: 0.8898588418960571
recon_loss: 0.04259373992681503, dist_loss: 0.7543686628341675
recon_loss: 0.042593248188495636, dist_loss: 0.5474122762680054
recon_loss: 0.04259275645017624, dist_loss: 0.7609849572181702
recon_loss: 0.042592115700244904, dist_loss: 0.5928823351860046
recon_loss: 0.04259147495031357, dist_loss: 0.7454870939254761
recon_loss: 0.042590752243995667, dist_loss: 0.7098134756088257
recon_loss: 0.04259018227458, dist_loss: 0.8524539470672607
recon_loss: 0.04258931428194046, dist_loss: 0.4533860683441162
recon_loss: 0.04258854314684868, dist_loss: 0.8012475967407227
recon_loss: 0.042587872594594955, dist_loss: 0.6571439504623413
recon_loss: 0.042587313801050186, dist_loss: 0.7058252096176147
recon_loss: 0.04258675128221512, dist_loss: 0.8546971678733826
recon_loss: 0.04258633404970169, dist_loss: 0.5396444201469421
recon_loss: 0.042585887014865875, dist_loss: 0.9297161102294922
recon_loss: 0.04258532077074051, dist_loss: 0.8002238273620605
recon_loss: 0.04258483275771141, dist_loss: 0.725799560546875
recon_loss: 0.04258445277810097, dist_loss: 0.47526562213897705
recon_loss: 0.042583927512168884, dist_loss: 0.650646448135376
recon_loss: 0.04258351773023605, dist_loss: 0.5945730209350586
recon_loss: 0.04258298873901367, dist_loss: 0.4775654673576355
recon_loss: 0.04258232191205025, dist_loss: 0.5608025789260864
recon_loss: 0.04258152097463608, dist_loss: 0.35729503631591797
recon_loss: 0.042580679059028625, dist_loss: 0.4308009743690491
recon_loss: 0.04257981479167938, dist_loss: 0.6854637265205383
recon_loss: 0.04257893189787865, dist_loss: 0.6436277627944946
recon_loss: 0.042577970772981644, dist_loss: 0.7996900081634521
recon_loss: 0.04257698729634285, dist_loss: 0.724708080291748
recon_loss: 0.04257594048976898, dist_loss: 1.003859519958496
recon_loss: 0.04257490858435631, dist_loss: 0.9934738874435425
recon_loss: 0.0425739660859108, dist_loss: 0.6383156776428223
recon_loss: 0.04257304593920708, dist_loss: 0.59187251329422
recon_loss: 0.042572129517793655, dist_loss: 0.5735048055648804
recon_loss: 0.04257120192050934, dist_loss: 0.8056426048278809
recon_loss: 0.04256996884942055, dist_loss: 0.7287442088127136
recon_loss: 0.042568691074848175, dist_loss: 1.234320044517517
recon_loss: 0.04256753623485565, dist_loss: 0.5917345881462097
recon_loss: 0.04256640747189522, dist_loss: 0.6761282682418823
recon_loss: 0.042565397918224335, dist_loss: 0.5084867477416992
recon_loss: 0.04256456717848778, dist_loss: 0.5484597682952881
recon_loss: 0.042563654482364655, dist_loss: 0.6475405693054199
recon_loss: 0.042562615126371384, dist_loss: 0.4749657213687897
recon_loss: 0.042561523616313934, dist_loss: 0.3910830616950989
recon_loss: 0.042560625821352005, dist_loss: 0.4563937485218048
recon_loss: 0.04255981370806694, dist_loss: 0.45686614513397217
recon_loss: 0.042559005320072174, dist_loss: 1.0448683500289917
recon_loss: 0.04255833849310875, dist_loss: 0.9970719814300537
recon_loss: 0.04255767539143562, dist_loss: 0.7745983600616455
recon_loss: 0.04255702719092369, dist_loss: 0.5985742807388306
recon_loss: 0.042556315660476685, dist_loss: 0.8641902208328247
recon_loss: 0.042555611580610275, dist_loss: 0.47745364904403687
recon_loss: 0.04255485162138939, dist_loss: 0.7995041012763977
recon_loss: 0.04255395755171776, dist_loss: 0.651569664478302
recon_loss: 0.04255308583378792, dist_loss: 0.2581665813922882
recon_loss: 0.042552243918180466, dist_loss: 1.2644753456115723
recon_loss: 0.042551279067993164, dist_loss: 0.44602954387664795
recon_loss: 0.04255043715238571, dist_loss: 0.5048812627792358
recon_loss: 0.042549602687358856, dist_loss: 0.977133572101593
Pre-training Epoch 10:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 10:   4%|▍         | 16/367 [00:00<00:02, 158.84it/s]Pre-training Epoch 10:   9%|▉         | 33/367 [00:00<00:02, 162.66it/s]Pre-training Epoch 10:  14%|█▎        | 50/367 [00:00<00:01, 163.93it/s]Pre-training Epoch 10:  18%|█▊        | 67/367 [00:00<00:01, 164.58it/s]Pre-training Epoch 10:  23%|██▎       | 84/367 [00:00<00:01, 164.61it/s]Pre-training Epoch 10:  28%|██▊       | 101/367 [00:00<00:01, 164.82it/s]Pre-training Epoch 10:  32%|███▏      | 118/367 [00:00<00:01, 158.47it/s]recon_loss: 0.04254879429936409, dist_loss: 0.6028194427490234
recon_loss: 0.04254801571369171, dist_loss: 1.027099609375
recon_loss: 0.04254714027047157, dist_loss: 0.7119638323783875
recon_loss: 0.042546287178993225, dist_loss: 0.8822911977767944
recon_loss: 0.04254546016454697, dist_loss: 0.42542290687561035
recon_loss: 0.04254452884197235, dist_loss: 0.30415773391723633
recon_loss: 0.042543571442365646, dist_loss: 0.9474228024482727
recon_loss: 0.042542729526758194, dist_loss: 0.7464501857757568
recon_loss: 0.04254189878702164, dist_loss: 0.8356569409370422
recon_loss: 0.042541101574897766, dist_loss: 0.6634454727172852
recon_loss: 0.04254049062728882, dist_loss: 0.9190018773078918
recon_loss: 0.042539894580841064, dist_loss: 0.7830631732940674
recon_loss: 0.04253927245736122, dist_loss: 0.9112380743026733
recon_loss: 0.04253864660859108, dist_loss: 0.8821411728858948
recon_loss: 0.04253802448511124, dist_loss: 0.5379989147186279
recon_loss: 0.04253743216395378, dist_loss: 0.8657311201095581
recon_loss: 0.04253680258989334, dist_loss: 0.8461064100265503
recon_loss: 0.04253612086176872, dist_loss: 0.7500286102294922
recon_loss: 0.04253534972667694, dist_loss: 0.38230079412460327
recon_loss: 0.042534537613391876, dist_loss: 1.0936098098754883
recon_loss: 0.04253378137946129, dist_loss: 0.6605642437934875
recon_loss: 0.042533040046691895, dist_loss: 0.5443323254585266
recon_loss: 0.04253226891160011, dist_loss: 1.088167428970337
recon_loss: 0.04253150522708893, dist_loss: 0.9567778706550598
recon_loss: 0.04253063350915909, dist_loss: 0.8017187118530273
recon_loss: 0.04252983257174492, dist_loss: 0.7898836135864258
recon_loss: 0.042528826743364334, dist_loss: 0.869996964931488
recon_loss: 0.042527779936790466, dist_loss: 0.8343179821968079
recon_loss: 0.0425267331302166, dist_loss: 0.5824875831604004
recon_loss: 0.04252573847770691, dist_loss: 0.588654637336731
recon_loss: 0.0425247997045517, dist_loss: 0.438399076461792
recon_loss: 0.04252390190958977, dist_loss: 0.8767238855361938
recon_loss: 0.042523086071014404, dist_loss: 1.170229434967041
recon_loss: 0.04252221807837486, dist_loss: 0.41104793548583984
recon_loss: 0.04252145439386368, dist_loss: 0.5199047327041626
recon_loss: 0.04252077639102936, dist_loss: 0.4311552345752716
recon_loss: 0.042520131915807724, dist_loss: 0.5122606158256531
recon_loss: 0.042519569396972656, dist_loss: 0.7253471612930298
recon_loss: 0.04251900687813759, dist_loss: 0.5449123382568359
recon_loss: 0.042518407106399536, dist_loss: 0.8619726896286011
recon_loss: 0.042517729103565216, dist_loss: 0.41864776611328125
recon_loss: 0.04251708462834358, dist_loss: 0.915013313293457
recon_loss: 0.042516279965639114, dist_loss: 0.8987047672271729
recon_loss: 0.042515456676483154, dist_loss: 0.7576700448989868
recon_loss: 0.0425146222114563, dist_loss: 0.6044840812683105
recon_loss: 0.0425138883292675, dist_loss: 0.7347664833068848
recon_loss: 0.04251313582062721, dist_loss: 0.5381982326507568
recon_loss: 0.042512405663728714, dist_loss: 1.3294304609298706
recon_loss: 0.04251161590218544, dist_loss: 1.0268714427947998
recon_loss: 0.042510662227869034, dist_loss: 0.43358325958251953
recon_loss: 0.04250972718000412, dist_loss: 0.9806056022644043
recon_loss: 0.0425088107585907, dist_loss: 0.8453130125999451
recon_loss: 0.04250770062208176, dist_loss: 1.225762128829956
recon_loss: 0.04250654950737953, dist_loss: 0.5583296418190002
recon_loss: 0.04250558465719223, dist_loss: 0.6661731600761414
recon_loss: 0.04250461980700493, dist_loss: 1.0507938861846924
recon_loss: 0.04250350594520569, dist_loss: 0.7446696758270264
recon_loss: 0.04250242933630943, dist_loss: 0.680410623550415
recon_loss: 0.04250151664018631, dist_loss: 0.47361743450164795
recon_loss: 0.042500682175159454, dist_loss: 0.49616047739982605
recon_loss: 0.042499788105487823, dist_loss: 0.6942738890647888
recon_loss: 0.042498987168073654, dist_loss: 0.5168198943138123
recon_loss: 0.04249820113182068, dist_loss: 0.4215412139892578
recon_loss: 0.042497213929891586, dist_loss: 0.6768948435783386
recon_loss: 0.0424962155520916, dist_loss: 0.4622300863265991
recon_loss: 0.04249527305364609, dist_loss: 0.6351416110992432
recon_loss: 0.04249434173107147, dist_loss: 0.6055703163146973
recon_loss: 0.042493466287851334, dist_loss: 0.2566116452217102
recon_loss: 0.04249263554811478, dist_loss: 0.40647685527801514
recon_loss: 0.0424918606877327, dist_loss: 0.9507871270179749
recon_loss: 0.04249129071831703, dist_loss: 0.6355791091918945
recon_loss: 0.04249062016606331, dist_loss: 0.6247353553771973
recon_loss: 0.04248976334929466, dist_loss: 0.9570369124412537
recon_loss: 0.0424891896545887, dist_loss: 0.3961499333381653
recon_loss: 0.04248860478401184, dist_loss: 0.6848094463348389
recon_loss: 0.04248800128698349, dist_loss: 0.3976648449897766
recon_loss: 0.042487386614084244, dist_loss: 0.6330167055130005
recon_loss: 0.04248682036995888, dist_loss: 0.48486536741256714
recon_loss: 0.04248626157641411, dist_loss: 0.3605794608592987
recon_loss: 0.042485810816287994, dist_loss: 0.8525829315185547
recon_loss: 0.04248526319861412, dist_loss: 0.5776020884513855
recon_loss: 0.04248480871319771, dist_loss: 0.6380171775817871
recon_loss: 0.04248429089784622, dist_loss: 0.7003231048583984
recon_loss: 0.04248369112610817, dist_loss: 0.49326157569885254
recon_loss: 0.042483046650886536, dist_loss: 0.854922890663147
recon_loss: 0.04248218983411789, dist_loss: 0.5437129735946655
recon_loss: 0.04248138889670372, dist_loss: 0.6427890062332153
recon_loss: 0.04248083382844925, dist_loss: 0.9408152103424072
recon_loss: 0.042480070143938065, dist_loss: 0.6536799669265747
recon_loss: 0.04247935488820076, dist_loss: 0.5533632040023804
recon_loss: 0.042478714138269424, dist_loss: 0.82780522108078
recon_loss: 0.04247816279530525, dist_loss: 0.2630038857460022
recon_loss: 0.04247763380408287, dist_loss: 0.536683201789856
recon_loss: 0.0424768403172493, dist_loss: 0.7603500485420227
recon_loss: 0.042476169764995575, dist_loss: 0.6519752740859985
recon_loss: 0.0424753874540329, dist_loss: 0.7836201190948486
recon_loss: 0.04247470572590828, dist_loss: 0.755833089351654
recon_loss: 0.042473867535591125, dist_loss: 0.7855164408683777
recon_loss: 0.04247300326824188, dist_loss: 0.7218948602676392
recon_loss: 0.042472198605537415, dist_loss: 0.5970572233200073
recon_loss: 0.04247147589921951, dist_loss: 0.5817857980728149
recon_loss: 0.04247089847922325, dist_loss: 0.7203609943389893
recon_loss: 0.04247039556503296, dist_loss: 0.8801403045654297
recon_loss: 0.042469996958971024, dist_loss: 0.9153043627738953
recon_loss: 0.04246949404478073, dist_loss: 0.6449455618858337
recon_loss: 0.04246901348233223, dist_loss: 0.529843807220459
recon_loss: 0.04246816784143448, dist_loss: 0.6081928610801697
recon_loss: 0.04246724396944046, dist_loss: 0.744408369064331
recon_loss: 0.04246633127331734, dist_loss: 1.1615569591522217
recon_loss: 0.04246552661061287, dist_loss: 0.48132213950157166
recon_loss: 0.0424647256731987, dist_loss: 0.8275047540664673
recon_loss: 0.04246390238404274, dist_loss: 0.8587350249290466
recon_loss: 0.04246286675333977, dist_loss: 0.3193281292915344
recon_loss: 0.04246184602379799, dist_loss: 0.7371751070022583
recon_loss: 0.042460847645998, dist_loss: 0.9255114793777466
recon_loss: 0.04245996102690697, dist_loss: 0.7252188920974731
recon_loss: 0.04245923459529877, dist_loss: 0.7957262992858887
recon_loss: 0.04245840013027191, dist_loss: 0.5840315818786621
recon_loss: 0.04245774447917938, dist_loss: 0.6864979267120361
recon_loss: 0.0424569696187973, dist_loss: 0.39760643243789673
recon_loss: 0.042456284165382385, dist_loss: 0.9794739484786987
recon_loss: 0.04245549440383911, dist_loss: 0.8239758014678955
recon_loss: 0.04245448857545853, dist_loss: 0.7210358381271362
recon_loss: 0.04245299845933914, dist_loss: 0.7902405261993408
recon_loss: 0.04245150834321976, dist_loss: 0.501856803894043
recon_loss: 0.042450129985809326, dist_loss: 1.1231632232666016
recon_loss: 0.04244883731007576, dist_loss: 0.6239000558853149
recon_loss: 0.04244765266776085, dist_loss: 0.7054970264434814
recon_loss: 0.0424463264644146, dist_loss: 0.458413302898407
Pre-training Epoch 10:  37%|███▋      | 134/367 [00:00<00:01, 156.96it/s]Pre-training Epoch 10:  41%|████      | 150/367 [00:00<00:01, 156.09it/s]Pre-training Epoch 10:  45%|████▌     | 166/367 [00:01<00:01, 154.66it/s]Pre-training Epoch 10:  50%|████▉     | 182/367 [00:01<00:01, 155.07it/s]Pre-training Epoch 10:  54%|█████▍    | 198/367 [00:01<00:01, 155.22it/s]Pre-training Epoch 10:  58%|█████▊    | 214/367 [00:01<00:00, 155.80it/s]Pre-training Epoch 10:  63%|██████▎   | 230/367 [00:01<00:00, 156.44it/s]Pre-training Epoch 10:  67%|██████▋   | 246/367 [00:01<00:00, 156.06it/s]recon_loss: 0.042445048689842224, dist_loss: 0.8923844695091248
recon_loss: 0.04244396835565567, dist_loss: 0.9249165058135986
recon_loss: 0.04244289547204971, dist_loss: 0.6357240676879883
recon_loss: 0.04244199022650719, dist_loss: 0.8834748268127441
recon_loss: 0.042441077530384064, dist_loss: 0.615594208240509
recon_loss: 0.04244033619761467, dist_loss: 0.5351558923721313
recon_loss: 0.04243967682123184, dist_loss: 1.1196879148483276
recon_loss: 0.04243886470794678, dist_loss: 0.6742475032806396
recon_loss: 0.042438190430402756, dist_loss: 0.7457591891288757
recon_loss: 0.042437292635440826, dist_loss: 0.7038947343826294
recon_loss: 0.04243643954396248, dist_loss: 0.8438141345977783
recon_loss: 0.04243568331003189, dist_loss: 0.6725668907165527
recon_loss: 0.042434994131326675, dist_loss: 0.3941541016101837
recon_loss: 0.042434293776750565, dist_loss: 0.4946240186691284
recon_loss: 0.042433518916368484, dist_loss: 0.7326335906982422
recon_loss: 0.04243270680308342, dist_loss: 0.7811723947525024
recon_loss: 0.04243190586566925, dist_loss: 1.1418334245681763
recon_loss: 0.04243107885122299, dist_loss: 0.6097543239593506
recon_loss: 0.04243038594722748, dist_loss: 0.49783122539520264
recon_loss: 0.042429521679878235, dist_loss: 0.6649268865585327
recon_loss: 0.04242875054478645, dist_loss: 0.44957196712493896
recon_loss: 0.04242806136608124, dist_loss: 0.6716907024383545
recon_loss: 0.04242755472660065, dist_loss: 0.6486756801605225
recon_loss: 0.04242700710892677, dist_loss: 0.9216622710227966
recon_loss: 0.04242630675435066, dist_loss: 0.7015395760536194
recon_loss: 0.04242551699280739, dist_loss: 0.6215801239013672
recon_loss: 0.04242483898997307, dist_loss: 0.7021769285202026
recon_loss: 0.04242430627346039, dist_loss: 0.5439964532852173
recon_loss: 0.04242372885346413, dist_loss: 0.6980714797973633
recon_loss: 0.04242303594946861, dist_loss: 0.7437132596969604
recon_loss: 0.04242229834198952, dist_loss: 0.6100178956985474
recon_loss: 0.04242147132754326, dist_loss: 0.7378836870193481
recon_loss: 0.04242071136832237, dist_loss: 1.0664401054382324
recon_loss: 0.042419806122779846, dist_loss: 0.6714615821838379
recon_loss: 0.04241878166794777, dist_loss: 0.5640019774436951
recon_loss: 0.04241776838898659, dist_loss: 0.5235534310340881
recon_loss: 0.04241667315363884, dist_loss: 1.0229941606521606
recon_loss: 0.04241570457816124, dist_loss: 1.0774555206298828
recon_loss: 0.04241471365094185, dist_loss: 0.5956539511680603
recon_loss: 0.04241357743740082, dist_loss: 0.5843282341957092
recon_loss: 0.0424124076962471, dist_loss: 0.6224247813224792
recon_loss: 0.04241129010915756, dist_loss: 0.5976581573486328
recon_loss: 0.04241029918193817, dist_loss: 0.44665175676345825
recon_loss: 0.04240936040878296, dist_loss: 0.693182647228241
recon_loss: 0.04240838810801506, dist_loss: 0.5909796357154846
recon_loss: 0.04240759089589119, dist_loss: 0.9083292484283447
recon_loss: 0.04240673780441284, dist_loss: 0.748505175113678
recon_loss: 0.04240588843822479, dist_loss: 0.6010164618492126
recon_loss: 0.04240504279732704, dist_loss: 1.2765284776687622
recon_loss: 0.04240433871746063, dist_loss: 0.916808009147644
recon_loss: 0.04240383952856064, dist_loss: 0.5277547240257263
recon_loss: 0.04240339994430542, dist_loss: 1.6218210458755493
recon_loss: 0.04240257665514946, dist_loss: 0.917096734046936
recon_loss: 0.0424019955098629, dist_loss: 0.5149019956588745
recon_loss: 0.04240135848522186, dist_loss: 1.3198106288909912
recon_loss: 0.04240058362483978, dist_loss: 0.4673056900501251
recon_loss: 0.042399812489748, dist_loss: 0.6225601434707642
recon_loss: 0.04239887371659279, dist_loss: 0.4108038544654846
recon_loss: 0.04239806532859802, dist_loss: 0.6979871392250061
recon_loss: 0.04239727929234505, dist_loss: 0.4846920371055603
recon_loss: 0.0423966683447361, dist_loss: 0.564724862575531
recon_loss: 0.04239613190293312, dist_loss: 0.6801401376724243
recon_loss: 0.04239557310938835, dist_loss: 0.6957453489303589
recon_loss: 0.042394619435071945, dist_loss: 0.5910505056381226
recon_loss: 0.04239384084939957, dist_loss: 0.6118255853652954
recon_loss: 0.04239306598901749, dist_loss: 0.47878599166870117
recon_loss: 0.04239236190915108, dist_loss: 0.8880255818367004
recon_loss: 0.04239171743392944, dist_loss: 0.5092655420303345
recon_loss: 0.042391035705804825, dist_loss: 0.8463349938392639
recon_loss: 0.04239051789045334, dist_loss: 0.857664942741394
recon_loss: 0.04239014536142349, dist_loss: 0.9451832175254822
recon_loss: 0.042389877140522, dist_loss: 0.845547616481781
recon_loss: 0.042389728128910065, dist_loss: 0.8147460222244263
recon_loss: 0.04238966479897499, dist_loss: 0.9547376036643982
recon_loss: 0.04238968715071678, dist_loss: 0.9044573903083801
recon_loss: 0.04238991066813469, dist_loss: 0.7105467319488525
recon_loss: 0.04238991066813469, dist_loss: 0.6414787769317627
recon_loss: 0.0423898808658123, dist_loss: 0.7801849246025085
recon_loss: 0.0423896424472332, dist_loss: 0.6719624400138855
recon_loss: 0.04238926246762276, dist_loss: 0.6808675527572632
recon_loss: 0.042388975620269775, dist_loss: 0.6816807985305786
recon_loss: 0.04238861799240112, dist_loss: 0.8981941938400269
recon_loss: 0.04238798841834068, dist_loss: 0.8050184845924377
recon_loss: 0.042387351393699646, dist_loss: 0.9552280902862549
recon_loss: 0.042386990040540695, dist_loss: 0.8886092901229858
recon_loss: 0.042386893182992935, dist_loss: 0.7733981609344482
recon_loss: 0.042386818677186966, dist_loss: 0.7222438454627991
recon_loss: 0.04238647595047951, dist_loss: 0.7386486530303955
recon_loss: 0.04238598793745041, dist_loss: 0.3714678883552551
recon_loss: 0.04238539934158325, dist_loss: 0.7504968643188477
recon_loss: 0.042384956032037735, dist_loss: 0.7203766107559204
recon_loss: 0.04238457232713699, dist_loss: 0.5802801847457886
recon_loss: 0.04238404706120491, dist_loss: 0.7554889917373657
recon_loss: 0.04238339886069298, dist_loss: 0.2790067195892334
recon_loss: 0.04238274693489075, dist_loss: 0.6423252820968628
recon_loss: 0.042382076382637024, dist_loss: 0.8914990425109863
recon_loss: 0.04238131642341614, dist_loss: 0.6127286553382874
recon_loss: 0.04238046333193779, dist_loss: 0.500288188457489
recon_loss: 0.042379800230264664, dist_loss: 0.6525154113769531
recon_loss: 0.04237927123904228, dist_loss: 0.520768404006958
recon_loss: 0.04237857460975647, dist_loss: 0.8020058870315552
recon_loss: 0.04237789660692215, dist_loss: 0.8524693250656128
recon_loss: 0.042377352714538574, dist_loss: 0.8131362199783325
recon_loss: 0.04237690195441246, dist_loss: 0.4055984318256378
recon_loss: 0.042376548051834106, dist_loss: 0.8271844983100891
recon_loss: 0.042376041412353516, dist_loss: 0.683582603931427
recon_loss: 0.04237537458539009, dist_loss: 0.6609553098678589
recon_loss: 0.042374879121780396, dist_loss: 0.6795341968536377
recon_loss: 0.04237432777881622, dist_loss: 0.621035099029541
recon_loss: 0.042373817414045334, dist_loss: 0.3602766692638397
recon_loss: 0.042373377829790115, dist_loss: 0.45658227801322937
recon_loss: 0.04237296059727669, dist_loss: 0.9330114126205444
recon_loss: 0.042372528463602066, dist_loss: 0.40142595767974854
recon_loss: 0.042372215539216995, dist_loss: 0.5609229207038879
recon_loss: 0.04237187281250954, dist_loss: 0.7384285926818848
recon_loss: 0.042371559888124466, dist_loss: 0.6539880037307739
recon_loss: 0.042371198534965515, dist_loss: 1.078911542892456
recon_loss: 0.042371105402708054, dist_loss: 0.39319556951522827
recon_loss: 0.0423710010945797, dist_loss: 0.4915504455566406
recon_loss: 0.04237106442451477, dist_loss: 0.7357509732246399
recon_loss: 0.04237089306116104, dist_loss: 0.8462222814559937
recon_loss: 0.04237058386206627, dist_loss: 0.48785728216171265
recon_loss: 0.04237022250890732, dist_loss: 0.9902164936065674
recon_loss: 0.04236970096826553, dist_loss: 0.6050135493278503
recon_loss: 0.042368970811367035, dist_loss: 0.4217450022697449
recon_loss: 0.042368125170469284, dist_loss: 0.5882405042648315
recon_loss: 0.04236713424324989, dist_loss: 0.7590423822402954
recon_loss: 0.042366188019514084, dist_loss: 0.550079345703125
recon_loss: 0.04236525669693947, dist_loss: 0.9093554019927979
Pre-training Epoch 10:  71%|███████▏  | 262/367 [00:01<00:00, 155.61it/s]Pre-training Epoch 10:  76%|███████▋  | 280/367 [00:01<00:00, 160.53it/s]Pre-training Epoch 10:  81%|████████  | 298/367 [00:01<00:00, 165.09it/s]Pre-training Epoch 10:  86%|████████▌ | 316/367 [00:01<00:00, 168.29it/s]Pre-training Epoch 10:  91%|█████████ | 333/367 [00:02<00:00, 166.18it/s]Pre-training Epoch 10:  96%|█████████▌| 351/367 [00:02<00:00, 168.27it/s]Pre-training Epoch 10: 100%|██████████| 367/367 [00:02<00:00, 161.56it/s]
recon_loss: 0.04236409813165665, dist_loss: 0.7815872430801392
recon_loss: 0.04236292093992233, dist_loss: 0.6166196465492249
recon_loss: 0.04236174002289772, dist_loss: 0.269619882106781
recon_loss: 0.04236048087477684, dist_loss: 1.0402026176452637
recon_loss: 0.04235919564962387, dist_loss: 0.48824000358581543
recon_loss: 0.04235795885324478, dist_loss: 0.33521124720573425
recon_loss: 0.04235677421092987, dist_loss: 0.5878767371177673
recon_loss: 0.04235546290874481, dist_loss: 0.5659704208374023
recon_loss: 0.04235415533185005, dist_loss: 0.5066407322883606
recon_loss: 0.042352963238954544, dist_loss: 0.6425955891609192
recon_loss: 0.04235203564167023, dist_loss: 0.6978838443756104
recon_loss: 0.042350977659225464, dist_loss: 0.8109393119812012
recon_loss: 0.04234977811574936, dist_loss: 0.8146750926971436
recon_loss: 0.04234842583537102, dist_loss: 0.7499233484268188
recon_loss: 0.0423470214009285, dist_loss: 0.9995130300521851
recon_loss: 0.04234571009874344, dist_loss: 0.7232141494750977
recon_loss: 0.04234447330236435, dist_loss: 0.6054791212081909
recon_loss: 0.042343366891145706, dist_loss: 0.9190914630889893
recon_loss: 0.042342279106378555, dist_loss: 1.1660107374191284
recon_loss: 0.04234124347567558, dist_loss: 0.38486361503601074
recon_loss: 0.042340245097875595, dist_loss: 0.4858994781970978
recon_loss: 0.042339224368333817, dist_loss: 1.6168994903564453
recon_loss: 0.04233810678124428, dist_loss: 0.45999467372894287
recon_loss: 0.0423370786011219, dist_loss: 0.9053890705108643
recon_loss: 0.042336173355579376, dist_loss: 0.9872030019760132
recon_loss: 0.042335133999586105, dist_loss: 0.7450802326202393
recon_loss: 0.04233424738049507, dist_loss: 0.7691231966018677
recon_loss: 0.042333103716373444, dist_loss: 0.6651718616485596
recon_loss: 0.04233213886618614, dist_loss: 0.5963026285171509
recon_loss: 0.04233121871948242, dist_loss: 0.8547181487083435
recon_loss: 0.04233038052916527, dist_loss: 0.4175065755844116
recon_loss: 0.04232973977923393, dist_loss: 0.4393497705459595
recon_loss: 0.042329058051109314, dist_loss: 0.37055474519729614
recon_loss: 0.04232839122414589, dist_loss: 0.8237534761428833
recon_loss: 0.04232783243060112, dist_loss: 0.5802980661392212
recon_loss: 0.04232730716466904, dist_loss: 0.5762900114059448
recon_loss: 0.04232685640454292, dist_loss: 0.6246049404144287
recon_loss: 0.042326245456933975, dist_loss: 0.91041100025177
recon_loss: 0.04232544079422951, dist_loss: 0.623281717300415
recon_loss: 0.042324770241975784, dist_loss: 0.778167724609375
recon_loss: 0.04232409968972206, dist_loss: 0.8139132857322693
recon_loss: 0.0423235148191452, dist_loss: 0.8207844495773315
recon_loss: 0.042322903871536255, dist_loss: 1.2088981866836548
recon_loss: 0.04232243821024895, dist_loss: 0.7718476057052612
recon_loss: 0.04232170060276985, dist_loss: 0.7112994194030762
recon_loss: 0.04232089966535568, dist_loss: 0.5656701326370239
recon_loss: 0.042319998145103455, dist_loss: 0.5281069874763489
recon_loss: 0.04231903702020645, dist_loss: 0.4894822835922241
recon_loss: 0.042318228632211685, dist_loss: 1.113884687423706
recon_loss: 0.04231728985905647, dist_loss: 0.4196813702583313
recon_loss: 0.04231642931699753, dist_loss: 1.0296460390090942
recon_loss: 0.04231534153223038, dist_loss: 0.3660818338394165
recon_loss: 0.04231445491313934, dist_loss: 0.5852465033531189
recon_loss: 0.04231347143650055, dist_loss: 0.984610915184021
recon_loss: 0.04231226071715355, dist_loss: 0.44100260734558105
recon_loss: 0.04231088608503342, dist_loss: 0.6405059099197388
recon_loss: 0.042309630662202835, dist_loss: 0.42761144042015076
recon_loss: 0.04230859503149986, dist_loss: 0.5509753227233887
recon_loss: 0.0423075370490551, dist_loss: 0.5138305425643921
recon_loss: 0.04230641946196556, dist_loss: 0.5244511365890503
recon_loss: 0.04230543598532677, dist_loss: 0.5794273614883423
recon_loss: 0.04230446740984917, dist_loss: 0.5697835087776184
recon_loss: 0.042303554713726044, dist_loss: 0.6248712539672852
recon_loss: 0.042302608489990234, dist_loss: 0.4862689971923828
recon_loss: 0.042301665991544724, dist_loss: 1.1994566917419434
recon_loss: 0.04230061173439026, dist_loss: 0.5189555883407593
recon_loss: 0.04229940101504326, dist_loss: 0.6182718276977539
recon_loss: 0.042298201471567154, dist_loss: 0.9113291501998901
recon_loss: 0.04229724034667015, dist_loss: 1.0638647079467773
recon_loss: 0.042296092957258224, dist_loss: 0.7932223081588745
recon_loss: 0.04229509457945824, dist_loss: 0.4773821532726288
recon_loss: 0.04229435697197914, dist_loss: 1.013823390007019
recon_loss: 0.04229370504617691, dist_loss: 0.5688780546188354
recon_loss: 0.04229309409856796, dist_loss: 0.5437893867492676
recon_loss: 0.04229241982102394, dist_loss: 0.6405170559883118
recon_loss: 0.04229147732257843, dist_loss: 1.7326576709747314
recon_loss: 0.04229038953781128, dist_loss: 0.44612061977386475
recon_loss: 0.04228924587368965, dist_loss: 0.6966355443000793
recon_loss: 0.04228793457150459, dist_loss: 0.5955798625946045
recon_loss: 0.042286697775125504, dist_loss: 0.9196589589118958
recon_loss: 0.04228508844971657, dist_loss: 0.42259183526039124
recon_loss: 0.04228369891643524, dist_loss: 0.8331035375595093
recon_loss: 0.042282313108444214, dist_loss: 0.8971053957939148
recon_loss: 0.04228108003735542, dist_loss: 0.747549295425415
recon_loss: 0.042279813438653946, dist_loss: 1.1708228588104248
recon_loss: 0.042278535664081573, dist_loss: 0.48513782024383545
recon_loss: 0.0422772578895092, dist_loss: 0.3453557789325714
recon_loss: 0.04227598011493683, dist_loss: 0.6818220615386963
recon_loss: 0.04227486997842789, dist_loss: 1.0314124822616577
recon_loss: 0.04227357730269432, dist_loss: 0.42995840311050415
recon_loss: 0.04227250814437866, dist_loss: 0.6171318292617798
recon_loss: 0.04227127879858017, dist_loss: 0.8055716753005981
recon_loss: 0.042270150035619736, dist_loss: 1.267470359802246
recon_loss: 0.04226900264620781, dist_loss: 0.4314575791358948
recon_loss: 0.04226785898208618, dist_loss: 0.6137750744819641
recon_loss: 0.04226674512028694, dist_loss: 0.4480963945388794
recon_loss: 0.04226579889655113, dist_loss: 0.6657246351242065
recon_loss: 0.042264971882104874, dist_loss: 0.5425325036048889
recon_loss: 0.042263951152563095, dist_loss: 0.3893169164657593
recon_loss: 0.04226294159889221, dist_loss: 0.5028805732727051
recon_loss: 0.04226185753941536, dist_loss: 0.5932470560073853
recon_loss: 0.042260877788066864, dist_loss: 0.7723414897918701
recon_loss: 0.042259931564331055, dist_loss: 0.33295145630836487
recon_loss: 0.04225894436240196, dist_loss: 0.7223718166351318
recon_loss: 0.04225802794098854, dist_loss: 0.47358378767967224
recon_loss: 0.04225708544254303, dist_loss: 0.5193643569946289
recon_loss: 0.042256150394678116, dist_loss: 0.6564325094223022
recon_loss: 0.04225512966513634, dist_loss: 0.9532233476638794
recon_loss: 0.04225416108965874, dist_loss: 0.3162822723388672
Pre-train Epoch: 10
Train - Total Loss: 0.1124, Recon Loss: 0.0424, Dist Loss: 0.7004, l1 regularization: 0.0000
Val - Total Loss: 0.1164, Recon Loss: 0.0423, Dist Loss: 0.7415, l1 regularization: 0.0000
Pre-training Epoch 11:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 11:   5%|▍         | 18/367 [00:00<00:02, 171.25it/s]Pre-training Epoch 11:  10%|▉         | 36/367 [00:00<00:02, 157.58it/s]Pre-training Epoch 11:  14%|█▍        | 52/367 [00:00<00:02, 156.70it/s]Pre-training Epoch 11:  19%|█▊        | 68/367 [00:00<00:01, 155.27it/s]Pre-training Epoch 11:  23%|██▎       | 84/367 [00:00<00:01, 155.22it/s]Pre-training Epoch 11:  27%|██▋       | 100/367 [00:00<00:01, 153.13it/s]Pre-training Epoch 11:  32%|███▏      | 116/367 [00:00<00:01, 154.49it/s]recon_loss: 0.04225301742553711, dist_loss: 0.6179661750793457
recon_loss: 0.042251914739608765, dist_loss: 0.7776037454605103
recon_loss: 0.04225093871355057, dist_loss: 0.44213446974754333
recon_loss: 0.04225008934736252, dist_loss: 1.0507763624191284
recon_loss: 0.04224921762943268, dist_loss: 0.6826328039169312
recon_loss: 0.04224848002195358, dist_loss: 1.0712612867355347
recon_loss: 0.04224761575460434, dist_loss: 0.5441821813583374
recon_loss: 0.04224672168493271, dist_loss: 0.4684211313724518
recon_loss: 0.042245808988809586, dist_loss: 0.8812522888183594
recon_loss: 0.042244803160429, dist_loss: 0.8685741424560547
recon_loss: 0.04224372282624245, dist_loss: 0.9634246230125427
recon_loss: 0.04224274680018425, dist_loss: 0.47139567136764526
recon_loss: 0.04224196448922157, dist_loss: 0.7207639217376709
recon_loss: 0.04224124178290367, dist_loss: 0.8553279042243958
recon_loss: 0.04224061593413353, dist_loss: 0.5675451755523682
recon_loss: 0.04223994165658951, dist_loss: 0.5246409177780151
recon_loss: 0.042239319533109665, dist_loss: 0.5499181747436523
recon_loss: 0.042238712310791016, dist_loss: 0.5625692009925842
recon_loss: 0.04223816469311714, dist_loss: 0.8082878589630127
recon_loss: 0.04223764315247536, dist_loss: 0.952411413192749
recon_loss: 0.04223712533712387, dist_loss: 1.1980814933776855
recon_loss: 0.04223676398396492, dist_loss: 0.7666898965835571
recon_loss: 0.04223622754216194, dist_loss: 0.5824829339981079
recon_loss: 0.04223558306694031, dist_loss: 0.4604133367538452
recon_loss: 0.04223490133881569, dist_loss: 0.7301322221755981
recon_loss: 0.042233943939208984, dist_loss: 0.6134147047996521
recon_loss: 0.04223298281431198, dist_loss: 1.0976815223693848
recon_loss: 0.042232029139995575, dist_loss: 0.48459571599960327
recon_loss: 0.04223116114735603, dist_loss: 0.41769832372665405
recon_loss: 0.04223043844103813, dist_loss: 0.561725914478302
recon_loss: 0.0422297827899456, dist_loss: 0.5157939195632935
recon_loss: 0.04222904145717621, dist_loss: 0.841700553894043
recon_loss: 0.04222854971885681, dist_loss: 0.46606022119522095
recon_loss: 0.04222805052995682, dist_loss: 0.6706081628799438
recon_loss: 0.04222759231925011, dist_loss: 1.009900450706482
recon_loss: 0.04222735017538071, dist_loss: 0.5411547422409058
recon_loss: 0.0422271303832531, dist_loss: 0.7657018303871155
recon_loss: 0.042227063328027725, dist_loss: 0.5861929655075073
recon_loss: 0.04222699627280235, dist_loss: 0.56373530626297
recon_loss: 0.042226798832416534, dist_loss: 0.6449185609817505
recon_loss: 0.04222659766674042, dist_loss: 0.9739716053009033
recon_loss: 0.04222619906067848, dist_loss: 0.7995815873146057
recon_loss: 0.04222574830055237, dist_loss: 0.9516323804855347
recon_loss: 0.04222512245178223, dist_loss: 1.0433526039123535
recon_loss: 0.0422244556248188, dist_loss: 0.5459749698638916
recon_loss: 0.042223721742630005, dist_loss: 0.7910460233688354
recon_loss: 0.04222268611192703, dist_loss: 0.5461645126342773
recon_loss: 0.04222176596522331, dist_loss: 0.45585447549819946
recon_loss: 0.0422210618853569, dist_loss: 0.5934341549873352
recon_loss: 0.04222029447555542, dist_loss: 0.4975338280200958
recon_loss: 0.04221944510936737, dist_loss: 0.7107218503952026
recon_loss: 0.04221876338124275, dist_loss: 0.6653972864151001
recon_loss: 0.042218003422021866, dist_loss: 0.984124481678009
recon_loss: 0.04221700504422188, dist_loss: 0.3626353442668915
recon_loss: 0.042216040194034576, dist_loss: 0.7163804769515991
recon_loss: 0.0422150082886219, dist_loss: 0.45844146609306335
recon_loss: 0.0422140471637249, dist_loss: 1.0177783966064453
recon_loss: 0.04221326485276222, dist_loss: 0.6766203045845032
recon_loss: 0.04221238195896149, dist_loss: 0.6918092966079712
recon_loss: 0.04221150651574135, dist_loss: 0.9224196672439575
recon_loss: 0.04221121221780777, dist_loss: 1.4258263111114502
recon_loss: 0.04221080243587494, dist_loss: 0.35674166679382324
recon_loss: 0.042210422456264496, dist_loss: 0.5879638195037842
recon_loss: 0.042209770530462265, dist_loss: 0.9716815948486328
recon_loss: 0.042209137231111526, dist_loss: 0.46331942081451416
recon_loss: 0.042208366096019745, dist_loss: 0.4601428508758545
recon_loss: 0.04220777750015259, dist_loss: 0.698440670967102
recon_loss: 0.04220692813396454, dist_loss: 0.47491127252578735
recon_loss: 0.042206063866615295, dist_loss: 0.921826183795929
recon_loss: 0.04220513626933098, dist_loss: 0.48469048738479614
recon_loss: 0.04220430552959442, dist_loss: 0.6253054738044739
recon_loss: 0.0422031432390213, dist_loss: 1.0255767107009888
recon_loss: 0.04220191016793251, dist_loss: 0.509405791759491
recon_loss: 0.04220060631632805, dist_loss: 0.7496881484985352
recon_loss: 0.04219934344291687, dist_loss: 1.0186991691589355
recon_loss: 0.04219807684421539, dist_loss: 0.9412651062011719
recon_loss: 0.04219669848680496, dist_loss: 0.7301769256591797
recon_loss: 0.04219517111778259, dist_loss: 1.068272590637207
recon_loss: 0.04219381511211395, dist_loss: 0.9947060346603394
recon_loss: 0.04219237342476845, dist_loss: 0.6757501363754272
recon_loss: 0.04219091683626175, dist_loss: 0.3800477385520935
recon_loss: 0.04218953102827072, dist_loss: 0.5694833397865295
recon_loss: 0.042188405990600586, dist_loss: 0.7579077482223511
recon_loss: 0.04218735173344612, dist_loss: 0.6193029880523682
recon_loss: 0.04218636453151703, dist_loss: 0.46472787857055664
recon_loss: 0.04218553006649017, dist_loss: 0.3852996826171875
recon_loss: 0.04218476265668869, dist_loss: 0.755946159362793
recon_loss: 0.04218375310301781, dist_loss: 0.36705076694488525
recon_loss: 0.0421827994287014, dist_loss: 0.9293453693389893
recon_loss: 0.042181868106126785, dist_loss: 0.46938860416412354
recon_loss: 0.04218099266290665, dist_loss: 0.898169755935669
recon_loss: 0.04218028858304024, dist_loss: 0.6215911507606506
recon_loss: 0.04217957332730293, dist_loss: 0.4130428433418274
recon_loss: 0.042178791016340256, dist_loss: 0.3484431803226471
recon_loss: 0.04217825457453728, dist_loss: 0.5738633871078491
recon_loss: 0.042177729308605194, dist_loss: 0.5864647030830383
recon_loss: 0.0421772375702858, dist_loss: 0.6451704502105713
recon_loss: 0.042176295071840286, dist_loss: 0.26268821954727173
recon_loss: 0.0421753004193306, dist_loss: 0.7975876927375793
recon_loss: 0.04217434674501419, dist_loss: 0.9422436952590942
recon_loss: 0.04217324033379555, dist_loss: 0.5590180158615112
recon_loss: 0.04217232018709183, dist_loss: 0.6008139848709106
recon_loss: 0.04217129945755005, dist_loss: 0.8367477655410767
recon_loss: 0.042170409113168716, dist_loss: 0.4635072648525238
recon_loss: 0.04216957464814186, dist_loss: 0.7555867433547974
recon_loss: 0.04216896370053291, dist_loss: 0.5142978429794312
recon_loss: 0.04216848686337471, dist_loss: 0.5749467611312866
recon_loss: 0.04216788336634636, dist_loss: 0.6141124367713928
recon_loss: 0.04216738045215607, dist_loss: 0.50496506690979
recon_loss: 0.04216689243912697, dist_loss: 0.5269375443458557
recon_loss: 0.0421663299202919, dist_loss: 0.6552014350891113
recon_loss: 0.04216572269797325, dist_loss: 1.1915093660354614
recon_loss: 0.04216472804546356, dist_loss: 0.6687874794006348
recon_loss: 0.0421636737883091, dist_loss: 0.4383966624736786
recon_loss: 0.04216281697154045, dist_loss: 0.7584195137023926
recon_loss: 0.04216167703270912, dist_loss: 1.0474481582641602
recon_loss: 0.04216068983078003, dist_loss: 0.6013531684875488
recon_loss: 0.04215972498059273, dist_loss: 1.1821012496948242
recon_loss: 0.04215862229466438, dist_loss: 0.5645303130149841
recon_loss: 0.0421576201915741, dist_loss: 0.6881771087646484
recon_loss: 0.04215649515390396, dist_loss: 0.6648041009902954
recon_loss: 0.04215553402900696, dist_loss: 0.504831850528717
recon_loss: 0.0421544685959816, dist_loss: 0.8660407066345215
recon_loss: 0.04215339571237564, dist_loss: 0.5709761381149292
recon_loss: 0.04215221852064133, dist_loss: 0.516842246055603
recon_loss: 0.042151011526584625, dist_loss: 0.49478355050086975
recon_loss: 0.042149901390075684, dist_loss: 0.8272936344146729
recon_loss: 0.04214848205447197, dist_loss: 0.8069591522216797
recon_loss: 0.04214707389473915, dist_loss: 0.7679338455200195
Pre-training Epoch 11:  36%|███▌      | 132/367 [00:00<00:01, 151.48it/s]Pre-training Epoch 11:  40%|████      | 148/367 [00:00<00:01, 152.64it/s]Pre-training Epoch 11:  45%|████▍     | 164/367 [00:01<00:01, 151.72it/s]Pre-training Epoch 11:  49%|████▉     | 180/367 [00:01<00:01, 153.03it/s]Pre-training Epoch 11:  53%|█████▎    | 196/367 [00:01<00:01, 150.94it/s]Pre-training Epoch 11:  58%|█████▊    | 212/367 [00:01<00:01, 152.31it/s]Pre-training Epoch 11:  62%|██████▏   | 228/367 [00:01<00:00, 151.44it/s]Pre-training Epoch 11:  66%|██████▋   | 244/367 [00:01<00:00, 152.19it/s]recon_loss: 0.04214554652571678, dist_loss: 0.6660498976707458
recon_loss: 0.0421440415084362, dist_loss: 0.6573971509933472
recon_loss: 0.04214268922805786, dist_loss: 1.1136651039123535
recon_loss: 0.04214126989245415, dist_loss: 0.8584564924240112
recon_loss: 0.04213990271091461, dist_loss: 0.7003822326660156
recon_loss: 0.04213862866163254, dist_loss: 0.4770466387271881
recon_loss: 0.04213753715157509, dist_loss: 0.5393767356872559
recon_loss: 0.0421365350484848, dist_loss: 0.4869394302368164
recon_loss: 0.04213564470410347, dist_loss: 0.6623305082321167
recon_loss: 0.04213489964604378, dist_loss: 0.3369401693344116
recon_loss: 0.04213415086269379, dist_loss: 0.7612003087997437
recon_loss: 0.0421333909034729, dist_loss: 0.4494774639606476
recon_loss: 0.042132627218961716, dist_loss: 0.689663827419281
recon_loss: 0.042131856083869934, dist_loss: 0.5863213539123535
recon_loss: 0.04213110730051994, dist_loss: 0.4440409541130066
recon_loss: 0.04213029146194458, dist_loss: 0.5651471614837646
recon_loss: 0.042129624634981155, dist_loss: 0.6756758093833923
recon_loss: 0.04212918505072594, dist_loss: 0.458171546459198
recon_loss: 0.042128704488277435, dist_loss: 0.6098992824554443
recon_loss: 0.042128510773181915, dist_loss: 0.5535497069358826
recon_loss: 0.042128175497055054, dist_loss: 0.6399179697036743
recon_loss: 0.042127374559640884, dist_loss: 0.7062931060791016
recon_loss: 0.04212668165564537, dist_loss: 1.1443228721618652
recon_loss: 0.04212599992752075, dist_loss: 0.5325286388397217
recon_loss: 0.04212510958313942, dist_loss: 0.7015889883041382
recon_loss: 0.042124077677726746, dist_loss: 0.7178009748458862
recon_loss: 0.0421229712665081, dist_loss: 0.7297544479370117
recon_loss: 0.04212189093232155, dist_loss: 0.8246846199035645
recon_loss: 0.042120691388845444, dist_loss: 0.5309628844261169
recon_loss: 0.04211940988898277, dist_loss: 0.7034459710121155
recon_loss: 0.0421181321144104, dist_loss: 0.6776666045188904
recon_loss: 0.04211685433983803, dist_loss: 0.5850210189819336
recon_loss: 0.042115725576877594, dist_loss: 0.5612136125564575
recon_loss: 0.042114414274692535, dist_loss: 0.869136393070221
recon_loss: 0.04211295023560524, dist_loss: 0.7560688853263855
recon_loss: 0.04211141914129257, dist_loss: 0.5930156707763672
recon_loss: 0.0421098992228508, dist_loss: 0.5191731452941895
recon_loss: 0.04210829734802246, dist_loss: 0.7175754904747009
recon_loss: 0.042106762528419495, dist_loss: 0.7244879007339478
recon_loss: 0.04210550710558891, dist_loss: 0.7101790308952332
recon_loss: 0.042104270309209824, dist_loss: 0.3860642910003662
recon_loss: 0.04210302233695984, dist_loss: 0.584231436252594
recon_loss: 0.042101792991161346, dist_loss: 0.30273765325546265
recon_loss: 0.04210054501891136, dist_loss: 0.5170563459396362
recon_loss: 0.042099449783563614, dist_loss: 0.47659847140312195
recon_loss: 0.04209855571389198, dist_loss: 0.7415642738342285
recon_loss: 0.04209788888692856, dist_loss: 0.6721962094306946
recon_loss: 0.04209710657596588, dist_loss: 0.6908560991287231
recon_loss: 0.0420960932970047, dist_loss: 1.004071831703186
recon_loss: 0.042095087468624115, dist_loss: 0.4661025106906891
recon_loss: 0.04209412261843681, dist_loss: 0.7023522853851318
recon_loss: 0.04209302365779877, dist_loss: 0.7082031965255737
recon_loss: 0.0420919694006443, dist_loss: 0.6053265333175659
recon_loss: 0.042090777307748795, dist_loss: 0.8688204884529114
recon_loss: 0.042089760303497314, dist_loss: 0.3577406406402588
recon_loss: 0.042088836431503296, dist_loss: 0.7625899314880371
recon_loss: 0.042087893933057785, dist_loss: 0.6903187036514282
recon_loss: 0.04208676889538765, dist_loss: 0.568234920501709
recon_loss: 0.042085420340299606, dist_loss: 1.149906873703003
recon_loss: 0.042084090411663055, dist_loss: 0.68247389793396
recon_loss: 0.04208281636238098, dist_loss: 0.6452419757843018
recon_loss: 0.04208139330148697, dist_loss: 0.5770841240882874
recon_loss: 0.042080093175172806, dist_loss: 0.4909064471721649
recon_loss: 0.04207887500524521, dist_loss: 0.5800584554672241
recon_loss: 0.04207773879170418, dist_loss: 0.4434390664100647
recon_loss: 0.04207652807235718, dist_loss: 0.5419888496398926
recon_loss: 0.042075272649526596, dist_loss: 0.5506800413131714
recon_loss: 0.042074039578437805, dist_loss: 1.084463357925415
recon_loss: 0.042072854936122894, dist_loss: 1.1020684242248535
recon_loss: 0.042071614414453506, dist_loss: 0.8406808376312256
recon_loss: 0.042070284485816956, dist_loss: 1.013974666595459
recon_loss: 0.042068928480148315, dist_loss: 0.8264342546463013
recon_loss: 0.04206755384802818, dist_loss: 1.0458464622497559
recon_loss: 0.042066264897584915, dist_loss: 1.0658893585205078
recon_loss: 0.042065102607011795, dist_loss: 0.9267010688781738
recon_loss: 0.04206368699669838, dist_loss: 0.7755522727966309
recon_loss: 0.042062245309352875, dist_loss: 1.1292672157287598
recon_loss: 0.04206092283129692, dist_loss: 0.4679938554763794
recon_loss: 0.04205979034304619, dist_loss: 0.6477391123771667
recon_loss: 0.042058467864990234, dist_loss: 1.150694489479065
recon_loss: 0.04205719381570816, dist_loss: 1.4088011980056763
recon_loss: 0.04205619916319847, dist_loss: 0.521889865398407
recon_loss: 0.04205517843365669, dist_loss: 0.6688376665115356
recon_loss: 0.04205421730875969, dist_loss: 0.6438058614730835
recon_loss: 0.04205330088734627, dist_loss: 0.5304481983184814
recon_loss: 0.042052265256643295, dist_loss: 0.6903277635574341
recon_loss: 0.04205130785703659, dist_loss: 0.8768371939659119
recon_loss: 0.04205053299665451, dist_loss: 0.9950135946273804
recon_loss: 0.042049895972013474, dist_loss: 0.6651654839515686
recon_loss: 0.04204939678311348, dist_loss: 0.9465514421463013
recon_loss: 0.04204893857240677, dist_loss: 0.5606490969657898
recon_loss: 0.04204823076725006, dist_loss: 1.0207340717315674
recon_loss: 0.042047303169965744, dist_loss: 0.8068208694458008
recon_loss: 0.042046383023262024, dist_loss: 0.5934008359909058
recon_loss: 0.04204545170068741, dist_loss: 0.31828245520591736
recon_loss: 0.04204428568482399, dist_loss: 0.37645214796066284
recon_loss: 0.04204317927360535, dist_loss: 0.4414379298686981
recon_loss: 0.04204217717051506, dist_loss: 0.8256232738494873
recon_loss: 0.042040929198265076, dist_loss: 0.5580748319625854
recon_loss: 0.04203943908214569, dist_loss: 0.45873165130615234
recon_loss: 0.042038120329380035, dist_loss: 0.7847301363945007
recon_loss: 0.04203692078590393, dist_loss: 0.9721983671188354
recon_loss: 0.042035557329654694, dist_loss: 0.47543811798095703
recon_loss: 0.04203428700566292, dist_loss: 0.8101285099983215
recon_loss: 0.0420328825712204, dist_loss: 0.5978078842163086
recon_loss: 0.042031388729810715, dist_loss: 0.4083336293697357
recon_loss: 0.0420299656689167, dist_loss: 0.6707503795623779
recon_loss: 0.042028605937957764, dist_loss: 0.40903788805007935
recon_loss: 0.04202717915177345, dist_loss: 0.40002286434173584
recon_loss: 0.04202573746442795, dist_loss: 0.6877617835998535
recon_loss: 0.04202456399798393, dist_loss: 0.7957590222358704
recon_loss: 0.04202304035425186, dist_loss: 0.7716459035873413
recon_loss: 0.04202158376574516, dist_loss: 0.7678284645080566
recon_loss: 0.04202016815543175, dist_loss: 0.6656578779220581
recon_loss: 0.04201896861195564, dist_loss: 0.82338547706604
recon_loss: 0.04201778769493103, dist_loss: 0.9871858954429626
recon_loss: 0.04201677814126015, dist_loss: 0.6995914578437805
recon_loss: 0.04201579838991165, dist_loss: 0.4708983302116394
recon_loss: 0.04201476648449898, dist_loss: 0.5699517726898193
recon_loss: 0.042013805359601974, dist_loss: 1.002288818359375
recon_loss: 0.04201282188296318, dist_loss: 0.9634574055671692
recon_loss: 0.04201190918684006, dist_loss: 0.6356956958770752
recon_loss: 0.042010948061943054, dist_loss: 0.9624580144882202
recon_loss: 0.0420098751783371, dist_loss: 0.7017181515693665
recon_loss: 0.042008642107248306, dist_loss: 0.9022326469421387
recon_loss: 0.04200758785009384, dist_loss: 0.6797761917114258
recon_loss: 0.04200643673539162, dist_loss: 0.8830358386039734
recon_loss: 0.04200564697384834, dist_loss: 0.5771204233169556
recon_loss: 0.0420047752559185, dist_loss: 1.0580891370773315
Pre-training Epoch 11:  71%|███████   | 260/367 [00:01<00:00, 152.92it/s]Pre-training Epoch 11:  75%|███████▌  | 276/367 [00:01<00:00, 150.62it/s]Pre-training Epoch 11:  80%|███████▉  | 292/367 [00:01<00:00, 150.49it/s]Pre-training Epoch 11:  84%|████████▍ | 308/367 [00:02<00:00, 152.69it/s]Pre-training Epoch 11:  89%|████████▉ | 327/367 [00:02<00:00, 161.24it/s]Pre-training Epoch 11:  94%|█████████▎| 344/367 [00:02<00:00, 160.04it/s]Pre-training Epoch 11:  98%|█████████▊| 361/367 [00:02<00:00, 159.31it/s]Pre-training Epoch 11: 100%|██████████| 367/367 [00:02<00:00, 154.73it/s]
recon_loss: 0.042003776878118515, dist_loss: 0.9536363482475281
recon_loss: 0.04200277850031853, dist_loss: 0.7438416481018066
recon_loss: 0.04200199618935585, dist_loss: 1.172927975654602
recon_loss: 0.04200113192200661, dist_loss: 0.5711591839790344
recon_loss: 0.04200032725930214, dist_loss: 1.0732612609863281
recon_loss: 0.04199922829866409, dist_loss: 0.5313875079154968
recon_loss: 0.041998084634542465, dist_loss: 0.38484278321266174
recon_loss: 0.041997019201517105, dist_loss: 0.4878394305706024
recon_loss: 0.041996102780103683, dist_loss: 1.0636919736862183
recon_loss: 0.041995447129011154, dist_loss: 0.9990910887718201
recon_loss: 0.04199475795030594, dist_loss: 0.6086358428001404
recon_loss: 0.04199383035302162, dist_loss: 0.6982425451278687
recon_loss: 0.04199303314089775, dist_loss: 0.7722383737564087
recon_loss: 0.041992075741291046, dist_loss: 0.6736948490142822
recon_loss: 0.041991133242845535, dist_loss: 0.5654803514480591
recon_loss: 0.04199018329381943, dist_loss: 0.5191267728805542
recon_loss: 0.041989102959632874, dist_loss: 1.0476958751678467
recon_loss: 0.04198792576789856, dist_loss: 0.5335822105407715
recon_loss: 0.041986867785453796, dist_loss: 0.9938721656799316
recon_loss: 0.04198593273758888, dist_loss: 1.2659251689910889
recon_loss: 0.04198508709669113, dist_loss: 0.551904559135437
recon_loss: 0.041984155774116516, dist_loss: 0.4508565664291382
recon_loss: 0.04198320209980011, dist_loss: 0.9494256973266602
recon_loss: 0.041982367634773254, dist_loss: 0.8738244771957397
recon_loss: 0.041981205344200134, dist_loss: 0.76738041639328
recon_loss: 0.04198018088936806, dist_loss: 0.6588280200958252
recon_loss: 0.04197930917143822, dist_loss: 0.9895443320274353
recon_loss: 0.04197845980525017, dist_loss: 0.5561071634292603
recon_loss: 0.04197778180241585, dist_loss: 0.6238529682159424
recon_loss: 0.041976895183324814, dist_loss: 0.5522012710571289
recon_loss: 0.041975948959589005, dist_loss: 0.4569278359413147
recon_loss: 0.041974905878305435, dist_loss: 1.3594821691513062
recon_loss: 0.04197370260953903, dist_loss: 0.792122483253479
recon_loss: 0.04197240620851517, dist_loss: 0.7534335255622864
recon_loss: 0.04197123274207115, dist_loss: 1.0603055953979492
recon_loss: 0.04197006672620773, dist_loss: 0.7225974202156067
recon_loss: 0.04196902737021446, dist_loss: 0.49837711453437805
recon_loss: 0.04196815937757492, dist_loss: 0.5450231432914734
recon_loss: 0.04196731746196747, dist_loss: 0.9820187091827393
recon_loss: 0.041966140270233154, dist_loss: 0.6861863136291504
recon_loss: 0.041965052485466, dist_loss: 0.6914291977882385
recon_loss: 0.04196403548121452, dist_loss: 0.971527636051178
recon_loss: 0.04196329042315483, dist_loss: 0.7942295074462891
recon_loss: 0.041962649673223495, dist_loss: 0.6885867714881897
recon_loss: 0.04196210205554962, dist_loss: 0.4777660071849823
recon_loss: 0.04196177423000336, dist_loss: 0.7879265546798706
recon_loss: 0.04196127876639366, dist_loss: 0.3581846356391907
recon_loss: 0.04196090251207352, dist_loss: 0.5084468126296997
recon_loss: 0.04196055233478546, dist_loss: 1.097962737083435
recon_loss: 0.041960034519433975, dist_loss: 0.8870354890823364
recon_loss: 0.041959356516599655, dist_loss: 1.0032130479812622
recon_loss: 0.04195864498615265, dist_loss: 0.678072452545166
recon_loss: 0.041958022862672806, dist_loss: 0.722662627696991
recon_loss: 0.04195713251829147, dist_loss: 0.46839985251426697
recon_loss: 0.04195614904165268, dist_loss: 0.7441497445106506
recon_loss: 0.04195519536733627, dist_loss: 0.5387893915176392
recon_loss: 0.04195418581366539, dist_loss: 0.46990227699279785
recon_loss: 0.04195309802889824, dist_loss: 0.8460032343864441
recon_loss: 0.04195218160748482, dist_loss: 0.8252025842666626
recon_loss: 0.041951362043619156, dist_loss: 0.9557287693023682
recon_loss: 0.04195084795355797, dist_loss: 0.36501991748809814
recon_loss: 0.04195026308298111, dist_loss: 0.6795756816864014
recon_loss: 0.04194964841008186, dist_loss: 0.75656658411026
recon_loss: 0.0419488325715065, dist_loss: 0.6675482988357544
recon_loss: 0.04194827750325203, dist_loss: 0.8624210357666016
recon_loss: 0.04194752871990204, dist_loss: 0.6329667568206787
recon_loss: 0.04194658249616623, dist_loss: 0.5793033242225647
recon_loss: 0.04194570332765579, dist_loss: 0.48416295647621155
recon_loss: 0.041944779455661774, dist_loss: 0.7648305892944336
recon_loss: 0.04194406419992447, dist_loss: 1.0746798515319824
recon_loss: 0.041943132877349854, dist_loss: 0.7538102865219116
recon_loss: 0.04194224253296852, dist_loss: 0.7379965782165527
recon_loss: 0.04194130003452301, dist_loss: 0.32570117712020874
recon_loss: 0.04194038733839989, dist_loss: 0.5748966932296753
recon_loss: 0.04193926975131035, dist_loss: 0.6894943714141846
recon_loss: 0.041937895119190216, dist_loss: 0.4318660497665405
recon_loss: 0.04193653538823128, dist_loss: 0.6963924169540405
recon_loss: 0.041935116052627563, dist_loss: 0.6959805488586426
recon_loss: 0.041933655738830566, dist_loss: 0.6231700778007507
recon_loss: 0.04193218797445297, dist_loss: 0.48003822565078735
recon_loss: 0.04193086177110672, dist_loss: 0.6256012916564941
recon_loss: 0.04192940518260002, dist_loss: 1.182010293006897
recon_loss: 0.04192795976996422, dist_loss: 0.8966833353042603
recon_loss: 0.04192676767706871, dist_loss: 0.5198947191238403
recon_loss: 0.04192565754055977, dist_loss: 0.6323903203010559
recon_loss: 0.04192464426159859, dist_loss: 0.7199795246124268
recon_loss: 0.04192366451025009, dist_loss: 0.38218098878860474
recon_loss: 0.041922830045223236, dist_loss: 0.48007431626319885
recon_loss: 0.0419219471514225, dist_loss: 0.3949741721153259
recon_loss: 0.041921164840459824, dist_loss: 1.2588527202606201
recon_loss: 0.04192003980278969, dist_loss: 0.8312969207763672
recon_loss: 0.041918884962797165, dist_loss: 0.8991703987121582
recon_loss: 0.041917584836483, dist_loss: 0.5549598932266235
recon_loss: 0.04191628843545914, dist_loss: 0.6827132105827332
recon_loss: 0.041914891451597214, dist_loss: 0.7746865749359131
recon_loss: 0.04191366955637932, dist_loss: 0.9502736926078796
recon_loss: 0.04191260039806366, dist_loss: 0.7407169342041016
recon_loss: 0.04191150516271591, dist_loss: 0.8939573168754578
recon_loss: 0.04191025346517563, dist_loss: 0.6220443248748779
recon_loss: 0.041909024119377136, dist_loss: 0.5441367626190186
recon_loss: 0.04190769046545029, dist_loss: 0.5069880485534668
recon_loss: 0.04190638288855553, dist_loss: 0.2919463515281677
recon_loss: 0.04190512374043465, dist_loss: 0.9277744293212891
recon_loss: 0.04190389811992645, dist_loss: 0.5800012350082397
recon_loss: 0.041902896016836166, dist_loss: 1.064134120941162
recon_loss: 0.04190213605761528, dist_loss: 0.5928207635879517
recon_loss: 0.04190149903297424, dist_loss: 0.7781792283058167
recon_loss: 0.04190043359994888, dist_loss: 0.6670385599136353
recon_loss: 0.041899487376213074, dist_loss: 0.6159331202507019
Pre-training Epoch 12:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 12:   5%|▍         | 18/367 [00:00<00:02, 170.53it/s]Pre-training Epoch 12:  10%|█         | 37/367 [00:00<00:01, 177.16it/s]Pre-training Epoch 12:  16%|█▌        | 57/367 [00:00<00:01, 184.94it/s]Pre-training Epoch 12:  21%|██        | 77/367 [00:00<00:01, 188.71it/s]Pre-training Epoch 12:  26%|██▋       | 97/367 [00:00<00:01, 190.86it/s]Pre-training Epoch 12:  32%|███▏      | 117/367 [00:00<00:01, 192.20it/s]recon_loss: 0.04189865663647652, dist_loss: 0.5610576868057251
recon_loss: 0.04189802706241608, dist_loss: 0.6922976970672607
recon_loss: 0.04189726710319519, dist_loss: 0.8094646334648132
recon_loss: 0.041896503418684006, dist_loss: 0.555004894733429
recon_loss: 0.041895922273397446, dist_loss: 0.7120555639266968
recon_loss: 0.04189518839120865, dist_loss: 0.3583463430404663
recon_loss: 0.04189426824450493, dist_loss: 0.3978806436061859
recon_loss: 0.04189370572566986, dist_loss: 0.9803414344787598
recon_loss: 0.041892893612384796, dist_loss: 0.4589341878890991
recon_loss: 0.04189223051071167, dist_loss: 0.3228659927845001
recon_loss: 0.04189144819974899, dist_loss: 1.1574598550796509
recon_loss: 0.04189101979136467, dist_loss: 0.4420139491558075
recon_loss: 0.04189048334956169, dist_loss: 0.6985474824905396
recon_loss: 0.04188985750079155, dist_loss: 0.5457768440246582
recon_loss: 0.04188941791653633, dist_loss: 1.0660982131958008
recon_loss: 0.041888684034347534, dist_loss: 0.4043450653553009
recon_loss: 0.041887879371643066, dist_loss: 0.855709969997406
recon_loss: 0.041887227445840836, dist_loss: 0.37420743703842163
recon_loss: 0.04188653826713562, dist_loss: 0.581792950630188
recon_loss: 0.041885651648044586, dist_loss: 0.7974448204040527
recon_loss: 0.041884757578372955, dist_loss: 0.4600050449371338
recon_loss: 0.041883982717990875, dist_loss: 1.0144057273864746
recon_loss: 0.04188283160328865, dist_loss: 0.7110435962677002
recon_loss: 0.0418814942240715, dist_loss: 0.8217836618423462
recon_loss: 0.04188035801053047, dist_loss: 0.6461871266365051
recon_loss: 0.0418790839612484, dist_loss: 0.7367640137672424
recon_loss: 0.041877925395965576, dist_loss: 0.5627212524414062
recon_loss: 0.041876740753650665, dist_loss: 0.9417137503623962
recon_loss: 0.04187575355172157, dist_loss: 0.9366660714149475
recon_loss: 0.04187482222914696, dist_loss: 0.5454874038696289
recon_loss: 0.04187387600541115, dist_loss: 0.9708883762359619
recon_loss: 0.04187287390232086, dist_loss: 0.5505536794662476
recon_loss: 0.041871704161167145, dist_loss: 0.555185079574585
recon_loss: 0.04187079891562462, dist_loss: 0.49264848232269287
recon_loss: 0.04186999425292015, dist_loss: 0.8002501726150513
recon_loss: 0.04186943173408508, dist_loss: 1.642042875289917
recon_loss: 0.041868939995765686, dist_loss: 0.4370242655277252
recon_loss: 0.04186831787228584, dist_loss: 0.4351033568382263
recon_loss: 0.04186750575900078, dist_loss: 0.8090457916259766
recon_loss: 0.04186684265732765, dist_loss: 0.7314061522483826
recon_loss: 0.04186591878533363, dist_loss: 0.5599134564399719
recon_loss: 0.04186481237411499, dist_loss: 0.644033670425415
recon_loss: 0.04186399281024933, dist_loss: 0.6072171330451965
recon_loss: 0.04186282306909561, dist_loss: 0.7283374071121216
recon_loss: 0.04186186566948891, dist_loss: 0.5190216302871704
recon_loss: 0.04186074808239937, dist_loss: 0.5016940832138062
recon_loss: 0.0418597012758255, dist_loss: 0.8704251050949097
recon_loss: 0.04185850918292999, dist_loss: 0.7018817663192749
recon_loss: 0.041857436299324036, dist_loss: 1.215789556503296
recon_loss: 0.04185617342591286, dist_loss: 0.7242783308029175
recon_loss: 0.041854847222566605, dist_loss: 0.5522220730781555
recon_loss: 0.04185362532734871, dist_loss: 0.6858644485473633
recon_loss: 0.041852496564388275, dist_loss: 0.816190242767334
recon_loss: 0.04185161367058754, dist_loss: 0.5195791721343994
recon_loss: 0.04185069724917412, dist_loss: 0.6340450048446655
recon_loss: 0.04184994101524353, dist_loss: 0.6983451247215271
recon_loss: 0.04184916988015175, dist_loss: 0.3942628800868988
recon_loss: 0.04184834659099579, dist_loss: 0.8103561997413635
recon_loss: 0.041847582906484604, dist_loss: 0.6775108575820923
recon_loss: 0.04184657707810402, dist_loss: 0.782054603099823
recon_loss: 0.041845545172691345, dist_loss: 0.4284721612930298
recon_loss: 0.041844550520181656, dist_loss: 0.9649027585983276
recon_loss: 0.04184342175722122, dist_loss: 0.5882067680358887
recon_loss: 0.04184246063232422, dist_loss: 0.6835577487945557
recon_loss: 0.04184117168188095, dist_loss: 0.5328848361968994
recon_loss: 0.04183994233608246, dist_loss: 0.3210071921348572
recon_loss: 0.04183876886963844, dist_loss: 0.30939748883247375
recon_loss: 0.04183760657906532, dist_loss: 0.45884978771209717
recon_loss: 0.04183655232191086, dist_loss: 1.0195733308792114
recon_loss: 0.041835982352495193, dist_loss: 0.8764907121658325
recon_loss: 0.04183546081185341, dist_loss: 0.6885391473770142
recon_loss: 0.04183470085263252, dist_loss: 0.6816588640213013
recon_loss: 0.0418337807059288, dist_loss: 0.6043218374252319
recon_loss: 0.0418328233063221, dist_loss: 0.8506922125816345
recon_loss: 0.04183186963200569, dist_loss: 0.5995811223983765
recon_loss: 0.04183090850710869, dist_loss: 0.5161126255989075
recon_loss: 0.04182998463511467, dist_loss: 0.460477739572525
recon_loss: 0.04182906076312065, dist_loss: 0.37413278222084045
recon_loss: 0.04182819277048111, dist_loss: 0.2649507522583008
recon_loss: 0.04182738810777664, dist_loss: 0.9441064596176147
recon_loss: 0.04182671010494232, dist_loss: 0.7424682378768921
recon_loss: 0.041826095432043076, dist_loss: 0.7717188596725464
recon_loss: 0.041825518012046814, dist_loss: 0.3680611848831177
recon_loss: 0.041824910789728165, dist_loss: 0.7931081056594849
recon_loss: 0.04182438179850578, dist_loss: 0.9165278673171997
recon_loss: 0.04182346537709236, dist_loss: 0.7106820344924927
recon_loss: 0.04182279482483864, dist_loss: 0.5824553370475769
recon_loss: 0.041822005063295364, dist_loss: 0.40614941716194153
recon_loss: 0.041821178048849106, dist_loss: 0.5257803201675415
recon_loss: 0.04182051122188568, dist_loss: 0.5570165514945984
recon_loss: 0.04181990399956703, dist_loss: 0.7838057279586792
recon_loss: 0.041819363832473755, dist_loss: 0.6538907885551453
recon_loss: 0.04181857407093048, dist_loss: 0.8501167297363281
recon_loss: 0.04181773588061333, dist_loss: 0.5960718989372253
recon_loss: 0.041816823184490204, dist_loss: 0.7649496793746948
recon_loss: 0.04181598126888275, dist_loss: 0.6330621242523193
recon_loss: 0.04181453958153725, dist_loss: 0.6155893206596375
recon_loss: 0.041813164949417114, dist_loss: 0.6453903317451477
recon_loss: 0.0418122336268425, dist_loss: 0.5770414471626282
recon_loss: 0.0418114960193634, dist_loss: 0.534221887588501
recon_loss: 0.041810572147369385, dist_loss: 0.5576837062835693
recon_loss: 0.04180954769253731, dist_loss: 0.5124068856239319
recon_loss: 0.04180865362286568, dist_loss: 0.8037469983100891
recon_loss: 0.041807517409324646, dist_loss: 0.5254135727882385
recon_loss: 0.041806478053331375, dist_loss: 0.8214960694313049
recon_loss: 0.04180530458688736, dist_loss: 0.6073128581047058
recon_loss: 0.041804105043411255, dist_loss: 0.5318655371665955
recon_loss: 0.04180281609296799, dist_loss: 0.7066834568977356
recon_loss: 0.04180174693465233, dist_loss: 0.3983851373195648
recon_loss: 0.041800614446401596, dist_loss: 1.0295560359954834
recon_loss: 0.04179934412240982, dist_loss: 0.8120282888412476
recon_loss: 0.041798148304224014, dist_loss: 0.6751641631126404
recon_loss: 0.04179682210087776, dist_loss: 0.47701865434646606
recon_loss: 0.041795745491981506, dist_loss: 0.8940870761871338
recon_loss: 0.0417945496737957, dist_loss: 0.4186449646949768
recon_loss: 0.04179338738322258, dist_loss: 0.4313335716724396
recon_loss: 0.04179220646619797, dist_loss: 0.8067910671234131
recon_loss: 0.04179101437330246, dist_loss: 0.7869024276733398
recon_loss: 0.04178972914814949, dist_loss: 0.9643775224685669
recon_loss: 0.04178842902183533, dist_loss: 0.49205446243286133
recon_loss: 0.04178714379668236, dist_loss: 1.1855273246765137
recon_loss: 0.04178570210933685, dist_loss: 0.7540923357009888
recon_loss: 0.04178452119231224, dist_loss: 0.5369492173194885
recon_loss: 0.041783224791288376, dist_loss: 0.37217146158218384
recon_loss: 0.04178182780742645, dist_loss: 0.5236393213272095
recon_loss: 0.04178052023053169, dist_loss: 0.7736597061157227
recon_loss: 0.041779160499572754, dist_loss: 0.6600976586341858
recon_loss: 0.041777875274419785, dist_loss: 0.9101064801216125
recon_loss: 0.04177685081958771, dist_loss: 0.6092609763145447
Pre-training Epoch 12:  37%|███▋      | 137/367 [00:00<00:01, 190.01it/s]Pre-training Epoch 12:  43%|████▎     | 157/367 [00:00<00:01, 185.14it/s]Pre-training Epoch 12:  48%|████▊     | 176/367 [00:00<00:01, 182.08it/s]Pre-training Epoch 12:  53%|█████▎    | 195/367 [00:01<00:00, 181.34it/s]Pre-training Epoch 12:  58%|█████▊    | 214/367 [00:01<00:00, 183.82it/s]Pre-training Epoch 12:  64%|██████▍   | 234/367 [00:01<00:00, 187.13it/s]Pre-training Epoch 12:  69%|██████▉   | 254/367 [00:01<00:00, 189.50it/s]recon_loss: 0.041775960475206375, dist_loss: 0.801891565322876
recon_loss: 0.04177502542734146, dist_loss: 1.1460543870925903
recon_loss: 0.04177414998412132, dist_loss: 0.8049677014350891
recon_loss: 0.041773345321416855, dist_loss: 0.7500686645507812
recon_loss: 0.04177218675613403, dist_loss: 0.531039834022522
recon_loss: 0.04177084192633629, dist_loss: 0.46293193101882935
recon_loss: 0.04176943376660347, dist_loss: 0.8374907970428467
recon_loss: 0.041768256574869156, dist_loss: 0.5997506380081177
recon_loss: 0.04176703467965126, dist_loss: 0.670509397983551
recon_loss: 0.041766129434108734, dist_loss: 0.9461292028427124
recon_loss: 0.04176543280482292, dist_loss: 0.9314429759979248
recon_loss: 0.04176487773656845, dist_loss: 0.9588297605514526
recon_loss: 0.041764289140701294, dist_loss: 0.9963105916976929
recon_loss: 0.041763417422771454, dist_loss: 0.5167429447174072
recon_loss: 0.04176265373826027, dist_loss: 0.7053025960922241
recon_loss: 0.04176178574562073, dist_loss: 0.5339398384094238
recon_loss: 0.041760750114917755, dist_loss: 0.5341096520423889
recon_loss: 0.04175974056124687, dist_loss: 0.8987438678741455
recon_loss: 0.041758425533771515, dist_loss: 1.1546143293380737
recon_loss: 0.04175714775919914, dist_loss: 0.44478264451026917
recon_loss: 0.04175593703985214, dist_loss: 0.5915002226829529
recon_loss: 0.0417545810341835, dist_loss: 0.34614822268486023
recon_loss: 0.0417533814907074, dist_loss: 0.6757583022117615
recon_loss: 0.041751839220523834, dist_loss: 0.4415428638458252
recon_loss: 0.04175035282969475, dist_loss: 0.9347946047782898
recon_loss: 0.04174887388944626, dist_loss: 0.46505412459373474
recon_loss: 0.04174734652042389, dist_loss: 0.5939598083496094
recon_loss: 0.04174575209617615, dist_loss: 1.0813028812408447
recon_loss: 0.041744232177734375, dist_loss: 0.6074778437614441
recon_loss: 0.041742634028196335, dist_loss: 0.7329839468002319
recon_loss: 0.04174095392227173, dist_loss: 0.2507423758506775
recon_loss: 0.04173931106925011, dist_loss: 0.6814868450164795
recon_loss: 0.04173768684267998, dist_loss: 1.1660337448120117
recon_loss: 0.04173607379198074, dist_loss: 0.9309015274047852
recon_loss: 0.041734278202056885, dist_loss: 0.5520373582839966
recon_loss: 0.04173235222697258, dist_loss: 0.5271798968315125
recon_loss: 0.04173007234930992, dist_loss: 0.6216652393341064
recon_loss: 0.04172772169113159, dist_loss: 0.8234138488769531
recon_loss: 0.041725803166627884, dist_loss: 0.9902573823928833
recon_loss: 0.0417240746319294, dist_loss: 0.4348031282424927
recon_loss: 0.041722558438777924, dist_loss: 0.6968001127243042
recon_loss: 0.04172096028923988, dist_loss: 0.6810321807861328
recon_loss: 0.04171938821673393, dist_loss: 0.6736818552017212
recon_loss: 0.04171786829829216, dist_loss: 0.6269199252128601
recon_loss: 0.04171646013855934, dist_loss: 0.4499961733818054
recon_loss: 0.04171501100063324, dist_loss: 0.8376032114028931
recon_loss: 0.04171357303857803, dist_loss: 0.800118088722229
recon_loss: 0.04171207547187805, dist_loss: 0.686741292476654
recon_loss: 0.041710857301950455, dist_loss: 1.021353840827942
recon_loss: 0.04170968383550644, dist_loss: 0.6070276498794556
recon_loss: 0.04170854762196541, dist_loss: 0.40879005193710327
recon_loss: 0.04170724377036095, dist_loss: 0.7131724953651428
recon_loss: 0.0417059101164341, dist_loss: 0.595064640045166
recon_loss: 0.04170461371541023, dist_loss: 0.591886043548584
recon_loss: 0.04170330986380577, dist_loss: 0.9090315103530884
recon_loss: 0.04170219600200653, dist_loss: 1.068094253540039
recon_loss: 0.041700951755046844, dist_loss: 0.7885161638259888
recon_loss: 0.04169995337724686, dist_loss: 0.48351582884788513
recon_loss: 0.04169875383377075, dist_loss: 0.768942654132843
recon_loss: 0.04169769212603569, dist_loss: 0.5603936910629272
recon_loss: 0.04169657826423645, dist_loss: 0.8166959285736084
recon_loss: 0.0416954904794693, dist_loss: 0.6996181011199951
recon_loss: 0.041694674640893936, dist_loss: 0.8046916723251343
recon_loss: 0.04169381409883499, dist_loss: 0.9021146297454834
recon_loss: 0.04169302433729172, dist_loss: 0.8007142543792725
recon_loss: 0.04169229790568352, dist_loss: 0.5085403919219971
recon_loss: 0.04169156029820442, dist_loss: 0.5497627258300781
recon_loss: 0.04169066622853279, dist_loss: 0.8471114635467529
recon_loss: 0.04168982058763504, dist_loss: 0.4401698112487793
recon_loss: 0.04168890044093132, dist_loss: 0.783759355545044
recon_loss: 0.04168800637125969, dist_loss: 0.7147800922393799
recon_loss: 0.04168729856610298, dist_loss: 0.8716554641723633
recon_loss: 0.04168674349784851, dist_loss: 0.4957196116447449
recon_loss: 0.041686367243528366, dist_loss: 0.5162032246589661
recon_loss: 0.04168596491217613, dist_loss: 0.36664879322052
recon_loss: 0.041685499250888824, dist_loss: 1.2224524021148682
recon_loss: 0.041684992611408234, dist_loss: 0.9046205282211304
recon_loss: 0.04168443754315376, dist_loss: 0.48638203740119934
recon_loss: 0.04168364405632019, dist_loss: 0.5460953712463379
recon_loss: 0.04168277606368065, dist_loss: 0.442985475063324
recon_loss: 0.041682351380586624, dist_loss: 0.6252279281616211
recon_loss: 0.04168222099542618, dist_loss: 0.5908294916152954
recon_loss: 0.041681889444589615, dist_loss: 0.9815571308135986
recon_loss: 0.0416812002658844, dist_loss: 0.8652577996253967
recon_loss: 0.04167997092008591, dist_loss: 0.5610749125480652
recon_loss: 0.041679125279188156, dist_loss: 0.9351403117179871
recon_loss: 0.04167832434177399, dist_loss: 0.5393359065055847
recon_loss: 0.04167766124010086, dist_loss: 0.6874181032180786
recon_loss: 0.04167719930410385, dist_loss: 0.5193634033203125
recon_loss: 0.04167669266462326, dist_loss: 0.643058717250824
recon_loss: 0.041675738990306854, dist_loss: 0.770481288433075
recon_loss: 0.04167500510811806, dist_loss: 1.1039259433746338
recon_loss: 0.0416741669178009, dist_loss: 0.4836651682853699
recon_loss: 0.041673045605421066, dist_loss: 0.5508880615234375
recon_loss: 0.041671738028526306, dist_loss: 0.7446873188018799
recon_loss: 0.041670192033052444, dist_loss: 0.6102619767189026
recon_loss: 0.0416688546538353, dist_loss: 0.7303760051727295
recon_loss: 0.041667450219392776, dist_loss: 0.7679259777069092
recon_loss: 0.04166654124855995, dist_loss: 0.5707838535308838
recon_loss: 0.04166543856263161, dist_loss: 0.9477813839912415
recon_loss: 0.04166443645954132, dist_loss: 0.4537489414215088
recon_loss: 0.041663359850645065, dist_loss: 0.5226100087165833
recon_loss: 0.0416623130440712, dist_loss: 0.5636289119720459
recon_loss: 0.04166139289736748, dist_loss: 0.746601939201355
recon_loss: 0.0416601225733757, dist_loss: 0.791521430015564
recon_loss: 0.04165879264473915, dist_loss: 0.2279869168996811
recon_loss: 0.04165772348642349, dist_loss: 1.214613676071167
recon_loss: 0.04165686294436455, dist_loss: 1.0989655256271362
recon_loss: 0.04165620729327202, dist_loss: 0.8576240539550781
recon_loss: 0.04165513440966606, dist_loss: 0.8811686038970947
recon_loss: 0.041653625667095184, dist_loss: 0.9035018682479858
recon_loss: 0.041652120649814606, dist_loss: 0.6794103384017944
recon_loss: 0.04165074601769447, dist_loss: 1.184319019317627
recon_loss: 0.041649602353572845, dist_loss: 0.753106415271759
recon_loss: 0.041648417711257935, dist_loss: 1.306490182876587
recon_loss: 0.041647594422101974, dist_loss: 0.8073999881744385
recon_loss: 0.04164688661694527, dist_loss: 0.5186640024185181
recon_loss: 0.04164613038301468, dist_loss: 0.5328787565231323
recon_loss: 0.04164543002843857, dist_loss: 0.6087420582771301
recon_loss: 0.041644614189863205, dist_loss: 0.9251665472984314
recon_loss: 0.04164380207657814, dist_loss: 0.6030240058898926
recon_loss: 0.041643176227808, dist_loss: 0.8150810599327087
recon_loss: 0.04164259508252144, dist_loss: 0.7700453400611877
recon_loss: 0.04164205119013786, dist_loss: 0.8580197095870972
recon_loss: 0.041641540825366974, dist_loss: 0.9430239200592041
recon_loss: 0.04164082929491997, dist_loss: 0.9581093788146973
recon_loss: 0.04164014011621475, dist_loss: 0.5337944030761719
recon_loss: 0.04163927584886551, dist_loss: 0.6946505308151245
recon_loss: 0.04163862019777298, dist_loss: 0.564306914806366
Pre-training Epoch 12:  75%|███████▍  | 274/367 [00:01<00:00, 191.20it/s]Pre-training Epoch 12:  80%|████████  | 294/367 [00:01<00:00, 191.99it/s]Pre-training Epoch 12:  86%|████████▌ | 314/367 [00:01<00:00, 192.81it/s]Pre-training Epoch 12:  91%|█████████ | 334/367 [00:01<00:00, 183.32it/s]Pre-training Epoch 12:  96%|█████████▌| 353/367 [00:01<00:00, 175.84it/s]Pre-training Epoch 12: 100%|██████████| 367/367 [00:01<00:00, 183.87it/s]
recon_loss: 0.041637688875198364, dist_loss: 0.8220013380050659
recon_loss: 0.04163675010204315, dist_loss: 0.5411815047264099
recon_loss: 0.04163544625043869, dist_loss: 0.8527551293373108
recon_loss: 0.04163413867354393, dist_loss: 0.6071813702583313
recon_loss: 0.0416330024600029, dist_loss: 0.5573991537094116
recon_loss: 0.041631732136011124, dist_loss: 0.5453957915306091
recon_loss: 0.041630182415246964, dist_loss: 0.5481027364730835
recon_loss: 0.04162885248661041, dist_loss: 0.7647852301597595
recon_loss: 0.041627436876297, dist_loss: 0.8342301845550537
recon_loss: 0.041625481098890305, dist_loss: 1.0020273923873901
recon_loss: 0.04162360355257988, dist_loss: 0.603950023651123
recon_loss: 0.041621796786785126, dist_loss: 0.4199560284614563
recon_loss: 0.04162007197737694, dist_loss: 0.8377238512039185
recon_loss: 0.04161844030022621, dist_loss: 0.6394959688186646
recon_loss: 0.041616830974817276, dist_loss: 1.0619820356369019
recon_loss: 0.04161537438631058, dist_loss: 0.6192317008972168
recon_loss: 0.04161382094025612, dist_loss: 0.6392500996589661
recon_loss: 0.04161223769187927, dist_loss: 0.6490723490715027
recon_loss: 0.041610561311244965, dist_loss: 0.6407545208930969
recon_loss: 0.041609033942222595, dist_loss: 0.5751981139183044
recon_loss: 0.04160743206739426, dist_loss: 0.7392558455467224
recon_loss: 0.04160572960972786, dist_loss: 0.5184386968612671
recon_loss: 0.04160408675670624, dist_loss: 0.6944836378097534
recon_loss: 0.041602350771427155, dist_loss: 0.7266193628311157
recon_loss: 0.041600488126277924, dist_loss: 1.3192319869995117
recon_loss: 0.04159874469041824, dist_loss: 0.770840048789978
recon_loss: 0.04159706458449364, dist_loss: 0.6061457991600037
recon_loss: 0.04159535467624664, dist_loss: 0.6312128901481628
recon_loss: 0.04159381240606308, dist_loss: 1.04701828956604
recon_loss: 0.041592344641685486, dist_loss: 1.03146231174469
recon_loss: 0.04159093275666237, dist_loss: 0.6691120862960815
recon_loss: 0.041589442640542984, dist_loss: 0.7330181002616882
recon_loss: 0.0415879487991333, dist_loss: 0.746238648891449
recon_loss: 0.04158654808998108, dist_loss: 0.7845791578292847
recon_loss: 0.041585199534893036, dist_loss: 0.7331819534301758
recon_loss: 0.041584063321352005, dist_loss: 0.8390815258026123
recon_loss: 0.04158296436071396, dist_loss: 0.701885461807251
recon_loss: 0.04158187657594681, dist_loss: 0.29631298780441284
recon_loss: 0.04158083349466324, dist_loss: 0.5172997117042542
recon_loss: 0.041579704731702805, dist_loss: 0.6723654270172119
recon_loss: 0.041578639298677444, dist_loss: 1.0157883167266846
recon_loss: 0.04157737269997597, dist_loss: 0.6256976127624512
recon_loss: 0.0415763296186924, dist_loss: 0.6927489638328552
recon_loss: 0.04157538339495659, dist_loss: 0.5609126091003418
recon_loss: 0.041574545204639435, dist_loss: 0.6228722333908081
recon_loss: 0.04157356917858124, dist_loss: 0.964207112789154
recon_loss: 0.04157223924994469, dist_loss: 0.8226649761199951
recon_loss: 0.04157101735472679, dist_loss: 1.0388368368148804
recon_loss: 0.04157016798853874, dist_loss: 0.9758931398391724
recon_loss: 0.041569266468286514, dist_loss: 0.9019272327423096
recon_loss: 0.04156796634197235, dist_loss: 0.4856939911842346
recon_loss: 0.04156671091914177, dist_loss: 0.6751985549926758
recon_loss: 0.04156513139605522, dist_loss: 0.7256064414978027
recon_loss: 0.04156387224793434, dist_loss: 0.786521315574646
recon_loss: 0.04156206548213959, dist_loss: 0.6532678008079529
recon_loss: 0.041560325771570206, dist_loss: 0.8723657131195068
recon_loss: 0.04155843332409859, dist_loss: 0.5394884347915649
recon_loss: 0.04155666381120682, dist_loss: 0.7299537658691406
recon_loss: 0.04155505448579788, dist_loss: 0.640832245349884
recon_loss: 0.04155327379703522, dist_loss: 0.695510983467102
recon_loss: 0.04155145585536957, dist_loss: 0.7683093547821045
recon_loss: 0.0415496900677681, dist_loss: 0.542854905128479
recon_loss: 0.041548166424036026, dist_loss: 0.6384454965591431
recon_loss: 0.04154668375849724, dist_loss: 0.5780709981918335
recon_loss: 0.04154522344470024, dist_loss: 0.7738661766052246
recon_loss: 0.04154374822974205, dist_loss: 0.5410897135734558
recon_loss: 0.04154237359762192, dist_loss: 0.5551496744155884
recon_loss: 0.041541215032339096, dist_loss: 0.7622718811035156
recon_loss: 0.04153997823596001, dist_loss: 0.6792775988578796
recon_loss: 0.041538793593645096, dist_loss: 0.8905535936355591
recon_loss: 0.04153773933649063, dist_loss: 1.242648720741272
recon_loss: 0.041536636650562286, dist_loss: 0.6499406099319458
recon_loss: 0.04153558239340782, dist_loss: 0.4135677218437195
recon_loss: 0.04153447598218918, dist_loss: 0.4424455463886261
recon_loss: 0.041533056646585464, dist_loss: 0.746225893497467
recon_loss: 0.04153170809149742, dist_loss: 0.4689572751522064
recon_loss: 0.0415305532515049, dist_loss: 0.7090754508972168
recon_loss: 0.04152965545654297, dist_loss: 0.6086534261703491
recon_loss: 0.0415286123752594, dist_loss: 0.9170824289321899
recon_loss: 0.0415271520614624, dist_loss: 0.7255096435546875
recon_loss: 0.04152578487992287, dist_loss: 0.9091159105300903
recon_loss: 0.041524287313222885, dist_loss: 0.8061745166778564
recon_loss: 0.041523005813360214, dist_loss: 0.4403585195541382
recon_loss: 0.04152165353298187, dist_loss: 1.0139431953430176
recon_loss: 0.041520681232213974, dist_loss: 0.5700386762619019
recon_loss: 0.041519757360219955, dist_loss: 0.8466871976852417
recon_loss: 0.04151879996061325, dist_loss: 0.49952977895736694
recon_loss: 0.04151780903339386, dist_loss: 0.6107354164123535
recon_loss: 0.041516661643981934, dist_loss: 0.418290913105011
recon_loss: 0.041515398770570755, dist_loss: 0.673035740852356
recon_loss: 0.041513800621032715, dist_loss: 0.585848867893219
recon_loss: 0.04151219129562378, dist_loss: 0.650416910648346
recon_loss: 0.04151081293821335, dist_loss: 0.4885474443435669
recon_loss: 0.041509609669446945, dist_loss: 0.7576451301574707
recon_loss: 0.041508350521326065, dist_loss: 0.9189020395278931
recon_loss: 0.04150707274675369, dist_loss: 0.7809591293334961
recon_loss: 0.04150582104921341, dist_loss: 0.7476500272750854
recon_loss: 0.04150494933128357, dist_loss: 0.5463693141937256
recon_loss: 0.041503917425870895, dist_loss: 0.4928945302963257
recon_loss: 0.041502851992845535, dist_loss: 0.7860661745071411
recon_loss: 0.04150184616446495, dist_loss: 0.7685434818267822
recon_loss: 0.04150083661079407, dist_loss: 1.457247257232666
recon_loss: 0.04149964451789856, dist_loss: 1.0534381866455078
recon_loss: 0.04149835556745529, dist_loss: 0.6634600162506104
recon_loss: 0.04149683937430382, dist_loss: 0.6282376050949097
recon_loss: 0.041495244950056076, dist_loss: 0.5855550765991211
recon_loss: 0.04149366542696953, dist_loss: 0.6030556559562683
recon_loss: 0.041492097079753876, dist_loss: 0.465792715549469
recon_loss: 0.041490498930215836, dist_loss: 1.1089998483657837
Pre-training Epoch 13:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 13:   5%|▌         | 19/367 [00:00<00:01, 188.30it/s]Pre-training Epoch 13:  10%|█         | 38/367 [00:00<00:01, 189.27it/s]Pre-training Epoch 13:  16%|█▌        | 57/367 [00:00<00:01, 185.86it/s]Pre-training Epoch 13:  21%|██        | 76/367 [00:00<00:01, 184.47it/s]Pre-training Epoch 13:  26%|██▌       | 96/367 [00:00<00:01, 187.92it/s]Pre-training Epoch 13:  32%|███▏      | 116/367 [00:00<00:01, 190.00it/s]recon_loss: 0.04148904234170914, dist_loss: 0.5266681909561157
recon_loss: 0.041487645357847214, dist_loss: 0.776484489440918
recon_loss: 0.04148624464869499, dist_loss: 0.7894911766052246
recon_loss: 0.04148484393954277, dist_loss: 0.7159510850906372
recon_loss: 0.04148365184664726, dist_loss: 0.5385867953300476
recon_loss: 0.041482459753751755, dist_loss: 0.8834353089332581
recon_loss: 0.04148126021027565, dist_loss: 0.8127844929695129
recon_loss: 0.04148001968860626, dist_loss: 0.5461134314537048
recon_loss: 0.04147880896925926, dist_loss: 0.6148375272750854
recon_loss: 0.04147740826010704, dist_loss: 0.6518889665603638
recon_loss: 0.04147599637508392, dist_loss: 0.7312816381454468
recon_loss: 0.04147490859031677, dist_loss: 0.7521064281463623
recon_loss: 0.04147407412528992, dist_loss: 1.0407495498657227
recon_loss: 0.041473161429166794, dist_loss: 0.7681298851966858
recon_loss: 0.04147225245833397, dist_loss: 0.47653916478157043
recon_loss: 0.041471224278211594, dist_loss: 0.4728825092315674
recon_loss: 0.041470300406217575, dist_loss: 0.5436338186264038
recon_loss: 0.041469454765319824, dist_loss: 0.6313994526863098
recon_loss: 0.041468627750873566, dist_loss: 0.7543866634368896
recon_loss: 0.04146752879023552, dist_loss: 0.8227149844169617
recon_loss: 0.0414663627743721, dist_loss: 0.595535397529602
recon_loss: 0.0414653941988945, dist_loss: 0.4642796516418457
recon_loss: 0.04146462306380272, dist_loss: 0.46471452713012695
recon_loss: 0.04146408289670944, dist_loss: 0.3792528212070465
recon_loss: 0.04146351292729378, dist_loss: 0.6140644550323486
recon_loss: 0.04146292433142662, dist_loss: 1.0821659564971924
recon_loss: 0.04146210476756096, dist_loss: 0.8450276851654053
recon_loss: 0.04146093130111694, dist_loss: 0.5800866484642029
recon_loss: 0.04145977646112442, dist_loss: 0.41716131567955017
recon_loss: 0.041458610445261, dist_loss: 0.8645628690719604
recon_loss: 0.04145752638578415, dist_loss: 0.5133275985717773
recon_loss: 0.04145648702979088, dist_loss: 0.5540896654129028
recon_loss: 0.041455186903476715, dist_loss: 0.5275938510894775
recon_loss: 0.04145403951406479, dist_loss: 0.6092227101325989
recon_loss: 0.04145305976271629, dist_loss: 0.62006676197052
recon_loss: 0.04145197197794914, dist_loss: 0.45968541502952576
recon_loss: 0.041450731456279755, dist_loss: 0.3296660780906677
recon_loss: 0.041449397802352905, dist_loss: 0.6739839911460876
recon_loss: 0.041448138654232025, dist_loss: 0.7048203945159912
recon_loss: 0.04144665598869324, dist_loss: 0.5132156610488892
recon_loss: 0.04144534096121788, dist_loss: 1.0586159229278564
recon_loss: 0.04144377261400223, dist_loss: 0.8034313917160034
recon_loss: 0.041442278772592545, dist_loss: 0.7634097337722778
recon_loss: 0.041440874338150024, dist_loss: 1.0706052780151367
recon_loss: 0.04143946245312691, dist_loss: 0.6163337230682373
recon_loss: 0.041437938809394836, dist_loss: 0.46102234721183777
recon_loss: 0.04143655300140381, dist_loss: 0.9210882186889648
recon_loss: 0.041434817016124725, dist_loss: 0.5394567251205444
recon_loss: 0.0414329469203949, dist_loss: 0.479310542345047
recon_loss: 0.041431017220020294, dist_loss: 0.5045698285102844
recon_loss: 0.041428934782743454, dist_loss: 0.7186702489852905
recon_loss: 0.041427016258239746, dist_loss: 0.6294336318969727
recon_loss: 0.0414251983165741, dist_loss: 0.8633900880813599
recon_loss: 0.04142347723245621, dist_loss: 0.8423420190811157
recon_loss: 0.04142200946807861, dist_loss: 0.5969133377075195
recon_loss: 0.04142017662525177, dist_loss: 1.1181710958480835
recon_loss: 0.041418224573135376, dist_loss: 0.5661250352859497
recon_loss: 0.04141661152243614, dist_loss: 0.9542602300643921
recon_loss: 0.04141489788889885, dist_loss: 0.6712064743041992
recon_loss: 0.04141323268413544, dist_loss: 1.011937141418457
recon_loss: 0.041411805897951126, dist_loss: 0.6818938255310059
recon_loss: 0.041410669684410095, dist_loss: 0.5942370891571045
recon_loss: 0.041409097611904144, dist_loss: 0.9683414697647095
recon_loss: 0.04140755906701088, dist_loss: 0.9062502980232239
recon_loss: 0.04140596091747284, dist_loss: 0.8859450221061707
recon_loss: 0.041404325515031815, dist_loss: 0.6892051696777344
recon_loss: 0.04140270873904228, dist_loss: 0.755101203918457
recon_loss: 0.041400887072086334, dist_loss: 0.5141452550888062
recon_loss: 0.04139917343854904, dist_loss: 0.5215886235237122
recon_loss: 0.04139747843146324, dist_loss: 0.7010365128517151
recon_loss: 0.04139567166566849, dist_loss: 0.813910722732544
recon_loss: 0.04139387235045433, dist_loss: 0.7204264998435974
recon_loss: 0.04139213636517525, dist_loss: 0.7689002752304077
recon_loss: 0.04139035940170288, dist_loss: 0.6434413194656372
recon_loss: 0.04138889163732529, dist_loss: 0.5954692363739014
recon_loss: 0.04138736426830292, dist_loss: 0.5546765327453613
recon_loss: 0.04138565808534622, dist_loss: 0.5628505349159241
recon_loss: 0.041383981704711914, dist_loss: 0.7052677869796753
recon_loss: 0.04138237237930298, dist_loss: 0.7295128107070923
recon_loss: 0.04138088598847389, dist_loss: 0.7114219665527344
recon_loss: 0.041379619389772415, dist_loss: 0.3907198905944824
recon_loss: 0.04137818515300751, dist_loss: 0.5345394015312195
recon_loss: 0.041376736015081406, dist_loss: 0.7216370105743408
recon_loss: 0.04137522354722023, dist_loss: 0.8546333312988281
recon_loss: 0.04137367010116577, dist_loss: 1.0967576503753662
recon_loss: 0.0413721464574337, dist_loss: 0.5781714916229248
recon_loss: 0.04137054458260536, dist_loss: 0.6580224633216858
recon_loss: 0.041369155049324036, dist_loss: 0.9077457189559937
recon_loss: 0.04136783629655838, dist_loss: 0.6093316078186035
recon_loss: 0.041366323828697205, dist_loss: 0.7557922005653381
recon_loss: 0.04136476293206215, dist_loss: 0.4641650319099426
recon_loss: 0.04136327654123306, dist_loss: 1.074022889137268
recon_loss: 0.04136194288730621, dist_loss: 0.658137857913971
recon_loss: 0.04136061668395996, dist_loss: 0.3982561230659485
recon_loss: 0.0413593053817749, dist_loss: 0.8621331453323364
recon_loss: 0.04135797172784805, dist_loss: 0.6778755187988281
recon_loss: 0.04135666415095329, dist_loss: 0.8141734004020691
recon_loss: 0.041354794055223465, dist_loss: 0.6530952453613281
recon_loss: 0.0413530208170414, dist_loss: 0.5917366743087769
recon_loss: 0.04135141521692276, dist_loss: 0.789474606513977
recon_loss: 0.04135026037693024, dist_loss: 0.4830450415611267
recon_loss: 0.041349247097969055, dist_loss: 0.33733153343200684
recon_loss: 0.041348379105329514, dist_loss: 1.3030815124511719
recon_loss: 0.04134739562869072, dist_loss: 0.869889497756958
recon_loss: 0.041346486657857895, dist_loss: 0.6105080842971802
recon_loss: 0.04134540632367134, dist_loss: 0.3298974633216858
recon_loss: 0.04134426265954971, dist_loss: 0.7855871915817261
recon_loss: 0.041343286633491516, dist_loss: 0.5047621130943298
recon_loss: 0.04134241119027138, dist_loss: 0.5477375984191895
recon_loss: 0.041341494768857956, dist_loss: 0.5982113480567932
recon_loss: 0.04134076088666916, dist_loss: 0.6663402318954468
recon_loss: 0.04133942350745201, dist_loss: 0.7067986726760864
recon_loss: 0.041338302195072174, dist_loss: 0.3948304057121277
recon_loss: 0.0413372740149498, dist_loss: 0.7306729555130005
recon_loss: 0.04133587330579758, dist_loss: 1.214046597480774
recon_loss: 0.04133479297161102, dist_loss: 0.47821903228759766
recon_loss: 0.041333846747875214, dist_loss: 0.7924625277519226
recon_loss: 0.04133277386426926, dist_loss: 0.8105747699737549
recon_loss: 0.04133155569434166, dist_loss: 1.031416893005371
recon_loss: 0.041330136358737946, dist_loss: 0.9876554012298584
recon_loss: 0.04132876545190811, dist_loss: 0.5322593450546265
recon_loss: 0.041327543556690216, dist_loss: 1.0061233043670654
recon_loss: 0.04132653772830963, dist_loss: 0.6856328845024109
recon_loss: 0.041325442492961884, dist_loss: 0.45762208104133606
recon_loss: 0.04132438451051712, dist_loss: 0.42469340562820435
recon_loss: 0.04132341220974922, dist_loss: 0.32086318731307983
recon_loss: 0.04132247716188431, dist_loss: 0.6093453168869019
recon_loss: 0.041321612894535065, dist_loss: 0.8333854079246521
recon_loss: 0.0413210429251194, dist_loss: 0.7271983623504639
Pre-training Epoch 13:  37%|███▋      | 136/367 [00:00<00:01, 191.30it/s]Pre-training Epoch 13:  43%|████▎     | 156/367 [00:00<00:01, 192.11it/s]Pre-training Epoch 13:  48%|████▊     | 176/367 [00:00<00:00, 192.71it/s]Pre-training Epoch 13:  53%|█████▎    | 196/367 [00:01<00:00, 186.94it/s]Pre-training Epoch 13:  59%|█████▊    | 215/367 [00:01<00:00, 178.95it/s]Pre-training Epoch 13:  63%|██████▎   | 233/367 [00:01<00:00, 173.95it/s]Pre-training Epoch 13:  68%|██████▊   | 251/367 [00:01<00:00, 166.36it/s]recon_loss: 0.04132017865777016, dist_loss: 0.6408798098564148
recon_loss: 0.04131907597184181, dist_loss: 0.7360539436340332
recon_loss: 0.04131762310862541, dist_loss: 0.5876563787460327
recon_loss: 0.04131639003753662, dist_loss: 0.6170885562896729
recon_loss: 0.04131516441702843, dist_loss: 0.5019823908805847
recon_loss: 0.04131390526890755, dist_loss: 0.6578950881958008
recon_loss: 0.04131245240569115, dist_loss: 0.7607640624046326
recon_loss: 0.04131126031279564, dist_loss: 0.5598998069763184
recon_loss: 0.041310299187898636, dist_loss: 0.888651967048645
recon_loss: 0.041308753192424774, dist_loss: 0.5956133604049683
recon_loss: 0.04130738601088524, dist_loss: 0.5923305749893188
recon_loss: 0.04130621626973152, dist_loss: 1.1002049446105957
recon_loss: 0.041305143386125565, dist_loss: 0.5934865474700928
recon_loss: 0.0413038395345211, dist_loss: 0.7156185507774353
recon_loss: 0.041302330791950226, dist_loss: 0.6234695315361023
recon_loss: 0.041300851851701736, dist_loss: 0.8451896905899048
recon_loss: 0.04129922762513161, dist_loss: 0.3835379183292389
recon_loss: 0.041297607123851776, dist_loss: 1.176908016204834
recon_loss: 0.04129599407315254, dist_loss: 0.48840317130088806
recon_loss: 0.0412946380674839, dist_loss: 0.6248965263366699
recon_loss: 0.04129326343536377, dist_loss: 0.5790131092071533
recon_loss: 0.04129203036427498, dist_loss: 1.306837558746338
recon_loss: 0.04129130393266678, dist_loss: 0.6365550756454468
recon_loss: 0.04129057005047798, dist_loss: 0.4717889130115509
recon_loss: 0.04128986969590187, dist_loss: 0.9715955853462219
recon_loss: 0.04128890484571457, dist_loss: 1.2400717735290527
recon_loss: 0.04128764569759369, dist_loss: 0.6129088997840881
recon_loss: 0.04128632694482803, dist_loss: 0.6710532903671265
recon_loss: 0.0412849560379982, dist_loss: 0.7896679639816284
recon_loss: 0.041283756494522095, dist_loss: 0.41963639855384827
recon_loss: 0.041282352060079575, dist_loss: 0.49173077940940857
recon_loss: 0.04128080606460571, dist_loss: 0.6460540294647217
recon_loss: 0.04127909243106842, dist_loss: 0.9659636616706848
recon_loss: 0.04127773270010948, dist_loss: 0.7961989641189575
recon_loss: 0.04127610847353935, dist_loss: 0.7166833877563477
recon_loss: 0.04127431660890579, dist_loss: 0.8284198045730591
recon_loss: 0.041272275149822235, dist_loss: 0.7840004563331604
recon_loss: 0.04127010330557823, dist_loss: 0.8795279264450073
recon_loss: 0.0412682481110096, dist_loss: 0.35033488273620605
recon_loss: 0.04126650467514992, dist_loss: 0.5911298394203186
recon_loss: 0.041265033185482025, dist_loss: 0.5127004384994507
recon_loss: 0.04126352444291115, dist_loss: 0.7171467542648315
recon_loss: 0.04126188904047012, dist_loss: 0.62954181432724
recon_loss: 0.04126010462641716, dist_loss: 0.6068931818008423
recon_loss: 0.04125869274139404, dist_loss: 0.6634091734886169
recon_loss: 0.041257306933403015, dist_loss: 1.0658354759216309
recon_loss: 0.04125569015741348, dist_loss: 0.5682387351989746
recon_loss: 0.04125407338142395, dist_loss: 1.1692230701446533
recon_loss: 0.04125235602259636, dist_loss: 0.652302622795105
recon_loss: 0.04125078022480011, dist_loss: 0.21867218613624573
recon_loss: 0.04124904051423073, dist_loss: 0.5854223966598511
recon_loss: 0.04124746471643448, dist_loss: 0.4296150207519531
recon_loss: 0.04124579578638077, dist_loss: 0.662055492401123
recon_loss: 0.041244085878133774, dist_loss: 0.9238821268081665
recon_loss: 0.04124215617775917, dist_loss: 0.5587294101715088
recon_loss: 0.041240144520998, dist_loss: 0.6334795951843262
recon_loss: 0.04123818874359131, dist_loss: 1.1143739223480225
recon_loss: 0.041236188262701035, dist_loss: 0.5147786140441895
recon_loss: 0.04123459383845329, dist_loss: 0.5470532178878784
recon_loss: 0.041233133524656296, dist_loss: 0.7654693126678467
recon_loss: 0.04123172163963318, dist_loss: 0.680328905582428
recon_loss: 0.041230324655771255, dist_loss: 1.078906774520874
recon_loss: 0.04122919216752052, dist_loss: 0.468266099691391
recon_loss: 0.04122830182313919, dist_loss: 0.5804178714752197
recon_loss: 0.04122759401798248, dist_loss: 0.5247291922569275
recon_loss: 0.041227005422115326, dist_loss: 0.6105583310127258
recon_loss: 0.04122632369399071, dist_loss: 0.44523024559020996
recon_loss: 0.04122565686702728, dist_loss: 0.46198058128356934
recon_loss: 0.04122551158070564, dist_loss: 0.907103419303894
recon_loss: 0.04122491925954819, dist_loss: 1.141448736190796
recon_loss: 0.041224393993616104, dist_loss: 1.1239781379699707
recon_loss: 0.04122393578290939, dist_loss: 1.0999836921691895
recon_loss: 0.04122326523065567, dist_loss: 0.623673141002655
recon_loss: 0.04122258722782135, dist_loss: 0.5854630470275879
recon_loss: 0.0412214957177639, dist_loss: 0.5529088973999023
recon_loss: 0.0412205271422863, dist_loss: 0.870598554611206
recon_loss: 0.04121941328048706, dist_loss: 1.0318820476531982
recon_loss: 0.04121839627623558, dist_loss: 0.31355834007263184
recon_loss: 0.04121730849146843, dist_loss: 0.7896349430084229
recon_loss: 0.041216518729925156, dist_loss: 0.7455066442489624
recon_loss: 0.04121578484773636, dist_loss: 0.8641566038131714
recon_loss: 0.04121554270386696, dist_loss: 0.6023479104042053
recon_loss: 0.041215285658836365, dist_loss: 0.8308958411216736
recon_loss: 0.04121462255716324, dist_loss: 0.9282151460647583
recon_loss: 0.04121372848749161, dist_loss: 0.4865424931049347
recon_loss: 0.041212692856788635, dist_loss: 0.5796744227409363
recon_loss: 0.041211437433958054, dist_loss: 0.583221435546875
recon_loss: 0.041210077702999115, dist_loss: 0.5753093957901001
recon_loss: 0.04120855778455734, dist_loss: 0.9338305592536926
recon_loss: 0.04120723158121109, dist_loss: 0.576736569404602
recon_loss: 0.04120542109012604, dist_loss: 0.6833674907684326
recon_loss: 0.04120365157723427, dist_loss: 0.4460669755935669
recon_loss: 0.04120220988988876, dist_loss: 0.6720995903015137
recon_loss: 0.04120069369673729, dist_loss: 0.676488995552063
recon_loss: 0.04119914397597313, dist_loss: 0.6075547933578491
recon_loss: 0.041197340935468674, dist_loss: 0.5855453014373779
recon_loss: 0.041195765137672424, dist_loss: 0.7757803201675415
recon_loss: 0.04119395837187767, dist_loss: 0.6522419452667236
recon_loss: 0.04119225963950157, dist_loss: 0.5305562019348145
recon_loss: 0.041190408170223236, dist_loss: 0.7522664666175842
recon_loss: 0.04118838533759117, dist_loss: 0.43399348855018616
recon_loss: 0.041186437010765076, dist_loss: 0.616558313369751
recon_loss: 0.041184354573488235, dist_loss: 0.6270736455917358
recon_loss: 0.04118243604898453, dist_loss: 0.6776127815246582
recon_loss: 0.04118047654628754, dist_loss: 0.8639979362487793
recon_loss: 0.041178442537784576, dist_loss: 0.4598936140537262
recon_loss: 0.04117639735341072, dist_loss: 0.5044629573822021
recon_loss: 0.04117431864142418, dist_loss: 0.74387127161026
recon_loss: 0.04117228090763092, dist_loss: 0.30369389057159424
recon_loss: 0.04117023944854736, dist_loss: 1.1814384460449219
recon_loss: 0.04116855189204216, dist_loss: 0.9449571371078491
recon_loss: 0.04116646945476532, dist_loss: 0.5419788360595703
recon_loss: 0.041164640337228775, dist_loss: 0.510944128036499
recon_loss: 0.04116269573569298, dist_loss: 0.7273718118667603
recon_loss: 0.04116079956293106, dist_loss: 0.3743249773979187
recon_loss: 0.041159018874168396, dist_loss: 0.5736343860626221
recon_loss: 0.04115733504295349, dist_loss: 0.5934205651283264
recon_loss: 0.04115596413612366, dist_loss: 0.444912850856781
recon_loss: 0.041154250502586365, dist_loss: 0.8099521398544312
recon_loss: 0.041152473539114, dist_loss: 0.5694537162780762
recon_loss: 0.04115089774131775, dist_loss: 1.2641900777816772
recon_loss: 0.04114958643913269, dist_loss: 0.9174762964248657
recon_loss: 0.041148457676172256, dist_loss: 0.3654020130634308
recon_loss: 0.041147589683532715, dist_loss: 0.8040437698364258
recon_loss: 0.04114693030714989, dist_loss: 0.940952718257904
recon_loss: 0.04114632308483124, dist_loss: 0.7289392948150635
recon_loss: 0.04114537686109543, dist_loss: 1.008476972579956
recon_loss: 0.04114460200071335, dist_loss: 0.26173534989356995
recon_loss: 0.041143983602523804, dist_loss: 0.49103397130966187
Pre-training Epoch 13:  73%|███████▎  | 268/367 [00:01<00:00, 160.49it/s]Pre-training Epoch 13:  78%|███████▊  | 285/367 [00:01<00:00, 157.82it/s]Pre-training Epoch 13:  82%|████████▏ | 301/367 [00:01<00:00, 156.19it/s]Pre-training Epoch 13:  86%|████████▋ | 317/367 [00:01<00:00, 153.98it/s]Pre-training Epoch 13:  91%|█████████ | 333/367 [00:01<00:00, 152.92it/s]Pre-training Epoch 13:  95%|█████████▌| 350/367 [00:02<00:00, 155.71it/s]Pre-training Epoch 13: 100%|██████████| 367/367 [00:02<00:00, 172.56it/s]
recon_loss: 0.04114355146884918, dist_loss: 0.7225620746612549
recon_loss: 0.041142720729112625, dist_loss: 0.6013367176055908
recon_loss: 0.04114207252860069, dist_loss: 0.643970251083374
recon_loss: 0.04114101082086563, dist_loss: 0.7841489315032959
recon_loss: 0.0411398746073246, dist_loss: 0.8048738241195679
recon_loss: 0.041138842701911926, dist_loss: 0.948932409286499
recon_loss: 0.04113763943314552, dist_loss: 0.613105297088623
recon_loss: 0.04113628342747688, dist_loss: 1.1366727352142334
recon_loss: 0.04113507270812988, dist_loss: 0.6162194609642029
recon_loss: 0.041133537888526917, dist_loss: 0.5511215329170227
recon_loss: 0.04113191366195679, dist_loss: 0.5687172412872314
recon_loss: 0.04113055393099785, dist_loss: 0.941702127456665
recon_loss: 0.041128747165203094, dist_loss: 0.5829679369926453
recon_loss: 0.04112708568572998, dist_loss: 1.1052055358886719
recon_loss: 0.041125159710645676, dist_loss: 0.7297451496124268
recon_loss: 0.0411229133605957, dist_loss: 0.5077472925186157
recon_loss: 0.04112091287970543, dist_loss: 1.112640142440796
recon_loss: 0.04111867398023605, dist_loss: 0.5839086771011353
recon_loss: 0.041116613894701004, dist_loss: 0.6695277690887451
recon_loss: 0.041114695370197296, dist_loss: 0.6818881630897522
recon_loss: 0.04111288860440254, dist_loss: 0.9427957534790039
recon_loss: 0.04111100360751152, dist_loss: 0.7833594679832458
recon_loss: 0.04110932722687721, dist_loss: 0.6701595783233643
recon_loss: 0.04110731557011604, dist_loss: 0.3304448127746582
recon_loss: 0.041105274111032486, dist_loss: 1.1385438442230225
recon_loss: 0.04110340401530266, dist_loss: 0.5408066511154175
recon_loss: 0.04110151529312134, dist_loss: 0.9865689873695374
recon_loss: 0.041099656373262405, dist_loss: 0.42180341482162476
recon_loss: 0.041098013520240784, dist_loss: 0.8645703792572021
recon_loss: 0.04109642654657364, dist_loss: 0.5293130874633789
recon_loss: 0.04109468311071396, dist_loss: 0.44066286087036133
recon_loss: 0.04109290987253189, dist_loss: 0.6195414066314697
recon_loss: 0.04109121114015579, dist_loss: 0.708780825138092
recon_loss: 0.04108920693397522, dist_loss: 0.8347489833831787
recon_loss: 0.04108741506934166, dist_loss: 0.8064725995063782
recon_loss: 0.04108545929193497, dist_loss: 0.8373711109161377
recon_loss: 0.041083939373493195, dist_loss: 0.5239408016204834
recon_loss: 0.04108254238963127, dist_loss: 0.5061331987380981
recon_loss: 0.04108097031712532, dist_loss: 0.7420697808265686
recon_loss: 0.04107945039868355, dist_loss: 0.5767754912376404
recon_loss: 0.04107831045985222, dist_loss: 0.3615001142024994
recon_loss: 0.04107731580734253, dist_loss: 0.7441002130508423
recon_loss: 0.0410761795938015, dist_loss: 0.7511091232299805
recon_loss: 0.04107506945729256, dist_loss: 1.1326773166656494
recon_loss: 0.041073888540267944, dist_loss: 0.4537970721721649
recon_loss: 0.04107268154621124, dist_loss: 0.8758853673934937
recon_loss: 0.041071243584156036, dist_loss: 0.8144823312759399
recon_loss: 0.04106976091861725, dist_loss: 0.751764178276062
recon_loss: 0.041068196296691895, dist_loss: 0.3802371919155121
recon_loss: 0.04106665402650833, dist_loss: 0.9262573719024658
recon_loss: 0.04106500744819641, dist_loss: 0.7855454087257385
recon_loss: 0.041063275188207626, dist_loss: 1.0337698459625244
recon_loss: 0.04106137156486511, dist_loss: 0.4149649441242218
recon_loss: 0.04105951637029648, dist_loss: 0.8409950733184814
recon_loss: 0.041058026254177094, dist_loss: 0.7705659866333008
recon_loss: 0.04105684161186218, dist_loss: 0.814293384552002
recon_loss: 0.041055403649806976, dist_loss: 0.3122037947177887
recon_loss: 0.04105392098426819, dist_loss: 1.000706434249878
recon_loss: 0.04105241969227791, dist_loss: 0.5478093028068542
recon_loss: 0.041051022708415985, dist_loss: 0.9537212252616882
recon_loss: 0.041049644351005554, dist_loss: 0.622008204460144
recon_loss: 0.04104848951101303, dist_loss: 1.0552799701690674
recon_loss: 0.04104703664779663, dist_loss: 0.502838134765625
recon_loss: 0.041045013815164566, dist_loss: 0.5437763929367065
recon_loss: 0.04104306921362877, dist_loss: 0.714937686920166
recon_loss: 0.041041094809770584, dist_loss: 0.7928673028945923
recon_loss: 0.04103910177946091, dist_loss: 0.6469783782958984
recon_loss: 0.04103729501366615, dist_loss: 0.7364606261253357
recon_loss: 0.041035789996385574, dist_loss: 0.8643741011619568
recon_loss: 0.04103412851691246, dist_loss: 0.7008239030838013
recon_loss: 0.0410323329269886, dist_loss: 0.44296571612358093
recon_loss: 0.04103079065680504, dist_loss: 0.5848621129989624
recon_loss: 0.04102908819913864, dist_loss: 0.5767846703529358
recon_loss: 0.041027527302503586, dist_loss: 0.6839346885681152
recon_loss: 0.04102559760212898, dist_loss: 0.544468879699707
recon_loss: 0.041023824363946915, dist_loss: 0.8978220224380493
recon_loss: 0.04102187976241112, dist_loss: 1.0470473766326904
recon_loss: 0.041019707918167114, dist_loss: 0.6378693580627441
recon_loss: 0.04101752117276192, dist_loss: 1.0689046382904053
recon_loss: 0.041015129536390305, dist_loss: 0.5962331295013428
recon_loss: 0.04101278632879257, dist_loss: 1.4008822441101074
recon_loss: 0.04101031646132469, dist_loss: 0.3638928234577179
recon_loss: 0.041007980704307556, dist_loss: 0.6538664102554321
recon_loss: 0.0410059317946434, dist_loss: 0.7624050974845886
recon_loss: 0.04100368544459343, dist_loss: 0.6705809235572815
recon_loss: 0.04100187122821808, dist_loss: 0.35438790917396545
recon_loss: 0.041000232100486755, dist_loss: 0.6450022459030151
recon_loss: 0.04099871590733528, dist_loss: 0.528244137763977
recon_loss: 0.0409972108900547, dist_loss: 0.3505169451236725
recon_loss: 0.04099573194980621, dist_loss: 0.9010740518569946
recon_loss: 0.04099417105317116, dist_loss: 0.601333498954773
recon_loss: 0.040992725640535355, dist_loss: 0.5505793690681458
recon_loss: 0.040991369634866714, dist_loss: 0.6208981275558472
recon_loss: 0.0409899577498436, dist_loss: 0.6700242757797241
recon_loss: 0.04098834469914436, dist_loss: 0.6390209794044495
recon_loss: 0.04098643362522125, dist_loss: 1.0816251039505005
recon_loss: 0.040984779596328735, dist_loss: 0.46389535069465637
recon_loss: 0.040983326733112335, dist_loss: 0.9828176498413086
recon_loss: 0.04098166525363922, dist_loss: 1.0248180627822876
recon_loss: 0.04097967594861984, dist_loss: 0.9717108011245728
recon_loss: 0.040977783501148224, dist_loss: 0.6831177473068237
recon_loss: 0.0409759059548378, dist_loss: 0.5106140375137329
recon_loss: 0.04097416624426842, dist_loss: 0.6035324931144714
recon_loss: 0.04097268357872963, dist_loss: 0.44200754165649414
recon_loss: 0.04097111150622368, dist_loss: 0.7465937733650208
recon_loss: 0.04096943512558937, dist_loss: 0.8542557954788208
recon_loss: 0.040968019515275955, dist_loss: 0.8994065523147583
recon_loss: 0.04096669703722, dist_loss: 0.6982953548431396
recon_loss: 0.040965646505355835, dist_loss: 0.46701011061668396
Pre-training Epoch 14:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 14:   5%|▌         | 19/367 [00:00<00:01, 187.51it/s]Pre-training Epoch 14:  11%|█         | 39/367 [00:00<00:01, 191.39it/s]Pre-training Epoch 14:  16%|█▌        | 59/367 [00:00<00:01, 183.98it/s]Pre-training Epoch 14:  21%|██▏       | 78/367 [00:00<00:01, 176.17it/s]Pre-training Epoch 14:  26%|██▌       | 96/367 [00:00<00:01, 171.07it/s]Pre-training Epoch 14:  31%|███       | 114/367 [00:00<00:01, 166.23it/s]recon_loss: 0.040964771062135696, dist_loss: 0.7840707898139954
recon_loss: 0.04096395894885063, dist_loss: 0.6199835538864136
recon_loss: 0.040963064879179, dist_loss: 0.5397445559501648
recon_loss: 0.04096195474267006, dist_loss: 0.7767808437347412
recon_loss: 0.04096105694770813, dist_loss: 0.6081569194793701
recon_loss: 0.040960073471069336, dist_loss: 0.7409229278564453
recon_loss: 0.04095904901623726, dist_loss: 0.2284439504146576
recon_loss: 0.04095796123147011, dist_loss: 1.15077543258667
recon_loss: 0.04095710813999176, dist_loss: 0.8278063535690308
recon_loss: 0.04095631092786789, dist_loss: 0.5266314744949341
recon_loss: 0.0409558042883873, dist_loss: 0.6969542503356934
recon_loss: 0.04095509648323059, dist_loss: 0.478113055229187
recon_loss: 0.040954384952783585, dist_loss: 0.5078743696212769
recon_loss: 0.040953733026981354, dist_loss: 0.6057289242744446
recon_loss: 0.04095309227705002, dist_loss: 0.5433205962181091
recon_loss: 0.040952377021312714, dist_loss: 0.5306529998779297
recon_loss: 0.040951207280159, dist_loss: 0.6915773153305054
recon_loss: 0.04094994440674782, dist_loss: 0.44203537702560425
recon_loss: 0.0409487783908844, dist_loss: 0.7291743755340576
recon_loss: 0.040947481989860535, dist_loss: 0.842589795589447
recon_loss: 0.040946099907159805, dist_loss: 1.0389511585235596
recon_loss: 0.040944311767816544, dist_loss: 0.7733578681945801
recon_loss: 0.04094226658344269, dist_loss: 0.3824392855167389
recon_loss: 0.04094037041068077, dist_loss: 1.0935906171798706
recon_loss: 0.040938153862953186, dist_loss: 0.6350079774856567
recon_loss: 0.0409359373152256, dist_loss: 1.1950994729995728
recon_loss: 0.040933553129434586, dist_loss: 0.7491474747657776
recon_loss: 0.040931377559900284, dist_loss: 1.0643562078475952
recon_loss: 0.04092933610081673, dist_loss: 0.7773219347000122
recon_loss: 0.040927134454250336, dist_loss: 0.34838247299194336
recon_loss: 0.040925148874521255, dist_loss: 0.8381755352020264
recon_loss: 0.04092348366975784, dist_loss: 1.126114010810852
recon_loss: 0.040921539068222046, dist_loss: 0.6315171718597412
recon_loss: 0.04091951623558998, dist_loss: 0.5622560977935791
recon_loss: 0.04091746732592583, dist_loss: 0.369904100894928
recon_loss: 0.04091528058052063, dist_loss: 0.6118142604827881
recon_loss: 0.04091333970427513, dist_loss: 0.7668652534484863
recon_loss: 0.04091143608093262, dist_loss: 0.3897320032119751
recon_loss: 0.04090974107384682, dist_loss: 0.7985544204711914
recon_loss: 0.04090792313218117, dist_loss: 1.2668514251708984
recon_loss: 0.04090623930096626, dist_loss: 0.4861792325973511
recon_loss: 0.04090480878949165, dist_loss: 0.46016260981559753
recon_loss: 0.040903396904468536, dist_loss: 0.830707311630249
recon_loss: 0.04090235009789467, dist_loss: 0.8222745656967163
recon_loss: 0.040901217609643936, dist_loss: 0.6603341102600098
recon_loss: 0.04090038314461708, dist_loss: 0.5784988403320312
recon_loss: 0.04089997708797455, dist_loss: 0.38548552989959717
recon_loss: 0.040899842977523804, dist_loss: 0.6102347373962402
recon_loss: 0.04089969024062157, dist_loss: 1.1230041980743408
recon_loss: 0.04089950770139694, dist_loss: 0.6106448173522949
recon_loss: 0.040899284183979034, dist_loss: 0.5067093372344971
recon_loss: 0.04089885577559471, dist_loss: 0.5552138686180115
recon_loss: 0.040898118168115616, dist_loss: 0.7337836623191833
recon_loss: 0.04089736565947533, dist_loss: 0.461744487285614
recon_loss: 0.040896471589803696, dist_loss: 0.7682840824127197
recon_loss: 0.0408950075507164, dist_loss: 0.5081123113632202
recon_loss: 0.04089387133717537, dist_loss: 0.3321687877178192
recon_loss: 0.04089292511343956, dist_loss: 0.6026080846786499
recon_loss: 0.04089178517460823, dist_loss: 0.8691929578781128
recon_loss: 0.04089036211371422, dist_loss: 0.8556823134422302
recon_loss: 0.04088900238275528, dist_loss: 0.54567551612854
recon_loss: 0.040887534618377686, dist_loss: 0.5499321818351746
recon_loss: 0.04088607430458069, dist_loss: 0.6193332076072693
recon_loss: 0.040884505957365036, dist_loss: 0.5344277620315552
recon_loss: 0.040882665663957596, dist_loss: 0.6085671186447144
recon_loss: 0.04088090360164642, dist_loss: 0.5649678707122803
recon_loss: 0.04087873920798302, dist_loss: 0.5005649328231812
recon_loss: 0.04087638482451439, dist_loss: 0.8867532014846802
recon_loss: 0.04087419435381889, dist_loss: 0.6173998117446899
recon_loss: 0.04087178781628609, dist_loss: 0.7264091968536377
recon_loss: 0.040869519114494324, dist_loss: 1.54646897315979
recon_loss: 0.04086718708276749, dist_loss: 0.6356640458106995
recon_loss: 0.04086511582136154, dist_loss: 0.566713273525238
recon_loss: 0.04086291417479515, dist_loss: 0.9245301485061646
recon_loss: 0.0408603809773922, dist_loss: 0.31362026929855347
recon_loss: 0.04085787758231163, dist_loss: 0.5967535376548767
recon_loss: 0.04085522145032883, dist_loss: 0.9350532293319702
recon_loss: 0.04085289686918259, dist_loss: 0.9306511878967285
recon_loss: 0.04085041210055351, dist_loss: 1.1296429634094238
recon_loss: 0.040848035365343094, dist_loss: 1.0058008432388306
recon_loss: 0.04084578529000282, dist_loss: 0.7725695371627808
recon_loss: 0.04084340110421181, dist_loss: 0.8011338114738464
recon_loss: 0.04084092378616333, dist_loss: 0.6555977463722229
recon_loss: 0.04083850234746933, dist_loss: 0.9269061088562012
recon_loss: 0.040836188942193985, dist_loss: 0.5046384334564209
recon_loss: 0.04083393141627312, dist_loss: 0.37439626455307007
recon_loss: 0.0408317893743515, dist_loss: 0.9577820301055908
recon_loss: 0.04082990810275078, dist_loss: 0.9306280612945557
recon_loss: 0.04082818701863289, dist_loss: 0.5686649084091187
recon_loss: 0.04082656651735306, dist_loss: 0.8239770531654358
recon_loss: 0.04082527384161949, dist_loss: 0.7629514932632446
recon_loss: 0.04082391783595085, dist_loss: 0.6493901014328003
recon_loss: 0.04082236438989639, dist_loss: 0.36192458868026733
recon_loss: 0.04082084447145462, dist_loss: 0.4901605248451233
recon_loss: 0.04081915318965912, dist_loss: 0.34035682678222656
recon_loss: 0.04081752896308899, dist_loss: 0.3980303406715393
recon_loss: 0.04081587493419647, dist_loss: 0.6230031251907349
recon_loss: 0.040814176201820374, dist_loss: 0.4502946734428406
recon_loss: 0.04081273078918457, dist_loss: 1.0350382328033447
recon_loss: 0.04081122949719429, dist_loss: 0.9005175828933716
recon_loss: 0.04080948978662491, dist_loss: 1.1852025985717773
recon_loss: 0.04080762341618538, dist_loss: 0.4359259009361267
recon_loss: 0.040805939584970474, dist_loss: 0.7271878719329834
recon_loss: 0.04080422595143318, dist_loss: 0.6176992058753967
recon_loss: 0.04080231115221977, dist_loss: 0.5181910991668701
recon_loss: 0.04080075025558472, dist_loss: 0.8943883180618286
recon_loss: 0.04079887270927429, dist_loss: 0.7438918948173523
recon_loss: 0.040797289460897446, dist_loss: 0.515749990940094
recon_loss: 0.04079584404826164, dist_loss: 0.8775829672813416
recon_loss: 0.04079451784491539, dist_loss: 0.726271390914917
recon_loss: 0.04079321026802063, dist_loss: 0.6307559609413147
recon_loss: 0.04079210385680199, dist_loss: 0.7188690900802612
recon_loss: 0.04079088196158409, dist_loss: 1.0678844451904297
recon_loss: 0.04078906774520874, dist_loss: 0.6019361019134521
recon_loss: 0.04078717902302742, dist_loss: 0.9792665243148804
recon_loss: 0.04078488051891327, dist_loss: 0.5936342477798462
recon_loss: 0.04078257828950882, dist_loss: 0.5031713843345642
recon_loss: 0.04078010469675064, dist_loss: 0.7060491442680359
recon_loss: 0.04077768698334694, dist_loss: 0.6542484760284424
recon_loss: 0.04077548906207085, dist_loss: 0.8413782715797424
recon_loss: 0.04077329859137535, dist_loss: 0.7258729934692383
recon_loss: 0.040771014988422394, dist_loss: 0.5615535378456116
recon_loss: 0.040769062936306, dist_loss: 0.6474261283874512
recon_loss: 0.040767136961221695, dist_loss: 0.6799907684326172
recon_loss: 0.040764935314655304, dist_loss: 0.5266020894050598
recon_loss: 0.04076289385557175, dist_loss: 0.6699151992797852
recon_loss: 0.04076077416539192, dist_loss: 0.7352088689804077
recon_loss: 0.04075886681675911, dist_loss: 0.42783844470977783
recon_loss: 0.04075707122683525, dist_loss: 0.7822074890136719
Pre-training Epoch 14:  37%|███▋      | 134/367 [00:00<00:01, 174.27it/s]Pre-training Epoch 14:  42%|████▏     | 154/367 [00:00<00:01, 180.11it/s]Pre-training Epoch 14:  47%|████▋     | 174/367 [00:00<00:01, 183.95it/s]Pre-training Epoch 14:  53%|█████▎    | 194/367 [00:01<00:00, 186.70it/s]Pre-training Epoch 14:  58%|█████▊    | 214/367 [00:01<00:00, 188.49it/s]Pre-training Epoch 14:  63%|██████▎   | 233/367 [00:01<00:00, 187.47it/s]Pre-training Epoch 14:  69%|██████▊   | 252/367 [00:01<00:00, 178.04it/s]recon_loss: 0.04075518995523453, dist_loss: 0.6082223653793335
recon_loss: 0.040753304958343506, dist_loss: 0.766613245010376
recon_loss: 0.040751613676548004, dist_loss: 0.6292648911476135
recon_loss: 0.04074999317526817, dist_loss: 0.4552435874938965
recon_loss: 0.04074816778302193, dist_loss: 0.6278170347213745
recon_loss: 0.04074634611606598, dist_loss: 0.8205242156982422
recon_loss: 0.04074467718601227, dist_loss: 0.321851521730423
recon_loss: 0.04074304923415184, dist_loss: 0.5917787551879883
recon_loss: 0.04074135050177574, dist_loss: 0.46646469831466675
recon_loss: 0.040739547461271286, dist_loss: 0.4318394660949707
recon_loss: 0.04073747619986534, dist_loss: 0.6383751630783081
recon_loss: 0.04073503613471985, dist_loss: 0.45146405696868896
recon_loss: 0.0407324954867363, dist_loss: 0.47384458780288696
recon_loss: 0.04073004052042961, dist_loss: 1.0779671669006348
recon_loss: 0.04072794318199158, dist_loss: 0.497040331363678
recon_loss: 0.04072576016187668, dist_loss: 0.8343589901924133
recon_loss: 0.040723416954278946, dist_loss: 0.8045531511306763
recon_loss: 0.040721192955970764, dist_loss: 0.8207465410232544
recon_loss: 0.040718816220760345, dist_loss: 0.5866124033927917
recon_loss: 0.040716782212257385, dist_loss: 0.8501480221748352
recon_loss: 0.040714457631111145, dist_loss: 0.6291685104370117
recon_loss: 0.040712304413318634, dist_loss: 0.7598938941955566
recon_loss: 0.04071008786559105, dist_loss: 1.0014746189117432
recon_loss: 0.04070768132805824, dist_loss: 0.8416805267333984
recon_loss: 0.040705662220716476, dist_loss: 0.9118229150772095
recon_loss: 0.040703482925891876, dist_loss: 0.5410510301589966
recon_loss: 0.04070147126913071, dist_loss: 0.7089077234268188
recon_loss: 0.04069963097572327, dist_loss: 1.1183243989944458
recon_loss: 0.04069787263870239, dist_loss: 0.6536239981651306
recon_loss: 0.040696002542972565, dist_loss: 0.6006788015365601
recon_loss: 0.04069409519433975, dist_loss: 0.8813556432723999
recon_loss: 0.0406925305724144, dist_loss: 1.21436607837677
recon_loss: 0.040690887719392776, dist_loss: 0.948935866355896
recon_loss: 0.0406888909637928, dist_loss: 0.6902549266815186
recon_loss: 0.0406872034072876, dist_loss: 0.9396831393241882
recon_loss: 0.04068582504987717, dist_loss: 0.4780128598213196
recon_loss: 0.04068448394536972, dist_loss: 0.44646745920181274
recon_loss: 0.040683064609766006, dist_loss: 0.5063453316688538
recon_loss: 0.0406816191971302, dist_loss: 0.5365111827850342
recon_loss: 0.04068027436733246, dist_loss: 0.5747541189193726
recon_loss: 0.040679045021533966, dist_loss: 0.9564661979675293
recon_loss: 0.04067761078476906, dist_loss: 0.5135571956634521
recon_loss: 0.04067595303058624, dist_loss: 0.7631794810295105
recon_loss: 0.04067423194646835, dist_loss: 0.35770151019096375
recon_loss: 0.040672626346349716, dist_loss: 1.2389750480651855
recon_loss: 0.04067098721861839, dist_loss: 1.2698168754577637
recon_loss: 0.04066930711269379, dist_loss: 0.29760006070137024
recon_loss: 0.04066750034689903, dist_loss: 0.5586735606193542
recon_loss: 0.04066571593284607, dist_loss: 0.6377425789833069
recon_loss: 0.040663909167051315, dist_loss: 0.39052727818489075
recon_loss: 0.040662072598934174, dist_loss: 0.9534808397293091
recon_loss: 0.04066074639558792, dist_loss: 0.9466508626937866
recon_loss: 0.040659550577402115, dist_loss: 0.524178683757782
recon_loss: 0.04065845161676407, dist_loss: 0.7348834872245789
recon_loss: 0.04065676033496857, dist_loss: 0.748023271560669
recon_loss: 0.04065486416220665, dist_loss: 0.895689845085144
recon_loss: 0.04065287113189697, dist_loss: 0.7114323377609253
recon_loss: 0.04065048322081566, dist_loss: 1.1778912544250488
recon_loss: 0.04064847156405449, dist_loss: 0.5928102731704712
recon_loss: 0.0406465008854866, dist_loss: 0.9691576957702637
recon_loss: 0.04064446687698364, dist_loss: 0.5491718053817749
recon_loss: 0.0406423881649971, dist_loss: 0.5253502726554871
recon_loss: 0.04064014554023743, dist_loss: 0.5356606841087341
recon_loss: 0.04063793271780014, dist_loss: 0.9577764868736267
recon_loss: 0.040635764598846436, dist_loss: 0.7399778962135315
recon_loss: 0.040633540600538254, dist_loss: 0.582930862903595
recon_loss: 0.04063202068209648, dist_loss: 0.3951948285102844
recon_loss: 0.04063018038868904, dist_loss: 0.719173014163971
recon_loss: 0.040628399699926376, dist_loss: 0.8364675045013428
recon_loss: 0.0406268835067749, dist_loss: 0.5311992764472961
recon_loss: 0.040625765919685364, dist_loss: 0.8135757446289062
recon_loss: 0.04062430560588837, dist_loss: 0.7631932497024536
recon_loss: 0.04062282666563988, dist_loss: 0.5678213834762573
recon_loss: 0.040621425956487656, dist_loss: 0.7562000751495361
recon_loss: 0.040619224309921265, dist_loss: 0.9020644426345825
recon_loss: 0.040617506951093674, dist_loss: 0.30794402956962585
recon_loss: 0.04061558470129967, dist_loss: 0.7540213465690613
recon_loss: 0.040613722056150436, dist_loss: 0.811552107334137
recon_loss: 0.040611833333969116, dist_loss: 0.953400194644928
recon_loss: 0.04061007872223854, dist_loss: 0.9984459280967712
recon_loss: 0.04060860350728035, dist_loss: 0.974350094795227
recon_loss: 0.04060671105980873, dist_loss: 0.9384950399398804
recon_loss: 0.0406043604016304, dist_loss: 0.6837818622589111
recon_loss: 0.040601953864097595, dist_loss: 0.649665117263794
recon_loss: 0.04059961065649986, dist_loss: 0.5220485925674438
recon_loss: 0.0405970998108387, dist_loss: 0.5454010963439941
recon_loss: 0.04059455916285515, dist_loss: 0.568359911441803
recon_loss: 0.04059215262532234, dist_loss: 0.5750229358673096
recon_loss: 0.04058999940752983, dist_loss: 0.5362337827682495
recon_loss: 0.040588438510894775, dist_loss: 0.6419306993484497
recon_loss: 0.04058682918548584, dist_loss: 0.5063493251800537
recon_loss: 0.04058532416820526, dist_loss: 0.6889984607696533
recon_loss: 0.04058419540524483, dist_loss: 0.4871256649494171
recon_loss: 0.04058298468589783, dist_loss: 0.4555038809776306
recon_loss: 0.040581874549388885, dist_loss: 0.4306400418281555
recon_loss: 0.040580857545137405, dist_loss: 0.8813492059707642
recon_loss: 0.040579844266176224, dist_loss: 0.662821888923645
recon_loss: 0.04057895019650459, dist_loss: 0.9579843282699585
recon_loss: 0.04057852551341057, dist_loss: 0.6259692907333374
recon_loss: 0.040577907115221024, dist_loss: 0.4895050823688507
recon_loss: 0.04057743027806282, dist_loss: 0.9939683675765991
recon_loss: 0.0405767522752285, dist_loss: 0.924461305141449
recon_loss: 0.040576085448265076, dist_loss: 0.600397527217865
recon_loss: 0.0405753068625927, dist_loss: 0.6030751466751099
recon_loss: 0.0405743271112442, dist_loss: 0.7550678253173828
recon_loss: 0.04057270288467407, dist_loss: 1.1104538440704346
recon_loss: 0.040571413934230804, dist_loss: 0.9925121068954468
recon_loss: 0.04057002440094948, dist_loss: 0.6110291481018066
recon_loss: 0.04056863114237785, dist_loss: 0.6791836023330688
recon_loss: 0.04056716337800026, dist_loss: 0.4854219853878021
recon_loss: 0.040565524250268936, dist_loss: 1.1692993640899658
recon_loss: 0.0405634306371212, dist_loss: 0.6225945353507996
recon_loss: 0.04056170582771301, dist_loss: 0.5821335315704346
recon_loss: 0.04055998474359512, dist_loss: 0.9576784372329712
recon_loss: 0.04055771976709366, dist_loss: 0.7229270935058594
recon_loss: 0.040555454790592194, dist_loss: 0.8286324739456177
recon_loss: 0.04055317863821983, dist_loss: 0.9060372114181519
recon_loss: 0.040550775825977325, dist_loss: 0.7560465335845947
recon_loss: 0.04054843634366989, dist_loss: 0.82553631067276
recon_loss: 0.040546268224716187, dist_loss: 0.6215605735778809
recon_loss: 0.040544018149375916, dist_loss: 0.7118618488311768
recon_loss: 0.040541816502809525, dist_loss: 0.8064899444580078
recon_loss: 0.0405399315059185, dist_loss: 0.801662802696228
recon_loss: 0.04053821787238121, dist_loss: 0.6246233582496643
recon_loss: 0.04053633287549019, dist_loss: 0.9049234986305237
recon_loss: 0.0405338853597641, dist_loss: 0.7712132930755615
recon_loss: 0.04053147882223129, dist_loss: 0.8430801630020142
recon_loss: 0.04052889347076416, dist_loss: 0.4788878560066223
recon_loss: 0.040526825934648514, dist_loss: 0.8591136336326599
Pre-training Epoch 14:  74%|███████▎  | 270/367 [00:01<00:00, 171.46it/s]Pre-training Epoch 14:  78%|███████▊  | 288/367 [00:01<00:00, 166.06it/s]Pre-training Epoch 14:  83%|████████▎ | 306/367 [00:01<00:00, 168.04it/s]Pre-training Epoch 14:  89%|████████▉ | 326/367 [00:01<00:00, 174.98it/s]Pre-training Epoch 14:  94%|█████████▍| 346/367 [00:01<00:00, 179.77it/s]Pre-training Epoch 14: 100%|█████████▉| 366/367 [00:02<00:00, 183.22it/s]Pre-training Epoch 14: 100%|██████████| 367/367 [00:02<00:00, 178.66it/s]
recon_loss: 0.040524616837501526, dist_loss: 0.5586469769477844
recon_loss: 0.040522243827581406, dist_loss: 0.5236338376998901
recon_loss: 0.04052026569843292, dist_loss: 0.8415997624397278
recon_loss: 0.040518563240766525, dist_loss: 0.49592480063438416
recon_loss: 0.04051702469587326, dist_loss: 0.48437023162841797
recon_loss: 0.04051598161458969, dist_loss: 0.6828947067260742
recon_loss: 0.04051494225859642, dist_loss: 0.9384171366691589
recon_loss: 0.04051372408866882, dist_loss: 0.8407261371612549
recon_loss: 0.040512580424547195, dist_loss: 0.6753789186477661
recon_loss: 0.040511563420295715, dist_loss: 0.6771149635314941
recon_loss: 0.040510356426239014, dist_loss: 0.556499719619751
recon_loss: 0.0405091717839241, dist_loss: 0.8940186500549316
recon_loss: 0.04050746187567711, dist_loss: 0.5225653648376465
recon_loss: 0.04050567001104355, dist_loss: 0.8403651118278503
recon_loss: 0.04050366207957268, dist_loss: 0.624290943145752
recon_loss: 0.040501441806554794, dist_loss: 0.5429596900939941
recon_loss: 0.040498994290828705, dist_loss: 0.46540969610214233
recon_loss: 0.040496692061424255, dist_loss: 0.7445074319839478
recon_loss: 0.04049467667937279, dist_loss: 0.9114933013916016
recon_loss: 0.04049278423190117, dist_loss: 0.7380285263061523
recon_loss: 0.04049079492688179, dist_loss: 0.497050404548645
recon_loss: 0.04048871994018555, dist_loss: 0.5145831108093262
recon_loss: 0.04048647731542587, dist_loss: 0.40633076429367065
recon_loss: 0.04048417508602142, dist_loss: 0.5789291262626648
recon_loss: 0.04048183187842369, dist_loss: 0.5780874490737915
recon_loss: 0.04047953337430954, dist_loss: 0.5915043950080872
recon_loss: 0.04047741740942001, dist_loss: 0.4759535789489746
recon_loss: 0.04047513008117676, dist_loss: 0.6932324767112732
recon_loss: 0.040472570806741714, dist_loss: 1.4168918132781982
recon_loss: 0.04047005996108055, dist_loss: 0.6679679155349731
recon_loss: 0.0404675267636776, dist_loss: 0.6582431793212891
recon_loss: 0.040464967489242554, dist_loss: 1.093822956085205
recon_loss: 0.040462374687194824, dist_loss: 1.066589593887329
recon_loss: 0.040460005402565, dist_loss: 1.1514184474945068
recon_loss: 0.04045814275741577, dist_loss: 0.946465015411377
recon_loss: 0.04045630246400833, dist_loss: 0.6165622472763062
recon_loss: 0.040454503148794174, dist_loss: 0.38543587923049927
recon_loss: 0.04045293480157852, dist_loss: 0.7463167905807495
recon_loss: 0.04045182839035988, dist_loss: 0.674895703792572
recon_loss: 0.04045042395591736, dist_loss: 0.48690515756607056
recon_loss: 0.04044913128018379, dist_loss: 0.414067804813385
recon_loss: 0.040447626262903214, dist_loss: 0.614148736000061
recon_loss: 0.04044608399271965, dist_loss: 0.9213440418243408
recon_loss: 0.04044472798705101, dist_loss: 0.9978621602058411
recon_loss: 0.04044341668486595, dist_loss: 0.7353724241256714
recon_loss: 0.040442079305648804, dist_loss: 1.4364793300628662
recon_loss: 0.040440697222948074, dist_loss: 0.6357811689376831
recon_loss: 0.04043915867805481, dist_loss: 0.6898168325424194
recon_loss: 0.040437862277030945, dist_loss: 0.6370450854301453
recon_loss: 0.04043631628155708, dist_loss: 0.5992486476898193
recon_loss: 0.0404348149895668, dist_loss: 0.6936312913894653
recon_loss: 0.04043316841125488, dist_loss: 0.7377331256866455
recon_loss: 0.04043157398700714, dist_loss: 0.4914833903312683
recon_loss: 0.04042985290288925, dist_loss: 0.8794047236442566
recon_loss: 0.04042788967490196, dist_loss: 1.2379769086837769
recon_loss: 0.040426019579172134, dist_loss: 0.3439573645591736
recon_loss: 0.04042403772473335, dist_loss: 0.6428040862083435
recon_loss: 0.04042205587029457, dist_loss: 1.0755938291549683
recon_loss: 0.04041997343301773, dist_loss: 0.5363594889640808
recon_loss: 0.040417566895484924, dist_loss: 0.6535950899124146
recon_loss: 0.04041542112827301, dist_loss: 1.1221356391906738
recon_loss: 0.04041321948170662, dist_loss: 0.9551165103912354
recon_loss: 0.040410690009593964, dist_loss: 0.9671894311904907
recon_loss: 0.04040807485580444, dist_loss: 0.6696814298629761
recon_loss: 0.040405575186014175, dist_loss: 0.5142139792442322
recon_loss: 0.0404030941426754, dist_loss: 0.7378633618354797
recon_loss: 0.04040057584643364, dist_loss: 0.6541956663131714
recon_loss: 0.04039822891354561, dist_loss: 0.5373972654342651
recon_loss: 0.04039599001407623, dist_loss: 0.7281202673912048
recon_loss: 0.04039372131228447, dist_loss: 0.3985665440559387
recon_loss: 0.040391385555267334, dist_loss: 0.758634626865387
recon_loss: 0.04038933292031288, dist_loss: 0.6535110473632812
recon_loss: 0.0403873510658741, dist_loss: 0.7868772745132446
recon_loss: 0.04038612172007561, dist_loss: 0.8924183249473572
recon_loss: 0.04038497060537338, dist_loss: 0.6455684900283813
recon_loss: 0.04038374125957489, dist_loss: 0.4675261676311493
recon_loss: 0.040382642298936844, dist_loss: 0.522631824016571
recon_loss: 0.04038151726126671, dist_loss: 0.3723214268684387
recon_loss: 0.04038017615675926, dist_loss: 0.6062519550323486
recon_loss: 0.04037901386618614, dist_loss: 0.5378334522247314
recon_loss: 0.04037768021225929, dist_loss: 0.7447450160980225
recon_loss: 0.04037630185484886, dist_loss: 0.6469689607620239
recon_loss: 0.04037517309188843, dist_loss: 0.8502006530761719
recon_loss: 0.04037380591034889, dist_loss: 0.4198950231075287
recon_loss: 0.04037259891629219, dist_loss: 0.7720131874084473
recon_loss: 0.04037140682339668, dist_loss: 0.3913482129573822
recon_loss: 0.040370263159275055, dist_loss: 0.5412228107452393
recon_loss: 0.04036908596754074, dist_loss: 0.7380759119987488
recon_loss: 0.04036753252148628, dist_loss: 0.6965705156326294
recon_loss: 0.0403657965362072, dist_loss: 0.2444583773612976
recon_loss: 0.040364157408475876, dist_loss: 0.5132702589035034
recon_loss: 0.040362585335969925, dist_loss: 0.8516782522201538
recon_loss: 0.04036053642630577, dist_loss: 0.40868422389030457
recon_loss: 0.0403585284948349, dist_loss: 0.44795653223991394
recon_loss: 0.04035664722323418, dist_loss: 0.5971847772598267
recon_loss: 0.04035443440079689, dist_loss: 0.5835545063018799
recon_loss: 0.04035280644893646, dist_loss: 1.0158246755599976
recon_loss: 0.04035063460469246, dist_loss: 0.546305775642395
recon_loss: 0.04034858196973801, dist_loss: 0.33095625042915344
recon_loss: 0.04034664109349251, dist_loss: 0.8910592198371887
recon_loss: 0.040344852954149246, dist_loss: 0.8617517948150635
recon_loss: 0.040343355387449265, dist_loss: 1.0591530799865723
recon_loss: 0.04034166783094406, dist_loss: 0.364902526140213
recon_loss: 0.04034017398953438, dist_loss: 0.5540269017219543
recon_loss: 0.04033835232257843, dist_loss: 0.5366134643554688
recon_loss: 0.04033636301755905, dist_loss: 0.8705602884292603
recon_loss: 0.04033390432596207, dist_loss: 0.43087610602378845
recon_loss: 0.04033137112855911, dist_loss: 0.8364630937576294
recon_loss: 0.040328703820705414, dist_loss: 0.16376130282878876
Pre-training Epoch 15:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 15:   5%|▌         | 19/367 [00:00<00:01, 183.31it/s]Pre-training Epoch 15:  11%|█         | 39/367 [00:00<00:01, 187.32it/s]Pre-training Epoch 15:  16%|█▌        | 59/367 [00:00<00:01, 188.89it/s]Pre-training Epoch 15:  22%|██▏       | 79/367 [00:00<00:01, 190.26it/s]Pre-training Epoch 15:  27%|██▋       | 99/367 [00:00<00:01, 190.80it/s]Pre-training Epoch 15:  32%|███▏      | 119/367 [00:00<00:01, 189.53it/s]recon_loss: 0.04032600298523903, dist_loss: 0.5214083790779114
recon_loss: 0.040323302149772644, dist_loss: 0.30582791566848755
recon_loss: 0.040320705622434616, dist_loss: 0.6846238374710083
recon_loss: 0.04031828045845032, dist_loss: 1.2181849479675293
recon_loss: 0.040316175669431686, dist_loss: 0.38197433948516846
recon_loss: 0.040314141660928726, dist_loss: 1.069960355758667
recon_loss: 0.04031238332390785, dist_loss: 0.7197773456573486
recon_loss: 0.04031078889966011, dist_loss: 0.9706330299377441
recon_loss: 0.04030880331993103, dist_loss: 0.6968773007392883
recon_loss: 0.040306832641363144, dist_loss: 0.6838890314102173
recon_loss: 0.0403047613799572, dist_loss: 0.431870698928833
recon_loss: 0.04030255228281021, dist_loss: 0.6965242624282837
recon_loss: 0.0403008759021759, dist_loss: 0.49354273080825806
recon_loss: 0.04029923304915428, dist_loss: 1.200169563293457
recon_loss: 0.04029770568013191, dist_loss: 0.7424145340919495
recon_loss: 0.040296006947755814, dist_loss: 0.40817034244537354
recon_loss: 0.040293894708156586, dist_loss: 0.5633615851402283
recon_loss: 0.040291737765073776, dist_loss: 0.8027551174163818
recon_loss: 0.040289588272571564, dist_loss: 0.6344119310379028
recon_loss: 0.04028729721903801, dist_loss: 0.42098650336265564
recon_loss: 0.040284931659698486, dist_loss: 0.9278981685638428
recon_loss: 0.0402824692428112, dist_loss: 0.5768856406211853
recon_loss: 0.04027993604540825, dist_loss: 0.785735011100769
recon_loss: 0.040277257561683655, dist_loss: 0.9866539239883423
recon_loss: 0.040274880826473236, dist_loss: 0.602440357208252
recon_loss: 0.040272463113069534, dist_loss: 0.6804347038269043
recon_loss: 0.04027031734585762, dist_loss: 0.8530583381652832
recon_loss: 0.04026816412806511, dist_loss: 0.5727497339248657
recon_loss: 0.04026605561375618, dist_loss: 0.4705914258956909
recon_loss: 0.04026384651660919, dist_loss: 0.5078379511833191
recon_loss: 0.040261559188365936, dist_loss: 0.6646455526351929
recon_loss: 0.040259383618831635, dist_loss: 0.37192070484161377
recon_loss: 0.040257152169942856, dist_loss: 0.9923416376113892
recon_loss: 0.040254972875118256, dist_loss: 1.4597357511520386
recon_loss: 0.0402531735599041, dist_loss: 0.9713410139083862
recon_loss: 0.040251199156045914, dist_loss: 0.5056031346321106
recon_loss: 0.040249090641736984, dist_loss: 1.217333197593689
recon_loss: 0.040247198194265366, dist_loss: 1.6994458436965942
recon_loss: 0.04024514555931091, dist_loss: 0.43080735206604004
recon_loss: 0.0402432456612587, dist_loss: 0.5612037181854248
recon_loss: 0.04024112969636917, dist_loss: 0.4950478971004486
recon_loss: 0.040238961577415466, dist_loss: 0.8012125492095947
recon_loss: 0.040236346423625946, dist_loss: 0.49212753772735596
recon_loss: 0.0402340367436409, dist_loss: 0.6380195617675781
recon_loss: 0.0402316078543663, dist_loss: 0.727425217628479
recon_loss: 0.04022904857993126, dist_loss: 0.6094517707824707
recon_loss: 0.04022679850459099, dist_loss: 0.8994389772415161
recon_loss: 0.04022430256009102, dist_loss: 0.4084528088569641
recon_loss: 0.040222059935331345, dist_loss: 0.5856413841247559
recon_loss: 0.04021959379315376, dist_loss: 0.7493640780448914
recon_loss: 0.04021691158413887, dist_loss: 0.8522883653640747
recon_loss: 0.04021437093615532, dist_loss: 0.7169051170349121
recon_loss: 0.04021144285798073, dist_loss: 0.8189626932144165
recon_loss: 0.04020891338586807, dist_loss: 0.9383180141448975
recon_loss: 0.04020652920007706, dist_loss: 0.7284178137779236
recon_loss: 0.04020407423377037, dist_loss: 0.38544899225234985
recon_loss: 0.04020148888230324, dist_loss: 0.8466572761535645
recon_loss: 0.040198519825935364, dist_loss: 0.9555003643035889
recon_loss: 0.040195658802986145, dist_loss: 0.5243743062019348
recon_loss: 0.04019305855035782, dist_loss: 0.29798728227615356
recon_loss: 0.04019039124250412, dist_loss: 0.8533019423484802
recon_loss: 0.04018788784742355, dist_loss: 0.7073105573654175
recon_loss: 0.04018564149737358, dist_loss: 0.8116148710250854
recon_loss: 0.040183499455451965, dist_loss: 0.6042144894599915
recon_loss: 0.04018115997314453, dist_loss: 1.114555835723877
recon_loss: 0.040179356932640076, dist_loss: 0.8151193857192993
recon_loss: 0.040177419781684875, dist_loss: 0.4683157205581665
recon_loss: 0.04017513245344162, dist_loss: 0.7581493854522705
recon_loss: 0.04017317667603493, dist_loss: 0.639662504196167
recon_loss: 0.04017117992043495, dist_loss: 0.7814159393310547
recon_loss: 0.040169183164834976, dist_loss: 0.6029923558235168
recon_loss: 0.040167491883039474, dist_loss: 1.2938915491104126
recon_loss: 0.04016575217247009, dist_loss: 0.46298861503601074
recon_loss: 0.04016362130641937, dist_loss: 0.6196837425231934
recon_loss: 0.04016191139817238, dist_loss: 0.42775627970695496
recon_loss: 0.04016003757715225, dist_loss: 0.7334951162338257
recon_loss: 0.04015817493200302, dist_loss: 0.4447709918022156
recon_loss: 0.040156155824661255, dist_loss: 0.714834988117218
recon_loss: 0.040154241025447845, dist_loss: 0.8514184951782227
recon_loss: 0.040152233093976974, dist_loss: 0.7329787015914917
recon_loss: 0.040150709450244904, dist_loss: 0.5668458938598633
recon_loss: 0.04014902561903, dist_loss: 0.6474761962890625
recon_loss: 0.040147144347429276, dist_loss: 0.5786195993423462
recon_loss: 0.040145497769117355, dist_loss: 0.3827361464500427
recon_loss: 0.040143780410289764, dist_loss: 0.544352650642395
recon_loss: 0.04014177992939949, dist_loss: 0.682117760181427
recon_loss: 0.04013969376683235, dist_loss: 0.9014354944229126
recon_loss: 0.040137879550457, dist_loss: 0.6605850458145142
recon_loss: 0.04013603925704956, dist_loss: 0.5766993761062622
recon_loss: 0.04013455659151077, dist_loss: 1.161387324333191
recon_loss: 0.04013274237513542, dist_loss: 1.2408781051635742
recon_loss: 0.04013102874159813, dist_loss: 0.352202445268631
recon_loss: 0.04012899473309517, dist_loss: 0.7050663828849792
recon_loss: 0.04012688249349594, dist_loss: 0.9105231165885925
recon_loss: 0.040124740451574326, dist_loss: 0.6246117949485779
recon_loss: 0.04012235999107361, dist_loss: 0.8813267946243286
recon_loss: 0.04011974111199379, dist_loss: 0.8660836219787598
recon_loss: 0.04011775925755501, dist_loss: 0.7056663036346436
recon_loss: 0.04011603817343712, dist_loss: 0.7637650370597839
recon_loss: 0.04011405631899834, dist_loss: 0.6977202296257019
recon_loss: 0.04011184722185135, dist_loss: 0.5809728503227234
recon_loss: 0.04010935127735138, dist_loss: 0.422305166721344
recon_loss: 0.04010709747672081, dist_loss: 0.8827512264251709
recon_loss: 0.04010531306266785, dist_loss: 0.7214993238449097
recon_loss: 0.04010367393493652, dist_loss: 0.7234309911727905
recon_loss: 0.040101971477270126, dist_loss: 0.4452524781227112
recon_loss: 0.04010020196437836, dist_loss: 0.8498586416244507
recon_loss: 0.04009849950671196, dist_loss: 0.3247930407524109
recon_loss: 0.04009661823511124, dist_loss: 0.6929023265838623
recon_loss: 0.040094684809446335, dist_loss: 0.46456199884414673
recon_loss: 0.0400925949215889, dist_loss: 0.692848801612854
recon_loss: 0.04009012505412102, dist_loss: 0.29928064346313477
recon_loss: 0.04008777439594269, dist_loss: 0.8705922365188599
recon_loss: 0.04008539766073227, dist_loss: 0.9368805885314941
recon_loss: 0.040082693099975586, dist_loss: 0.8807830810546875
recon_loss: 0.04008018225431442, dist_loss: 0.6807643175125122
recon_loss: 0.04007789492607117, dist_loss: 1.1007554531097412
recon_loss: 0.040075644850730896, dist_loss: 0.731712281703949
recon_loss: 0.04007388651371002, dist_loss: 0.7600051760673523
recon_loss: 0.04007197543978691, dist_loss: 0.625856876373291
recon_loss: 0.04007012024521828, dist_loss: 0.24297329783439636
recon_loss: 0.0400683656334877, dist_loss: 0.7728856205940247
recon_loss: 0.040066760033369064, dist_loss: 0.8549889326095581
recon_loss: 0.04006483033299446, dist_loss: 0.5649821758270264
recon_loss: 0.04006299749016762, dist_loss: 0.6194471120834351
recon_loss: 0.04006112366914749, dist_loss: 0.4200044572353363
recon_loss: 0.04005908966064453, dist_loss: 0.77031409740448
recon_loss: 0.04005703702569008, dist_loss: 0.8255364894866943
recon_loss: 0.04005490988492966, dist_loss: 0.4940635561943054
Pre-training Epoch 15:  38%|███▊      | 138/367 [00:00<00:01, 184.55it/s]Pre-training Epoch 15:  43%|████▎     | 157/367 [00:00<00:01, 182.64it/s]Pre-training Epoch 15:  48%|████▊     | 176/367 [00:00<00:01, 180.94it/s]Pre-training Epoch 15:  53%|█████▎    | 195/367 [00:01<00:00, 177.59it/s]Pre-training Epoch 15:  59%|█████▊    | 215/367 [00:01<00:00, 182.00it/s]Pre-training Epoch 15:  64%|██████▍   | 235/367 [00:01<00:00, 184.93it/s]Pre-training Epoch 15:  69%|██████▉   | 255/367 [00:01<00:00, 187.22it/s]recon_loss: 0.04005280137062073, dist_loss: 0.34679484367370605
recon_loss: 0.04005049541592598, dist_loss: 0.7773017883300781
recon_loss: 0.04004787653684616, dist_loss: 0.42601674795150757
recon_loss: 0.040045417845249176, dist_loss: 0.8917089700698853
recon_loss: 0.04004298523068428, dist_loss: 0.4837687611579895
recon_loss: 0.0400405153632164, dist_loss: 0.6017427444458008
recon_loss: 0.04003813862800598, dist_loss: 0.7863097190856934
recon_loss: 0.040035903453826904, dist_loss: 0.690579891204834
recon_loss: 0.040033549070358276, dist_loss: 0.6483776569366455
recon_loss: 0.040031127631664276, dist_loss: 0.771877646446228
recon_loss: 0.040028829127550125, dist_loss: 0.7696108818054199
recon_loss: 0.04002632200717926, dist_loss: 0.7640512585639954
recon_loss: 0.040023695677518845, dist_loss: 0.6127825975418091
recon_loss: 0.04002085328102112, dist_loss: 0.9529873132705688
recon_loss: 0.04001773148775101, dist_loss: 0.7862374186515808
recon_loss: 0.04001450538635254, dist_loss: 1.002197265625
recon_loss: 0.04001098871231079, dist_loss: 0.45358267426490784
recon_loss: 0.04000793769955635, dist_loss: 0.4663677513599396
recon_loss: 0.04000478237867355, dist_loss: 1.4657299518585205
recon_loss: 0.04000164568424225, dist_loss: 0.7463794946670532
recon_loss: 0.03999863192439079, dist_loss: 1.1327993869781494
recon_loss: 0.039995890110731125, dist_loss: 0.41061198711395264
recon_loss: 0.039992980659008026, dist_loss: 0.5465893149375916
recon_loss: 0.039990250021219254, dist_loss: 0.3874255418777466
recon_loss: 0.0399877093732357, dist_loss: 0.9649232625961304
recon_loss: 0.03998476639389992, dist_loss: 0.566939115524292
recon_loss: 0.03998177498579025, dist_loss: 0.48130083084106445
recon_loss: 0.03997906297445297, dist_loss: 0.5018112063407898
recon_loss: 0.03997629135847092, dist_loss: 0.5290564298629761
recon_loss: 0.03997359797358513, dist_loss: 0.40450358390808105
recon_loss: 0.03997090458869934, dist_loss: 0.8386683464050293
recon_loss: 0.03996836394071579, dist_loss: 0.47581151127815247
recon_loss: 0.039965759962797165, dist_loss: 0.673366129398346
recon_loss: 0.0399635024368763, dist_loss: 0.6561931371688843
recon_loss: 0.0399615652859211, dist_loss: 0.4521125555038452
recon_loss: 0.03995978832244873, dist_loss: 0.5572714805603027
recon_loss: 0.03995769843459129, dist_loss: 1.0098154544830322
recon_loss: 0.039955832064151764, dist_loss: 1.1310064792633057
recon_loss: 0.03995397686958313, dist_loss: 0.47527942061424255
recon_loss: 0.0399521179497242, dist_loss: 0.9239045977592468
recon_loss: 0.03995036333799362, dist_loss: 0.5037301182746887
recon_loss: 0.03994850069284439, dist_loss: 0.5417982935905457
recon_loss: 0.03994666039943695, dist_loss: 0.6316710114479065
recon_loss: 0.03994506224989891, dist_loss: 0.562236487865448
recon_loss: 0.03994346037507057, dist_loss: 0.5897235870361328
recon_loss: 0.039941802620887756, dist_loss: 0.7167430520057678
recon_loss: 0.03994004428386688, dist_loss: 0.5956943035125732
recon_loss: 0.0399385467171669, dist_loss: 0.8620432019233704
recon_loss: 0.03993725776672363, dist_loss: 0.659328818321228
recon_loss: 0.03993585333228111, dist_loss: 1.2002248764038086
recon_loss: 0.039934344589710236, dist_loss: 0.9042562246322632
recon_loss: 0.03993264213204384, dist_loss: 0.5422919988632202
recon_loss: 0.039930764585733414, dist_loss: 1.4154813289642334
recon_loss: 0.039929091930389404, dist_loss: 0.43272271752357483
recon_loss: 0.03992731124162674, dist_loss: 1.0824406147003174
recon_loss: 0.03992529213428497, dist_loss: 0.6573600769042969
recon_loss: 0.03992325812578201, dist_loss: 1.001746416091919
recon_loss: 0.03992132842540741, dist_loss: 1.1630141735076904
recon_loss: 0.039919495582580566, dist_loss: 0.30291086435317993
recon_loss: 0.03991742059588432, dist_loss: 0.5889846086502075
recon_loss: 0.03991532698273659, dist_loss: 0.45267799496650696
recon_loss: 0.03991343453526497, dist_loss: 0.995761513710022
recon_loss: 0.03991146385669708, dist_loss: 0.709763765335083
recon_loss: 0.039909400045871735, dist_loss: 0.33362796902656555
recon_loss: 0.03990750387310982, dist_loss: 0.33716291189193726
recon_loss: 0.03990533947944641, dist_loss: 0.8395893573760986
recon_loss: 0.03990362957119942, dist_loss: 0.7953922748565674
recon_loss: 0.0399019680917263, dist_loss: 0.8557482361793518
recon_loss: 0.03990032896399498, dist_loss: 0.4250994324684143
recon_loss: 0.039898693561553955, dist_loss: 0.7663977146148682
recon_loss: 0.039896853268146515, dist_loss: 0.6052002906799316
recon_loss: 0.039895135909318924, dist_loss: 0.5555427074432373
recon_loss: 0.03989339992403984, dist_loss: 0.6383594274520874
recon_loss: 0.03989177197217941, dist_loss: 0.9855704307556152
recon_loss: 0.039890583604574203, dist_loss: 0.4713512659072876
recon_loss: 0.03988949581980705, dist_loss: 0.8720555305480957
recon_loss: 0.03988834097981453, dist_loss: 0.9434754848480225
recon_loss: 0.039886899292469025, dist_loss: 0.6950922012329102
recon_loss: 0.03988519310951233, dist_loss: 0.8205409646034241
recon_loss: 0.039883315563201904, dist_loss: 0.9232622981071472
recon_loss: 0.03988049551844597, dist_loss: 0.8234421610832214
recon_loss: 0.03987744450569153, dist_loss: 0.8930984139442444
recon_loss: 0.039874233305454254, dist_loss: 0.5169497132301331
recon_loss: 0.0398712083697319, dist_loss: 0.7231478691101074
recon_loss: 0.03986849635839462, dist_loss: 0.6274732351303101
recon_loss: 0.03986577317118645, dist_loss: 0.7315554618835449
recon_loss: 0.03986313194036484, dist_loss: 0.5765012502670288
recon_loss: 0.039860669523477554, dist_loss: 1.057106614112854
recon_loss: 0.03985769301652908, dist_loss: 0.7777928709983826
recon_loss: 0.03985470533370972, dist_loss: 0.5635212659835815
recon_loss: 0.03985196724534035, dist_loss: 0.45911890268325806
recon_loss: 0.039849430322647095, dist_loss: 0.8695333003997803
recon_loss: 0.03984656184911728, dist_loss: 0.42286819219589233
recon_loss: 0.03984370082616806, dist_loss: 0.2510901689529419
recon_loss: 0.0398411825299263, dist_loss: 0.6750739216804504
recon_loss: 0.03983881324529648, dist_loss: 0.9866774678230286
recon_loss: 0.03983611986041069, dist_loss: 0.6895326375961304
recon_loss: 0.039833731949329376, dist_loss: 0.9387989044189453
recon_loss: 0.03983126953244209, dist_loss: 0.6169407963752747
recon_loss: 0.03982880711555481, dist_loss: 0.700468897819519
recon_loss: 0.03982625901699066, dist_loss: 0.48913848400115967
recon_loss: 0.039823826402425766, dist_loss: 0.831231951713562
recon_loss: 0.03982122987508774, dist_loss: 0.40254005789756775
recon_loss: 0.03981878235936165, dist_loss: 0.5873163342475891
recon_loss: 0.03981642425060272, dist_loss: 0.4243427515029907
recon_loss: 0.0398143008351326, dist_loss: 0.623414933681488
recon_loss: 0.03981216624379158, dist_loss: 0.6694095134735107
recon_loss: 0.03980981186032295, dist_loss: 0.7225242853164673
recon_loss: 0.039807554334402084, dist_loss: 0.5542155504226685
recon_loss: 0.03980512171983719, dist_loss: 0.56798255443573
recon_loss: 0.03980265557765961, dist_loss: 0.42671096324920654
recon_loss: 0.03980043902993202, dist_loss: 0.6432597041130066
recon_loss: 0.039798151701688766, dist_loss: 0.3663390278816223
recon_loss: 0.039795998483896255, dist_loss: 0.6881241202354431
recon_loss: 0.03979364410042763, dist_loss: 0.44145750999450684
recon_loss: 0.039791129529476166, dist_loss: 0.5634379982948303
recon_loss: 0.039788153022527695, dist_loss: 0.9968991279602051
recon_loss: 0.039785243570804596, dist_loss: 0.6046333909034729
recon_loss: 0.03978235647082329, dist_loss: 1.1924875974655151
recon_loss: 0.039779309183359146, dist_loss: 0.8936997652053833
recon_loss: 0.03977620601654053, dist_loss: 0.5959581136703491
recon_loss: 0.03977338224649429, dist_loss: 0.5594408512115479
recon_loss: 0.03977056220173836, dist_loss: 0.620816707611084
recon_loss: 0.039767999202013016, dist_loss: 0.6909298300743103
recon_loss: 0.03976535052061081, dist_loss: 0.37348484992980957
recon_loss: 0.03976276144385338, dist_loss: 0.9565559029579163
recon_loss: 0.03976045548915863, dist_loss: 0.7644160389900208
recon_loss: 0.03975813463330269, dist_loss: 0.5189770460128784
recon_loss: 0.03975570574402809, dist_loss: 0.7362496852874756
Pre-training Epoch 15:  75%|███████▍  | 275/367 [00:01<00:00, 188.88it/s]Pre-training Epoch 15:  80%|████████  | 295/367 [00:01<00:00, 190.00it/s]Pre-training Epoch 15:  86%|████████▌ | 315/367 [00:01<00:00, 190.61it/s]Pre-training Epoch 15:  91%|█████████▏| 335/367 [00:01<00:00, 191.22it/s]Pre-training Epoch 15:  97%|█████████▋| 355/367 [00:01<00:00, 191.67it/s]Pre-training Epoch 15: 100%|██████████| 367/367 [00:01<00:00, 187.51it/s]
recon_loss: 0.0397532656788826, dist_loss: 0.5106321573257446
recon_loss: 0.03975086286664009, dist_loss: 0.9921393990516663
recon_loss: 0.0397484228014946, dist_loss: 0.7971889972686768
recon_loss: 0.03974581137299538, dist_loss: 0.7808676958084106
recon_loss: 0.03974305838346481, dist_loss: 0.9222527742385864
recon_loss: 0.039740391075611115, dist_loss: 0.618912935256958
recon_loss: 0.03973803669214249, dist_loss: 0.6511067152023315
recon_loss: 0.03973567113280296, dist_loss: 0.7202492952346802
recon_loss: 0.03973308950662613, dist_loss: 1.5199171304702759
recon_loss: 0.039730582386255264, dist_loss: 0.5674330592155457
recon_loss: 0.03972834721207619, dist_loss: 0.6479990482330322
recon_loss: 0.03972610831260681, dist_loss: 1.1195037364959717
recon_loss: 0.03972390666604042, dist_loss: 0.8757004737854004
recon_loss: 0.0397217832505703, dist_loss: 0.8032674193382263
recon_loss: 0.03971976414322853, dist_loss: 0.5405943989753723
recon_loss: 0.03971773758530617, dist_loss: 0.5260645151138306
recon_loss: 0.039715755730867386, dist_loss: 0.43299031257629395
recon_loss: 0.03971373289823532, dist_loss: 0.6963422298431396
recon_loss: 0.03971148654818535, dist_loss: 1.2906148433685303
recon_loss: 0.0397094264626503, dist_loss: 0.3655528128147125
recon_loss: 0.03970757871866226, dist_loss: 0.42629924416542053
recon_loss: 0.03970559313893318, dist_loss: 0.49809104204177856
recon_loss: 0.03970351815223694, dist_loss: 0.8581773042678833
recon_loss: 0.0397009439766407, dist_loss: 0.5503267049789429
recon_loss: 0.03969857469201088, dist_loss: 0.7456384301185608
recon_loss: 0.03969595208764076, dist_loss: 1.2125318050384521
recon_loss: 0.03969355672597885, dist_loss: 1.085667610168457
recon_loss: 0.03969082981348038, dist_loss: 0.34680986404418945
recon_loss: 0.03968820720911026, dist_loss: 0.48313236236572266
recon_loss: 0.03968567028641701, dist_loss: 1.0423758029937744
recon_loss: 0.039683498442173004, dist_loss: 0.9064900875091553
recon_loss: 0.039681192487478256, dist_loss: 0.5610900521278381
recon_loss: 0.039678942412137985, dist_loss: 0.5232844352722168
recon_loss: 0.03967661038041115, dist_loss: 0.6401194930076599
recon_loss: 0.03967408835887909, dist_loss: 0.9066119194030762
recon_loss: 0.039671722799539566, dist_loss: 0.7560887336730957
recon_loss: 0.03966895490884781, dist_loss: 0.3549598455429077
recon_loss: 0.03966669738292694, dist_loss: 0.5662204027175903
recon_loss: 0.0396646223962307, dist_loss: 0.5629748106002808
recon_loss: 0.03966274857521057, dist_loss: 1.088320016860962
recon_loss: 0.03966084495186806, dist_loss: 0.9129385948181152
recon_loss: 0.03965887054800987, dist_loss: 0.4393347203731537
recon_loss: 0.03965698927640915, dist_loss: 0.7758476734161377
recon_loss: 0.039655350148677826, dist_loss: 0.5153080224990845
recon_loss: 0.03965369984507561, dist_loss: 0.6630799770355225
recon_loss: 0.03965197131037712, dist_loss: 0.5572392344474792
recon_loss: 0.03964981064200401, dist_loss: 0.7356684803962708
recon_loss: 0.039647553116083145, dist_loss: 0.5911290645599365
recon_loss: 0.0396452359855175, dist_loss: 0.3288649916648865
recon_loss: 0.03964294120669365, dist_loss: 0.6684309840202332
recon_loss: 0.03964061290025711, dist_loss: 0.33330661058425903
recon_loss: 0.03963811323046684, dist_loss: 0.48206108808517456
recon_loss: 0.0396355465054512, dist_loss: 0.5169044733047485
recon_loss: 0.03963306546211243, dist_loss: 0.5235573649406433
recon_loss: 0.0396306999027729, dist_loss: 0.8884844183921814
recon_loss: 0.03962883725762367, dist_loss: 0.954684317111969
recon_loss: 0.03962702304124832, dist_loss: 0.7503368854522705
recon_loss: 0.03962519019842148, dist_loss: 0.5118482112884521
recon_loss: 0.039623431861400604, dist_loss: 0.5367333292961121
recon_loss: 0.039621785283088684, dist_loss: 0.5362434983253479
recon_loss: 0.03962022438645363, dist_loss: 0.6642199754714966
recon_loss: 0.03961862996220589, dist_loss: 0.9301391243934631
recon_loss: 0.03961741179227829, dist_loss: 0.522038459777832
recon_loss: 0.03961583599448204, dist_loss: 0.6933109760284424
recon_loss: 0.03961441293358803, dist_loss: 0.35680416226387024
recon_loss: 0.03961294889450073, dist_loss: 0.8150782585144043
recon_loss: 0.03961167111992836, dist_loss: 0.520731508731842
recon_loss: 0.039610397070646286, dist_loss: 0.5606800317764282
recon_loss: 0.039608754217624664, dist_loss: 1.114558219909668
recon_loss: 0.0396069698035717, dist_loss: 0.7522623538970947
recon_loss: 0.03960495442152023, dist_loss: 0.6874184012413025
recon_loss: 0.03960273414850235, dist_loss: 0.7423860430717468
recon_loss: 0.03960011526942253, dist_loss: 0.46281206607818604
recon_loss: 0.03959737718105316, dist_loss: 0.5974938869476318
recon_loss: 0.03959475830197334, dist_loss: 0.5531682372093201
recon_loss: 0.039591994136571884, dist_loss: 0.4360928535461426
recon_loss: 0.039589133113622665, dist_loss: 0.722553014755249
recon_loss: 0.039586205035448074, dist_loss: 1.162487506866455
recon_loss: 0.03958318009972572, dist_loss: 0.7444295287132263
recon_loss: 0.03957999497652054, dist_loss: 0.637592077255249
recon_loss: 0.039577264338731766, dist_loss: 0.8801827430725098
recon_loss: 0.0395742766559124, dist_loss: 0.3749920725822449
recon_loss: 0.039571426808834076, dist_loss: 0.5661605596542358
recon_loss: 0.039568543434143066, dist_loss: 0.9262872338294983
recon_loss: 0.039565425366163254, dist_loss: 0.5611768960952759
recon_loss: 0.03956260159611702, dist_loss: 0.9237414598464966
recon_loss: 0.039559684693813324, dist_loss: 0.6169212460517883
recon_loss: 0.03955703228712082, dist_loss: 0.49343976378440857
recon_loss: 0.03955437242984772, dist_loss: 0.6038455963134766
recon_loss: 0.03955164924263954, dist_loss: 0.5635355710983276
recon_loss: 0.039549101144075394, dist_loss: 0.8023124933242798
recon_loss: 0.03954644501209259, dist_loss: 1.069690227508545
recon_loss: 0.039543695747852325, dist_loss: 0.9808822870254517
recon_loss: 0.039541203528642654, dist_loss: 0.7180736064910889
recon_loss: 0.03953889012336731, dist_loss: 0.6481037139892578
recon_loss: 0.039536427706480026, dist_loss: 0.788565993309021
recon_loss: 0.03953413665294647, dist_loss: 0.7540403604507446
recon_loss: 0.03953172266483307, dist_loss: 0.46017616987228394
recon_loss: 0.03952932730317116, dist_loss: 0.46272391080856323
recon_loss: 0.03952684998512268, dist_loss: 0.46557462215423584
recon_loss: 0.03952451050281525, dist_loss: 0.9777488112449646
recon_loss: 0.03952201455831528, dist_loss: 0.48575493693351746
recon_loss: 0.03951934352517128, dist_loss: 0.8614892959594727
recon_loss: 0.03951648250222206, dist_loss: 0.5422849059104919
recon_loss: 0.03951379656791687, dist_loss: 0.5052922964096069
recon_loss: 0.03951115533709526, dist_loss: 0.6020069122314453
recon_loss: 0.03950830176472664, dist_loss: 0.954552173614502
recon_loss: 0.039505261927843094, dist_loss: 0.653287410736084
recon_loss: 0.03950202465057373, dist_loss: 1.230355978012085
Pre-training Epoch 16:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 16:   5%|▌         | 19/367 [00:00<00:01, 188.93it/s]Pre-training Epoch 16:  11%|█         | 39/367 [00:00<00:01, 191.28it/s]Pre-training Epoch 16:  16%|█▌        | 59/367 [00:00<00:01, 192.06it/s]Pre-training Epoch 16:  22%|██▏       | 79/367 [00:00<00:01, 192.47it/s]Pre-training Epoch 16:  27%|██▋       | 99/367 [00:00<00:01, 190.39it/s]Pre-training Epoch 16:  32%|███▏      | 119/367 [00:00<00:01, 190.26it/s]recon_loss: 0.03949856013059616, dist_loss: 0.47836530208587646
recon_loss: 0.03949526324868202, dist_loss: 0.564570426940918
recon_loss: 0.03949200361967087, dist_loss: 0.8535234928131104
recon_loss: 0.039488598704338074, dist_loss: 0.8422770500183105
recon_loss: 0.03948535397648811, dist_loss: 0.5163627862930298
recon_loss: 0.03948204591870308, dist_loss: 1.1777033805847168
recon_loss: 0.039478469640016556, dist_loss: 0.27879682183265686
recon_loss: 0.039474863559007645, dist_loss: 0.9802121520042419
recon_loss: 0.03947136178612709, dist_loss: 0.8507301211357117
recon_loss: 0.03946820646524429, dist_loss: 0.5908573269844055
recon_loss: 0.03946498781442642, dist_loss: 0.9958888292312622
recon_loss: 0.039461757987737656, dist_loss: 0.8837944269180298
recon_loss: 0.03945876657962799, dist_loss: 0.8343459367752075
recon_loss: 0.039455853402614594, dist_loss: 1.4621891975402832
recon_loss: 0.03945271298289299, dist_loss: 0.791732668876648
recon_loss: 0.03944974020123482, dist_loss: 0.5291088223457336
recon_loss: 0.039446715265512466, dist_loss: 1.4691795110702515
recon_loss: 0.03944360837340355, dist_loss: 0.8490070104598999
recon_loss: 0.03944075480103493, dist_loss: 1.0725758075714111
recon_loss: 0.03943795710802078, dist_loss: 0.4913201928138733
recon_loss: 0.03943505883216858, dist_loss: 0.6434569358825684
recon_loss: 0.03943236172199249, dist_loss: 0.52256840467453
recon_loss: 0.039429593831300735, dist_loss: 0.9800237417221069
recon_loss: 0.03942691907286644, dist_loss: 0.941278338432312
recon_loss: 0.039424411952495575, dist_loss: 1.3808413743972778
recon_loss: 0.03942209854722023, dist_loss: 1.2675673961639404
recon_loss: 0.03941992297768593, dist_loss: 0.6118477582931519
recon_loss: 0.03941788151860237, dist_loss: 0.6110258102416992
recon_loss: 0.039415787905454636, dist_loss: 0.6751570701599121
recon_loss: 0.03941376507282257, dist_loss: 0.7466316223144531
recon_loss: 0.03941170871257782, dist_loss: 0.39834290742874146
recon_loss: 0.039409395307302475, dist_loss: 0.30490586161613464
recon_loss: 0.03940723091363907, dist_loss: 1.2483174800872803
recon_loss: 0.039404697716236115, dist_loss: 0.5744750499725342
recon_loss: 0.039401937276124954, dist_loss: 0.3734279274940491
recon_loss: 0.03939869627356529, dist_loss: 0.4286485016345978
recon_loss: 0.039395514875650406, dist_loss: 0.6468404531478882
recon_loss: 0.03939235955476761, dist_loss: 0.6633201241493225
recon_loss: 0.039389193058013916, dist_loss: 0.41826528310775757
recon_loss: 0.039386115968227386, dist_loss: 0.8651923537254333
recon_loss: 0.03938312828540802, dist_loss: 0.7712054252624512
recon_loss: 0.039380017668008804, dist_loss: 0.6657275557518005
recon_loss: 0.039377085864543915, dist_loss: 0.4560890197753906
recon_loss: 0.0393742136657238, dist_loss: 0.6081402897834778
recon_loss: 0.03937120363116264, dist_loss: 0.6265960931777954
recon_loss: 0.03936827555298805, dist_loss: 1.2286264896392822
recon_loss: 0.039365239441394806, dist_loss: 0.44467806816101074
recon_loss: 0.039362452924251556, dist_loss: 0.7270611524581909
recon_loss: 0.03935982286930084, dist_loss: 0.7725881338119507
recon_loss: 0.03935729339718819, dist_loss: 0.6520366668701172
recon_loss: 0.03935481980443001, dist_loss: 0.5360766053199768
recon_loss: 0.03935236856341362, dist_loss: 0.7596877813339233
recon_loss: 0.039349958300590515, dist_loss: 0.8069374561309814
recon_loss: 0.03934729844331741, dist_loss: 0.45095741748809814
recon_loss: 0.03934464231133461, dist_loss: 0.7008877992630005
recon_loss: 0.03934204578399658, dist_loss: 0.7190029621124268
recon_loss: 0.039339467883110046, dist_loss: 0.4451090693473816
recon_loss: 0.039336930960416794, dist_loss: 0.7209148406982422
recon_loss: 0.03933470696210861, dist_loss: 1.091117262840271
recon_loss: 0.03933222219347954, dist_loss: 0.6590256690979004
recon_loss: 0.039329785853624344, dist_loss: 1.1347326040267944
recon_loss: 0.0393274761736393, dist_loss: 0.667228639125824
recon_loss: 0.03932502120733261, dist_loss: 0.6008831858634949
recon_loss: 0.03932267427444458, dist_loss: 0.6430574059486389
recon_loss: 0.03932010009884834, dist_loss: 1.1117355823516846
recon_loss: 0.039317574352025986, dist_loss: 0.7071845531463623
recon_loss: 0.039314672350883484, dist_loss: 0.8850695490837097
recon_loss: 0.03931181877851486, dist_loss: 1.0332701206207275
recon_loss: 0.03930892422795296, dist_loss: 0.9546974897384644
recon_loss: 0.03930620104074478, dist_loss: 0.7697469592094421
recon_loss: 0.03930359706282616, dist_loss: 0.8674433827400208
recon_loss: 0.03930124640464783, dist_loss: 0.9484134912490845
recon_loss: 0.03929855301976204, dist_loss: 0.5976454615592957
recon_loss: 0.03929603844881058, dist_loss: 0.8117091655731201
recon_loss: 0.03929335996508598, dist_loss: 0.49383366107940674
recon_loss: 0.039290811866521835, dist_loss: 1.1836016178131104
recon_loss: 0.039288025349378586, dist_loss: 0.892643928527832
recon_loss: 0.03928546980023384, dist_loss: 0.7525144815444946
recon_loss: 0.039282944053411484, dist_loss: 0.6711992025375366
recon_loss: 0.039280664175748825, dist_loss: 0.47448018193244934
recon_loss: 0.03927852585911751, dist_loss: 0.8895465731620789
recon_loss: 0.039276354014873505, dist_loss: 0.5777028799057007
recon_loss: 0.03927411511540413, dist_loss: 0.7300846576690674
recon_loss: 0.03927203640341759, dist_loss: 0.5820658802986145
recon_loss: 0.03926978260278702, dist_loss: 0.6394971013069153
recon_loss: 0.0392674095928669, dist_loss: 0.255260705947876
recon_loss: 0.0392649844288826, dist_loss: 0.495777428150177
recon_loss: 0.03926224634051323, dist_loss: 0.8027652502059937
recon_loss: 0.03925945609807968, dist_loss: 0.9421659708023071
recon_loss: 0.03925672546029091, dist_loss: 0.7974305152893066
recon_loss: 0.039253875613212585, dist_loss: 0.7951903343200684
recon_loss: 0.03925097733736038, dist_loss: 0.5060098171234131
recon_loss: 0.03924829140305519, dist_loss: 0.5623840689659119
recon_loss: 0.039245884865522385, dist_loss: 0.6229966878890991
recon_loss: 0.03924345225095749, dist_loss: 0.7975257635116577
recon_loss: 0.03924080729484558, dist_loss: 0.4563349783420563
recon_loss: 0.03923828527331352, dist_loss: 0.4643447995185852
recon_loss: 0.03923560306429863, dist_loss: 0.8424972891807556
recon_loss: 0.03923308849334717, dist_loss: 0.7279515266418457
recon_loss: 0.03923061490058899, dist_loss: 0.37296390533447266
recon_loss: 0.03922830894589424, dist_loss: 1.4983372688293457
recon_loss: 0.039225880056619644, dist_loss: 0.6299787759780884
recon_loss: 0.03922348469495773, dist_loss: 0.8890328407287598
recon_loss: 0.03922083601355553, dist_loss: 0.747292697429657
recon_loss: 0.03921835124492645, dist_loss: 0.9086107015609741
recon_loss: 0.03921588882803917, dist_loss: 0.6323044300079346
recon_loss: 0.03921329602599144, dist_loss: 0.5450501441955566
recon_loss: 0.03921079263091087, dist_loss: 0.8049416542053223
recon_loss: 0.039208222180604935, dist_loss: 0.40148022770881653
recon_loss: 0.03920567035675049, dist_loss: 0.44084039330482483
recon_loss: 0.03920299932360649, dist_loss: 0.5586065649986267
recon_loss: 0.03920035809278488, dist_loss: 0.7138832211494446
recon_loss: 0.03919780254364014, dist_loss: 0.6873772740364075
recon_loss: 0.03919494152069092, dist_loss: 0.9457644820213318
recon_loss: 0.03919203579425812, dist_loss: 0.8885443806648254
recon_loss: 0.03918915614485741, dist_loss: 0.6261523962020874
recon_loss: 0.03918612375855446, dist_loss: 0.41394704580307007
recon_loss: 0.03918324410915375, dist_loss: 0.4438559114933014
recon_loss: 0.039180390536785126, dist_loss: 1.2879395484924316
recon_loss: 0.03917758911848068, dist_loss: 0.5852452516555786
recon_loss: 0.03917498141527176, dist_loss: 0.593786358833313
recon_loss: 0.03917226195335388, dist_loss: 0.48725032806396484
recon_loss: 0.03916938230395317, dist_loss: 0.5266941785812378
recon_loss: 0.03916652500629425, dist_loss: 1.0294957160949707
recon_loss: 0.03916370868682861, dist_loss: 0.39673110842704773
recon_loss: 0.039161086082458496, dist_loss: 0.6148443818092346
recon_loss: 0.03915869817137718, dist_loss: 0.9260116815567017
recon_loss: 0.03915613517165184, dist_loss: 0.3107607662677765
recon_loss: 0.03915366157889366, dist_loss: 0.9261978268623352
Pre-training Epoch 16:  38%|███▊      | 139/367 [00:00<00:01, 190.89it/s]Pre-training Epoch 16:  43%|████▎     | 159/367 [00:00<00:01, 191.42it/s]Pre-training Epoch 16:  49%|████▉     | 179/367 [00:00<00:00, 191.64it/s]Pre-training Epoch 16:  54%|█████▍    | 199/367 [00:01<00:00, 191.31it/s]Pre-training Epoch 16:  60%|█████▉    | 219/367 [00:01<00:00, 189.93it/s]Pre-training Epoch 16:  65%|██████▌   | 239/367 [00:01<00:00, 190.82it/s]recon_loss: 0.039151232689619064, dist_loss: 0.6671745777130127
recon_loss: 0.03914874047040939, dist_loss: 1.1167232990264893
recon_loss: 0.039146292954683304, dist_loss: 0.4674750864505768
recon_loss: 0.039144158363342285, dist_loss: 0.6629122495651245
recon_loss: 0.039141733199357986, dist_loss: 0.7292462587356567
recon_loss: 0.039139602333307266, dist_loss: 0.4746860861778259
recon_loss: 0.03913741558790207, dist_loss: 0.5199527740478516
recon_loss: 0.039135273545980453, dist_loss: 0.6856384873390198
recon_loss: 0.03913303092122078, dist_loss: 0.5195140838623047
recon_loss: 0.03913075849413872, dist_loss: 1.3405951261520386
recon_loss: 0.03912869840860367, dist_loss: 0.6734412908554077
recon_loss: 0.03912657871842384, dist_loss: 0.8194544315338135
recon_loss: 0.039124418050050735, dist_loss: 0.6656240224838257
recon_loss: 0.039122335612773895, dist_loss: 0.85621577501297
recon_loss: 0.039120182394981384, dist_loss: 0.35718870162963867
recon_loss: 0.03911789506673813, dist_loss: 0.555351972579956
recon_loss: 0.03911573067307472, dist_loss: 0.8430629968643188
recon_loss: 0.03911373019218445, dist_loss: 0.8575658798217773
recon_loss: 0.039111342281103134, dist_loss: 0.599545955657959
recon_loss: 0.03910927474498749, dist_loss: 0.7705594301223755
recon_loss: 0.039107274264097214, dist_loss: 0.7732637524604797
recon_loss: 0.03910529613494873, dist_loss: 0.5697274804115295
recon_loss: 0.03910291567444801, dist_loss: 0.5530521869659424
recon_loss: 0.039100512862205505, dist_loss: 0.5889534950256348
recon_loss: 0.039098262786865234, dist_loss: 0.841376543045044
recon_loss: 0.0390956774353981, dist_loss: 0.9410617351531982
recon_loss: 0.03909313678741455, dist_loss: 0.34628263115882874
recon_loss: 0.03909069299697876, dist_loss: 0.8316532969474792
recon_loss: 0.03908785432577133, dist_loss: 0.4240105450153351
recon_loss: 0.03908490389585495, dist_loss: 1.0472030639648438
recon_loss: 0.03908226266503334, dist_loss: 0.8161409497261047
recon_loss: 0.03907983377575874, dist_loss: 0.4249836206436157
recon_loss: 0.039077356457710266, dist_loss: 0.41864141821861267
recon_loss: 0.03907499089837074, dist_loss: 0.9074524641036987
recon_loss: 0.03907236084342003, dist_loss: 0.8554666042327881
recon_loss: 0.039070289582014084, dist_loss: 0.8599693775177002
recon_loss: 0.03906821087002754, dist_loss: 0.49426043033599854
recon_loss: 0.03906623274087906, dist_loss: 0.5287197828292847
recon_loss: 0.03906415030360222, dist_loss: 0.4301491975784302
recon_loss: 0.03906204551458359, dist_loss: 0.5303590297698975
recon_loss: 0.03905976191163063, dist_loss: 0.7122726440429688
recon_loss: 0.03905755281448364, dist_loss: 1.0490391254425049
recon_loss: 0.039055194705724716, dist_loss: 0.9146971702575684
recon_loss: 0.03905295208096504, dist_loss: 0.7443619966506958
recon_loss: 0.03905101120471954, dist_loss: 0.8314513564109802
recon_loss: 0.039048969745635986, dist_loss: 0.4129849672317505
recon_loss: 0.039046820253133774, dist_loss: 0.5510499477386475
recon_loss: 0.03904466703534126, dist_loss: 0.5666588544845581
recon_loss: 0.039042506366968155, dist_loss: 0.45214587450027466
recon_loss: 0.039040569216012955, dist_loss: 1.3063328266143799
recon_loss: 0.039038464426994324, dist_loss: 0.7786211967468262
recon_loss: 0.03903631865978241, dist_loss: 0.6933584213256836
recon_loss: 0.039034001529216766, dist_loss: 0.776462197303772
recon_loss: 0.03903214633464813, dist_loss: 0.8772193193435669
recon_loss: 0.039029739797115326, dist_loss: 0.5327119827270508
recon_loss: 0.03902733325958252, dist_loss: 0.9519427418708801
recon_loss: 0.039024896919727325, dist_loss: 0.6852519512176514
recon_loss: 0.039022039622068405, dist_loss: 0.7009059190750122
recon_loss: 0.03901923447847366, dist_loss: 0.5809448957443237
recon_loss: 0.03901662677526474, dist_loss: 0.4126091003417969
recon_loss: 0.03901411592960358, dist_loss: 0.4461010694503784
recon_loss: 0.03901183232665062, dist_loss: 0.9780102372169495
recon_loss: 0.03900937736034393, dist_loss: 0.5492244362831116
recon_loss: 0.03900660574436188, dist_loss: 0.8283482789993286
recon_loss: 0.039004042744636536, dist_loss: 0.37169408798217773
recon_loss: 0.03900141268968582, dist_loss: 0.8386051654815674
recon_loss: 0.03899874910712242, dist_loss: 0.8884677290916443
recon_loss: 0.0389961376786232, dist_loss: 0.5258734226226807
recon_loss: 0.03899325430393219, dist_loss: 0.863535463809967
recon_loss: 0.03899027034640312, dist_loss: 0.6850030422210693
recon_loss: 0.038986966013908386, dist_loss: 0.5348222255706787
recon_loss: 0.03898380324244499, dist_loss: 0.8807830214500427
recon_loss: 0.03898090124130249, dist_loss: 0.8119275569915771
recon_loss: 0.038978081196546555, dist_loss: 0.45193710923194885
recon_loss: 0.03897511959075928, dist_loss: 0.33646729588508606
recon_loss: 0.03897218406200409, dist_loss: 1.1707980632781982
recon_loss: 0.038969382643699646, dist_loss: 0.37905895709991455
recon_loss: 0.038966692984104156, dist_loss: 0.7554061412811279
recon_loss: 0.038963742554187775, dist_loss: 0.632398784160614
recon_loss: 0.03896038234233856, dist_loss: 0.26574036478996277
recon_loss: 0.0389571450650692, dist_loss: 1.0731714963912964
recon_loss: 0.03895396739244461, dist_loss: 0.923110842704773
recon_loss: 0.038950663059949875, dist_loss: 0.43232378363609314
recon_loss: 0.038947273045778275, dist_loss: 0.7632082104682922
recon_loss: 0.03894398361444473, dist_loss: 0.483395516872406
recon_loss: 0.03894058242440224, dist_loss: 0.7181410193443298
recon_loss: 0.038937315344810486, dist_loss: 0.682453453540802
recon_loss: 0.03893459215760231, dist_loss: 0.8450933694839478
recon_loss: 0.038931798189878464, dist_loss: 0.6399033665657043
recon_loss: 0.038928840309381485, dist_loss: 0.96980220079422
recon_loss: 0.038926053792238235, dist_loss: 1.0233910083770752
recon_loss: 0.038923103362321854, dist_loss: 0.3520278334617615
recon_loss: 0.03892018646001816, dist_loss: 0.9825819730758667
recon_loss: 0.038917362689971924, dist_loss: 0.5775334239006042
recon_loss: 0.03891463950276375, dist_loss: 0.715707540512085
recon_loss: 0.038912225514650345, dist_loss: 0.775465726852417
recon_loss: 0.03890947625041008, dist_loss: 1.0006749629974365
recon_loss: 0.03890698775649071, dist_loss: 0.5675784349441528
recon_loss: 0.038904473185539246, dist_loss: 0.5948946475982666
recon_loss: 0.03890211880207062, dist_loss: 0.8344861268997192
recon_loss: 0.03889959305524826, dist_loss: 0.8692865967750549
recon_loss: 0.03889714553952217, dist_loss: 0.8776960372924805
recon_loss: 0.038894619792699814, dist_loss: 0.5436972379684448
recon_loss: 0.03889177739620209, dist_loss: 0.9170969724655151
recon_loss: 0.03888882324099541, dist_loss: 0.7925249338150024
recon_loss: 0.03888570889830589, dist_loss: 0.7872104644775391
recon_loss: 0.0388827845454216, dist_loss: 0.6933274269104004
recon_loss: 0.038879744708538055, dist_loss: 0.49701404571533203
recon_loss: 0.03887670487165451, dist_loss: 0.7043014764785767
recon_loss: 0.0388735830783844, dist_loss: 0.5953822731971741
recon_loss: 0.038870394229888916, dist_loss: 0.9176883697509766
recon_loss: 0.03886738419532776, dist_loss: 0.8112156987190247
recon_loss: 0.038864120841026306, dist_loss: 1.1146836280822754
recon_loss: 0.03886089473962784, dist_loss: 0.6867940425872803
recon_loss: 0.03885801136493683, dist_loss: 0.6458545923233032
recon_loss: 0.03885491564869881, dist_loss: 0.8621435165405273
recon_loss: 0.03885182738304138, dist_loss: 0.7905714511871338
recon_loss: 0.03884870186448097, dist_loss: 0.7714210748672485
recon_loss: 0.038845498114824295, dist_loss: 0.45623335242271423
recon_loss: 0.03884243965148926, dist_loss: 0.6649435758590698
recon_loss: 0.0388394296169281, dist_loss: 0.5411638617515564
recon_loss: 0.03883635625243187, dist_loss: 0.9426254034042358
recon_loss: 0.03883299604058266, dist_loss: 0.6702291369438171
recon_loss: 0.038829345256090164, dist_loss: 0.9052854776382446
recon_loss: 0.038825780153274536, dist_loss: 0.7597346901893616
recon_loss: 0.03882255777716637, dist_loss: 0.7903453707695007
recon_loss: 0.03881921246647835, dist_loss: 0.4471321105957031
recon_loss: 0.03881596773862839, dist_loss: 0.5924599170684814
recon_loss: 0.038813184946775436, dist_loss: 0.9698064923286438
Pre-training Epoch 16:  71%|███████   | 259/367 [00:01<00:00, 191.43it/s]Pre-training Epoch 16:  76%|███████▌  | 279/367 [00:01<00:00, 191.85it/s]Pre-training Epoch 16:  81%|████████▏ | 299/367 [00:01<00:00, 181.94it/s]Pre-training Epoch 16:  87%|████████▋ | 318/367 [00:01<00:00, 181.38it/s]Pre-training Epoch 16:  92%|█████████▏| 337/367 [00:01<00:00, 179.62it/s]Pre-training Epoch 16:  97%|█████████▋| 356/367 [00:01<00:00, 179.36it/s]Pre-training Epoch 16: 100%|██████████| 367/367 [00:01<00:00, 186.84it/s]
recon_loss: 0.03881022706627846, dist_loss: 0.4557117819786072
recon_loss: 0.03880720213055611, dist_loss: 0.2647395133972168
recon_loss: 0.03880424425005913, dist_loss: 0.7955643534660339
recon_loss: 0.03880108892917633, dist_loss: 0.5139569640159607
recon_loss: 0.038798071444034576, dist_loss: 0.581789493560791
recon_loss: 0.03879495710134506, dist_loss: 0.6536847949028015
recon_loss: 0.03879173845052719, dist_loss: 0.6312427520751953
recon_loss: 0.03878872096538544, dist_loss: 0.3976414203643799
recon_loss: 0.03878561407327652, dist_loss: 0.3886588513851166
recon_loss: 0.038782503455877304, dist_loss: 0.6582318544387817
recon_loss: 0.0387796089053154, dist_loss: 0.771451473236084
recon_loss: 0.038776613771915436, dist_loss: 0.534121572971344
recon_loss: 0.03877353295683861, dist_loss: 0.7331708669662476
recon_loss: 0.03877067193388939, dist_loss: 0.5563443899154663
recon_loss: 0.03876763582229614, dist_loss: 0.4973437786102295
recon_loss: 0.038764677941799164, dist_loss: 0.8009287714958191
recon_loss: 0.03876156359910965, dist_loss: 0.7282317876815796
recon_loss: 0.03875841572880745, dist_loss: 0.8061710596084595
recon_loss: 0.038755469024181366, dist_loss: 0.41475728154182434
recon_loss: 0.03875245898962021, dist_loss: 0.9384047985076904
recon_loss: 0.03874935582280159, dist_loss: 0.5363888740539551
recon_loss: 0.03874623775482178, dist_loss: 0.5303320288658142
recon_loss: 0.038743048906326294, dist_loss: 0.5773725509643555
recon_loss: 0.038739994168281555, dist_loss: 0.6065858602523804
recon_loss: 0.03873727470636368, dist_loss: 0.4922410547733307
recon_loss: 0.03873433172702789, dist_loss: 0.5231531858444214
recon_loss: 0.03873158618807793, dist_loss: 0.5172516107559204
recon_loss: 0.03872909024357796, dist_loss: 1.1769952774047852
recon_loss: 0.03872697427868843, dist_loss: 0.4483368694782257
recon_loss: 0.03872479870915413, dist_loss: 0.5242422819137573
recon_loss: 0.03872261568903923, dist_loss: 0.9460998773574829
recon_loss: 0.03872036188840866, dist_loss: 0.5879170298576355
recon_loss: 0.0387178398668766, dist_loss: 0.8157079219818115
recon_loss: 0.038715314120054245, dist_loss: 0.5229623913764954
recon_loss: 0.03871277719736099, dist_loss: 0.8040307760238647
recon_loss: 0.038709886372089386, dist_loss: 0.5205186605453491
recon_loss: 0.03870689868927002, dist_loss: 0.878555417060852
recon_loss: 0.038703933358192444, dist_loss: 0.5634723901748657
recon_loss: 0.03870071470737457, dist_loss: 0.8860941529273987
recon_loss: 0.038697656244039536, dist_loss: 0.4977765381336212
recon_loss: 0.03869480639696121, dist_loss: 0.6837587356567383
recon_loss: 0.03869189694523811, dist_loss: 0.45589059591293335
recon_loss: 0.038688745349645615, dist_loss: 1.1326768398284912
recon_loss: 0.03868553042411804, dist_loss: 0.9618465900421143
recon_loss: 0.038682278245687485, dist_loss: 0.5780657529830933
recon_loss: 0.03867889195680618, dist_loss: 0.7365080118179321
recon_loss: 0.03867531567811966, dist_loss: 0.6218934655189514
recon_loss: 0.038671884685754776, dist_loss: 0.5987263321876526
recon_loss: 0.03866852447390556, dist_loss: 0.4969426393508911
recon_loss: 0.03866539150476456, dist_loss: 0.603047251701355
recon_loss: 0.038662295788526535, dist_loss: 0.6755974292755127
recon_loss: 0.038659386336803436, dist_loss: 0.48871350288391113
recon_loss: 0.03865639865398407, dist_loss: 0.5638689994812012
recon_loss: 0.03865358978509903, dist_loss: 0.7078993320465088
recon_loss: 0.038650546222925186, dist_loss: 0.61976158618927
recon_loss: 0.038646962493658066, dist_loss: 0.6072019338607788
recon_loss: 0.038643430918455124, dist_loss: 0.7741539478302002
recon_loss: 0.03863995522260666, dist_loss: 0.49902892112731934
recon_loss: 0.038636624813079834, dist_loss: 0.7424763441085815
recon_loss: 0.03863321244716644, dist_loss: 0.7098970413208008
recon_loss: 0.03862990066409111, dist_loss: 0.7479164600372314
recon_loss: 0.038626715540885925, dist_loss: 0.5739172697067261
recon_loss: 0.03862394019961357, dist_loss: 0.470364511013031
recon_loss: 0.03862106055021286, dist_loss: 0.6896247267723083
recon_loss: 0.038618266582489014, dist_loss: 0.7526726722717285
recon_loss: 0.03861536085605621, dist_loss: 0.9918033480644226
recon_loss: 0.038612835109233856, dist_loss: 0.4135803282260895
recon_loss: 0.038610439747571945, dist_loss: 0.3986421823501587
recon_loss: 0.03860803693532944, dist_loss: 0.791446328163147
recon_loss: 0.03860582411289215, dist_loss: 0.6389065384864807
recon_loss: 0.038603540509939194, dist_loss: 1.1043291091918945
recon_loss: 0.038601670414209366, dist_loss: 0.8086073398590088
recon_loss: 0.03859938308596611, dist_loss: 0.6287353038787842
recon_loss: 0.03859679400920868, dist_loss: 0.582529604434967
recon_loss: 0.03859427198767662, dist_loss: 0.5970336198806763
recon_loss: 0.03859157860279083, dist_loss: 0.6363288164138794
recon_loss: 0.03858888894319534, dist_loss: 0.40462052822113037
recon_loss: 0.03858588635921478, dist_loss: 0.603766143321991
recon_loss: 0.03858306631445885, dist_loss: 0.6001015305519104
recon_loss: 0.038580503314733505, dist_loss: 0.44943276047706604
recon_loss: 0.03857768326997757, dist_loss: 0.7720407247543335
recon_loss: 0.038574736565351486, dist_loss: 0.6632387638092041
recon_loss: 0.03857174515724182, dist_loss: 0.933522641658783
recon_loss: 0.03856905177235603, dist_loss: 0.6752158403396606
recon_loss: 0.0385662205517292, dist_loss: 0.6405657529830933
recon_loss: 0.03856349736452103, dist_loss: 0.31173086166381836
recon_loss: 0.038560766726732254, dist_loss: 0.8197739720344543
recon_loss: 0.03855809196829796, dist_loss: 0.7474496364593506
recon_loss: 0.03855528309941292, dist_loss: 0.794922947883606
recon_loss: 0.03855203092098236, dist_loss: 0.5261331796646118
recon_loss: 0.03854873403906822, dist_loss: 0.39627712965011597
recon_loss: 0.038545481860637665, dist_loss: 0.5305508375167847
recon_loss: 0.03854244202375412, dist_loss: 0.39640313386917114
recon_loss: 0.038539379835128784, dist_loss: 0.7046476602554321
recon_loss: 0.03853641450405121, dist_loss: 0.461037814617157
recon_loss: 0.038533344864845276, dist_loss: 0.5995749235153198
recon_loss: 0.03853029012680054, dist_loss: 0.5687633156776428
recon_loss: 0.03852728381752968, dist_loss: 0.9597867727279663
recon_loss: 0.03852398693561554, dist_loss: 0.5738391876220703
recon_loss: 0.038520656526088715, dist_loss: 0.6384811401367188
recon_loss: 0.0385172963142395, dist_loss: 0.6741138696670532
recon_loss: 0.038514409214258194, dist_loss: 0.4747695028781891
recon_loss: 0.03851151838898659, dist_loss: 0.7688596248626709
recon_loss: 0.0385083369910717, dist_loss: 0.6671430468559265
recon_loss: 0.03850512206554413, dist_loss: 0.9965865015983582
recon_loss: 0.038502052426338196, dist_loss: 0.673241376876831
recon_loss: 0.03849932923913002, dist_loss: 0.36072733998298645
recon_loss: 0.038496747612953186, dist_loss: 0.6633902788162231
recon_loss: 0.03849445655941963, dist_loss: 0.39632663130760193
Pre-training Epoch 17:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 17:   5%|▍         | 17/367 [00:00<00:02, 167.57it/s]Pre-training Epoch 17:  10%|▉         | 36/367 [00:00<00:01, 175.40it/s]Pre-training Epoch 17:  15%|█▍        | 55/367 [00:00<00:01, 178.44it/s]Pre-training Epoch 17:  20%|█▉        | 73/367 [00:00<00:01, 178.42it/s]Pre-training Epoch 17:  25%|██▍       | 91/367 [00:00<00:01, 177.95it/s]Pre-training Epoch 17:  30%|██▉       | 109/367 [00:00<00:01, 176.44it/s]Pre-training Epoch 17:  35%|███▍      | 127/367 [00:00<00:01, 177.10it/s]recon_loss: 0.0384921096265316, dist_loss: 0.852625846862793
recon_loss: 0.03848935663700104, dist_loss: 0.5040014386177063
recon_loss: 0.03848658502101898, dist_loss: 0.8659536838531494
recon_loss: 0.03848366066813469, dist_loss: 0.7802698612213135
recon_loss: 0.0384809747338295, dist_loss: 0.871870756149292
recon_loss: 0.038478199392557144, dist_loss: 0.7015078663825989
recon_loss: 0.038475409150123596, dist_loss: 1.263959288597107
recon_loss: 0.03847251459956169, dist_loss: 0.880763590335846
recon_loss: 0.038469523191452026, dist_loss: 0.9187598824501038
recon_loss: 0.03846653178334236, dist_loss: 0.634272575378418
recon_loss: 0.03846351429820061, dist_loss: 0.9997103214263916
recon_loss: 0.038460489362478256, dist_loss: 0.7141008377075195
recon_loss: 0.03845739737153053, dist_loss: 0.5791020393371582
recon_loss: 0.03845416009426117, dist_loss: 0.7467852830886841
recon_loss: 0.03845096006989479, dist_loss: 0.32320642471313477
recon_loss: 0.0384477935731411, dist_loss: 0.39313846826553345
recon_loss: 0.03844470903277397, dist_loss: 1.0435945987701416
recon_loss: 0.03844185546040535, dist_loss: 0.8500043153762817
recon_loss: 0.038438983261585236, dist_loss: 0.42438992857933044
recon_loss: 0.03843599557876587, dist_loss: 1.0768542289733887
recon_loss: 0.03843313455581665, dist_loss: 0.5552493333816528
recon_loss: 0.038430292159318924, dist_loss: 0.5104543566703796
recon_loss: 0.0384269654750824, dist_loss: 0.5483863353729248
recon_loss: 0.03842348977923393, dist_loss: 0.5332474708557129
recon_loss: 0.03842024877667427, dist_loss: 0.8898497223854065
recon_loss: 0.038417138159275055, dist_loss: 0.609244167804718
recon_loss: 0.0384143702685833, dist_loss: 0.707490086555481
recon_loss: 0.0384114570915699, dist_loss: 0.38634878396987915
recon_loss: 0.03840868920087814, dist_loss: 0.8844238519668579
recon_loss: 0.038405854254961014, dist_loss: 0.5541772246360779
recon_loss: 0.038403403013944626, dist_loss: 0.3330349922180176
recon_loss: 0.038400739431381226, dist_loss: 0.7770228981971741
recon_loss: 0.03839839994907379, dist_loss: 0.5641114711761475
recon_loss: 0.03839564695954323, dist_loss: 0.8004210591316223
recon_loss: 0.038392867892980576, dist_loss: 0.5751748085021973
recon_loss: 0.03838999196887016, dist_loss: 0.4355560839176178
recon_loss: 0.03838725388050079, dist_loss: 0.8683246374130249
recon_loss: 0.038384489715099335, dist_loss: 0.833385705947876
recon_loss: 0.03838195651769638, dist_loss: 0.8940385580062866
recon_loss: 0.03837979584932327, dist_loss: 0.7715734839439392
recon_loss: 0.03837747126817703, dist_loss: 0.5587832927703857
recon_loss: 0.038374967873096466, dist_loss: 1.068264365196228
recon_loss: 0.03837209567427635, dist_loss: 1.0549895763397217
recon_loss: 0.03836936876177788, dist_loss: 0.643789529800415
recon_loss: 0.03836650401353836, dist_loss: 0.68948894739151
recon_loss: 0.03836384788155556, dist_loss: 0.38147294521331787
recon_loss: 0.03836121782660484, dist_loss: 0.7374540567398071
recon_loss: 0.03835858777165413, dist_loss: 1.3820903301239014
recon_loss: 0.03835591301321983, dist_loss: 0.551276683807373
recon_loss: 0.038353271782398224, dist_loss: 0.8415570259094238
recon_loss: 0.03835057094693184, dist_loss: 0.48502790927886963
recon_loss: 0.03834778442978859, dist_loss: 0.43579626083374023
recon_loss: 0.03834493085741997, dist_loss: 0.6609704494476318
recon_loss: 0.03834245353937149, dist_loss: 0.7684268951416016
recon_loss: 0.03833999112248421, dist_loss: 0.5650221109390259
recon_loss: 0.03833768516778946, dist_loss: 0.5190081596374512
recon_loss: 0.03833546116948128, dist_loss: 0.2986421585083008
recon_loss: 0.03833318129181862, dist_loss: 0.6277871131896973
recon_loss: 0.03833095729351044, dist_loss: 0.5323702692985535
recon_loss: 0.03832913190126419, dist_loss: 1.7287019491195679
recon_loss: 0.03832772746682167, dist_loss: 1.1177430152893066
recon_loss: 0.03832612931728363, dist_loss: 0.8276166915893555
recon_loss: 0.03832406550645828, dist_loss: 0.5958329439163208
recon_loss: 0.03832215070724487, dist_loss: 0.4441203773021698
recon_loss: 0.03832037001848221, dist_loss: 0.6283983588218689
recon_loss: 0.03831860050559044, dist_loss: 0.6227850914001465
recon_loss: 0.03831646591424942, dist_loss: 0.6439914107322693
recon_loss: 0.03831372782588005, dist_loss: 0.5263463854789734
recon_loss: 0.03831076994538307, dist_loss: 1.040233850479126
recon_loss: 0.03830792009830475, dist_loss: 0.4013258218765259
recon_loss: 0.0383051298558712, dist_loss: 0.5451515913009644
recon_loss: 0.038302287459373474, dist_loss: 0.8919117450714111
recon_loss: 0.03829887881875038, dist_loss: 1.1172312498092651
recon_loss: 0.0382954403758049, dist_loss: 1.0422124862670898
recon_loss: 0.03829200938344002, dist_loss: 0.5615636110305786
recon_loss: 0.03828897327184677, dist_loss: 0.633536696434021
recon_loss: 0.038286127150058746, dist_loss: 0.6327605247497559
recon_loss: 0.038283009082078934, dist_loss: 0.9882587194442749
recon_loss: 0.038279782980680466, dist_loss: 0.5427777171134949
recon_loss: 0.038276467472314835, dist_loss: 0.5951558351516724
recon_loss: 0.038273345679044724, dist_loss: 0.5813981294631958
recon_loss: 0.03827006369829178, dist_loss: 0.3115953803062439
recon_loss: 0.038266777992248535, dist_loss: 0.5278199911117554
recon_loss: 0.03826351836323738, dist_loss: 0.23370245099067688
recon_loss: 0.038260310888290405, dist_loss: 0.6588793992996216
recon_loss: 0.038257066160440445, dist_loss: 0.9212641716003418
recon_loss: 0.03825359418988228, dist_loss: 0.7773264050483704
recon_loss: 0.038250457495450974, dist_loss: 0.5204980969429016
recon_loss: 0.03824746236205101, dist_loss: 0.877070963382721
recon_loss: 0.03824450448155403, dist_loss: 0.6900783777236938
recon_loss: 0.03824175149202347, dist_loss: 0.45371219515800476
recon_loss: 0.03823883458971977, dist_loss: 0.7058577537536621
recon_loss: 0.03823567554354668, dist_loss: 1.0119192600250244
recon_loss: 0.03823253884911537, dist_loss: 0.6765405535697937
recon_loss: 0.0382295660674572, dist_loss: 0.8664569854736328
recon_loss: 0.0382261797785759, dist_loss: 0.9764477014541626
recon_loss: 0.038222648203372955, dist_loss: 1.036316156387329
recon_loss: 0.038218915462493896, dist_loss: 0.8234259486198425
recon_loss: 0.038215264678001404, dist_loss: 0.5641428232192993
recon_loss: 0.03821151331067085, dist_loss: 0.9455376863479614
recon_loss: 0.038207873702049255, dist_loss: 0.5963492393493652
recon_loss: 0.03820425271987915, dist_loss: 0.8258390426635742
recon_loss: 0.03820066526532173, dist_loss: 0.6729028820991516
recon_loss: 0.03819708153605461, dist_loss: 0.8234134912490845
recon_loss: 0.03819364681839943, dist_loss: 0.5950119495391846
recon_loss: 0.038190167397260666, dist_loss: 0.4199860692024231
recon_loss: 0.038186777383089066, dist_loss: 0.8742480278015137
recon_loss: 0.03818304091691971, dist_loss: 0.6690461039543152
recon_loss: 0.03817928582429886, dist_loss: 0.917308509349823
recon_loss: 0.03817582130432129, dist_loss: 0.9134522676467896
recon_loss: 0.038172367960214615, dist_loss: 0.5088791847229004
recon_loss: 0.03816899657249451, dist_loss: 1.1952950954437256
recon_loss: 0.03816554695367813, dist_loss: 0.6221573948860168
recon_loss: 0.03816227987408638, dist_loss: 0.41546428203582764
recon_loss: 0.038158878684043884, dist_loss: 0.8053382039070129
recon_loss: 0.03815540298819542, dist_loss: 0.7629538178443909
recon_loss: 0.03815209120512009, dist_loss: 0.48173171281814575
recon_loss: 0.038148876279592514, dist_loss: 0.7058988809585571
recon_loss: 0.03814572095870972, dist_loss: 0.5848150253295898
recon_loss: 0.03814256936311722, dist_loss: 0.6490992307662964
recon_loss: 0.03813937306404114, dist_loss: 0.7260842323303223
recon_loss: 0.03813592717051506, dist_loss: 0.5394800305366516
recon_loss: 0.03813261166214943, dist_loss: 0.7527942657470703
recon_loss: 0.03812925145030022, dist_loss: 0.601775050163269
recon_loss: 0.038125816732645035, dist_loss: 0.5419864058494568
recon_loss: 0.038122471421957016, dist_loss: 0.9928706288337708
recon_loss: 0.03811904788017273, dist_loss: 0.4742652177810669
recon_loss: 0.038115669041872025, dist_loss: 0.737115740776062
recon_loss: 0.03811236470937729, dist_loss: 0.5461767911911011
Pre-training Epoch 17:  40%|███▉      | 145/367 [00:00<00:01, 176.49it/s]Pre-training Epoch 17:  44%|████▍     | 163/367 [00:00<00:01, 177.50it/s]Pre-training Epoch 17:  50%|████▉     | 182/367 [00:01<00:01, 179.96it/s]Pre-training Epoch 17:  55%|█████▌    | 202/367 [00:01<00:00, 184.40it/s]Pre-training Epoch 17:  60%|██████    | 222/367 [00:01<00:00, 187.47it/s]Pre-training Epoch 17:  66%|██████▌   | 241/367 [00:01<00:00, 187.87it/s]recon_loss: 0.038109105080366135, dist_loss: 0.6153752207756042
recon_loss: 0.0381058007478714, dist_loss: 0.5257622003555298
recon_loss: 0.03810260817408562, dist_loss: 0.5960540771484375
recon_loss: 0.03809945657849312, dist_loss: 0.6621167659759521
recon_loss: 0.03809656947851181, dist_loss: 0.5446553826332092
recon_loss: 0.03809363394975662, dist_loss: 0.6953569054603577
recon_loss: 0.038090843707323074, dist_loss: 0.817509651184082
recon_loss: 0.03808854892849922, dist_loss: 0.5596022605895996
recon_loss: 0.038086310029029846, dist_loss: 0.7894724607467651
recon_loss: 0.038083989173173904, dist_loss: 0.9412845373153687
recon_loss: 0.038081612437963486, dist_loss: 0.7494449019432068
recon_loss: 0.038079310208559036, dist_loss: 0.4002178907394409
recon_loss: 0.038076918572187424, dist_loss: 0.4175657331943512
recon_loss: 0.038074735552072525, dist_loss: 0.650809109210968
recon_loss: 0.038072194904088974, dist_loss: 0.845067024230957
recon_loss: 0.03806939721107483, dist_loss: 0.8606886267662048
recon_loss: 0.03806644678115845, dist_loss: 0.576854944229126
recon_loss: 0.03806349262595177, dist_loss: 0.7179559469223022
recon_loss: 0.03806018456816673, dist_loss: 0.7623195052146912
recon_loss: 0.03805674612522125, dist_loss: 0.7983989715576172
recon_loss: 0.038053348660469055, dist_loss: 0.7869653701782227
recon_loss: 0.038049958646297455, dist_loss: 0.6534886360168457
recon_loss: 0.03804641216993332, dist_loss: 0.42745310068130493
recon_loss: 0.038042910397052765, dist_loss: 0.7591480016708374
recon_loss: 0.038039207458496094, dist_loss: 0.9723107814788818
recon_loss: 0.038035642355680466, dist_loss: 0.6163226366043091
recon_loss: 0.038031984120607376, dist_loss: 0.5322487354278564
recon_loss: 0.0380285270512104, dist_loss: 0.5364024639129639
recon_loss: 0.03802526369690895, dist_loss: 0.7044290900230408
recon_loss: 0.03802226856350899, dist_loss: 0.6653797626495361
recon_loss: 0.03801938146352768, dist_loss: 0.7310025691986084
recon_loss: 0.03801683709025383, dist_loss: 0.8261334896087646
recon_loss: 0.038014449179172516, dist_loss: 0.49995654821395874
recon_loss: 0.038011740893125534, dist_loss: 0.6817775964736938
recon_loss: 0.03800909221172333, dist_loss: 0.45206567645072937
recon_loss: 0.03800617903470993, dist_loss: 0.9465071558952332
recon_loss: 0.03800300881266594, dist_loss: 0.34252673387527466
recon_loss: 0.03799961507320404, dist_loss: 1.3936607837677002
recon_loss: 0.03799660876393318, dist_loss: 0.6175459623336792
recon_loss: 0.03799377381801605, dist_loss: 0.855567991733551
recon_loss: 0.037990864366292953, dist_loss: 0.34475043416023254
recon_loss: 0.03798803314566612, dist_loss: 0.5883438587188721
recon_loss: 0.03798525407910347, dist_loss: 0.4993864893913269
recon_loss: 0.03798261657357216, dist_loss: 0.5890299081802368
recon_loss: 0.037980157881975174, dist_loss: 0.9070028066635132
recon_loss: 0.03797750547528267, dist_loss: 0.440328985452652
recon_loss: 0.037974994629621506, dist_loss: 0.6474331617355347
recon_loss: 0.037972342222929, dist_loss: 0.36160364747047424
recon_loss: 0.037969592958688736, dist_loss: 0.5659696459770203
recon_loss: 0.03796684741973877, dist_loss: 0.9422301054000854
recon_loss: 0.03796420618891716, dist_loss: 0.2590738534927368
recon_loss: 0.037961412221193314, dist_loss: 0.905613124370575
recon_loss: 0.03795841708779335, dist_loss: 0.5622401237487793
recon_loss: 0.03795545548200607, dist_loss: 0.4695943593978882
recon_loss: 0.03795266151428223, dist_loss: 0.33911627531051636
recon_loss: 0.03794999048113823, dist_loss: 0.643386721611023
recon_loss: 0.037947263568639755, dist_loss: 0.5831321477890015
recon_loss: 0.03794465586543083, dist_loss: 0.6059496998786926
recon_loss: 0.03794212266802788, dist_loss: 0.4876510202884674
recon_loss: 0.03793943300843239, dist_loss: 0.47088491916656494
recon_loss: 0.037936579436063766, dist_loss: 1.1723768711090088
recon_loss: 0.03793366998434067, dist_loss: 0.9077205061912537
recon_loss: 0.03793063014745712, dist_loss: 0.6400961875915527
recon_loss: 0.03792744502425194, dist_loss: 0.8264706134796143
recon_loss: 0.0379243828356266, dist_loss: 0.6402386426925659
recon_loss: 0.03792117163538933, dist_loss: 0.6312509775161743
recon_loss: 0.03791802376508713, dist_loss: 0.8957542181015015
recon_loss: 0.037914905697107315, dist_loss: 0.5255455374717712
recon_loss: 0.03791161626577377, dist_loss: 0.48761409521102905
recon_loss: 0.037908364087343216, dist_loss: 0.7802205085754395
recon_loss: 0.037905141711235046, dist_loss: 0.9899740815162659
recon_loss: 0.037901949137449265, dist_loss: 0.8267090320587158
recon_loss: 0.03789876028895378, dist_loss: 1.4892222881317139
recon_loss: 0.037895478308200836, dist_loss: 0.4482106566429138
recon_loss: 0.03789210319519043, dist_loss: 0.5699716210365295
recon_loss: 0.037889041006565094, dist_loss: 0.5800955891609192
recon_loss: 0.03788594529032707, dist_loss: 0.6016615629196167
recon_loss: 0.03788292407989502, dist_loss: 0.580561637878418
recon_loss: 0.03787961229681969, dist_loss: 0.7428849935531616
recon_loss: 0.037876300513744354, dist_loss: 0.6986340284347534
recon_loss: 0.0378732830286026, dist_loss: 0.5154550075531006
recon_loss: 0.037870485335588455, dist_loss: 0.5333558917045593
recon_loss: 0.03786754235625267, dist_loss: 0.8716704845428467
recon_loss: 0.03786453977227211, dist_loss: 0.9366003274917603
recon_loss: 0.037861768156290054, dist_loss: 0.6659995317459106
recon_loss: 0.037858929485082626, dist_loss: 0.9816938042640686
recon_loss: 0.03785643354058266, dist_loss: 0.7164437770843506
recon_loss: 0.037853993475437164, dist_loss: 0.9188043475151062
recon_loss: 0.03785157948732376, dist_loss: 0.4984486997127533
recon_loss: 0.03784927353262901, dist_loss: 0.6194669008255005
recon_loss: 0.037846941500902176, dist_loss: 0.4929271936416626
recon_loss: 0.03784465044736862, dist_loss: 0.7188687324523926
recon_loss: 0.037842199206352234, dist_loss: 1.1144485473632812
recon_loss: 0.03783969208598137, dist_loss: 0.6662719249725342
recon_loss: 0.037837229669094086, dist_loss: 0.7293487787246704
recon_loss: 0.037834666669368744, dist_loss: 0.8787308931350708
recon_loss: 0.03783196210861206, dist_loss: 1.2186965942382812
recon_loss: 0.03782942518591881, dist_loss: 0.614349365234375
recon_loss: 0.03782682120800018, dist_loss: 0.7334216833114624
recon_loss: 0.037824224680662155, dist_loss: 0.46857377886772156
recon_loss: 0.03782142326235771, dist_loss: 0.42392343282699585
recon_loss: 0.03781885653734207, dist_loss: 0.49023884534835815
recon_loss: 0.03781633824110031, dist_loss: 0.5690462589263916
recon_loss: 0.03781356289982796, dist_loss: 0.7890837788581848
recon_loss: 0.03781057521700859, dist_loss: 0.6708418130874634
recon_loss: 0.03780755400657654, dist_loss: 1.0091294050216675
recon_loss: 0.03780505806207657, dist_loss: 0.7877426743507385
recon_loss: 0.0378023125231266, dist_loss: 0.7952264547348022
recon_loss: 0.037799518555402756, dist_loss: 0.40475568175315857
recon_loss: 0.037797048687934875, dist_loss: 0.5940765142440796
recon_loss: 0.03779501095414162, dist_loss: 0.49421679973602295
recon_loss: 0.037792645394802094, dist_loss: 0.5516384840011597
recon_loss: 0.037790313363075256, dist_loss: 0.49643224477767944
recon_loss: 0.03778788819909096, dist_loss: 0.4797218441963196
recon_loss: 0.03778523579239845, dist_loss: 0.4705212116241455
recon_loss: 0.03778253495693207, dist_loss: 1.242989182472229
recon_loss: 0.0377797894179821, dist_loss: 0.6169683337211609
recon_loss: 0.03777709975838661, dist_loss: 0.9204200506210327
recon_loss: 0.03777410462498665, dist_loss: 0.5920844078063965
recon_loss: 0.03777123615145683, dist_loss: 0.7640968561172485
recon_loss: 0.03776845335960388, dist_loss: 0.7873189449310303
recon_loss: 0.03776586428284645, dist_loss: 0.5870696306228638
recon_loss: 0.0377633236348629, dist_loss: 0.4472753405570984
recon_loss: 0.03776080906391144, dist_loss: 0.6104795932769775
recon_loss: 0.03775820508599281, dist_loss: 0.7561008930206299
recon_loss: 0.03775583580136299, dist_loss: 0.6317108869552612
recon_loss: 0.03775349631905556, dist_loss: 1.011861801147461
recon_loss: 0.03775086998939514, dist_loss: 0.798546552658081
recon_loss: 0.03774820268154144, dist_loss: 1.205944538116455
Pre-training Epoch 17:  71%|███████   | 260/367 [00:01<00:00, 187.80it/s]Pre-training Epoch 17:  76%|███████▋  | 280/367 [00:01<00:00, 188.72it/s]Pre-training Epoch 17:  81%|████████▏ | 299/367 [00:01<00:00, 187.47it/s]Pre-training Epoch 17:  87%|████████▋ | 319/367 [00:01<00:00, 189.78it/s]Pre-training Epoch 17:  92%|█████████▏| 339/367 [00:01<00:00, 191.33it/s]Pre-training Epoch 17:  98%|█████████▊| 359/367 [00:01<00:00, 191.89it/s]Pre-training Epoch 17: 100%|██████████| 367/367 [00:01<00:00, 183.90it/s]
recon_loss: 0.03774527087807655, dist_loss: 1.1641106605529785
recon_loss: 0.03774246200919151, dist_loss: 0.8015992641448975
recon_loss: 0.037739675492048264, dist_loss: 0.7971433401107788
recon_loss: 0.03773700073361397, dist_loss: 0.5464338064193726
recon_loss: 0.03773428127169609, dist_loss: 0.23804418742656708
recon_loss: 0.037731509655714035, dist_loss: 0.4714526832103729
recon_loss: 0.03772876411676407, dist_loss: 0.9084693789482117
recon_loss: 0.03772610425949097, dist_loss: 1.1297259330749512
recon_loss: 0.03772345557808876, dist_loss: 0.7276756167411804
recon_loss: 0.037720829248428345, dist_loss: 0.6365552544593811
recon_loss: 0.03771820291876793, dist_loss: 0.7085062265396118
recon_loss: 0.037715453654527664, dist_loss: 0.5572600364685059
recon_loss: 0.03771233558654785, dist_loss: 0.8230252861976624
recon_loss: 0.03770909830927849, dist_loss: 0.8691360354423523
recon_loss: 0.03770611435174942, dist_loss: 0.42213547229766846
recon_loss: 0.037703048437833786, dist_loss: 0.42933422327041626
recon_loss: 0.037700094282627106, dist_loss: 0.495476096868515
recon_loss: 0.03769713640213013, dist_loss: 0.4219668507575989
recon_loss: 0.03769434988498688, dist_loss: 0.46028339862823486
recon_loss: 0.0376918651163578, dist_loss: 1.0310399532318115
recon_loss: 0.03768926486372948, dist_loss: 0.7322672605514526
recon_loss: 0.03768685832619667, dist_loss: 0.6328003406524658
recon_loss: 0.03768450394272804, dist_loss: 0.5991730690002441
recon_loss: 0.0376821793615818, dist_loss: 0.7813832759857178
recon_loss: 0.037679921835660934, dist_loss: 0.684926450252533
recon_loss: 0.0376775898039341, dist_loss: 0.4454447627067566
recon_loss: 0.03767513483762741, dist_loss: 0.8160006999969482
recon_loss: 0.03767266124486923, dist_loss: 0.7589197158813477
recon_loss: 0.03767015412449837, dist_loss: 1.0196692943572998
recon_loss: 0.037667736411094666, dist_loss: 1.0699462890625
recon_loss: 0.03766532242298126, dist_loss: 0.6775354743003845
recon_loss: 0.03766287490725517, dist_loss: 0.7345583438873291
recon_loss: 0.037660349160432816, dist_loss: 0.4255068898200989
recon_loss: 0.03765781223773956, dist_loss: 0.7478920221328735
recon_loss: 0.037654999643564224, dist_loss: 1.399639368057251
recon_loss: 0.037652380764484406, dist_loss: 0.455646276473999
recon_loss: 0.03764953091740608, dist_loss: 0.2537993788719177
recon_loss: 0.037646595388650894, dist_loss: 1.0996912717819214
recon_loss: 0.03764374554157257, dist_loss: 0.6223907470703125
recon_loss: 0.037640850991010666, dist_loss: 0.7977368831634521
recon_loss: 0.03763798996806145, dist_loss: 0.7585699558258057
recon_loss: 0.03763524070382118, dist_loss: 0.7558882832527161
recon_loss: 0.03763255104422569, dist_loss: 0.6467643976211548
recon_loss: 0.03762981295585632, dist_loss: 1.0628042221069336
recon_loss: 0.037627145648002625, dist_loss: 0.6256109476089478
recon_loss: 0.03762464225292206, dist_loss: 0.8292871117591858
recon_loss: 0.03762223944067955, dist_loss: 0.347208708524704
recon_loss: 0.037619806826114655, dist_loss: 0.7413262128829956
recon_loss: 0.0376172736287117, dist_loss: 0.8539128303527832
recon_loss: 0.03761494532227516, dist_loss: 0.7947908043861389
recon_loss: 0.037612833082675934, dist_loss: 0.4827177822589874
recon_loss: 0.03761069104075432, dist_loss: 0.651923418045044
recon_loss: 0.03760843724012375, dist_loss: 0.7794383764266968
recon_loss: 0.03760609030723572, dist_loss: 0.5745507478713989
recon_loss: 0.03760363534092903, dist_loss: 0.5821658372879028
recon_loss: 0.03760114312171936, dist_loss: 0.6900991201400757
recon_loss: 0.03759865090250969, dist_loss: 0.6807564496994019
recon_loss: 0.03759615495800972, dist_loss: 0.43989813327789307
recon_loss: 0.0375935323536396, dist_loss: 0.7830862998962402
recon_loss: 0.03759068623185158, dist_loss: 0.7337960600852966
recon_loss: 0.037587426602840424, dist_loss: 0.5497305393218994
recon_loss: 0.0375840924680233, dist_loss: 0.8713825345039368
recon_loss: 0.037580929696559906, dist_loss: 0.7295492887496948
recon_loss: 0.0375780388712883, dist_loss: 0.9236474633216858
recon_loss: 0.03757505863904953, dist_loss: 1.248445987701416
recon_loss: 0.03757229447364807, dist_loss: 0.4221619665622711
recon_loss: 0.037569597363471985, dist_loss: 0.41363272070884705
recon_loss: 0.037566788494586945, dist_loss: 0.7188728451728821
recon_loss: 0.03756404295563698, dist_loss: 0.48020485043525696
recon_loss: 0.03756127133965492, dist_loss: 0.5609550476074219
recon_loss: 0.03755846992135048, dist_loss: 0.7553955316543579
recon_loss: 0.037555575370788574, dist_loss: 0.5822256207466125
recon_loss: 0.03755281865596771, dist_loss: 1.0076751708984375
recon_loss: 0.03754999116063118, dist_loss: 0.5940441489219666
recon_loss: 0.0375470295548439, dist_loss: 0.7442159056663513
recon_loss: 0.03754403814673424, dist_loss: 0.4949079751968384
recon_loss: 0.0375409796833992, dist_loss: 0.5162790417671204
recon_loss: 0.03753767907619476, dist_loss: 0.5814841985702515
recon_loss: 0.03753432631492615, dist_loss: 0.7978496551513672
recon_loss: 0.037531036883592606, dist_loss: 0.5920941233634949
recon_loss: 0.03752772882580757, dist_loss: 0.4957696795463562
recon_loss: 0.03752479702234268, dist_loss: 0.35037729144096375
recon_loss: 0.03752179443836212, dist_loss: 0.6955128908157349
recon_loss: 0.03751874342560768, dist_loss: 1.183377742767334
recon_loss: 0.0375157855451107, dist_loss: 0.4330219030380249
recon_loss: 0.0375126376748085, dist_loss: 0.953627347946167
recon_loss: 0.03751017898321152, dist_loss: 0.9032425880432129
recon_loss: 0.037507813423871994, dist_loss: 0.6055053472518921
recon_loss: 0.037505507469177246, dist_loss: 0.7218189239501953
recon_loss: 0.03750305250287056, dist_loss: 0.8465609550476074
recon_loss: 0.03750062733888626, dist_loss: 0.5933360457420349
recon_loss: 0.037498265504837036, dist_loss: 0.3757404685020447
recon_loss: 0.03749573975801468, dist_loss: 1.1635901927947998
recon_loss: 0.037492915987968445, dist_loss: 0.4808453917503357
recon_loss: 0.037489939481019974, dist_loss: 0.576541006565094
recon_loss: 0.037486910820007324, dist_loss: 0.37108173966407776
recon_loss: 0.03748391941189766, dist_loss: 0.4806058406829834
recon_loss: 0.037480905652046204, dist_loss: 0.47049981355667114
recon_loss: 0.03747784346342087, dist_loss: 0.8019980788230896
recon_loss: 0.037474725395441055, dist_loss: 0.4486513137817383
recon_loss: 0.03747185319662094, dist_loss: 0.5863739252090454
recon_loss: 0.037469036877155304, dist_loss: 0.6025106310844421
recon_loss: 0.03746623545885086, dist_loss: 0.5975306034088135
recon_loss: 0.03746327385306358, dist_loss: 0.591424822807312
recon_loss: 0.03746018558740616, dist_loss: 0.7248153686523438
recon_loss: 0.03745708242058754, dist_loss: 0.5014311075210571
recon_loss: 0.0374540351331234, dist_loss: 0.4482981562614441
recon_loss: 0.03745100274682045, dist_loss: 1.4106920957565308
recon_loss: 0.03744770959019661, dist_loss: 0.2083725482225418
Pre-training Epoch 18:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 18:   5%|▌         | 19/367 [00:00<00:01, 186.44it/s]Pre-training Epoch 18:  10%|█         | 38/367 [00:00<00:01, 174.21it/s]Pre-training Epoch 18:  15%|█▌        | 56/367 [00:00<00:01, 169.96it/s]Pre-training Epoch 18:  20%|██        | 74/367 [00:00<00:01, 168.07it/s]Pre-training Epoch 18:  25%|██▍       | 91/367 [00:00<00:01, 166.88it/s]Pre-training Epoch 18:  29%|██▉       | 108/367 [00:00<00:01, 164.46it/s]Pre-training Epoch 18:  34%|███▍      | 125/367 [00:00<00:01, 164.58it/s]recon_loss: 0.03744462504982948, dist_loss: 0.587830126285553
recon_loss: 0.0374414287507534, dist_loss: 0.6335055232048035
recon_loss: 0.03743830695748329, dist_loss: 0.6110955476760864
recon_loss: 0.037435468286275864, dist_loss: 0.7104802131652832
recon_loss: 0.037432994693517685, dist_loss: 0.7891879677772522
recon_loss: 0.037430498749017715, dist_loss: 0.8312352895736694
recon_loss: 0.03742797672748566, dist_loss: 0.5126572847366333
recon_loss: 0.03742528334259987, dist_loss: 1.2427700757980347
recon_loss: 0.03742235526442528, dist_loss: 0.7236217856407166
recon_loss: 0.03741962090134621, dist_loss: 0.5957179069519043
recon_loss: 0.03741702064871788, dist_loss: 1.2301647663116455
recon_loss: 0.037414006888866425, dist_loss: 0.8973314762115479
recon_loss: 0.037411246448755264, dist_loss: 0.4310187101364136
recon_loss: 0.03740854188799858, dist_loss: 0.6884706020355225
recon_loss: 0.03740603104233742, dist_loss: 0.5345581769943237
recon_loss: 0.037403739988803864, dist_loss: 0.40021514892578125
recon_loss: 0.03740128502249718, dist_loss: 0.44906601309776306
recon_loss: 0.0373985730111599, dist_loss: 0.539728581905365
recon_loss: 0.037395767867565155, dist_loss: 0.5186920762062073
recon_loss: 0.03739279881119728, dist_loss: 0.6682311296463013
recon_loss: 0.037389956414699554, dist_loss: 0.5528185367584229
recon_loss: 0.03738728538155556, dist_loss: 0.6752235889434814
recon_loss: 0.03738485649228096, dist_loss: 0.8001620769500732
recon_loss: 0.037382546812295914, dist_loss: 0.713571310043335
recon_loss: 0.03738001734018326, dist_loss: 0.6040371060371399
recon_loss: 0.03737735375761986, dist_loss: 0.5388876795768738
recon_loss: 0.03737443685531616, dist_loss: 0.7494242191314697
recon_loss: 0.03737153485417366, dist_loss: 0.24542821943759918
recon_loss: 0.037368807941675186, dist_loss: 0.594733715057373
recon_loss: 0.037365999072790146, dist_loss: 0.8726328611373901
recon_loss: 0.03736322373151779, dist_loss: 0.6493343114852905
recon_loss: 0.03736051544547081, dist_loss: 0.5846654772758484
recon_loss: 0.03735792636871338, dist_loss: 0.9041836857795715
recon_loss: 0.03735518082976341, dist_loss: 0.5041703581809998
recon_loss: 0.037352386862039566, dist_loss: 0.2738657295703888
recon_loss: 0.03734937310218811, dist_loss: 0.7135975360870361
recon_loss: 0.03734627738595009, dist_loss: 1.025721549987793
recon_loss: 0.037342943251132965, dist_loss: 0.587959885597229
recon_loss: 0.03733959048986435, dist_loss: 0.6264406442642212
recon_loss: 0.037336260080337524, dist_loss: 1.1537446975708008
recon_loss: 0.037333227694034576, dist_loss: 0.6667346954345703
recon_loss: 0.037330225110054016, dist_loss: 0.49883967638015747
recon_loss: 0.03732719644904137, dist_loss: 0.9766371250152588
recon_loss: 0.03732433170080185, dist_loss: 0.7732487916946411
recon_loss: 0.03732150420546532, dist_loss: 0.35074925422668457
recon_loss: 0.03731871768832207, dist_loss: 0.5441324710845947
recon_loss: 0.03731561079621315, dist_loss: 0.6882171630859375
recon_loss: 0.0373125784099102, dist_loss: 0.6151124238967896
recon_loss: 0.03730953112244606, dist_loss: 0.45187902450561523
recon_loss: 0.03730650991201401, dist_loss: 0.3606750965118408
recon_loss: 0.03730345144867897, dist_loss: 1.0523059368133545
recon_loss: 0.03730033338069916, dist_loss: 0.5273276567459106
recon_loss: 0.03729710355401039, dist_loss: 0.5720703601837158
recon_loss: 0.037293873727321625, dist_loss: 0.5086461305618286
recon_loss: 0.03729034587740898, dist_loss: 0.4649672508239746
recon_loss: 0.03728683292865753, dist_loss: 0.590350866317749
recon_loss: 0.03728342428803444, dist_loss: 0.4854160249233246
recon_loss: 0.037280142307281494, dist_loss: 0.8103417158126831
recon_loss: 0.03727684170007706, dist_loss: 1.07637357711792
recon_loss: 0.03727341815829277, dist_loss: 0.7182260751724243
recon_loss: 0.037270087748765945, dist_loss: 0.5875747203826904
recon_loss: 0.03726687654852867, dist_loss: 1.0100420713424683
recon_loss: 0.0372636653482914, dist_loss: 1.1463011503219604
recon_loss: 0.03726040944457054, dist_loss: 0.867158830165863
recon_loss: 0.03725731372833252, dist_loss: 0.40960872173309326
recon_loss: 0.03725422918796539, dist_loss: 0.4546637535095215
recon_loss: 0.03725115582346916, dist_loss: 0.9329499006271362
recon_loss: 0.03724788501858711, dist_loss: 0.822258472442627
recon_loss: 0.03724445030093193, dist_loss: 1.155822992324829
recon_loss: 0.03724117577075958, dist_loss: 0.47291678190231323
recon_loss: 0.03723781555891037, dist_loss: 0.46022355556488037
recon_loss: 0.03723452240228653, dist_loss: 0.7823114395141602
recon_loss: 0.03723123297095299, dist_loss: 0.8978076577186584
recon_loss: 0.03722810000181198, dist_loss: 0.5096681714057922
recon_loss: 0.03722492977976799, dist_loss: 0.4991871118545532
recon_loss: 0.037221699953079224, dist_loss: 0.45741039514541626
recon_loss: 0.03721857815980911, dist_loss: 1.148215889930725
recon_loss: 0.037215545773506165, dist_loss: 0.645238995552063
recon_loss: 0.037212762981653214, dist_loss: 0.6543195247650146
recon_loss: 0.037210043519735336, dist_loss: 0.6791185140609741
recon_loss: 0.03720719367265701, dist_loss: 0.4390815198421478
recon_loss: 0.03720445558428764, dist_loss: 0.4435257911682129
recon_loss: 0.03720182552933693, dist_loss: 0.453171044588089
recon_loss: 0.0371989980340004, dist_loss: 0.2887566089630127
recon_loss: 0.03719617426395416, dist_loss: 0.6442809104919434
recon_loss: 0.03719335049390793, dist_loss: 0.9425561428070068
recon_loss: 0.03719038888812065, dist_loss: 0.8703895807266235
recon_loss: 0.03718763217329979, dist_loss: 0.9061145782470703
recon_loss: 0.037184931337833405, dist_loss: 0.702802836894989
recon_loss: 0.03718230873346329, dist_loss: 0.8146461844444275
recon_loss: 0.03717995062470436, dist_loss: 0.5030062794685364
recon_loss: 0.03717773035168648, dist_loss: 0.5067095160484314
recon_loss: 0.03717557713389397, dist_loss: 0.5427321195602417
recon_loss: 0.03717336058616638, dist_loss: 0.8639990091323853
recon_loss: 0.0371708907186985, dist_loss: 0.6396777629852295
recon_loss: 0.03716806694865227, dist_loss: 0.7907658219337463
recon_loss: 0.03716514632105827, dist_loss: 0.5239717960357666
recon_loss: 0.03716220334172249, dist_loss: 1.192868947982788
recon_loss: 0.03715933859348297, dist_loss: 1.023300290107727
recon_loss: 0.03715652599930763, dist_loss: 0.7084688544273376
recon_loss: 0.03715379163622856, dist_loss: 1.1044903993606567
recon_loss: 0.03715106099843979, dist_loss: 0.6258202791213989
recon_loss: 0.037148427218198776, dist_loss: 0.9207647442817688
recon_loss: 0.037145838141441345, dist_loss: 0.9072630405426025
recon_loss: 0.037142980843782425, dist_loss: 0.7253202199935913
recon_loss: 0.037140291184186935, dist_loss: 0.9163261651992798
recon_loss: 0.0371372364461422, dist_loss: 0.6268397569656372
recon_loss: 0.03713374212384224, dist_loss: 0.781938910484314
recon_loss: 0.03713018447160721, dist_loss: 0.6216352581977844
recon_loss: 0.03712690994143486, dist_loss: 0.6458978652954102
recon_loss: 0.03712409362196922, dist_loss: 0.6906241178512573
recon_loss: 0.03712116926908493, dist_loss: 0.6142146587371826
recon_loss: 0.03711846470832825, dist_loss: 0.6990811228752136
recon_loss: 0.03711571916937828, dist_loss: 0.8643327951431274
recon_loss: 0.037113167345523834, dist_loss: 0.590652346611023
recon_loss: 0.03711085021495819, dist_loss: 0.5310998558998108
recon_loss: 0.037108320742845535, dist_loss: 0.670742392539978
recon_loss: 0.03710523992776871, dist_loss: 0.6331824064254761
recon_loss: 0.037102654576301575, dist_loss: 0.332006573677063
recon_loss: 0.037100326269865036, dist_loss: 0.6364969611167908
recon_loss: 0.037098098546266556, dist_loss: 0.5359799861907959
recon_loss: 0.03709542006254196, dist_loss: 0.6609583497047424
recon_loss: 0.037092696875333786, dist_loss: 0.7106654644012451
recon_loss: 0.03709008917212486, dist_loss: 0.8436082601547241
recon_loss: 0.03708752244710922, dist_loss: 0.9470946788787842
recon_loss: 0.03708494454622269, dist_loss: 0.46376603841781616
recon_loss: 0.037082500755786896, dist_loss: 1.5255731344223022
recon_loss: 0.03707974776625633, dist_loss: 0.6648751497268677
recon_loss: 0.03707685321569443, dist_loss: 0.532793402671814
Pre-training Epoch 18:  39%|███▊      | 142/367 [00:00<00:01, 164.00it/s]Pre-training Epoch 18:  43%|████▎     | 159/367 [00:00<00:01, 164.52it/s]Pre-training Epoch 18:  48%|████▊     | 176/367 [00:01<00:01, 165.03it/s]Pre-training Epoch 18:  53%|█████▎    | 193/367 [00:01<00:01, 165.97it/s]Pre-training Epoch 18:  57%|█████▋    | 211/367 [00:01<00:00, 169.97it/s]Pre-training Epoch 18:  63%|██████▎   | 231/367 [00:01<00:00, 176.31it/s]Pre-training Epoch 18:  68%|██████▊   | 250/367 [00:01<00:00, 180.00it/s]recon_loss: 0.03707430139183998, dist_loss: 0.7048649191856384
recon_loss: 0.037071727216243744, dist_loss: 0.815902590751648
recon_loss: 0.03706912323832512, dist_loss: 0.5947467088699341
recon_loss: 0.03706671670079231, dist_loss: 0.7825263738632202
recon_loss: 0.03706381097435951, dist_loss: 0.45983070135116577
recon_loss: 0.03706095740199089, dist_loss: 0.8493655920028687
recon_loss: 0.0370577871799469, dist_loss: 1.061893343925476
recon_loss: 0.037054698914289474, dist_loss: 1.0236601829528809
recon_loss: 0.03705174848437309, dist_loss: 0.8511239290237427
recon_loss: 0.03704864904284477, dist_loss: 0.5500228404998779
recon_loss: 0.037045519798994064, dist_loss: 0.48522108793258667
recon_loss: 0.037042438983917236, dist_loss: 0.5771902799606323
recon_loss: 0.037039339542388916, dist_loss: 0.8988321423530579
recon_loss: 0.03703605383634567, dist_loss: 0.9116067886352539
recon_loss: 0.037032756954431534, dist_loss: 0.9978247880935669
recon_loss: 0.037029657512903214, dist_loss: 0.7180180549621582
recon_loss: 0.03702655807137489, dist_loss: 0.5538272857666016
recon_loss: 0.03702360391616821, dist_loss: 0.6334861516952515
recon_loss: 0.03702068328857422, dist_loss: 0.5759720206260681
recon_loss: 0.037017837166786194, dist_loss: 0.5965449213981628
recon_loss: 0.03701494634151459, dist_loss: 0.9331232905387878
recon_loss: 0.03701227530837059, dist_loss: 0.5320978164672852
recon_loss: 0.037009455263614655, dist_loss: 0.5240762233734131
recon_loss: 0.03700663149356842, dist_loss: 1.1367822885513306
recon_loss: 0.03700379282236099, dist_loss: 0.6563658118247986
recon_loss: 0.03700093552470207, dist_loss: 0.5901494026184082
recon_loss: 0.03699823468923569, dist_loss: 0.6700983047485352
recon_loss: 0.036995504051446915, dist_loss: 0.5545364022254944
recon_loss: 0.03699258342385292, dist_loss: 0.7968823313713074
recon_loss: 0.036989372223615646, dist_loss: 0.7405286431312561
recon_loss: 0.036986470222473145, dist_loss: 0.6055405735969543
recon_loss: 0.036983367055654526, dist_loss: 0.7614614963531494
recon_loss: 0.03698047250509262, dist_loss: 0.5526596307754517
recon_loss: 0.03697769343852997, dist_loss: 0.6888573169708252
recon_loss: 0.03697529807686806, dist_loss: 0.5055966377258301
recon_loss: 0.036973029375076294, dist_loss: 0.7020258903503418
recon_loss: 0.03697080910205841, dist_loss: 0.46634483337402344
recon_loss: 0.036968689411878586, dist_loss: 0.4740605354309082
recon_loss: 0.03696659207344055, dist_loss: 0.947759211063385
recon_loss: 0.03696407377719879, dist_loss: 0.9357448220252991
recon_loss: 0.03696155548095703, dist_loss: 0.5993643403053284
recon_loss: 0.03695906698703766, dist_loss: 0.6042184233665466
recon_loss: 0.03695647045969963, dist_loss: 0.49827975034713745
recon_loss: 0.03695452958345413, dist_loss: 0.7490836381912231
recon_loss: 0.036952905356884, dist_loss: 0.46756500005722046
recon_loss: 0.03695130720734596, dist_loss: 0.6176468729972839
recon_loss: 0.03694983199238777, dist_loss: 0.865050196647644
recon_loss: 0.03694829344749451, dist_loss: 0.6191678643226624
recon_loss: 0.036947101354599, dist_loss: 0.8141621351242065
recon_loss: 0.036946289241313934, dist_loss: 0.4830334484577179
recon_loss: 0.036945365369319916, dist_loss: 0.5855728983879089
recon_loss: 0.036944180727005005, dist_loss: 1.2412455081939697
recon_loss: 0.036942850798368454, dist_loss: 1.044032335281372
recon_loss: 0.03694155067205429, dist_loss: 0.5818081498146057
recon_loss: 0.03694014623761177, dist_loss: 0.8733348250389099
recon_loss: 0.03693862631917, dist_loss: 0.7165365219116211
recon_loss: 0.03693708777427673, dist_loss: 0.5979582071304321
recon_loss: 0.036935899406671524, dist_loss: 0.8416935205459595
recon_loss: 0.03693465515971184, dist_loss: 0.692259669303894
recon_loss: 0.03693341091275215, dist_loss: 0.5971964597702026
recon_loss: 0.03693198785185814, dist_loss: 0.8240989446640015
recon_loss: 0.036930255591869354, dist_loss: 0.5972653031349182
recon_loss: 0.036928147077560425, dist_loss: 0.6351680755615234
recon_loss: 0.03692617267370224, dist_loss: 0.4315447211265564
recon_loss: 0.03692417964339256, dist_loss: 0.6592884063720703
recon_loss: 0.03692202642560005, dist_loss: 1.1233985424041748
recon_loss: 0.03691982477903366, dist_loss: 0.7249594330787659
recon_loss: 0.03691786155104637, dist_loss: 1.0384457111358643
recon_loss: 0.0369158536195755, dist_loss: 0.5750809907913208
recon_loss: 0.03691408410668373, dist_loss: 0.42720547318458557
recon_loss: 0.036912303417921066, dist_loss: 0.8640671968460083
recon_loss: 0.036910537630319595, dist_loss: 0.6907369494438171
recon_loss: 0.03690878301858902, dist_loss: 0.4681074023246765
recon_loss: 0.03690684214234352, dist_loss: 0.5412685871124268
recon_loss: 0.03690493479371071, dist_loss: 0.8418728113174438
recon_loss: 0.036903224885463715, dist_loss: 0.7708373665809631
recon_loss: 0.03690133988857269, dist_loss: 0.4688096046447754
recon_loss: 0.036899417638778687, dist_loss: 0.5679097771644592
recon_loss: 0.036897528916597366, dist_loss: 0.3578048348426819
recon_loss: 0.03689568117260933, dist_loss: 0.5361155271530151
recon_loss: 0.036893680691719055, dist_loss: 0.5228739380836487
recon_loss: 0.03689190745353699, dist_loss: 1.0914990901947021
recon_loss: 0.03689010068774223, dist_loss: 0.5039607286453247
recon_loss: 0.03688843920826912, dist_loss: 0.990737795829773
recon_loss: 0.03688661754131317, dist_loss: 0.906119704246521
recon_loss: 0.036884818226099014, dist_loss: 0.8367747068405151
recon_loss: 0.03688284009695053, dist_loss: 0.3947358727455139
recon_loss: 0.036881014704704285, dist_loss: 0.49388206005096436
recon_loss: 0.03687896206974983, dist_loss: 0.7450588941574097
recon_loss: 0.0368768647313118, dist_loss: 0.9242820739746094
recon_loss: 0.03687461093068123, dist_loss: 0.5206402540206909
recon_loss: 0.03687218949198723, dist_loss: 0.48290908336639404
recon_loss: 0.03686974570155144, dist_loss: 0.5470337867736816
recon_loss: 0.0368669368326664, dist_loss: 0.883362889289856
recon_loss: 0.03686418756842613, dist_loss: 0.3523927628993988
recon_loss: 0.036861352622509, dist_loss: 0.7606556415557861
recon_loss: 0.03685835003852844, dist_loss: 0.950361967086792
recon_loss: 0.03685562312602997, dist_loss: 0.5344645977020264
recon_loss: 0.03685290366411209, dist_loss: 0.6588175296783447
recon_loss: 0.03685010224580765, dist_loss: 0.6929557919502258
recon_loss: 0.03684714436531067, dist_loss: 1.3887279033660889
recon_loss: 0.03684467077255249, dist_loss: 0.5975562930107117
recon_loss: 0.036842141300439835, dist_loss: 0.8724595308303833
recon_loss: 0.03683973476290703, dist_loss: 1.0046961307525635
recon_loss: 0.036837585270404816, dist_loss: 0.7619243860244751
recon_loss: 0.0368351936340332, dist_loss: 0.47197309136390686
recon_loss: 0.03683279827237129, dist_loss: 0.7450953722000122
recon_loss: 0.03683049604296684, dist_loss: 0.5182007551193237
recon_loss: 0.0368281826376915, dist_loss: 0.47113996744155884
recon_loss: 0.03682572767138481, dist_loss: 0.44709512591362
recon_loss: 0.03682286664843559, dist_loss: 0.9488987326622009
recon_loss: 0.03681998327374458, dist_loss: 0.45300254225730896
recon_loss: 0.03681691735982895, dist_loss: 0.6679973602294922
recon_loss: 0.03681423142552376, dist_loss: 1.0156960487365723
recon_loss: 0.03681167587637901, dist_loss: 0.84479159116745
recon_loss: 0.036809246987104416, dist_loss: 0.7280067205429077
recon_loss: 0.036806944757699966, dist_loss: 1.0998693704605103
recon_loss: 0.036804381757974625, dist_loss: 0.6662805080413818
recon_loss: 0.03680165857076645, dist_loss: 0.8908072710037231
recon_loss: 0.03679881989955902, dist_loss: 0.8407744765281677
recon_loss: 0.03679606691002846, dist_loss: 0.40341392159461975
recon_loss: 0.03679332882165909, dist_loss: 0.4489704370498657
recon_loss: 0.03679042309522629, dist_loss: 0.3045353591442108
recon_loss: 0.036787599325180054, dist_loss: 0.6635135412216187
recon_loss: 0.03678491711616516, dist_loss: 0.6042123436927795
recon_loss: 0.03678232431411743, dist_loss: 0.6383231282234192
recon_loss: 0.036779969930648804, dist_loss: 0.5392341613769531
recon_loss: 0.03677750751376152, dist_loss: 0.5179166197776794
recon_loss: 0.03677523136138916, dist_loss: 0.67376708984375
Pre-training Epoch 18:  73%|███████▎  | 269/367 [00:01<00:00, 181.91it/s]Pre-training Epoch 18:  79%|███████▊  | 289/367 [00:01<00:00, 184.50it/s]Pre-training Epoch 18:  84%|████████▍ | 308/367 [00:01<00:00, 185.93it/s]Pre-training Epoch 18:  89%|████████▉ | 327/367 [00:01<00:00, 172.91it/s]Pre-training Epoch 18:  94%|█████████▍| 345/367 [00:02<00:00, 168.01it/s]Pre-training Epoch 18:  99%|█████████▊| 362/367 [00:02<00:00, 164.45it/s]Pre-training Epoch 18: 100%|██████████| 367/367 [00:02<00:00, 170.30it/s]
recon_loss: 0.036773063242435455, dist_loss: 0.5591081380844116
recon_loss: 0.036770690232515335, dist_loss: 1.2948367595672607
recon_loss: 0.03676851838827133, dist_loss: 0.44765496253967285
recon_loss: 0.036766182631254196, dist_loss: 0.5945842266082764
recon_loss: 0.03676394745707512, dist_loss: 0.6551569104194641
recon_loss: 0.03676185756921768, dist_loss: 0.3783200979232788
recon_loss: 0.0367596410214901, dist_loss: 0.5426506400108337
recon_loss: 0.03675726801156998, dist_loss: 1.139756202697754
recon_loss: 0.03675507381558418, dist_loss: 0.6159306764602661
recon_loss: 0.03675282001495361, dist_loss: 0.3643976151943207
recon_loss: 0.036750536412000656, dist_loss: 0.3958868086338043
recon_loss: 0.03674839809536934, dist_loss: 0.5086276531219482
recon_loss: 0.036746226251125336, dist_loss: 0.3715534508228302
recon_loss: 0.03674405813217163, dist_loss: 0.6161972880363464
recon_loss: 0.03674202784895897, dist_loss: 0.7116314172744751
recon_loss: 0.036740101873874664, dist_loss: 0.7186292409896851
recon_loss: 0.03673825040459633, dist_loss: 0.5129799842834473
recon_loss: 0.03673632815480232, dist_loss: 0.5066258907318115
recon_loss: 0.0367341972887516, dist_loss: 1.6019995212554932
recon_loss: 0.036732111126184464, dist_loss: 0.3680075407028198
recon_loss: 0.03672979772090912, dist_loss: 0.9236409068107605
recon_loss: 0.036727599799633026, dist_loss: 0.4678182899951935
recon_loss: 0.03672528639435768, dist_loss: 0.6034465432167053
recon_loss: 0.03672308474779129, dist_loss: 0.7160604596138
recon_loss: 0.03672114014625549, dist_loss: 0.47022706270217896
recon_loss: 0.0367191843688488, dist_loss: 0.5327796936035156
recon_loss: 0.036717094480991364, dist_loss: 0.4535010755062103
recon_loss: 0.036714982241392136, dist_loss: 0.4171186089515686
recon_loss: 0.03671281039714813, dist_loss: 0.8815150856971741
recon_loss: 0.03671051189303398, dist_loss: 0.4009586572647095
recon_loss: 0.03670818731188774, dist_loss: 0.35990408062934875
recon_loss: 0.03670581802725792, dist_loss: 0.4130503535270691
recon_loss: 0.0367034412920475, dist_loss: 0.3452635407447815
recon_loss: 0.03670096397399902, dist_loss: 0.765529990196228
recon_loss: 0.03669857233762741, dist_loss: 1.0009137392044067
recon_loss: 0.036696165800094604, dist_loss: 0.9749829769134521
recon_loss: 0.036693744361400604, dist_loss: 0.9986335039138794
recon_loss: 0.036691345274448395, dist_loss: 0.9775601029396057
recon_loss: 0.03668881207704544, dist_loss: 0.7749109268188477
recon_loss: 0.036686550825834274, dist_loss: 0.5837075710296631
recon_loss: 0.03668423369526863, dist_loss: 0.9181671142578125
recon_loss: 0.03668183088302612, dist_loss: 0.9156666994094849
recon_loss: 0.03667988255620003, dist_loss: 0.5416015386581421
recon_loss: 0.03667803108692169, dist_loss: 0.7059454917907715
recon_loss: 0.036676112562417984, dist_loss: 0.8523420095443726
recon_loss: 0.0366743765771389, dist_loss: 1.153852939605713
recon_loss: 0.03667258471250534, dist_loss: 0.7660730481147766
recon_loss: 0.036670610308647156, dist_loss: 0.7017850279808044
recon_loss: 0.03666844591498375, dist_loss: 0.451077401638031
recon_loss: 0.03666592761874199, dist_loss: 0.7037919759750366
recon_loss: 0.03666342422366142, dist_loss: 0.7138585448265076
recon_loss: 0.0366608165204525, dist_loss: 0.5650635957717896
recon_loss: 0.03665837273001671, dist_loss: 0.45269447565078735
recon_loss: 0.03665583208203316, dist_loss: 0.6596914529800415
recon_loss: 0.03665336221456528, dist_loss: 1.197882056236267
recon_loss: 0.03665120527148247, dist_loss: 1.027771234512329
recon_loss: 0.0366494320333004, dist_loss: 0.8905892372131348
recon_loss: 0.03664795309305191, dist_loss: 0.6840705871582031
recon_loss: 0.03664637729525566, dist_loss: 0.5078723430633545
recon_loss: 0.036644626408815384, dist_loss: 0.5253764986991882
recon_loss: 0.03664269298315048, dist_loss: 0.587775707244873
recon_loss: 0.03664059564471245, dist_loss: 0.5109061598777771
recon_loss: 0.036638565361499786, dist_loss: 0.4155868589878082
recon_loss: 0.0366365946829319, dist_loss: 0.42110347747802734
recon_loss: 0.03663460537791252, dist_loss: 0.7414825558662415
recon_loss: 0.036632221192121506, dist_loss: 0.933098554611206
recon_loss: 0.03662971779704094, dist_loss: 0.5349887609481812
recon_loss: 0.03662742301821709, dist_loss: 0.5933317542076111
recon_loss: 0.03662508726119995, dist_loss: 0.7889465093612671
recon_loss: 0.03662245720624924, dist_loss: 0.5961184501647949
recon_loss: 0.036619823426008224, dist_loss: 0.862169623374939
recon_loss: 0.03661726787686348, dist_loss: 0.522515058517456
recon_loss: 0.036614593118429184, dist_loss: 0.7128627896308899
recon_loss: 0.03661251813173294, dist_loss: 0.682541012763977
recon_loss: 0.03661055862903595, dist_loss: 0.43522992730140686
recon_loss: 0.03660887852311134, dist_loss: 0.43776735663414
recon_loss: 0.03660701587796211, dist_loss: 0.5898352861404419
recon_loss: 0.03660574555397034, dist_loss: 0.38424187898635864
recon_loss: 0.036604367196559906, dist_loss: 0.9605547189712524
recon_loss: 0.0366029366850853, dist_loss: 0.7489054203033447
recon_loss: 0.03660144656896591, dist_loss: 0.6444708108901978
recon_loss: 0.03659990802407265, dist_loss: 1.4920108318328857
recon_loss: 0.036598194390535355, dist_loss: 0.568910539150238
recon_loss: 0.036596331745386124, dist_loss: 0.4736745059490204
recon_loss: 0.03659431263804436, dist_loss: 1.0137025117874146
recon_loss: 0.03659244626760483, dist_loss: 0.78154456615448
recon_loss: 0.03659072890877724, dist_loss: 1.1090353727340698
recon_loss: 0.036589037626981735, dist_loss: 0.7994358539581299
recon_loss: 0.03658711910247803, dist_loss: 1.323080062866211
recon_loss: 0.03658493235707283, dist_loss: 0.6246175765991211
recon_loss: 0.03658253699541092, dist_loss: 0.868602991104126
recon_loss: 0.03658030554652214, dist_loss: 0.37906748056411743
recon_loss: 0.03657815232872963, dist_loss: 0.7241880893707275
recon_loss: 0.03657573089003563, dist_loss: 0.6165856719017029
recon_loss: 0.03657350689172745, dist_loss: 0.588823676109314
recon_loss: 0.03657114878296852, dist_loss: 0.5014692544937134
recon_loss: 0.036568645387887955, dist_loss: 0.5995751619338989
recon_loss: 0.03656622767448425, dist_loss: 0.45416712760925293
recon_loss: 0.0365636982023716, dist_loss: 0.6062777042388916
recon_loss: 0.036561306565999985, dist_loss: 0.9026758074760437
recon_loss: 0.03655887395143509, dist_loss: 0.858679473400116
recon_loss: 0.03655629605054855, dist_loss: 0.8761898279190063
recon_loss: 0.03655371069908142, dist_loss: 1.1115543842315674
recon_loss: 0.036551207304000854, dist_loss: 0.3976697623729706
recon_loss: 0.03654890134930611, dist_loss: 0.912915825843811
recon_loss: 0.03654653578996658, dist_loss: 0.8095995187759399
recon_loss: 0.03654438257217407, dist_loss: 1.0783377885818481
recon_loss: 0.03654205799102783, dist_loss: 0.9028993844985962
recon_loss: 0.03653990477323532, dist_loss: 1.4802263975143433
Pre-training Epoch 19:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 19:   5%|▍         | 18/367 [00:00<00:02, 173.55it/s]Pre-training Epoch 19:  10%|█         | 37/367 [00:00<00:01, 177.17it/s]Pre-training Epoch 19:  15%|█▍        | 55/367 [00:00<00:01, 172.95it/s]Pre-training Epoch 19:  20%|█▉        | 73/367 [00:00<00:01, 175.59it/s]Pre-training Epoch 19:  25%|██▍       | 91/367 [00:00<00:01, 177.14it/s]Pre-training Epoch 19:  30%|██▉       | 110/367 [00:00<00:01, 178.98it/s]Pre-training Epoch 19:  35%|███▍      | 128/367 [00:00<00:01, 179.10it/s]recon_loss: 0.03653749078512192, dist_loss: 0.5860450267791748
recon_loss: 0.03653488680720329, dist_loss: 0.5804725885391235
recon_loss: 0.03653215616941452, dist_loss: 0.6189497709274292
recon_loss: 0.036529213190078735, dist_loss: 0.5613164305686951
recon_loss: 0.036526598036289215, dist_loss: 0.9401372075080872
recon_loss: 0.03652402013540268, dist_loss: 0.6680939197540283
recon_loss: 0.036521609872579575, dist_loss: 0.83305424451828
recon_loss: 0.036519527435302734, dist_loss: 0.3195955157279968
recon_loss: 0.036517322063446045, dist_loss: 0.6140396595001221
recon_loss: 0.03651491925120354, dist_loss: 0.5068614482879639
recon_loss: 0.036512453109025955, dist_loss: 0.6624147295951843
recon_loss: 0.0365099161863327, dist_loss: 1.0011777877807617
recon_loss: 0.036507610231637955, dist_loss: 0.7116588354110718
recon_loss: 0.03650571405887604, dist_loss: 0.305850088596344
recon_loss: 0.03650383651256561, dist_loss: 0.5103708505630493
recon_loss: 0.03650221973657608, dist_loss: 0.7048838138580322
recon_loss: 0.03650051727890968, dist_loss: 0.45990216732025146
recon_loss: 0.036498840898275375, dist_loss: 0.59721839427948
recon_loss: 0.03649701178073883, dist_loss: 1.033961296081543
recon_loss: 0.03649509325623512, dist_loss: 0.9213327765464783
recon_loss: 0.036493025720119476, dist_loss: 0.5690706968307495
recon_loss: 0.03649090602993965, dist_loss: 0.8055967092514038
recon_loss: 0.036489032208919525, dist_loss: 0.8783808350563049
recon_loss: 0.03648698702454567, dist_loss: 0.8107708692550659
recon_loss: 0.036485012620687485, dist_loss: 0.4339865744113922
recon_loss: 0.03648309409618378, dist_loss: 0.7951909303665161
recon_loss: 0.036481112241744995, dist_loss: 0.6146884560585022
recon_loss: 0.03647886961698532, dist_loss: 0.7780173420906067
recon_loss: 0.0364769771695137, dist_loss: 0.5120985507965088
recon_loss: 0.03647497296333313, dist_loss: 0.6252183318138123
recon_loss: 0.03647291287779808, dist_loss: 0.44571158289909363
recon_loss: 0.0364709235727787, dist_loss: 0.6282025575637817
recon_loss: 0.03646886721253395, dist_loss: 0.7617183923721313
recon_loss: 0.03646690025925636, dist_loss: 0.7946663498878479
recon_loss: 0.036465175449848175, dist_loss: 0.9253638386726379
recon_loss: 0.036463528871536255, dist_loss: 0.8714599609375
recon_loss: 0.036461833864450455, dist_loss: 0.7119107246398926
recon_loss: 0.036460231989622116, dist_loss: 1.0231406688690186
recon_loss: 0.036458518356084824, dist_loss: 0.6306089758872986
recon_loss: 0.03645657002925873, dist_loss: 0.5432946085929871
recon_loss: 0.036454495042562485, dist_loss: 1.22501802444458
recon_loss: 0.03645249456167221, dist_loss: 0.737829327583313
recon_loss: 0.03645038604736328, dist_loss: 0.5612627267837524
recon_loss: 0.03644828125834465, dist_loss: 0.3748733103275299
recon_loss: 0.036446504294872284, dist_loss: 0.8610153198242188
recon_loss: 0.03644485026597977, dist_loss: 0.7499046325683594
recon_loss: 0.036442793905735016, dist_loss: 0.4347280263900757
recon_loss: 0.03644076734781265, dist_loss: 0.6695055961608887
recon_loss: 0.03643851727247238, dist_loss: 0.7262701988220215
recon_loss: 0.03643621504306793, dist_loss: 0.4522820711135864
recon_loss: 0.03643375635147095, dist_loss: 0.6268821954727173
recon_loss: 0.03643146529793739, dist_loss: 0.8708672523498535
recon_loss: 0.0364292711019516, dist_loss: 0.7622616291046143
recon_loss: 0.03642721846699715, dist_loss: 0.6143491268157959
recon_loss: 0.0364253856241703, dist_loss: 0.4366714060306549
recon_loss: 0.03642354533076286, dist_loss: 0.42881491780281067
recon_loss: 0.036422017961740494, dist_loss: 0.4242691397666931
recon_loss: 0.036420490592718124, dist_loss: 0.4905412197113037
recon_loss: 0.03641865774989128, dist_loss: 0.4995783269405365
recon_loss: 0.036416929215192795, dist_loss: 0.8751615285873413
recon_loss: 0.036415498703718185, dist_loss: 0.8813133835792542
recon_loss: 0.03641393035650253, dist_loss: 0.5059350728988647
recon_loss: 0.03641234710812569, dist_loss: 0.453266441822052
recon_loss: 0.036410555243492126, dist_loss: 0.5216571688652039
recon_loss: 0.03640862926840782, dist_loss: 0.7539404034614563
recon_loss: 0.03640652820467949, dist_loss: 0.5551384687423706
recon_loss: 0.03640448674559593, dist_loss: 0.8349970579147339
recon_loss: 0.03640275076031685, dist_loss: 0.5795196294784546
recon_loss: 0.03640095889568329, dist_loss: 0.6846962571144104
recon_loss: 0.036399003118276596, dist_loss: 0.7046625018119812
recon_loss: 0.036397017538547516, dist_loss: 0.3937062919139862
recon_loss: 0.036394912749528885, dist_loss: 0.7706363201141357
recon_loss: 0.036392729729413986, dist_loss: 0.6416516304016113
recon_loss: 0.03639056533575058, dist_loss: 0.7099745273590088
recon_loss: 0.036388710141181946, dist_loss: 0.858299970626831
recon_loss: 0.03638702258467674, dist_loss: 0.6858605146408081
recon_loss: 0.03638544678688049, dist_loss: 0.40238693356513977
recon_loss: 0.03638369217514992, dist_loss: 1.1070728302001953
recon_loss: 0.036381885409355164, dist_loss: 0.5579015016555786
recon_loss: 0.0363798663020134, dist_loss: 0.605901300907135
recon_loss: 0.03637773171067238, dist_loss: 0.8610348701477051
recon_loss: 0.03637539967894554, dist_loss: 0.4035772681236267
recon_loss: 0.03637302294373512, dist_loss: 0.412101149559021
recon_loss: 0.036370452493429184, dist_loss: 1.0226645469665527
recon_loss: 0.036368031054735184, dist_loss: 0.8170844316482544
recon_loss: 0.036365583539009094, dist_loss: 0.326632559299469
recon_loss: 0.03636298328638077, dist_loss: 1.0653202533721924
recon_loss: 0.0363604761660099, dist_loss: 0.974490761756897
recon_loss: 0.03635820373892784, dist_loss: 0.6830422878265381
recon_loss: 0.03635590523481369, dist_loss: 1.029449462890625
recon_loss: 0.036353521049022675, dist_loss: 1.1819825172424316
recon_loss: 0.03635146841406822, dist_loss: 0.8377647995948792
recon_loss: 0.036349374800920486, dist_loss: 0.7114725708961487
recon_loss: 0.03634751960635185, dist_loss: 0.33925965428352356
recon_loss: 0.0363454706966877, dist_loss: 0.6687837243080139
recon_loss: 0.0363432839512825, dist_loss: 0.5423294901847839
recon_loss: 0.03634120523929596, dist_loss: 0.5351963043212891
recon_loss: 0.03633953630924225, dist_loss: 0.959847092628479
recon_loss: 0.03633807599544525, dist_loss: 0.5780463218688965
recon_loss: 0.036336660385131836, dist_loss: 0.8131294250488281
recon_loss: 0.03633495047688484, dist_loss: 0.727796196937561
recon_loss: 0.03633297607302666, dist_loss: 1.1175872087478638
recon_loss: 0.03633056581020355, dist_loss: 0.4425131678581238
recon_loss: 0.03632797673344612, dist_loss: 0.4328678250312805
recon_loss: 0.03632521629333496, dist_loss: 0.6112605333328247
recon_loss: 0.03632257133722305, dist_loss: 0.49901580810546875
recon_loss: 0.03631987422704697, dist_loss: 1.082742691040039
recon_loss: 0.03631740063428879, dist_loss: 0.5464242100715637
recon_loss: 0.036314819008111954, dist_loss: 0.7366503477096558
recon_loss: 0.0363125279545784, dist_loss: 0.6475658416748047
recon_loss: 0.03631012141704559, dist_loss: 0.5884371995925903
recon_loss: 0.036307886242866516, dist_loss: 0.4759475588798523
recon_loss: 0.036305807530879974, dist_loss: 0.625403642654419
recon_loss: 0.036303531378507614, dist_loss: 0.45335838198661804
recon_loss: 0.036301225423812866, dist_loss: 0.5096801519393921
recon_loss: 0.03629891574382782, dist_loss: 0.7361900806427002
recon_loss: 0.03629688546061516, dist_loss: 0.849250078201294
recon_loss: 0.03629500791430473, dist_loss: 1.0253034830093384
recon_loss: 0.03629281371831894, dist_loss: 0.7446259260177612
recon_loss: 0.036290984600782394, dist_loss: 0.46697431802749634
recon_loss: 0.036289095878601074, dist_loss: 1.226101040840149
recon_loss: 0.03628738224506378, dist_loss: 0.2928094267845154
recon_loss: 0.036285609006881714, dist_loss: 1.0485508441925049
recon_loss: 0.0362837091088295, dist_loss: 0.9274994134902954
recon_loss: 0.03628157079219818, dist_loss: 0.4276658296585083
recon_loss: 0.03627939522266388, dist_loss: 0.6199594736099243
recon_loss: 0.03627774491906166, dist_loss: 0.5677711963653564
recon_loss: 0.036276400089263916, dist_loss: 0.6499481201171875
recon_loss: 0.03627495840191841, dist_loss: 0.6721550226211548
Pre-training Epoch 19:  40%|███▉      | 146/367 [00:00<00:01, 179.34it/s]Pre-training Epoch 19:  45%|████▍     | 165/367 [00:00<00:01, 179.56it/s]Pre-training Epoch 19:  50%|████▉     | 183/367 [00:01<00:01, 178.79it/s]Pre-training Epoch 19:  55%|█████▍    | 201/367 [00:01<00:00, 178.99it/s]Pre-training Epoch 19:  60%|█████▉    | 219/367 [00:01<00:00, 179.09it/s]Pre-training Epoch 19:  65%|██████▍   | 237/367 [00:01<00:00, 176.46it/s]Pre-training Epoch 19:  70%|██████▉   | 256/367 [00:01<00:00, 177.60it/s]recon_loss: 0.036273639649152756, dist_loss: 1.2275583744049072
recon_loss: 0.03627203777432442, dist_loss: 0.5392902493476868
recon_loss: 0.03627029061317444, dist_loss: 0.7559496164321899
recon_loss: 0.03626818582415581, dist_loss: 1.0344007015228271
recon_loss: 0.03626631200313568, dist_loss: 1.0528578758239746
recon_loss: 0.036264218389987946, dist_loss: 0.8997328281402588
recon_loss: 0.036262962967157364, dist_loss: 1.3202227354049683
recon_loss: 0.03626168146729469, dist_loss: 0.6713263392448425
recon_loss: 0.03626037761569023, dist_loss: 0.49160340428352356
recon_loss: 0.03625911474227905, dist_loss: 0.3821050524711609
recon_loss: 0.036257702857255936, dist_loss: 0.5495499968528748
recon_loss: 0.036255910992622375, dist_loss: 0.8604939579963684
recon_loss: 0.03625421226024628, dist_loss: 0.6460937857627869
recon_loss: 0.03625250235199928, dist_loss: 0.6867998838424683
recon_loss: 0.03625098615884781, dist_loss: 0.6784916520118713
recon_loss: 0.036249395459890366, dist_loss: 0.7796186804771423
recon_loss: 0.03624768927693367, dist_loss: 0.7251670360565186
recon_loss: 0.036246128380298615, dist_loss: 0.8700008392333984
recon_loss: 0.036244768649339676, dist_loss: 0.7200649976730347
recon_loss: 0.03624332323670387, dist_loss: 0.6944578886032104
recon_loss: 0.036241818219423294, dist_loss: 1.5076905488967896
recon_loss: 0.036240413784980774, dist_loss: 0.7340814471244812
recon_loss: 0.03623906522989273, dist_loss: 0.6657724380493164
recon_loss: 0.03623783588409424, dist_loss: 0.6264737844467163
recon_loss: 0.03623706102371216, dist_loss: 0.6339994072914124
recon_loss: 0.03623645380139351, dist_loss: 0.5440447330474854
recon_loss: 0.03623584657907486, dist_loss: 0.9867645502090454
recon_loss: 0.03623491898179054, dist_loss: 0.4005056619644165
recon_loss: 0.036233801394701004, dist_loss: 0.9001967906951904
recon_loss: 0.0362323559820652, dist_loss: 0.5148910284042358
recon_loss: 0.03623085096478462, dist_loss: 0.5424684286117554
recon_loss: 0.03622947633266449, dist_loss: 0.6612883806228638
recon_loss: 0.0362279899418354, dist_loss: 0.5649903416633606
recon_loss: 0.03622669726610184, dist_loss: 0.7400617599487305
recon_loss: 0.0362253300845623, dist_loss: 0.7592541575431824
recon_loss: 0.036223821341991425, dist_loss: 0.47995495796203613
recon_loss: 0.03622220829129219, dist_loss: 0.6973682045936584
recon_loss: 0.03622042387723923, dist_loss: 0.7605150938034058
recon_loss: 0.03621850907802582, dist_loss: 0.7565284967422485
recon_loss: 0.03621676564216614, dist_loss: 0.8774394989013672
recon_loss: 0.0362151600420475, dist_loss: 0.531568169593811
recon_loss: 0.03621375560760498, dist_loss: 1.1899149417877197
recon_loss: 0.036212194710969925, dist_loss: 1.2241321802139282
recon_loss: 0.03621057793498039, dist_loss: 0.6280797719955444
recon_loss: 0.03620907664299011, dist_loss: 0.8811265826225281
recon_loss: 0.036207783967256546, dist_loss: 0.8790687918663025
recon_loss: 0.036206550896167755, dist_loss: 0.6407861113548279
recon_loss: 0.03620517626404762, dist_loss: 1.3676742315292358
recon_loss: 0.03620345890522003, dist_loss: 0.38353264331817627
recon_loss: 0.036201607435941696, dist_loss: 0.5649368166923523
recon_loss: 0.036199815571308136, dist_loss: 0.6053799390792847
recon_loss: 0.03619800880551338, dist_loss: 0.5632030963897705
recon_loss: 0.036196496337652206, dist_loss: 1.0103187561035156
recon_loss: 0.03619495406746864, dist_loss: 0.48462623357772827
recon_loss: 0.03619338199496269, dist_loss: 0.6650269627571106
recon_loss: 0.036191776394844055, dist_loss: 0.701810359954834
recon_loss: 0.03619028255343437, dist_loss: 0.5380021333694458
recon_loss: 0.036188531666994095, dist_loss: 0.7200266122817993
recon_loss: 0.03618696704506874, dist_loss: 1.0548374652862549
recon_loss: 0.03618505597114563, dist_loss: 0.6470755338668823
recon_loss: 0.03618356212973595, dist_loss: 0.609384298324585
recon_loss: 0.036182161420583725, dist_loss: 1.2620868682861328
recon_loss: 0.036180876195430756, dist_loss: 1.0132296085357666
recon_loss: 0.036179669201374054, dist_loss: 0.4100589156150818
recon_loss: 0.03617830574512482, dist_loss: 0.9429413676261902
recon_loss: 0.03617676720023155, dist_loss: 0.4355481266975403
recon_loss: 0.03617521747946739, dist_loss: 0.7698503136634827
recon_loss: 0.036173444241285324, dist_loss: 0.61366868019104
recon_loss: 0.036171820014715195, dist_loss: 0.8915186524391174
recon_loss: 0.03617002069950104, dist_loss: 0.7506691217422485
recon_loss: 0.03616820648312569, dist_loss: 0.3069014847278595
recon_loss: 0.0361664742231369, dist_loss: 0.663939893245697
recon_loss: 0.03616458550095558, dist_loss: 0.3964443802833557
recon_loss: 0.03616292402148247, dist_loss: 0.7796494960784912
recon_loss: 0.03616119548678398, dist_loss: 0.5778226852416992
recon_loss: 0.03615961968898773, dist_loss: 0.6796364784240723
recon_loss: 0.03615783527493477, dist_loss: 0.6357319355010986
recon_loss: 0.03615601733326912, dist_loss: 1.174665927886963
recon_loss: 0.03615422919392586, dist_loss: 0.7012026309967041
recon_loss: 0.03615257889032364, dist_loss: 0.7270066738128662
recon_loss: 0.036150891333818436, dist_loss: 0.7882576584815979
recon_loss: 0.03614933043718338, dist_loss: 0.5280882120132446
recon_loss: 0.03614778444170952, dist_loss: 0.5425428152084351
recon_loss: 0.036146242171525955, dist_loss: 0.573508620262146
recon_loss: 0.03614446520805359, dist_loss: 0.5017474889755249
recon_loss: 0.03614254295825958, dist_loss: 0.7658363580703735
recon_loss: 0.03614077717065811, dist_loss: 0.5339609980583191
recon_loss: 0.036138907074928284, dist_loss: 0.4866480827331543
recon_loss: 0.0361371710896492, dist_loss: 0.8717420697212219
recon_loss: 0.0361357256770134, dist_loss: 0.499502956867218
recon_loss: 0.03613436967134476, dist_loss: 0.6180008053779602
recon_loss: 0.036132827401161194, dist_loss: 0.6138445734977722
recon_loss: 0.03613142669200897, dist_loss: 0.5664254426956177
recon_loss: 0.036130089312791824, dist_loss: 0.6706927418708801
recon_loss: 0.03612874448299408, dist_loss: 0.9605095386505127
recon_loss: 0.03612736612558365, dist_loss: 0.6196339726448059
recon_loss: 0.036125823855400085, dist_loss: 0.20080915093421936
recon_loss: 0.03612421452999115, dist_loss: 0.7126187086105347
recon_loss: 0.03612242639064789, dist_loss: 0.5773512721061707
recon_loss: 0.036120448261499405, dist_loss: 0.7649788856506348
recon_loss: 0.0361185260117054, dist_loss: 0.5898504257202148
recon_loss: 0.03611649200320244, dist_loss: 0.3919200599193573
recon_loss: 0.03611455485224724, dist_loss: 0.6050572395324707
recon_loss: 0.03611265867948532, dist_loss: 0.624958872795105
recon_loss: 0.036110907793045044, dist_loss: 0.8845124840736389
recon_loss: 0.036108922213315964, dist_loss: 0.5224227905273438
recon_loss: 0.036106955260038376, dist_loss: 0.42167431116104126
recon_loss: 0.036104995757341385, dist_loss: 0.5798038244247437
recon_loss: 0.0361030250787735, dist_loss: 0.5161864757537842
recon_loss: 0.03610112518072128, dist_loss: 0.44568613171577454
recon_loss: 0.036099184304475784, dist_loss: 0.5974140763282776
recon_loss: 0.03609727323055267, dist_loss: 0.4946288764476776
recon_loss: 0.03609544783830643, dist_loss: 0.6374784708023071
recon_loss: 0.03609340637922287, dist_loss: 1.1043429374694824
recon_loss: 0.03609149158000946, dist_loss: 0.5979201197624207
recon_loss: 0.036089010536670685, dist_loss: 0.4784719944000244
recon_loss: 0.03608661890029907, dist_loss: 0.5766627788543701
recon_loss: 0.03608418628573418, dist_loss: 0.8274781703948975
recon_loss: 0.03608172759413719, dist_loss: 0.3642950654029846
recon_loss: 0.03607931733131409, dist_loss: 0.6470634937286377
recon_loss: 0.036076869815588, dist_loss: 0.49808183312416077
recon_loss: 0.036074329167604446, dist_loss: 1.0058631896972656
recon_loss: 0.03607189655303955, dist_loss: 0.4649568200111389
recon_loss: 0.036069709807634354, dist_loss: 0.5493526458740234
recon_loss: 0.036067359149456024, dist_loss: 0.4481629431247711
recon_loss: 0.036065034568309784, dist_loss: 0.37947261333465576
recon_loss: 0.03606277331709862, dist_loss: 0.524783194065094
recon_loss: 0.03606046363711357, dist_loss: 0.6878186464309692
recon_loss: 0.03605800122022629, dist_loss: 1.0886181592941284
Pre-training Epoch 19:  75%|███████▍  | 274/367 [00:01<00:00, 178.16it/s]Pre-training Epoch 19:  80%|███████▉  | 293/367 [00:01<00:00, 178.93it/s]Pre-training Epoch 19:  85%|████████▍ | 311/367 [00:01<00:00, 179.04it/s]Pre-training Epoch 19:  90%|████████▉ | 330/367 [00:01<00:00, 179.69it/s]Pre-training Epoch 19:  95%|█████████▍| 348/367 [00:01<00:00, 173.00it/s]Pre-training Epoch 19: 100%|██████████| 367/367 [00:02<00:00, 177.89it/s]
recon_loss: 0.03605573624372482, dist_loss: 0.7388777136802673
recon_loss: 0.0360533781349659, dist_loss: 0.8495810627937317
recon_loss: 0.03605126962065697, dist_loss: 0.6384460926055908
recon_loss: 0.036049388349056244, dist_loss: 0.5741013884544373
recon_loss: 0.036047618836164474, dist_loss: 0.3840026557445526
recon_loss: 0.036045629531145096, dist_loss: 0.3649539351463318
recon_loss: 0.036043569445610046, dist_loss: 0.5200644731521606
recon_loss: 0.036041609942913055, dist_loss: 0.7027812004089355
recon_loss: 0.03603949770331383, dist_loss: 0.4226635992527008
recon_loss: 0.0360373891890049, dist_loss: 0.6406214833259583
recon_loss: 0.036035165190696716, dist_loss: 0.6181533336639404
recon_loss: 0.0360330194234848, dist_loss: 0.74078369140625
recon_loss: 0.03603077679872513, dist_loss: 0.5199256539344788
recon_loss: 0.03602851927280426, dist_loss: 0.39468345046043396
recon_loss: 0.036026425659656525, dist_loss: 0.4834461808204651
recon_loss: 0.03602425381541252, dist_loss: 0.8921548128128052
recon_loss: 0.03602217882871628, dist_loss: 0.6245093941688538
recon_loss: 0.03602027893066406, dist_loss: 0.6558493375778198
recon_loss: 0.0360184907913208, dist_loss: 0.7550742030143738
recon_loss: 0.03601660951972008, dist_loss: 0.8957915306091309
recon_loss: 0.036014754325151443, dist_loss: 0.5154717564582825
recon_loss: 0.03601277992129326, dist_loss: 0.8272205591201782
recon_loss: 0.03601102530956268, dist_loss: 0.7701273560523987
recon_loss: 0.036009181290864944, dist_loss: 0.574874758720398
recon_loss: 0.03600744530558586, dist_loss: 0.7656089067459106
recon_loss: 0.0360056534409523, dist_loss: 0.4362154006958008
recon_loss: 0.03600386902689934, dist_loss: 0.7844185829162598
recon_loss: 0.03600208833813667, dist_loss: 0.7509809732437134
recon_loss: 0.035999953746795654, dist_loss: 1.3485078811645508
recon_loss: 0.0359976626932621, dist_loss: 0.6350082159042358
recon_loss: 0.0359954796731472, dist_loss: 1.11122727394104
recon_loss: 0.03599303215742111, dist_loss: 0.6801843643188477
recon_loss: 0.03599074110388756, dist_loss: 0.6373358368873596
recon_loss: 0.03598865494132042, dist_loss: 0.5839864611625671
recon_loss: 0.03598652780056, dist_loss: 0.5704416036605835
recon_loss: 0.03598451241850853, dist_loss: 0.8602375984191895
recon_loss: 0.035982176661491394, dist_loss: 0.7032608985900879
recon_loss: 0.035979852080345154, dist_loss: 1.1923097372055054
recon_loss: 0.03597768023610115, dist_loss: 0.7104273438453674
recon_loss: 0.035975437611341476, dist_loss: 1.0502612590789795
recon_loss: 0.03597313538193703, dist_loss: 1.1440403461456299
recon_loss: 0.03597112372517586, dist_loss: 0.5734148025512695
recon_loss: 0.03596904128789902, dist_loss: 1.227657437324524
recon_loss: 0.03596695140004158, dist_loss: 1.145505428314209
recon_loss: 0.035964928567409515, dist_loss: 0.4857465624809265
recon_loss: 0.03596281260251999, dist_loss: 0.9217138886451721
recon_loss: 0.035960596054792404, dist_loss: 0.7615095973014832
recon_loss: 0.03595837205648422, dist_loss: 0.5616768598556519
recon_loss: 0.03595643863081932, dist_loss: 0.37542790174484253
recon_loss: 0.03595442324876785, dist_loss: 0.6985641121864319
recon_loss: 0.03595231845974922, dist_loss: 0.9936613440513611
recon_loss: 0.03595026955008507, dist_loss: 0.7434700727462769
recon_loss: 0.035948075354099274, dist_loss: 0.7466153502464294
recon_loss: 0.03594597429037094, dist_loss: 0.7418460845947266
recon_loss: 0.03594374284148216, dist_loss: 0.37806376814842224
recon_loss: 0.035941533744335175, dist_loss: 0.7008567452430725
recon_loss: 0.03593943640589714, dist_loss: 0.8637261390686035
recon_loss: 0.03593723103404045, dist_loss: 0.7527828812599182
recon_loss: 0.0359354242682457, dist_loss: 0.6870054006576538
recon_loss: 0.03593362495303154, dist_loss: 0.406936377286911
recon_loss: 0.03593187406659126, dist_loss: 1.1726479530334473
recon_loss: 0.03593007102608681, dist_loss: 1.5932945013046265
recon_loss: 0.035928111523389816, dist_loss: 0.7896557450294495
recon_loss: 0.035926178097724915, dist_loss: 0.720876157283783
recon_loss: 0.035924281924963, dist_loss: 0.8623090982437134
recon_loss: 0.03592252731323242, dist_loss: 0.34024739265441895
recon_loss: 0.03592079505324364, dist_loss: 0.7181812524795532
recon_loss: 0.03591917082667351, dist_loss: 0.8447822332382202
recon_loss: 0.03591766208410263, dist_loss: 0.361552894115448
recon_loss: 0.035916250199079514, dist_loss: 0.5272003412246704
recon_loss: 0.03591461852192879, dist_loss: 0.6849915981292725
recon_loss: 0.03591323643922806, dist_loss: 0.8055197596549988
recon_loss: 0.035911936312913895, dist_loss: 1.012470006942749
recon_loss: 0.035910870879888535, dist_loss: 0.7796884179115295
recon_loss: 0.035909637808799744, dist_loss: 0.5146243572235107
recon_loss: 0.03590838238596916, dist_loss: 0.42820510268211365
recon_loss: 0.035907112061977386, dist_loss: 0.5977058410644531
recon_loss: 0.03590606525540352, dist_loss: 0.46640506386756897
recon_loss: 0.035904984921216965, dist_loss: 0.6174741387367249
recon_loss: 0.03590397164225578, dist_loss: 0.4682534337043762
recon_loss: 0.0359027273952961, dist_loss: 0.9305854439735413
recon_loss: 0.03590133786201477, dist_loss: 0.6226687431335449
recon_loss: 0.03590002655982971, dist_loss: 0.3440643548965454
recon_loss: 0.035898659378290176, dist_loss: 0.6564851999282837
recon_loss: 0.0358973927795887, dist_loss: 0.792904794216156
recon_loss: 0.035896655172109604, dist_loss: 0.9414972066879272
recon_loss: 0.0358961746096611, dist_loss: 0.6640744209289551
recon_loss: 0.03589567169547081, dist_loss: 0.6535362005233765
recon_loss: 0.0358952134847641, dist_loss: 0.8231697082519531
recon_loss: 0.035894520580768585, dist_loss: 0.39521458745002747
recon_loss: 0.035893600434064865, dist_loss: 0.44163721799850464
recon_loss: 0.03589262440800667, dist_loss: 1.1593132019042969
recon_loss: 0.03589155152440071, dist_loss: 0.7538710832595825
recon_loss: 0.03589029610157013, dist_loss: 0.8521865010261536
recon_loss: 0.035888925194740295, dist_loss: 0.7281944155693054
recon_loss: 0.035887349396944046, dist_loss: 1.0895875692367554
recon_loss: 0.035885486751794815, dist_loss: 0.724557638168335
recon_loss: 0.03588353469967842, dist_loss: 0.6131433248519897
recon_loss: 0.03588155284523964, dist_loss: 0.5685426592826843
recon_loss: 0.03587961569428444, dist_loss: 0.5545859336853027
recon_loss: 0.03587745875120163, dist_loss: 0.8228899240493774
recon_loss: 0.03587504103779793, dist_loss: 0.5903024673461914
recon_loss: 0.03587298095226288, dist_loss: 0.6791694164276123
recon_loss: 0.035870909690856934, dist_loss: 0.4402077794075012
recon_loss: 0.035868845880031586, dist_loss: 0.6861248016357422
recon_loss: 0.035866640508174896, dist_loss: 0.3910720646381378
recon_loss: 0.035864509642124176, dist_loss: 0.541144847869873
recon_loss: 0.03586244955658913, dist_loss: 0.9497777223587036
recon_loss: 0.03586064279079437, dist_loss: 0.9355959296226501
Pre-training Epoch 20:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 20:   5%|▌         | 19/367 [00:00<00:01, 187.92it/s]Pre-training Epoch 20:  11%|█         | 39/367 [00:00<00:01, 191.17it/s]Pre-training Epoch 20:  16%|█▌        | 59/367 [00:00<00:01, 177.24it/s]Pre-training Epoch 20:  21%|██        | 77/367 [00:00<00:01, 167.84it/s]Pre-training Epoch 20:  26%|██▌       | 94/367 [00:00<00:01, 162.90it/s]Pre-training Epoch 20:  30%|███       | 111/367 [00:00<00:01, 156.24it/s]Pre-training Epoch 20:  35%|███▍      | 127/367 [00:00<00:01, 154.99it/s]recon_loss: 0.035858962684869766, dist_loss: 0.6510976552963257
recon_loss: 0.035857152193784714, dist_loss: 0.41641098260879517
recon_loss: 0.035855233669281006, dist_loss: 0.7514544725418091
recon_loss: 0.03585309162735939, dist_loss: 0.6773064136505127
recon_loss: 0.035850889980793, dist_loss: 0.6620233058929443
recon_loss: 0.03584852069616318, dist_loss: 0.6702744960784912
recon_loss: 0.03584621474146843, dist_loss: 0.7673022747039795
recon_loss: 0.0358438715338707, dist_loss: 0.9038941264152527
recon_loss: 0.035841889679431915, dist_loss: 0.6862077713012695
recon_loss: 0.03583969548344612, dist_loss: 0.794126570224762
recon_loss: 0.035837411880493164, dist_loss: 0.8034704923629761
recon_loss: 0.035835132002830505, dist_loss: 0.6008378267288208
recon_loss: 0.035833004862070084, dist_loss: 0.71770179271698
recon_loss: 0.035830944776535034, dist_loss: 0.9380600452423096
recon_loss: 0.03582925349473953, dist_loss: 0.5289762020111084
recon_loss: 0.03582748770713806, dist_loss: 0.3475583791732788
recon_loss: 0.03582572937011719, dist_loss: 0.7876601219177246
recon_loss: 0.035824064165353775, dist_loss: 0.5697898864746094
recon_loss: 0.03582219406962395, dist_loss: 0.8130276203155518
recon_loss: 0.03582026809453964, dist_loss: 0.9269734025001526
recon_loss: 0.035818491131067276, dist_loss: 0.5942084193229675
recon_loss: 0.035816702991724014, dist_loss: 0.6618146300315857
recon_loss: 0.03581496328115463, dist_loss: 0.9943779706954956
recon_loss: 0.035813070833683014, dist_loss: 0.7095736265182495
recon_loss: 0.03581125661730766, dist_loss: 0.47643351554870605
recon_loss: 0.03580935671925545, dist_loss: 0.39892053604125977
recon_loss: 0.03580743819475174, dist_loss: 0.51910400390625
recon_loss: 0.03580554947257042, dist_loss: 0.40401017665863037
recon_loss: 0.03580372780561447, dist_loss: 0.407260000705719
recon_loss: 0.03580211475491524, dist_loss: 0.4253722131252289
recon_loss: 0.03580056130886078, dist_loss: 0.45769837498664856
recon_loss: 0.035799071192741394, dist_loss: 0.7808215022087097
recon_loss: 0.03579748794436455, dist_loss: 0.5699119567871094
recon_loss: 0.035795874893665314, dist_loss: 0.9749866127967834
recon_loss: 0.035794589668512344, dist_loss: 0.5910860896110535
recon_loss: 0.03579295054078102, dist_loss: 0.7192228436470032
recon_loss: 0.03579125180840492, dist_loss: 0.8872292041778564
recon_loss: 0.035789601504802704, dist_loss: 0.5277098417282104
recon_loss: 0.03578796237707138, dist_loss: 0.5363316535949707
recon_loss: 0.03578627482056618, dist_loss: 0.6033978462219238
recon_loss: 0.03578490763902664, dist_loss: 0.8122206926345825
recon_loss: 0.03578350692987442, dist_loss: 0.5341511964797974
recon_loss: 0.03578229621052742, dist_loss: 0.9236993789672852
recon_loss: 0.03578111529350281, dist_loss: 0.6179360151290894
recon_loss: 0.03577997162938118, dist_loss: 0.7854329347610474
recon_loss: 0.03577886149287224, dist_loss: 0.8506126403808594
recon_loss: 0.0357777364552021, dist_loss: 0.7813557386398315
recon_loss: 0.03577648103237152, dist_loss: 0.9603428840637207
recon_loss: 0.035775039345026016, dist_loss: 1.2145345211029053
recon_loss: 0.035773906856775284, dist_loss: 1.0526409149169922
recon_loss: 0.035773105919361115, dist_loss: 0.5461446046829224
recon_loss: 0.03577222302556038, dist_loss: 0.5077638626098633
recon_loss: 0.03577112779021263, dist_loss: 0.7370045185089111
recon_loss: 0.03576995059847832, dist_loss: 0.3562564253807068
recon_loss: 0.035768840461969376, dist_loss: 0.6263285875320435
recon_loss: 0.035767752677202225, dist_loss: 1.1848082542419434
recon_loss: 0.03576644882559776, dist_loss: 1.1169346570968628
recon_loss: 0.035764943808317184, dist_loss: 0.6062283515930176
recon_loss: 0.03576331213116646, dist_loss: 0.41323530673980713
recon_loss: 0.03576183691620827, dist_loss: 0.7159308195114136
recon_loss: 0.035760365426540375, dist_loss: 0.948660135269165
recon_loss: 0.03575877100229263, dist_loss: 0.8961110711097717
recon_loss: 0.035757265985012054, dist_loss: 0.4145727753639221
recon_loss: 0.03575579822063446, dist_loss: 1.259459137916565
recon_loss: 0.035754092037677765, dist_loss: 0.8181129693984985
recon_loss: 0.035752128809690475, dist_loss: 0.6581820249557495
recon_loss: 0.035750553011894226, dist_loss: 0.5854764580726624
recon_loss: 0.035748809576034546, dist_loss: 0.48993024230003357
recon_loss: 0.035747382789850235, dist_loss: 0.7156999111175537
recon_loss: 0.03574582561850548, dist_loss: 0.6721634864807129
recon_loss: 0.035744115710258484, dist_loss: 0.8532853722572327
recon_loss: 0.03574255481362343, dist_loss: 0.44972026348114014
recon_loss: 0.03574076294898987, dist_loss: 0.6142231225967407
recon_loss: 0.03573891520500183, dist_loss: 0.8081730604171753
recon_loss: 0.03573722392320633, dist_loss: 0.7070046663284302
recon_loss: 0.03573541343212128, dist_loss: 0.60332852602005
recon_loss: 0.03573397919535637, dist_loss: 0.6143207550048828
recon_loss: 0.03573249652981758, dist_loss: 0.5755524635314941
recon_loss: 0.03573101386427879, dist_loss: 0.6029819846153259
recon_loss: 0.035729411989450455, dist_loss: 0.45564019680023193
recon_loss: 0.03572779521346092, dist_loss: 0.716769814491272
recon_loss: 0.03572603687644005, dist_loss: 0.546099066734314
recon_loss: 0.035724226385354996, dist_loss: 0.6755216121673584
recon_loss: 0.03572220727801323, dist_loss: 0.6422693729400635
recon_loss: 0.035720087587833405, dist_loss: 0.9615857601165771
recon_loss: 0.035718049854040146, dist_loss: 0.5020121335983276
recon_loss: 0.0357162281870842, dist_loss: 0.9679403901100159
recon_loss: 0.035714250057935715, dist_loss: 0.7310799360275269
recon_loss: 0.0357123538851738, dist_loss: 0.514360785484314
recon_loss: 0.035710521042346954, dist_loss: 1.149890661239624
recon_loss: 0.03570898249745369, dist_loss: 1.5531656742095947
recon_loss: 0.0357077457010746, dist_loss: 0.6420793533325195
recon_loss: 0.03570672497153282, dist_loss: 0.98199862241745
recon_loss: 0.0357055589556694, dist_loss: 0.8644216656684875
recon_loss: 0.035704486072063446, dist_loss: 0.697212815284729
recon_loss: 0.03570317104458809, dist_loss: 0.42085015773773193
recon_loss: 0.035702213644981384, dist_loss: 0.48209553956985474
recon_loss: 0.03570104017853737, dist_loss: 0.8992144465446472
recon_loss: 0.03569984808564186, dist_loss: 0.4628010392189026
recon_loss: 0.03569835424423218, dist_loss: 0.8130443692207336
recon_loss: 0.03569694235920906, dist_loss: 0.5704934597015381
recon_loss: 0.03569571301341057, dist_loss: 0.8702391386032104
recon_loss: 0.03569421172142029, dist_loss: 0.46704229712486267
recon_loss: 0.03569277748465538, dist_loss: 0.8293322920799255
recon_loss: 0.035691309720277786, dist_loss: 0.8770656585693359
recon_loss: 0.0356898158788681, dist_loss: 0.4614385962486267
recon_loss: 0.035688381642103195, dist_loss: 1.1492600440979004
recon_loss: 0.035686954855918884, dist_loss: 0.8660187125205994
recon_loss: 0.03568565845489502, dist_loss: 0.7152406573295593
recon_loss: 0.035684432834386826, dist_loss: 0.6921917200088501
recon_loss: 0.03568347170948982, dist_loss: 0.6682194471359253
recon_loss: 0.035682421177625656, dist_loss: 0.8217414617538452
recon_loss: 0.03568122535943985, dist_loss: 0.9855390191078186
recon_loss: 0.035680126398801804, dist_loss: 0.5850332379341125
recon_loss: 0.035678938031196594, dist_loss: 0.5072314739227295
recon_loss: 0.03567773848772049, dist_loss: 0.5400141477584839
recon_loss: 0.03567633032798767, dist_loss: 0.8397566676139832
recon_loss: 0.035675011575222015, dist_loss: 0.5141047835350037
recon_loss: 0.03567349538207054, dist_loss: 0.4826800227165222
recon_loss: 0.035671740770339966, dist_loss: 0.5952577590942383
recon_loss: 0.03566986322402954, dist_loss: 0.5889932513237
recon_loss: 0.03566804528236389, dist_loss: 0.5066407918930054
recon_loss: 0.03566615283489227, dist_loss: 0.5626890659332275
recon_loss: 0.0356643944978714, dist_loss: 0.6295521855354309
recon_loss: 0.03566264361143112, dist_loss: 0.7028605341911316
recon_loss: 0.03566084802150726, dist_loss: 0.726341724395752
recon_loss: 0.03565888851881027, dist_loss: 0.7432736158370972
recon_loss: 0.03565707057714462, dist_loss: 0.30200517177581787
recon_loss: 0.03565526008605957, dist_loss: 0.7923233509063721
Pre-training Epoch 20:  39%|███▉      | 143/367 [00:00<00:01, 154.45it/s]Pre-training Epoch 20:  43%|████▎     | 159/367 [00:00<00:01, 153.46it/s]Pre-training Epoch 20:  48%|████▊     | 175/367 [00:01<00:01, 151.29it/s]Pre-training Epoch 20:  52%|█████▏    | 191/367 [00:01<00:01, 151.90it/s]Pre-training Epoch 20:  56%|█████▋    | 207/367 [00:01<00:01, 150.21it/s]Pre-training Epoch 20:  61%|██████    | 223/367 [00:01<00:00, 150.52it/s]Pre-training Epoch 20:  65%|██████▌   | 239/367 [00:01<00:00, 151.03it/s]Pre-training Epoch 20:  69%|██████▉   | 255/367 [00:01<00:00, 151.75it/s]recon_loss: 0.03565329685807228, dist_loss: 0.6848608255386353
recon_loss: 0.03565145283937454, dist_loss: 0.5701794028282166
recon_loss: 0.03564983606338501, dist_loss: 0.29871755838394165
recon_loss: 0.03564823046326637, dist_loss: 0.6534825563430786
recon_loss: 0.03564666956663132, dist_loss: 0.5129654407501221
recon_loss: 0.03564518690109253, dist_loss: 0.9567095041275024
recon_loss: 0.035643916577100754, dist_loss: 0.44359132647514343
recon_loss: 0.03564297780394554, dist_loss: 0.5914738178253174
recon_loss: 0.03564193844795227, dist_loss: 0.5738424062728882
recon_loss: 0.03564096614718437, dist_loss: 0.811692476272583
recon_loss: 0.03563984856009483, dist_loss: 0.8659481406211853
recon_loss: 0.03563864529132843, dist_loss: 0.6805270910263062
recon_loss: 0.0356375090777874, dist_loss: 0.88262540102005
recon_loss: 0.035636451095342636, dist_loss: 0.6096915006637573
recon_loss: 0.03563534840941429, dist_loss: 1.25557541847229
recon_loss: 0.03563399985432625, dist_loss: 0.7666506171226501
recon_loss: 0.0356324128806591, dist_loss: 0.8326824903488159
recon_loss: 0.035630956292152405, dist_loss: 0.5074126720428467
recon_loss: 0.03562941402196884, dist_loss: 1.1285649538040161
recon_loss: 0.0356278121471405, dist_loss: 0.4981133043766022
recon_loss: 0.035626061260700226, dist_loss: 0.5561667680740356
recon_loss: 0.035624463111162186, dist_loss: 0.4099932909011841
recon_loss: 0.03562275320291519, dist_loss: 0.5996348857879639
recon_loss: 0.03562106937170029, dist_loss: 0.590003490447998
recon_loss: 0.03561939299106598, dist_loss: 0.6260826587677002
recon_loss: 0.03561760112643242, dist_loss: 0.560932457447052
recon_loss: 0.03561583533883095, dist_loss: 0.5730330944061279
recon_loss: 0.035614386200904846, dist_loss: 0.44274115562438965
recon_loss: 0.03561306372284889, dist_loss: 0.7543540000915527
recon_loss: 0.035611893981695175, dist_loss: 0.8446304798126221
recon_loss: 0.035610806196928024, dist_loss: 0.6679390668869019
recon_loss: 0.03560970723628998, dist_loss: 0.8221957683563232
recon_loss: 0.03560827299952507, dist_loss: 1.0490120649337769
recon_loss: 0.03560657054185867, dist_loss: 0.47792133688926697
recon_loss: 0.03560500219464302, dist_loss: 0.39737194776535034
recon_loss: 0.03560343757271767, dist_loss: 0.7193045616149902
recon_loss: 0.035601794719696045, dist_loss: 0.6431729197502136
recon_loss: 0.03560040518641472, dist_loss: 0.5879753828048706
recon_loss: 0.03559906408190727, dist_loss: 0.5717567205429077
recon_loss: 0.03559739142656326, dist_loss: 0.7380855083465576
recon_loss: 0.035595547407865524, dist_loss: 0.9089277982711792
recon_loss: 0.03559347242116928, dist_loss: 0.6535362601280212
recon_loss: 0.035591039806604385, dist_loss: 0.4666111469268799
recon_loss: 0.035588618367910385, dist_loss: 0.7096006274223328
recon_loss: 0.03558659926056862, dist_loss: 0.5255595445632935
recon_loss: 0.03558453917503357, dist_loss: 0.39667269587516785
recon_loss: 0.035582490265369415, dist_loss: 0.6488604545593262
recon_loss: 0.03558070585131645, dist_loss: 0.5995550155639648
recon_loss: 0.035579048097133636, dist_loss: 1.498317003250122
recon_loss: 0.035577237606048584, dist_loss: 0.4822733998298645
recon_loss: 0.03557530418038368, dist_loss: 0.8150926232337952
recon_loss: 0.03557334095239639, dist_loss: 0.6423166394233704
recon_loss: 0.035571325570344925, dist_loss: 0.43543529510498047
recon_loss: 0.03556933254003525, dist_loss: 1.1894243955612183
recon_loss: 0.035567376762628555, dist_loss: 0.6133904457092285
recon_loss: 0.03556601703166962, dist_loss: 0.6498268842697144
recon_loss: 0.03556514531373978, dist_loss: 0.4037958085536957
recon_loss: 0.03556431084871292, dist_loss: 0.5650403499603271
recon_loss: 0.03556322678923607, dist_loss: 0.6955261826515198
recon_loss: 0.03556183725595474, dist_loss: 1.167035698890686
recon_loss: 0.03556019440293312, dist_loss: 1.0150669813156128
recon_loss: 0.03555809333920479, dist_loss: 0.6709420680999756
recon_loss: 0.03555602580308914, dist_loss: 1.2764761447906494
recon_loss: 0.0355544276535511, dist_loss: 0.9221558570861816
recon_loss: 0.03555288165807724, dist_loss: 0.7959451079368591
recon_loss: 0.03555140644311905, dist_loss: 0.4918645918369293
recon_loss: 0.03554999455809593, dist_loss: 1.1143499612808228
recon_loss: 0.035548269748687744, dist_loss: 0.6240147352218628
recon_loss: 0.03554631769657135, dist_loss: 0.8474963903427124
recon_loss: 0.03554453328251839, dist_loss: 0.7169348001480103
recon_loss: 0.03554297238588333, dist_loss: 0.5692561864852905
recon_loss: 0.03554151952266693, dist_loss: 0.7323652505874634
recon_loss: 0.03554023057222366, dist_loss: 0.6964524984359741
recon_loss: 0.03553900867700577, dist_loss: 0.9173538684844971
recon_loss: 0.035537850111722946, dist_loss: 0.5653467774391174
recon_loss: 0.035536736249923706, dist_loss: 0.7629970908164978
recon_loss: 0.03553569316864014, dist_loss: 0.6055151224136353
recon_loss: 0.03553418815135956, dist_loss: 0.9393246173858643
recon_loss: 0.03553258627653122, dist_loss: 0.8653576374053955
recon_loss: 0.03553103655576706, dist_loss: 0.3117104172706604
recon_loss: 0.035529688000679016, dist_loss: 0.6504786014556885
recon_loss: 0.03552837297320366, dist_loss: 0.7331142425537109
recon_loss: 0.0355273075401783, dist_loss: 1.0973258018493652
recon_loss: 0.03552638739347458, dist_loss: 0.9750349521636963
recon_loss: 0.03552542254328728, dist_loss: 0.9959378242492676
recon_loss: 0.035524237900972366, dist_loss: 0.5532296895980835
recon_loss: 0.03552314266562462, dist_loss: 0.5405322313308716
recon_loss: 0.03552216663956642, dist_loss: 0.821982204914093
recon_loss: 0.035521000623703, dist_loss: 0.6076445579528809
recon_loss: 0.0355200320482254, dist_loss: 0.4409284293651581
recon_loss: 0.0355188325047493, dist_loss: 0.803194522857666
recon_loss: 0.0355173721909523, dist_loss: 0.6324333548545837
recon_loss: 0.03551574423909187, dist_loss: 0.5411291122436523
recon_loss: 0.03551418334245682, dist_loss: 0.5966426134109497
recon_loss: 0.03551255911588669, dist_loss: 0.6300691962242126
recon_loss: 0.03551066666841507, dist_loss: 0.6659391522407532
recon_loss: 0.03550896793603897, dist_loss: 0.4083176851272583
recon_loss: 0.035507019609212875, dist_loss: 0.6637842655181885
recon_loss: 0.03550485149025917, dist_loss: 0.7209750413894653
recon_loss: 0.035502925515174866, dist_loss: 0.8891693353652954
recon_loss: 0.03550118952989578, dist_loss: 0.3524249196052551
recon_loss: 0.03549971431493759, dist_loss: 0.6220757365226746
recon_loss: 0.03549820929765701, dist_loss: 0.6258909702301025
recon_loss: 0.03549656271934509, dist_loss: 0.4929767847061157
recon_loss: 0.0354948453605175, dist_loss: 0.7016202211380005
recon_loss: 0.03549302741885185, dist_loss: 0.5245094299316406
recon_loss: 0.03549126535654068, dist_loss: 0.6839295625686646
recon_loss: 0.03548948094248772, dist_loss: 0.633388102054596
recon_loss: 0.03548774495720863, dist_loss: 1.2331557273864746
recon_loss: 0.0354861244559288, dist_loss: 0.5237095952033997
recon_loss: 0.03548496216535568, dist_loss: 1.2317907810211182
recon_loss: 0.03548404946923256, dist_loss: 0.6706387400627136
recon_loss: 0.03548324480652809, dist_loss: 0.5717921853065491
recon_loss: 0.03548221290111542, dist_loss: 0.6483144164085388
recon_loss: 0.03548114746809006, dist_loss: 0.8668787479400635
recon_loss: 0.03547970950603485, dist_loss: 0.7414824366569519
recon_loss: 0.03547816723585129, dist_loss: 0.3971295952796936
recon_loss: 0.035476893186569214, dist_loss: 0.6869907975196838
recon_loss: 0.03547567129135132, dist_loss: 0.39197492599487305
recon_loss: 0.03547430410981178, dist_loss: 0.6644052267074585
recon_loss: 0.03547286242246628, dist_loss: 0.5395037531852722
recon_loss: 0.03547143191099167, dist_loss: 0.9006744623184204
recon_loss: 0.035470057278871536, dist_loss: 0.7646718621253967
recon_loss: 0.03546858951449394, dist_loss: 0.49669647216796875
recon_loss: 0.0354672335088253, dist_loss: 0.753373384475708
recon_loss: 0.03546607121825218, dist_loss: 0.3649260997772217
recon_loss: 0.03546495735645294, dist_loss: 0.8405790328979492
recon_loss: 0.03546355664730072, dist_loss: 0.555564284324646
recon_loss: 0.03546217828989029, dist_loss: 0.5459436774253845
Pre-training Epoch 20:  74%|███████▍  | 272/367 [00:01<00:00, 154.71it/s]Pre-training Epoch 20:  79%|███████▉  | 290/367 [00:01<00:00, 161.91it/s]Pre-training Epoch 20:  84%|████████▍ | 308/367 [00:01<00:00, 166.89it/s]Pre-training Epoch 20:  89%|████████▉ | 326/367 [00:02<00:00, 169.83it/s]Pre-training Epoch 20:  94%|█████████▎| 344/367 [00:02<00:00, 172.31it/s]Pre-training Epoch 20:  99%|█████████▊| 362/367 [00:02<00:00, 173.81it/s]Pre-training Epoch 20: 100%|██████████| 367/367 [00:02<00:00, 161.69it/s]
recon_loss: 0.0354609489440918, dist_loss: 0.7575044631958008
recon_loss: 0.035459425300359726, dist_loss: 0.9156603813171387
recon_loss: 0.03545776754617691, dist_loss: 0.5292407274246216
recon_loss: 0.03545595332980156, dist_loss: 0.48548775911331177
recon_loss: 0.03545396029949188, dist_loss: 1.0044995546340942
recon_loss: 0.03545205667614937, dist_loss: 0.9385868310928345
recon_loss: 0.03544998541474342, dist_loss: 0.4986317455768585
recon_loss: 0.0354478619992733, dist_loss: 0.488491415977478
recon_loss: 0.03544573485851288, dist_loss: 0.8874428272247314
recon_loss: 0.035444099456071854, dist_loss: 0.5176987648010254
recon_loss: 0.03544213995337486, dist_loss: 0.8660383224487305
recon_loss: 0.03544017672538757, dist_loss: 0.7145123481750488
recon_loss: 0.03543820604681969, dist_loss: 0.5784135460853577
recon_loss: 0.035436250269412994, dist_loss: 0.6016249656677246
recon_loss: 0.03543424606323242, dist_loss: 0.42273199558258057
recon_loss: 0.03543219342827797, dist_loss: 0.796257495880127
recon_loss: 0.03543044626712799, dist_loss: 0.863943338394165
recon_loss: 0.035428736358881, dist_loss: 0.44581013917922974
recon_loss: 0.03542707860469818, dist_loss: 1.2961190938949585
recon_loss: 0.03542562574148178, dist_loss: 0.7058056592941284
recon_loss: 0.035424232482910156, dist_loss: 0.7629863023757935
recon_loss: 0.03542332351207733, dist_loss: 0.6162481307983398
recon_loss: 0.03542252629995346, dist_loss: 0.41781899333000183
recon_loss: 0.035421472042798996, dist_loss: 0.522468626499176
recon_loss: 0.03542056679725647, dist_loss: 0.4311772286891937
recon_loss: 0.03541942313313484, dist_loss: 0.5174054503440857
recon_loss: 0.03541792556643486, dist_loss: 0.7912957668304443
recon_loss: 0.03541649505496025, dist_loss: 0.8952775001525879
recon_loss: 0.0354151725769043, dist_loss: 0.5861976742744446
recon_loss: 0.03541383147239685, dist_loss: 1.1521477699279785
recon_loss: 0.035412371158599854, dist_loss: 0.5698955059051514
recon_loss: 0.03541099280118942, dist_loss: 0.9459227323532104
recon_loss: 0.0354093536734581, dist_loss: 0.7720716595649719
recon_loss: 0.03540773689746857, dist_loss: 0.6575765609741211
recon_loss: 0.03540628030896187, dist_loss: 0.6508102416992188
recon_loss: 0.0354049876332283, dist_loss: 0.5417102575302124
recon_loss: 0.03540373593568802, dist_loss: 0.9580172896385193
recon_loss: 0.03540227189660072, dist_loss: 1.0548712015151978
recon_loss: 0.035400617867708206, dist_loss: 0.7347206473350525
recon_loss: 0.03539877384901047, dist_loss: 0.7862486839294434
recon_loss: 0.03539688512682915, dist_loss: 0.568350076675415
recon_loss: 0.03539510816335678, dist_loss: 0.47489747405052185
recon_loss: 0.035393550992012024, dist_loss: 0.698388934135437
recon_loss: 0.035392068326473236, dist_loss: 0.4778091609477997
recon_loss: 0.03539065644145012, dist_loss: 0.7297097444534302
recon_loss: 0.035389356315135956, dist_loss: 0.6529247760772705
recon_loss: 0.035387806594371796, dist_loss: 1.2661161422729492
recon_loss: 0.03538604825735092, dist_loss: 0.8786526918411255
recon_loss: 0.03538436070084572, dist_loss: 0.8299397230148315
recon_loss: 0.0353827103972435, dist_loss: 0.5978360176086426
recon_loss: 0.03538093715906143, dist_loss: 0.47821682691574097
recon_loss: 0.03537925332784653, dist_loss: 0.6723834276199341
recon_loss: 0.03537773713469505, dist_loss: 1.0208661556243896
recon_loss: 0.035376064479351044, dist_loss: 0.5567994117736816
recon_loss: 0.035374365746974945, dist_loss: 0.9179008603096008
recon_loss: 0.03537250682711601, dist_loss: 0.7710279822349548
recon_loss: 0.035370662808418274, dist_loss: 0.5583426356315613
recon_loss: 0.03536880761384964, dist_loss: 0.6104281544685364
recon_loss: 0.03536706417798996, dist_loss: 0.6422306299209595
recon_loss: 0.03536519780755043, dist_loss: 0.4022303521633148
recon_loss: 0.03536339849233627, dist_loss: 0.6055243015289307
recon_loss: 0.03536161035299301, dist_loss: 0.7803729772567749
recon_loss: 0.0353596955537796, dist_loss: 1.0014797449111938
recon_loss: 0.03535770997405052, dist_loss: 0.8382091522216797
recon_loss: 0.03535568714141846, dist_loss: 0.8897731304168701
recon_loss: 0.03535415604710579, dist_loss: 0.6938052177429199
recon_loss: 0.035352542996406555, dist_loss: 0.5321910977363586
recon_loss: 0.03535120189189911, dist_loss: 0.6230579614639282
recon_loss: 0.035349588841199875, dist_loss: 0.6017746925354004
recon_loss: 0.03534791246056557, dist_loss: 0.4426690340042114
recon_loss: 0.03534626588225365, dist_loss: 0.6304227113723755
recon_loss: 0.03534475341439247, dist_loss: 0.3936384618282318
recon_loss: 0.03534319996833801, dist_loss: 0.47317999601364136
recon_loss: 0.03534155711531639, dist_loss: 0.8630043268203735
recon_loss: 0.03534000366926193, dist_loss: 0.5744368433952332
recon_loss: 0.03533844277262688, dist_loss: 0.44660109281539917
recon_loss: 0.03533676639199257, dist_loss: 1.0616445541381836
recon_loss: 0.035335056483745575, dist_loss: 0.6478675603866577
recon_loss: 0.03533307835459709, dist_loss: 0.7748340964317322
recon_loss: 0.03533070906996727, dist_loss: 1.0696560144424438
recon_loss: 0.03532852977514267, dist_loss: 0.5379922986030579
recon_loss: 0.035326164215803146, dist_loss: 0.4961804151535034
recon_loss: 0.035324010998010635, dist_loss: 0.8374754190444946
recon_loss: 0.03532218560576439, dist_loss: 0.6674519777297974
recon_loss: 0.03532063215970993, dist_loss: 0.3701426684856415
recon_loss: 0.035319384187459946, dist_loss: 0.43141889572143555
recon_loss: 0.03531806543469429, dist_loss: 0.7598947882652283
recon_loss: 0.03531675785779953, dist_loss: 0.4155629575252533
recon_loss: 0.03531533107161522, dist_loss: 0.6388709545135498
recon_loss: 0.03531400486826897, dist_loss: 0.56742262840271
recon_loss: 0.0353124625980854, dist_loss: 0.47314590215682983
recon_loss: 0.035310763865709305, dist_loss: 0.44344303011894226
recon_loss: 0.03530912846326828, dist_loss: 0.9861747622489929
recon_loss: 0.035307399928569794, dist_loss: 0.9189944267272949
recon_loss: 0.035305581986904144, dist_loss: 0.52910315990448
recon_loss: 0.035304050892591476, dist_loss: 0.3836546540260315
recon_loss: 0.03530286252498627, dist_loss: 0.48738208413124084
recon_loss: 0.03530173376202583, dist_loss: 0.31785276532173157
recon_loss: 0.035300351679325104, dist_loss: 0.4453938603401184
recon_loss: 0.03529895097017288, dist_loss: 0.6328115463256836
recon_loss: 0.035297464579343796, dist_loss: 0.7322145700454712
recon_loss: 0.035295795649290085, dist_loss: 0.37571072578430176
recon_loss: 0.035294175148010254, dist_loss: 0.5372434258460999
recon_loss: 0.0352926105260849, dist_loss: 0.9279891848564148
recon_loss: 0.03529118373990059, dist_loss: 0.7199600338935852
recon_loss: 0.035289693623781204, dist_loss: 0.5702165365219116
recon_loss: 0.03528821840882301, dist_loss: 0.8825796842575073
recon_loss: 0.035286590456962585, dist_loss: 0.7339370846748352
recon_loss: 0.035284947603940964, dist_loss: 1.795731782913208
Pre-train Epoch: 20
Train - Total Loss: 0.1049, Recon Loss: 0.0356, Dist Loss: 0.6934, l1 regularization: 0.0000
Val - Total Loss: 0.1084, Recon Loss: 0.0353, Dist Loss: 0.7316, l1 regularization: 0.0000
Pre-training Epoch 21:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 21:   5%|▍         | 17/367 [00:00<00:02, 166.70it/s]Pre-training Epoch 21:  10%|▉         | 35/367 [00:00<00:01, 174.31it/s]Pre-training Epoch 21:  14%|█▍        | 53/367 [00:00<00:01, 174.46it/s]Pre-training Epoch 21:  20%|█▉        | 73/367 [00:00<00:01, 181.56it/s]Pre-training Epoch 21:  25%|██▌       | 93/367 [00:00<00:01, 185.50it/s]Pre-training Epoch 21:  31%|███       | 113/367 [00:00<00:01, 187.74it/s]recon_loss: 0.035282548516988754, dist_loss: 0.43315303325653076
recon_loss: 0.03527997434139252, dist_loss: 0.8195122480392456
recon_loss: 0.03527737408876419, dist_loss: 0.5153183937072754
recon_loss: 0.035275258123874664, dist_loss: 1.0514858961105347
recon_loss: 0.03527342155575752, dist_loss: 0.420635849237442
recon_loss: 0.03527165204286575, dist_loss: 0.7050374746322632
recon_loss: 0.0352700799703598, dist_loss: 1.138992428779602
recon_loss: 0.03526858612895012, dist_loss: 0.9137714505195618
recon_loss: 0.03526691347360611, dist_loss: 0.7522391676902771
recon_loss: 0.035265181213617325, dist_loss: 0.5075911283493042
recon_loss: 0.03526347875595093, dist_loss: 0.8445325493812561
recon_loss: 0.035262107849121094, dist_loss: 0.6163427829742432
recon_loss: 0.03526068106293678, dist_loss: 0.89726722240448
recon_loss: 0.035259146243333817, dist_loss: 0.4224592447280884
recon_loss: 0.03525747358798981, dist_loss: 0.9520580768585205
recon_loss: 0.035255905240774155, dist_loss: 0.7498765587806702
recon_loss: 0.03525460138916969, dist_loss: 0.7362130880355835
recon_loss: 0.03525347262620926, dist_loss: 0.7671994566917419
recon_loss: 0.03525226563215256, dist_loss: 1.0319796800613403
recon_loss: 0.035250719636678696, dist_loss: 1.0394654273986816
recon_loss: 0.03524898365139961, dist_loss: 1.3155848979949951
recon_loss: 0.03524738922715187, dist_loss: 0.364590048789978
recon_loss: 0.03524584695696831, dist_loss: 0.5213946104049683
recon_loss: 0.03524451330304146, dist_loss: 0.3614422082901001
recon_loss: 0.0352432057261467, dist_loss: 0.33912211656570435
recon_loss: 0.035241808742284775, dist_loss: 0.7448980808258057
recon_loss: 0.035240288823843, dist_loss: 0.7914026975631714
recon_loss: 0.03523882478475571, dist_loss: 0.344224214553833
recon_loss: 0.035237494856119156, dist_loss: 0.9703028202056885
recon_loss: 0.03523635119199753, dist_loss: 0.6226354241371155
recon_loss: 0.03523514047265053, dist_loss: 0.3367083668708801
recon_loss: 0.03523382917046547, dist_loss: 0.6885979175567627
recon_loss: 0.035232219845056534, dist_loss: 0.6361006498336792
recon_loss: 0.03523055836558342, dist_loss: 0.7137670516967773
recon_loss: 0.03522899001836777, dist_loss: 0.32119572162628174
recon_loss: 0.03522749990224838, dist_loss: 0.44964760541915894
recon_loss: 0.035226333886384964, dist_loss: 0.9516229033470154
recon_loss: 0.03522505238652229, dist_loss: 0.516498863697052
recon_loss: 0.035223785787820816, dist_loss: 0.5870196223258972
recon_loss: 0.03522259369492531, dist_loss: 0.664695143699646
recon_loss: 0.03522126376628876, dist_loss: 0.6934999823570251
recon_loss: 0.03522016480565071, dist_loss: 0.7084231376647949
recon_loss: 0.03521902114152908, dist_loss: 0.4838780164718628
recon_loss: 0.03521774709224701, dist_loss: 0.5190746188163757
recon_loss: 0.03521634638309479, dist_loss: 0.9830930233001709
recon_loss: 0.035214804112911224, dist_loss: 0.8035656213760376
recon_loss: 0.035213325172662735, dist_loss: 0.7038503885269165
recon_loss: 0.03521179407835007, dist_loss: 0.8867570161819458
recon_loss: 0.035210516303777695, dist_loss: 0.8935453295707703
recon_loss: 0.035209041088819504, dist_loss: 0.6786917448043823
recon_loss: 0.03520744666457176, dist_loss: 0.6135143041610718
recon_loss: 0.03520563244819641, dist_loss: 0.3751703202724457
recon_loss: 0.03520391881465912, dist_loss: 0.6549896001815796
recon_loss: 0.03520260006189346, dist_loss: 0.5164377689361572
recon_loss: 0.03520140424370766, dist_loss: 0.499263733625412
recon_loss: 0.03520013764500618, dist_loss: 0.8901182413101196
recon_loss: 0.03519903123378754, dist_loss: 0.39362233877182007
recon_loss: 0.03519769012928009, dist_loss: 0.5388709902763367
recon_loss: 0.03519631177186966, dist_loss: 0.9902655482292175
recon_loss: 0.03519517555832863, dist_loss: 0.528374433517456
recon_loss: 0.03519399091601372, dist_loss: 0.8542559146881104
recon_loss: 0.03519248217344284, dist_loss: 1.177642822265625
recon_loss: 0.0351908914744854, dist_loss: 0.6676746606826782
recon_loss: 0.03518947586417198, dist_loss: 0.6679178476333618
recon_loss: 0.03518765792250633, dist_loss: 0.7706677913665771
recon_loss: 0.035185959190130234, dist_loss: 0.6103689670562744
recon_loss: 0.03518417105078697, dist_loss: 0.8598119020462036
recon_loss: 0.03518248349428177, dist_loss: 0.6272657513618469
recon_loss: 0.035180605947971344, dist_loss: 0.981342613697052
recon_loss: 0.03517872840166092, dist_loss: 0.6677793264389038
recon_loss: 0.03517686203122139, dist_loss: 0.5737596750259399
recon_loss: 0.0351751483976841, dist_loss: 0.35027146339416504
recon_loss: 0.03517379239201546, dist_loss: 0.8447188138961792
recon_loss: 0.035172585397958755, dist_loss: 1.0482286214828491
recon_loss: 0.035171423107385635, dist_loss: 0.8420072793960571
recon_loss: 0.035170234739780426, dist_loss: 0.42987924814224243
recon_loss: 0.03516903147101402, dist_loss: 0.8531517386436462
recon_loss: 0.035167794674634933, dist_loss: 0.7814791202545166
recon_loss: 0.03516657277941704, dist_loss: 0.4126061201095581
recon_loss: 0.035165395587682724, dist_loss: 0.8141006231307983
recon_loss: 0.035164009779691696, dist_loss: 0.952827513217926
recon_loss: 0.03516286239027977, dist_loss: 0.4900999069213867
recon_loss: 0.035161539912223816, dist_loss: 0.5322452187538147
recon_loss: 0.035159964114427567, dist_loss: 0.586353063583374
recon_loss: 0.035158269107341766, dist_loss: 0.6663390398025513
recon_loss: 0.03515661507844925, dist_loss: 0.34763526916503906
recon_loss: 0.03515502065420151, dist_loss: 0.732450008392334
recon_loss: 0.0351533368229866, dist_loss: 0.45284122228622437
recon_loss: 0.035151802003383636, dist_loss: 0.46152463555336
recon_loss: 0.035150256007909775, dist_loss: 0.6293313503265381
recon_loss: 0.03514871746301651, dist_loss: 0.8178287148475647
recon_loss: 0.03514732047915459, dist_loss: 0.46807435154914856
recon_loss: 0.03514601290225983, dist_loss: 0.8911905884742737
recon_loss: 0.03514459729194641, dist_loss: 0.8304274678230286
recon_loss: 0.03514312207698822, dist_loss: 0.6806426644325256
recon_loss: 0.03514164686203003, dist_loss: 0.6431681513786316
recon_loss: 0.0351400300860405, dist_loss: 0.5748926401138306
recon_loss: 0.03513845056295395, dist_loss: 1.3470878601074219
recon_loss: 0.03513667359948158, dist_loss: 0.4590327739715576
recon_loss: 0.03513506427407265, dist_loss: 0.6822048425674438
recon_loss: 0.03513345867395401, dist_loss: 0.28706130385398865
recon_loss: 0.03513180464506149, dist_loss: 0.6643764972686768
recon_loss: 0.03513013944029808, dist_loss: 0.747200071811676
recon_loss: 0.03512846678495407, dist_loss: 0.6576863527297974
recon_loss: 0.03512667492032051, dist_loss: 1.1071968078613281
recon_loss: 0.035124681890010834, dist_loss: 0.9803241491317749
recon_loss: 0.035122863948345184, dist_loss: 0.5570164918899536
recon_loss: 0.03512093797326088, dist_loss: 0.8092235326766968
recon_loss: 0.03511909395456314, dist_loss: 0.5580746531486511
recon_loss: 0.035117439925670624, dist_loss: 0.7522542476654053
recon_loss: 0.03511588275432587, dist_loss: 1.2061017751693726
recon_loss: 0.03511445224285126, dist_loss: 1.1719889640808105
recon_loss: 0.035113245248794556, dist_loss: 0.6299755573272705
recon_loss: 0.03511177375912666, dist_loss: 0.6165100336074829
recon_loss: 0.03511044755578041, dist_loss: 0.422743022441864
recon_loss: 0.035109102725982666, dist_loss: 0.5168845653533936
recon_loss: 0.03510792925953865, dist_loss: 0.5294725298881531
recon_loss: 0.03510657697916031, dist_loss: 0.6744043231010437
recon_loss: 0.035105150192976, dist_loss: 0.7889285087585449
recon_loss: 0.035103391855955124, dist_loss: 0.6757577657699585
recon_loss: 0.03510177507996559, dist_loss: 0.7946020364761353
recon_loss: 0.03510009124875069, dist_loss: 0.8266785144805908
recon_loss: 0.035098325461149216, dist_loss: 0.48498016595840454
recon_loss: 0.035096585750579834, dist_loss: 0.6670122146606445
recon_loss: 0.0350949689745903, dist_loss: 0.5497866868972778
recon_loss: 0.035093456506729126, dist_loss: 0.47035467624664307
recon_loss: 0.03509229049086571, dist_loss: 0.8821296095848083
recon_loss: 0.03509104624390602, dist_loss: 0.4996408224105835
recon_loss: 0.03508978709578514, dist_loss: 0.6924304962158203
Pre-training Epoch 21:  36%|███▌      | 132/367 [00:00<00:01, 186.06it/s]Pre-training Epoch 21:  41%|████▏     | 152/367 [00:00<00:01, 188.54it/s]Pre-training Epoch 21:  47%|████▋     | 172/367 [00:00<00:01, 190.52it/s]Pre-training Epoch 21:  52%|█████▏    | 192/367 [00:01<00:00, 191.90it/s]Pre-training Epoch 21:  58%|█████▊    | 212/367 [00:01<00:00, 192.71it/s]Pre-training Epoch 21:  63%|██████▎   | 232/367 [00:01<00:00, 193.40it/s]Pre-training Epoch 21:  69%|██████▊   | 252/367 [00:01<00:00, 184.92it/s]recon_loss: 0.03508825600147247, dist_loss: 0.9062477350234985
recon_loss: 0.0350867435336113, dist_loss: 0.9891825914382935
recon_loss: 0.03508535400032997, dist_loss: 0.5042839050292969
recon_loss: 0.03508397936820984, dist_loss: 0.6518783569335938
recon_loss: 0.035082653164863586, dist_loss: 1.028156042098999
recon_loss: 0.035080913454294205, dist_loss: 0.9147830009460449
recon_loss: 0.0350792221724987, dist_loss: 0.8729100227355957
recon_loss: 0.03507738187909126, dist_loss: 0.9097578525543213
recon_loss: 0.03507546707987785, dist_loss: 0.5926790237426758
recon_loss: 0.035073451697826385, dist_loss: 0.9855607748031616
recon_loss: 0.035071250051259995, dist_loss: 0.4810957908630371
recon_loss: 0.03506890684366226, dist_loss: 0.4707714319229126
recon_loss: 0.0350666418671608, dist_loss: 0.9341912865638733
recon_loss: 0.03506452217698097, dist_loss: 1.1972324848175049
recon_loss: 0.035062603652477264, dist_loss: 0.4644376337528229
recon_loss: 0.03506084904074669, dist_loss: 0.7469187378883362
recon_loss: 0.03505918011069298, dist_loss: 0.7486184239387512
recon_loss: 0.03505759313702583, dist_loss: 0.501865804195404
recon_loss: 0.035055745393037796, dist_loss: 0.6426182985305786
recon_loss: 0.03505381941795349, dist_loss: 0.5729427933692932
recon_loss: 0.03505159169435501, dist_loss: 0.7019805908203125
recon_loss: 0.03504948318004608, dist_loss: 0.3077671229839325
recon_loss: 0.03504754602909088, dist_loss: 0.38183358311653137
recon_loss: 0.035045962780714035, dist_loss: 0.6344947218894958
recon_loss: 0.03504456952214241, dist_loss: 0.7707076072692871
recon_loss: 0.035043105483055115, dist_loss: 0.7667591571807861
recon_loss: 0.03504177927970886, dist_loss: 0.3045843243598938
recon_loss: 0.0350402407348156, dist_loss: 0.9306822419166565
recon_loss: 0.035038724541664124, dist_loss: 0.7030941247940063
recon_loss: 0.03503705933690071, dist_loss: 0.7767101526260376
recon_loss: 0.03503556177020073, dist_loss: 0.9132888317108154
recon_loss: 0.035034384578466415, dist_loss: 0.7842749357223511
recon_loss: 0.03503349423408508, dist_loss: 0.6596285104751587
recon_loss: 0.0350329652428627, dist_loss: 0.5931552648544312
recon_loss: 0.0350319929420948, dist_loss: 0.3265424370765686
recon_loss: 0.03503099083900452, dist_loss: 0.3753945827484131
recon_loss: 0.03502973914146423, dist_loss: 0.5274888277053833
recon_loss: 0.03502883017063141, dist_loss: 1.1241796016693115
recon_loss: 0.035027820616960526, dist_loss: 0.8734517693519592
recon_loss: 0.03502713888883591, dist_loss: 0.9314900636672974
recon_loss: 0.035026200115680695, dist_loss: 0.815362811088562
recon_loss: 0.03502481430768967, dist_loss: 0.9131600856781006
recon_loss: 0.03502344340085983, dist_loss: 0.6433397531509399
recon_loss: 0.03502201288938522, dist_loss: 0.8467920422554016
recon_loss: 0.03502083942294121, dist_loss: 1.0886352062225342
recon_loss: 0.035019464790821075, dist_loss: 0.8629220128059387
recon_loss: 0.03501801937818527, dist_loss: 0.6848591566085815
recon_loss: 0.03501657396554947, dist_loss: 0.8102750182151794
recon_loss: 0.03501524403691292, dist_loss: 0.4236029386520386
recon_loss: 0.03501385822892189, dist_loss: 0.3254198431968689
recon_loss: 0.03501252830028534, dist_loss: 0.6422327160835266
recon_loss: 0.03501133620738983, dist_loss: 0.6947662234306335
recon_loss: 0.03501014783978462, dist_loss: 0.7878870964050293
recon_loss: 0.03500869497656822, dist_loss: 1.0968283414840698
recon_loss: 0.0350072905421257, dist_loss: 0.46411311626434326
recon_loss: 0.03500571846961975, dist_loss: 0.5601917505264282
recon_loss: 0.035004161298274994, dist_loss: 0.6304360628128052
recon_loss: 0.035002343356609344, dist_loss: 0.46172744035720825
recon_loss: 0.03500043600797653, dist_loss: 1.5730082988739014
recon_loss: 0.0349985733628273, dist_loss: 0.7211381196975708
recon_loss: 0.03499674052000046, dist_loss: 0.8712641000747681
recon_loss: 0.034994836896657944, dist_loss: 0.45330196619033813
recon_loss: 0.03499281033873558, dist_loss: 0.638700544834137
recon_loss: 0.03499075025320053, dist_loss: 0.38225728273391724
recon_loss: 0.03498866409063339, dist_loss: 1.2418906688690186
recon_loss: 0.034986481070518494, dist_loss: 0.6873166561126709
recon_loss: 0.03498419001698494, dist_loss: 0.4939495027065277
recon_loss: 0.03498218208551407, dist_loss: 1.3342642784118652
recon_loss: 0.034980304539203644, dist_loss: 0.9400785565376282
recon_loss: 0.03497842326760292, dist_loss: 0.7226083874702454
recon_loss: 0.03497646376490593, dist_loss: 0.8455486297607422
recon_loss: 0.03497466817498207, dist_loss: 0.6613642573356628
recon_loss: 0.03497323393821716, dist_loss: 0.9854371547698975
recon_loss: 0.03497178480029106, dist_loss: 0.5393007397651672
recon_loss: 0.03497008606791496, dist_loss: 1.0801594257354736
recon_loss: 0.03496864065527916, dist_loss: 0.749019205570221
recon_loss: 0.0349670834839344, dist_loss: 0.8926360607147217
recon_loss: 0.03496583178639412, dist_loss: 0.36356163024902344
recon_loss: 0.034964703023433685, dist_loss: 0.6949413418769836
recon_loss: 0.03496353328227997, dist_loss: 0.9901632070541382
recon_loss: 0.03496241196990013, dist_loss: 0.4507581293582916
recon_loss: 0.03496116027235985, dist_loss: 0.9732770919799805
recon_loss: 0.034959934651851654, dist_loss: 0.5941009521484375
recon_loss: 0.0349586047232151, dist_loss: 0.6783438920974731
recon_loss: 0.034957364201545715, dist_loss: 0.7352873682975769
recon_loss: 0.03495617210865021, dist_loss: 0.4903343915939331
recon_loss: 0.03495493531227112, dist_loss: 0.6104647517204285
recon_loss: 0.03495386987924576, dist_loss: 0.4762301445007324
recon_loss: 0.034952837973833084, dist_loss: 0.6077855229377747
recon_loss: 0.03495161980390549, dist_loss: 0.5394182801246643
recon_loss: 0.03495044261217117, dist_loss: 0.3665063679218292
recon_loss: 0.03494905307888985, dist_loss: 0.40998557209968567
recon_loss: 0.034947674721479416, dist_loss: 0.6754635572433472
recon_loss: 0.03494628518819809, dist_loss: 0.5164017677307129
recon_loss: 0.03494471311569214, dist_loss: 0.945819079875946
recon_loss: 0.03494320064783096, dist_loss: 0.5250277519226074
recon_loss: 0.034941691905260086, dist_loss: 0.6685948371887207
recon_loss: 0.03494010120630264, dist_loss: 0.5090051293373108
recon_loss: 0.034938402473926544, dist_loss: 0.6502046585083008
recon_loss: 0.03493662178516388, dist_loss: 0.5678790211677551
recon_loss: 0.03493482992053032, dist_loss: 0.4983009696006775
recon_loss: 0.03493313118815422, dist_loss: 0.7845789194107056
recon_loss: 0.0349314920604229, dist_loss: 0.9746180772781372
recon_loss: 0.03492981940507889, dist_loss: 0.7443185448646545
recon_loss: 0.03492821380496025, dist_loss: 0.9872680306434631
recon_loss: 0.03492652624845505, dist_loss: 0.5756150484085083
recon_loss: 0.03492490202188492, dist_loss: 0.37143221497535706
recon_loss: 0.034923434257507324, dist_loss: 0.6940726041793823
recon_loss: 0.034922193735837936, dist_loss: 0.7883713245391846
recon_loss: 0.034921083599328995, dist_loss: 0.631630539894104
recon_loss: 0.03492024540901184, dist_loss: 0.9177439212799072
recon_loss: 0.03491951897740364, dist_loss: 0.8723440170288086
recon_loss: 0.03491833433508873, dist_loss: 0.8857232928276062
recon_loss: 0.034917041659355164, dist_loss: 0.6274659633636475
recon_loss: 0.03491542488336563, dist_loss: 0.5001348257064819
recon_loss: 0.034913744777441025, dist_loss: 0.8976227045059204
recon_loss: 0.034912243485450745, dist_loss: 0.760897696018219
recon_loss: 0.03491062670946121, dist_loss: 0.7213192582130432
recon_loss: 0.034908898174762726, dist_loss: 0.35604119300842285
recon_loss: 0.03490729257464409, dist_loss: 0.5339520573616028
recon_loss: 0.03490583598613739, dist_loss: 0.693969190120697
recon_loss: 0.0349043533205986, dist_loss: 0.8190615773200989
recon_loss: 0.03490276634693146, dist_loss: 0.5227901935577393
recon_loss: 0.03490115702152252, dist_loss: 0.7115031480789185
recon_loss: 0.034899163991212845, dist_loss: 0.8237305283546448
recon_loss: 0.03489728271961212, dist_loss: 0.7379946112632751
recon_loss: 0.03489498794078827, dist_loss: 0.5876425504684448
recon_loss: 0.034892674535512924, dist_loss: 1.205590844154358
recon_loss: 0.034890394657850266, dist_loss: 0.9660528302192688
Pre-training Epoch 21:  74%|███████▍  | 271/367 [00:01<00:00, 183.13it/s]Pre-training Epoch 21:  79%|███████▉  | 290/367 [00:01<00:00, 182.02it/s]Pre-training Epoch 21:  84%|████████▍ | 309/367 [00:01<00:00, 180.63it/s]Pre-training Epoch 21:  89%|████████▉ | 328/367 [00:01<00:00, 178.62it/s]Pre-training Epoch 21:  95%|█████████▍| 347/367 [00:01<00:00, 179.29it/s]Pre-training Epoch 21:  99%|█████████▉| 365/367 [00:01<00:00, 179.33it/s]Pre-training Epoch 21: 100%|██████████| 367/367 [00:02<00:00, 183.48it/s]
recon_loss: 0.034888193011283875, dist_loss: 1.0104963779449463
recon_loss: 0.03488597646355629, dist_loss: 0.8658303022384644
recon_loss: 0.03488369286060333, dist_loss: 0.3865787386894226
recon_loss: 0.03488157317042351, dist_loss: 0.6306045651435852
recon_loss: 0.034879300743341446, dist_loss: 0.6443591117858887
recon_loss: 0.03487705811858177, dist_loss: 0.8312069177627563
recon_loss: 0.03487463295459747, dist_loss: 0.8222020268440247
recon_loss: 0.03487228602170944, dist_loss: 1.2645459175109863
recon_loss: 0.03487023338675499, dist_loss: 0.731271505355835
recon_loss: 0.034868355840444565, dist_loss: 0.47984087467193604
recon_loss: 0.034866541624069214, dist_loss: 0.3731091022491455
recon_loss: 0.034864675253629684, dist_loss: 0.6496031284332275
recon_loss: 0.034862831234931946, dist_loss: 1.2840864658355713
recon_loss: 0.03486114367842674, dist_loss: 0.6485425233840942
recon_loss: 0.034859295934438705, dist_loss: 0.3827627897262573
recon_loss: 0.03485742583870888, dist_loss: 0.5790104866027832
recon_loss: 0.034855443984270096, dist_loss: 0.7215679883956909
recon_loss: 0.03485358506441116, dist_loss: 0.6306637525558472
recon_loss: 0.03485177084803581, dist_loss: 0.41472327709198
recon_loss: 0.034849803894758224, dist_loss: 0.9104411005973816
recon_loss: 0.03484775871038437, dist_loss: 0.7426432371139526
recon_loss: 0.03484554588794708, dist_loss: 0.5585356950759888
recon_loss: 0.03484334424138069, dist_loss: 1.0670323371887207
recon_loss: 0.03484092280268669, dist_loss: 0.44804713129997253
recon_loss: 0.034838516265153885, dist_loss: 0.46060457825660706
recon_loss: 0.03483610600233078, dist_loss: 0.8625824451446533
recon_loss: 0.034833647310733795, dist_loss: 0.6538803577423096
recon_loss: 0.03483128175139427, dist_loss: 0.5314410924911499
recon_loss: 0.034828901290893555, dist_loss: 0.6493853330612183
recon_loss: 0.034826647490262985, dist_loss: 0.39722615480422974
recon_loss: 0.03482440486550331, dist_loss: 0.6427737474441528
recon_loss: 0.0348222441971302, dist_loss: 0.6461357474327087
recon_loss: 0.034820254892110825, dist_loss: 0.40572068095207214
recon_loss: 0.03481823578476906, dist_loss: 0.4864691495895386
recon_loss: 0.03481640666723251, dist_loss: 0.46747323870658875
recon_loss: 0.034814462065696716, dist_loss: 1.2262587547302246
recon_loss: 0.034812282770872116, dist_loss: 0.5013622045516968
recon_loss: 0.0348101370036602, dist_loss: 0.5018208026885986
recon_loss: 0.034808237105607986, dist_loss: 0.5713396668434143
recon_loss: 0.03480628877878189, dist_loss: 0.4357263743877411
recon_loss: 0.034804172813892365, dist_loss: 0.8889516592025757
recon_loss: 0.03480219095945358, dist_loss: 0.6189038753509521
recon_loss: 0.03480043634772301, dist_loss: 0.8292081952095032
recon_loss: 0.03479871153831482, dist_loss: 0.3541104197502136
recon_loss: 0.03479688614606857, dist_loss: 0.5656288862228394
recon_loss: 0.0347948856651783, dist_loss: 0.761367678642273
recon_loss: 0.03479278087615967, dist_loss: 0.4443448781967163
recon_loss: 0.034790512174367905, dist_loss: 1.1229360103607178
recon_loss: 0.03478816896677017, dist_loss: 0.5659946203231812
recon_loss: 0.03478575870394707, dist_loss: 1.047454595565796
recon_loss: 0.03478365018963814, dist_loss: 1.6317558288574219
recon_loss: 0.03478173539042473, dist_loss: 0.4198229908943176
recon_loss: 0.034779906272888184, dist_loss: 0.4941314458847046
recon_loss: 0.03477806970477104, dist_loss: 0.546824038028717
recon_loss: 0.03477613627910614, dist_loss: 0.4072958827018738
recon_loss: 0.03477424383163452, dist_loss: 0.8131197690963745
recon_loss: 0.03477274999022484, dist_loss: 0.5325356721878052
recon_loss: 0.03477137163281441, dist_loss: 0.8943474888801575
recon_loss: 0.03477012366056442, dist_loss: 0.6444286108016968
recon_loss: 0.034768830984830856, dist_loss: 0.9067574739456177
recon_loss: 0.03476740047335625, dist_loss: 0.7268334627151489
recon_loss: 0.03476594761013985, dist_loss: 0.5553162097930908
recon_loss: 0.03476456180214882, dist_loss: 0.6975563168525696
recon_loss: 0.03476324677467346, dist_loss: 0.38994133472442627
recon_loss: 0.03476197272539139, dist_loss: 0.4130147695541382
recon_loss: 0.03476056456565857, dist_loss: 0.7861855030059814
recon_loss: 0.03475899621844292, dist_loss: 0.5177473425865173
recon_loss: 0.03475714847445488, dist_loss: 0.482307106256485
recon_loss: 0.034755170345306396, dist_loss: 0.6849286556243896
recon_loss: 0.03475314378738403, dist_loss: 0.5426017045974731
recon_loss: 0.03475094959139824, dist_loss: 0.6541057229042053
recon_loss: 0.03474863991141319, dist_loss: 0.6597336530685425
recon_loss: 0.03474614396691322, dist_loss: 0.7646608352661133
recon_loss: 0.03474375978112221, dist_loss: 0.6206117272377014
recon_loss: 0.03474155813455582, dist_loss: 0.6554408073425293
recon_loss: 0.03473954275250435, dist_loss: 0.9118447303771973
recon_loss: 0.03473750129342079, dist_loss: 0.666395902633667
recon_loss: 0.03473563864827156, dist_loss: 0.9360952973365784
recon_loss: 0.03473372012376785, dist_loss: 0.6095192432403564
recon_loss: 0.034731704741716385, dist_loss: 1.2468290328979492
recon_loss: 0.0347297377884388, dist_loss: 0.695327639579773
recon_loss: 0.03472767025232315, dist_loss: 0.5537153482437134
recon_loss: 0.03472597524523735, dist_loss: 0.7813841700553894
recon_loss: 0.03472422435879707, dist_loss: 0.4254324436187744
recon_loss: 0.03472229465842247, dist_loss: 0.6103278398513794
recon_loss: 0.03472049906849861, dist_loss: 0.4889810085296631
recon_loss: 0.034718770533800125, dist_loss: 0.31801360845565796
recon_loss: 0.03471701219677925, dist_loss: 0.6923497915267944
recon_loss: 0.034715332090854645, dist_loss: 0.7384254932403564
recon_loss: 0.034713808447122574, dist_loss: 0.23782388865947723
recon_loss: 0.034712448716163635, dist_loss: 0.7910464406013489
recon_loss: 0.03471123427152634, dist_loss: 0.8016465902328491
recon_loss: 0.03470981866121292, dist_loss: 0.7539568543434143
recon_loss: 0.03470858559012413, dist_loss: 0.6942219734191895
recon_loss: 0.034707508981227875, dist_loss: 0.5628361701965332
recon_loss: 0.034706000238657, dist_loss: 0.7711458206176758
recon_loss: 0.034704484045505524, dist_loss: 0.8306220769882202
recon_loss: 0.03470272198319435, dist_loss: 0.3810971975326538
recon_loss: 0.034701157361269, dist_loss: 0.5180670022964478
recon_loss: 0.0346997044980526, dist_loss: 0.787074625492096
recon_loss: 0.03469843789935112, dist_loss: 0.7688586711883545
recon_loss: 0.0346972681581974, dist_loss: 0.9069097638130188
recon_loss: 0.03469599038362503, dist_loss: 0.5410056710243225
recon_loss: 0.03469429537653923, dist_loss: 0.5751784443855286
recon_loss: 0.034692272543907166, dist_loss: 0.7002224326133728
recon_loss: 0.0346904881298542, dist_loss: 0.45185762643814087
recon_loss: 0.03468851000070572, dist_loss: 0.6985658407211304
recon_loss: 0.03468647971749306, dist_loss: 0.4250473380088806
recon_loss: 0.0346844345331192, dist_loss: 0.9551435708999634
Pre-training Epoch 22:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 22:   5%|▍         | 17/367 [00:00<00:02, 164.17it/s]Pre-training Epoch 22:  10%|▉         | 35/367 [00:00<00:01, 168.83it/s]Pre-training Epoch 22:  14%|█▍        | 53/367 [00:00<00:01, 172.87it/s]Pre-training Epoch 22:  19%|█▉        | 71/367 [00:00<00:01, 175.57it/s]Pre-training Epoch 22:  24%|██▍       | 89/367 [00:00<00:01, 176.10it/s]Pre-training Epoch 22:  29%|██▉       | 107/367 [00:00<00:01, 177.31it/s]Pre-training Epoch 22:  34%|███▍      | 125/367 [00:00<00:01, 172.10it/s]recon_loss: 0.034682851284742355, dist_loss: 0.6435484886169434
recon_loss: 0.034681227058172226, dist_loss: 0.7628830671310425
recon_loss: 0.03467955440282822, dist_loss: 0.5205228924751282
recon_loss: 0.034677810966968536, dist_loss: 1.1924384832382202
recon_loss: 0.034676071256399155, dist_loss: 1.0700948238372803
recon_loss: 0.03467436134815216, dist_loss: 0.6020557880401611
recon_loss: 0.03467269986867905, dist_loss: 0.6410157680511475
recon_loss: 0.03467065840959549, dist_loss: 0.6144595146179199
recon_loss: 0.03466872125864029, dist_loss: 0.2990610599517822
recon_loss: 0.034666914492845535, dist_loss: 0.7626389265060425
recon_loss: 0.034665096551179886, dist_loss: 0.64628666639328
recon_loss: 0.03466302901506424, dist_loss: 0.4888935685157776
recon_loss: 0.034660737961530685, dist_loss: 0.5513803958892822
recon_loss: 0.03465831279754639, dist_loss: 0.6113515496253967
recon_loss: 0.03465588763356209, dist_loss: 0.5427200794219971
recon_loss: 0.034653715789318085, dist_loss: 0.8359948396682739
recon_loss: 0.03465156629681587, dist_loss: 0.5489228963851929
recon_loss: 0.03464967757463455, dist_loss: 0.9176307320594788
recon_loss: 0.03464784100651741, dist_loss: 0.6240503191947937
recon_loss: 0.03464623540639877, dist_loss: 0.8947495222091675
recon_loss: 0.03464445099234581, dist_loss: 0.6558748483657837
recon_loss: 0.03464234247803688, dist_loss: 0.7454688549041748
recon_loss: 0.03464028984308243, dist_loss: 1.0301499366760254
recon_loss: 0.03463822975754738, dist_loss: 0.7490858435630798
recon_loss: 0.03463597223162651, dist_loss: 0.468377947807312
recon_loss: 0.03463396802544594, dist_loss: 1.2410881519317627
recon_loss: 0.034632034599781036, dist_loss: 0.3042558431625366
recon_loss: 0.03463037684559822, dist_loss: 0.21294791996479034
recon_loss: 0.034628674387931824, dist_loss: 0.47576332092285156
recon_loss: 0.03462688997387886, dist_loss: 0.49650460481643677
recon_loss: 0.03462459519505501, dist_loss: 0.7733081579208374
recon_loss: 0.03462248295545578, dist_loss: 0.6316205859184265
recon_loss: 0.03462030738592148, dist_loss: 0.43179845809936523
recon_loss: 0.03461829200387001, dist_loss: 0.6385447382926941
recon_loss: 0.034616582095623016, dist_loss: 0.7714027166366577
recon_loss: 0.034614719450473785, dist_loss: 0.525118350982666
recon_loss: 0.034613095223903656, dist_loss: 0.4626161754131317
recon_loss: 0.03461172431707382, dist_loss: 0.6207887530326843
recon_loss: 0.03461027890443802, dist_loss: 0.5051987171173096
recon_loss: 0.03460881859064102, dist_loss: 0.6478633880615234
recon_loss: 0.03460737317800522, dist_loss: 1.2506301403045654
recon_loss: 0.03460565581917763, dist_loss: 0.4407396912574768
recon_loss: 0.03460392355918884, dist_loss: 0.5042275190353394
recon_loss: 0.0346023365855217, dist_loss: 0.8094983100891113
recon_loss: 0.03460096940398216, dist_loss: 0.7606781721115112
recon_loss: 0.03459961339831352, dist_loss: 0.6455612182617188
recon_loss: 0.034598059952259064, dist_loss: 0.5121102333068848
recon_loss: 0.034596338868141174, dist_loss: 0.853894829750061
recon_loss: 0.03459440916776657, dist_loss: 0.92605060338974
recon_loss: 0.03459249436855316, dist_loss: 0.642645001411438
recon_loss: 0.034590546041727066, dist_loss: 0.91016685962677
recon_loss: 0.034588638693094254, dist_loss: 0.522731363773346
recon_loss: 0.03458651155233383, dist_loss: 0.5669376254081726
recon_loss: 0.03458435833454132, dist_loss: 0.6724538803100586
recon_loss: 0.03458254784345627, dist_loss: 0.5996633172035217
recon_loss: 0.03458080068230629, dist_loss: 0.7293538451194763
recon_loss: 0.03457896038889885, dist_loss: 0.6448217630386353
recon_loss: 0.03457696735858917, dist_loss: 0.5818542242050171
recon_loss: 0.03457514941692352, dist_loss: 0.5999890565872192
recon_loss: 0.03457363694906235, dist_loss: 0.514297604560852
recon_loss: 0.034572042524814606, dist_loss: 0.6754536628723145
recon_loss: 0.034570515155792236, dist_loss: 1.1793442964553833
recon_loss: 0.034569092094898224, dist_loss: 0.8508716821670532
recon_loss: 0.034567538648843765, dist_loss: 0.5283782482147217
recon_loss: 0.03456587344408035, dist_loss: 0.7503540515899658
recon_loss: 0.034563928842544556, dist_loss: 0.47141537070274353
recon_loss: 0.03456207364797592, dist_loss: 0.8599993586540222
recon_loss: 0.03456052020192146, dist_loss: 0.4825671315193176
recon_loss: 0.034559186547994614, dist_loss: 0.7493264675140381
recon_loss: 0.03455813229084015, dist_loss: 0.5943093299865723
recon_loss: 0.03455713018774986, dist_loss: 1.1872498989105225
recon_loss: 0.034556031227111816, dist_loss: 1.0182507038116455
recon_loss: 0.034554462879896164, dist_loss: 0.6901118159294128
recon_loss: 0.03455284237861633, dist_loss: 0.6411409974098206
recon_loss: 0.034551069140434265, dist_loss: 0.5867058038711548
recon_loss: 0.034549228847026825, dist_loss: 0.44701021909713745
recon_loss: 0.034547366201877594, dist_loss: 0.8011555671691895
recon_loss: 0.03454555198550224, dist_loss: 0.8680939674377441
recon_loss: 0.0345437116920948, dist_loss: 1.1710842847824097
recon_loss: 0.034542061388492584, dist_loss: 0.4291820824146271
recon_loss: 0.03454052656888962, dist_loss: 0.5004909634590149
recon_loss: 0.03453918173909187, dist_loss: 0.34176260232925415
recon_loss: 0.03453771397471428, dist_loss: 0.699388861656189
recon_loss: 0.03453605994582176, dist_loss: 1.267359972000122
recon_loss: 0.034534163773059845, dist_loss: 0.6584944725036621
recon_loss: 0.03453212231397629, dist_loss: 0.9240058660507202
recon_loss: 0.03453006222844124, dist_loss: 0.46808162331581116
recon_loss: 0.03452792391180992, dist_loss: 0.721706748008728
recon_loss: 0.03452594578266144, dist_loss: 0.7859492301940918
recon_loss: 0.0345240980386734, dist_loss: 1.479063868522644
recon_loss: 0.03452261537313461, dist_loss: 0.343791127204895
recon_loss: 0.03452124074101448, dist_loss: 0.6883693933486938
recon_loss: 0.03451992943882942, dist_loss: 0.5287508368492126
recon_loss: 0.0345185324549675, dist_loss: 0.580735445022583
recon_loss: 0.03451690822839737, dist_loss: 0.2920336127281189
recon_loss: 0.03451504558324814, dist_loss: 0.6935580968856812
recon_loss: 0.0345131941139698, dist_loss: 0.434783935546875
recon_loss: 0.03451145067811012, dist_loss: 0.38730573654174805
recon_loss: 0.03450971469283104, dist_loss: 0.6008560657501221
recon_loss: 0.03450767695903778, dist_loss: 0.5696043968200684
recon_loss: 0.03450562059879303, dist_loss: 1.0030609369277954
recon_loss: 0.03450338914990425, dist_loss: 0.8342009782791138
recon_loss: 0.034501127898693085, dist_loss: 0.9374913573265076
recon_loss: 0.03449880704283714, dist_loss: 0.813610315322876
recon_loss: 0.034496527165174484, dist_loss: 0.573821485042572
recon_loss: 0.034494560211896896, dist_loss: 1.0874251127243042
recon_loss: 0.034492578357458115, dist_loss: 0.7719656229019165
recon_loss: 0.03449077531695366, dist_loss: 0.4125639796257019
recon_loss: 0.03448884189128876, dist_loss: 1.174660563468933
recon_loss: 0.03448712080717087, dist_loss: 0.5216043591499329
recon_loss: 0.03448553383350372, dist_loss: 0.9821093678474426
recon_loss: 0.03448401391506195, dist_loss: 0.594494104385376
recon_loss: 0.0344824455678463, dist_loss: 0.5456751585006714
recon_loss: 0.03448094427585602, dist_loss: 0.513041079044342
recon_loss: 0.03447924554347992, dist_loss: 0.8687387108802795
recon_loss: 0.034477636218070984, dist_loss: 0.9286500215530396
recon_loss: 0.03447595611214638, dist_loss: 0.5174216628074646
recon_loss: 0.03447426110506058, dist_loss: 1.052119493484497
recon_loss: 0.03447258472442627, dist_loss: 0.5410447716712952
recon_loss: 0.034470852464437485, dist_loss: 1.287790298461914
recon_loss: 0.0344686396420002, dist_loss: 0.3822566866874695
recon_loss: 0.034466274082660675, dist_loss: 0.5878117084503174
recon_loss: 0.0344637967646122, dist_loss: 0.6586726903915405
recon_loss: 0.0344613753259182, dist_loss: 0.3462640941143036
recon_loss: 0.03445902839303017, dist_loss: 0.5936528444290161
recon_loss: 0.03445674106478691, dist_loss: 0.4596601128578186
recon_loss: 0.034454409033060074, dist_loss: 1.426668405532837
recon_loss: 0.03445218876004219, dist_loss: 1.0416532754898071
recon_loss: 0.03444996476173401, dist_loss: 0.725272536277771
Pre-training Epoch 22:  39%|███▉      | 143/367 [00:00<00:01, 162.36it/s]Pre-training Epoch 22:  44%|████▎     | 160/367 [00:00<00:01, 160.10it/s]Pre-training Epoch 22:  48%|████▊     | 177/367 [00:01<00:01, 158.22it/s]Pre-training Epoch 22:  53%|█████▎    | 193/367 [00:01<00:01, 157.58it/s]Pre-training Epoch 22:  57%|█████▋    | 211/367 [00:01<00:00, 163.40it/s]Pre-training Epoch 22:  62%|██████▏   | 229/367 [00:01<00:00, 167.65it/s]Pre-training Epoch 22:  67%|██████▋   | 247/367 [00:01<00:00, 170.49it/s]recon_loss: 0.03444777429103851, dist_loss: 0.4484056234359741
recon_loss: 0.03444559872150421, dist_loss: 0.5008841156959534
recon_loss: 0.03444357216358185, dist_loss: 0.48861950635910034
recon_loss: 0.034441545605659485, dist_loss: 0.7053589820861816
recon_loss: 0.03443961217999458, dist_loss: 0.42921462655067444
recon_loss: 0.03443768620491028, dist_loss: 0.6932686567306519
recon_loss: 0.03443577140569687, dist_loss: 0.8253822326660156
recon_loss: 0.034433670341968536, dist_loss: 0.40260767936706543
recon_loss: 0.034431565552949905, dist_loss: 0.5756042003631592
recon_loss: 0.03442955017089844, dist_loss: 0.5877870321273804
recon_loss: 0.03442759066820145, dist_loss: 1.4577924013137817
recon_loss: 0.034425582736730576, dist_loss: 0.8375256061553955
recon_loss: 0.03442353010177612, dist_loss: 0.466239869594574
recon_loss: 0.034421809017658234, dist_loss: 0.7753683924674988
recon_loss: 0.0344201885163784, dist_loss: 0.44125205278396606
recon_loss: 0.03441869094967842, dist_loss: 0.523993968963623
recon_loss: 0.03441712632775307, dist_loss: 0.6382921934127808
recon_loss: 0.03441549837589264, dist_loss: 0.5271711349487305
recon_loss: 0.03441387042403221, dist_loss: 0.9800666570663452
recon_loss: 0.034411944448947906, dist_loss: 1.0467157363891602
recon_loss: 0.03440996631979942, dist_loss: 0.8716343641281128
recon_loss: 0.034408051520586014, dist_loss: 0.5111467242240906
recon_loss: 0.03440610691905022, dist_loss: 0.8632624745368958
recon_loss: 0.03440399840474129, dist_loss: 0.5477432608604431
recon_loss: 0.03440159559249878, dist_loss: 0.9560606479644775
recon_loss: 0.03439943864941597, dist_loss: 1.1588928699493408
recon_loss: 0.034397538751363754, dist_loss: 0.5047078728675842
recon_loss: 0.03439558669924736, dist_loss: 0.7039768695831299
recon_loss: 0.034393876791000366, dist_loss: 0.8580242395401001
recon_loss: 0.034392036497592926, dist_loss: 0.6125891208648682
recon_loss: 0.0343896746635437, dist_loss: 0.44869962334632874
recon_loss: 0.03438704088330269, dist_loss: 0.627208948135376
recon_loss: 0.03438442200422287, dist_loss: 0.5743460059165955
recon_loss: 0.034381866455078125, dist_loss: 0.42376184463500977
recon_loss: 0.0343795120716095, dist_loss: 1.0539958477020264
recon_loss: 0.03437742218375206, dist_loss: 0.7546229362487793
recon_loss: 0.034375373274087906, dist_loss: 0.8250476717948914
recon_loss: 0.03437323495745659, dist_loss: 0.6290680170059204
recon_loss: 0.03437109291553497, dist_loss: 0.49449843168258667
recon_loss: 0.034369293600320816, dist_loss: 0.9981019496917725
recon_loss: 0.03436784818768501, dist_loss: 1.0439858436584473
recon_loss: 0.03436638414859772, dist_loss: 0.632635772228241
recon_loss: 0.03436482697725296, dist_loss: 0.8308296799659729
recon_loss: 0.03436299040913582, dist_loss: 0.3643009066581726
recon_loss: 0.0343613401055336, dist_loss: 0.47654396295547485
recon_loss: 0.034359585493803024, dist_loss: 0.8541511297225952
recon_loss: 0.03435773402452469, dist_loss: 0.5413596630096436
recon_loss: 0.03435591235756874, dist_loss: 0.6777961254119873
recon_loss: 0.034354351460933685, dist_loss: 0.5960660576820374
recon_loss: 0.03435270115733147, dist_loss: 0.5508506894111633
recon_loss: 0.03435094282031059, dist_loss: 0.4704166054725647
recon_loss: 0.03434907644987106, dist_loss: 0.7530204653739929
recon_loss: 0.03434712439775467, dist_loss: 0.47640347480773926
recon_loss: 0.03434517979621887, dist_loss: 0.4919373393058777
recon_loss: 0.03434321656823158, dist_loss: 0.6425677537918091
recon_loss: 0.03434111177921295, dist_loss: 0.566106379032135
recon_loss: 0.03433888778090477, dist_loss: 0.4308726191520691
recon_loss: 0.03433676436543465, dist_loss: 0.4366638958454132
recon_loss: 0.03433471545577049, dist_loss: 1.106231927871704
recon_loss: 0.034332629293203354, dist_loss: 0.41059571504592896
recon_loss: 0.03433047980070114, dist_loss: 0.6768723726272583
recon_loss: 0.034328360110521317, dist_loss: 0.445525586605072
recon_loss: 0.034326259046792984, dist_loss: 0.7780396938323975
recon_loss: 0.03432414308190346, dist_loss: 0.6121734380722046
recon_loss: 0.034322138875722885, dist_loss: 0.7883867621421814
recon_loss: 0.034320127218961716, dist_loss: 0.4750332534313202
recon_loss: 0.0343182273209095, dist_loss: 0.6840107440948486
recon_loss: 0.03431626036763191, dist_loss: 0.48999178409576416
recon_loss: 0.03431440144777298, dist_loss: 0.4972931444644928
recon_loss: 0.03431232273578644, dist_loss: 0.7070286870002747
recon_loss: 0.03431004285812378, dist_loss: 0.5176785588264465
recon_loss: 0.03430789336562157, dist_loss: 0.5710139870643616
recon_loss: 0.03430573642253876, dist_loss: 0.7780221104621887
recon_loss: 0.03430379554629326, dist_loss: 0.6847283840179443
recon_loss: 0.03430192172527313, dist_loss: 0.7254214882850647
recon_loss: 0.034299999475479126, dist_loss: 0.4111228883266449
recon_loss: 0.034297991544008255, dist_loss: 1.0304232835769653
recon_loss: 0.034296028316020966, dist_loss: 0.6600635051727295
recon_loss: 0.03429412841796875, dist_loss: 0.7633252143859863
recon_loss: 0.034292254596948624, dist_loss: 0.6632730960845947
recon_loss: 0.03429046645760536, dist_loss: 0.8928890228271484
recon_loss: 0.03428860753774643, dist_loss: 0.827446699142456
recon_loss: 0.03428691625595093, dist_loss: 0.9191339015960693
recon_loss: 0.03428530693054199, dist_loss: 0.38342028856277466
recon_loss: 0.03428354859352112, dist_loss: 1.1247740983963013
recon_loss: 0.03428173437714577, dist_loss: 0.5702165961265564
recon_loss: 0.03427994251251221, dist_loss: 0.6024880409240723
recon_loss: 0.034278277307748795, dist_loss: 0.6025629639625549
recon_loss: 0.03427658602595329, dist_loss: 0.346016526222229
recon_loss: 0.034274835139513016, dist_loss: 0.4262208938598633
recon_loss: 0.03427300602197647, dist_loss: 0.5766255855560303
recon_loss: 0.03427143394947052, dist_loss: 0.3805205821990967
recon_loss: 0.034269630908966064, dist_loss: 1.1682968139648438
recon_loss: 0.0342678464949131, dist_loss: 0.6795076131820679
recon_loss: 0.034266117960214615, dist_loss: 0.5483589172363281
recon_loss: 0.03426438197493553, dist_loss: 0.9364030957221985
recon_loss: 0.03426254168152809, dist_loss: 0.6202952265739441
recon_loss: 0.034260671585798264, dist_loss: 0.8629708290100098
recon_loss: 0.03425879403948784, dist_loss: 0.4344280958175659
recon_loss: 0.03425697982311249, dist_loss: 0.4861043691635132
recon_loss: 0.03425505384802818, dist_loss: 0.6683588624000549
recon_loss: 0.03425319120287895, dist_loss: 0.5603066086769104
recon_loss: 0.03425128757953644, dist_loss: 0.30610987544059753
recon_loss: 0.03424949198961258, dist_loss: 0.9631349444389343
recon_loss: 0.03424767032265663, dist_loss: 0.44638749957084656
recon_loss: 0.03424568846821785, dist_loss: 0.6702510118484497
recon_loss: 0.03424374386668205, dist_loss: 0.63260817527771
recon_loss: 0.03424167260527611, dist_loss: 0.3811167776584625
recon_loss: 0.0342395082116127, dist_loss: 0.8832655549049377
recon_loss: 0.03423731401562691, dist_loss: 0.6312003135681152
recon_loss: 0.034235309809446335, dist_loss: 0.49257194995880127
recon_loss: 0.03423338383436203, dist_loss: 0.7711946368217468
recon_loss: 0.03423147648572922, dist_loss: 0.7640126943588257
recon_loss: 0.0342295840382576, dist_loss: 0.9755278825759888
recon_loss: 0.03422754257917404, dist_loss: 0.5401374101638794
recon_loss: 0.03422557935118675, dist_loss: 0.9719369411468506
recon_loss: 0.034223757684230804, dist_loss: 0.5394324064254761
recon_loss: 0.03422180190682411, dist_loss: 0.6311476230621338
recon_loss: 0.03421972319483757, dist_loss: 0.4844968318939209
recon_loss: 0.03421775996685028, dist_loss: 0.8211446404457092
recon_loss: 0.0342157743871212, dist_loss: 0.9086427688598633
recon_loss: 0.03421389311552048, dist_loss: 0.7523638010025024
recon_loss: 0.03421201556921005, dist_loss: 0.5686360001564026
recon_loss: 0.034210145473480225, dist_loss: 0.6036785244941711
recon_loss: 0.0342082679271698, dist_loss: 0.8453795909881592
recon_loss: 0.03420622646808624, dist_loss: 0.5253804326057434
recon_loss: 0.03420424461364746, dist_loss: 0.6871813535690308
recon_loss: 0.034202225506305695, dist_loss: 0.7307382822036743
recon_loss: 0.03420032188296318, dist_loss: 0.7130898833274841
Pre-training Epoch 22:  72%|███████▏  | 265/367 [00:01<00:00, 172.37it/s]Pre-training Epoch 22:  77%|███████▋  | 283/367 [00:01<00:00, 174.12it/s]Pre-training Epoch 22:  82%|████████▏ | 301/367 [00:01<00:00, 167.59it/s]Pre-training Epoch 22:  87%|████████▋ | 320/367 [00:01<00:00, 171.40it/s]Pre-training Epoch 22:  92%|█████████▏| 338/367 [00:02<00:00, 172.85it/s]Pre-training Epoch 22:  97%|█████████▋| 356/367 [00:02<00:00, 174.44it/s]Pre-training Epoch 22: 100%|██████████| 367/367 [00:02<00:00, 169.27it/s]
recon_loss: 0.03419831022620201, dist_loss: 0.454936146736145
recon_loss: 0.03419644013047218, dist_loss: 0.6839766502380371
recon_loss: 0.03419450670480728, dist_loss: 0.4432832598686218
recon_loss: 0.03419240191578865, dist_loss: 0.9846529960632324
recon_loss: 0.0341900959610939, dist_loss: 0.47126030921936035
recon_loss: 0.034187909215688705, dist_loss: 1.1645400524139404
recon_loss: 0.03418596088886261, dist_loss: 0.7430908679962158
recon_loss: 0.03418406471610069, dist_loss: 0.9700601100921631
recon_loss: 0.03418200835585594, dist_loss: 0.34921950101852417
recon_loss: 0.034179795533418655, dist_loss: 0.42361366748809814
recon_loss: 0.03417753800749779, dist_loss: 0.5497388243675232
recon_loss: 0.03417547792196274, dist_loss: 0.675212025642395
recon_loss: 0.03417343273758888, dist_loss: 0.7806061506271362
recon_loss: 0.03417133167386055, dist_loss: 0.6997709274291992
recon_loss: 0.03416922688484192, dist_loss: 0.550345778465271
recon_loss: 0.03416699171066284, dist_loss: 0.7595627307891846
recon_loss: 0.03416480869054794, dist_loss: 0.5068492293357849
recon_loss: 0.03416271507740021, dist_loss: 0.8447030186653137
recon_loss: 0.0341605544090271, dist_loss: 0.5738669037818909
recon_loss: 0.03415846824645996, dist_loss: 0.5629770755767822
recon_loss: 0.03415631502866745, dist_loss: 0.9526870846748352
recon_loss: 0.034154124557971954, dist_loss: 0.8496114611625671
recon_loss: 0.03415199741721153, dist_loss: 0.48737505078315735
recon_loss: 0.03414999693632126, dist_loss: 0.36936813592910767
recon_loss: 0.034147996455430984, dist_loss: 0.6031597256660461
recon_loss: 0.03414594754576683, dist_loss: 1.196653127670288
recon_loss: 0.03414416313171387, dist_loss: 0.24203641712665558
recon_loss: 0.03414223715662956, dist_loss: 0.8583726286888123
recon_loss: 0.03414003551006317, dist_loss: 0.5899527072906494
recon_loss: 0.03413759917020798, dist_loss: 1.3729650974273682
recon_loss: 0.034135185182094574, dist_loss: 0.6091422438621521
recon_loss: 0.034132763743400574, dist_loss: 1.2989625930786133
recon_loss: 0.03413035720586777, dist_loss: 0.7600024938583374
recon_loss: 0.03412793576717377, dist_loss: 0.7286595106124878
recon_loss: 0.03412594273686409, dist_loss: 0.5506476759910583
recon_loss: 0.034124117344617844, dist_loss: 0.8486855030059814
recon_loss: 0.034122440963983536, dist_loss: 0.6478413939476013
recon_loss: 0.0341205857694149, dist_loss: 0.7836480140686035
recon_loss: 0.034118834882974625, dist_loss: 0.5413322448730469
recon_loss: 0.03411730378866196, dist_loss: 0.9251694679260254
recon_loss: 0.03411519527435303, dist_loss: 0.9665765762329102
recon_loss: 0.03411312401294708, dist_loss: 0.8693263530731201
recon_loss: 0.03411121293902397, dist_loss: 0.8304452896118164
recon_loss: 0.034109558910131454, dist_loss: 0.8768020868301392
recon_loss: 0.0341080017387867, dist_loss: 0.7995019555091858
recon_loss: 0.034106433391571045, dist_loss: 0.7713643908500671
recon_loss: 0.03410469368100166, dist_loss: 0.6612868309020996
recon_loss: 0.034102823585271835, dist_loss: 0.6156509518623352
recon_loss: 0.03410100191831589, dist_loss: 0.5920447111129761
recon_loss: 0.03409913182258606, dist_loss: 0.6990203857421875
recon_loss: 0.03409714251756668, dist_loss: 0.4643765687942505
recon_loss: 0.03409532830119133, dist_loss: 0.5727314949035645
recon_loss: 0.0340934582054615, dist_loss: 0.30508720874786377
recon_loss: 0.034091416746377945, dist_loss: 0.5975691080093384
recon_loss: 0.034089453518390656, dist_loss: 0.7639394998550415
recon_loss: 0.034087568521499634, dist_loss: 1.0087199211120605
recon_loss: 0.034085605293512344, dist_loss: 0.47000187635421753
recon_loss: 0.03408370539546013, dist_loss: 0.9291016459465027
recon_loss: 0.034082021564245224, dist_loss: 0.6752171516418457
recon_loss: 0.03408028185367584, dist_loss: 0.617891788482666
recon_loss: 0.03407856449484825, dist_loss: 0.5136750340461731
recon_loss: 0.03407681733369827, dist_loss: 0.6107136011123657
recon_loss: 0.034075040370225906, dist_loss: 0.6162712574005127
recon_loss: 0.03407321125268936, dist_loss: 0.6389945149421692
recon_loss: 0.03407128527760506, dist_loss: 1.025484561920166
recon_loss: 0.03406939283013344, dist_loss: 0.6483376026153564
recon_loss: 0.034067317843437195, dist_loss: 0.4584463834762573
recon_loss: 0.03406524658203125, dist_loss: 0.7684412598609924
recon_loss: 0.034063056111335754, dist_loss: 0.5885300636291504
recon_loss: 0.03406091779470444, dist_loss: 0.5210000872612
recon_loss: 0.034058745950460434, dist_loss: 0.6397719383239746
recon_loss: 0.034056566655635834, dist_loss: 0.7391639351844788
recon_loss: 0.03405444696545601, dist_loss: 0.6636189818382263
recon_loss: 0.03405235335230827, dist_loss: 0.46461021900177
recon_loss: 0.034050311893224716, dist_loss: 0.598311185836792
recon_loss: 0.03404828533530235, dist_loss: 0.4651358723640442
recon_loss: 0.034046147018671036, dist_loss: 0.6873254776000977
recon_loss: 0.03404402732849121, dist_loss: 0.6579384207725525
recon_loss: 0.03404200077056885, dist_loss: 0.9416244029998779
recon_loss: 0.03403991833329201, dist_loss: 0.6761288642883301
recon_loss: 0.03403786942362785, dist_loss: 0.7295968532562256
recon_loss: 0.034035954624414444, dist_loss: 0.8834596872329712
recon_loss: 0.034033942967653275, dist_loss: 1.4035017490386963
recon_loss: 0.03403201326727867, dist_loss: 0.4685494303703308
recon_loss: 0.03403007239103317, dist_loss: 0.5008379817008972
recon_loss: 0.034028034657239914, dist_loss: 0.8759669065475464
recon_loss: 0.03402620553970337, dist_loss: 0.5625306367874146
recon_loss: 0.03402440622448921, dist_loss: 0.7982726097106934
recon_loss: 0.03402248024940491, dist_loss: 0.7433292865753174
recon_loss: 0.034020330756902695, dist_loss: 1.0523771047592163
recon_loss: 0.03401816263794899, dist_loss: 0.8782246112823486
recon_loss: 0.03401627019047737, dist_loss: 1.0881847143173218
recon_loss: 0.034014392644166946, dist_loss: 1.0814805030822754
recon_loss: 0.03401254490017891, dist_loss: 0.8695708513259888
recon_loss: 0.034010790288448334, dist_loss: 0.4178457260131836
recon_loss: 0.034009043127298355, dist_loss: 0.5041094422340393
recon_loss: 0.03400726616382599, dist_loss: 1.0873724222183228
recon_loss: 0.03400533273816109, dist_loss: 0.9365954399108887
recon_loss: 0.034003328531980515, dist_loss: 0.9027578830718994
recon_loss: 0.034001365303993225, dist_loss: 0.6250717639923096
recon_loss: 0.03399918973445892, dist_loss: 0.669913649559021
recon_loss: 0.03399694710969925, dist_loss: 0.6552869081497192
recon_loss: 0.03399466723203659, dist_loss: 0.6431529521942139
recon_loss: 0.03399238735437393, dist_loss: 0.7515509128570557
recon_loss: 0.033990245312452316, dist_loss: 0.39977362751960754
recon_loss: 0.03398822620511055, dist_loss: 0.47000932693481445
recon_loss: 0.033986128866672516, dist_loss: 0.7744358777999878
recon_loss: 0.03398416191339493, dist_loss: 0.5422788858413696
recon_loss: 0.033982232213020325, dist_loss: 1.0228723287582397
Pre-training Epoch 23:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 23:   5%|▌         | 19/367 [00:00<00:01, 184.80it/s]Pre-training Epoch 23:  11%|█         | 39/367 [00:00<00:01, 189.86it/s]Pre-training Epoch 23:  16%|█▌        | 59/367 [00:00<00:01, 191.26it/s]Pre-training Epoch 23:  22%|██▏       | 79/367 [00:00<00:01, 189.13it/s]Pre-training Epoch 23:  27%|██▋       | 99/367 [00:00<00:01, 190.60it/s]Pre-training Epoch 23:  32%|███▏      | 119/367 [00:00<00:01, 191.69it/s]recon_loss: 0.03398088738322258, dist_loss: 0.6465543508529663
recon_loss: 0.03397951275110245, dist_loss: 0.9489873051643372
recon_loss: 0.033978112041950226, dist_loss: 0.5369365811347961
recon_loss: 0.03397664427757263, dist_loss: 1.082290768623352
recon_loss: 0.03397490829229355, dist_loss: 0.6644536256790161
recon_loss: 0.03397297486662865, dist_loss: 0.5895560383796692
recon_loss: 0.03397083282470703, dist_loss: 0.9063532948493958
recon_loss: 0.03396882489323616, dist_loss: 0.40011078119277954
recon_loss: 0.03396686539053917, dist_loss: 0.3683597147464752
recon_loss: 0.03396479785442352, dist_loss: 0.7423357963562012
recon_loss: 0.03396284207701683, dist_loss: 0.7005189657211304
recon_loss: 0.033960986882448196, dist_loss: 0.34768563508987427
recon_loss: 0.0339592806994915, dist_loss: 0.4482835829257965
recon_loss: 0.033957500010728836, dist_loss: 0.5304783582687378
recon_loss: 0.033955566585063934, dist_loss: 0.589058518409729
recon_loss: 0.0339534766972065, dist_loss: 0.6296924352645874
recon_loss: 0.03395162895321846, dist_loss: 1.1093089580535889
recon_loss: 0.03394973650574684, dist_loss: 0.8809695839881897
recon_loss: 0.033947888761758804, dist_loss: 1.2024582624435425
recon_loss: 0.03394588828086853, dist_loss: 0.7303126454353333
recon_loss: 0.033943742513656616, dist_loss: 0.6058346629142761
recon_loss: 0.03394157066941261, dist_loss: 0.8059079051017761
recon_loss: 0.03393934294581413, dist_loss: 0.8612701892852783
recon_loss: 0.033937226980924606, dist_loss: 0.5234339237213135
recon_loss: 0.03393508866429329, dist_loss: 0.8304208517074585
recon_loss: 0.0339328832924366, dist_loss: 1.5089900493621826
recon_loss: 0.033930644392967224, dist_loss: 0.5154657363891602
recon_loss: 0.033928461372852325, dist_loss: 0.5432367324829102
recon_loss: 0.03392622992396355, dist_loss: 0.7208815217018127
recon_loss: 0.03392386436462402, dist_loss: 0.9351081848144531
recon_loss: 0.0339217372238636, dist_loss: 0.6369130611419678
recon_loss: 0.03391946852207184, dist_loss: 1.0072965621948242
recon_loss: 0.03391716629266739, dist_loss: 1.1092662811279297
recon_loss: 0.033914972096681595, dist_loss: 0.8874211311340332
recon_loss: 0.03391304984688759, dist_loss: 0.8473628759384155
recon_loss: 0.0339110866189003, dist_loss: 0.5616355538368225
recon_loss: 0.033908989280462265, dist_loss: 0.931531548500061
recon_loss: 0.03390679508447647, dist_loss: 0.9396830797195435
recon_loss: 0.033904608339071274, dist_loss: 0.44881555438041687
recon_loss: 0.033902451395988464, dist_loss: 0.661659836769104
recon_loss: 0.033900436013936996, dist_loss: 0.9485441446304321
recon_loss: 0.03389846906065941, dist_loss: 0.5195028185844421
recon_loss: 0.03389636054635048, dist_loss: 0.7526775598526001
recon_loss: 0.03389430046081543, dist_loss: 0.6207647323608398
recon_loss: 0.03389228880405426, dist_loss: 0.438775897026062
recon_loss: 0.03389028459787369, dist_loss: 0.663667619228363
recon_loss: 0.03388829529285431, dist_loss: 0.6110975742340088
recon_loss: 0.03388648107647896, dist_loss: 1.0047190189361572
recon_loss: 0.03388454392552376, dist_loss: 1.027461290359497
recon_loss: 0.03388218209147453, dist_loss: 0.833763837814331
recon_loss: 0.03387968987226486, dist_loss: 0.6973292231559753
recon_loss: 0.03387735038995743, dist_loss: 0.6554397344589233
recon_loss: 0.033874984830617905, dist_loss: 0.6712276935577393
recon_loss: 0.03387269750237465, dist_loss: 1.0909615755081177
recon_loss: 0.03387048840522766, dist_loss: 0.7022830843925476
recon_loss: 0.033868320286273956, dist_loss: 0.6277989149093628
recon_loss: 0.03386618196964264, dist_loss: 0.33125579357147217
recon_loss: 0.03386405110359192, dist_loss: 0.865839958190918
recon_loss: 0.0338619165122509, dist_loss: 0.5571374893188477
recon_loss: 0.03385980799794197, dist_loss: 0.6645410656929016
recon_loss: 0.033857863396406174, dist_loss: 0.45494315028190613
recon_loss: 0.03385602682828903, dist_loss: 0.5299453139305115
recon_loss: 0.03385430574417114, dist_loss: 0.47509852051734924
recon_loss: 0.033852528780698776, dist_loss: 0.9792464375495911
recon_loss: 0.033850617706775665, dist_loss: 0.66285240650177
recon_loss: 0.033848609775304794, dist_loss: 1.229111909866333
recon_loss: 0.03384660929441452, dist_loss: 0.4083993434906006
recon_loss: 0.033844590187072754, dist_loss: 0.5708486437797546
recon_loss: 0.03384270519018173, dist_loss: 0.6196323037147522
recon_loss: 0.033840831369161606, dist_loss: 0.814871072769165
recon_loss: 0.03383888676762581, dist_loss: 0.8250346183776855
recon_loss: 0.0338372066617012, dist_loss: 0.6180094480514526
recon_loss: 0.03383537381887436, dist_loss: 0.49946898221969604
recon_loss: 0.03383348509669304, dist_loss: 0.9758568406105042
recon_loss: 0.033831074833869934, dist_loss: 1.1043431758880615
recon_loss: 0.033829037100076675, dist_loss: 0.7928520441055298
recon_loss: 0.03382720798254013, dist_loss: 0.8404347896575928
recon_loss: 0.03382555767893791, dist_loss: 0.6330548524856567
recon_loss: 0.03382395580410957, dist_loss: 1.0335071086883545
recon_loss: 0.033822283148765564, dist_loss: 0.6999415159225464
recon_loss: 0.033820390701293945, dist_loss: 0.5734038352966309
recon_loss: 0.03381837531924248, dist_loss: 0.49992528557777405
recon_loss: 0.03381703048944473, dist_loss: 0.7222137451171875
recon_loss: 0.033815648406744, dist_loss: 0.6499764919281006
recon_loss: 0.03381451964378357, dist_loss: 0.6849949359893799
recon_loss: 0.03381335735321045, dist_loss: 0.650885283946991
recon_loss: 0.03381194546818733, dist_loss: 1.1559184789657593
recon_loss: 0.03380988538265228, dist_loss: 0.8440884351730347
recon_loss: 0.033807557076215744, dist_loss: 0.6397199630737305
recon_loss: 0.03380490839481354, dist_loss: 0.797309160232544
recon_loss: 0.03380231931805611, dist_loss: 0.767000675201416
recon_loss: 0.03379976749420166, dist_loss: 1.3466706275939941
recon_loss: 0.03379741311073303, dist_loss: 0.6744436025619507
recon_loss: 0.03379461169242859, dist_loss: 0.6868999004364014
recon_loss: 0.03379199281334877, dist_loss: 0.9132829308509827
recon_loss: 0.03378948196768761, dist_loss: 0.45422178506851196
recon_loss: 0.033787019550800323, dist_loss: 0.6066752672195435
recon_loss: 0.03378453478217125, dist_loss: 0.47055763006210327
recon_loss: 0.03378207981586456, dist_loss: 0.45179489254951477
recon_loss: 0.033779628574848175, dist_loss: 0.6503334641456604
recon_loss: 0.03377718850970268, dist_loss: 0.7280871868133545
recon_loss: 0.033774662762880325, dist_loss: 0.5854088068008423
recon_loss: 0.0337720662355423, dist_loss: 0.6444212198257446
recon_loss: 0.0337696447968483, dist_loss: 0.32764554023742676
recon_loss: 0.03376724570989609, dist_loss: 0.9567973613739014
recon_loss: 0.0337647907435894, dist_loss: 0.49511730670928955
recon_loss: 0.03376225754618645, dist_loss: 0.7074902653694153
recon_loss: 0.0337597094476223, dist_loss: 0.4926968216896057
recon_loss: 0.033757131546735764, dist_loss: 0.47030889987945557
recon_loss: 0.033754605799913406, dist_loss: 0.615527331829071
recon_loss: 0.033752258867025375, dist_loss: 0.6455583572387695
recon_loss: 0.033749956637620926, dist_loss: 0.7845174670219421
recon_loss: 0.033747702836990356, dist_loss: 0.9457984566688538
recon_loss: 0.033745430409908295, dist_loss: 1.1664494276046753
recon_loss: 0.03374314308166504, dist_loss: 0.5736901760101318
recon_loss: 0.033740874379873276, dist_loss: 0.5623390078544617
recon_loss: 0.03373883292078972, dist_loss: 0.7565135955810547
recon_loss: 0.03373676538467407, dist_loss: 0.9151297807693481
recon_loss: 0.03373449295759201, dist_loss: 0.8387286067008972
recon_loss: 0.03373222425580025, dist_loss: 0.32563573122024536
recon_loss: 0.03372993692755699, dist_loss: 1.0948693752288818
recon_loss: 0.03372768312692642, dist_loss: 0.5219053626060486
recon_loss: 0.03372541815042496, dist_loss: 0.8741048574447632
recon_loss: 0.03372325748205185, dist_loss: 0.4750807285308838
recon_loss: 0.033721037209033966, dist_loss: 0.5420089364051819
recon_loss: 0.033718813210725784, dist_loss: 0.7154726982116699
recon_loss: 0.033716607838869095, dist_loss: 0.7928617596626282
recon_loss: 0.033714234828948975, dist_loss: 0.23243477940559387
recon_loss: 0.03371192142367363, dist_loss: 0.44975796341896057
Pre-training Epoch 23:  38%|███▊      | 139/367 [00:00<00:01, 188.99it/s]Pre-training Epoch 23:  43%|████▎     | 158/367 [00:00<00:01, 185.17it/s]Pre-training Epoch 23:  48%|████▊     | 177/367 [00:00<00:01, 182.65it/s]Pre-training Epoch 23:  53%|█████▎    | 196/367 [00:01<00:00, 175.35it/s]Pre-training Epoch 23:  58%|█████▊    | 214/367 [00:01<00:00, 172.21it/s]Pre-training Epoch 23:  63%|██████▎   | 232/367 [00:01<00:00, 170.69it/s]Pre-training Epoch 23:  69%|██████▊   | 252/367 [00:01<00:00, 177.36it/s]recon_loss: 0.033709682524204254, dist_loss: 0.8062995672225952
recon_loss: 0.033707477152347565, dist_loss: 0.6292818784713745
recon_loss: 0.033705275505781174, dist_loss: 0.46301212906837463
recon_loss: 0.03370310738682747, dist_loss: 0.5179470777511597
recon_loss: 0.03370070084929466, dist_loss: 1.0162073373794556
recon_loss: 0.0336981937289238, dist_loss: 1.2191895246505737
recon_loss: 0.033695828169584274, dist_loss: 0.8259508609771729
recon_loss: 0.03369338437914848, dist_loss: 0.6848187446594238
recon_loss: 0.03369097411632538, dist_loss: 0.4677685499191284
recon_loss: 0.03368848189711571, dist_loss: 1.0054285526275635
recon_loss: 0.0336860828101635, dist_loss: 0.7351242899894714
recon_loss: 0.03368384763598442, dist_loss: 0.9551196694374084
recon_loss: 0.033681720495224, dist_loss: 0.44741785526275635
recon_loss: 0.033679649233818054, dist_loss: 0.490666002035141
recon_loss: 0.03367762267589569, dist_loss: 0.43961817026138306
recon_loss: 0.033675674349069595, dist_loss: 0.6108465790748596
recon_loss: 0.03367359936237335, dist_loss: 0.5807156562805176
recon_loss: 0.03367142751812935, dist_loss: 0.9355511665344238
recon_loss: 0.03366921469569206, dist_loss: 0.3584350347518921
recon_loss: 0.03366711363196373, dist_loss: 1.0195341110229492
recon_loss: 0.03366503119468689, dist_loss: 1.0842242240905762
recon_loss: 0.03366302326321602, dist_loss: 1.0145643949508667
recon_loss: 0.033661138266325, dist_loss: 0.9005841016769409
recon_loss: 0.0336591899394989, dist_loss: 0.3053353428840637
recon_loss: 0.03365718573331833, dist_loss: 0.5846260786056519
recon_loss: 0.03365509212017059, dist_loss: 0.44895094633102417
recon_loss: 0.033652979880571365, dist_loss: 0.6144838929176331
recon_loss: 0.033651020377874374, dist_loss: 0.6780866384506226
recon_loss: 0.03364910930395126, dist_loss: 0.6357554197311401
recon_loss: 0.033647146075963974, dist_loss: 0.5882405638694763
recon_loss: 0.03364511579275131, dist_loss: 0.5333532094955444
recon_loss: 0.033643074333667755, dist_loss: 0.557401180267334
recon_loss: 0.033641137182712555, dist_loss: 0.7606753706932068
recon_loss: 0.03363910689949989, dist_loss: 0.6080423593521118
recon_loss: 0.03363703191280365, dist_loss: 0.6458514928817749
recon_loss: 0.033634934574365616, dist_loss: 0.6120036840438843
recon_loss: 0.033632792532444, dist_loss: 1.2906811237335205
recon_loss: 0.033630724996328354, dist_loss: 0.6638590097427368
recon_loss: 0.033628564327955246, dist_loss: 0.658311665058136
recon_loss: 0.03362636640667915, dist_loss: 0.5457355380058289
recon_loss: 0.03362402692437172, dist_loss: 0.6917895078659058
recon_loss: 0.033621713519096375, dist_loss: 0.8778563141822815
recon_loss: 0.03361930325627327, dist_loss: 0.8460491895675659
recon_loss: 0.033616941422224045, dist_loss: 0.6360721588134766
recon_loss: 0.03361460566520691, dist_loss: 0.575846791267395
recon_loss: 0.03361237421631813, dist_loss: 0.6691470146179199
recon_loss: 0.03361018747091293, dist_loss: 0.6017131805419922
recon_loss: 0.033608026802539825, dist_loss: 0.4531722366809845
recon_loss: 0.03360578417778015, dist_loss: 0.6398342847824097
recon_loss: 0.03360360488295555, dist_loss: 0.8672429919242859
recon_loss: 0.033601365983486176, dist_loss: 0.5868822336196899
recon_loss: 0.03359918296337128, dist_loss: 0.5335378646850586
recon_loss: 0.033597156405448914, dist_loss: 0.9232519865036011
recon_loss: 0.03359532356262207, dist_loss: 0.8396691083908081
recon_loss: 0.033593639731407166, dist_loss: 0.6820018887519836
recon_loss: 0.03359182924032211, dist_loss: 0.525235116481781
recon_loss: 0.033589866012334824, dist_loss: 0.702771008014679
recon_loss: 0.03358794003725052, dist_loss: 0.5933659672737122
recon_loss: 0.03358606994152069, dist_loss: 0.7557468414306641
recon_loss: 0.033584244549274445, dist_loss: 0.4126027524471283
recon_loss: 0.03358244150876999, dist_loss: 0.508644700050354
recon_loss: 0.033580608665943146, dist_loss: 0.40707629919052124
recon_loss: 0.033578772097826004, dist_loss: 0.5196821093559265
recon_loss: 0.03357689827680588, dist_loss: 0.7557728290557861
recon_loss: 0.03357502818107605, dist_loss: 0.8862266540527344
recon_loss: 0.033572956919670105, dist_loss: 0.6359965801239014
recon_loss: 0.033570803701877594, dist_loss: 0.6468023657798767
recon_loss: 0.033568594604730606, dist_loss: 0.8753432631492615
recon_loss: 0.03356636315584183, dist_loss: 0.598707914352417
recon_loss: 0.03356410935521126, dist_loss: 0.5501679182052612
recon_loss: 0.033561885356903076, dist_loss: 0.44602108001708984
recon_loss: 0.03355962783098221, dist_loss: 0.888527512550354
recon_loss: 0.03355736657977104, dist_loss: 0.6617462635040283
recon_loss: 0.033555127680301666, dist_loss: 0.5189007520675659
recon_loss: 0.0335528738796711, dist_loss: 0.8174728155136108
recon_loss: 0.033550750464200974, dist_loss: 0.323153555393219
recon_loss: 0.033548757433891296, dist_loss: 0.8702352046966553
recon_loss: 0.03354675695300102, dist_loss: 1.0130043029785156
recon_loss: 0.03354456648230553, dist_loss: 0.70290207862854
recon_loss: 0.033542435616254807, dist_loss: 0.5600652694702148
recon_loss: 0.03354036435484886, dist_loss: 0.42802542448043823
recon_loss: 0.0335383266210556, dist_loss: 0.5325857996940613
recon_loss: 0.03353629633784294, dist_loss: 0.5311615467071533
recon_loss: 0.03353441134095192, dist_loss: 0.7032290101051331
recon_loss: 0.033532604575157166, dist_loss: 0.5794010162353516
recon_loss: 0.03353065997362137, dist_loss: 0.8691648244857788
recon_loss: 0.033528681844472885, dist_loss: 0.6012930870056152
recon_loss: 0.03352666273713112, dist_loss: 0.7463514804840088
recon_loss: 0.033524688333272934, dist_loss: 0.8608678579330444
recon_loss: 0.03352265805006027, dist_loss: 0.6161912679672241
recon_loss: 0.03352053090929985, dist_loss: 0.4941434860229492
recon_loss: 0.033518437296152115, dist_loss: 0.5232601165771484
recon_loss: 0.03351637348532677, dist_loss: 0.7056334018707275
recon_loss: 0.03351427614688873, dist_loss: 0.6503807306289673
recon_loss: 0.03351223096251488, dist_loss: 0.8741782903671265
recon_loss: 0.03351029008626938, dist_loss: 0.6614790558815002
recon_loss: 0.03350837156176567, dist_loss: 0.40166041254997253
recon_loss: 0.03350643068552017, dist_loss: 0.7319915294647217
recon_loss: 0.033504635095596313, dist_loss: 0.9531930685043335
recon_loss: 0.033502887934446335, dist_loss: 0.3526545464992523
recon_loss: 0.033501166850328445, dist_loss: 0.4447609782218933
recon_loss: 0.033499352633953094, dist_loss: 0.6474353075027466
recon_loss: 0.03349747881293297, dist_loss: 0.6323757171630859
recon_loss: 0.0334954708814621, dist_loss: 0.5411441326141357
recon_loss: 0.03349342569708824, dist_loss: 0.5956747531890869
recon_loss: 0.033491529524326324, dist_loss: 0.7506539821624756
recon_loss: 0.03348958119750023, dist_loss: 0.6007447242736816
recon_loss: 0.03348741680383682, dist_loss: 0.6433073282241821
recon_loss: 0.0334852896630764, dist_loss: 1.227804183959961
recon_loss: 0.03348318487405777, dist_loss: 0.9837953448295593
recon_loss: 0.033481329679489136, dist_loss: 0.5614013075828552
recon_loss: 0.03347928076982498, dist_loss: 0.6490581035614014
recon_loss: 0.033477362245321274, dist_loss: 0.8404428958892822
recon_loss: 0.03347539156675339, dist_loss: 0.8903779983520508
recon_loss: 0.03347363695502281, dist_loss: 0.6698235273361206
recon_loss: 0.03347167372703552, dist_loss: 0.5029575228691101
recon_loss: 0.03346958011388779, dist_loss: 0.8142563104629517
recon_loss: 0.03346763551235199, dist_loss: 0.39808735251426697
recon_loss: 0.03346552327275276, dist_loss: 0.5692902207374573
recon_loss: 0.0334634892642498, dist_loss: 0.6311793923377991
recon_loss: 0.033461350947618484, dist_loss: 0.4639836549758911
recon_loss: 0.03345935419201851, dist_loss: 0.346696674823761
recon_loss: 0.03345722705125809, dist_loss: 0.5335372686386108
recon_loss: 0.0334550179541111, dist_loss: 0.7188276052474976
recon_loss: 0.033452704548835754, dist_loss: 1.0147992372512817
recon_loss: 0.03345029801130295, dist_loss: 0.6199129819869995
recon_loss: 0.033447977155447006, dist_loss: 0.7841777801513672
recon_loss: 0.03344552963972092, dist_loss: 0.9179089069366455
recon_loss: 0.0334431529045105, dist_loss: 0.7987872362136841
Pre-training Epoch 23:  74%|███████▍  | 271/367 [00:01<00:00, 179.42it/s]Pre-training Epoch 23:  79%|███████▉  | 291/367 [00:01<00:00, 184.11it/s]Pre-training Epoch 23:  85%|████████▍ | 311/367 [00:01<00:00, 187.24it/s]Pre-training Epoch 23:  90%|█████████ | 331/367 [00:01<00:00, 189.49it/s]Pre-training Epoch 23:  96%|█████████▌| 351/367 [00:01<00:00, 191.06it/s]Pre-training Epoch 23: 100%|██████████| 367/367 [00:01<00:00, 185.17it/s]
recon_loss: 0.033440787345170975, dist_loss: 0.5110971331596375
recon_loss: 0.03343843296170235, dist_loss: 0.8067830801010132
recon_loss: 0.03343614190816879, dist_loss: 0.6146038770675659
recon_loss: 0.033433858305215836, dist_loss: 0.5283665060997009
recon_loss: 0.03343161940574646, dist_loss: 0.6267238855361938
recon_loss: 0.03342922031879425, dist_loss: 0.5677905082702637
recon_loss: 0.03342684730887413, dist_loss: 0.8572065234184265
recon_loss: 0.033424582332372665, dist_loss: 0.7885884046554565
recon_loss: 0.03342241793870926, dist_loss: 0.6678122282028198
recon_loss: 0.033420246094465256, dist_loss: 0.7250221371650696
recon_loss: 0.03341810405254364, dist_loss: 0.6098765730857849
recon_loss: 0.033415887504816055, dist_loss: 0.8399131298065186
recon_loss: 0.03341372311115265, dist_loss: 0.7132976055145264
recon_loss: 0.033411506563425064, dist_loss: 0.9636200070381165
recon_loss: 0.03340898081660271, dist_loss: 0.7723519802093506
recon_loss: 0.03340636566281319, dist_loss: 0.8343457579612732
recon_loss: 0.03340397775173187, dist_loss: 0.5799348950386047
recon_loss: 0.03340171277523041, dist_loss: 1.0144014358520508
recon_loss: 0.03339964151382446, dist_loss: 0.5817434191703796
recon_loss: 0.033397626131772995, dist_loss: 0.3649696707725525
recon_loss: 0.03339555114507675, dist_loss: 0.663865327835083
recon_loss: 0.03339351341128349, dist_loss: 0.6901004314422607
recon_loss: 0.033391423523426056, dist_loss: 0.6767235398292542
recon_loss: 0.03338932991027832, dist_loss: 0.4647114872932434
recon_loss: 0.03338705375790596, dist_loss: 0.6429204940795898
recon_loss: 0.03338468447327614, dist_loss: 0.7187721729278564
recon_loss: 0.03338230028748512, dist_loss: 0.6446583867073059
recon_loss: 0.03338015452027321, dist_loss: 0.5487006902694702
recon_loss: 0.03337792307138443, dist_loss: 0.9494626522064209
recon_loss: 0.03337578475475311, dist_loss: 0.5351917147636414
recon_loss: 0.03337372466921806, dist_loss: 1.0195727348327637
recon_loss: 0.03337184712290764, dist_loss: 0.9947184324264526
recon_loss: 0.03337003290653229, dist_loss: 0.5945082306861877
recon_loss: 0.0333680734038353, dist_loss: 0.7878497838973999
recon_loss: 0.03336590901017189, dist_loss: 0.9070804715156555
recon_loss: 0.033363696187734604, dist_loss: 0.6669930219650269
recon_loss: 0.0333615280687809, dist_loss: 0.6437387466430664
recon_loss: 0.03335932642221451, dist_loss: 0.6907404065132141
recon_loss: 0.0333571583032608, dist_loss: 0.3068310022354126
recon_loss: 0.033354971557855606, dist_loss: 0.5174838900566101
recon_loss: 0.03335285186767578, dist_loss: 0.41927266120910645
recon_loss: 0.03335072100162506, dist_loss: 0.4227299690246582
recon_loss: 0.033348649740219116, dist_loss: 0.6384792327880859
recon_loss: 0.03334641084074974, dist_loss: 0.8425309658050537
recon_loss: 0.0333440937101841, dist_loss: 1.0099252462387085
recon_loss: 0.03334197402000427, dist_loss: 0.5952567458152771
recon_loss: 0.03333992511034012, dist_loss: 0.42650794982910156
recon_loss: 0.033337827771902084, dist_loss: 0.3952258229255676
recon_loss: 0.033335715532302856, dist_loss: 0.7038514018058777
recon_loss: 0.03333361819386482, dist_loss: 0.5941203832626343
recon_loss: 0.03333154693245888, dist_loss: 0.7999500632286072
recon_loss: 0.033329419791698456, dist_loss: 0.607715368270874
recon_loss: 0.03332729637622833, dist_loss: 0.6843969821929932
recon_loss: 0.033325131982564926, dist_loss: 0.7004841566085815
recon_loss: 0.03332303464412689, dist_loss: 0.7868736982345581
recon_loss: 0.03332098200917244, dist_loss: 1.2182209491729736
recon_loss: 0.033318933099508286, dist_loss: 0.6669577956199646
recon_loss: 0.03331686183810234, dist_loss: 0.4768158793449402
recon_loss: 0.03331471607089043, dist_loss: 0.5273756980895996
recon_loss: 0.03331231698393822, dist_loss: 0.7200292348861694
recon_loss: 0.03330991789698601, dist_loss: 0.9187220931053162
recon_loss: 0.03330754488706589, dist_loss: 0.9518064260482788
recon_loss: 0.0333050861954689, dist_loss: 1.0500595569610596
recon_loss: 0.03330276161432266, dist_loss: 0.7977616190910339
recon_loss: 0.033300504088401794, dist_loss: 0.510492205619812
recon_loss: 0.033298153430223465, dist_loss: 0.5218746066093445
recon_loss: 0.03329581767320633, dist_loss: 0.7205984592437744
recon_loss: 0.033293746411800385, dist_loss: 0.7562512159347534
recon_loss: 0.033292006701231, dist_loss: 0.4675494134426117
recon_loss: 0.033290207386016846, dist_loss: 0.5915854573249817
recon_loss: 0.03328828141093254, dist_loss: 1.0602539777755737
recon_loss: 0.033286675810813904, dist_loss: 0.694062352180481
recon_loss: 0.033285073935985565, dist_loss: 0.7914317846298218
recon_loss: 0.033283475786447525, dist_loss: 0.6741333603858948
recon_loss: 0.033282168209552765, dist_loss: 0.4339214563369751
recon_loss: 0.03328032046556473, dist_loss: 0.6078053116798401
recon_loss: 0.033278532326221466, dist_loss: 0.9310605525970459
recon_loss: 0.033276624977588654, dist_loss: 0.5776098966598511
recon_loss: 0.033274371176958084, dist_loss: 0.7645604610443115
recon_loss: 0.03327212855219841, dist_loss: 0.7617056369781494
recon_loss: 0.03326999768614769, dist_loss: 0.2523699104785919
recon_loss: 0.033267997205257416, dist_loss: 0.6491177082061768
recon_loss: 0.03326595574617386, dist_loss: 0.8349229693412781
recon_loss: 0.03326380252838135, dist_loss: 0.6105115413665771
recon_loss: 0.033261582255363464, dist_loss: 0.4198351800441742
recon_loss: 0.03325947746634483, dist_loss: 0.43700534105300903
recon_loss: 0.0332576259970665, dist_loss: 0.8745853900909424
recon_loss: 0.033255685120821, dist_loss: 0.5891414880752563
recon_loss: 0.03325361758470535, dist_loss: 0.7743707895278931
recon_loss: 0.03325140103697777, dist_loss: 0.592165470123291
recon_loss: 0.03324928507208824, dist_loss: 0.34075087308883667
recon_loss: 0.0332471989095211, dist_loss: 0.5230647921562195
recon_loss: 0.03324510529637337, dist_loss: 0.513532280921936
recon_loss: 0.03324315696954727, dist_loss: 0.7973594665527344
recon_loss: 0.03324126824736595, dist_loss: 0.7000960111618042
recon_loss: 0.03323933854699135, dist_loss: 0.33119356632232666
recon_loss: 0.033237479627132416, dist_loss: 0.8081196546554565
recon_loss: 0.03323550522327423, dist_loss: 0.7847102880477905
recon_loss: 0.033233482390642166, dist_loss: 0.5442206263542175
recon_loss: 0.03323148190975189, dist_loss: 0.6724230051040649
recon_loss: 0.03322961553931236, dist_loss: 0.6538115739822388
recon_loss: 0.03322798013687134, dist_loss: 0.5305487513542175
recon_loss: 0.033226221799850464, dist_loss: 0.8840497732162476
recon_loss: 0.033224139362573624, dist_loss: 0.6041518449783325
recon_loss: 0.03322163596749306, dist_loss: 0.3675779104232788
recon_loss: 0.03321921452879906, dist_loss: 0.7548240423202515
recon_loss: 0.03321673721075058, dist_loss: 1.0721544027328491
recon_loss: 0.03321445733308792, dist_loss: 0.6594854593276978
recon_loss: 0.03321217745542526, dist_loss: 0.7068012356758118
Pre-training Epoch 24:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 24:   5%|▌         | 19/367 [00:00<00:01, 184.50it/s]Pre-training Epoch 24:  11%|█         | 39/367 [00:00<00:01, 189.95it/s]Pre-training Epoch 24:  16%|█▌        | 59/367 [00:00<00:01, 192.29it/s]Pre-training Epoch 24:  22%|██▏       | 79/367 [00:00<00:01, 193.07it/s]Pre-training Epoch 24:  27%|██▋       | 99/367 [00:00<00:01, 183.81it/s]Pre-training Epoch 24:  32%|███▏      | 118/367 [00:00<00:01, 183.11it/s]recon_loss: 0.03320993483066559, dist_loss: 0.9067614674568176
recon_loss: 0.03320770338177681, dist_loss: 0.4627234935760498
recon_loss: 0.03320546820759773, dist_loss: 0.7390214204788208
recon_loss: 0.03320346400141716, dist_loss: 0.4373146891593933
recon_loss: 0.033201370388269424, dist_loss: 0.6704986095428467
recon_loss: 0.033198948949575424, dist_loss: 0.32620668411254883
recon_loss: 0.033196646720170975, dist_loss: 0.5543309450149536
recon_loss: 0.03319442644715309, dist_loss: 1.3183212280273438
recon_loss: 0.03319237381219864, dist_loss: 0.8231184482574463
recon_loss: 0.033190399408340454, dist_loss: 0.4645693898200989
recon_loss: 0.03318851441144943, dist_loss: 0.4368956387042999
recon_loss: 0.03318678215146065, dist_loss: 0.6534695625305176
recon_loss: 0.03318493068218231, dist_loss: 1.0143232345581055
recon_loss: 0.03318334370851517, dist_loss: 0.6717005968093872
recon_loss: 0.033181771636009216, dist_loss: 0.567817211151123
recon_loss: 0.033180058002471924, dist_loss: 0.7457377910614014
recon_loss: 0.033178191632032394, dist_loss: 0.7060799598693848
recon_loss: 0.03317609429359436, dist_loss: 0.8623736500740051
recon_loss: 0.03317388892173767, dist_loss: 0.8933560848236084
recon_loss: 0.03317165747284889, dist_loss: 0.559753954410553
recon_loss: 0.033169109374284744, dist_loss: 1.0047389268875122
recon_loss: 0.033166639506816864, dist_loss: 0.5669155120849609
recon_loss: 0.03316431865096092, dist_loss: 0.6674289107322693
recon_loss: 0.033162180334329605, dist_loss: 0.72509765625
recon_loss: 0.033159736543893814, dist_loss: 0.30669060349464417
recon_loss: 0.0331573523581028, dist_loss: 0.6904337406158447
recon_loss: 0.033155158162117004, dist_loss: 0.6702611446380615
recon_loss: 0.03315306827425957, dist_loss: 0.8517796993255615
recon_loss: 0.0331510454416275, dist_loss: 0.6525344252586365
recon_loss: 0.03314898535609245, dist_loss: 0.6433212757110596
recon_loss: 0.03314701467752457, dist_loss: 0.3055955469608307
recon_loss: 0.033145006746053696, dist_loss: 0.5573825240135193
recon_loss: 0.03314301371574402, dist_loss: 0.5892899036407471
recon_loss: 0.03314068540930748, dist_loss: 0.3767949938774109
recon_loss: 0.033138226717710495, dist_loss: 0.7701627016067505
recon_loss: 0.03313571959733963, dist_loss: 0.872480034828186
recon_loss: 0.03313327580690384, dist_loss: 0.48060163855552673
recon_loss: 0.03313078358769417, dist_loss: 0.7243599891662598
recon_loss: 0.03312847018241882, dist_loss: 0.542900800704956
recon_loss: 0.03312620520591736, dist_loss: 0.7733666896820068
recon_loss: 0.03312407061457634, dist_loss: 0.9235570430755615
recon_loss: 0.0331219844520092, dist_loss: 0.5034579038619995
recon_loss: 0.03312002122402191, dist_loss: 0.33417683839797974
recon_loss: 0.033118050545454025, dist_loss: 0.7112887501716614
recon_loss: 0.03311595693230629, dist_loss: 1.4293549060821533
recon_loss: 0.03311377763748169, dist_loss: 0.32748493552207947
recon_loss: 0.033111680299043655, dist_loss: 0.9616937637329102
recon_loss: 0.03310969099402428, dist_loss: 0.7702903747558594
recon_loss: 0.03310780972242355, dist_loss: 0.8602177500724792
recon_loss: 0.03310588002204895, dist_loss: 0.3844040334224701
recon_loss: 0.033104054629802704, dist_loss: 0.6655170917510986
recon_loss: 0.0331021323800087, dist_loss: 0.6603580713272095
recon_loss: 0.033100128173828125, dist_loss: 1.1786251068115234
recon_loss: 0.03309809789061546, dist_loss: 0.653565526008606
recon_loss: 0.033096011728048325, dist_loss: 0.6462780237197876
recon_loss: 0.03309396654367447, dist_loss: 0.37821120023727417
recon_loss: 0.03309205546975136, dist_loss: 1.2830017805099487
recon_loss: 0.03309023007750511, dist_loss: 0.48887401819229126
recon_loss: 0.03308829665184021, dist_loss: 0.7848953008651733
recon_loss: 0.03308631852269173, dist_loss: 1.1098308563232422
recon_loss: 0.03308429941534996, dist_loss: 0.5241931676864624
recon_loss: 0.033082325011491776, dist_loss: 1.2913188934326172
recon_loss: 0.03308038413524628, dist_loss: 1.2268811464309692
recon_loss: 0.033078525215387344, dist_loss: 0.9984008073806763
recon_loss: 0.03307679668068886, dist_loss: 0.5943393707275391
recon_loss: 0.03307519480586052, dist_loss: 0.6698700189590454
recon_loss: 0.03307340666651726, dist_loss: 0.7390077114105225
recon_loss: 0.0330716148018837, dist_loss: 0.4750407040119171
recon_loss: 0.033069908618927, dist_loss: 0.3800255358219147
recon_loss: 0.033068228513002396, dist_loss: 0.7053160667419434
recon_loss: 0.033066555857658386, dist_loss: 0.5948305130004883
recon_loss: 0.033064860850572586, dist_loss: 0.9177206754684448
recon_loss: 0.03306320309638977, dist_loss: 0.6812957525253296
recon_loss: 0.03306150808930397, dist_loss: 0.5693333148956299
recon_loss: 0.03305980935692787, dist_loss: 0.6251953840255737
recon_loss: 0.0330582819879055, dist_loss: 0.765261173248291
recon_loss: 0.033056966960430145, dist_loss: 0.8760354518890381
recon_loss: 0.03305596485733986, dist_loss: 0.8335118293762207
recon_loss: 0.03305506706237793, dist_loss: 0.7390750646591187
recon_loss: 0.03305400162935257, dist_loss: 0.9351425170898438
recon_loss: 0.03305301070213318, dist_loss: 1.0155413150787354
recon_loss: 0.03305196017026901, dist_loss: 0.5988461375236511
recon_loss: 0.03305055946111679, dist_loss: 0.5387290716171265
recon_loss: 0.03304959833621979, dist_loss: 0.6730412244796753
recon_loss: 0.033048078417778015, dist_loss: 0.4895402789115906
recon_loss: 0.033046312630176544, dist_loss: 0.552397608757019
recon_loss: 0.033044323325157166, dist_loss: 0.7633650302886963
recon_loss: 0.03304240480065346, dist_loss: 0.727289080619812
recon_loss: 0.033039819449186325, dist_loss: 0.5827730298042297
recon_loss: 0.03303717449307442, dist_loss: 0.6167405843734741
recon_loss: 0.03303452581167221, dist_loss: 0.795470118522644
recon_loss: 0.03303220868110657, dist_loss: 0.6586722135543823
recon_loss: 0.03303001821041107, dist_loss: 0.538825511932373
recon_loss: 0.03302795812487602, dist_loss: 1.1554598808288574
recon_loss: 0.033026088029146194, dist_loss: 0.8192074298858643
recon_loss: 0.033023979514837265, dist_loss: 0.5042243003845215
recon_loss: 0.033021844923496246, dist_loss: 1.118666648864746
recon_loss: 0.033019471913576126, dist_loss: 0.7340918779373169
recon_loss: 0.03301701322197914, dist_loss: 0.8471776247024536
recon_loss: 0.03301438316702843, dist_loss: 0.7461166977882385
recon_loss: 0.033011894673109055, dist_loss: 0.6342267990112305
recon_loss: 0.03300948813557625, dist_loss: 0.9966212511062622
recon_loss: 0.03300733119249344, dist_loss: 1.0392725467681885
recon_loss: 0.033005502074956894, dist_loss: 0.6077392101287842
recon_loss: 0.03300393745303154, dist_loss: 0.3906098008155823
recon_loss: 0.033002354204654694, dist_loss: 0.5565409660339355
recon_loss: 0.03300090134143829, dist_loss: 1.001134991645813
recon_loss: 0.03299917280673981, dist_loss: 0.7398210167884827
recon_loss: 0.03299727290868759, dist_loss: 0.9440517425537109
recon_loss: 0.032994966953992844, dist_loss: 0.7429672479629517
recon_loss: 0.03299272432923317, dist_loss: 0.8746063113212585
recon_loss: 0.03299045190215111, dist_loss: 0.49477124214172363
recon_loss: 0.032987985759973526, dist_loss: 0.8404461741447449
recon_loss: 0.032985687255859375, dist_loss: 0.8254668712615967
recon_loss: 0.03298325091600418, dist_loss: 0.6972163319587708
recon_loss: 0.03298092260956764, dist_loss: 0.4855378270149231
recon_loss: 0.03297867253422737, dist_loss: 0.6080948710441589
recon_loss: 0.03297648951411247, dist_loss: 0.8357285261154175
recon_loss: 0.032974664121866226, dist_loss: 0.8602892756462097
recon_loss: 0.03297271579504013, dist_loss: 0.9763619303703308
recon_loss: 0.032970868051052094, dist_loss: 0.339594304561615
recon_loss: 0.03296908736228943, dist_loss: 0.7036142349243164
recon_loss: 0.03296709060668945, dist_loss: 0.6871616244316101
recon_loss: 0.032964982092380524, dist_loss: 0.7889739274978638
recon_loss: 0.03296288475394249, dist_loss: 0.8780221939086914
recon_loss: 0.032960884273052216, dist_loss: 0.4338586926460266
recon_loss: 0.03295904025435448, dist_loss: 0.737123429775238
recon_loss: 0.03295712545514107, dist_loss: 0.43216317892074585
recon_loss: 0.03295545652508736, dist_loss: 0.765847384929657
Pre-training Epoch 24:  37%|███▋      | 137/367 [00:00<00:01, 180.86it/s]Pre-training Epoch 24:  43%|████▎     | 156/367 [00:00<00:01, 178.46it/s]Pre-training Epoch 24:  47%|████▋     | 174/367 [00:00<00:01, 178.52it/s]Pre-training Epoch 24:  52%|█████▏    | 192/367 [00:01<00:00, 178.20it/s]Pre-training Epoch 24:  57%|█████▋    | 210/367 [00:01<00:00, 178.53it/s]Pre-training Epoch 24:  62%|██████▏   | 228/367 [00:01<00:00, 178.73it/s]Pre-training Epoch 24:  67%|██████▋   | 246/367 [00:01<00:00, 177.90it/s]recon_loss: 0.032953739166259766, dist_loss: 0.37783491611480713
recon_loss: 0.03295201435685158, dist_loss: 0.5060663819313049
recon_loss: 0.03295052796602249, dist_loss: 0.54844731092453
recon_loss: 0.03294920548796654, dist_loss: 0.4888593852519989
recon_loss: 0.032947931438684464, dist_loss: 0.5705727934837341
recon_loss: 0.032946597784757614, dist_loss: 0.7197824120521545
recon_loss: 0.03294520825147629, dist_loss: 0.6013359427452087
recon_loss: 0.03294374793767929, dist_loss: 0.518558919429779
recon_loss: 0.03294188156723976, dist_loss: 0.5112687349319458
recon_loss: 0.03293979540467262, dist_loss: 0.8760812282562256
recon_loss: 0.032937679439783096, dist_loss: 1.4293303489685059
recon_loss: 0.032935816794633865, dist_loss: 0.9395102858543396
recon_loss: 0.032934144139289856, dist_loss: 0.724452793598175
recon_loss: 0.03293247148394585, dist_loss: 0.33131515979766846
recon_loss: 0.03293103724718094, dist_loss: 0.8735088109970093
recon_loss: 0.03292907401919365, dist_loss: 1.167276382446289
recon_loss: 0.032927148044109344, dist_loss: 0.5058403611183167
recon_loss: 0.03292512521147728, dist_loss: 0.29465943574905396
recon_loss: 0.03292297571897507, dist_loss: 0.6885839104652405
recon_loss: 0.03292063623666763, dist_loss: 0.5706644058227539
recon_loss: 0.03291820362210274, dist_loss: 0.7437763214111328
recon_loss: 0.03291585296392441, dist_loss: 0.7477549314498901
recon_loss: 0.03291374072432518, dist_loss: 0.6654702425003052
recon_loss: 0.03291192650794983, dist_loss: 0.5438637137413025
recon_loss: 0.03291011229157448, dist_loss: 0.3772314786911011
recon_loss: 0.03290807455778122, dist_loss: 0.4234667122364044
recon_loss: 0.032905884087085724, dist_loss: 0.7544043064117432
recon_loss: 0.03290366381406784, dist_loss: 0.36665546894073486
recon_loss: 0.03290176764130592, dist_loss: 0.9683268070220947
recon_loss: 0.032900113612413406, dist_loss: 0.7297210693359375
recon_loss: 0.032898660749197006, dist_loss: 0.8717009425163269
recon_loss: 0.03289720416069031, dist_loss: 0.5504134297370911
recon_loss: 0.03289586678147316, dist_loss: 0.6035443544387817
recon_loss: 0.03289421647787094, dist_loss: 0.7453634142875671
recon_loss: 0.032892435789108276, dist_loss: 0.769210934638977
recon_loss: 0.03289085999131203, dist_loss: 0.3798341751098633
recon_loss: 0.03288945183157921, dist_loss: 1.0363049507141113
recon_loss: 0.03288740664720535, dist_loss: 1.2705583572387695
recon_loss: 0.03288532420992851, dist_loss: 0.7600654363632202
recon_loss: 0.03288343921303749, dist_loss: 0.5448554754257202
recon_loss: 0.03288156911730766, dist_loss: 0.32638800144195557
recon_loss: 0.032879553735256195, dist_loss: 0.7387781143188477
recon_loss: 0.03287772089242935, dist_loss: 0.40870875120162964
recon_loss: 0.0328756608068943, dist_loss: 0.8266595602035522
recon_loss: 0.032873548567295074, dist_loss: 0.7847886085510254
recon_loss: 0.032871514558792114, dist_loss: 0.8274118304252625
recon_loss: 0.03286963328719139, dist_loss: 0.8846573233604431
recon_loss: 0.03286779299378395, dist_loss: 0.6373040080070496
recon_loss: 0.03286588937044144, dist_loss: 0.6500512361526489
recon_loss: 0.032864104956388474, dist_loss: 0.6851111650466919
recon_loss: 0.0328623503446579, dist_loss: 0.5317758321762085
recon_loss: 0.032860565930604935, dist_loss: 0.4705756902694702
recon_loss: 0.032858747988939285, dist_loss: 0.4588715732097626
recon_loss: 0.03285689651966095, dist_loss: 1.5129725933074951
recon_loss: 0.03285503387451172, dist_loss: 0.5456757545471191
recon_loss: 0.03285310044884682, dist_loss: 0.9242372512817383
recon_loss: 0.03285118192434311, dist_loss: 0.5832010507583618
recon_loss: 0.03284924849867821, dist_loss: 0.9223806858062744
recon_loss: 0.03284752368927002, dist_loss: 0.5150411128997803
recon_loss: 0.032845769077539444, dist_loss: 0.8331758975982666
recon_loss: 0.03284404054284096, dist_loss: 0.5231794714927673
recon_loss: 0.03284226730465889, dist_loss: 0.629463791847229
recon_loss: 0.03284049406647682, dist_loss: 1.4165233373641968
recon_loss: 0.032838862389326096, dist_loss: 0.6701779961585999
recon_loss: 0.032837122678756714, dist_loss: 0.3339892029762268
recon_loss: 0.03283552825450897, dist_loss: 0.9987030029296875
recon_loss: 0.03283411264419556, dist_loss: 1.02323317527771
recon_loss: 0.03283271566033363, dist_loss: 0.6110184192657471
recon_loss: 0.032831013202667236, dist_loss: 0.6523824334144592
recon_loss: 0.03282938525080681, dist_loss: 0.6888483762741089
recon_loss: 0.03282782435417175, dist_loss: 0.9470879435539246
recon_loss: 0.032825764268636703, dist_loss: 0.6816303133964539
recon_loss: 0.032823264598846436, dist_loss: 0.5329793095588684
recon_loss: 0.03282101824879646, dist_loss: 0.6479884386062622
recon_loss: 0.03281889855861664, dist_loss: 0.5089738368988037
recon_loss: 0.032816700637340546, dist_loss: 0.5375431776046753
recon_loss: 0.03281466290354729, dist_loss: 0.5118238925933838
recon_loss: 0.032812751829624176, dist_loss: 0.5299988985061646
recon_loss: 0.0328107513487339, dist_loss: 0.8307268619537354
recon_loss: 0.03280874341726303, dist_loss: 0.6009054183959961
recon_loss: 0.03280648961663246, dist_loss: 0.560671329498291
recon_loss: 0.032804153859615326, dist_loss: 0.8023337125778198
recon_loss: 0.03280188888311386, dist_loss: 0.455841600894928
recon_loss: 0.03279978781938553, dist_loss: 0.605255126953125
recon_loss: 0.03279772028326988, dist_loss: 0.3536028265953064
recon_loss: 0.03279554471373558, dist_loss: 0.49147629737854004
recon_loss: 0.03279335796833038, dist_loss: 0.6503565907478333
recon_loss: 0.03279117867350578, dist_loss: 1.1700834035873413
recon_loss: 0.03278900682926178, dist_loss: 0.3874709904193878
recon_loss: 0.03278693929314613, dist_loss: 0.546536386013031
recon_loss: 0.032784827053546906, dist_loss: 0.8267327547073364
recon_loss: 0.03278282657265663, dist_loss: 0.7787258625030518
recon_loss: 0.032780639827251434, dist_loss: 0.5944425463676453
recon_loss: 0.032778460532426834, dist_loss: 1.1234347820281982
recon_loss: 0.03277602046728134, dist_loss: 0.548855721950531
recon_loss: 0.032773759216070175, dist_loss: 0.8051356077194214
recon_loss: 0.03277144581079483, dist_loss: 0.46921154856681824
recon_loss: 0.03276931494474411, dist_loss: 1.1057500839233398
recon_loss: 0.03276735916733742, dist_loss: 0.5569510459899902
recon_loss: 0.0327654704451561, dist_loss: 0.5589789152145386
recon_loss: 0.032763462513685226, dist_loss: 0.5496864914894104
recon_loss: 0.03276153281331062, dist_loss: 0.8134949207305908
recon_loss: 0.03275955095887184, dist_loss: 0.5340592861175537
recon_loss: 0.03275756537914276, dist_loss: 0.757210373878479
recon_loss: 0.032755713909864426, dist_loss: 0.7542444467544556
recon_loss: 0.03275385871529579, dist_loss: 0.5207165479660034
recon_loss: 0.032752152532339096, dist_loss: 0.448513001203537
recon_loss: 0.03275052830576897, dist_loss: 0.5199423432350159
recon_loss: 0.03274890035390854, dist_loss: 0.37677448987960815
recon_loss: 0.0327470488846302, dist_loss: 0.5287993550300598
recon_loss: 0.032745249569416046, dist_loss: 0.7856818437576294
recon_loss: 0.0327436663210392, dist_loss: 0.4047623872756958
recon_loss: 0.03274231404066086, dist_loss: 0.48993247747421265
recon_loss: 0.032740864902734756, dist_loss: 0.31512323021888733
recon_loss: 0.03273942321538925, dist_loss: 0.7467129230499268
recon_loss: 0.032738085836172104, dist_loss: 0.3853512108325958
recon_loss: 0.03273673355579376, dist_loss: 0.6626976728439331
recon_loss: 0.032735422253608704, dist_loss: 0.6584120988845825
recon_loss: 0.032734137028455734, dist_loss: 0.7285342216491699
recon_loss: 0.032732173800468445, dist_loss: 0.6136149168014526
recon_loss: 0.032730620354413986, dist_loss: 1.412178874015808
recon_loss: 0.032729435712099075, dist_loss: 0.604107677936554
recon_loss: 0.03272855654358864, dist_loss: 0.6498615741729736
recon_loss: 0.032727137207984924, dist_loss: 0.8581568002700806
recon_loss: 0.032725755125284195, dist_loss: 0.46368443965911865
recon_loss: 0.03272434324026108, dist_loss: 0.7546690702438354
recon_loss: 0.03272300586104393, dist_loss: 0.687984824180603
recon_loss: 0.03272141143679619, dist_loss: 0.6338891386985779
recon_loss: 0.0327199250459671, dist_loss: 0.44729524850845337
Pre-training Epoch 24:  72%|███████▏  | 264/367 [00:01<00:00, 175.60it/s]Pre-training Epoch 24:  77%|███████▋  | 282/367 [00:01<00:00, 174.43it/s]Pre-training Epoch 24:  82%|████████▏ | 301/367 [00:01<00:00, 176.13it/s]Pre-training Epoch 24:  87%|████████▋ | 319/367 [00:01<00:00, 176.82it/s]Pre-training Epoch 24:  92%|█████████▏| 337/367 [00:01<00:00, 174.83it/s]Pre-training Epoch 24:  97%|█████████▋| 355/367 [00:01<00:00, 173.96it/s]Pre-training Epoch 24: 100%|██████████| 367/367 [00:02<00:00, 178.08it/s]
recon_loss: 0.03271805867552757, dist_loss: 0.5410577058792114
recon_loss: 0.0327158123254776, dist_loss: 0.4571380019187927
recon_loss: 0.03271356597542763, dist_loss: 0.5968294143676758
recon_loss: 0.03271118924021721, dist_loss: 1.0003201961517334
recon_loss: 0.032708775252103806, dist_loss: 0.7006102204322815
recon_loss: 0.03270648792386055, dist_loss: 0.4025096595287323
recon_loss: 0.03270408883690834, dist_loss: 0.9836409687995911
recon_loss: 0.03270168974995613, dist_loss: 0.3279597759246826
recon_loss: 0.0326993465423584, dist_loss: 0.626162052154541
recon_loss: 0.03269701078534126, dist_loss: 0.5686308145523071
recon_loss: 0.032694701105356216, dist_loss: 0.5434215664863586
recon_loss: 0.032692331820726395, dist_loss: 0.5664200186729431
recon_loss: 0.03268995136022568, dist_loss: 1.0872257947921753
recon_loss: 0.032687559723854065, dist_loss: 0.46135765314102173
recon_loss: 0.03268527612090111, dist_loss: 0.9217667579650879
recon_loss: 0.03268297761678696, dist_loss: 0.5043805837631226
recon_loss: 0.0326806977391243, dist_loss: 1.1788357496261597
recon_loss: 0.03267841413617134, dist_loss: 0.8278543949127197
recon_loss: 0.03267623484134674, dist_loss: 0.5258967876434326
recon_loss: 0.032674092799425125, dist_loss: 0.8390660285949707
recon_loss: 0.0326719768345356, dist_loss: 0.7504224181175232
recon_loss: 0.032670099288225174, dist_loss: 0.5124197006225586
recon_loss: 0.032668329775333405, dist_loss: 0.34536436200141907
recon_loss: 0.032666560262441635, dist_loss: 0.8212942481040955
recon_loss: 0.032664861530065536, dist_loss: 1.1365853548049927
recon_loss: 0.03266311064362526, dist_loss: 0.6383944153785706
recon_loss: 0.03266137093305588, dist_loss: 0.8401490449905396
recon_loss: 0.032659538090229034, dist_loss: 0.6065699458122253
recon_loss: 0.03265754505991936, dist_loss: 0.6192100048065186
recon_loss: 0.03265562653541565, dist_loss: 0.5319433212280273
recon_loss: 0.03265361115336418, dist_loss: 0.7142340540885925
recon_loss: 0.03265140950679779, dist_loss: 0.9101876020431519
recon_loss: 0.03264910355210304, dist_loss: 0.5766716003417969
recon_loss: 0.03264716640114784, dist_loss: 0.3835606575012207
recon_loss: 0.032645147293806076, dist_loss: 0.783706784248352
recon_loss: 0.03264319524168968, dist_loss: 0.4970443546772003
recon_loss: 0.03264125436544418, dist_loss: 1.0224854946136475
recon_loss: 0.032639261335134506, dist_loss: 1.0641250610351562
recon_loss: 0.03263740986585617, dist_loss: 0.9305671453475952
recon_loss: 0.032635774463415146, dist_loss: 0.8353654146194458
recon_loss: 0.03263429179787636, dist_loss: 0.8135818243026733
recon_loss: 0.032632794231176376, dist_loss: 0.40027540922164917
recon_loss: 0.03263122960925102, dist_loss: 1.051242470741272
recon_loss: 0.0326295830309391, dist_loss: 0.3375163972377777
recon_loss: 0.03262794390320778, dist_loss: 0.7005404233932495
recon_loss: 0.03262634202837944, dist_loss: 1.0946582555770874
recon_loss: 0.032624613493680954, dist_loss: 0.47790640592575073
recon_loss: 0.03262285515666008, dist_loss: 0.5105912685394287
recon_loss: 0.03262097015976906, dist_loss: 0.5157723426818848
recon_loss: 0.03261922299861908, dist_loss: 0.6318255662918091
recon_loss: 0.03261764720082283, dist_loss: 0.4395824670791626
recon_loss: 0.03261591121554375, dist_loss: 0.5077041387557983
recon_loss: 0.03261410444974899, dist_loss: 0.4756909906864166
recon_loss: 0.032612454146146774, dist_loss: 0.6590989232063293
recon_loss: 0.03261088952422142, dist_loss: 0.9609427452087402
recon_loss: 0.03260890394449234, dist_loss: 0.4558468461036682
recon_loss: 0.03260685130953789, dist_loss: 0.6640655994415283
recon_loss: 0.03260480985045433, dist_loss: 0.38631606101989746
recon_loss: 0.03260284289717674, dist_loss: 0.4799672067165375
recon_loss: 0.0326010063290596, dist_loss: 0.7787450551986694
recon_loss: 0.03259925916790962, dist_loss: 1.3507251739501953
recon_loss: 0.032597865909338, dist_loss: 0.533559262752533
recon_loss: 0.03259669616818428, dist_loss: 1.0656366348266602
recon_loss: 0.03259536996483803, dist_loss: 0.6002293229103088
recon_loss: 0.03259405866265297, dist_loss: 0.4917623996734619
recon_loss: 0.03259256109595299, dist_loss: 0.5705260634422302
recon_loss: 0.03259103745222092, dist_loss: 0.4229770600795746
recon_loss: 0.032589271664619446, dist_loss: 0.43226170539855957
recon_loss: 0.03258713334798813, dist_loss: 1.1746253967285156
recon_loss: 0.032584939152002335, dist_loss: 0.8173511028289795
recon_loss: 0.03258302062749863, dist_loss: 0.84540855884552
recon_loss: 0.032581184059381485, dist_loss: 0.5914087295532227
recon_loss: 0.03257941082119942, dist_loss: 1.1508691310882568
recon_loss: 0.03257761895656586, dist_loss: 0.8024694323539734
recon_loss: 0.032575950026512146, dist_loss: 1.0524015426635742
recon_loss: 0.032574187964200974, dist_loss: 1.0033767223358154
recon_loss: 0.032572388648986816, dist_loss: 1.2706319093704224
recon_loss: 0.03257057070732117, dist_loss: 0.6150030493736267
recon_loss: 0.03256841376423836, dist_loss: 0.6618636846542358
recon_loss: 0.03256608918309212, dist_loss: 0.35785791277885437
recon_loss: 0.03256392851471901, dist_loss: 0.8773678541183472
recon_loss: 0.032561883330345154, dist_loss: 0.7382411956787109
recon_loss: 0.03255990147590637, dist_loss: 0.4749656915664673
recon_loss: 0.03255801275372505, dist_loss: 0.6350581645965576
recon_loss: 0.032556161284446716, dist_loss: 0.785515308380127
recon_loss: 0.032554250210523605, dist_loss: 0.5292513966560364
recon_loss: 0.03255206719040871, dist_loss: 0.454054594039917
recon_loss: 0.03255010396242142, dist_loss: 0.6246224045753479
recon_loss: 0.03254835307598114, dist_loss: 0.6939607858657837
recon_loss: 0.03254662826657295, dist_loss: 0.5021435618400574
recon_loss: 0.03254476562142372, dist_loss: 0.40226027369499207
recon_loss: 0.03254299238324165, dist_loss: 0.61867356300354
recon_loss: 0.03254155069589615, dist_loss: 0.7120943069458008
recon_loss: 0.03254067897796631, dist_loss: 0.5747805237770081
recon_loss: 0.032539788633584976, dist_loss: 0.7363319396972656
recon_loss: 0.032538872212171555, dist_loss: 0.5404617190361023
recon_loss: 0.03253769502043724, dist_loss: 0.8039002418518066
recon_loss: 0.03253573924303055, dist_loss: 0.7348755598068237
recon_loss: 0.03253401070833206, dist_loss: 0.7156960964202881
recon_loss: 0.03253237530589104, dist_loss: 0.7555859088897705
recon_loss: 0.0325302891433239, dist_loss: 0.4176568388938904
recon_loss: 0.03252836689352989, dist_loss: 0.47325554490089417
recon_loss: 0.032526109367609024, dist_loss: 0.3479180932044983
recon_loss: 0.03252367675304413, dist_loss: 0.6939839124679565
recon_loss: 0.032521359622478485, dist_loss: 0.8696978092193604
recon_loss: 0.03251933306455612, dist_loss: 0.9222837090492249
recon_loss: 0.032517436891794205, dist_loss: 0.5268670320510864
recon_loss: 0.0325155034661293, dist_loss: 0.5295377373695374
recon_loss: 0.032513637095689774, dist_loss: 0.7474713325500488
Pre-training Epoch 25:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 25:   4%|▍         | 15/367 [00:00<00:02, 144.77it/s]Pre-training Epoch 25:   8%|▊         | 31/367 [00:00<00:02, 151.42it/s]Pre-training Epoch 25:  13%|█▎        | 47/367 [00:00<00:02, 151.99it/s]Pre-training Epoch 25:  17%|█▋        | 63/367 [00:00<00:01, 152.43it/s]Pre-training Epoch 25:  22%|██▏       | 79/367 [00:00<00:01, 153.01it/s]Pre-training Epoch 25:  26%|██▌       | 95/367 [00:00<00:01, 152.02it/s]Pre-training Epoch 25:  30%|███       | 111/367 [00:00<00:01, 149.94it/s]Pre-training Epoch 25:  35%|███▍      | 127/367 [00:00<00:01, 149.89it/s]recon_loss: 0.03251175954937935, dist_loss: 0.6369697451591492
recon_loss: 0.032509807497262955, dist_loss: 0.8122344017028809
recon_loss: 0.032507870346307755, dist_loss: 0.6310039758682251
recon_loss: 0.032505977898836136, dist_loss: 0.9945887327194214
recon_loss: 0.032504063099622726, dist_loss: 0.5199004411697388
recon_loss: 0.03250208497047424, dist_loss: 0.4840238392353058
recon_loss: 0.03250010684132576, dist_loss: 0.5532257556915283
recon_loss: 0.03249802440404892, dist_loss: 0.6209201216697693
recon_loss: 0.03249586746096611, dist_loss: 0.5149022340774536
recon_loss: 0.032493822276592255, dist_loss: 0.47957348823547363
recon_loss: 0.032491933554410934, dist_loss: 0.3581877648830414
recon_loss: 0.032490119338035583, dist_loss: 0.8627617359161377
recon_loss: 0.032488174736499786, dist_loss: 0.5666017532348633
recon_loss: 0.03248625248670578, dist_loss: 0.8846558928489685
recon_loss: 0.03248449042439461, dist_loss: 0.5865068435668945
recon_loss: 0.03248284384608269, dist_loss: 0.5410560369491577
recon_loss: 0.032480984926223755, dist_loss: 0.7371654510498047
recon_loss: 0.03247898072004318, dist_loss: 0.5698360800743103
recon_loss: 0.032477062195539474, dist_loss: 0.42962902784347534
recon_loss: 0.032475318759679794, dist_loss: 0.76203453540802
recon_loss: 0.03247370198369026, dist_loss: 0.6529321670532227
recon_loss: 0.03247224912047386, dist_loss: 0.569388210773468
recon_loss: 0.03247031942009926, dist_loss: 0.982079803943634
recon_loss: 0.032468393445014954, dist_loss: 0.5666213631629944
recon_loss: 0.032466642558574677, dist_loss: 0.5457268357276917
recon_loss: 0.03246496617794037, dist_loss: 0.5977964401245117
recon_loss: 0.03246331959962845, dist_loss: 0.6685002446174622
recon_loss: 0.032461605966091156, dist_loss: 0.9994023442268372
recon_loss: 0.03245987743139267, dist_loss: 0.758222758769989
recon_loss: 0.032458141446113586, dist_loss: 0.532081127166748
recon_loss: 0.032456524670124054, dist_loss: 0.5959934592247009
recon_loss: 0.03245504945516586, dist_loss: 0.48935049772262573
recon_loss: 0.03245356306433678, dist_loss: 0.7982443571090698
recon_loss: 0.0324520505964756, dist_loss: 0.4057905375957489
recon_loss: 0.03245048224925995, dist_loss: 0.4028092622756958
recon_loss: 0.032448817044496536, dist_loss: 0.7371624112129211
recon_loss: 0.032447151839733124, dist_loss: 0.8153904676437378
recon_loss: 0.03244555741548538, dist_loss: 0.7905582189559937
recon_loss: 0.03244379907846451, dist_loss: 0.8767399787902832
recon_loss: 0.032441966235637665, dist_loss: 0.6749413013458252
recon_loss: 0.032440196722745895, dist_loss: 0.5952368974685669
recon_loss: 0.03243844211101532, dist_loss: 1.0287134647369385
recon_loss: 0.0324367992579937, dist_loss: 1.1252280473709106
recon_loss: 0.032435093075037, dist_loss: 0.5323736667633057
recon_loss: 0.03243345767259598, dist_loss: 0.5682349801063538
recon_loss: 0.03243178874254227, dist_loss: 0.33239686489105225
recon_loss: 0.03243013843894005, dist_loss: 0.3871538043022156
recon_loss: 0.03242838755249977, dist_loss: 0.6709415316581726
recon_loss: 0.03242682293057442, dist_loss: 0.6553764343261719
recon_loss: 0.03242510184645653, dist_loss: 0.8810940384864807
recon_loss: 0.03242364153265953, dist_loss: 0.8126795291900635
recon_loss: 0.032421987503767014, dist_loss: 0.46037256717681885
recon_loss: 0.03242024406790733, dist_loss: 0.5550135970115662
recon_loss: 0.03241826966404915, dist_loss: 0.8821661472320557
recon_loss: 0.032416392117738724, dist_loss: 0.3898189067840576
recon_loss: 0.03241457790136337, dist_loss: 0.7171307802200317
recon_loss: 0.032412756234407425, dist_loss: 0.9617326259613037
recon_loss: 0.03241109475493431, dist_loss: 1.0827813148498535
recon_loss: 0.03240935504436493, dist_loss: 0.9506058692932129
recon_loss: 0.032407503575086594, dist_loss: 0.7934134006500244
recon_loss: 0.03240542113780975, dist_loss: 0.7877056002616882
recon_loss: 0.03240342065691948, dist_loss: 0.4113451838493347
recon_loss: 0.032401375472545624, dist_loss: 0.7696988582611084
recon_loss: 0.03239941969513893, dist_loss: 0.795952320098877
recon_loss: 0.03239763528108597, dist_loss: 0.9136620759963989
recon_loss: 0.03239606320858002, dist_loss: 0.8439423441886902
recon_loss: 0.03239430859684944, dist_loss: 0.44006800651550293
recon_loss: 0.03239228576421738, dist_loss: 0.8018559217453003
recon_loss: 0.03239024057984352, dist_loss: 0.45291030406951904
recon_loss: 0.03238826245069504, dist_loss: 0.800800621509552
recon_loss: 0.03238638862967491, dist_loss: 0.440439909696579
recon_loss: 0.03238442540168762, dist_loss: 0.41293004155158997
recon_loss: 0.03238244727253914, dist_loss: 0.7760300636291504
recon_loss: 0.03238051384687424, dist_loss: 0.8346236348152161
recon_loss: 0.03237869217991829, dist_loss: 0.6024959087371826
recon_loss: 0.032377030700445175, dist_loss: 0.6617864370346069
recon_loss: 0.03237530589103699, dist_loss: 0.5376735329627991
recon_loss: 0.03237355127930641, dist_loss: 0.40843063592910767
recon_loss: 0.0323718823492527, dist_loss: 0.5864521861076355
recon_loss: 0.03237006068229675, dist_loss: 0.4639136493206024
recon_loss: 0.03236826881766319, dist_loss: 0.45812588930130005
recon_loss: 0.03236648067831993, dist_loss: 0.526945173740387
recon_loss: 0.03236457332968712, dist_loss: 0.8833097815513611
recon_loss: 0.032362598925828934, dist_loss: 0.5164294242858887
recon_loss: 0.0323607474565506, dist_loss: 0.7657599449157715
recon_loss: 0.032359108328819275, dist_loss: 0.7943456172943115
recon_loss: 0.0323575884103775, dist_loss: 0.997563898563385
recon_loss: 0.03235583007335663, dist_loss: 0.47687312960624695
recon_loss: 0.03235405683517456, dist_loss: 0.6313518285751343
recon_loss: 0.03235240280628204, dist_loss: 0.3948117196559906
recon_loss: 0.03235074132680893, dist_loss: 0.7082955837249756
recon_loss: 0.03234903886914253, dist_loss: 0.3897021412849426
recon_loss: 0.032347340136766434, dist_loss: 0.38715803623199463
recon_loss: 0.032345615327358246, dist_loss: 1.1238176822662354
recon_loss: 0.03234399855136871, dist_loss: 0.7011348605155945
recon_loss: 0.032342515885829926, dist_loss: 0.8973923921585083
recon_loss: 0.032341115176677704, dist_loss: 1.0941818952560425
recon_loss: 0.0323396772146225, dist_loss: 0.4784296751022339
recon_loss: 0.032338082790374756, dist_loss: 1.2512885332107544
recon_loss: 0.03233649581670761, dist_loss: 0.6290345788002014
recon_loss: 0.03233502805233002, dist_loss: 0.9776242971420288
recon_loss: 0.03233364224433899, dist_loss: 0.3090510070323944
recon_loss: 0.032332275062799454, dist_loss: 0.9561814069747925
recon_loss: 0.032330818474292755, dist_loss: 0.3070622682571411
recon_loss: 0.03232923150062561, dist_loss: 0.7253757119178772
recon_loss: 0.03232768923044205, dist_loss: 0.43961212038993835
recon_loss: 0.03232625126838684, dist_loss: 0.951670229434967
recon_loss: 0.032324809581041336, dist_loss: 0.4928748607635498
recon_loss: 0.03232349455356598, dist_loss: 1.0481963157653809
recon_loss: 0.03232206031680107, dist_loss: 0.6870871186256409
recon_loss: 0.032320573925971985, dist_loss: 0.7955127954483032
recon_loss: 0.03231902793049812, dist_loss: 0.4169435203075409
recon_loss: 0.03231748566031456, dist_loss: 0.6575403213500977
recon_loss: 0.032316215336322784, dist_loss: 0.589496910572052
recon_loss: 0.032314833253622055, dist_loss: 0.33970722556114197
recon_loss: 0.03231317177414894, dist_loss: 0.545629620552063
recon_loss: 0.03231155127286911, dist_loss: 0.7220972776412964
recon_loss: 0.032310184091329575, dist_loss: 0.3687559962272644
recon_loss: 0.03230896592140198, dist_loss: 0.8566555976867676
recon_loss: 0.032307643443346024, dist_loss: 0.8536336421966553
recon_loss: 0.03230571746826172, dist_loss: 0.593848466873169
recon_loss: 0.0323035828769207, dist_loss: 0.6844092607498169
recon_loss: 0.03230166807770729, dist_loss: 0.4075145125389099
recon_loss: 0.03230004385113716, dist_loss: 0.36289429664611816
recon_loss: 0.03229852765798569, dist_loss: 0.7710599899291992
recon_loss: 0.03229687735438347, dist_loss: 0.4959218502044678
recon_loss: 0.03229505568742752, dist_loss: 0.6510612964630127
recon_loss: 0.03229324147105217, dist_loss: 0.4678976535797119
recon_loss: 0.0322914682328701, dist_loss: 0.8321040868759155
Pre-training Epoch 25:  39%|███▉      | 143/367 [00:00<00:01, 150.53it/s]Pre-training Epoch 25:  43%|████▎     | 159/367 [00:01<00:01, 150.18it/s]Pre-training Epoch 25:  48%|████▊     | 175/367 [00:01<00:01, 151.77it/s]Pre-training Epoch 25:  52%|█████▏    | 191/367 [00:01<00:01, 152.10it/s]Pre-training Epoch 25:  56%|█████▋    | 207/367 [00:01<00:01, 152.10it/s]Pre-training Epoch 25:  61%|██████    | 223/367 [00:01<00:00, 151.67it/s]Pre-training Epoch 25:  65%|██████▌   | 239/367 [00:01<00:00, 151.12it/s]Pre-training Epoch 25:  69%|██████▉   | 255/367 [00:01<00:00, 150.90it/s]recon_loss: 0.03228963539004326, dist_loss: 1.0240168571472168
recon_loss: 0.03228778764605522, dist_loss: 0.6583523154258728
recon_loss: 0.03228595107793808, dist_loss: 0.835304856300354
recon_loss: 0.032284047454595566, dist_loss: 0.7458151578903198
recon_loss: 0.03228219971060753, dist_loss: 1.1086418628692627
recon_loss: 0.03228062391281128, dist_loss: 0.699851930141449
recon_loss: 0.03227921202778816, dist_loss: 1.1598761081695557
recon_loss: 0.03227774798870087, dist_loss: 0.8115665912628174
recon_loss: 0.03227652609348297, dist_loss: 0.6629153490066528
recon_loss: 0.032275114208459854, dist_loss: 0.5840184688568115
recon_loss: 0.03227386251091957, dist_loss: 0.8846209049224854
recon_loss: 0.03227267414331436, dist_loss: 0.6620262861251831
recon_loss: 0.03227163478732109, dist_loss: 0.8454712629318237
recon_loss: 0.03227031230926514, dist_loss: 0.7212429046630859
recon_loss: 0.03226858004927635, dist_loss: 0.5976358652114868
recon_loss: 0.03226689249277115, dist_loss: 0.8545739650726318
recon_loss: 0.03226526454091072, dist_loss: 0.7169410586357117
recon_loss: 0.032263752073049545, dist_loss: 0.9082961082458496
recon_loss: 0.03226184472441673, dist_loss: 0.3284349739551544
recon_loss: 0.032260145992040634, dist_loss: 0.9673693180084229
recon_loss: 0.03225838020443916, dist_loss: 0.6886756420135498
recon_loss: 0.03225649520754814, dist_loss: 0.8059166669845581
recon_loss: 0.03225468844175339, dist_loss: 0.965673565864563
recon_loss: 0.032253116369247437, dist_loss: 0.7681134343147278
recon_loss: 0.03225186839699745, dist_loss: 0.6529762744903564
recon_loss: 0.03225036337971687, dist_loss: 0.5704443454742432
recon_loss: 0.03224853798747063, dist_loss: 0.5215238332748413
recon_loss: 0.0322464182972908, dist_loss: 0.7046490907669067
recon_loss: 0.0322447270154953, dist_loss: 0.7358788251876831
recon_loss: 0.03224319964647293, dist_loss: 0.5158385634422302
recon_loss: 0.03224159777164459, dist_loss: 0.801594078540802
recon_loss: 0.032239850610494614, dist_loss: 0.9291139841079712
recon_loss: 0.03223801404237747, dist_loss: 1.3368009328842163
recon_loss: 0.03223607316613197, dist_loss: 0.7893552184104919
recon_loss: 0.032234374433755875, dist_loss: 0.7855293154716492
recon_loss: 0.03223307058215141, dist_loss: 0.7942039966583252
recon_loss: 0.03223196789622307, dist_loss: 0.5667704343795776
recon_loss: 0.032230839133262634, dist_loss: 0.5692440867424011
recon_loss: 0.03222951665520668, dist_loss: 0.376833975315094
recon_loss: 0.032227806746959686, dist_loss: 0.727890133857727
recon_loss: 0.03222624585032463, dist_loss: 0.5251362323760986
recon_loss: 0.03222433477640152, dist_loss: 0.4047534465789795
recon_loss: 0.032222505658864975, dist_loss: 0.7776056528091431
recon_loss: 0.032220542430877686, dist_loss: 0.8855389356613159
recon_loss: 0.03221874311566353, dist_loss: 0.4591083526611328
recon_loss: 0.032217226922512054, dist_loss: 0.7458611726760864
recon_loss: 0.03221600502729416, dist_loss: 0.6445481777191162
recon_loss: 0.032215241342782974, dist_loss: 0.8008301258087158
recon_loss: 0.0322144515812397, dist_loss: 0.7380162477493286
recon_loss: 0.03221389278769493, dist_loss: 0.9271224737167358
recon_loss: 0.03221302479505539, dist_loss: 0.8453221917152405
recon_loss: 0.03221158683300018, dist_loss: 0.47582030296325684
recon_loss: 0.03220966458320618, dist_loss: 1.023424506187439
recon_loss: 0.03220764175057411, dist_loss: 0.5760969519615173
recon_loss: 0.0322052426636219, dist_loss: 0.8600211143493652
recon_loss: 0.03220270201563835, dist_loss: 0.3972392976284027
recon_loss: 0.03220048546791077, dist_loss: 0.48327359557151794
recon_loss: 0.0321984738111496, dist_loss: 0.7429561614990234
recon_loss: 0.03219678997993469, dist_loss: 0.6663272380828857
recon_loss: 0.032194819301366806, dist_loss: 0.5620990991592407
recon_loss: 0.032193105667829514, dist_loss: 0.7320201396942139
recon_loss: 0.03219189867377281, dist_loss: 0.813307523727417
recon_loss: 0.032190870493650436, dist_loss: 0.7944995164871216
recon_loss: 0.03219006210565567, dist_loss: 0.6838971376419067
recon_loss: 0.03218907490372658, dist_loss: 0.7086878418922424
recon_loss: 0.03218778967857361, dist_loss: 1.0936840772628784
recon_loss: 0.03218633681535721, dist_loss: 1.0754268169403076
recon_loss: 0.03218487650156021, dist_loss: 0.8000473976135254
recon_loss: 0.03218322992324829, dist_loss: 0.8088168501853943
recon_loss: 0.032181136310100555, dist_loss: 0.6904627084732056
recon_loss: 0.0321790836751461, dist_loss: 1.1125290393829346
recon_loss: 0.03217679634690285, dist_loss: 0.8249302506446838
recon_loss: 0.032174382358789444, dist_loss: 0.4680444598197937
recon_loss: 0.032172203063964844, dist_loss: 0.8378158807754517
recon_loss: 0.03217052295804024, dist_loss: 0.37959402799606323
recon_loss: 0.03216895833611488, dist_loss: 0.5707011818885803
recon_loss: 0.03216731175780296, dist_loss: 0.9515320062637329
recon_loss: 0.032165929675102234, dist_loss: 0.958723783493042
recon_loss: 0.03216482698917389, dist_loss: 0.6683837175369263
recon_loss: 0.03216371685266495, dist_loss: 0.5204004049301147
recon_loss: 0.03216267004609108, dist_loss: 0.7513362169265747
recon_loss: 0.03216170892119408, dist_loss: 0.7960560321807861
recon_loss: 0.03216041624546051, dist_loss: 0.5162264108657837
recon_loss: 0.032159093767404556, dist_loss: 1.0386592149734497
recon_loss: 0.03215792402625084, dist_loss: 0.8142699599266052
recon_loss: 0.03215659782290459, dist_loss: 1.2593315839767456
recon_loss: 0.03215489909052849, dist_loss: 0.986250638961792
recon_loss: 0.03215295821428299, dist_loss: 0.8219593167304993
recon_loss: 0.03215055912733078, dist_loss: 0.39253681898117065
recon_loss: 0.03214803338050842, dist_loss: 0.7184641361236572
recon_loss: 0.03214547783136368, dist_loss: 0.8381762504577637
recon_loss: 0.032143108546733856, dist_loss: 0.7525579929351807
recon_loss: 0.032141342759132385, dist_loss: 1.0538420677185059
recon_loss: 0.03213983029127121, dist_loss: 0.45950886607170105
recon_loss: 0.03213845565915108, dist_loss: 0.3926258683204651
recon_loss: 0.03213667497038841, dist_loss: 0.7580693364143372
recon_loss: 0.032134760171175, dist_loss: 0.7085995674133301
recon_loss: 0.03213312104344368, dist_loss: 1.209820032119751
recon_loss: 0.03213152289390564, dist_loss: 0.5181883573532104
recon_loss: 0.032129984349012375, dist_loss: 0.5631727576255798
recon_loss: 0.03212837129831314, dist_loss: 0.30725380778312683
recon_loss: 0.03212672844529152, dist_loss: 0.48963019251823425
recon_loss: 0.0321250818669796, dist_loss: 0.6508240699768066
recon_loss: 0.032123494893312454, dist_loss: 0.6194775700569153
recon_loss: 0.03212214633822441, dist_loss: 0.6416950225830078
recon_loss: 0.032120730727910995, dist_loss: 0.7103578448295593
recon_loss: 0.03211919218301773, dist_loss: 0.7548375129699707
recon_loss: 0.03211737424135208, dist_loss: 0.8085372447967529
recon_loss: 0.032115936279296875, dist_loss: 0.8536540865898132
recon_loss: 0.0321144163608551, dist_loss: 0.454992413520813
recon_loss: 0.03211285546422005, dist_loss: 0.6373204588890076
recon_loss: 0.03211129829287529, dist_loss: 0.40020301938056946
recon_loss: 0.03210970014333725, dist_loss: 0.8867204189300537
recon_loss: 0.032108042389154434, dist_loss: 0.7883163690567017
recon_loss: 0.03210608288645744, dist_loss: 0.6223873496055603
recon_loss: 0.0321042574942112, dist_loss: 0.5301908850669861
recon_loss: 0.03210250288248062, dist_loss: 0.8582046627998352
recon_loss: 0.03210066258907318, dist_loss: 0.7501187324523926
recon_loss: 0.03209903463721275, dist_loss: 0.8139922618865967
recon_loss: 0.032097574323415756, dist_loss: 0.9118854999542236
recon_loss: 0.03209640458226204, dist_loss: 0.9657484889030457
recon_loss: 0.03209543228149414, dist_loss: 0.6147134900093079
recon_loss: 0.03209464251995087, dist_loss: 0.4649597108364105
recon_loss: 0.03209361806511879, dist_loss: 0.8508780598640442
recon_loss: 0.032092176377773285, dist_loss: 0.46443673968315125
recon_loss: 0.03209061920642853, dist_loss: 0.5863552093505859
recon_loss: 0.032089121639728546, dist_loss: 0.5988948345184326
recon_loss: 0.03208751603960991, dist_loss: 0.5661334991455078
recon_loss: 0.03208570182323456, dist_loss: 0.9434484243392944
Pre-training Epoch 25:  74%|███████▍  | 271/367 [00:01<00:00, 149.59it/s]Pre-training Epoch 25:  78%|███████▊  | 286/367 [00:01<00:00, 149.64it/s]Pre-training Epoch 25:  82%|████████▏ | 302/367 [00:02<00:00, 150.29it/s]Pre-training Epoch 25:  87%|████████▋ | 318/367 [00:02<00:00, 148.87it/s]Pre-training Epoch 25:  91%|█████████ | 334/367 [00:02<00:00, 149.99it/s]Pre-training Epoch 25:  95%|█████████▌| 350/367 [00:02<00:00, 151.11it/s]Pre-training Epoch 25: 100%|█████████▉| 366/367 [00:02<00:00, 153.26it/s]Pre-training Epoch 25: 100%|██████████| 367/367 [00:02<00:00, 151.11it/s]
recon_loss: 0.032083433121442795, dist_loss: 0.6956394910812378
recon_loss: 0.03208087012171745, dist_loss: 0.6262319087982178
recon_loss: 0.032078757882118225, dist_loss: 0.31159377098083496
recon_loss: 0.032076992094516754, dist_loss: 0.7912465929985046
recon_loss: 0.03207552805542946, dist_loss: 0.6783962249755859
recon_loss: 0.03207434341311455, dist_loss: 0.821087121963501
recon_loss: 0.03207312151789665, dist_loss: 0.777236819267273
recon_loss: 0.032071810215711594, dist_loss: 1.1602402925491333
recon_loss: 0.032070450484752655, dist_loss: 0.614565372467041
recon_loss: 0.032068945467472076, dist_loss: 0.6392917633056641
recon_loss: 0.03206720948219299, dist_loss: 0.7147661447525024
recon_loss: 0.03206542506814003, dist_loss: 0.43891316652297974
recon_loss: 0.03206371143460274, dist_loss: 0.3640269637107849
recon_loss: 0.03206183761358261, dist_loss: 0.46640217304229736
recon_loss: 0.032060131430625916, dist_loss: 1.3663411140441895
recon_loss: 0.032058537006378174, dist_loss: 0.3513110876083374
recon_loss: 0.032056983560323715, dist_loss: 0.5530676245689392
recon_loss: 0.03205551207065582, dist_loss: 0.42428386211395264
recon_loss: 0.032054103910923004, dist_loss: 0.6086126565933228
recon_loss: 0.03205301612615585, dist_loss: 0.7835118174552917
recon_loss: 0.03205231577157974, dist_loss: 0.446808397769928
recon_loss: 0.032051198184490204, dist_loss: 0.9815353155136108
recon_loss: 0.032049816101789474, dist_loss: 0.564354419708252
recon_loss: 0.03204865753650665, dist_loss: 0.47342878580093384
recon_loss: 0.03204736486077309, dist_loss: 0.4263581931591034
recon_loss: 0.032046157866716385, dist_loss: 1.1682555675506592
recon_loss: 0.032044894993305206, dist_loss: 0.7787840366363525
recon_loss: 0.032043419778347015, dist_loss: 0.7348036766052246
recon_loss: 0.03204188123345375, dist_loss: 0.5182449817657471
recon_loss: 0.032040368765592575, dist_loss: 0.4470508396625519
recon_loss: 0.03203868493437767, dist_loss: 0.3844876289367676
recon_loss: 0.03203706443309784, dist_loss: 0.933512270450592
recon_loss: 0.032035551965236664, dist_loss: 0.7543148398399353
recon_loss: 0.032034147530794144, dist_loss: 0.6222496032714844
recon_loss: 0.03203289955854416, dist_loss: 0.6492953300476074
recon_loss: 0.03203149512410164, dist_loss: 0.5343117117881775
recon_loss: 0.03203006088733673, dist_loss: 0.8132005929946899
recon_loss: 0.03202858939766884, dist_loss: 0.5845441818237305
recon_loss: 0.03202718868851662, dist_loss: 0.4759296476840973
recon_loss: 0.03202584385871887, dist_loss: 0.6674603819847107
recon_loss: 0.032024480402469635, dist_loss: 0.537635087966919
recon_loss: 0.03202301636338234, dist_loss: 0.3286305367946625
recon_loss: 0.032021600753068924, dist_loss: 0.6198413968086243
recon_loss: 0.032020337879657745, dist_loss: 0.7701218128204346
recon_loss: 0.03201906383037567, dist_loss: 0.563984751701355
recon_loss: 0.03201793134212494, dist_loss: 0.5036337375640869
recon_loss: 0.032016728073358536, dist_loss: 1.0342521667480469
recon_loss: 0.03201523795723915, dist_loss: 0.8944539427757263
recon_loss: 0.032013677060604095, dist_loss: 0.8497495651245117
recon_loss: 0.032011840492486954, dist_loss: 0.429179847240448
recon_loss: 0.03201043978333473, dist_loss: 0.7331113815307617
recon_loss: 0.032009199261665344, dist_loss: 0.7475857734680176
recon_loss: 0.032007887959480286, dist_loss: 0.36086025834083557
recon_loss: 0.03200644999742508, dist_loss: 0.7182689905166626
recon_loss: 0.03200500085949898, dist_loss: 0.38815510272979736
recon_loss: 0.03200370445847511, dist_loss: 0.5119199752807617
recon_loss: 0.0320025309920311, dist_loss: 0.9405859708786011
recon_loss: 0.032001201063394547, dist_loss: 0.9099926948547363
recon_loss: 0.03199973329901695, dist_loss: 0.31654617190361023
recon_loss: 0.0319983996450901, dist_loss: 0.5777871012687683
recon_loss: 0.03199715539813042, dist_loss: 0.5738588571548462
recon_loss: 0.03199584037065506, dist_loss: 0.791689932346344
recon_loss: 0.031994618475437164, dist_loss: 0.9632140398025513
recon_loss: 0.03199327737092972, dist_loss: 0.41794127225875854
recon_loss: 0.03199191018939018, dist_loss: 0.3906867504119873
recon_loss: 0.03199038654565811, dist_loss: 1.3135132789611816
recon_loss: 0.03198916092514992, dist_loss: 0.7926527261734009
recon_loss: 0.0319882370531559, dist_loss: 1.073718547821045
recon_loss: 0.0319877453148365, dist_loss: 0.45831727981567383
recon_loss: 0.031987279653549194, dist_loss: 0.40502405166625977
recon_loss: 0.03198667988181114, dist_loss: 0.539584219455719
recon_loss: 0.031985461711883545, dist_loss: 0.8377232551574707
recon_loss: 0.03198421001434326, dist_loss: 0.8278518915176392
recon_loss: 0.03198230266571045, dist_loss: 0.450133740901947
recon_loss: 0.031980570405721664, dist_loss: 0.7785801887512207
recon_loss: 0.0319787971675396, dist_loss: 1.3571146726608276
recon_loss: 0.03197712451219559, dist_loss: 1.0440642833709717
recon_loss: 0.03197557479143143, dist_loss: 0.843756914138794
recon_loss: 0.031974174082279205, dist_loss: 0.7957034111022949
recon_loss: 0.031972676515579224, dist_loss: 0.8705783486366272
recon_loss: 0.03197122737765312, dist_loss: 0.5662828087806702
recon_loss: 0.03196980431675911, dist_loss: 0.48876675963401794
recon_loss: 0.03196835145354271, dist_loss: 0.5737898945808411
recon_loss: 0.03196709230542183, dist_loss: 0.6257544755935669
recon_loss: 0.03196597844362259, dist_loss: 0.9861750602722168
recon_loss: 0.03196479380130768, dist_loss: 0.9589112997055054
recon_loss: 0.03196345269680023, dist_loss: 0.5240494608879089
recon_loss: 0.03196240961551666, dist_loss: 0.7640109062194824
recon_loss: 0.03196194767951965, dist_loss: 0.9698033332824707
recon_loss: 0.03196132183074951, dist_loss: 0.533484697341919
recon_loss: 0.03196032717823982, dist_loss: 0.47231626510620117
recon_loss: 0.03195924684405327, dist_loss: 0.6288227438926697
recon_loss: 0.03195779398083687, dist_loss: 0.4114951193332672
recon_loss: 0.03195608779788017, dist_loss: 0.9576159715652466
recon_loss: 0.03195423632860184, dist_loss: 0.477755606174469
recon_loss: 0.031952448189258575, dist_loss: 0.9143099188804626
recon_loss: 0.0319511853158474, dist_loss: 0.5953511595726013
recon_loss: 0.03195010498166084, dist_loss: 0.8459640741348267
recon_loss: 0.03194918856024742, dist_loss: 0.4313890337944031
recon_loss: 0.03194810450077057, dist_loss: 0.7223485112190247
recon_loss: 0.03194689005613327, dist_loss: 0.2932846248149872
recon_loss: 0.03194552659988403, dist_loss: 0.5022697448730469
recon_loss: 0.031944241374731064, dist_loss: 0.7475167512893677
recon_loss: 0.03194311261177063, dist_loss: 0.6643663644790649
recon_loss: 0.03194178640842438, dist_loss: 0.5154709815979004
recon_loss: 0.031940214335918427, dist_loss: 0.6179460287094116
recon_loss: 0.03193842992186546, dist_loss: 0.3467101752758026
recon_loss: 0.03193676844239235, dist_loss: 0.6329204440116882
recon_loss: 0.03193572536110878, dist_loss: 0.383939653635025
Pre-training Epoch 26:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 26:   5%|▍         | 17/367 [00:00<00:02, 164.06it/s]Pre-training Epoch 26:  10%|▉         | 36/367 [00:00<00:01, 173.91it/s]Pre-training Epoch 26:  15%|█▍        | 54/367 [00:00<00:01, 173.65it/s]Pre-training Epoch 26:  20%|█▉        | 72/367 [00:00<00:01, 164.12it/s]Pre-training Epoch 26:  24%|██▍       | 89/367 [00:00<00:01, 159.77it/s]Pre-training Epoch 26:  29%|██▉       | 106/367 [00:00<00:01, 157.01it/s]Pre-training Epoch 26:  33%|███▎      | 122/367 [00:00<00:01, 153.87it/s]recon_loss: 0.03193487226963043, dist_loss: 0.5160679817199707
recon_loss: 0.03193342313170433, dist_loss: 0.8267025947570801
recon_loss: 0.03193168714642525, dist_loss: 0.9659497737884521
recon_loss: 0.031930454075336456, dist_loss: 0.4752350151538849
recon_loss: 0.03192943334579468, dist_loss: 0.35571497678756714
recon_loss: 0.03192837908864021, dist_loss: 0.5142269730567932
recon_loss: 0.03192656859755516, dist_loss: 0.8343874216079712
recon_loss: 0.03192448243498802, dist_loss: 0.4278392791748047
recon_loss: 0.03192254900932312, dist_loss: 1.0444116592407227
recon_loss: 0.031921058893203735, dist_loss: 0.5075606107711792
recon_loss: 0.031919997185468674, dist_loss: 1.058316707611084
recon_loss: 0.03191860020160675, dist_loss: 0.9948418140411377
recon_loss: 0.031916793435811996, dist_loss: 0.7685863375663757
recon_loss: 0.03191512078046799, dist_loss: 1.2096079587936401
recon_loss: 0.03191392496228218, dist_loss: 0.5532183647155762
recon_loss: 0.031912971287965775, dist_loss: 0.6836682558059692
recon_loss: 0.03191182017326355, dist_loss: 0.5105932354927063
recon_loss: 0.031910307705402374, dist_loss: 0.49019211530685425
recon_loss: 0.03190857544541359, dist_loss: 0.37021052837371826
recon_loss: 0.03190714493393898, dist_loss: 0.48690563440322876
recon_loss: 0.03190583735704422, dist_loss: 0.7415067553520203
recon_loss: 0.03190446272492409, dist_loss: 0.7561194896697998
recon_loss: 0.031902946531772614, dist_loss: 0.4747963547706604
recon_loss: 0.03190142661333084, dist_loss: 0.3408820331096649
recon_loss: 0.031899962574243546, dist_loss: 0.784873366355896
recon_loss: 0.031898632645606995, dist_loss: 0.4143636226654053
recon_loss: 0.0318974107503891, dist_loss: 0.7850035429000854
recon_loss: 0.031896088272333145, dist_loss: 0.6750208735466003
recon_loss: 0.03189468011260033, dist_loss: 1.1061396598815918
recon_loss: 0.03189336881041527, dist_loss: 0.8919517993927002
recon_loss: 0.03189218416810036, dist_loss: 0.7834447622299194
recon_loss: 0.03189121186733246, dist_loss: 0.8097407221794128
recon_loss: 0.03189028799533844, dist_loss: 0.7230693697929382
recon_loss: 0.03188922256231308, dist_loss: 0.588242769241333
recon_loss: 0.03188806399703026, dist_loss: 0.6488099694252014
recon_loss: 0.031886812299489975, dist_loss: 0.5443703532218933
recon_loss: 0.03188571333885193, dist_loss: 0.37968266010284424
recon_loss: 0.03188449889421463, dist_loss: 0.721537172794342
recon_loss: 0.031883347779512405, dist_loss: 1.306971788406372
recon_loss: 0.031881872564554214, dist_loss: 0.6964462399482727
recon_loss: 0.031880296766757965, dist_loss: 0.9059889316558838
recon_loss: 0.031878840178251266, dist_loss: 0.5301615595817566
recon_loss: 0.031877364963293076, dist_loss: 0.4648650288581848
recon_loss: 0.03187583386898041, dist_loss: 0.69548100233078
recon_loss: 0.031874168664216995, dist_loss: 0.8744816780090332
recon_loss: 0.031872790306806564, dist_loss: 0.5318031311035156
recon_loss: 0.03187193349003792, dist_loss: 0.9702033996582031
recon_loss: 0.03187146410346031, dist_loss: 0.8210344314575195
recon_loss: 0.03187069669365883, dist_loss: 0.46254032850265503
recon_loss: 0.03186960890889168, dist_loss: 0.2724045515060425
recon_loss: 0.03186877444386482, dist_loss: 0.4807268977165222
recon_loss: 0.03186802938580513, dist_loss: 0.7545620799064636
recon_loss: 0.03186685964465141, dist_loss: 0.3176065683364868
recon_loss: 0.031865425407886505, dist_loss: 0.8590059280395508
recon_loss: 0.03186413645744324, dist_loss: 0.5635461211204529
recon_loss: 0.03186260163784027, dist_loss: 0.6861804723739624
recon_loss: 0.031861260533332825, dist_loss: 0.5491335391998291
recon_loss: 0.0318598747253418, dist_loss: 0.7149204611778259
recon_loss: 0.031858690083026886, dist_loss: 0.6795834302902222
recon_loss: 0.031857118010520935, dist_loss: 0.7603424787521362
recon_loss: 0.031855832785367966, dist_loss: 1.0293629169464111
recon_loss: 0.03185461461544037, dist_loss: 0.3843420445919037
recon_loss: 0.03185337781906128, dist_loss: 0.4871591031551361
recon_loss: 0.03185216337442398, dist_loss: 0.5664467811584473
recon_loss: 0.03185097500681877, dist_loss: 0.553945779800415
recon_loss: 0.03184978663921356, dist_loss: 0.6889497637748718
recon_loss: 0.031848471611738205, dist_loss: 0.9316398501396179
recon_loss: 0.03184695169329643, dist_loss: 1.0252352952957153
recon_loss: 0.031845398247241974, dist_loss: 0.7939254641532898
recon_loss: 0.03184390068054199, dist_loss: 0.32205730676651
recon_loss: 0.0318424291908741, dist_loss: 0.6032024621963501
recon_loss: 0.031841080635786057, dist_loss: 0.5086746215820312
recon_loss: 0.031839773058891296, dist_loss: 0.5542726516723633
recon_loss: 0.0318383052945137, dist_loss: 0.6022172570228577
recon_loss: 0.031837098300457, dist_loss: 0.6884816884994507
recon_loss: 0.0318361334502697, dist_loss: 0.8115244507789612
recon_loss: 0.03183517977595329, dist_loss: 0.4949986934661865
recon_loss: 0.031833913177251816, dist_loss: 0.33353111147880554
recon_loss: 0.031832531094551086, dist_loss: 0.6181730031967163
recon_loss: 0.03183097764849663, dist_loss: 0.7585223913192749
recon_loss: 0.03182956203818321, dist_loss: 0.3890114426612854
recon_loss: 0.03182833641767502, dist_loss: 0.8874232769012451
recon_loss: 0.03182729706168175, dist_loss: 0.5983797311782837
recon_loss: 0.03182637318968773, dist_loss: 0.9038345217704773
recon_loss: 0.03182538226246834, dist_loss: 0.7871454954147339
recon_loss: 0.03182433918118477, dist_loss: 0.8130351305007935
recon_loss: 0.0318232960999012, dist_loss: 0.4051401615142822
recon_loss: 0.03182210773229599, dist_loss: 0.4474891424179077
recon_loss: 0.031820837408304214, dist_loss: 0.6692664623260498
recon_loss: 0.03181951865553856, dist_loss: 0.5177147388458252
recon_loss: 0.03181808814406395, dist_loss: 0.6652061343193054
recon_loss: 0.03181661292910576, dist_loss: 0.5402034521102905
recon_loss: 0.031815141439437866, dist_loss: 0.3491845726966858
recon_loss: 0.03181374445557594, dist_loss: 0.599456250667572
recon_loss: 0.03181236609816551, dist_loss: 0.5488390326499939
recon_loss: 0.03181114047765732, dist_loss: 0.5381155014038086
recon_loss: 0.031810078769922256, dist_loss: 0.8584099411964417
recon_loss: 0.03180930018424988, dist_loss: 0.4161621928215027
recon_loss: 0.03180842474102974, dist_loss: 1.1696460247039795
recon_loss: 0.03180759400129318, dist_loss: 0.9658923149108887
recon_loss: 0.03180653601884842, dist_loss: 1.010775089263916
recon_loss: 0.03180541470646858, dist_loss: 0.8489955067634583
recon_loss: 0.03180445358157158, dist_loss: 1.0177264213562012
recon_loss: 0.03180340677499771, dist_loss: 0.5849281549453735
recon_loss: 0.031802255660295486, dist_loss: 0.9300475716590881
recon_loss: 0.03180084004998207, dist_loss: 0.4562191963195801
recon_loss: 0.03179938718676567, dist_loss: 0.4764152765274048
recon_loss: 0.031798090785741806, dist_loss: 0.5228849053382874
recon_loss: 0.03179696574807167, dist_loss: 0.6274253129959106
recon_loss: 0.03179597109556198, dist_loss: 0.798975944519043
recon_loss: 0.03179468587040901, dist_loss: 1.1590555906295776
recon_loss: 0.0317932553589344, dist_loss: 0.8566418886184692
recon_loss: 0.03179198503494263, dist_loss: 0.45292186737060547
recon_loss: 0.03179066255688667, dist_loss: 0.648552417755127
recon_loss: 0.031789250671863556, dist_loss: 0.7909542918205261
recon_loss: 0.031787991523742676, dist_loss: 0.46024906635284424
recon_loss: 0.03178681805729866, dist_loss: 0.626928448677063
recon_loss: 0.03178567811846733, dist_loss: 1.2687244415283203
recon_loss: 0.03178400546312332, dist_loss: 0.41659921407699585
recon_loss: 0.031782116740942, dist_loss: 0.5826514959335327
recon_loss: 0.03178057447075844, dist_loss: 0.9130810499191284
recon_loss: 0.0317799337208271, dist_loss: 0.5958157181739807
recon_loss: 0.03177906945347786, dist_loss: 0.6643425226211548
recon_loss: 0.031777236610651016, dist_loss: 0.6517243385314941
recon_loss: 0.03177562728524208, dist_loss: 1.0853650569915771
recon_loss: 0.0317743755877018, dist_loss: 0.7636398077011108
recon_loss: 0.031773585826158524, dist_loss: 0.8885596990585327
recon_loss: 0.03177320584654808, dist_loss: 0.7226946949958801
recon_loss: 0.03177299350500107, dist_loss: 0.7566490769386292
Pre-training Epoch 26:  38%|███▊      | 138/367 [00:00<00:01, 153.88it/s]Pre-training Epoch 26:  42%|████▏     | 154/367 [00:00<00:01, 153.61it/s]Pre-training Epoch 26:  46%|████▋     | 170/367 [00:01<00:01, 153.71it/s]Pre-training Epoch 26:  51%|█████     | 186/367 [00:01<00:01, 154.03it/s]Pre-training Epoch 26:  55%|█████▌    | 202/367 [00:01<00:01, 153.83it/s]Pre-training Epoch 26:  60%|█████▉    | 219/367 [00:01<00:00, 157.41it/s]Pre-training Epoch 26:  65%|██████▍   | 237/367 [00:01<00:00, 163.17it/s]Pre-training Epoch 26:  69%|██████▉   | 255/367 [00:01<00:00, 166.11it/s]recon_loss: 0.03177257627248764, dist_loss: 0.6539111137390137
recon_loss: 0.03177163749933243, dist_loss: 0.7925456166267395
recon_loss: 0.03177077695727348, dist_loss: 0.8386406302452087
recon_loss: 0.031770043075084686, dist_loss: 0.714577317237854
recon_loss: 0.0317692793905735, dist_loss: 0.8452717065811157
recon_loss: 0.03176826238632202, dist_loss: 0.7373311519622803
recon_loss: 0.031766872853040695, dist_loss: 0.5671997666358948
recon_loss: 0.03176502883434296, dist_loss: 0.7533594369888306
recon_loss: 0.03176356106996536, dist_loss: 0.40361660718917847
recon_loss: 0.0317622646689415, dist_loss: 0.8679998517036438
recon_loss: 0.031760938465595245, dist_loss: 0.5703777074813843
recon_loss: 0.031759604811668396, dist_loss: 0.6253995895385742
recon_loss: 0.031758420169353485, dist_loss: 0.6929718255996704
recon_loss: 0.03175758197903633, dist_loss: 0.5859546065330505
recon_loss: 0.031756691634655, dist_loss: 0.4631853401660919
recon_loss: 0.03175553306937218, dist_loss: 0.5953662395477295
recon_loss: 0.03175385668873787, dist_loss: 0.9300881624221802
recon_loss: 0.0317523293197155, dist_loss: 1.0735557079315186
recon_loss: 0.031750887632369995, dist_loss: 0.7115663886070251
recon_loss: 0.03174953535199165, dist_loss: 0.3613438606262207
recon_loss: 0.031748272478580475, dist_loss: 0.7032331228256226
recon_loss: 0.03174690157175064, dist_loss: 0.6155068278312683
recon_loss: 0.031745485961437225, dist_loss: 0.8491398096084595
recon_loss: 0.03174397349357605, dist_loss: 1.1568583250045776
recon_loss: 0.03174246847629547, dist_loss: 0.9243488311767578
recon_loss: 0.03174113482236862, dist_loss: 0.46400487422943115
recon_loss: 0.031739939004182816, dist_loss: 0.5538702011108398
recon_loss: 0.03173881024122238, dist_loss: 0.8302195072174072
recon_loss: 0.03173789009451866, dist_loss: 0.9238611459732056
recon_loss: 0.03173687309026718, dist_loss: 0.8235141634941101
recon_loss: 0.031735874712467194, dist_loss: 0.8110610842704773
recon_loss: 0.031734708696603775, dist_loss: 1.0681445598602295
recon_loss: 0.03173360973596573, dist_loss: 0.7790703773498535
recon_loss: 0.03173265606164932, dist_loss: 0.6999080777168274
recon_loss: 0.03173194080591202, dist_loss: 0.40660789608955383
recon_loss: 0.03173122927546501, dist_loss: 0.6699310541152954
recon_loss: 0.03173032030463219, dist_loss: 0.6426954865455627
recon_loss: 0.03172915428876877, dist_loss: 1.3381874561309814
recon_loss: 0.03172801062464714, dist_loss: 0.7069262266159058
recon_loss: 0.03172687068581581, dist_loss: 0.5364890694618225
recon_loss: 0.031725745648145676, dist_loss: 1.2375950813293457
recon_loss: 0.03172474354505539, dist_loss: 0.7406140565872192
recon_loss: 0.03172343969345093, dist_loss: 0.5725039839744568
recon_loss: 0.03172207251191139, dist_loss: 0.9200462698936462
recon_loss: 0.03172096610069275, dist_loss: 0.38897380232810974
recon_loss: 0.03172006085515022, dist_loss: 0.7361792325973511
recon_loss: 0.03171920031309128, dist_loss: 0.5262770056724548
recon_loss: 0.03171776607632637, dist_loss: 0.4510006904602051
recon_loss: 0.03171604871749878, dist_loss: 0.8075104355812073
recon_loss: 0.031714726239442825, dist_loss: 0.5625224709510803
recon_loss: 0.031713612377643585, dist_loss: 0.42165762186050415
recon_loss: 0.03171224892139435, dist_loss: 0.7239853143692017
recon_loss: 0.031710680574178696, dist_loss: 0.7519311904907227
recon_loss: 0.03170911595225334, dist_loss: 0.9363292455673218
recon_loss: 0.03170786425471306, dist_loss: 0.95916348695755
recon_loss: 0.03170715644955635, dist_loss: 0.663817286491394
recon_loss: 0.03170609101653099, dist_loss: 0.4603908360004425
recon_loss: 0.031704287976026535, dist_loss: 0.5192368030548096
recon_loss: 0.031702056527137756, dist_loss: 0.7293124794960022
recon_loss: 0.031700581312179565, dist_loss: 0.6441136598587036
recon_loss: 0.03169964998960495, dist_loss: 0.6546019315719604
recon_loss: 0.03169851377606392, dist_loss: 0.4267430007457733
recon_loss: 0.031696807593107224, dist_loss: 0.4890945851802826
recon_loss: 0.03169535472989082, dist_loss: 1.438936471939087
recon_loss: 0.03169446066021919, dist_loss: 0.6031419038772583
recon_loss: 0.031693704426288605, dist_loss: 0.7549681067466736
recon_loss: 0.031692296266555786, dist_loss: 1.0971605777740479
recon_loss: 0.03169054165482521, dist_loss: 0.48402267694473267
recon_loss: 0.03168998658657074, dist_loss: 0.9411373138427734
recon_loss: 0.03168942406773567, dist_loss: 1.356356143951416
recon_loss: 0.031688328832387924, dist_loss: 0.5165024399757385
recon_loss: 0.03168714791536331, dist_loss: 0.7271636724472046
recon_loss: 0.03168579190969467, dist_loss: 0.6469208002090454
recon_loss: 0.03168477490544319, dist_loss: 0.8025238513946533
recon_loss: 0.031684208661317825, dist_loss: 0.9110445380210876
recon_loss: 0.0316835418343544, dist_loss: 0.733190655708313
recon_loss: 0.031682875007390976, dist_loss: 0.39222490787506104
recon_loss: 0.03168211504817009, dist_loss: 0.7405688762664795
recon_loss: 0.03168101608753204, dist_loss: 0.7649900913238525
recon_loss: 0.03167993947863579, dist_loss: 0.679269552230835
recon_loss: 0.03167884796857834, dist_loss: 0.5453469157218933
recon_loss: 0.03167770802974701, dist_loss: 0.5751405954360962
recon_loss: 0.03167654573917389, dist_loss: 1.1943233013153076
recon_loss: 0.03167544677853584, dist_loss: 0.6895013451576233
recon_loss: 0.03167419135570526, dist_loss: 1.634064793586731
recon_loss: 0.03167275711894035, dist_loss: 1.2769336700439453
recon_loss: 0.03167128935456276, dist_loss: 0.809914767742157
recon_loss: 0.03166970983147621, dist_loss: 0.329645037651062
recon_loss: 0.03166821226477623, dist_loss: 0.47501879930496216
recon_loss: 0.03166684880852699, dist_loss: 0.49753233790397644
recon_loss: 0.03166552260518074, dist_loss: 0.542638897895813
recon_loss: 0.03166431933641434, dist_loss: 0.5587350726127625
recon_loss: 0.03166321665048599, dist_loss: 0.5257101655006409
recon_loss: 0.03166201710700989, dist_loss: 0.7085098028182983
recon_loss: 0.031660906970500946, dist_loss: 0.5118430852890015
recon_loss: 0.03165982663631439, dist_loss: 0.9368447065353394
recon_loss: 0.03165878355503082, dist_loss: 0.45337656140327454
recon_loss: 0.031657591462135315, dist_loss: 0.7614091634750366
recon_loss: 0.031656112521886826, dist_loss: 0.8630969524383545
recon_loss: 0.031654514372348785, dist_loss: 0.6899721026420593
recon_loss: 0.03165296092629433, dist_loss: 0.8353434205055237
recon_loss: 0.03165153041481972, dist_loss: 0.3602552115917206
recon_loss: 0.031650230288505554, dist_loss: 0.6883708238601685
recon_loss: 0.031649038195610046, dist_loss: 0.6037432551383972
recon_loss: 0.03164795786142349, dist_loss: 0.6373435258865356
recon_loss: 0.031646937131881714, dist_loss: 0.4465506374835968
recon_loss: 0.031645819544792175, dist_loss: 0.5616213083267212
recon_loss: 0.03164467215538025, dist_loss: 0.9170337915420532
recon_loss: 0.03164345771074295, dist_loss: 0.6820557713508606
recon_loss: 0.03164220601320267, dist_loss: 0.5151001214981079
recon_loss: 0.03164088726043701, dist_loss: 0.3571469783782959
recon_loss: 0.03163962438702583, dist_loss: 0.48876678943634033
recon_loss: 0.03163853660225868, dist_loss: 0.8124269247055054
recon_loss: 0.03163760527968407, dist_loss: 0.4360416829586029
recon_loss: 0.031636592000722885, dist_loss: 0.6450165510177612
recon_loss: 0.0316355936229229, dist_loss: 0.5532549619674683
recon_loss: 0.031634483486413956, dist_loss: 0.5387691259384155
recon_loss: 0.031633444130420685, dist_loss: 0.9374859929084778
recon_loss: 0.03163238614797592, dist_loss: 0.9993870258331299
recon_loss: 0.031631387770175934, dist_loss: 0.75162672996521
recon_loss: 0.03163042664527893, dist_loss: 0.5433838963508606
recon_loss: 0.031629566103219986, dist_loss: 0.6106114387512207
recon_loss: 0.03162883594632149, dist_loss: 0.7254079580307007
recon_loss: 0.031627532094717026, dist_loss: 1.0876723527908325
recon_loss: 0.031626082956790924, dist_loss: 0.6083954572677612
recon_loss: 0.03162461146712303, dist_loss: 0.5887025594711304
recon_loss: 0.03162332996726036, dist_loss: 0.42249923944473267
recon_loss: 0.03162219375371933, dist_loss: 0.5546137094497681
recon_loss: 0.03162116929888725, dist_loss: 1.316270351409912
Pre-training Epoch 26:  74%|███████▍  | 273/367 [00:01<00:00, 169.21it/s]Pre-training Epoch 26:  79%|███████▉  | 291/367 [00:01<00:00, 169.83it/s]Pre-training Epoch 26:  84%|████████▍ | 309/367 [00:01<00:00, 172.17it/s]Pre-training Epoch 26:  89%|████████▉ | 327/367 [00:02<00:00, 172.57it/s]Pre-training Epoch 26:  94%|█████████▍| 345/367 [00:02<00:00, 174.50it/s]Pre-training Epoch 26:  99%|█████████▉| 363/367 [00:02<00:00, 174.87it/s]Pre-training Epoch 26: 100%|██████████| 367/367 [00:02<00:00, 164.52it/s]
recon_loss: 0.03162030130624771, dist_loss: 0.658920168876648
recon_loss: 0.03161938861012459, dist_loss: 0.7456831336021423
recon_loss: 0.03161824494600296, dist_loss: 0.880826473236084
recon_loss: 0.031617049127817154, dist_loss: 0.6073561906814575
recon_loss: 0.03161582723259926, dist_loss: 0.4723711907863617
recon_loss: 0.031614769250154495, dist_loss: 0.8641963005065918
recon_loss: 0.031613677740097046, dist_loss: 0.8466718196868896
recon_loss: 0.03161211684346199, dist_loss: 0.41554364562034607
recon_loss: 0.03161022439599037, dist_loss: 0.611587643623352
recon_loss: 0.03160839527845383, dist_loss: 0.8766646981239319
recon_loss: 0.031606901437044144, dist_loss: 0.6820708513259888
recon_loss: 0.03160582855343819, dist_loss: 0.4381268620491028
recon_loss: 0.031605273485183716, dist_loss: 0.5661064982414246
recon_loss: 0.03160467743873596, dist_loss: 0.5661873817443848
recon_loss: 0.03160380944609642, dist_loss: 0.828610897064209
recon_loss: 0.0316026471555233, dist_loss: 0.5072184801101685
recon_loss: 0.031601566821336746, dist_loss: 0.8390260934829712
recon_loss: 0.031600575894117355, dist_loss: 0.4693402051925659
recon_loss: 0.031599365174770355, dist_loss: 0.7361701726913452
recon_loss: 0.03159743547439575, dist_loss: 0.6380571126937866
recon_loss: 0.03159550949931145, dist_loss: 0.43149057030677795
recon_loss: 0.031593695282936096, dist_loss: 0.8448431491851807
recon_loss: 0.03159205988049507, dist_loss: 0.7084078788757324
recon_loss: 0.031590770930051804, dist_loss: 1.0093451738357544
recon_loss: 0.03158960118889809, dist_loss: 0.7726035714149475
recon_loss: 0.03158849477767944, dist_loss: 0.8498297333717346
recon_loss: 0.03158740699291229, dist_loss: 1.1165207624435425
recon_loss: 0.031586408615112305, dist_loss: 0.4874151945114136
recon_loss: 0.03158549219369888, dist_loss: 0.55560702085495
recon_loss: 0.03158416971564293, dist_loss: 0.7620755434036255
recon_loss: 0.0315827876329422, dist_loss: 0.739051878452301
recon_loss: 0.03158147260546684, dist_loss: 0.9904639720916748
recon_loss: 0.03158062323927879, dist_loss: 0.680355429649353
recon_loss: 0.03157949820160866, dist_loss: 0.5109270215034485
recon_loss: 0.03157816454768181, dist_loss: 0.3880394697189331
recon_loss: 0.031576842069625854, dist_loss: 0.8838375806808472
recon_loss: 0.03157569095492363, dist_loss: 0.25948530435562134
recon_loss: 0.03157474845647812, dist_loss: 0.6538163423538208
recon_loss: 0.031573861837387085, dist_loss: 0.6293962001800537
recon_loss: 0.03157263249158859, dist_loss: 0.7663094401359558
recon_loss: 0.03157135099172592, dist_loss: 0.5607101321220398
recon_loss: 0.03157021850347519, dist_loss: 0.5217283964157104
recon_loss: 0.03156951814889908, dist_loss: 0.413068026304245
recon_loss: 0.031568754464387894, dist_loss: 0.5902575254440308
recon_loss: 0.031567614525556564, dist_loss: 0.701224684715271
recon_loss: 0.031566277146339417, dist_loss: 0.599857747554779
recon_loss: 0.03156489133834839, dist_loss: 0.8069679737091064
recon_loss: 0.031563740223646164, dist_loss: 0.8196268081665039
recon_loss: 0.03156270831823349, dist_loss: 0.6526210308074951
recon_loss: 0.031561702489852905, dist_loss: 0.8426478505134583
recon_loss: 0.03156071528792381, dist_loss: 0.3459811210632324
recon_loss: 0.03155968338251114, dist_loss: 0.6428035497665405
recon_loss: 0.031558696180582047, dist_loss: 0.5643738508224487
recon_loss: 0.031557757407426834, dist_loss: 0.3183498680591583
recon_loss: 0.03155679255723953, dist_loss: 0.6735045909881592
recon_loss: 0.03155582398176193, dist_loss: 0.992634654045105
recon_loss: 0.031554825603961945, dist_loss: 0.9683713912963867
recon_loss: 0.03155365213751793, dist_loss: 0.6880319118499756
recon_loss: 0.03155255690217018, dist_loss: 0.8647575378417969
recon_loss: 0.03155157342553139, dist_loss: 0.41540011763572693
recon_loss: 0.031550582498311996, dist_loss: 0.5893540382385254
recon_loss: 0.03154950216412544, dist_loss: 0.6623765230178833
recon_loss: 0.03154846280813217, dist_loss: 0.8931087851524353
recon_loss: 0.031547531485557556, dist_loss: 0.6703945398330688
recon_loss: 0.03154664486646652, dist_loss: 0.7473543286323547
recon_loss: 0.0315457247197628, dist_loss: 1.1699798107147217
recon_loss: 0.03154492378234863, dist_loss: 0.5042225122451782
recon_loss: 0.03154410794377327, dist_loss: 0.661420464515686
recon_loss: 0.03154323622584343, dist_loss: 0.49251341819763184
recon_loss: 0.03154230862855911, dist_loss: 0.5212778449058533
recon_loss: 0.03154149651527405, dist_loss: 0.2546430230140686
recon_loss: 0.03154067322611809, dist_loss: 1.1095916032791138
recon_loss: 0.03153972327709198, dist_loss: 0.7002959251403809
recon_loss: 0.03153873234987259, dist_loss: 0.3633314371109009
recon_loss: 0.031537771224975586, dist_loss: 0.9388372898101807
recon_loss: 0.03153664246201515, dist_loss: 0.6020128130912781
recon_loss: 0.03153541684150696, dist_loss: 0.2753288745880127
recon_loss: 0.03153418377041817, dist_loss: 1.084316372871399
recon_loss: 0.03153298795223236, dist_loss: 0.5606270432472229
recon_loss: 0.03153187781572342, dist_loss: 0.7123233079910278
recon_loss: 0.031531013548374176, dist_loss: 1.0016915798187256
recon_loss: 0.0315302275121212, dist_loss: 0.6727097034454346
recon_loss: 0.0315295085310936, dist_loss: 0.786175012588501
recon_loss: 0.03152911365032196, dist_loss: 0.5291972756385803
recon_loss: 0.03152833878993988, dist_loss: 0.5250132083892822
recon_loss: 0.03152748942375183, dist_loss: 0.6794216632843018
recon_loss: 0.031526707112789154, dist_loss: 0.5042649507522583
recon_loss: 0.03152567148208618, dist_loss: 0.7169457674026489
recon_loss: 0.0315244197845459, dist_loss: 0.5292554497718811
recon_loss: 0.031523339450359344, dist_loss: 0.572738766670227
recon_loss: 0.031522538512945175, dist_loss: 0.742457389831543
recon_loss: 0.03152143210172653, dist_loss: 1.0064222812652588
recon_loss: 0.03152012452483177, dist_loss: 0.8114346265792847
recon_loss: 0.03151888772845268, dist_loss: 0.43708693981170654
recon_loss: 0.03151813521981239, dist_loss: 0.4928080439567566
recon_loss: 0.03151772916316986, dist_loss: 1.2251172065734863
recon_loss: 0.03151669353246689, dist_loss: 0.5306639671325684
recon_loss: 0.03151523321866989, dist_loss: 0.4857273995876312
recon_loss: 0.031514108180999756, dist_loss: 0.6956620812416077
recon_loss: 0.03151295334100723, dist_loss: 0.5620894432067871
recon_loss: 0.03151164576411247, dist_loss: 0.35059672594070435
recon_loss: 0.03151041269302368, dist_loss: 0.45259249210357666
recon_loss: 0.03150927275419235, dist_loss: 0.5457000732421875
recon_loss: 0.031508415937423706, dist_loss: 0.7224145531654358
recon_loss: 0.03150776028633118, dist_loss: 0.6867660284042358
recon_loss: 0.03150704503059387, dist_loss: 0.6508248448371887
recon_loss: 0.03150605410337448, dist_loss: 0.6788875460624695
recon_loss: 0.031504977494478226, dist_loss: 0.6342933177947998
recon_loss: 0.03150361031293869, dist_loss: 0.3114745616912842
Pre-training Epoch 27:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 27:   5%|▍         | 18/367 [00:00<00:02, 171.66it/s]Pre-training Epoch 27:  10%|▉         | 36/367 [00:00<00:01, 175.24it/s]Pre-training Epoch 27:  15%|█▍        | 54/367 [00:00<00:01, 174.12it/s]Pre-training Epoch 27:  20%|█▉        | 72/367 [00:00<00:01, 175.76it/s]Pre-training Epoch 27:  25%|██▍       | 90/367 [00:00<00:01, 174.12it/s]Pre-training Epoch 27:  29%|██▉       | 108/367 [00:00<00:01, 174.81it/s]Pre-training Epoch 27:  34%|███▍      | 126/367 [00:00<00:01, 174.55it/s]recon_loss: 0.03150208294391632, dist_loss: 1.184389591217041
recon_loss: 0.03150051459670067, dist_loss: 0.8212525844573975
recon_loss: 0.03149938955903053, dist_loss: 0.6953374743461609
recon_loss: 0.03149806335568428, dist_loss: 0.505083441734314
recon_loss: 0.03149702772498131, dist_loss: 0.7812554240226746
recon_loss: 0.03149598091840744, dist_loss: 0.46781665086746216
recon_loss: 0.03149500861763954, dist_loss: 0.4316630959510803
recon_loss: 0.03149396926164627, dist_loss: 0.7282572984695435
recon_loss: 0.03149283304810524, dist_loss: 0.5162851810455322
recon_loss: 0.03149174526333809, dist_loss: 0.48395267128944397
recon_loss: 0.03149056434631348, dist_loss: 1.1254490613937378
recon_loss: 0.03148921951651573, dist_loss: 0.7431361675262451
recon_loss: 0.03148790821433067, dist_loss: 0.9108420014381409
recon_loss: 0.031486544758081436, dist_loss: 0.8575400114059448
recon_loss: 0.03148527070879936, dist_loss: 0.44874703884124756
recon_loss: 0.03148394823074341, dist_loss: 0.5990796089172363
recon_loss: 0.03148255869746208, dist_loss: 0.7056424617767334
recon_loss: 0.03148126229643822, dist_loss: 1.0170353651046753
recon_loss: 0.03147983178496361, dist_loss: 0.37345466017723083
recon_loss: 0.0314784049987793, dist_loss: 0.6955831050872803
recon_loss: 0.03147711977362633, dist_loss: 0.9599066972732544
recon_loss: 0.03147612139582634, dist_loss: 0.44063854217529297
recon_loss: 0.031475212424993515, dist_loss: 0.37475985288619995
recon_loss: 0.031474266201257706, dist_loss: 0.6776643991470337
recon_loss: 0.031473372131586075, dist_loss: 0.9324563145637512
recon_loss: 0.03147245943546295, dist_loss: 0.4830390512943268
recon_loss: 0.03147158771753311, dist_loss: 0.4076469838619232
recon_loss: 0.03147060424089432, dist_loss: 0.822824239730835
recon_loss: 0.03146946802735329, dist_loss: 0.601564884185791
recon_loss: 0.03146824613213539, dist_loss: 0.43404334783554077
recon_loss: 0.0314670205116272, dist_loss: 0.4464836120605469
recon_loss: 0.031465962529182434, dist_loss: 0.9076157808303833
recon_loss: 0.031464945524930954, dist_loss: 0.47221845388412476
recon_loss: 0.031463705003261566, dist_loss: 0.5471251010894775
recon_loss: 0.031462665647268295, dist_loss: 0.6740257740020752
recon_loss: 0.03146180510520935, dist_loss: 0.5764954686164856
recon_loss: 0.03146106377243996, dist_loss: 0.758309006690979
recon_loss: 0.031460635364055634, dist_loss: 0.36947059631347656
recon_loss: 0.031460367143154144, dist_loss: 0.46047425270080566
recon_loss: 0.03146025165915489, dist_loss: 0.5010908842086792
recon_loss: 0.031459808349609375, dist_loss: 0.7629887461662292
recon_loss: 0.03145873546600342, dist_loss: 0.5428582429885864
recon_loss: 0.03145751729607582, dist_loss: 0.38008320331573486
recon_loss: 0.03145607188344002, dist_loss: 1.1812117099761963
recon_loss: 0.03145495057106018, dist_loss: 0.5663644075393677
recon_loss: 0.03145359829068184, dist_loss: 0.3407193422317505
recon_loss: 0.03145240247249603, dist_loss: 0.757072925567627
recon_loss: 0.03145136684179306, dist_loss: 0.8014354109764099
recon_loss: 0.03145061060786247, dist_loss: 0.598166286945343
recon_loss: 0.03144972771406174, dist_loss: 0.8438727855682373
recon_loss: 0.03144897520542145, dist_loss: 1.0708004236221313
recon_loss: 0.031447868794202805, dist_loss: 0.2962390184402466
recon_loss: 0.0314469151198864, dist_loss: 1.0198062658309937
recon_loss: 0.03144603967666626, dist_loss: 1.064875602722168
recon_loss: 0.031445130705833435, dist_loss: 0.8038153052330017
recon_loss: 0.03144391253590584, dist_loss: 0.6664108633995056
recon_loss: 0.03144257515668869, dist_loss: 0.9483489990234375
recon_loss: 0.031441155821084976, dist_loss: 0.700088620185852
recon_loss: 0.0314398892223835, dist_loss: 0.8407027721405029
recon_loss: 0.0314389131963253, dist_loss: 0.5721120834350586
recon_loss: 0.03143792599439621, dist_loss: 0.6225820779800415
recon_loss: 0.03143696114420891, dist_loss: 1.028322696685791
recon_loss: 0.03143589571118355, dist_loss: 0.721741795539856
recon_loss: 0.03143465891480446, dist_loss: 0.7631025314331055
recon_loss: 0.031433556228876114, dist_loss: 0.840883195400238
recon_loss: 0.03143266588449478, dist_loss: 0.6465801000595093
recon_loss: 0.031431686133146286, dist_loss: 1.0555574893951416
recon_loss: 0.03143072873353958, dist_loss: 0.8502160310745239
recon_loss: 0.03142979368567467, dist_loss: 0.6668663620948792
recon_loss: 0.031429074704647064, dist_loss: 0.6878418922424316
recon_loss: 0.03142838925123215, dist_loss: 0.6496867537498474
recon_loss: 0.031427521258592606, dist_loss: 0.7315634489059448
recon_loss: 0.03142664581537247, dist_loss: 0.9997429251670837
recon_loss: 0.03142578527331352, dist_loss: 0.34422728419303894
recon_loss: 0.031425051391124725, dist_loss: 0.6198596954345703
recon_loss: 0.03142452985048294, dist_loss: 1.0173792839050293
recon_loss: 0.031424056738615036, dist_loss: 0.49857959151268005
recon_loss: 0.031423620879650116, dist_loss: 0.4176730513572693
recon_loss: 0.03142324090003967, dist_loss: 0.4067375063896179
recon_loss: 0.0314224548637867, dist_loss: 0.9904379844665527
recon_loss: 0.03142115846276283, dist_loss: 0.8549587726593018
recon_loss: 0.031419817358255386, dist_loss: 0.8514837622642517
recon_loss: 0.0314188152551651, dist_loss: 0.36108285188674927
recon_loss: 0.03141782805323601, dist_loss: 1.1918550729751587
recon_loss: 0.03141743689775467, dist_loss: 0.4708966016769409
recon_loss: 0.03141654655337334, dist_loss: 0.9788998365402222
recon_loss: 0.031415753066539764, dist_loss: 0.4363113343715668
recon_loss: 0.031415343284606934, dist_loss: 0.662929892539978
recon_loss: 0.03141501173377037, dist_loss: 0.38463497161865234
recon_loss: 0.0314146988093853, dist_loss: 0.3043980002403259
recon_loss: 0.031414277851581573, dist_loss: 0.7407011389732361
recon_loss: 0.03141346573829651, dist_loss: 0.6519638299942017
recon_loss: 0.0314127579331398, dist_loss: 0.8772794008255005
recon_loss: 0.03141201660037041, dist_loss: 0.5352535843849182
recon_loss: 0.03141125664114952, dist_loss: 0.8150303363800049
recon_loss: 0.03141046687960625, dist_loss: 1.204254150390625
recon_loss: 0.03140949457883835, dist_loss: 0.6898882985115051
recon_loss: 0.03140844777226448, dist_loss: 0.9623599052429199
recon_loss: 0.03140763193368912, dist_loss: 0.3921995460987091
recon_loss: 0.03140697255730629, dist_loss: 0.5630887746810913
recon_loss: 0.03140632435679436, dist_loss: 0.24900713562965393
recon_loss: 0.03140551224350929, dist_loss: 0.5327585935592651
recon_loss: 0.03140450268983841, dist_loss: 0.9616137146949768
recon_loss: 0.03140362724661827, dist_loss: 0.6177922487258911
recon_loss: 0.03140254691243172, dist_loss: 0.6540073156356812
recon_loss: 0.031401533633470535, dist_loss: 0.7608535289764404
recon_loss: 0.03140021860599518, dist_loss: 0.7361357808113098
recon_loss: 0.031399041414260864, dist_loss: 0.5637954473495483
recon_loss: 0.03139789029955864, dist_loss: 0.6661205291748047
recon_loss: 0.03139694780111313, dist_loss: 0.6994251012802124
recon_loss: 0.031395845115184784, dist_loss: 0.5899542570114136
recon_loss: 0.03139481320977211, dist_loss: 1.0886666774749756
recon_loss: 0.031393956393003464, dist_loss: 0.6796947121620178
recon_loss: 0.031393107026815414, dist_loss: 0.47607138752937317
recon_loss: 0.03139224648475647, dist_loss: 0.49793553352355957
recon_loss: 0.03139135241508484, dist_loss: 0.690725564956665
recon_loss: 0.03139033541083336, dist_loss: 0.4899871051311493
recon_loss: 0.031389329582452774, dist_loss: 0.6274083852767944
recon_loss: 0.03138832375407219, dist_loss: 0.44108015298843384
recon_loss: 0.0313873328268528, dist_loss: 0.5398329496383667
recon_loss: 0.03138626739382744, dist_loss: 0.9864664673805237
recon_loss: 0.031385306268930435, dist_loss: 0.7611461877822876
recon_loss: 0.031384438276290894, dist_loss: 0.49754539132118225
recon_loss: 0.0313834585249424, dist_loss: 0.49581071734428406
recon_loss: 0.0313824862241745, dist_loss: 0.7747481465339661
recon_loss: 0.03138149157166481, dist_loss: 0.6288853287696838
recon_loss: 0.03138064220547676, dist_loss: 0.2222907990217209
recon_loss: 0.03137985244393349, dist_loss: 0.6947817206382751
recon_loss: 0.03137889504432678, dist_loss: 0.3798503875732422
Pre-training Epoch 27:  39%|███▉      | 144/367 [00:00<00:01, 175.63it/s]Pre-training Epoch 27:  44%|████▍     | 162/367 [00:00<00:01, 174.69it/s]Pre-training Epoch 27:  49%|████▉     | 180/367 [00:01<00:01, 175.94it/s]Pre-training Epoch 27:  54%|█████▍    | 198/367 [00:01<00:00, 175.59it/s]Pre-training Epoch 27:  59%|█████▉    | 216/367 [00:01<00:00, 173.10it/s]Pre-training Epoch 27:  64%|██████▍   | 234/367 [00:01<00:00, 174.60it/s]Pre-training Epoch 27:  69%|██████▉   | 253/367 [00:01<00:00, 176.29it/s]recon_loss: 0.03137782961130142, dist_loss: 0.8508179187774658
recon_loss: 0.031376879662275314, dist_loss: 0.48155686259269714
recon_loss: 0.03137589991092682, dist_loss: 0.4871010184288025
recon_loss: 0.03137485682964325, dist_loss: 0.4733782410621643
recon_loss: 0.03137371316552162, dist_loss: 0.4578142762184143
recon_loss: 0.03137248381972313, dist_loss: 0.4612678289413452
recon_loss: 0.03137125074863434, dist_loss: 0.8176372051239014
recon_loss: 0.03136999160051346, dist_loss: 0.6730561852455139
recon_loss: 0.031368646770715714, dist_loss: 0.5975996255874634
recon_loss: 0.031367383897304535, dist_loss: 0.8858282566070557
recon_loss: 0.0313662588596344, dist_loss: 0.6149650812149048
recon_loss: 0.03136514127254486, dist_loss: 0.7799071073532104
recon_loss: 0.0313640758395195, dist_loss: 0.5319496393203735
recon_loss: 0.03136303648352623, dist_loss: 0.4107324481010437
recon_loss: 0.031362056732177734, dist_loss: 0.554438054561615
recon_loss: 0.031361207365989685, dist_loss: 1.0196330547332764
recon_loss: 0.03136058151721954, dist_loss: 0.4739599823951721
recon_loss: 0.03136003017425537, dist_loss: 0.9554409980773926
recon_loss: 0.03135918453335762, dist_loss: 0.9949700832366943
recon_loss: 0.031358249485492706, dist_loss: 0.38452011346817017
recon_loss: 0.03135750815272331, dist_loss: 1.0379643440246582
recon_loss: 0.03135674074292183, dist_loss: 0.4447667598724365
recon_loss: 0.031355924904346466, dist_loss: 0.6095578670501709
recon_loss: 0.03135525435209274, dist_loss: 0.5356178283691406
recon_loss: 0.031354524195194244, dist_loss: 1.258714199066162
recon_loss: 0.03135380148887634, dist_loss: 1.153088927268982
recon_loss: 0.03135283291339874, dist_loss: 0.6013534069061279
recon_loss: 0.03135176748037338, dist_loss: 1.106882095336914
recon_loss: 0.03135073557496071, dist_loss: 0.8211673498153687
recon_loss: 0.0313497819006443, dist_loss: 0.6322203874588013
recon_loss: 0.03134899213910103, dist_loss: 1.3480864763259888
recon_loss: 0.03134838491678238, dist_loss: 0.4728209674358368
recon_loss: 0.03134787082672119, dist_loss: 0.5574238300323486
recon_loss: 0.031347084790468216, dist_loss: 0.7151848673820496
recon_loss: 0.03134611248970032, dist_loss: 1.1476094722747803
recon_loss: 0.03134515509009361, dist_loss: 1.100078821182251
recon_loss: 0.0313449501991272, dist_loss: 0.9613958597183228
recon_loss: 0.03134432062506676, dist_loss: 1.164536714553833
recon_loss: 0.031343378126621246, dist_loss: 0.9661908745765686
recon_loss: 0.031342763453722, dist_loss: 0.649470329284668
recon_loss: 0.031342022120952606, dist_loss: 1.1263694763183594
recon_loss: 0.03134148567914963, dist_loss: 0.914249062538147
recon_loss: 0.03134087845683098, dist_loss: 0.8274111747741699
recon_loss: 0.031340137124061584, dist_loss: 0.6991602182388306
recon_loss: 0.031339071691036224, dist_loss: 0.4546353816986084
recon_loss: 0.031337857246398926, dist_loss: 1.20566987991333
recon_loss: 0.03133659437298775, dist_loss: 0.3802046775817871
recon_loss: 0.03133537992835045, dist_loss: 0.5725712180137634
recon_loss: 0.031334176659584045, dist_loss: 0.5037188529968262
recon_loss: 0.03133270889520645, dist_loss: 0.49404942989349365
recon_loss: 0.03133118525147438, dist_loss: 0.8497326374053955
recon_loss: 0.03132960572838783, dist_loss: 0.8340793251991272
recon_loss: 0.031328074634075165, dist_loss: 0.6122463345527649
recon_loss: 0.031326714903116226, dist_loss: 0.7397916913032532
recon_loss: 0.031325563788414, dist_loss: 0.6916933059692383
recon_loss: 0.03132457658648491, dist_loss: 0.6992601156234741
recon_loss: 0.03132406994700432, dist_loss: 0.6064398884773254
recon_loss: 0.03132354095578194, dist_loss: 0.6412087678909302
recon_loss: 0.03132292628288269, dist_loss: 0.5350527763366699
recon_loss: 0.03132188320159912, dist_loss: 0.8036268949508667
recon_loss: 0.031320251524448395, dist_loss: 0.5917866230010986
recon_loss: 0.03131868317723274, dist_loss: 0.6814778447151184
recon_loss: 0.03131726011633873, dist_loss: 0.8521884083747864
recon_loss: 0.03131604939699173, dist_loss: 0.5543684959411621
recon_loss: 0.0313149094581604, dist_loss: 0.7504698038101196
recon_loss: 0.03131397068500519, dist_loss: 0.8612579107284546
recon_loss: 0.03131311386823654, dist_loss: 0.4750545024871826
recon_loss: 0.03131229057908058, dist_loss: 0.4945904016494751
recon_loss: 0.0313115119934082, dist_loss: 0.5135560631752014
recon_loss: 0.031310759484767914, dist_loss: 0.6515258550643921
recon_loss: 0.03131004050374031, dist_loss: 0.49333882331848145
recon_loss: 0.031309425830841064, dist_loss: 0.5455225110054016
recon_loss: 0.031308580189943314, dist_loss: 0.6240566372871399
recon_loss: 0.031307950615882874, dist_loss: 0.6424016952514648
recon_loss: 0.03130771219730377, dist_loss: 0.6799007058143616
recon_loss: 0.03130684792995453, dist_loss: 0.9894994497299194
recon_loss: 0.03130577877163887, dist_loss: 0.5253756046295166
recon_loss: 0.03130468726158142, dist_loss: 0.33957424759864807
recon_loss: 0.0313037671148777, dist_loss: 0.6666505336761475
recon_loss: 0.03130267933011055, dist_loss: 0.3597536087036133
recon_loss: 0.031301774084568024, dist_loss: 1.2213270664215088
recon_loss: 0.031300850212574005, dist_loss: 0.5947117805480957
recon_loss: 0.03129994869232178, dist_loss: 1.178868055343628
recon_loss: 0.03129905089735985, dist_loss: 0.953713059425354
recon_loss: 0.03129805997014046, dist_loss: 0.5395876169204712
recon_loss: 0.031296879053115845, dist_loss: 0.6586936712265015
recon_loss: 0.031295694410800934, dist_loss: 0.9218682646751404
recon_loss: 0.031294479966163635, dist_loss: 0.8193345069885254
recon_loss: 0.03129323571920395, dist_loss: 0.7776963710784912
recon_loss: 0.031292084604501724, dist_loss: 0.8181039094924927
recon_loss: 0.03129105642437935, dist_loss: 0.6815871000289917
recon_loss: 0.03129028528928757, dist_loss: 0.8565411567687988
recon_loss: 0.03128970414400101, dist_loss: 1.236539602279663
recon_loss: 0.03128876909613609, dist_loss: 0.5826811790466309
recon_loss: 0.0312875472009182, dist_loss: 0.37494486570358276
recon_loss: 0.03128684312105179, dist_loss: 0.5354759693145752
recon_loss: 0.031286194920539856, dist_loss: 0.877167820930481
recon_loss: 0.031285058706998825, dist_loss: 0.8368251323699951
recon_loss: 0.03128402680158615, dist_loss: 0.6814450025558472
recon_loss: 0.031283188611269, dist_loss: 0.5735675096511841
recon_loss: 0.03128237649798393, dist_loss: 0.5031827688217163
recon_loss: 0.03128144145011902, dist_loss: 0.8177862167358398
recon_loss: 0.031280357390642166, dist_loss: 0.48711109161376953
recon_loss: 0.031279321759939194, dist_loss: 0.6476821899414062
recon_loss: 0.03127826005220413, dist_loss: 0.7970123291015625
recon_loss: 0.0312771275639534, dist_loss: 0.4437907934188843
recon_loss: 0.03127603977918625, dist_loss: 0.724402666091919
recon_loss: 0.03127499297261238, dist_loss: 0.9232476353645325
recon_loss: 0.031273990869522095, dist_loss: 0.5180522799491882
recon_loss: 0.031272925436496735, dist_loss: 0.8109905123710632
recon_loss: 0.03127221018075943, dist_loss: 1.0576897859573364
recon_loss: 0.03127218037843704, dist_loss: 0.6335287690162659
recon_loss: 0.031271886080503464, dist_loss: 0.5673748254776001
recon_loss: 0.03127073124051094, dist_loss: 0.18951357901096344
recon_loss: 0.03126940503716469, dist_loss: 0.88609379529953
recon_loss: 0.03126826137304306, dist_loss: 0.3371267318725586
recon_loss: 0.03126711770892143, dist_loss: 0.34195512533187866
recon_loss: 0.031265731900930405, dist_loss: 0.3800209164619446
recon_loss: 0.031264401972293854, dist_loss: 0.6519923210144043
recon_loss: 0.03126310929656029, dist_loss: 0.5481320023536682
recon_loss: 0.03126216679811478, dist_loss: 0.6645340919494629
recon_loss: 0.03126140683889389, dist_loss: 0.5894225835800171
recon_loss: 0.03126077353954315, dist_loss: 0.7366882562637329
recon_loss: 0.031260278075933456, dist_loss: 0.39286234974861145
recon_loss: 0.031259503215551376, dist_loss: 0.4048112630844116
recon_loss: 0.031258851289749146, dist_loss: 0.6080132126808167
recon_loss: 0.03125814348459244, dist_loss: 0.9018440842628479
recon_loss: 0.03125733882188797, dist_loss: 0.9072211980819702
recon_loss: 0.031255997717380524, dist_loss: 0.9712458848953247
Pre-training Epoch 27:  74%|███████▍  | 271/367 [00:01<00:00, 174.03it/s]Pre-training Epoch 27:  79%|███████▊  | 289/367 [00:01<00:00, 173.63it/s]Pre-training Epoch 27:  84%|████████▎ | 307/367 [00:01<00:00, 174.56it/s]Pre-training Epoch 27:  89%|████████▊ | 325/367 [00:01<00:00, 174.99it/s]Pre-training Epoch 27:  93%|█████████▎| 343/367 [00:01<00:00, 173.22it/s]Pre-training Epoch 27:  98%|█████████▊| 361/367 [00:02<00:00, 174.85it/s]Pre-training Epoch 27: 100%|██████████| 367/367 [00:02<00:00, 174.50it/s]
recon_loss: 0.03125448897480965, dist_loss: 0.4926965832710266
recon_loss: 0.03125347942113876, dist_loss: 1.1447250843048096
recon_loss: 0.031252581626176834, dist_loss: 0.6962077617645264
recon_loss: 0.031251467764377594, dist_loss: 0.7268792986869812
recon_loss: 0.031250473111867905, dist_loss: 0.325586199760437
recon_loss: 0.031250182539224625, dist_loss: 1.2761826515197754
recon_loss: 0.03125029429793358, dist_loss: 0.47071483731269836
recon_loss: 0.03124997764825821, dist_loss: 0.6418013572692871
recon_loss: 0.03124856948852539, dist_loss: 0.5362302660942078
recon_loss: 0.03124704211950302, dist_loss: 0.6549332737922668
recon_loss: 0.031246032565832138, dist_loss: 0.764168918132782
recon_loss: 0.031245630234479904, dist_loss: 0.8058197498321533
recon_loss: 0.03124546818435192, dist_loss: 0.6296381950378418
recon_loss: 0.03124457225203514, dist_loss: 0.5484319925308228
recon_loss: 0.031243637204170227, dist_loss: 0.854845404624939
recon_loss: 0.0312433373183012, dist_loss: 0.8170478343963623
recon_loss: 0.031243853271007538, dist_loss: 0.6576512455940247
recon_loss: 0.03124382719397545, dist_loss: 0.6532086133956909
recon_loss: 0.03124229982495308, dist_loss: 0.8834405541419983
recon_loss: 0.03124093823134899, dist_loss: 0.35493385791778564
recon_loss: 0.031240709125995636, dist_loss: 1.195555329322815
recon_loss: 0.03124050423502922, dist_loss: 0.723480224609375
recon_loss: 0.03123949095606804, dist_loss: 0.44307637214660645
recon_loss: 0.031238220632076263, dist_loss: 0.6564044952392578
recon_loss: 0.031237423419952393, dist_loss: 0.7768629193305969
recon_loss: 0.03123733215034008, dist_loss: 0.891705334186554
recon_loss: 0.031237374991178513, dist_loss: 0.6331900954246521
recon_loss: 0.031236976385116577, dist_loss: 0.9512463808059692
recon_loss: 0.031235620379447937, dist_loss: 0.5921196937561035
recon_loss: 0.031234558671712875, dist_loss: 0.418894499540329
recon_loss: 0.031233813613653183, dist_loss: 0.675066351890564
recon_loss: 0.03123294934630394, dist_loss: 0.4494932293891907
recon_loss: 0.031232226639986038, dist_loss: 0.5318628549575806
recon_loss: 0.03123147413134575, dist_loss: 0.4266658425331116
recon_loss: 0.03123066946864128, dist_loss: 0.768714427947998
recon_loss: 0.03123004175722599, dist_loss: 1.0204274654388428
recon_loss: 0.031229576095938683, dist_loss: 1.2046055793762207
recon_loss: 0.031229469925165176, dist_loss: 0.42625316977500916
recon_loss: 0.031229611486196518, dist_loss: 0.8222060203552246
recon_loss: 0.03122883103787899, dist_loss: 0.8685098886489868
recon_loss: 0.031227625906467438, dist_loss: 1.1427829265594482
recon_loss: 0.031226972118020058, dist_loss: 0.9191116094589233
recon_loss: 0.03122653439640999, dist_loss: 0.6506730318069458
recon_loss: 0.03122558258473873, dist_loss: 0.7283996343612671
recon_loss: 0.031224418431520462, dist_loss: 0.5954314470291138
recon_loss: 0.031223705038428307, dist_loss: 0.7419427037239075
recon_loss: 0.031223054975271225, dist_loss: 0.7058320045471191
recon_loss: 0.031222110614180565, dist_loss: 0.5513014793395996
recon_loss: 0.031220825389027596, dist_loss: 0.5846777558326721
recon_loss: 0.03121911734342575, dist_loss: 0.43864864110946655
recon_loss: 0.03121735341846943, dist_loss: 0.3498832881450653
recon_loss: 0.031215762719511986, dist_loss: 0.5980006456375122
recon_loss: 0.03121432289481163, dist_loss: 1.0333433151245117
recon_loss: 0.031213201582431793, dist_loss: 0.7096152901649475
recon_loss: 0.031212732195854187, dist_loss: 0.5029341578483582
recon_loss: 0.031212184578180313, dist_loss: 0.6935730576515198
recon_loss: 0.031211785972118378, dist_loss: 0.45509272813796997
recon_loss: 0.03121079131960869, dist_loss: 0.821853756904602
recon_loss: 0.031209668144583702, dist_loss: 0.6622971296310425
recon_loss: 0.031209062784910202, dist_loss: 0.8426517248153687
recon_loss: 0.031208420172333717, dist_loss: 0.7917908430099487
recon_loss: 0.0312073715031147, dist_loss: 0.5099920034408569
recon_loss: 0.031206633895635605, dist_loss: 1.0385020971298218
recon_loss: 0.031205985695123672, dist_loss: 0.7980676889419556
recon_loss: 0.031205469742417336, dist_loss: 0.5888918042182922
recon_loss: 0.031204961240291595, dist_loss: 0.8975878953933716
recon_loss: 0.031204281374812126, dist_loss: 0.8597471714019775
recon_loss: 0.031203772872686386, dist_loss: 0.6357669830322266
recon_loss: 0.031202921643853188, dist_loss: 0.6368149518966675
recon_loss: 0.03120199404656887, dist_loss: 0.6870542168617249
recon_loss: 0.031200971454381943, dist_loss: 0.6723052859306335
recon_loss: 0.031199712306261063, dist_loss: 0.606881320476532
recon_loss: 0.031198441982269287, dist_loss: 0.6585404872894287
recon_loss: 0.031197382137179375, dist_loss: 0.7463561296463013
recon_loss: 0.03119618259370327, dist_loss: 0.3122327923774719
recon_loss: 0.03119487129151821, dist_loss: 0.691209077835083
recon_loss: 0.03119373880326748, dist_loss: 0.6204386353492737
recon_loss: 0.031192705035209656, dist_loss: 0.3942587971687317
recon_loss: 0.031191589310765266, dist_loss: 1.0346348285675049
recon_loss: 0.03119066171348095, dist_loss: 0.6148530840873718
recon_loss: 0.031190086156129837, dist_loss: 0.5580006837844849
recon_loss: 0.03118942305445671, dist_loss: 0.7000247240066528
recon_loss: 0.031189432367682457, dist_loss: 0.39875349402427673
recon_loss: 0.031189316883683205, dist_loss: 0.7208961844444275
recon_loss: 0.031188759952783585, dist_loss: 0.439348429441452
recon_loss: 0.03118816576898098, dist_loss: 0.5921304225921631
recon_loss: 0.031187167391180992, dist_loss: 0.4044302701950073
recon_loss: 0.03118622675538063, dist_loss: 0.45794785022735596
recon_loss: 0.031185375526547432, dist_loss: 0.6014337539672852
recon_loss: 0.031184200197458267, dist_loss: 0.6930364370346069
recon_loss: 0.031183015555143356, dist_loss: 0.2772394120693207
recon_loss: 0.031182242557406425, dist_loss: 1.020416021347046
recon_loss: 0.03118172287940979, dist_loss: 0.3146260678768158
recon_loss: 0.03118133172392845, dist_loss: 0.4534284472465515
recon_loss: 0.031181031838059425, dist_loss: 0.8831968903541565
recon_loss: 0.031180351972579956, dist_loss: 0.30830124020576477
recon_loss: 0.031179437413811684, dist_loss: 0.8180835247039795
recon_loss: 0.031178688630461693, dist_loss: 0.6907862424850464
recon_loss: 0.03117813542485237, dist_loss: 0.45793983340263367
recon_loss: 0.031177662312984467, dist_loss: 0.6575587391853333
recon_loss: 0.031177010387182236, dist_loss: 0.9010458588600159
recon_loss: 0.031176000833511353, dist_loss: 0.3043665587902069
recon_loss: 0.031175244599580765, dist_loss: 0.8012925982475281
recon_loss: 0.031174151226878166, dist_loss: 1.2207520008087158
recon_loss: 0.031172871589660645, dist_loss: 0.3632911443710327
recon_loss: 0.031171957030892372, dist_loss: 1.7625735998153687
recon_loss: 0.031171301379799843, dist_loss: 0.6010161638259888
recon_loss: 0.031170615926384926, dist_loss: 0.3703765273094177
recon_loss: 0.03116966411471367, dist_loss: 0.29217100143432617
Pre-training Epoch 28:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 28:   5%|▍         | 18/367 [00:00<00:02, 172.36it/s]Pre-training Epoch 28:  10%|▉         | 36/367 [00:00<00:01, 173.54it/s]Pre-training Epoch 28:  15%|█▍        | 54/367 [00:00<00:01, 175.00it/s]Pre-training Epoch 28:  20%|█▉        | 72/367 [00:00<00:01, 176.09it/s]Pre-training Epoch 28:  25%|██▍       | 90/367 [00:00<00:01, 176.59it/s]Pre-training Epoch 28:  29%|██▉       | 108/367 [00:00<00:01, 177.09it/s]Pre-training Epoch 28:  34%|███▍      | 126/367 [00:00<00:01, 177.59it/s]recon_loss: 0.03116864711046219, dist_loss: 1.068586826324463
recon_loss: 0.031167292967438698, dist_loss: 0.6986755728721619
recon_loss: 0.031165841966867447, dist_loss: 0.7614395022392273
recon_loss: 0.03116471692919731, dist_loss: 0.5306593179702759
recon_loss: 0.0311634112149477, dist_loss: 0.8423712253570557
recon_loss: 0.031161999329924583, dist_loss: 0.5208030939102173
recon_loss: 0.031160390004515648, dist_loss: 0.6388964653015137
recon_loss: 0.03115914948284626, dist_loss: 0.6272974014282227
recon_loss: 0.03115820325911045, dist_loss: 0.8978115320205688
recon_loss: 0.031157229095697403, dist_loss: 0.5448237061500549
recon_loss: 0.031156431883573532, dist_loss: 0.6392694711685181
recon_loss: 0.031155768781900406, dist_loss: 0.7863282561302185
recon_loss: 0.031155182048678398, dist_loss: 1.0823763608932495
recon_loss: 0.031154660508036613, dist_loss: 0.39256614446640015
recon_loss: 0.03115391917526722, dist_loss: 0.6245588064193726
recon_loss: 0.031153136864304543, dist_loss: 0.5069994330406189
recon_loss: 0.031152451410889626, dist_loss: 0.33070889115333557
recon_loss: 0.03115192987024784, dist_loss: 0.9348733425140381
recon_loss: 0.031151169911026955, dist_loss: 0.7807443737983704
recon_loss: 0.031150052323937416, dist_loss: 0.5560740232467651
recon_loss: 0.03114902228116989, dist_loss: 1.472244143486023
recon_loss: 0.0311480313539505, dist_loss: 1.133765459060669
recon_loss: 0.031146911904215813, dist_loss: 0.6223666667938232
recon_loss: 0.031145483255386353, dist_loss: 0.5018702745437622
recon_loss: 0.03114435449242592, dist_loss: 1.1741605997085571
recon_loss: 0.031143609434366226, dist_loss: 1.1999104022979736
recon_loss: 0.03114311583340168, dist_loss: 1.0206187963485718
recon_loss: 0.03114277683198452, dist_loss: 0.7041120529174805
recon_loss: 0.031142303720116615, dist_loss: 0.5121595859527588
recon_loss: 0.031141163781285286, dist_loss: 0.8732517957687378
recon_loss: 0.031140215694904327, dist_loss: 0.6415865421295166
recon_loss: 0.031138718128204346, dist_loss: 0.5638377666473389
recon_loss: 0.031137671321630478, dist_loss: 0.7702735662460327
recon_loss: 0.031136630102992058, dist_loss: 0.23046395182609558
recon_loss: 0.031135719269514084, dist_loss: 0.57771235704422
recon_loss: 0.031134914606809616, dist_loss: 0.5956888198852539
recon_loss: 0.03113425150513649, dist_loss: 1.2810943126678467
recon_loss: 0.031133659183979034, dist_loss: 0.7191967368125916
recon_loss: 0.03113292157649994, dist_loss: 0.5343403816223145
recon_loss: 0.031132113188505173, dist_loss: 1.1397361755371094
recon_loss: 0.031131330877542496, dist_loss: 0.6653509736061096
recon_loss: 0.031130606308579445, dist_loss: 0.713192880153656
recon_loss: 0.031129887327551842, dist_loss: 0.45416730642318726
recon_loss: 0.03112923353910446, dist_loss: 0.43327343463897705
recon_loss: 0.0311286561191082, dist_loss: 0.36116066575050354
recon_loss: 0.031128190457820892, dist_loss: 0.8054285049438477
recon_loss: 0.03112768940627575, dist_loss: 0.9258440136909485
recon_loss: 0.03112700767815113, dist_loss: 0.9288159608840942
recon_loss: 0.031126301735639572, dist_loss: 1.2183876037597656
recon_loss: 0.031125519424676895, dist_loss: 1.0293673276901245
recon_loss: 0.031125113368034363, dist_loss: 0.492048054933548
recon_loss: 0.03112463280558586, dist_loss: 0.48763132095336914
recon_loss: 0.031123891472816467, dist_loss: 0.5057784914970398
recon_loss: 0.031122932210564613, dist_loss: 0.6234552264213562
recon_loss: 0.03112223371863365, dist_loss: 0.5877431035041809
recon_loss: 0.03112131915986538, dist_loss: 0.7938811182975769
recon_loss: 0.031120603904128075, dist_loss: 0.830894947052002
recon_loss: 0.031119849532842636, dist_loss: 0.6398271322250366
recon_loss: 0.031119266524910927, dist_loss: 1.1332240104675293
recon_loss: 0.03111884370446205, dist_loss: 0.8059566617012024
recon_loss: 0.03111807070672512, dist_loss: 0.7724547386169434
recon_loss: 0.031117036938667297, dist_loss: 0.596024751663208
recon_loss: 0.031116144731640816, dist_loss: 0.6356737017631531
recon_loss: 0.031115049496293068, dist_loss: 0.7831687331199646
recon_loss: 0.031114062294363976, dist_loss: 0.534292459487915
recon_loss: 0.031113367527723312, dist_loss: 0.4363296926021576
recon_loss: 0.031112654134631157, dist_loss: 0.5871307253837585
recon_loss: 0.031111817806959152, dist_loss: 0.4850502014160156
recon_loss: 0.03111100010573864, dist_loss: 0.4917219579219818
recon_loss: 0.03111051581799984, dist_loss: 0.4889557659626007
recon_loss: 0.031110215932130814, dist_loss: 0.6692641377449036
recon_loss: 0.0311100035905838, dist_loss: 0.6950826644897461
recon_loss: 0.031109770759940147, dist_loss: 0.4896914064884186
recon_loss: 0.031109249219298363, dist_loss: 0.4367060363292694
recon_loss: 0.031108511611819267, dist_loss: 0.35873252153396606
recon_loss: 0.03110753372311592, dist_loss: 0.7317328453063965
recon_loss: 0.0311061292886734, dist_loss: 1.255105972290039
recon_loss: 0.031104542315006256, dist_loss: 0.7030282020568848
recon_loss: 0.031103024259209633, dist_loss: 0.6463446021080017
recon_loss: 0.031101886183023453, dist_loss: 0.49685683846473694
recon_loss: 0.031101303175091743, dist_loss: 0.8584644198417664
recon_loss: 0.031101122498512268, dist_loss: 0.3028620481491089
recon_loss: 0.031100420281291008, dist_loss: 0.4600812792778015
recon_loss: 0.031099433079361916, dist_loss: 0.795292854309082
recon_loss: 0.03109879046678543, dist_loss: 0.6382648348808289
recon_loss: 0.031098155304789543, dist_loss: 0.6506805419921875
recon_loss: 0.031097330152988434, dist_loss: 0.7271137237548828
recon_loss: 0.031096240505576134, dist_loss: 0.5131826400756836
recon_loss: 0.031095368787646294, dist_loss: 0.662871241569519
recon_loss: 0.031094839796423912, dist_loss: 0.49450990557670593
recon_loss: 0.0310946274548769, dist_loss: 0.6137990355491638
recon_loss: 0.031094765290617943, dist_loss: 0.7325115203857422
recon_loss: 0.03109414130449295, dist_loss: 0.36270612478256226
recon_loss: 0.031093357130885124, dist_loss: 0.6163264513015747
recon_loss: 0.031092030927538872, dist_loss: 1.193137288093567
recon_loss: 0.03109048120677471, dist_loss: 0.9276774525642395
recon_loss: 0.03108919784426689, dist_loss: 0.8702611327171326
recon_loss: 0.031088219955563545, dist_loss: 0.5480105876922607
recon_loss: 0.031087206676602364, dist_loss: 0.744942307472229
recon_loss: 0.031086603179574013, dist_loss: 0.4127510190010071
recon_loss: 0.031086081638932228, dist_loss: 0.4380280077457428
recon_loss: 0.03108547441661358, dist_loss: 0.9601778388023376
recon_loss: 0.031084895133972168, dist_loss: 0.6930325031280518
recon_loss: 0.031084254384040833, dist_loss: 0.6006858944892883
recon_loss: 0.031083455309271812, dist_loss: 0.7464773654937744
recon_loss: 0.03108246810734272, dist_loss: 0.736600399017334
recon_loss: 0.031081438064575195, dist_loss: 1.0563771724700928
recon_loss: 0.03108029067516327, dist_loss: 0.4372938871383667
recon_loss: 0.031079059466719627, dist_loss: 0.45502766966819763
recon_loss: 0.031078029423952103, dist_loss: 0.5137537717819214
recon_loss: 0.03107696771621704, dist_loss: 0.29846662282943726
recon_loss: 0.031076092272996902, dist_loss: 0.6585822701454163
recon_loss: 0.031075485050678253, dist_loss: 0.8599275946617126
recon_loss: 0.031075239181518555, dist_loss: 0.413403183221817
recon_loss: 0.03107479028403759, dist_loss: 0.4202098548412323
recon_loss: 0.03107438050210476, dist_loss: 0.4839419424533844
recon_loss: 0.031073907390236855, dist_loss: 0.531414270401001
recon_loss: 0.03107283264398575, dist_loss: 0.7399960160255432
recon_loss: 0.03107140026986599, dist_loss: 0.5030044317245483
recon_loss: 0.031070087105035782, dist_loss: 0.6830165386199951
recon_loss: 0.031069286167621613, dist_loss: 0.9796236753463745
recon_loss: 0.03106865845620632, dist_loss: 0.9142539501190186
recon_loss: 0.031067775562405586, dist_loss: 0.5284973978996277
recon_loss: 0.03106682375073433, dist_loss: 0.8606038093566895
recon_loss: 0.031066125258803368, dist_loss: 0.40686777234077454
recon_loss: 0.031065693125128746, dist_loss: 0.7284203171730042
recon_loss: 0.03106505796313286, dist_loss: 0.9290286302566528
recon_loss: 0.031064027920365334, dist_loss: 0.8998313546180725
Pre-training Epoch 28:  39%|███▉      | 144/367 [00:00<00:01, 176.57it/s]Pre-training Epoch 28:  44%|████▍     | 162/367 [00:00<00:01, 169.01it/s]Pre-training Epoch 28:  49%|████▉     | 179/367 [00:01<00:01, 164.59it/s]Pre-training Epoch 28:  53%|█████▎    | 196/367 [00:01<00:01, 162.03it/s]Pre-training Epoch 28:  58%|█████▊    | 214/367 [00:01<00:00, 165.86it/s]Pre-training Epoch 28:  63%|██████▎   | 232/367 [00:01<00:00, 169.25it/s]Pre-training Epoch 28:  68%|██████▊   | 250/367 [00:01<00:00, 172.03it/s]recon_loss: 0.03106330893933773, dist_loss: 0.838596761226654
recon_loss: 0.031062722206115723, dist_loss: 0.6307713985443115
recon_loss: 0.031062183901667595, dist_loss: 1.3099560737609863
recon_loss: 0.031061312183737755, dist_loss: 0.5775613784790039
recon_loss: 0.031060421839356422, dist_loss: 0.6551834344863892
recon_loss: 0.031059809029102325, dist_loss: 0.9490180015563965
recon_loss: 0.031059253960847855, dist_loss: 0.8624923825263977
recon_loss: 0.031058771535754204, dist_loss: 0.4192178249359131
recon_loss: 0.031058546155691147, dist_loss: 1.0224189758300781
recon_loss: 0.03105831891298294, dist_loss: 0.8120704889297485
recon_loss: 0.03105783276259899, dist_loss: 0.9512680768966675
recon_loss: 0.031056830659508705, dist_loss: 0.6187697649002075
recon_loss: 0.03105570189654827, dist_loss: 0.4730076193809509
recon_loss: 0.031054770573973656, dist_loss: 0.3792016804218292
recon_loss: 0.031054191291332245, dist_loss: 1.0056973695755005
recon_loss: 0.0310540571808815, dist_loss: 0.4622777998447418
recon_loss: 0.031054049730300903, dist_loss: 0.6196084022521973
recon_loss: 0.03105374053120613, dist_loss: 0.32406294345855713
recon_loss: 0.0310533307492733, dist_loss: 0.551151692867279
recon_loss: 0.031052617356181145, dist_loss: 0.7605170607566833
recon_loss: 0.031051456928253174, dist_loss: 0.8435211777687073
recon_loss: 0.031050296500325203, dist_loss: 0.8691191077232361
recon_loss: 0.031049378216266632, dist_loss: 0.8618434071540833
recon_loss: 0.031049134209752083, dist_loss: 0.5521882772445679
recon_loss: 0.031049275770783424, dist_loss: 0.28674614429473877
recon_loss: 0.03104960359632969, dist_loss: 0.5088860392570496
recon_loss: 0.0310498233884573, dist_loss: 0.2952774167060852
recon_loss: 0.031049568206071854, dist_loss: 0.8385103940963745
recon_loss: 0.031048975884914398, dist_loss: 0.8653750419616699
recon_loss: 0.03104783222079277, dist_loss: 0.4580078125
recon_loss: 0.031046679243445396, dist_loss: 0.36986035108566284
recon_loss: 0.03104555979371071, dist_loss: 0.8211844563484192
recon_loss: 0.031044552102684975, dist_loss: 1.1239464282989502
recon_loss: 0.031044067814946175, dist_loss: 0.4176993668079376
recon_loss: 0.03104362078011036, dist_loss: 0.4002179205417633
recon_loss: 0.03104337304830551, dist_loss: 1.3157750368118286
recon_loss: 0.031043188646435738, dist_loss: 0.6110329031944275
recon_loss: 0.031042808666825294, dist_loss: 0.7469906806945801
recon_loss: 0.03104250133037567, dist_loss: 0.9953016638755798
recon_loss: 0.03104211762547493, dist_loss: 0.43400731682777405
recon_loss: 0.031041759997606277, dist_loss: 0.748035728931427
recon_loss: 0.031041545793414116, dist_loss: 0.48324957489967346
recon_loss: 0.03104141168296337, dist_loss: 0.7673217058181763
recon_loss: 0.031041234731674194, dist_loss: 0.43618911504745483
recon_loss: 0.031041191890835762, dist_loss: 0.705114483833313
recon_loss: 0.031040646135807037, dist_loss: 0.9552388191223145
recon_loss: 0.031039593741297722, dist_loss: 0.8293727040290833
recon_loss: 0.031038280576467514, dist_loss: 0.7125338315963745
recon_loss: 0.03103724680840969, dist_loss: 0.4118940234184265
recon_loss: 0.031036851927638054, dist_loss: 0.7472240924835205
recon_loss: 0.03103652037680149, dist_loss: 0.3207700252532959
recon_loss: 0.03103586845099926, dist_loss: 0.41188180446624756
recon_loss: 0.03103550523519516, dist_loss: 0.7839661836624146
recon_loss: 0.03103538788855076, dist_loss: 0.5362116694450378
recon_loss: 0.03103487566113472, dist_loss: 0.8991189002990723
recon_loss: 0.031034298241138458, dist_loss: 0.6817751526832581
recon_loss: 0.031033912673592567, dist_loss: 0.6261463165283203
recon_loss: 0.03103405050933361, dist_loss: 1.1859543323516846
recon_loss: 0.03103407844901085, dist_loss: 0.39588117599487305
recon_loss: 0.031033683568239212, dist_loss: 0.48827028274536133
recon_loss: 0.031033284962177277, dist_loss: 0.4741464853286743
recon_loss: 0.031032713130116463, dist_loss: 0.4077568054199219
recon_loss: 0.031032104045152664, dist_loss: 0.812847375869751
recon_loss: 0.031031658872961998, dist_loss: 0.9350499510765076
recon_loss: 0.031030338257551193, dist_loss: 0.7844176292419434
recon_loss: 0.031029386445879936, dist_loss: 0.7307477593421936
recon_loss: 0.03102852590382099, dist_loss: 0.7776430249214172
recon_loss: 0.03102792613208294, dist_loss: 0.503878116607666
recon_loss: 0.03102722018957138, dist_loss: 0.6041462421417236
recon_loss: 0.031026048585772514, dist_loss: 1.1379811763763428
recon_loss: 0.03102484904229641, dist_loss: 0.6324063539505005
recon_loss: 0.031024252995848656, dist_loss: 0.9522338509559631
recon_loss: 0.03102373331785202, dist_loss: 0.7477664947509766
recon_loss: 0.031022628769278526, dist_loss: 0.7157222032546997
recon_loss: 0.03102095052599907, dist_loss: 0.3875391483306885
recon_loss: 0.03101971559226513, dist_loss: 0.6767175197601318
recon_loss: 0.031018860638141632, dist_loss: 0.7106550931930542
recon_loss: 0.031017933040857315, dist_loss: 0.7089606523513794
recon_loss: 0.03101697936654091, dist_loss: 0.8497494459152222
recon_loss: 0.03101605921983719, dist_loss: 0.712450385093689
recon_loss: 0.031015893444418907, dist_loss: 0.30693867802619934
recon_loss: 0.031015949323773384, dist_loss: 0.7030566930770874
recon_loss: 0.031015191227197647, dist_loss: 0.36018455028533936
recon_loss: 0.03101479634642601, dist_loss: 0.8518131971359253
recon_loss: 0.031015174463391304, dist_loss: 0.42096391320228577
recon_loss: 0.031014975160360336, dist_loss: 1.0549262762069702
recon_loss: 0.03101329319179058, dist_loss: 0.8380498886108398
recon_loss: 0.031011616811156273, dist_loss: 0.9341933727264404
recon_loss: 0.03101109154522419, dist_loss: 0.6843355894088745
recon_loss: 0.031010519713163376, dist_loss: 0.8838022351264954
recon_loss: 0.031008942052721977, dist_loss: 0.6380771398544312
recon_loss: 0.03100746124982834, dist_loss: 0.42792823910713196
recon_loss: 0.031006401404738426, dist_loss: 0.6065990924835205
recon_loss: 0.031005559489130974, dist_loss: 0.802565336227417
recon_loss: 0.031004566699266434, dist_loss: 0.5560100078582764
recon_loss: 0.031003519892692566, dist_loss: 0.6401352286338806
recon_loss: 0.03100268356502056, dist_loss: 0.40721938014030457
recon_loss: 0.031001990661025047, dist_loss: 0.27881741523742676
recon_loss: 0.031001610681414604, dist_loss: 0.5267513394355774
recon_loss: 0.031001165509223938, dist_loss: 0.4213482141494751
recon_loss: 0.031000573188066483, dist_loss: 0.48978641629219055
recon_loss: 0.03100000135600567, dist_loss: 0.5543855428695679
recon_loss: 0.03099946491420269, dist_loss: 0.8114235997200012
recon_loss: 0.03099895268678665, dist_loss: 1.0135835409164429
recon_loss: 0.030998360365629196, dist_loss: 0.3341548442840576
recon_loss: 0.0309976227581501, dist_loss: 0.4891749620437622
recon_loss: 0.030996881425380707, dist_loss: 0.6235360503196716
recon_loss: 0.030996177345514297, dist_loss: 0.9183030724525452
recon_loss: 0.03099537268280983, dist_loss: 0.5024614334106445
recon_loss: 0.030994486063718796, dist_loss: 0.7449782490730286
recon_loss: 0.030993621796369553, dist_loss: 0.6302419304847717
recon_loss: 0.030992789193987846, dist_loss: 0.6797385215759277
recon_loss: 0.0309919361025095, dist_loss: 1.0113016366958618
recon_loss: 0.030991148203611374, dist_loss: 0.9594611525535583
recon_loss: 0.03099038265645504, dist_loss: 0.9345153570175171
recon_loss: 0.030989861115813255, dist_loss: 0.7801734209060669
recon_loss: 0.03098907694220543, dist_loss: 0.8657166361808777
recon_loss: 0.030988434329628944, dist_loss: 1.175150990486145
recon_loss: 0.030987806618213654, dist_loss: 0.7016649842262268
recon_loss: 0.03098747879266739, dist_loss: 0.9971201419830322
recon_loss: 0.030986929312348366, dist_loss: 0.6122572422027588
recon_loss: 0.030985873192548752, dist_loss: 0.3915451765060425
recon_loss: 0.030985170975327492, dist_loss: 0.7814122438430786
recon_loss: 0.03098466619849205, dist_loss: 0.5711096525192261
recon_loss: 0.030983982607722282, dist_loss: 0.8964134454727173
recon_loss: 0.030983351171016693, dist_loss: 0.6925873160362244
recon_loss: 0.03098253160715103, dist_loss: 0.6658778190612793
recon_loss: 0.03098197840154171, dist_loss: 0.9751858711242676
Pre-training Epoch 28:  73%|███████▎  | 269/367 [00:01<00:00, 174.63it/s]Pre-training Epoch 28:  78%|███████▊  | 287/367 [00:01<00:00, 175.69it/s]Pre-training Epoch 28:  83%|████████▎ | 305/367 [00:01<00:00, 176.55it/s]Pre-training Epoch 28:  88%|████████▊ | 323/367 [00:01<00:00, 176.20it/s]Pre-training Epoch 28:  93%|█████████▎| 341/367 [00:01<00:00, 173.66it/s]Pre-training Epoch 28:  98%|█████████▊| 359/367 [00:02<00:00, 165.02it/s]Pre-training Epoch 28: 100%|██████████| 367/367 [00:02<00:00, 170.92it/s]
recon_loss: 0.030981745570898056, dist_loss: 0.3920109272003174
recon_loss: 0.030981052666902542, dist_loss: 0.7149890661239624
recon_loss: 0.0309798214584589, dist_loss: 0.43976253271102905
recon_loss: 0.030978605151176453, dist_loss: 0.4432615041732788
recon_loss: 0.030977511778473854, dist_loss: 0.6995233297348022
recon_loss: 0.030976276844739914, dist_loss: 0.9973857998847961
recon_loss: 0.030975941568613052, dist_loss: 0.8204193115234375
recon_loss: 0.03097626194357872, dist_loss: 0.6622425317764282
recon_loss: 0.03097653016448021, dist_loss: 0.8701872229576111
recon_loss: 0.030975880101323128, dist_loss: 1.002700924873352
recon_loss: 0.030975429341197014, dist_loss: 0.7356323599815369
recon_loss: 0.030974645167589188, dist_loss: 0.7159746885299683
recon_loss: 0.03097389079630375, dist_loss: 1.199109673500061
recon_loss: 0.030972959473729134, dist_loss: 0.6160916686058044
recon_loss: 0.030971858650445938, dist_loss: 0.35585543513298035
recon_loss: 0.030970877036452293, dist_loss: 0.5948343276977539
recon_loss: 0.030970100313425064, dist_loss: 1.150837779045105
recon_loss: 0.03096948377788067, dist_loss: 0.5227479338645935
recon_loss: 0.03096902184188366, dist_loss: 0.3437291383743286
recon_loss: 0.030968552455306053, dist_loss: 0.41641467809677124
recon_loss: 0.03096782974898815, dist_loss: 0.8373825550079346
recon_loss: 0.03096737712621689, dist_loss: 0.5065765976905823
recon_loss: 0.030966931954026222, dist_loss: 0.563499927520752
recon_loss: 0.030965929850935936, dist_loss: 0.8692132234573364
recon_loss: 0.03096492774784565, dist_loss: 0.4395895004272461
recon_loss: 0.030964208766818047, dist_loss: 0.6683943271636963
recon_loss: 0.0309637151658535, dist_loss: 0.4655529260635376
recon_loss: 0.030963290482759476, dist_loss: 0.8990110158920288
recon_loss: 0.030962899327278137, dist_loss: 1.0765104293823242
recon_loss: 0.03096223995089531, dist_loss: 0.4493151903152466
recon_loss: 0.030961675569415092, dist_loss: 0.4424513876438141
recon_loss: 0.030961276963353157, dist_loss: 0.9255319237709045
recon_loss: 0.03096098080277443, dist_loss: 0.7072148323059082
recon_loss: 0.0309605672955513, dist_loss: 0.7571991086006165
recon_loss: 0.030960002914071083, dist_loss: 1.0619969367980957
recon_loss: 0.030959509313106537, dist_loss: 0.7384155988693237
recon_loss: 0.030959047377109528, dist_loss: 0.5840007066726685
recon_loss: 0.030958697199821472, dist_loss: 0.6661188006401062
recon_loss: 0.030958302319049835, dist_loss: 0.8007990121841431
recon_loss: 0.030957773327827454, dist_loss: 0.5510056614875793
recon_loss: 0.030956784263253212, dist_loss: 0.7271779775619507
recon_loss: 0.030955979600548744, dist_loss: 0.5823897123336792
recon_loss: 0.03095555305480957, dist_loss: 0.7801634669303894
recon_loss: 0.030955281108617783, dist_loss: 0.4945210814476013
recon_loss: 0.03095485083758831, dist_loss: 0.7969179153442383
recon_loss: 0.03095412440598011, dist_loss: 0.45029211044311523
recon_loss: 0.03095342591404915, dist_loss: 0.4846731722354889
recon_loss: 0.030952582135796547, dist_loss: 0.4843628406524658
recon_loss: 0.03095179609954357, dist_loss: 0.6680504679679871
recon_loss: 0.03095104731619358, dist_loss: 0.7609836459159851
recon_loss: 0.030950253829360008, dist_loss: 1.0207054615020752
recon_loss: 0.03094954416155815, dist_loss: 0.9245156049728394
recon_loss: 0.03094899095594883, dist_loss: 0.9419077634811401
recon_loss: 0.03094833344221115, dist_loss: 0.7476053237915039
recon_loss: 0.030947428196668625, dist_loss: 0.9024513959884644
recon_loss: 0.030946344137191772, dist_loss: 0.8519231081008911
recon_loss: 0.030945567414164543, dist_loss: 0.6299567818641663
recon_loss: 0.03094504214823246, dist_loss: 0.7656252384185791
recon_loss: 0.030944569036364555, dist_loss: 0.3676516115665436
recon_loss: 0.03094378672540188, dist_loss: 1.052682876586914
recon_loss: 0.03094288893043995, dist_loss: 0.38969123363494873
recon_loss: 0.03094250150024891, dist_loss: 0.3970462679862976
recon_loss: 0.03094225376844406, dist_loss: 0.4400150775909424
recon_loss: 0.030941901728510857, dist_loss: 0.9801287651062012
recon_loss: 0.03094106912612915, dist_loss: 0.5914901494979858
recon_loss: 0.030940363183617592, dist_loss: 0.5404413342475891
recon_loss: 0.03093966469168663, dist_loss: 0.5339676141738892
recon_loss: 0.03093876875936985, dist_loss: 0.607164740562439
recon_loss: 0.030937837436795235, dist_loss: 0.7016295194625854
recon_loss: 0.03093704581260681, dist_loss: 0.8030668497085571
recon_loss: 0.03093634732067585, dist_loss: 0.36322617530822754
recon_loss: 0.03093555010855198, dist_loss: 0.8258745670318604
recon_loss: 0.030934752896428108, dist_loss: 0.6330651044845581
recon_loss: 0.030934015288949013, dist_loss: 0.7929534316062927
recon_loss: 0.030933206900954247, dist_loss: 0.6040259599685669
recon_loss: 0.030932409688830376, dist_loss: 0.6702086925506592
recon_loss: 0.030931703746318817, dist_loss: 0.6968716382980347
recon_loss: 0.03093121014535427, dist_loss: 0.6190927028656006
recon_loss: 0.030930906534194946, dist_loss: 1.1428231000900269
recon_loss: 0.03093036450445652, dist_loss: 0.8255038857460022
recon_loss: 0.03093007765710354, dist_loss: 0.35014545917510986
recon_loss: 0.030929509550333023, dist_loss: 0.9801432490348816
recon_loss: 0.030928825959563255, dist_loss: 0.5379931926727295
recon_loss: 0.030928531661629677, dist_loss: 0.7352097034454346
recon_loss: 0.03092828206717968, dist_loss: 0.8247796297073364
recon_loss: 0.030927492305636406, dist_loss: 0.5104639530181885
recon_loss: 0.030926965177059174, dist_loss: 0.8113462924957275
recon_loss: 0.030926601961255074, dist_loss: 0.3500440716743469
recon_loss: 0.030926356092095375, dist_loss: 0.5933331847190857
recon_loss: 0.03092605248093605, dist_loss: 0.5869175791740417
recon_loss: 0.030925307422876358, dist_loss: 0.3721471428871155
recon_loss: 0.030924782156944275, dist_loss: 0.744373619556427
recon_loss: 0.03092421032488346, dist_loss: 0.8144170641899109
recon_loss: 0.030923744663596153, dist_loss: 0.3715088367462158
recon_loss: 0.030923211947083473, dist_loss: 0.8340237140655518
recon_loss: 0.03092261590063572, dist_loss: 0.5917172431945801
recon_loss: 0.030921701341867447, dist_loss: 0.7924659252166748
recon_loss: 0.03092111274600029, dist_loss: 0.77161705493927
recon_loss: 0.03092060424387455, dist_loss: 0.8276340961456299
recon_loss: 0.030919913202524185, dist_loss: 0.8162810802459717
recon_loss: 0.030919183045625687, dist_loss: 0.5136013627052307
recon_loss: 0.030918536707758904, dist_loss: 0.5582028031349182
recon_loss: 0.030917851254343987, dist_loss: 0.8851756453514099
recon_loss: 0.030917344614863396, dist_loss: 1.1335252523422241
recon_loss: 0.030916698276996613, dist_loss: 0.48700571060180664
recon_loss: 0.030916141346096992, dist_loss: 0.47044920921325684
recon_loss: 0.030915692448616028, dist_loss: 0.6743602752685547
recon_loss: 0.03091520629823208, dist_loss: 0.5487593412399292
recon_loss: 0.030914638191461563, dist_loss: 0.4169456362724304
recon_loss: 0.030913976952433586, dist_loss: 0.5331480503082275
recon_loss: 0.030913084745407104, dist_loss: 0.7855620384216309
Pre-training Epoch 29:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 29:   4%|▍         | 15/367 [00:00<00:02, 149.62it/s]Pre-training Epoch 29:   9%|▊         | 32/367 [00:00<00:02, 160.56it/s]Pre-training Epoch 29:  14%|█▎        | 50/367 [00:00<00:01, 169.23it/s]Pre-training Epoch 29:  18%|█▊        | 67/367 [00:00<00:01, 163.18it/s]Pre-training Epoch 29:  23%|██▎       | 84/367 [00:00<00:01, 160.86it/s]Pre-training Epoch 29:  28%|██▊       | 101/367 [00:00<00:01, 160.07it/s]Pre-training Epoch 29:  32%|███▏      | 118/367 [00:00<00:01, 158.72it/s]recon_loss: 0.03091234341263771, dist_loss: 0.9388270974159241
recon_loss: 0.03091212920844555, dist_loss: 0.46025359630584717
recon_loss: 0.030911846086382866, dist_loss: 0.6799222230911255
recon_loss: 0.030911479145288467, dist_loss: 0.5919293761253357
recon_loss: 0.0309111550450325, dist_loss: 0.8852055668830872
recon_loss: 0.030911000445485115, dist_loss: 0.5916640162467957
recon_loss: 0.030910544097423553, dist_loss: 0.7007630467414856
recon_loss: 0.03090956062078476, dist_loss: 0.20314261317253113
recon_loss: 0.03090805374085903, dist_loss: 0.618394672870636
recon_loss: 0.03090740367770195, dist_loss: 0.5517686605453491
recon_loss: 0.030907856300473213, dist_loss: 0.32023507356643677
recon_loss: 0.030908117070794106, dist_loss: 0.4813990890979767
recon_loss: 0.03090694174170494, dist_loss: 1.1424380540847778
recon_loss: 0.03090548887848854, dist_loss: 0.45076483488082886
recon_loss: 0.030904902145266533, dist_loss: 0.5548021197319031
recon_loss: 0.03090364672243595, dist_loss: 0.919866681098938
recon_loss: 0.030901800841093063, dist_loss: 0.538591742515564
recon_loss: 0.030900640413165092, dist_loss: 0.5494182109832764
recon_loss: 0.030900223180651665, dist_loss: 0.6781815886497498
recon_loss: 0.03089970164000988, dist_loss: 0.49989771842956543
recon_loss: 0.0308991651982069, dist_loss: 0.5351192355155945
recon_loss: 0.03089877776801586, dist_loss: 0.4086214303970337
recon_loss: 0.03089856170117855, dist_loss: 0.6303838491439819
recon_loss: 0.03089827299118042, dist_loss: 1.3541662693023682
recon_loss: 0.030897796154022217, dist_loss: 0.35026490688323975
recon_loss: 0.030896980315446854, dist_loss: 0.8059967160224915
recon_loss: 0.030895883217453957, dist_loss: 0.7030630707740784
recon_loss: 0.030894789844751358, dist_loss: 0.44737985730171204
recon_loss: 0.030894197523593903, dist_loss: 0.46003419160842896
recon_loss: 0.030894123017787933, dist_loss: 0.4203576445579529
recon_loss: 0.03089425340294838, dist_loss: 0.800742506980896
recon_loss: 0.030894983559846878, dist_loss: 0.9032055139541626
recon_loss: 0.030895274132490158, dist_loss: 0.8498014211654663
recon_loss: 0.03089469112455845, dist_loss: 0.5556687712669373
recon_loss: 0.030893661081790924, dist_loss: 0.5583070516586304
recon_loss: 0.03089253231883049, dist_loss: 0.5830776691436768
recon_loss: 0.030891530215740204, dist_loss: 0.8389427661895752
recon_loss: 0.030890343710780144, dist_loss: 0.5757028460502625
recon_loss: 0.030889663845300674, dist_loss: 0.7248039245605469
recon_loss: 0.030888741835951805, dist_loss: 0.9902395009994507
recon_loss: 0.030887793749570847, dist_loss: 0.5679879188537598
recon_loss: 0.03088734857738018, dist_loss: 0.7451140880584717
recon_loss: 0.030887506902217865, dist_loss: 0.9600338935852051
recon_loss: 0.030887490138411522, dist_loss: 0.9941215515136719
recon_loss: 0.030888011679053307, dist_loss: 1.3667466640472412
recon_loss: 0.03088786080479622, dist_loss: 0.6670409440994263
recon_loss: 0.030887633562088013, dist_loss: 1.4364094734191895
recon_loss: 0.030887115746736526, dist_loss: 0.5117483139038086
recon_loss: 0.03088611736893654, dist_loss: 0.6467975378036499
recon_loss: 0.030885284766554832, dist_loss: 0.2753162384033203
recon_loss: 0.030884133651852608, dist_loss: 0.7678484916687012
recon_loss: 0.030882535502314568, dist_loss: 1.1612579822540283
recon_loss: 0.030881110578775406, dist_loss: 1.100640892982483
recon_loss: 0.03088073618710041, dist_loss: 0.6539494395256042
recon_loss: 0.030880823731422424, dist_loss: 0.6214439272880554
recon_loss: 0.030880523845553398, dist_loss: 0.6932109594345093
recon_loss: 0.030880440026521683, dist_loss: 0.857636570930481
recon_loss: 0.03088025189936161, dist_loss: 0.739244818687439
recon_loss: 0.03088005818426609, dist_loss: 0.6258155107498169
recon_loss: 0.03087972290813923, dist_loss: 0.46418946981430054
recon_loss: 0.030878819525241852, dist_loss: 0.378892183303833
recon_loss: 0.030877012759447098, dist_loss: 0.5983486175537109
recon_loss: 0.030874691903591156, dist_loss: 0.5519280433654785
recon_loss: 0.030872667208313942, dist_loss: 0.6346349716186523
recon_loss: 0.03087097965180874, dist_loss: 1.003044605255127
recon_loss: 0.030869558453559875, dist_loss: 0.4659827947616577
recon_loss: 0.03086879663169384, dist_loss: 0.8327515125274658
recon_loss: 0.030868513509631157, dist_loss: 1.0829238891601562
recon_loss: 0.030868560075759888, dist_loss: 0.49439752101898193
recon_loss: 0.030868714675307274, dist_loss: 0.506096601486206
recon_loss: 0.030868876725435257, dist_loss: 0.6593016386032104
recon_loss: 0.030868588015437126, dist_loss: 0.7760524153709412
recon_loss: 0.030868086963891983, dist_loss: 0.5369195938110352
recon_loss: 0.03086746484041214, dist_loss: 0.31009137630462646
recon_loss: 0.030866682529449463, dist_loss: 0.42518025636672974
recon_loss: 0.03086572326719761, dist_loss: 0.45347005128860474
recon_loss: 0.030864516273140907, dist_loss: 0.49760621786117554
recon_loss: 0.030863337218761444, dist_loss: 0.8279919624328613
recon_loss: 0.030862702056765556, dist_loss: 0.8722470998764038
recon_loss: 0.030862120911478996, dist_loss: 0.8281888365745544
recon_loss: 0.030861174687743187, dist_loss: 0.40889954566955566
recon_loss: 0.03086024709045887, dist_loss: 0.6352989077568054
recon_loss: 0.030859755352139473, dist_loss: 0.836233377456665
recon_loss: 0.030859682708978653, dist_loss: 0.7225700616836548
recon_loss: 0.030859194695949554, dist_loss: 0.6925031542778015
recon_loss: 0.030858824029564857, dist_loss: 0.39751332998275757
recon_loss: 0.030858460813760757, dist_loss: 0.7755810022354126
recon_loss: 0.030858200043439865, dist_loss: 0.9417160153388977
recon_loss: 0.03085782565176487, dist_loss: 0.6494896411895752
recon_loss: 0.030857529491186142, dist_loss: 0.621623158454895
recon_loss: 0.030857162550091743, dist_loss: 0.6537667512893677
recon_loss: 0.030856646597385406, dist_loss: 0.6397016048431396
recon_loss: 0.030855927616357803, dist_loss: 0.41262286901474
recon_loss: 0.030855052173137665, dist_loss: 0.9754209518432617
recon_loss: 0.030854180455207825, dist_loss: 1.0066086053848267
recon_loss: 0.030853260308504105, dist_loss: 1.0757527351379395
recon_loss: 0.030852356925606728, dist_loss: 0.5700432062149048
recon_loss: 0.030851425603032112, dist_loss: 0.5045527219772339
recon_loss: 0.030850648880004883, dist_loss: 0.6333732008934021
recon_loss: 0.030849970877170563, dist_loss: 0.6279889941215515
recon_loss: 0.030849432572722435, dist_loss: 0.7068964242935181
recon_loss: 0.030849065631628036, dist_loss: 0.45370692014694214
recon_loss: 0.030848700553178787, dist_loss: 1.2302515506744385
recon_loss: 0.030848313122987747, dist_loss: 0.6830654144287109
recon_loss: 0.03084796667098999, dist_loss: 0.6660672426223755
recon_loss: 0.03084774874150753, dist_loss: 0.6018587946891785
recon_loss: 0.030847424641251564, dist_loss: 1.103753924369812
recon_loss: 0.03084695152938366, dist_loss: 0.5741366744041443
recon_loss: 0.030846597626805305, dist_loss: 1.091377854347229
recon_loss: 0.0308466125279665, dist_loss: 0.9348703026771545
recon_loss: 0.030846336856484413, dist_loss: 0.29502546787261963
recon_loss: 0.030845440924167633, dist_loss: 0.8020377159118652
recon_loss: 0.03084457293152809, dist_loss: 1.0701524019241333
recon_loss: 0.030844086781144142, dist_loss: 0.6216006875038147
recon_loss: 0.030843961983919144, dist_loss: 0.49265092611312866
recon_loss: 0.030843626707792282, dist_loss: 0.7224270105361938
recon_loss: 0.030843108892440796, dist_loss: 0.5734042525291443
recon_loss: 0.03084263950586319, dist_loss: 0.9627508521080017
recon_loss: 0.030842237174510956, dist_loss: 0.577273964881897
recon_loss: 0.030841626226902008, dist_loss: 0.529425323009491
recon_loss: 0.030840924009680748, dist_loss: 0.8357027769088745
recon_loss: 0.030840599909424782, dist_loss: 0.7860201597213745
recon_loss: 0.0308404341340065, dist_loss: 0.5907444953918457
recon_loss: 0.03083985112607479, dist_loss: 0.37991756200790405
recon_loss: 0.030838998034596443, dist_loss: 0.3962765336036682
recon_loss: 0.030838744714856148, dist_loss: 0.604231595993042
recon_loss: 0.030838552862405777, dist_loss: 0.7826787233352661
recon_loss: 0.030837783589959145, dist_loss: 0.7760894894599915
Pre-training Epoch 29:  37%|███▋      | 136/367 [00:00<00:01, 163.27it/s]Pre-training Epoch 29:  42%|████▏     | 154/367 [00:00<00:01, 167.22it/s]Pre-training Epoch 29:  47%|████▋     | 171/367 [00:01<00:01, 165.61it/s]Pre-training Epoch 29:  51%|█████     | 188/367 [00:01<00:01, 162.05it/s]Pre-training Epoch 29:  56%|█████▌    | 205/367 [00:01<00:01, 160.19it/s]Pre-training Epoch 29:  60%|██████    | 222/367 [00:01<00:00, 157.42it/s]Pre-training Epoch 29:  65%|██████▍   | 238/367 [00:01<00:00, 156.76it/s]Pre-training Epoch 29:  69%|██████▉   | 254/367 [00:01<00:00, 156.07it/s]recon_loss: 0.030837148427963257, dist_loss: 0.5036852359771729
recon_loss: 0.030836492776870728, dist_loss: 0.4564230144023895
recon_loss: 0.030835896730422974, dist_loss: 0.5755806565284729
recon_loss: 0.030835332348942757, dist_loss: 0.7944623827934265
recon_loss: 0.030834689736366272, dist_loss: 0.2824402451515198
recon_loss: 0.030834008008241653, dist_loss: 0.6976334452629089
recon_loss: 0.030833635479211807, dist_loss: 1.009400486946106
recon_loss: 0.030833380296826363, dist_loss: 1.0038378238677979
recon_loss: 0.030832618474960327, dist_loss: 0.5422979593276978
recon_loss: 0.030831867828965187, dist_loss: 1.0050079822540283
recon_loss: 0.030831340700387955, dist_loss: 0.5625011324882507
recon_loss: 0.030830807983875275, dist_loss: 0.556220531463623
recon_loss: 0.03083023987710476, dist_loss: 0.7321208119392395
recon_loss: 0.030829517170786858, dist_loss: 0.46115434169769287
recon_loss: 0.030828790739178658, dist_loss: 0.9392554759979248
recon_loss: 0.030828341841697693, dist_loss: 0.6928710341453552
recon_loss: 0.030827827751636505, dist_loss: 0.6749794483184814
recon_loss: 0.030827106907963753, dist_loss: 0.2977813482284546
recon_loss: 0.030826324597001076, dist_loss: 0.8108612298965454
recon_loss: 0.030825793743133545, dist_loss: 0.4251644015312195
recon_loss: 0.03082536719739437, dist_loss: 0.49160975217819214
recon_loss: 0.030824916437268257, dist_loss: 0.33487898111343384
recon_loss: 0.03082459792494774, dist_loss: 0.29336899518966675
recon_loss: 0.030824262648820877, dist_loss: 0.5885441303253174
recon_loss: 0.030823973938822746, dist_loss: 0.30696189403533936
recon_loss: 0.030823614448308945, dist_loss: 0.7488197088241577
recon_loss: 0.030822735279798508, dist_loss: 0.755117654800415
recon_loss: 0.030822301283478737, dist_loss: 0.6968798041343689
recon_loss: 0.030822012573480606, dist_loss: 0.5900889039039612
recon_loss: 0.0308215469121933, dist_loss: 1.1183969974517822
recon_loss: 0.03082055039703846, dist_loss: 0.7502735257148743
recon_loss: 0.03082004375755787, dist_loss: 0.43070194125175476
recon_loss: 0.03081977553665638, dist_loss: 0.9208129644393921
recon_loss: 0.030819382518529892, dist_loss: 1.0471866130828857
recon_loss: 0.030818786472082138, dist_loss: 0.9361441135406494
recon_loss: 0.030818289145827293, dist_loss: 1.0932791233062744
recon_loss: 0.030817735940217972, dist_loss: 0.7318356037139893
recon_loss: 0.030816903337836266, dist_loss: 0.5607590675354004
recon_loss: 0.030815541744232178, dist_loss: 0.4018211364746094
recon_loss: 0.030814863741397858, dist_loss: 0.5879116654396057
recon_loss: 0.030814772471785545, dist_loss: 0.4179835617542267
recon_loss: 0.030814334750175476, dist_loss: 1.0294626951217651
recon_loss: 0.03081364929676056, dist_loss: 0.46800580620765686
recon_loss: 0.03081314079463482, dist_loss: 0.26831507682800293
recon_loss: 0.030812781304121017, dist_loss: 0.6462348103523254
recon_loss: 0.030811969190835953, dist_loss: 0.4589585065841675
recon_loss: 0.030810926109552383, dist_loss: 0.7483392357826233
recon_loss: 0.030810153111815453, dist_loss: 0.643341064453125
recon_loss: 0.0308095570653677, dist_loss: 0.5193673968315125
recon_loss: 0.03080899827182293, dist_loss: 0.4949202835559845
recon_loss: 0.030808523297309875, dist_loss: 0.468478262424469
recon_loss: 0.03080805018544197, dist_loss: 0.6550672054290771
recon_loss: 0.030807431787252426, dist_loss: 0.7010272145271301
recon_loss: 0.030807023867964745, dist_loss: 0.6552666425704956
recon_loss: 0.030806129798293114, dist_loss: 0.7641014456748962
recon_loss: 0.030805526301264763, dist_loss: 0.5442754626274109
recon_loss: 0.030805004760622978, dist_loss: 0.6433904767036438
recon_loss: 0.03080436959862709, dist_loss: 0.5768797397613525
recon_loss: 0.03080391138792038, dist_loss: 0.5827844142913818
recon_loss: 0.030803177505731583, dist_loss: 0.47271889448165894
recon_loss: 0.030802471563220024, dist_loss: 0.7477658987045288
recon_loss: 0.03080163523554802, dist_loss: 0.5012054443359375
recon_loss: 0.030800925567746162, dist_loss: 1.2123067378997803
recon_loss: 0.030800290405750275, dist_loss: 0.6751899719238281
recon_loss: 0.03079969808459282, dist_loss: 0.4713975191116333
recon_loss: 0.0307991374284029, dist_loss: 0.7033488750457764
recon_loss: 0.03079855442047119, dist_loss: 0.688001811504364
recon_loss: 0.030798036605119705, dist_loss: 0.8375033736228943
recon_loss: 0.030797623097896576, dist_loss: 0.47510582208633423
recon_loss: 0.03079705499112606, dist_loss: 1.0222855806350708
recon_loss: 0.0307963564991951, dist_loss: 0.8283208012580872
recon_loss: 0.030796008184552193, dist_loss: 0.6424392461776733
recon_loss: 0.030795563012361526, dist_loss: 0.6055639982223511
recon_loss: 0.03079482913017273, dist_loss: 0.8582198023796082
recon_loss: 0.03079400584101677, dist_loss: 0.7201024889945984
recon_loss: 0.03079354763031006, dist_loss: 0.6115801334381104
recon_loss: 0.03079308196902275, dist_loss: 0.6900936365127563
recon_loss: 0.03079231269657612, dist_loss: 0.9917985200881958
recon_loss: 0.03079160675406456, dist_loss: 0.6661673784255981
recon_loss: 0.03079116716980934, dist_loss: 0.9867604970932007
recon_loss: 0.030790647491812706, dist_loss: 0.6505237817764282
recon_loss: 0.030789945274591446, dist_loss: 0.9647994041442871
recon_loss: 0.030789274722337723, dist_loss: 0.34749138355255127
recon_loss: 0.030788742005825043, dist_loss: 0.6802980303764343
recon_loss: 0.03078804351389408, dist_loss: 0.5302321910858154
recon_loss: 0.0307875107973814, dist_loss: 0.57915860414505
recon_loss: 0.030787302181124687, dist_loss: 0.8436275720596313
recon_loss: 0.030787095427513123, dist_loss: 0.8064133524894714
recon_loss: 0.0307871513068676, dist_loss: 0.443942666053772
recon_loss: 0.030786314979195595, dist_loss: 1.3148283958435059
recon_loss: 0.03078627586364746, dist_loss: 0.8638902902603149
recon_loss: 0.030786724761128426, dist_loss: 0.6914440989494324
recon_loss: 0.030787190422415733, dist_loss: 0.5151656866073608
recon_loss: 0.03078763745725155, dist_loss: 0.3965597152709961
recon_loss: 0.030787285417318344, dist_loss: 0.48786550760269165
recon_loss: 0.03078649379312992, dist_loss: 1.1077914237976074
recon_loss: 0.030785830691456795, dist_loss: 0.22807447612285614
recon_loss: 0.03078542836010456, dist_loss: 0.5802990198135376
recon_loss: 0.03078502044081688, dist_loss: 1.6381639242172241
recon_loss: 0.030784539878368378, dist_loss: 0.9062989950180054
recon_loss: 0.03078409470617771, dist_loss: 0.8486462831497192
recon_loss: 0.030783619731664658, dist_loss: 0.5020012259483337
recon_loss: 0.030783111229538918, dist_loss: 0.6948827505111694
recon_loss: 0.030782140791416168, dist_loss: 0.559252917766571
recon_loss: 0.030781138688325882, dist_loss: 0.8793601989746094
recon_loss: 0.030780132859945297, dist_loss: 0.592424750328064
recon_loss: 0.030779466032981873, dist_loss: 0.5953850746154785
recon_loss: 0.030778883025050163, dist_loss: 0.48810723423957825
recon_loss: 0.030778128653764725, dist_loss: 0.5063607692718506
recon_loss: 0.030777178704738617, dist_loss: 0.6407091617584229
recon_loss: 0.030776195228099823, dist_loss: 0.6092528104782104
recon_loss: 0.030775655061006546, dist_loss: 0.6378528475761414
recon_loss: 0.030775249004364014, dist_loss: 0.7609367966651917
recon_loss: 0.030774829909205437, dist_loss: 0.3431006968021393
recon_loss: 0.03077440895140171, dist_loss: 0.512891948223114
recon_loss: 0.03077433630824089, dist_loss: 0.7385807037353516
recon_loss: 0.030773863196372986, dist_loss: 0.7457716464996338
recon_loss: 0.03077310509979725, dist_loss: 0.8138396143913269
recon_loss: 0.030772462487220764, dist_loss: 0.5310670733451843
recon_loss: 0.030771851539611816, dist_loss: 0.6193497180938721
recon_loss: 0.030771169811487198, dist_loss: 0.7576539516448975
recon_loss: 0.030770383775234222, dist_loss: 1.0074758529663086
recon_loss: 0.030769728124141693, dist_loss: 0.8859809637069702
recon_loss: 0.03076923079788685, dist_loss: 0.5112292766571045
recon_loss: 0.030768679454922676, dist_loss: 0.7419595718383789
recon_loss: 0.03076789900660515, dist_loss: 1.1516307592391968
recon_loss: 0.03076724335551262, dist_loss: 1.0003674030303955
recon_loss: 0.03076709248125553, dist_loss: 0.7660200595855713
Pre-training Epoch 29:  74%|███████▎  | 270/367 [00:01<00:00, 155.50it/s]Pre-training Epoch 29:  78%|███████▊  | 286/367 [00:01<00:00, 154.62it/s]Pre-training Epoch 29:  82%|████████▏ | 302/367 [00:01<00:00, 154.37it/s]Pre-training Epoch 29:  87%|████████▋ | 318/367 [00:02<00:00, 153.42it/s]Pre-training Epoch 29:  91%|█████████ | 334/367 [00:02<00:00, 152.90it/s]Pre-training Epoch 29:  95%|█████████▌| 350/367 [00:02<00:00, 152.99it/s]Pre-training Epoch 29: 100%|█████████▉| 366/367 [00:02<00:00, 151.18it/s]Pre-training Epoch 29: 100%|██████████| 367/367 [00:02<00:00, 157.54it/s]
recon_loss: 0.030766824260354042, dist_loss: 0.36142677068710327
recon_loss: 0.030766595155000687, dist_loss: 1.000778317451477
recon_loss: 0.030766000971198082, dist_loss: 1.1642968654632568
recon_loss: 0.03076634742319584, dist_loss: 0.6825865507125854
recon_loss: 0.030767349526286125, dist_loss: 0.6125898957252502
recon_loss: 0.030768591910600662, dist_loss: 0.4683477282524109
recon_loss: 0.030768103897571564, dist_loss: 0.43820130825042725
recon_loss: 0.030767271295189857, dist_loss: 0.8234671354293823
recon_loss: 0.030766360461711884, dist_loss: 0.45618173480033875
recon_loss: 0.03076545149087906, dist_loss: 0.6578271389007568
recon_loss: 0.03076484054327011, dist_loss: 0.33246248960494995
recon_loss: 0.030764667317271233, dist_loss: 0.6110885143280029
recon_loss: 0.03076469898223877, dist_loss: 0.512332558631897
recon_loss: 0.0307646244764328, dist_loss: 0.3604421317577362
recon_loss: 0.030764413997530937, dist_loss: 0.45392823219299316
recon_loss: 0.030764123424887657, dist_loss: 0.5819318890571594
recon_loss: 0.03076350688934326, dist_loss: 0.9664492607116699
recon_loss: 0.030762776732444763, dist_loss: 0.42012378573417664
recon_loss: 0.030761972069740295, dist_loss: 1.0071662664413452
recon_loss: 0.030760765075683594, dist_loss: 0.6802300214767456
recon_loss: 0.030759375542402267, dist_loss: 0.7138343453407288
recon_loss: 0.030758172273635864, dist_loss: 0.390908807516098
recon_loss: 0.03075713850557804, dist_loss: 0.8928960561752319
recon_loss: 0.03075624257326126, dist_loss: 0.8290183544158936
recon_loss: 0.030755387619137764, dist_loss: 0.9899789094924927
recon_loss: 0.030754834413528442, dist_loss: 0.5161474943161011
recon_loss: 0.03075448051095009, dist_loss: 0.6301449537277222
recon_loss: 0.03075435757637024, dist_loss: 0.6289256811141968
recon_loss: 0.030754435807466507, dist_loss: 0.581446647644043
recon_loss: 0.030754799023270607, dist_loss: 0.5185154676437378
recon_loss: 0.030755162239074707, dist_loss: 0.47253796458244324
recon_loss: 0.030755335465073586, dist_loss: 0.8239513635635376
recon_loss: 0.030754972249269485, dist_loss: 1.1506385803222656
recon_loss: 0.030754240229725838, dist_loss: 0.6799202561378479
recon_loss: 0.030753757804632187, dist_loss: 0.7900007963180542
recon_loss: 0.030753200873732567, dist_loss: 0.5286978483200073
recon_loss: 0.03075229749083519, dist_loss: 0.8807375431060791
recon_loss: 0.030751682817935944, dist_loss: 0.9488618969917297
recon_loss: 0.030751347541809082, dist_loss: 0.8112319111824036
recon_loss: 0.03075096383690834, dist_loss: 1.2191526889801025
recon_loss: 0.03075052611529827, dist_loss: 0.6417714357376099
recon_loss: 0.030750207602977753, dist_loss: 1.5051923990249634
recon_loss: 0.03075036033987999, dist_loss: 0.7878665328025818
recon_loss: 0.03075084649026394, dist_loss: 0.7911028861999512
recon_loss: 0.03075079806149006, dist_loss: 0.7076557278633118
recon_loss: 0.030750878155231476, dist_loss: 0.47865837812423706
recon_loss: 0.030750906094908714, dist_loss: 0.7268722057342529
recon_loss: 0.030749749392271042, dist_loss: 0.9356432557106018
recon_loss: 0.030748732388019562, dist_loss: 1.013149380683899
recon_loss: 0.03074818290770054, dist_loss: 0.4022190272808075
recon_loss: 0.030747441574931145, dist_loss: 0.5441770553588867
recon_loss: 0.03074595332145691, dist_loss: 0.52911776304245
recon_loss: 0.030745208263397217, dist_loss: 0.5521492958068848
recon_loss: 0.03074466809630394, dist_loss: 0.6396377086639404
recon_loss: 0.030744032934308052, dist_loss: 0.49662190675735474
recon_loss: 0.030743349343538284, dist_loss: 0.5240381956100464
recon_loss: 0.030743073672056198, dist_loss: 0.4397677183151245
recon_loss: 0.03074246644973755, dist_loss: 0.7392973303794861
recon_loss: 0.030741626396775246, dist_loss: 0.598610520362854
recon_loss: 0.030740801244974136, dist_loss: 0.4228059947490692
recon_loss: 0.030740465968847275, dist_loss: 0.8104734420776367
recon_loss: 0.030740419402718544, dist_loss: 0.5633241534233093
recon_loss: 0.03073985129594803, dist_loss: 0.9334983229637146
recon_loss: 0.030738966539502144, dist_loss: 0.6980624198913574
recon_loss: 0.030739132314920425, dist_loss: 0.8904187083244324
recon_loss: 0.03073921427130699, dist_loss: 0.6201638579368591
recon_loss: 0.030738169327378273, dist_loss: 0.9164010882377625
recon_loss: 0.030737344175577164, dist_loss: 0.5918753147125244
recon_loss: 0.030736954882740974, dist_loss: 0.819997251033783
recon_loss: 0.03073723055422306, dist_loss: 0.637343168258667
recon_loss: 0.030737152323126793, dist_loss: 0.6016104817390442
recon_loss: 0.030736394226551056, dist_loss: 0.573481023311615
recon_loss: 0.030736010521650314, dist_loss: 0.9653584361076355
recon_loss: 0.030736083164811134, dist_loss: 0.9535605907440186
recon_loss: 0.030735976994037628, dist_loss: 0.7893034219741821
recon_loss: 0.0307354424148798, dist_loss: 0.7958000898361206
recon_loss: 0.030735762789845467, dist_loss: 0.5734239816665649
recon_loss: 0.030736444517970085, dist_loss: 0.5486221313476562
recon_loss: 0.03073597513139248, dist_loss: 0.6041545271873474
recon_loss: 0.030735285952687263, dist_loss: 0.5940728187561035
recon_loss: 0.030734961852431297, dist_loss: 0.4670236110687256
recon_loss: 0.03073466569185257, dist_loss: 0.5071735382080078
recon_loss: 0.030733924359083176, dist_loss: 0.5653496384620667
recon_loss: 0.03073367290198803, dist_loss: 0.932807445526123
recon_loss: 0.03073347546160221, dist_loss: 1.0492427349090576
recon_loss: 0.030733143910765648, dist_loss: 0.7332068681716919
recon_loss: 0.030731797218322754, dist_loss: 0.6666529178619385
recon_loss: 0.030730586498975754, dist_loss: 0.9327417016029358
recon_loss: 0.03072974644601345, dist_loss: 0.4831050932407379
recon_loss: 0.03072868473827839, dist_loss: 0.47521719336509705
recon_loss: 0.0307272020727396, dist_loss: 0.6856714487075806
recon_loss: 0.03072606585919857, dist_loss: 1.0573850870132446
recon_loss: 0.030725939199328423, dist_loss: 0.3717692494392395
recon_loss: 0.030725441873073578, dist_loss: 0.6567708253860474
recon_loss: 0.03072476014494896, dist_loss: 0.8550622463226318
recon_loss: 0.03072424605488777, dist_loss: 0.4413432478904724
recon_loss: 0.030723681673407555, dist_loss: 0.6845722198486328
recon_loss: 0.03072282113134861, dist_loss: 0.638076663017273
recon_loss: 0.030721602961421013, dist_loss: 1.1016484498977661
recon_loss: 0.030720550566911697, dist_loss: 0.6395817995071411
recon_loss: 0.030720304697752, dist_loss: 0.8035867214202881
recon_loss: 0.030720284208655357, dist_loss: 0.9485983848571777
recon_loss: 0.030720187351107597, dist_loss: 0.7167385816574097
recon_loss: 0.030720455572009087, dist_loss: 0.6260851621627808
recon_loss: 0.03072097897529602, dist_loss: 0.20080843567848206
recon_loss: 0.030720505863428116, dist_loss: 0.46561694145202637
recon_loss: 0.030718903988599777, dist_loss: 0.5744003057479858
recon_loss: 0.03071712516248226, dist_loss: 0.9922438263893127
recon_loss: 0.030716240406036377, dist_loss: 0.6391509771347046
recon_loss: 0.03071524202823639, dist_loss: 0.5531014800071716
recon_loss: 0.030713766813278198, dist_loss: 0.38717469573020935
Pre-training Epoch 30:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 30:   4%|▍         | 15/367 [00:00<00:02, 145.80it/s]Pre-training Epoch 30:   8%|▊         | 31/367 [00:00<00:02, 151.69it/s]Pre-training Epoch 30:  13%|█▎        | 47/367 [00:00<00:02, 149.52it/s]Pre-training Epoch 30:  17%|█▋        | 63/367 [00:00<00:02, 151.87it/s]Pre-training Epoch 30:  22%|██▏       | 79/367 [00:00<00:01, 152.25it/s]Pre-training Epoch 30:  26%|██▌       | 95/367 [00:00<00:01, 153.83it/s]Pre-training Epoch 30:  30%|███       | 111/367 [00:00<00:01, 154.07it/s]Pre-training Epoch 30:  35%|███▍      | 127/367 [00:00<00:01, 154.83it/s]recon_loss: 0.030713103711605072, dist_loss: 0.48833444714546204
recon_loss: 0.030712777748703957, dist_loss: 1.1241095066070557
recon_loss: 0.03071250393986702, dist_loss: 0.49553364515304565
recon_loss: 0.030712220817804337, dist_loss: 0.987297534942627
recon_loss: 0.030711980536580086, dist_loss: 0.9068071246147156
recon_loss: 0.030711723491549492, dist_loss: 0.6308339238166809
recon_loss: 0.030711349099874496, dist_loss: 0.6166161894798279
recon_loss: 0.03071083128452301, dist_loss: 0.6829308271408081
recon_loss: 0.03071015328168869, dist_loss: 0.708665668964386
recon_loss: 0.030709605664014816, dist_loss: 0.37010860443115234
recon_loss: 0.03070911578834057, dist_loss: 1.3010432720184326
recon_loss: 0.030708208680152893, dist_loss: 0.45278602838516235
recon_loss: 0.030707012861967087, dist_loss: 1.0084147453308105
recon_loss: 0.03070632554590702, dist_loss: 0.6017196774482727
recon_loss: 0.030705926939845085, dist_loss: 0.6348167657852173
recon_loss: 0.03070509247481823, dist_loss: 0.38677066564559937
recon_loss: 0.03070458583533764, dist_loss: 0.8209460377693176
recon_loss: 0.030705079436302185, dist_loss: 0.8466386795043945
recon_loss: 0.030704783275723457, dist_loss: 0.6284867525100708
recon_loss: 0.030703650787472725, dist_loss: 0.65569669008255
recon_loss: 0.03070313110947609, dist_loss: 0.7785348892211914
recon_loss: 0.030703241005539894, dist_loss: 0.45822787284851074
recon_loss: 0.03070252016186714, dist_loss: 1.3665804862976074
recon_loss: 0.030701592564582825, dist_loss: 0.5463829040527344
recon_loss: 0.03070153295993805, dist_loss: 0.6490235328674316
recon_loss: 0.030701840296387672, dist_loss: 0.9786103963851929
recon_loss: 0.03070143796503544, dist_loss: 0.8528778553009033
recon_loss: 0.03070078231394291, dist_loss: 0.5536708235740662
recon_loss: 0.03070097230374813, dist_loss: 0.7401245832443237
recon_loss: 0.03070111945271492, dist_loss: 0.7174438238143921
recon_loss: 0.030700435861945152, dist_loss: 0.848863422870636
recon_loss: 0.030700143426656723, dist_loss: 0.5872558951377869
recon_loss: 0.030699504539370537, dist_loss: 0.9494500160217285
recon_loss: 0.03069869987666607, dist_loss: 0.7601896524429321
recon_loss: 0.030697444453835487, dist_loss: 1.2376198768615723
recon_loss: 0.030696677044034004, dist_loss: 0.5304467678070068
recon_loss: 0.030696392059326172, dist_loss: 0.8295930027961731
recon_loss: 0.03069591149687767, dist_loss: 1.042724370956421
recon_loss: 0.0306951142847538, dist_loss: 0.5650709867477417
recon_loss: 0.030694549903273582, dist_loss: 0.4052695333957672
recon_loss: 0.03069448657333851, dist_loss: 1.1946614980697632
recon_loss: 0.03069375269114971, dist_loss: 0.4888240694999695
recon_loss: 0.030692804604768753, dist_loss: 0.34554535150527954
recon_loss: 0.03069215826690197, dist_loss: 0.9377269744873047
recon_loss: 0.030691558495163918, dist_loss: 0.5889526605606079
recon_loss: 0.03069090098142624, dist_loss: 0.5164952278137207
recon_loss: 0.030690260231494904, dist_loss: 0.5314511060714722
recon_loss: 0.030689794570207596, dist_loss: 0.8435741662979126
recon_loss: 0.030689673498272896, dist_loss: 0.7041593790054321
recon_loss: 0.030689405277371407, dist_loss: 0.42802733182907104
recon_loss: 0.030688868835568428, dist_loss: 0.6274498105049133
recon_loss: 0.03068850189447403, dist_loss: 0.8473879098892212
recon_loss: 0.030688410624861717, dist_loss: 0.6130902767181396
recon_loss: 0.030688181519508362, dist_loss: 0.3890262842178345
recon_loss: 0.030687525868415833, dist_loss: 0.3421212434768677
recon_loss: 0.03068661130964756, dist_loss: 0.51948082447052
recon_loss: 0.03068576380610466, dist_loss: 0.44361940026283264
recon_loss: 0.030685383826494217, dist_loss: 0.7429108023643494
recon_loss: 0.030684586614370346, dist_loss: 0.40826380252838135
recon_loss: 0.03068375401198864, dist_loss: 0.5898508429527283
recon_loss: 0.030683333054184914, dist_loss: 0.6964113712310791
recon_loss: 0.030683131888508797, dist_loss: 0.5371496677398682
recon_loss: 0.030682997778058052, dist_loss: 1.299753189086914
recon_loss: 0.030682500451803207, dist_loss: 0.5522663593292236
recon_loss: 0.030681585893034935, dist_loss: 0.6424973011016846
recon_loss: 0.030680937692523003, dist_loss: 0.7203943729400635
recon_loss: 0.030680712312459946, dist_loss: 0.581100344657898
recon_loss: 0.030680563300848007, dist_loss: 0.6094716191291809
recon_loss: 0.030679749324917793, dist_loss: 0.5267192125320435
recon_loss: 0.03067941591143608, dist_loss: 0.578285276889801
recon_loss: 0.030679134652018547, dist_loss: 0.4348909556865692
recon_loss: 0.030678577721118927, dist_loss: 0.7809655666351318
recon_loss: 0.030677445232868195, dist_loss: 0.6289209127426147
recon_loss: 0.030677398666739464, dist_loss: 0.594010591506958
recon_loss: 0.03067730739712715, dist_loss: 0.8254993557929993
recon_loss: 0.03067694418132305, dist_loss: 0.7001127004623413
recon_loss: 0.030675804242491722, dist_loss: 0.6249100565910339
recon_loss: 0.030675532296299934, dist_loss: 0.622798502445221
recon_loss: 0.030675722286105156, dist_loss: 0.7582508325576782
recon_loss: 0.030675193294882774, dist_loss: 0.36455821990966797
recon_loss: 0.030674628913402557, dist_loss: 0.348755419254303
recon_loss: 0.03067435696721077, dist_loss: 0.8470783233642578
recon_loss: 0.030674373731017113, dist_loss: 0.535712718963623
recon_loss: 0.030673934146761894, dist_loss: 0.9041796922683716
recon_loss: 0.030672963708639145, dist_loss: 0.6528611183166504
recon_loss: 0.030672360211610794, dist_loss: 0.9214727878570557
recon_loss: 0.03067292831838131, dist_loss: 0.7389808297157288
recon_loss: 0.030672596767544746, dist_loss: 0.4966477155685425
recon_loss: 0.030671361833810806, dist_loss: 0.7146229147911072
recon_loss: 0.030670667067170143, dist_loss: 0.5919750928878784
recon_loss: 0.0306705292314291, dist_loss: 0.5796110033988953
recon_loss: 0.030670471489429474, dist_loss: 0.7928193211555481
recon_loss: 0.03066992200911045, dist_loss: 0.3529629111289978
recon_loss: 0.030669232830405235, dist_loss: 0.7594601511955261
recon_loss: 0.030668888241052628, dist_loss: 0.8851526379585266
recon_loss: 0.03066871128976345, dist_loss: 0.6327023506164551
recon_loss: 0.030668217688798904, dist_loss: 0.7629655599594116
recon_loss: 0.030668126419186592, dist_loss: 0.5715490579605103
recon_loss: 0.030668245628476143, dist_loss: 0.7376604080200195
recon_loss: 0.030668048188090324, dist_loss: 0.9054211974143982
recon_loss: 0.030667459592223167, dist_loss: 0.6879012584686279
recon_loss: 0.030666781589388847, dist_loss: 1.1983319520950317
recon_loss: 0.030666261911392212, dist_loss: 0.5864887833595276
recon_loss: 0.030665921047329903, dist_loss: 0.470321923494339
recon_loss: 0.030665302649140358, dist_loss: 1.0816404819488525
recon_loss: 0.03066457249224186, dist_loss: 1.0665462017059326
recon_loss: 0.030664244666695595, dist_loss: 0.6370505094528198
recon_loss: 0.030664291232824326, dist_loss: 0.3234953284263611
recon_loss: 0.030664054676890373, dist_loss: 0.47572439908981323
recon_loss: 0.030664121732115746, dist_loss: 1.1100305318832397
recon_loss: 0.030664071440696716, dist_loss: 0.6268121004104614
recon_loss: 0.030664190649986267, dist_loss: 0.8268591165542603
recon_loss: 0.03066415712237358, dist_loss: 0.6100544333457947
recon_loss: 0.030663680285215378, dist_loss: 0.5151920914649963
recon_loss: 0.03066321834921837, dist_loss: 0.575760006904602
recon_loss: 0.030662422999739647, dist_loss: 0.8139597773551941
recon_loss: 0.030661849305033684, dist_loss: 0.7223941087722778
recon_loss: 0.030661333352327347, dist_loss: 0.7559403777122498
recon_loss: 0.030661072582006454, dist_loss: 0.8284103870391846
recon_loss: 0.03066086769104004, dist_loss: 0.4185642898082733
recon_loss: 0.03066031076014042, dist_loss: 0.6382401585578918
recon_loss: 0.03065953403711319, dist_loss: 0.7413762807846069
recon_loss: 0.03065868653357029, dist_loss: 0.6114919185638428
recon_loss: 0.030657783150672913, dist_loss: 0.6109651327133179
recon_loss: 0.030656930059194565, dist_loss: 0.5503873229026794
recon_loss: 0.030656082555651665, dist_loss: 0.4209015965461731
recon_loss: 0.03065556101500988, dist_loss: 0.5000956654548645
recon_loss: 0.030654622241854668, dist_loss: 0.7876180410385132
Pre-training Epoch 30:  39%|███▉      | 143/367 [00:00<00:01, 153.56it/s]Pre-training Epoch 30:  43%|████▎     | 159/367 [00:01<00:01, 152.89it/s]Pre-training Epoch 30:  48%|████▊     | 175/367 [00:01<00:01, 152.71it/s]Pre-training Epoch 30:  52%|█████▏    | 191/367 [00:01<00:01, 153.42it/s]Pre-training Epoch 30:  57%|█████▋    | 208/367 [00:01<00:01, 157.87it/s]Pre-training Epoch 30:  62%|██████▏   | 227/367 [00:01<00:00, 165.43it/s]Pre-training Epoch 30:  67%|██████▋   | 245/367 [00:01<00:00, 169.70it/s]recon_loss: 0.03065367601811886, dist_loss: 0.7251795530319214
recon_loss: 0.030653104186058044, dist_loss: 0.40775439143180847
recon_loss: 0.030652906745672226, dist_loss: 0.8062903881072998
recon_loss: 0.03065287135541439, dist_loss: 0.631380558013916
recon_loss: 0.030652914196252823, dist_loss: 0.9106705784797668
recon_loss: 0.0306529738008976, dist_loss: 0.7800073027610779
recon_loss: 0.03065284714102745, dist_loss: 0.6338155269622803
recon_loss: 0.030652999877929688, dist_loss: 0.4827571511268616
recon_loss: 0.03065314330160618, dist_loss: 0.6562708616256714
recon_loss: 0.030652562156319618, dist_loss: 0.528972327709198
recon_loss: 0.03065134771168232, dist_loss: 0.8353182077407837
recon_loss: 0.030651072040200233, dist_loss: 0.27887144684791565
recon_loss: 0.030651235952973366, dist_loss: 0.8015868067741394
recon_loss: 0.030651235952973366, dist_loss: 0.7773023843765259
recon_loss: 0.03065117821097374, dist_loss: 0.9715330600738525
recon_loss: 0.030650833621621132, dist_loss: 0.5813354849815369
recon_loss: 0.0306503027677536, dist_loss: 0.917472243309021
recon_loss: 0.030650105327367783, dist_loss: 0.677054762840271
recon_loss: 0.030649466440081596, dist_loss: 0.6105543375015259
recon_loss: 0.030648401007056236, dist_loss: 0.6374502182006836
recon_loss: 0.030647501349449158, dist_loss: 0.6981585621833801
recon_loss: 0.03064734674990177, dist_loss: 0.9099957346916199
recon_loss: 0.030647508800029755, dist_loss: 0.4459225833415985
recon_loss: 0.03064688853919506, dist_loss: 0.4712375998497009
recon_loss: 0.030645914375782013, dist_loss: 0.6234911680221558
recon_loss: 0.03064546175301075, dist_loss: 0.8355051279067993
recon_loss: 0.030644964426755905, dist_loss: 0.6883811950683594
recon_loss: 0.030644139274954796, dist_loss: 0.42959028482437134
recon_loss: 0.030643345788121223, dist_loss: 0.6027371883392334
recon_loss: 0.030642829835414886, dist_loss: 0.509483814239502
recon_loss: 0.030642258003354073, dist_loss: 0.7209962010383606
recon_loss: 0.03064170852303505, dist_loss: 0.5794482827186584
recon_loss: 0.030641278252005577, dist_loss: 0.9609007835388184
recon_loss: 0.03064078651368618, dist_loss: 0.454535573720932
recon_loss: 0.03064044564962387, dist_loss: 0.9982944130897522
recon_loss: 0.030640028417110443, dist_loss: 0.5497519969940186
recon_loss: 0.030639562755823135, dist_loss: 0.6720210313796997
recon_loss: 0.03063913993537426, dist_loss: 0.41313302516937256
recon_loss: 0.030638741329312325, dist_loss: 0.36212214827537537
recon_loss: 0.030638307332992554, dist_loss: 0.4570122957229614
recon_loss: 0.03063787706196308, dist_loss: 0.49504294991493225
recon_loss: 0.030637459829449654, dist_loss: 0.40647709369659424
recon_loss: 0.030637022107839584, dist_loss: 1.0237078666687012
recon_loss: 0.030636591836810112, dist_loss: 0.9042303562164307
recon_loss: 0.030636047944426537, dist_loss: 0.6719656586647034
recon_loss: 0.030635487288236618, dist_loss: 0.6327163577079773
recon_loss: 0.03063485585153103, dist_loss: 0.6775350570678711
recon_loss: 0.03063439019024372, dist_loss: 0.5174434781074524
recon_loss: 0.030633963644504547, dist_loss: 0.7266446948051453
recon_loss: 0.030633119866251945, dist_loss: 0.5957306027412415
recon_loss: 0.03063245676457882, dist_loss: 0.43964725732803345
recon_loss: 0.030632026493549347, dist_loss: 0.4328324794769287
recon_loss: 0.030631940811872482, dist_loss: 0.48040804266929626
recon_loss: 0.03063199110329151, dist_loss: 0.5611531734466553
recon_loss: 0.030632244423031807, dist_loss: 0.3787236213684082
recon_loss: 0.03063247725367546, dist_loss: 0.8090252876281738
recon_loss: 0.030632145702838898, dist_loss: 0.6062755584716797
recon_loss: 0.030631734058260918, dist_loss: 0.8516861796379089
recon_loss: 0.03063136711716652, dist_loss: 0.70680171251297
recon_loss: 0.030630964785814285, dist_loss: 0.6556110978126526
recon_loss: 0.030629966408014297, dist_loss: 0.4665260910987854
recon_loss: 0.030629245564341545, dist_loss: 0.507592499256134
recon_loss: 0.0306291151791811, dist_loss: 0.376716285943985
recon_loss: 0.030628744512796402, dist_loss: 1.0216803550720215
recon_loss: 0.030628610402345657, dist_loss: 0.7139295339584351
recon_loss: 0.030628656968474388, dist_loss: 1.0372962951660156
recon_loss: 0.030628984794020653, dist_loss: 0.8269445300102234
recon_loss: 0.030629213899374008, dist_loss: 0.9295792579650879
recon_loss: 0.030629336833953857, dist_loss: 0.7026840448379517
recon_loss: 0.030628638342022896, dist_loss: 0.5265246629714966
recon_loss: 0.030628159642219543, dist_loss: 0.8080409169197083
recon_loss: 0.03062688186764717, dist_loss: 0.3985012173652649
recon_loss: 0.030625971034169197, dist_loss: 0.5455131530761719
recon_loss: 0.030625054612755775, dist_loss: 0.8320753574371338
recon_loss: 0.03062492609024048, dist_loss: 0.6238579750061035
recon_loss: 0.03062460944056511, dist_loss: 0.40990695357322693
recon_loss: 0.0306248739361763, dist_loss: 0.764498233795166
recon_loss: 0.03062504716217518, dist_loss: 0.7875939607620239
recon_loss: 0.03062503971159458, dist_loss: 0.7346992492675781
recon_loss: 0.03062453120946884, dist_loss: 0.32651689648628235
recon_loss: 0.030623752623796463, dist_loss: 1.0754168033599854
recon_loss: 0.030622731894254684, dist_loss: 1.1525795459747314
recon_loss: 0.030621059238910675, dist_loss: 1.019957184791565
recon_loss: 0.030619453638792038, dist_loss: 0.7328068017959595
recon_loss: 0.030618147924542427, dist_loss: 0.5910478234291077
recon_loss: 0.030617354437708855, dist_loss: 1.0408605337142944
recon_loss: 0.030616426840424538, dist_loss: 1.1009583473205566
recon_loss: 0.03061552718281746, dist_loss: 0.5346948504447937
recon_loss: 0.030615054070949554, dist_loss: 0.5986121296882629
recon_loss: 0.030614839866757393, dist_loss: 0.6839495897293091
recon_loss: 0.03061426430940628, dist_loss: 0.9932001233100891
recon_loss: 0.030613593757152557, dist_loss: 0.9891929626464844
recon_loss: 0.030613211914896965, dist_loss: 0.5768382549285889
recon_loss: 0.030613336712121964, dist_loss: 0.45023113489151
recon_loss: 0.03061230294406414, dist_loss: 0.4544520378112793
recon_loss: 0.030611490830779076, dist_loss: 0.758326530456543
recon_loss: 0.03061152622103691, dist_loss: 0.7977024912834167
recon_loss: 0.030611632391810417, dist_loss: 1.0716919898986816
recon_loss: 0.030611127614974976, dist_loss: 0.4477885663509369
recon_loss: 0.030610863119363785, dist_loss: 0.5255813598632812
recon_loss: 0.030610935762524605, dist_loss: 0.7803534269332886
recon_loss: 0.03061065822839737, dist_loss: 0.5429965257644653
recon_loss: 0.03061002306640148, dist_loss: 0.6288390755653381
recon_loss: 0.03061005473136902, dist_loss: 0.46306881308555603
recon_loss: 0.03061031922698021, dist_loss: 0.9304147362709045
recon_loss: 0.030609969049692154, dist_loss: 0.7209091186523438
recon_loss: 0.030609281733632088, dist_loss: 0.6951001882553101
recon_loss: 0.030608801171183586, dist_loss: 0.5944017171859741
recon_loss: 0.03060934878885746, dist_loss: 0.6099185347557068
recon_loss: 0.03060903213918209, dist_loss: 0.6407082080841064
recon_loss: 0.03060862235724926, dist_loss: 0.9107364416122437
recon_loss: 0.030608737841248512, dist_loss: 0.48396432399749756
recon_loss: 0.030608942732214928, dist_loss: 0.7165350317955017
recon_loss: 0.03060844913125038, dist_loss: 0.4071692228317261
recon_loss: 0.030607929453253746, dist_loss: 0.7463785409927368
recon_loss: 0.03060770407319069, dist_loss: 0.692536473274231
recon_loss: 0.03060723841190338, dist_loss: 0.5712082982063293
recon_loss: 0.030606219545006752, dist_loss: 1.0118311643600464
recon_loss: 0.030605435371398926, dist_loss: 0.9959186315536499
recon_loss: 0.030604824423789978, dist_loss: 0.6610066890716553
recon_loss: 0.030603893101215363, dist_loss: 0.8774547576904297
recon_loss: 0.03060271218419075, dist_loss: 0.6409115791320801
recon_loss: 0.030601970851421356, dist_loss: 0.7407546043395996
recon_loss: 0.030601371079683304, dist_loss: 0.8741798996925354
recon_loss: 0.030600637197494507, dist_loss: 0.8603472113609314
recon_loss: 0.030599504709243774, dist_loss: 0.7912468910217285
recon_loss: 0.030598992481827736, dist_loss: 0.660245418548584
recon_loss: 0.03059866465628147, dist_loss: 0.8641164898872375
Pre-training Epoch 30:  72%|███████▏  | 263/367 [00:01<00:00, 172.05it/s]Pre-training Epoch 30:  77%|███████▋  | 281/367 [00:01<00:00, 173.80it/s]Pre-training Epoch 30:  82%|████████▏ | 300/367 [00:01<00:00, 175.89it/s]Pre-training Epoch 30:  87%|████████▋ | 318/367 [00:01<00:00, 176.52it/s]Pre-training Epoch 30:  92%|█████████▏| 336/367 [00:02<00:00, 176.40it/s]Pre-training Epoch 30:  96%|█████████▋| 354/367 [00:02<00:00, 176.94it/s]Pre-training Epoch 30: 100%|██████████| 367/367 [00:02<00:00, 163.86it/s]
recon_loss: 0.030597800388932228, dist_loss: 1.0758386850357056
recon_loss: 0.030597319826483727, dist_loss: 0.6014003753662109
recon_loss: 0.03059755265712738, dist_loss: 1.1919291019439697
recon_loss: 0.03059770166873932, dist_loss: 1.1198395490646362
recon_loss: 0.0305975042283535, dist_loss: 1.311769723892212
recon_loss: 0.030597059056162834, dist_loss: 1.4336732625961304
recon_loss: 0.030596459284424782, dist_loss: 0.5896901488304138
recon_loss: 0.030595745891332626, dist_loss: 0.7337943315505981
recon_loss: 0.030594857409596443, dist_loss: 0.5357553958892822
recon_loss: 0.030593981966376305, dist_loss: 0.5392678380012512
recon_loss: 0.03059338964521885, dist_loss: 0.6666203737258911
recon_loss: 0.0305931493639946, dist_loss: 0.749284029006958
recon_loss: 0.030592916533350945, dist_loss: 0.433038592338562
recon_loss: 0.03059264086186886, dist_loss: 0.712856650352478
recon_loss: 0.030592288821935654, dist_loss: 0.8124902248382568
recon_loss: 0.030591929331421852, dist_loss: 0.5319130420684814
recon_loss: 0.03059174120426178, dist_loss: 0.8254005908966064
recon_loss: 0.03059140034019947, dist_loss: 0.3908003568649292
recon_loss: 0.030590631067752838, dist_loss: 0.85111403465271
recon_loss: 0.030590012669563293, dist_loss: 0.5892215967178345
recon_loss: 0.030589571222662926, dist_loss: 0.3223002552986145
recon_loss: 0.030589226633310318, dist_loss: 0.7611823678016663
recon_loss: 0.030589057132601738, dist_loss: 0.6351606845855713
recon_loss: 0.030589472502470016, dist_loss: 0.6357288956642151
recon_loss: 0.030589831992983818, dist_loss: 0.46198251843452454
recon_loss: 0.030589353293180466, dist_loss: 0.5161892771720886
recon_loss: 0.03058864362537861, dist_loss: 0.9584006667137146
recon_loss: 0.030588502064347267, dist_loss: 1.579054355621338
recon_loss: 0.030588295310735703, dist_loss: 0.9667609333992004
recon_loss: 0.03058757819235325, dist_loss: 0.6132586598396301
recon_loss: 0.03058694675564766, dist_loss: 0.5144506692886353
recon_loss: 0.03058655932545662, dist_loss: 0.6781826019287109
recon_loss: 0.03058652952313423, dist_loss: 0.6227969527244568
recon_loss: 0.030586520209908485, dist_loss: 0.4957599639892578
recon_loss: 0.030586224049329758, dist_loss: 0.550030529499054
recon_loss: 0.030585845932364464, dist_loss: 0.5485256910324097
recon_loss: 0.03058592416346073, dist_loss: 1.097103238105774
recon_loss: 0.03058617003262043, dist_loss: 0.6768646240234375
recon_loss: 0.03058532439172268, dist_loss: 0.5542598366737366
recon_loss: 0.030584733933210373, dist_loss: 1.0051592588424683
recon_loss: 0.030584674328565598, dist_loss: 0.2932293117046356
recon_loss: 0.03058454394340515, dist_loss: 0.676295280456543
recon_loss: 0.030583513900637627, dist_loss: 0.9807603359222412
recon_loss: 0.03058260679244995, dist_loss: 0.547235906124115
recon_loss: 0.030583016574382782, dist_loss: 0.5138449668884277
recon_loss: 0.030583424493670464, dist_loss: 0.5096537470817566
recon_loss: 0.030582567676901817, dist_loss: 0.5885463953018188
recon_loss: 0.030582109466195107, dist_loss: 1.1145179271697998
recon_loss: 0.030582521110773087, dist_loss: 0.6643831133842468
recon_loss: 0.030582429841160774, dist_loss: 0.9128051996231079
recon_loss: 0.030582444742321968, dist_loss: 0.43614816665649414
recon_loss: 0.030583051964640617, dist_loss: 0.8256170153617859
recon_loss: 0.030582914128899574, dist_loss: 0.5402228236198425
recon_loss: 0.03058229573071003, dist_loss: 0.6178666353225708
recon_loss: 0.03058178722858429, dist_loss: 1.3734076023101807
recon_loss: 0.030581040307879448, dist_loss: 0.35538995265960693
recon_loss: 0.030580200254917145, dist_loss: 0.5806668996810913
recon_loss: 0.030579183250665665, dist_loss: 0.45474985241889954
recon_loss: 0.03057834692299366, dist_loss: 0.502606213092804
recon_loss: 0.03057762049138546, dist_loss: 0.742516279220581
recon_loss: 0.030576834455132484, dist_loss: 0.7694007158279419
recon_loss: 0.030576206743717194, dist_loss: 0.6641491651535034
recon_loss: 0.03057558462023735, dist_loss: 0.7438253164291382
recon_loss: 0.030575143173336983, dist_loss: 0.5642404556274414
recon_loss: 0.030574774369597435, dist_loss: 0.8350529670715332
recon_loss: 0.030574321746826172, dist_loss: 0.6201286315917969
recon_loss: 0.03057396225631237, dist_loss: 0.6693592071533203
recon_loss: 0.030573619529604912, dist_loss: 0.7425500750541687
recon_loss: 0.030573410913348198, dist_loss: 0.4025005102157593
recon_loss: 0.030573047697544098, dist_loss: 0.5755087733268738
recon_loss: 0.030572514981031418, dist_loss: 0.5221120715141296
recon_loss: 0.030572010204195976, dist_loss: 0.7679318189620972
recon_loss: 0.03057156875729561, dist_loss: 0.7129361629486084
recon_loss: 0.03057120554149151, dist_loss: 0.7210073471069336
recon_loss: 0.030570730566978455, dist_loss: 0.762687087059021
recon_loss: 0.030570300295948982, dist_loss: 0.6112593412399292
recon_loss: 0.030569713562726974, dist_loss: 0.7295013666152954
recon_loss: 0.030569227412343025, dist_loss: 0.7341275215148926
recon_loss: 0.030569259077310562, dist_loss: 0.6513182520866394
recon_loss: 0.030569590628147125, dist_loss: 0.7882274389266968
recon_loss: 0.030568750575184822, dist_loss: 0.8064494132995605
recon_loss: 0.0305681973695755, dist_loss: 0.5670661926269531
recon_loss: 0.03056865558028221, dist_loss: 0.5757157802581787
recon_loss: 0.030568253248929977, dist_loss: 0.5777285099029541
recon_loss: 0.03056674264371395, dist_loss: 0.5074002742767334
recon_loss: 0.03056582808494568, dist_loss: 0.5170596837997437
recon_loss: 0.03056616336107254, dist_loss: 0.8092533349990845
recon_loss: 0.030565716326236725, dist_loss: 0.618280827999115
recon_loss: 0.030564533546566963, dist_loss: 0.6673072576522827
recon_loss: 0.030564051121473312, dist_loss: 0.6044172048568726
recon_loss: 0.030564427375793457, dist_loss: 0.5309579968452454
recon_loss: 0.030563760548830032, dist_loss: 1.0093188285827637
recon_loss: 0.0305622611194849, dist_loss: 0.5090843439102173
recon_loss: 0.030562493950128555, dist_loss: 0.5237530469894409
recon_loss: 0.030562441796064377, dist_loss: 0.5347968339920044
recon_loss: 0.03056124597787857, dist_loss: 1.040809154510498
recon_loss: 0.030560484156012535, dist_loss: 0.3925241529941559
recon_loss: 0.030560659244656563, dist_loss: 0.3880120813846588
recon_loss: 0.030560355633497238, dist_loss: 0.47660356760025024
recon_loss: 0.030559290200471878, dist_loss: 0.3480767607688904
recon_loss: 0.030558714643120766, dist_loss: 1.1502503156661987
recon_loss: 0.03055928274989128, dist_loss: 0.9582658410072327
recon_loss: 0.030559325590729713, dist_loss: 0.48760539293289185
recon_loss: 0.03055868297815323, dist_loss: 0.6657992601394653
recon_loss: 0.03055911511182785, dist_loss: 0.7050808072090149
recon_loss: 0.030559953302145004, dist_loss: 0.5735716819763184
recon_loss: 0.030559679493308067, dist_loss: 0.3569479286670685
recon_loss: 0.030559008941054344, dist_loss: 0.6531736850738525
recon_loss: 0.030558867380023003, dist_loss: 0.6444964408874512
recon_loss: 0.03055785782635212, dist_loss: 0.41104188561439514
recon_loss: 0.030556878075003624, dist_loss: 1.05209481716156
Pre-train Epoch: 30
Train - Total Loss: 0.0993, Recon Loss: 0.0306, Dist Loss: 0.6863, l1 regularization: 0.0000
Val - Total Loss: 0.1032, Recon Loss: 0.0306, Dist Loss: 0.7260, l1 regularization: 0.0000
Pre-training Epoch 31:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 31:   4%|▍         | 16/367 [00:00<00:02, 150.10it/s]Pre-training Epoch 31:   9%|▊         | 32/367 [00:00<00:02, 146.96it/s]Pre-training Epoch 31:  13%|█▎        | 48/367 [00:00<00:02, 150.63it/s]Pre-training Epoch 31:  17%|█▋        | 64/367 [00:00<00:01, 153.31it/s]Pre-training Epoch 31:  22%|██▏       | 80/367 [00:00<00:01, 154.51it/s]Pre-training Epoch 31:  27%|██▋       | 98/367 [00:00<00:01, 162.79it/s]Pre-training Epoch 31:  32%|███▏      | 116/367 [00:00<00:01, 168.18it/s]recon_loss: 0.030556440353393555, dist_loss: 0.5442980527877808
recon_loss: 0.03055630624294281, dist_loss: 0.46978896856307983
recon_loss: 0.030556445941329002, dist_loss: 0.4784383773803711
recon_loss: 0.03055640123784542, dist_loss: 0.7669975161552429
recon_loss: 0.030556010082364082, dist_loss: 0.699506402015686
recon_loss: 0.030555514618754387, dist_loss: 0.67900550365448
recon_loss: 0.03055492229759693, dist_loss: 0.8732787370681763
recon_loss: 0.03055422380566597, dist_loss: 0.8715635538101196
recon_loss: 0.030553806573152542, dist_loss: 0.4274333119392395
recon_loss: 0.030553651973605156, dist_loss: 0.75126713514328
recon_loss: 0.030553363263607025, dist_loss: 0.7871204018592834
recon_loss: 0.03055300936102867, dist_loss: 0.9034059047698975
recon_loss: 0.030552491545677185, dist_loss: 0.6654810905456543
recon_loss: 0.03055165521800518, dist_loss: 0.8181976079940796
recon_loss: 0.030551165342330933, dist_loss: 0.6532494425773621
recon_loss: 0.03055163472890854, dist_loss: 0.8310384154319763
recon_loss: 0.030551817268133163, dist_loss: 0.43867531418800354
recon_loss: 0.030552208423614502, dist_loss: 0.6768917441368103
recon_loss: 0.03055245243012905, dist_loss: 0.5337119102478027
recon_loss: 0.030553165823221207, dist_loss: 1.0289478302001953
recon_loss: 0.030553672462701797, dist_loss: 0.9451324939727783
recon_loss: 0.030553871765732765, dist_loss: 0.4226522445678711
recon_loss: 0.030553722754120827, dist_loss: 0.6507279872894287
recon_loss: 0.030553899705410004, dist_loss: 0.44899702072143555
recon_loss: 0.030553702265024185, dist_loss: 0.8208616971969604
recon_loss: 0.030552681535482407, dist_loss: 0.5013163685798645
recon_loss: 0.030551869422197342, dist_loss: 0.675762414932251
recon_loss: 0.030551139265298843, dist_loss: 0.9526677131652832
recon_loss: 0.030549947172403336, dist_loss: 0.5557852387428284
recon_loss: 0.030548352748155594, dist_loss: 0.6559796333312988
recon_loss: 0.03054705448448658, dist_loss: 0.27822422981262207
recon_loss: 0.030546270310878754, dist_loss: 0.3387279212474823
recon_loss: 0.030545243993401527, dist_loss: 0.5663871765136719
recon_loss: 0.03054404817521572, dist_loss: 0.9888638854026794
recon_loss: 0.030543355271220207, dist_loss: 0.9119253158569336
recon_loss: 0.03054329939186573, dist_loss: 0.7718179821968079
recon_loss: 0.030542587861418724, dist_loss: 0.6719216108322144
recon_loss: 0.03054186701774597, dist_loss: 0.5851728916168213
recon_loss: 0.03054152801632881, dist_loss: 0.5656949281692505
recon_loss: 0.03054145723581314, dist_loss: 0.5558152198791504
recon_loss: 0.03054129146039486, dist_loss: 0.48046639561653137
recon_loss: 0.030541183426976204, dist_loss: 0.9564956426620483
recon_loss: 0.03054092824459076, dist_loss: 0.6383548378944397
recon_loss: 0.03054041415452957, dist_loss: 0.9376245737075806
recon_loss: 0.030539795756340027, dist_loss: 0.8106948137283325
recon_loss: 0.03053930215537548, dist_loss: 0.4315396249294281
recon_loss: 0.03053903765976429, dist_loss: 0.3852834403514862
recon_loss: 0.030538776889443398, dist_loss: 0.735694169998169
recon_loss: 0.030538391321897507, dist_loss: 0.8054812550544739
recon_loss: 0.030537929385900497, dist_loss: 0.7698650360107422
recon_loss: 0.030537428334355354, dist_loss: 0.6400410532951355
recon_loss: 0.030537238344550133, dist_loss: 0.7005645632743835
recon_loss: 0.03053751029074192, dist_loss: 1.3598971366882324
recon_loss: 0.03053855709731579, dist_loss: 0.5206281542778015
recon_loss: 0.030539482831954956, dist_loss: 1.2386400699615479
recon_loss: 0.030541017651557922, dist_loss: 0.5392870903015137
recon_loss: 0.03054279088973999, dist_loss: 0.559516966342926
recon_loss: 0.030544474720954895, dist_loss: 0.9267356395721436
recon_loss: 0.03054540604352951, dist_loss: 1.2162599563598633
recon_loss: 0.030544932931661606, dist_loss: 0.4870591461658478
recon_loss: 0.030543938279151917, dist_loss: 0.45092275738716125
recon_loss: 0.030542727559804916, dist_loss: 0.7458089590072632
recon_loss: 0.03054232895374298, dist_loss: 0.3445533514022827
recon_loss: 0.030542420223355293, dist_loss: 0.941137433052063
recon_loss: 0.03054245375096798, dist_loss: 0.3084257245063782
recon_loss: 0.030542608350515366, dist_loss: 0.6649293303489685
recon_loss: 0.03054325096309185, dist_loss: 0.9429218173027039
recon_loss: 0.030543504282832146, dist_loss: 0.5191426277160645
recon_loss: 0.03054286539554596, dist_loss: 0.6169734001159668
recon_loss: 0.030541585758328438, dist_loss: 0.44122305512428284
recon_loss: 0.0305403433740139, dist_loss: 0.5653208494186401
recon_loss: 0.030538048595190048, dist_loss: 0.5481232404708862
recon_loss: 0.03053600899875164, dist_loss: 0.694398045539856
recon_loss: 0.030534394085407257, dist_loss: 0.7779769897460938
recon_loss: 0.030533336102962494, dist_loss: 0.516196608543396
recon_loss: 0.030532898381352425, dist_loss: 0.4498036801815033
recon_loss: 0.03053291141986847, dist_loss: 0.6230741143226624
recon_loss: 0.030533194541931152, dist_loss: 1.0733296871185303
recon_loss: 0.030533261597156525, dist_loss: 0.820260763168335
recon_loss: 0.030533036217093468, dist_loss: 0.37342503666877747
recon_loss: 0.03053244575858116, dist_loss: 0.7197588682174683
recon_loss: 0.030531534925103188, dist_loss: 0.6414598226547241
recon_loss: 0.03053060732781887, dist_loss: 0.9567388296127319
recon_loss: 0.0305298063904047, dist_loss: 0.8237635493278503
recon_loss: 0.030528996139764786, dist_loss: 0.8364517688751221
recon_loss: 0.030528239905834198, dist_loss: 0.5372029542922974
recon_loss: 0.03052763268351555, dist_loss: 1.0807719230651855
recon_loss: 0.03052721731364727, dist_loss: 0.5703433752059937
recon_loss: 0.030526921153068542, dist_loss: 0.7870655059814453
recon_loss: 0.030526624992489815, dist_loss: 0.6332387328147888
recon_loss: 0.030526595190167427, dist_loss: 0.6701446771621704
recon_loss: 0.030526574701070786, dist_loss: 0.6559361219406128
recon_loss: 0.030525915324687958, dist_loss: 0.6129294037818909
recon_loss: 0.030525272712111473, dist_loss: 0.8571454882621765
recon_loss: 0.030524902045726776, dist_loss: 1.3371613025665283
recon_loss: 0.030524492263793945, dist_loss: 0.7829304933547974
recon_loss: 0.030524125322699547, dist_loss: 0.9468911290168762
recon_loss: 0.03052382916212082, dist_loss: 0.8079343438148499
recon_loss: 0.03052365407347679, dist_loss: 0.9250414371490479
recon_loss: 0.030523426830768585, dist_loss: 0.8498015403747559
recon_loss: 0.030523434281349182, dist_loss: 1.03944993019104
recon_loss: 0.030523275956511497, dist_loss: 0.5735751390457153
recon_loss: 0.030523046851158142, dist_loss: 0.4475241005420685
recon_loss: 0.030523035675287247, dist_loss: 0.8595889806747437
recon_loss: 0.030523018911480904, dist_loss: 0.7825528979301453
recon_loss: 0.030522983521223068, dist_loss: 0.5788894295692444
recon_loss: 0.030522584915161133, dist_loss: 0.5292595028877258
recon_loss: 0.030522499233484268, dist_loss: 1.0843850374221802
recon_loss: 0.030522439628839493, dist_loss: 0.7409828901290894
recon_loss: 0.030522258952260017, dist_loss: 0.542823851108551
recon_loss: 0.030521811917424202, dist_loss: 0.9428550601005554
recon_loss: 0.03052130714058876, dist_loss: 0.4967285990715027
recon_loss: 0.030521154403686523, dist_loss: 0.42125600576400757
recon_loss: 0.03052091784775257, dist_loss: 0.6204280853271484
recon_loss: 0.030520597472786903, dist_loss: 0.6646916270256042
recon_loss: 0.030520088970661163, dist_loss: 0.5847517251968384
recon_loss: 0.030520131811499596, dist_loss: 0.7194077968597412
recon_loss: 0.03052043914794922, dist_loss: 0.5235587358474731
recon_loss: 0.03052031248807907, dist_loss: 1.1512391567230225
recon_loss: 0.03052002564072609, dist_loss: 0.6826914548873901
recon_loss: 0.03052038885653019, dist_loss: 0.6339424848556519
recon_loss: 0.030520174652338028, dist_loss: 0.3592424690723419
recon_loss: 0.030520029366016388, dist_loss: 0.4065976142883301
recon_loss: 0.030520033091306686, dist_loss: 0.4244852364063263
recon_loss: 0.030520068481564522, dist_loss: 1.0686839818954468
recon_loss: 0.030519645661115646, dist_loss: 0.3200226426124573
recon_loss: 0.030519263818860054, dist_loss: 0.5730962157249451
recon_loss: 0.030519496649503708, dist_loss: 0.5882576704025269
Pre-training Epoch 31:  37%|███▋      | 135/367 [00:00<00:01, 172.43it/s]Pre-training Epoch 31:  42%|████▏     | 154/367 [00:00<00:01, 175.01it/s]Pre-training Epoch 31:  47%|████▋     | 173/367 [00:01<00:01, 176.86it/s]Pre-training Epoch 31:  52%|█████▏    | 191/367 [00:01<00:01, 170.18it/s]Pre-training Epoch 31:  57%|█████▋    | 209/367 [00:01<00:00, 168.78it/s]Pre-training Epoch 31:  62%|██████▏   | 227/367 [00:01<00:00, 169.18it/s]Pre-training Epoch 31:  67%|██████▋   | 245/367 [00:01<00:00, 172.09it/s]recon_loss: 0.03051912970840931, dist_loss: 0.5262179374694824
recon_loss: 0.03051856905221939, dist_loss: 0.6938968896865845
recon_loss: 0.03051808476448059, dist_loss: 0.9257344007492065
recon_loss: 0.030517449602484703, dist_loss: 0.4423952102661133
recon_loss: 0.030517062172293663, dist_loss: 0.39598047733306885
recon_loss: 0.03051671013236046, dist_loss: 0.4040522277355194
recon_loss: 0.030515890568494797, dist_loss: 0.648189902305603
recon_loss: 0.030515121296048164, dist_loss: 0.4747564196586609
recon_loss: 0.030514264479279518, dist_loss: 1.1281812191009521
recon_loss: 0.030514154583215714, dist_loss: 0.47308164834976196
recon_loss: 0.03051391802728176, dist_loss: 0.6742823123931885
recon_loss: 0.030514169484376907, dist_loss: 0.8170658349990845
recon_loss: 0.03051454946398735, dist_loss: 0.9967776536941528
recon_loss: 0.030514437705278397, dist_loss: 0.5956681966781616
recon_loss: 0.030514607205986977, dist_loss: 0.6340601444244385
recon_loss: 0.030514581128954887, dist_loss: 0.8053269982337952
recon_loss: 0.03051474690437317, dist_loss: 0.672879695892334
recon_loss: 0.030514927580952644, dist_loss: 0.5249979496002197
recon_loss: 0.030515242367982864, dist_loss: 0.5597473382949829
recon_loss: 0.030515436083078384, dist_loss: 0.5702137351036072
recon_loss: 0.03051503747701645, dist_loss: 0.42469069361686707
recon_loss: 0.030513692647218704, dist_loss: 1.1832560300827026
recon_loss: 0.03051166981458664, dist_loss: 0.2858866751194
recon_loss: 0.030509786680340767, dist_loss: 0.5102947950363159
recon_loss: 0.030508046969771385, dist_loss: 0.7039591073989868
recon_loss: 0.030507002025842667, dist_loss: 0.8378747701644897
recon_loss: 0.030507056042551994, dist_loss: 0.5494924783706665
recon_loss: 0.030507704243063927, dist_loss: 0.6315297484397888
recon_loss: 0.030507897958159447, dist_loss: 0.8471564650535583
recon_loss: 0.030508220195770264, dist_loss: 0.47119423747062683
recon_loss: 0.030508145689964294, dist_loss: 0.4582632780075073
recon_loss: 0.0305071622133255, dist_loss: 0.46819257736206055
recon_loss: 0.030506089329719543, dist_loss: 0.47970059514045715
recon_loss: 0.030505403876304626, dist_loss: 0.6851255297660828
recon_loss: 0.030504776164889336, dist_loss: 0.6880459785461426
recon_loss: 0.03050377033650875, dist_loss: 0.6758003234863281
recon_loss: 0.030502988025546074, dist_loss: 0.4822055399417877
recon_loss: 0.030502665787935257, dist_loss: 0.46685075759887695
recon_loss: 0.03050217591226101, dist_loss: 0.6435194611549377
recon_loss: 0.03050168603658676, dist_loss: 0.5441834926605225
recon_loss: 0.030502086505293846, dist_loss: 0.44135355949401855
recon_loss: 0.030501915141940117, dist_loss: 0.6888791918754578
recon_loss: 0.03050130419433117, dist_loss: 0.9542780518531799
recon_loss: 0.030501123517751694, dist_loss: 0.6989593505859375
recon_loss: 0.030501004308462143, dist_loss: 1.082680344581604
recon_loss: 0.030500587075948715, dist_loss: 0.6750999689102173
recon_loss: 0.030499516054987907, dist_loss: 0.7345943450927734
recon_loss: 0.030498819425702095, dist_loss: 1.0468757152557373
recon_loss: 0.03049841709434986, dist_loss: 0.940333366394043
recon_loss: 0.03049800917506218, dist_loss: 0.5252552032470703
recon_loss: 0.030497204512357712, dist_loss: 0.3644469082355499
recon_loss: 0.030496643856167793, dist_loss: 0.7392728328704834
recon_loss: 0.030496766790747643, dist_loss: 0.4694143533706665
recon_loss: 0.030496712774038315, dist_loss: 0.6558240652084351
recon_loss: 0.03049613907933235, dist_loss: 0.5884189009666443
recon_loss: 0.03049565479159355, dist_loss: 0.653230607509613
recon_loss: 0.030496174469590187, dist_loss: 1.0942327976226807
recon_loss: 0.030495954677462578, dist_loss: 0.7695926427841187
recon_loss: 0.030495164915919304, dist_loss: 0.6584512591362
recon_loss: 0.030494507402181625, dist_loss: 0.9766292572021484
recon_loss: 0.03049461357295513, dist_loss: 0.43014782667160034
recon_loss: 0.03049439564347267, dist_loss: 0.9210102558135986
recon_loss: 0.030494175851345062, dist_loss: 0.7873295545578003
recon_loss: 0.030494797974824905, dist_loss: 1.2623698711395264
recon_loss: 0.030495669692754745, dist_loss: 0.7477070689201355
recon_loss: 0.03049621172249317, dist_loss: 1.0374829769134521
recon_loss: 0.030496127903461456, dist_loss: 1.0692908763885498
recon_loss: 0.030495228245854378, dist_loss: 0.5158460140228271
recon_loss: 0.030493875965476036, dist_loss: 0.9494689106941223
recon_loss: 0.030493251979351044, dist_loss: 0.45380863547325134
recon_loss: 0.03049316816031933, dist_loss: 0.769505500793457
recon_loss: 0.030493153259158134, dist_loss: 0.5649021863937378
recon_loss: 0.030492940917611122, dist_loss: 0.6565303206443787
recon_loss: 0.03049282170832157, dist_loss: 0.7905029654502869
recon_loss: 0.030492659658193588, dist_loss: 1.0865592956542969
recon_loss: 0.030492573976516724, dist_loss: 0.8294709920883179
recon_loss: 0.030492398887872696, dist_loss: 0.6284911036491394
recon_loss: 0.030491938814520836, dist_loss: 0.27432382106781006
recon_loss: 0.030491512268781662, dist_loss: 0.48779433965682983
recon_loss: 0.03049112856388092, dist_loss: 0.8970613479614258
recon_loss: 0.030490534380078316, dist_loss: 0.4266476631164551
recon_loss: 0.03048999235033989, dist_loss: 0.6696257591247559
recon_loss: 0.03048948384821415, dist_loss: 0.486561119556427
recon_loss: 0.030489152297377586, dist_loss: 0.4391947388648987
recon_loss: 0.030488615855574608, dist_loss: 0.7239656448364258
recon_loss: 0.03048846125602722, dist_loss: 0.6662269830703735
recon_loss: 0.030488446354866028, dist_loss: 0.9671878218650818
recon_loss: 0.030487945303320885, dist_loss: 0.3107653856277466
recon_loss: 0.030487345531582832, dist_loss: 0.40069735050201416
recon_loss: 0.030487196519970894, dist_loss: 0.9393620491027832
recon_loss: 0.030486347153782845, dist_loss: 0.6033213138580322
recon_loss: 0.0304857287555933, dist_loss: 0.7681325674057007
recon_loss: 0.030485475435853004, dist_loss: 0.5343424081802368
recon_loss: 0.03048512525856495, dist_loss: 0.3438151776790619
recon_loss: 0.03048454411327839, dist_loss: 0.4302327036857605
recon_loss: 0.03048417717218399, dist_loss: 0.5550940036773682
recon_loss: 0.03048384189605713, dist_loss: 1.0141335725784302
recon_loss: 0.030483348295092583, dist_loss: 0.6303004026412964
recon_loss: 0.030482757836580276, dist_loss: 1.078474998474121
recon_loss: 0.030482320114970207, dist_loss: 0.5317240357398987
recon_loss: 0.03048250451683998, dist_loss: 0.4710393249988556
recon_loss: 0.03048253245651722, dist_loss: 0.5805359482765198
recon_loss: 0.03048258274793625, dist_loss: 0.6128950715065002
recon_loss: 0.030482489615678787, dist_loss: 0.4441260099411011
recon_loss: 0.03048250824213028, dist_loss: 0.6920062303543091
recon_loss: 0.030482247471809387, dist_loss: 0.9632652401924133
recon_loss: 0.030481982976198196, dist_loss: 0.5191618800163269
recon_loss: 0.030481932684779167, dist_loss: 0.45749518275260925
recon_loss: 0.030482010915875435, dist_loss: 0.5291081070899963
recon_loss: 0.03048212267458439, dist_loss: 0.5323652029037476
recon_loss: 0.030482161790132523, dist_loss: 0.6169992685317993
recon_loss: 0.030482426285743713, dist_loss: 0.5844001770019531
recon_loss: 0.030481912195682526, dist_loss: 0.5490846633911133
recon_loss: 0.03048141859471798, dist_loss: 0.6587596535682678
recon_loss: 0.03048117086291313, dist_loss: 0.7472732663154602
recon_loss: 0.03048093058168888, dist_loss: 0.5817105770111084
recon_loss: 0.03048016130924225, dist_loss: 0.5152873992919922
recon_loss: 0.03047938458621502, dist_loss: 0.5449376106262207
recon_loss: 0.030478954315185547, dist_loss: 0.671043336391449
recon_loss: 0.030478524044156075, dist_loss: 0.5068520903587341
recon_loss: 0.03047780878841877, dist_loss: 0.6123759746551514
recon_loss: 0.030477240681648254, dist_loss: 0.4980977177619934
recon_loss: 0.03047669306397438, dist_loss: 0.8012300729751587
recon_loss: 0.03047635406255722, dist_loss: 0.7918345928192139
recon_loss: 0.030475687235593796, dist_loss: 0.590876579284668
recon_loss: 0.030474910512566566, dist_loss: 0.8431836366653442
recon_loss: 0.030474385246634483, dist_loss: 0.5787572860717773
recon_loss: 0.03047405742108822, dist_loss: 0.581332802772522
Pre-training Epoch 31:  72%|███████▏  | 263/367 [00:01<00:00, 172.97it/s]Pre-training Epoch 31:  77%|███████▋  | 281/367 [00:01<00:00, 174.74it/s]Pre-training Epoch 31:  81%|████████▏ | 299/367 [00:01<00:00, 176.18it/s]Pre-training Epoch 31:  86%|████████▋ | 317/367 [00:01<00:00, 177.23it/s]Pre-training Epoch 31:  91%|█████████▏| 335/367 [00:01<00:00, 177.91it/s]Pre-training Epoch 31:  96%|█████████▌| 353/367 [00:02<00:00, 177.42it/s]Pre-training Epoch 31: 100%|██████████| 367/367 [00:02<00:00, 170.00it/s]
recon_loss: 0.03047376126050949, dist_loss: 0.36096110939979553
recon_loss: 0.030473493039608, dist_loss: 0.28064003586769104
recon_loss: 0.03047332353889942, dist_loss: 0.8394473791122437
recon_loss: 0.030473237857222557, dist_loss: 0.435346782207489
recon_loss: 0.030473027378320694, dist_loss: 1.212965965270996
recon_loss: 0.03047240898013115, dist_loss: 0.684970498085022
recon_loss: 0.030471742153167725, dist_loss: 0.5573025941848755
recon_loss: 0.03047129139304161, dist_loss: 0.503946840763092
recon_loss: 0.03047061711549759, dist_loss: 0.7325718402862549
recon_loss: 0.03047008439898491, dist_loss: 0.889910101890564
recon_loss: 0.030469555407762527, dist_loss: 0.6104252338409424
recon_loss: 0.03046916052699089, dist_loss: 0.8613163232803345
recon_loss: 0.03046865202486515, dist_loss: 0.7416753768920898
recon_loss: 0.03046797402203083, dist_loss: 0.8845218420028687
recon_loss: 0.030467282980680466, dist_loss: 0.5994383692741394
recon_loss: 0.030466975644230843, dist_loss: 0.6925921440124512
recon_loss: 0.0304665919393301, dist_loss: 0.43674251437187195
recon_loss: 0.03046642243862152, dist_loss: 0.5349287986755371
recon_loss: 0.030466845259070396, dist_loss: 0.5848857164382935
recon_loss: 0.03046717680990696, dist_loss: 0.9921592473983765
recon_loss: 0.03046680986881256, dist_loss: 0.3809241056442261
recon_loss: 0.030467212200164795, dist_loss: 0.6421865224838257
recon_loss: 0.030467625707387924, dist_loss: 0.8135515451431274
recon_loss: 0.03046727553009987, dist_loss: 0.5948247909545898
recon_loss: 0.030466627329587936, dist_loss: 0.6885432004928589
recon_loss: 0.030467156320810318, dist_loss: 0.9164018630981445
recon_loss: 0.03046831302344799, dist_loss: 1.035477876663208
recon_loss: 0.030467748641967773, dist_loss: 0.5263304710388184
recon_loss: 0.03046783246099949, dist_loss: 0.9734530448913574
recon_loss: 0.03046836331486702, dist_loss: 0.6180161237716675
recon_loss: 0.03046797402203083, dist_loss: 0.7481328845024109
recon_loss: 0.030466919764876366, dist_loss: 0.8086385726928711
recon_loss: 0.0304665919393301, dist_loss: 0.5618385672569275
recon_loss: 0.030466372147202492, dist_loss: 0.9891096353530884
recon_loss: 0.03046577237546444, dist_loss: 0.8798959255218506
recon_loss: 0.030464738607406616, dist_loss: 0.5253440141677856
recon_loss: 0.030464090406894684, dist_loss: 0.9566246271133423
recon_loss: 0.030463755130767822, dist_loss: 0.9030323624610901
recon_loss: 0.03046325594186783, dist_loss: 0.7919080257415771
recon_loss: 0.0304626002907753, dist_loss: 0.8220959901809692
recon_loss: 0.030462011694908142, dist_loss: 0.6099458336830139
recon_loss: 0.030461909249424934, dist_loss: 0.5589189529418945
recon_loss: 0.030462222173810005, dist_loss: 0.5130578279495239
recon_loss: 0.030461983755230904, dist_loss: 0.6975597143173218
recon_loss: 0.030461890622973442, dist_loss: 0.6135370135307312
recon_loss: 0.03046201914548874, dist_loss: 1.1179969310760498
recon_loss: 0.030462153255939484, dist_loss: 0.7475157976150513
recon_loss: 0.03046179935336113, dist_loss: 1.0819575786590576
recon_loss: 0.03046192042529583, dist_loss: 0.32737061381340027
recon_loss: 0.030462149530649185, dist_loss: 0.8214887380599976
recon_loss: 0.030461683869361877, dist_loss: 0.42933130264282227
recon_loss: 0.030461357906460762, dist_loss: 0.7693918943405151
recon_loss: 0.030461054295301437, dist_loss: 0.5066455006599426
recon_loss: 0.03046036697924137, dist_loss: 0.6721700429916382
recon_loss: 0.030459456145763397, dist_loss: 0.2641410827636719
recon_loss: 0.030458781868219376, dist_loss: 0.44115108251571655
recon_loss: 0.030458224937319756, dist_loss: 0.5167815685272217
recon_loss: 0.030457304790616035, dist_loss: 0.8165050745010376
recon_loss: 0.03045628033578396, dist_loss: 0.6395859122276306
recon_loss: 0.030455900356173515, dist_loss: 0.9243176579475403
recon_loss: 0.03045511618256569, dist_loss: 0.6341709494590759
recon_loss: 0.030454473569989204, dist_loss: 0.7151650786399841
recon_loss: 0.030453680083155632, dist_loss: 0.3497563600540161
recon_loss: 0.03045317903161049, dist_loss: 0.4649202227592468
recon_loss: 0.030452847480773926, dist_loss: 0.5255659818649292
recon_loss: 0.03045247308909893, dist_loss: 0.8334516882896423
recon_loss: 0.030452068895101547, dist_loss: 1.2967450618743896
recon_loss: 0.03045143000781536, dist_loss: 1.1386889219284058
recon_loss: 0.030450917780399323, dist_loss: 0.9010969400405884
recon_loss: 0.03045019507408142, dist_loss: 0.6396329402923584
recon_loss: 0.03044928051531315, dist_loss: 0.5390032529830933
recon_loss: 0.030448680743575096, dist_loss: 0.5970977544784546
recon_loss: 0.030448267236351967, dist_loss: 0.4107706546783447
recon_loss: 0.03044774942100048, dist_loss: 0.8069391250610352
recon_loss: 0.030447205528616905, dist_loss: 0.6773359775543213
recon_loss: 0.030446292832493782, dist_loss: 0.4464542269706726
recon_loss: 0.030445646494627, dist_loss: 1.0644941329956055
recon_loss: 0.030445102602243423, dist_loss: 0.2798983156681061
recon_loss: 0.03044450283050537, dist_loss: 0.3726878762245178
recon_loss: 0.030444124713540077, dist_loss: 0.8652116060256958
recon_loss: 0.03044392727315426, dist_loss: 0.6442691683769226
recon_loss: 0.030443614348769188, dist_loss: 0.6847420930862427
recon_loss: 0.030443314462900162, dist_loss: 0.5213022232055664
recon_loss: 0.03044332191348076, dist_loss: 0.8356382846832275
recon_loss: 0.030442604795098305, dist_loss: 1.1660616397857666
recon_loss: 0.030442124232649803, dist_loss: 1.0246371030807495
recon_loss: 0.03044210374355316, dist_loss: 0.6039837002754211
recon_loss: 0.030442187562584877, dist_loss: 0.3663080632686615
recon_loss: 0.03044162318110466, dist_loss: 0.6476209163665771
recon_loss: 0.030441472306847572, dist_loss: 0.6602073907852173
recon_loss: 0.030441317707300186, dist_loss: 0.9747428297996521
recon_loss: 0.030440809205174446, dist_loss: 0.4968740940093994
recon_loss: 0.030439740046858788, dist_loss: 1.1255139112472534
recon_loss: 0.03043878637254238, dist_loss: 0.9280333518981934
recon_loss: 0.030438438057899475, dist_loss: 0.8504394292831421
recon_loss: 0.03043818660080433, dist_loss: 0.6120810508728027
recon_loss: 0.030437981709837914, dist_loss: 0.5443204641342163
recon_loss: 0.030438071116805077, dist_loss: 0.8381288051605225
recon_loss: 0.030438007786870003, dist_loss: 0.48195508122444153
recon_loss: 0.03043699823319912, dist_loss: 1.04786217212677
recon_loss: 0.030436210334300995, dist_loss: 0.3933926522731781
recon_loss: 0.030435653403401375, dist_loss: 1.5241997241973877
recon_loss: 0.030435265973210335, dist_loss: 0.81560218334198
recon_loss: 0.030434608459472656, dist_loss: 0.6433446407318115
recon_loss: 0.03043413907289505, dist_loss: 0.8440552949905396
recon_loss: 0.0304336529225111, dist_loss: 0.417538046836853
recon_loss: 0.03043309971690178, dist_loss: 0.37414151430130005
recon_loss: 0.030432622879743576, dist_loss: 0.9563760757446289
recon_loss: 0.03043205477297306, dist_loss: 0.7981736660003662
recon_loss: 0.030431631952524185, dist_loss: 0.37369856238365173
recon_loss: 0.03043113648891449, dist_loss: 0.9868637323379517
Pre-training Epoch 32:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 32:   5%|▍         | 17/367 [00:00<00:02, 169.90it/s]Pre-training Epoch 32:  10%|▉         | 36/367 [00:00<00:01, 177.44it/s]Pre-training Epoch 32:  15%|█▍        | 54/367 [00:00<00:01, 178.09it/s]Pre-training Epoch 32:  20%|█▉        | 72/367 [00:00<00:01, 169.18it/s]Pre-training Epoch 32:  24%|██▍       | 89/367 [00:00<00:01, 161.73it/s]Pre-training Epoch 32:  29%|██▉       | 106/367 [00:00<00:01, 159.60it/s]Pre-training Epoch 32:  34%|███▎      | 123/367 [00:00<00:01, 157.12it/s]recon_loss: 0.03043091855943203, dist_loss: 0.7028420567512512
recon_loss: 0.030430594459176064, dist_loss: 0.3899434208869934
recon_loss: 0.030429963022470474, dist_loss: 1.0585490465164185
recon_loss: 0.03042951412498951, dist_loss: 0.8058455586433411
recon_loss: 0.030429238453507423, dist_loss: 0.7744556665420532
recon_loss: 0.030429068952798843, dist_loss: 0.5745986700057983
recon_loss: 0.030428539961576462, dist_loss: 1.26048743724823
recon_loss: 0.030427860096096992, dist_loss: 0.39116907119750977
recon_loss: 0.03042733296751976, dist_loss: 0.49694591760635376
recon_loss: 0.030427126213908195, dist_loss: 0.5047396421432495
recon_loss: 0.03042709454894066, dist_loss: 0.5305581092834473
recon_loss: 0.030427178367972374, dist_loss: 0.5179360508918762
recon_loss: 0.030427249148488045, dist_loss: 0.6956017017364502
recon_loss: 0.03042653575539589, dist_loss: 1.4792451858520508
recon_loss: 0.03042551316320896, dist_loss: 0.44155773520469666
recon_loss: 0.030424389988183975, dist_loss: 0.8290711641311646
recon_loss: 0.030424224212765694, dist_loss: 0.28492236137390137
recon_loss: 0.03042442910373211, dist_loss: 1.1453394889831543
recon_loss: 0.030423423275351524, dist_loss: 0.6664433479309082
recon_loss: 0.030423589050769806, dist_loss: 0.7424144744873047
recon_loss: 0.030424049124121666, dist_loss: 0.43849503993988037
recon_loss: 0.030423322692513466, dist_loss: 0.6263469457626343
recon_loss: 0.030422450974583626, dist_loss: 0.36910709738731384
recon_loss: 0.030422188341617584, dist_loss: 0.6260263919830322
recon_loss: 0.030421465635299683, dist_loss: 1.2282484769821167
recon_loss: 0.0304202139377594, dist_loss: 0.5899368524551392
recon_loss: 0.03042011521756649, dist_loss: 0.7624587416648865
recon_loss: 0.03042062185704708, dist_loss: 0.7179625034332275
recon_loss: 0.03042050264775753, dist_loss: 0.7900750637054443
recon_loss: 0.030421221628785133, dist_loss: 0.47459661960601807
recon_loss: 0.030421920120716095, dist_loss: 0.6013376116752625
recon_loss: 0.030422097072005272, dist_loss: 0.5603376030921936
recon_loss: 0.030421346426010132, dist_loss: 0.94720059633255
recon_loss: 0.0304202139377594, dist_loss: 0.6706660389900208
recon_loss: 0.030419444665312767, dist_loss: 0.5820303559303284
recon_loss: 0.030418146401643753, dist_loss: 0.7055935263633728
recon_loss: 0.030417704954743385, dist_loss: 0.6332645416259766
recon_loss: 0.030418191105127335, dist_loss: 0.34961920976638794
recon_loss: 0.030418479815125465, dist_loss: 0.5308820009231567
recon_loss: 0.030418075621128082, dist_loss: 0.5004252791404724
recon_loss: 0.030417930334806442, dist_loss: 0.9540750980377197
recon_loss: 0.030417997390031815, dist_loss: 0.7099618911743164
recon_loss: 0.03041718527674675, dist_loss: 0.6631298065185547
recon_loss: 0.030416544526815414, dist_loss: 0.9786758422851562
recon_loss: 0.030416222289204597, dist_loss: 0.6341954469680786
recon_loss: 0.030416088178753853, dist_loss: 0.6422408223152161
recon_loss: 0.030415914952754974, dist_loss: 0.6612042784690857
recon_loss: 0.030416127294301987, dist_loss: 0.8122950196266174
recon_loss: 0.03041626140475273, dist_loss: 0.6541247367858887
recon_loss: 0.030416348949074745, dist_loss: 1.1498947143554688
recon_loss: 0.030416175723075867, dist_loss: 0.5920423269271851
recon_loss: 0.03041595034301281, dist_loss: 0.9016478061676025
recon_loss: 0.030416250228881836, dist_loss: 0.6774656772613525
recon_loss: 0.030416671186685562, dist_loss: 0.6461673974990845
recon_loss: 0.03041647933423519, dist_loss: 0.6477750539779663
recon_loss: 0.03041624091565609, dist_loss: 0.6335804462432861
recon_loss: 0.030416205525398254, dist_loss: 0.5277389883995056
recon_loss: 0.030415968969464302, dist_loss: 0.5392966270446777
recon_loss: 0.03041536547243595, dist_loss: 0.6300007700920105
recon_loss: 0.030414411798119545, dist_loss: 0.4050792455673218
recon_loss: 0.030413279309868813, dist_loss: 0.5244889259338379
recon_loss: 0.030412252992391586, dist_loss: 0.6704517602920532
recon_loss: 0.03041115216910839, dist_loss: 0.5053733587265015
recon_loss: 0.030410217121243477, dist_loss: 0.8696626424789429
recon_loss: 0.030409494414925575, dist_loss: 0.41696810722351074
recon_loss: 0.03040904551744461, dist_loss: 0.5903128385543823
recon_loss: 0.030408594757318497, dist_loss: 0.3591134250164032
recon_loss: 0.030408062040805817, dist_loss: 1.1027929782867432
recon_loss: 0.030407831072807312, dist_loss: 1.0051424503326416
recon_loss: 0.030407831072807312, dist_loss: 0.6095330715179443
recon_loss: 0.03040754608809948, dist_loss: 0.4038758873939514
recon_loss: 0.03040742687880993, dist_loss: 0.9861326217651367
recon_loss: 0.03040744736790657, dist_loss: 0.5647186040878296
recon_loss: 0.030407560989260674, dist_loss: 0.8439810276031494
recon_loss: 0.030407419428229332, dist_loss: 0.5378507375717163
recon_loss: 0.03040715493261814, dist_loss: 0.7621359825134277
recon_loss: 0.030406780540943146, dist_loss: 0.928768515586853
recon_loss: 0.030406149104237556, dist_loss: 0.6768082976341248
recon_loss: 0.030405329540371895, dist_loss: 0.7380551099777222
recon_loss: 0.03040486015379429, dist_loss: 0.6848088502883911
recon_loss: 0.030404556542634964, dist_loss: 0.6172676086425781
recon_loss: 0.030403925105929375, dist_loss: 0.9494869709014893
recon_loss: 0.03040328063070774, dist_loss: 0.8143627643585205
recon_loss: 0.030403075739741325, dist_loss: 0.26535505056381226
recon_loss: 0.03040270507335663, dist_loss: 0.5927119255065918
recon_loss: 0.03040202707052231, dist_loss: 0.6450846791267395
recon_loss: 0.030401382595300674, dist_loss: 0.5160253643989563
recon_loss: 0.030401194468140602, dist_loss: 0.5627579689025879
recon_loss: 0.03040076419711113, dist_loss: 0.7279922366142273
recon_loss: 0.03040040098130703, dist_loss: 0.8792768716812134
recon_loss: 0.0304003544151783, dist_loss: 0.38872748613357544
recon_loss: 0.030400045216083527, dist_loss: 0.4435405135154724
recon_loss: 0.03039909154176712, dist_loss: 0.6263403296470642
recon_loss: 0.03039880283176899, dist_loss: 0.6780446171760559
recon_loss: 0.03039841167628765, dist_loss: 1.1446106433868408
recon_loss: 0.030397603288292885, dist_loss: 0.3637734651565552
recon_loss: 0.030397552996873856, dist_loss: 0.7079819440841675
recon_loss: 0.030397245660424232, dist_loss: 1.4022717475891113
recon_loss: 0.03039664961397648, dist_loss: 0.4004666805267334
recon_loss: 0.03039615973830223, dist_loss: 0.5863681435585022
recon_loss: 0.030395619571208954, dist_loss: 0.5161654949188232
recon_loss: 0.030395319685339928, dist_loss: 0.7196853160858154
recon_loss: 0.030395008623600006, dist_loss: 0.47325336933135986
recon_loss: 0.03039480745792389, dist_loss: 0.6639655828475952
recon_loss: 0.030394673347473145, dist_loss: 0.7388826608657837
recon_loss: 0.030394336208701134, dist_loss: 0.5057328343391418
recon_loss: 0.030394067987799644, dist_loss: 0.41850417852401733
recon_loss: 0.030393870547413826, dist_loss: 0.6031973958015442
recon_loss: 0.03039410337805748, dist_loss: 0.6657233238220215
recon_loss: 0.03039362281560898, dist_loss: 1.0365991592407227
recon_loss: 0.030393235385417938, dist_loss: 0.7608833312988281
recon_loss: 0.03039373643696308, dist_loss: 0.5009000897407532
recon_loss: 0.030394045636057854, dist_loss: 0.5178828239440918
recon_loss: 0.030393848195672035, dist_loss: 0.9242611527442932
recon_loss: 0.03039288893342018, dist_loss: 1.1159710884094238
recon_loss: 0.030392032116651535, dist_loss: 0.6684815883636475
recon_loss: 0.03039156273007393, dist_loss: 0.707416832447052
recon_loss: 0.03039126843214035, dist_loss: 0.5786600112915039
recon_loss: 0.03039133921265602, dist_loss: 0.45350223779678345
recon_loss: 0.030391428619623184, dist_loss: 0.42324966192245483
recon_loss: 0.030391303822398186, dist_loss: 0.6743948459625244
recon_loss: 0.03039097599685192, dist_loss: 0.8656662702560425
recon_loss: 0.030390707775950432, dist_loss: 0.7997435331344604
recon_loss: 0.030390214174985886, dist_loss: 0.6914628744125366
recon_loss: 0.030390016734600067, dist_loss: 0.761259913444519
recon_loss: 0.03038928285241127, dist_loss: 0.6682221293449402
recon_loss: 0.030388640239834785, dist_loss: 0.7678125500679016
recon_loss: 0.030388090759515762, dist_loss: 0.559454619884491
Pre-training Epoch 32:  38%|███▊      | 139/367 [00:00<00:01, 154.89it/s]Pre-training Epoch 32:  42%|████▏     | 155/367 [00:00<00:01, 155.35it/s]Pre-training Epoch 32:  47%|████▋     | 171/367 [00:01<00:01, 154.27it/s]Pre-training Epoch 32:  51%|█████     | 187/367 [00:01<00:01, 153.77it/s]Pre-training Epoch 32:  55%|█████▌    | 203/367 [00:01<00:01, 154.12it/s]Pre-training Epoch 32:  60%|█████▉    | 219/367 [00:01<00:00, 153.35it/s]Pre-training Epoch 32:  65%|██████▍   | 237/367 [00:01<00:00, 158.53it/s]Pre-training Epoch 32:  69%|██████▉   | 253/367 [00:01<00:00, 154.92it/s]recon_loss: 0.03038773685693741, dist_loss: 0.8909717798233032
recon_loss: 0.030387531965970993, dist_loss: 0.5779744982719421
recon_loss: 0.030387306585907936, dist_loss: 0.37624144554138184
recon_loss: 0.030387144535779953, dist_loss: 0.5658124685287476
recon_loss: 0.03038712963461876, dist_loss: 0.6436017155647278
recon_loss: 0.030386896803975105, dist_loss: 0.7338151335716248
recon_loss: 0.03038681298494339, dist_loss: 0.49309390783309937
recon_loss: 0.03038688376545906, dist_loss: 0.8267899751663208
recon_loss: 0.03038644604384899, dist_loss: 0.42718592286109924
recon_loss: 0.030385810881853104, dist_loss: 0.8000351190567017
recon_loss: 0.030385266989469528, dist_loss: 0.9207043051719666
recon_loss: 0.030384674668312073, dist_loss: 0.6939035058021545
recon_loss: 0.030384039506316185, dist_loss: 1.0382500886917114
recon_loss: 0.030383842065930367, dist_loss: 0.5007840991020203
recon_loss: 0.030383968725800514, dist_loss: 0.8790397644042969
recon_loss: 0.030383383855223656, dist_loss: 0.7013649940490723
recon_loss: 0.03038317896425724, dist_loss: 0.940442681312561
recon_loss: 0.03038315661251545, dist_loss: 0.40038400888442993
recon_loss: 0.030382758006453514, dist_loss: 1.1337645053863525
recon_loss: 0.03038235940039158, dist_loss: 0.4440522789955139
recon_loss: 0.030382007360458374, dist_loss: 0.5770162343978882
recon_loss: 0.030381759628653526, dist_loss: 0.8740592002868652
recon_loss: 0.030381759628653526, dist_loss: 0.5099681615829468
recon_loss: 0.03038138523697853, dist_loss: 1.047658920288086
recon_loss: 0.03038126975297928, dist_loss: 0.7154896259307861
recon_loss: 0.030381565913558006, dist_loss: 0.9666109085083008
recon_loss: 0.03038085252046585, dist_loss: 1.1189913749694824
recon_loss: 0.0303808506578207, dist_loss: 0.4033922553062439
recon_loss: 0.030381182208657265, dist_loss: 0.6358832716941833
recon_loss: 0.030381569638848305, dist_loss: 0.8309476375579834
recon_loss: 0.030381809920072556, dist_loss: 0.5784304141998291
recon_loss: 0.03038197197020054, dist_loss: 1.3044464588165283
recon_loss: 0.030383016914129257, dist_loss: 0.7339935302734375
recon_loss: 0.030384456738829613, dist_loss: 0.6249615550041199
recon_loss: 0.030383961275219917, dist_loss: 0.5929116010665894
recon_loss: 0.03038349561393261, dist_loss: 0.5465141534805298
recon_loss: 0.030384346842765808, dist_loss: 0.5685369372367859
recon_loss: 0.030384063720703125, dist_loss: 0.5141935348510742
recon_loss: 0.030382338911294937, dist_loss: 0.7293609380722046
recon_loss: 0.030381618067622185, dist_loss: 0.32666757702827454
recon_loss: 0.030381424352526665, dist_loss: 0.7555742263793945
recon_loss: 0.030379917472600937, dist_loss: 0.9637496471405029
recon_loss: 0.030378511175513268, dist_loss: 0.5035587549209595
recon_loss: 0.030378146097064018, dist_loss: 0.8929338455200195
recon_loss: 0.0303775854408741, dist_loss: 0.5050310492515564
recon_loss: 0.030376199632883072, dist_loss: 0.5314990282058716
recon_loss: 0.03037552908062935, dist_loss: 0.6068128943443298
recon_loss: 0.030375514179468155, dist_loss: 0.7884227633476257
recon_loss: 0.030375387519598007, dist_loss: 0.8067802786827087
recon_loss: 0.03037484735250473, dist_loss: 0.525773286819458
recon_loss: 0.030374696478247643, dist_loss: 0.7753803730010986
recon_loss: 0.030374886468052864, dist_loss: 0.6843560338020325
recon_loss: 0.03037462942302227, dist_loss: 0.763674795627594
recon_loss: 0.030373871326446533, dist_loss: 1.2401221990585327
recon_loss: 0.030373666435480118, dist_loss: 0.5412453413009644
recon_loss: 0.03037342242896557, dist_loss: 0.5376120805740356
recon_loss: 0.03037281148135662, dist_loss: 0.5272473096847534
recon_loss: 0.030372176319360733, dist_loss: 0.5335972309112549
recon_loss: 0.030371936038136482, dist_loss: 1.1348648071289062
recon_loss: 0.03037174977362156, dist_loss: 0.3813793957233429
recon_loss: 0.03037145733833313, dist_loss: 0.7747065424919128
recon_loss: 0.030371244996786118, dist_loss: 1.1716679334640503
recon_loss: 0.030371196568012238, dist_loss: 0.576574444770813
recon_loss: 0.030371133238077164, dist_loss: 0.363164484500885
recon_loss: 0.030370933935046196, dist_loss: 0.8674719929695129
recon_loss: 0.030370766296982765, dist_loss: 0.723865807056427
recon_loss: 0.030370498076081276, dist_loss: 0.6210736036300659
recon_loss: 0.030370546504855156, dist_loss: 0.6858423948287964
recon_loss: 0.030370814725756645, dist_loss: 0.7568928599357605
recon_loss: 0.030371343716979027, dist_loss: 0.35456448793411255
recon_loss: 0.03037082590162754, dist_loss: 1.0436598062515259
recon_loss: 0.030371153727173805, dist_loss: 0.5924942493438721
recon_loss: 0.03037167899310589, dist_loss: 0.6802603006362915
recon_loss: 0.0303714070469141, dist_loss: 0.7824587821960449
recon_loss: 0.030371153727173805, dist_loss: 0.6320091485977173
recon_loss: 0.03037121705710888, dist_loss: 0.6767727136611938
recon_loss: 0.030372057110071182, dist_loss: 0.7193409204483032
recon_loss: 0.030372444540262222, dist_loss: 0.2680727541446686
recon_loss: 0.030372336506843567, dist_loss: 0.530719518661499
recon_loss: 0.030373087152838707, dist_loss: 0.32173043489456177
recon_loss: 0.030373934656381607, dist_loss: 0.868388295173645
recon_loss: 0.030373474583029747, dist_loss: 0.3885684609413147
recon_loss: 0.030372854322195053, dist_loss: 0.6858647465705872
recon_loss: 0.030373066663742065, dist_loss: 0.6876592636108398
recon_loss: 0.030372967943549156, dist_loss: 0.47058185935020447
recon_loss: 0.03037133999168873, dist_loss: 0.5731728076934814
recon_loss: 0.030370648950338364, dist_loss: 0.6870617866516113
recon_loss: 0.030370624735951424, dist_loss: 0.6335909366607666
recon_loss: 0.030369868502020836, dist_loss: 0.5588812828063965
recon_loss: 0.03036877140402794, dist_loss: 1.399254322052002
recon_loss: 0.030368411913514137, dist_loss: 0.29202190041542053
recon_loss: 0.030368486419320107, dist_loss: 0.5364720821380615
recon_loss: 0.0303671732544899, dist_loss: 0.5855075716972351
recon_loss: 0.030366336926817894, dist_loss: 0.5109747648239136
recon_loss: 0.03036665916442871, dist_loss: 0.5792099237442017
recon_loss: 0.030366364866495132, dist_loss: 0.6469820737838745
recon_loss: 0.030365334823727608, dist_loss: 0.8403478860855103
recon_loss: 0.03036482445895672, dist_loss: 0.4326774477958679
recon_loss: 0.030365141108632088, dist_loss: 0.7258744835853577
recon_loss: 0.03036516159772873, dist_loss: 0.7282989025115967
recon_loss: 0.030364979058504105, dist_loss: 0.44187456369400024
recon_loss: 0.030364999547600746, dist_loss: 1.3555059432983398
recon_loss: 0.030365606769919395, dist_loss: 0.4039458632469177
recon_loss: 0.030365116894245148, dist_loss: 0.46418169140815735
recon_loss: 0.03036443144083023, dist_loss: 0.6473320722579956
recon_loss: 0.03036421723663807, dist_loss: 0.5054764747619629
recon_loss: 0.030364057049155235, dist_loss: 0.5529186725616455
recon_loss: 0.030363401398062706, dist_loss: 1.3786050081253052
recon_loss: 0.03036290407180786, dist_loss: 0.43796345591545105
recon_loss: 0.030362848192453384, dist_loss: 0.5525871515274048
recon_loss: 0.030362501740455627, dist_loss: 0.6121907234191895
recon_loss: 0.030361929908394814, dist_loss: 0.5326038599014282
recon_loss: 0.030361400917172432, dist_loss: 0.8446522951126099
recon_loss: 0.0303609911352396, dist_loss: 0.5447442531585693
recon_loss: 0.030360490083694458, dist_loss: 0.699640154838562
recon_loss: 0.030360480770468712, dist_loss: 0.6957988739013672
recon_loss: 0.03036019764840603, dist_loss: 0.5181999802589417
recon_loss: 0.03035970777273178, dist_loss: 0.8412576913833618
recon_loss: 0.03035985492169857, dist_loss: 1.3221189975738525
recon_loss: 0.030360285192728043, dist_loss: 0.8847239017486572
recon_loss: 0.030359117314219475, dist_loss: 0.649339497089386
recon_loss: 0.03035799227654934, dist_loss: 0.627831757068634
recon_loss: 0.030357981100678444, dist_loss: 0.7157642841339111
recon_loss: 0.03035830706357956, dist_loss: 0.5797104835510254
recon_loss: 0.03035830706357956, dist_loss: 0.66323322057724
recon_loss: 0.03035837970674038, dist_loss: 0.6923940181732178
recon_loss: 0.030358606949448586, dist_loss: 0.6652573347091675
recon_loss: 0.030358528718352318, dist_loss: 0.351546049118042
Pre-training Epoch 32:  73%|███████▎  | 269/367 [00:01<00:00, 155.31it/s]Pre-training Epoch 32:  78%|███████▊  | 285/367 [00:01<00:00, 155.27it/s]Pre-training Epoch 32:  82%|████████▏ | 301/367 [00:01<00:00, 153.97it/s]Pre-training Epoch 32:  86%|████████▋ | 317/367 [00:02<00:00, 153.38it/s]Pre-training Epoch 32:  91%|█████████ | 333/367 [00:02<00:00, 152.56it/s]Pre-training Epoch 32:  95%|█████████▌| 349/367 [00:02<00:00, 154.06it/s]Pre-training Epoch 32:  99%|█████████▉| 365/367 [00:02<00:00, 154.50it/s]Pre-training Epoch 32: 100%|██████████| 367/367 [00:02<00:00, 157.01it/s]
recon_loss: 0.03035818226635456, dist_loss: 0.9959948658943176
recon_loss: 0.030358105897903442, dist_loss: 0.7697291374206543
recon_loss: 0.03035835176706314, dist_loss: 0.9214251041412354
recon_loss: 0.03035820461809635, dist_loss: 0.3407948315143585
recon_loss: 0.030357928946614265, dist_loss: 0.6936866044998169
recon_loss: 0.030357850715517998, dist_loss: 0.6783342361450195
recon_loss: 0.030357470735907555, dist_loss: 1.524189829826355
recon_loss: 0.03035671077668667, dist_loss: 0.7510406970977783
recon_loss: 0.030356165021657944, dist_loss: 0.8405181169509888
recon_loss: 0.030355775728821754, dist_loss: 0.6889525651931763
recon_loss: 0.030355403199791908, dist_loss: 0.44426262378692627
recon_loss: 0.030354812741279602, dist_loss: 0.4539603590965271
recon_loss: 0.030354468151926994, dist_loss: 0.4613555669784546
recon_loss: 0.030353927984833717, dist_loss: 0.4301850199699402
recon_loss: 0.030352946370840073, dist_loss: 0.3155284523963928
recon_loss: 0.030351683497428894, dist_loss: 0.4288070499897003
recon_loss: 0.030350258573889732, dist_loss: 0.5851225852966309
recon_loss: 0.03034886345267296, dist_loss: 0.5110787153244019
recon_loss: 0.030348168686032295, dist_loss: 0.8680093288421631
recon_loss: 0.030348429456353188, dist_loss: 1.0085108280181885
recon_loss: 0.030349114909768105, dist_loss: 0.3682468831539154
recon_loss: 0.03034972958266735, dist_loss: 0.6248492002487183
recon_loss: 0.0303497351706028, dist_loss: 0.7781902551651001
recon_loss: 0.030348902568221092, dist_loss: 0.8374646902084351
recon_loss: 0.030347710475325584, dist_loss: 0.6574270725250244
recon_loss: 0.030346397310495377, dist_loss: 0.682688295841217
recon_loss: 0.030344858765602112, dist_loss: 1.131060242652893
recon_loss: 0.030343666672706604, dist_loss: 0.4878394603729248
recon_loss: 0.03034311719238758, dist_loss: 0.6074807643890381
recon_loss: 0.030343152582645416, dist_loss: 0.7042580246925354
recon_loss: 0.030343232676386833, dist_loss: 0.8558473587036133
recon_loss: 0.03034316562116146, dist_loss: 0.9133428335189819
recon_loss: 0.0303431935608387, dist_loss: 0.4154488146305084
recon_loss: 0.03034292161464691, dist_loss: 0.7338820695877075
recon_loss: 0.03034181147813797, dist_loss: 0.38954728841781616
recon_loss: 0.03034115768969059, dist_loss: 0.3529478907585144
recon_loss: 0.030340900644659996, dist_loss: 0.8895812034606934
recon_loss: 0.030340371653437614, dist_loss: 0.6093212366104126
recon_loss: 0.03034023381769657, dist_loss: 0.6069833636283875
recon_loss: 0.03034041076898575, dist_loss: 0.5596560835838318
recon_loss: 0.030340032652020454, dist_loss: 0.851824164390564
recon_loss: 0.030339673161506653, dist_loss: 0.7164879441261292
recon_loss: 0.030339499935507774, dist_loss: 0.7618909478187561
recon_loss: 0.030339520424604416, dist_loss: 0.4965708255767822
recon_loss: 0.030339542776346207, dist_loss: 0.9410668015480042
recon_loss: 0.030339686200022697, dist_loss: 0.6130169034004211
recon_loss: 0.030339425429701805, dist_loss: 0.546769380569458
recon_loss: 0.030339157208800316, dist_loss: 0.8972474336624146
recon_loss: 0.030339637771248817, dist_loss: 0.8137040138244629
recon_loss: 0.03033922053873539, dist_loss: 0.5503278374671936
recon_loss: 0.0303387138992548, dist_loss: 0.5151089429855347
recon_loss: 0.030338643118739128, dist_loss: 0.9292578101158142
recon_loss: 0.030338462442159653, dist_loss: 0.807471513748169
recon_loss: 0.030338268727064133, dist_loss: 1.0976269245147705
recon_loss: 0.030338387936353683, dist_loss: 0.5967211127281189
recon_loss: 0.030338671058416367, dist_loss: 0.49922704696655273
recon_loss: 0.030338458716869354, dist_loss: 0.634820818901062
recon_loss: 0.030338024720549583, dist_loss: 0.4948856830596924
recon_loss: 0.030337681993842125, dist_loss: 0.4946742653846741
recon_loss: 0.030336977913975716, dist_loss: 0.3504495322704315
recon_loss: 0.030336221680045128, dist_loss: 0.5060654878616333
recon_loss: 0.03033585473895073, dist_loss: 0.64607173204422
recon_loss: 0.030335526913404465, dist_loss: 0.726854145526886
recon_loss: 0.030335841700434685, dist_loss: 0.8747986555099487
recon_loss: 0.030336102470755577, dist_loss: 0.7574800848960876
recon_loss: 0.03033633902668953, dist_loss: 0.5529770851135254
recon_loss: 0.030336327850818634, dist_loss: 0.370368629693985
recon_loss: 0.030336080119013786, dist_loss: 0.5766209959983826
recon_loss: 0.030335459858179092, dist_loss: 0.7015776634216309
recon_loss: 0.030334612354636192, dist_loss: 0.8187071084976196
recon_loss: 0.030333660542964935, dist_loss: 0.8513174057006836
recon_loss: 0.030332615599036217, dist_loss: 0.6155751347541809
recon_loss: 0.030331667512655258, dist_loss: 0.8079935312271118
recon_loss: 0.030330942943692207, dist_loss: 0.44561097025871277
recon_loss: 0.030330326408147812, dist_loss: 0.7629424929618835
recon_loss: 0.03032992035150528, dist_loss: 0.7782857418060303
recon_loss: 0.030329620465636253, dist_loss: 0.6955500841140747
recon_loss: 0.030329426750540733, dist_loss: 0.8384578824043274
recon_loss: 0.030329521745443344, dist_loss: 0.6995440721511841
recon_loss: 0.030329853296279907, dist_loss: 0.6873456239700317
recon_loss: 0.03033006750047207, dist_loss: 0.6041464805603027
recon_loss: 0.030329609289765358, dist_loss: 0.4785417914390564
recon_loss: 0.03032921440899372, dist_loss: 0.7165907025337219
recon_loss: 0.03032955713570118, dist_loss: 0.5108109712600708
recon_loss: 0.030329277738928795, dist_loss: 1.3413541316986084
recon_loss: 0.030328819528222084, dist_loss: 0.6944320201873779
recon_loss: 0.030328674241900444, dist_loss: 0.5264641046524048
recon_loss: 0.030328430235385895, dist_loss: 0.6262174248695374
recon_loss: 0.03032825142145157, dist_loss: 0.8503977656364441
recon_loss: 0.030328180640935898, dist_loss: 1.0425031185150146
recon_loss: 0.03032826818525791, dist_loss: 0.5612637996673584
recon_loss: 0.030328424647450447, dist_loss: 0.6360707879066467
recon_loss: 0.030328597873449326, dist_loss: 0.9486693143844604
recon_loss: 0.03032870590686798, dist_loss: 0.7988883852958679
recon_loss: 0.030328791588544846, dist_loss: 0.5776841640472412
recon_loss: 0.030328992754220963, dist_loss: 0.6194002628326416
recon_loss: 0.030328897759318352, dist_loss: 0.5954117178916931
recon_loss: 0.030328543856739998, dist_loss: 0.8413304686546326
recon_loss: 0.030328093096613884, dist_loss: 1.2373838424682617
recon_loss: 0.03032773919403553, dist_loss: 0.6594250798225403
recon_loss: 0.030327361077070236, dist_loss: 1.0115783214569092
recon_loss: 0.030327068641781807, dist_loss: 0.7007972002029419
recon_loss: 0.030326729640364647, dist_loss: 0.8429229259490967
recon_loss: 0.030326586216688156, dist_loss: 0.9351945519447327
recon_loss: 0.030326243489980698, dist_loss: 0.5561133623123169
recon_loss: 0.030325600877404213, dist_loss: 0.5288529396057129
recon_loss: 0.03032509610056877, dist_loss: 0.5434243679046631
recon_loss: 0.030324719846248627, dist_loss: 0.7645125389099121
recon_loss: 0.030324751511216164, dist_loss: 0.541761577129364
recon_loss: 0.03032565489411354, dist_loss: 0.6189861297607422
recon_loss: 0.030327273532748222, dist_loss: 1.2440805435180664
Pre-training Epoch 33:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 33:   5%|▍         | 18/367 [00:00<00:02, 173.02it/s]Pre-training Epoch 33:  10%|█         | 37/367 [00:00<00:01, 177.45it/s]Pre-training Epoch 33:  15%|█▍        | 55/367 [00:00<00:01, 177.88it/s]Pre-training Epoch 33:  20%|█▉        | 73/367 [00:00<00:01, 175.29it/s]Pre-training Epoch 33:  25%|██▍       | 91/367 [00:00<00:01, 173.15it/s]Pre-training Epoch 33:  30%|██▉       | 109/367 [00:00<00:01, 164.14it/s]Pre-training Epoch 33:  34%|███▍      | 126/367 [00:00<00:01, 164.39it/s]recon_loss: 0.030328961089253426, dist_loss: 0.32875847816467285
recon_loss: 0.030330166220664978, dist_loss: 0.7062089443206787
recon_loss: 0.030329853296279907, dist_loss: 0.7452918291091919
recon_loss: 0.03032880462706089, dist_loss: 0.5214880704879761
recon_loss: 0.030327295884490013, dist_loss: 0.4180569648742676
recon_loss: 0.03032625839114189, dist_loss: 0.9806668758392334
recon_loss: 0.030325431376695633, dist_loss: 0.43748849630355835
recon_loss: 0.030325083062052727, dist_loss: 0.8053443431854248
recon_loss: 0.030324973165988922, dist_loss: 0.8787649869918823
recon_loss: 0.030324755236506462, dist_loss: 1.1165580749511719
recon_loss: 0.03032439388334751, dist_loss: 0.6862850189208984
recon_loss: 0.03032338246703148, dist_loss: 0.5397040247917175
recon_loss: 0.030321719124913216, dist_loss: 0.6866381168365479
recon_loss: 0.030320309102535248, dist_loss: 0.8561810255050659
recon_loss: 0.03031931072473526, dist_loss: 0.5039125680923462
recon_loss: 0.030318325385451317, dist_loss: 0.45690008997917175
recon_loss: 0.03031727485358715, dist_loss: 0.7101045250892639
recon_loss: 0.030316928401589394, dist_loss: 0.6558236479759216
recon_loss: 0.030316483229398727, dist_loss: 0.3409883379936218
recon_loss: 0.03031613864004612, dist_loss: 0.9014197587966919
recon_loss: 0.030315978452563286, dist_loss: 0.5522379875183105
recon_loss: 0.030315708369016647, dist_loss: 0.4366416037082672
recon_loss: 0.030315212905406952, dist_loss: 0.951871395111084
recon_loss: 0.03031488135457039, dist_loss: 0.5195345282554626
recon_loss: 0.030314691364765167, dist_loss: 0.8540095090866089
recon_loss: 0.030314620584249496, dist_loss: 0.6862150430679321
recon_loss: 0.030313638970255852, dist_loss: 0.6165910363197327
recon_loss: 0.030313018709421158, dist_loss: 0.5635303854942322
recon_loss: 0.03031301125884056, dist_loss: 1.0795140266418457
recon_loss: 0.03031275048851967, dist_loss: 0.7153365612030029
recon_loss: 0.03031223826110363, dist_loss: 0.9370832443237305
recon_loss: 0.030311834067106247, dist_loss: 0.6460305452346802
recon_loss: 0.03031126782298088, dist_loss: 0.8263396620750427
recon_loss: 0.030310703441500664, dist_loss: 0.9806856513023376
recon_loss: 0.03031005524098873, dist_loss: 0.5737146139144897
recon_loss: 0.030309321358799934, dist_loss: 0.6624972820281982
recon_loss: 0.03030882403254509, dist_loss: 0.5760613679885864
recon_loss: 0.03030863031744957, dist_loss: 0.804351806640625
recon_loss: 0.030308488756418228, dist_loss: 0.7243012189865112
recon_loss: 0.030308198183774948, dist_loss: 0.8383435606956482
recon_loss: 0.030308036133646965, dist_loss: 0.4788995683193207
recon_loss: 0.030307861045002937, dist_loss: 0.7162737846374512
recon_loss: 0.030307892709970474, dist_loss: 0.5375267863273621
recon_loss: 0.030307486653327942, dist_loss: 0.7366297245025635
recon_loss: 0.03030715137720108, dist_loss: 0.5597570538520813
recon_loss: 0.03030703403055668, dist_loss: 0.46449193358421326
recon_loss: 0.030307069420814514, dist_loss: 0.5994619727134705
recon_loss: 0.030307486653327942, dist_loss: 0.5276756882667542
recon_loss: 0.030307909473776817, dist_loss: 0.39589738845825195
recon_loss: 0.030308283865451813, dist_loss: 0.5241438746452332
recon_loss: 0.030308431014418602, dist_loss: 0.5537422895431519
recon_loss: 0.030308622866868973, dist_loss: 0.8773390650749207
recon_loss: 0.030309179797768593, dist_loss: 0.632657527923584
recon_loss: 0.03030884824693203, dist_loss: 0.7083784937858582
recon_loss: 0.03030817024409771, dist_loss: 0.9331815242767334
recon_loss: 0.030308015644550323, dist_loss: 0.7958897352218628
recon_loss: 0.030307898297905922, dist_loss: 0.7011950016021729
recon_loss: 0.030307529494166374, dist_loss: 0.9394022226333618
recon_loss: 0.030306793749332428, dist_loss: 0.6673966646194458
recon_loss: 0.03030615672469139, dist_loss: 0.8428698778152466
recon_loss: 0.030305450782179832, dist_loss: 0.484228253364563
recon_loss: 0.030304744839668274, dist_loss: 1.3015943765640259
recon_loss: 0.03030424751341343, dist_loss: 0.35160690546035767
recon_loss: 0.03030303679406643, dist_loss: 0.3683147728443146
recon_loss: 0.030301742255687714, dist_loss: 0.7454589605331421
recon_loss: 0.030300704762339592, dist_loss: 0.6742618680000305
recon_loss: 0.03030005842447281, dist_loss: 0.6025236248970032
recon_loss: 0.030299540609121323, dist_loss: 0.5996813178062439
recon_loss: 0.03029903955757618, dist_loss: 0.8918284773826599
recon_loss: 0.030298791825771332, dist_loss: 0.7946052551269531
recon_loss: 0.030299512669444084, dist_loss: 0.34519511461257935
recon_loss: 0.030300287529826164, dist_loss: 0.6682097911834717
recon_loss: 0.03030099719762802, dist_loss: 0.4230113625526428
recon_loss: 0.030301643535494804, dist_loss: 0.6434703469276428
recon_loss: 0.030302003026008606, dist_loss: 1.2604600191116333
recon_loss: 0.030301451683044434, dist_loss: 0.9201726317405701
recon_loss: 0.030300768092274666, dist_loss: 0.49475178122520447
recon_loss: 0.03030070848762989, dist_loss: 0.891358494758606
recon_loss: 0.03030046820640564, dist_loss: 1.1890429258346558
recon_loss: 0.030299413949251175, dist_loss: 0.6121189594268799
recon_loss: 0.030299106612801552, dist_loss: 0.33996641635894775
recon_loss: 0.030298784375190735, dist_loss: 1.0720829963684082
recon_loss: 0.030298251658678055, dist_loss: 0.5955420732498169
recon_loss: 0.030297501012682915, dist_loss: 0.31935393810272217
recon_loss: 0.03029664047062397, dist_loss: 0.6021760106086731
recon_loss: 0.030295757576823235, dist_loss: 0.3778098225593567
recon_loss: 0.030294952914118767, dist_loss: 0.4887917637825012
recon_loss: 0.030294300988316536, dist_loss: 0.47601771354675293
recon_loss: 0.030293911695480347, dist_loss: 0.5528160333633423
recon_loss: 0.030294254422187805, dist_loss: 0.5134246349334717
recon_loss: 0.03029474802315235, dist_loss: 0.5369483232498169
recon_loss: 0.03029494918882847, dist_loss: 0.3991265296936035
recon_loss: 0.030295003205537796, dist_loss: 0.6410441398620605
recon_loss: 0.030295122414827347, dist_loss: 0.8740109205245972
recon_loss: 0.030293816700577736, dist_loss: 0.6455293893814087
recon_loss: 0.03029215894639492, dist_loss: 0.7869214415550232
recon_loss: 0.030291862785816193, dist_loss: 1.1212444305419922
recon_loss: 0.03029222972691059, dist_loss: 0.7807123064994812
recon_loss: 0.030292503535747528, dist_loss: 0.40644586086273193
recon_loss: 0.030292434617877007, dist_loss: 1.07109534740448
recon_loss: 0.030292900279164314, dist_loss: 0.7341344356536865
recon_loss: 0.03029477596282959, dist_loss: 0.39093470573425293
recon_loss: 0.0302957221865654, dist_loss: 0.6560685634613037
recon_loss: 0.03029526397585869, dist_loss: 1.2703418731689453
recon_loss: 0.030294738709926605, dist_loss: 0.663148045539856
recon_loss: 0.0302942655980587, dist_loss: 0.621780514717102
recon_loss: 0.0302934218198061, dist_loss: 0.7059801816940308
recon_loss: 0.030293062329292297, dist_loss: 0.9430534839630127
recon_loss: 0.030293205752968788, dist_loss: 0.9286469221115112
recon_loss: 0.030293164774775505, dist_loss: 0.9194563627243042
recon_loss: 0.030293205752968788, dist_loss: 1.104588270187378
recon_loss: 0.030293161049485207, dist_loss: 0.9409918785095215
recon_loss: 0.030292775481939316, dist_loss: 0.6297407150268555
recon_loss: 0.030291954055428505, dist_loss: 0.4598269760608673
recon_loss: 0.030290905386209488, dist_loss: 0.727126955986023
recon_loss: 0.03028976358473301, dist_loss: 0.7032346725463867
recon_loss: 0.03028874285519123, dist_loss: 0.4927023649215698
recon_loss: 0.03028782829642296, dist_loss: 0.8245956301689148
recon_loss: 0.030287062749266624, dist_loss: 0.613898754119873
recon_loss: 0.030286315828561783, dist_loss: 0.5403551459312439
recon_loss: 0.030285384505987167, dist_loss: 0.7063143253326416
recon_loss: 0.030284801498055458, dist_loss: 0.42277517914772034
recon_loss: 0.030284367501735687, dist_loss: 0.6607619524002075
recon_loss: 0.030284063890576363, dist_loss: 0.4695257842540741
recon_loss: 0.03028395213186741, dist_loss: 0.5432677268981934
recon_loss: 0.030284035950899124, dist_loss: 0.9301801919937134
recon_loss: 0.030283818021416664, dist_loss: 0.5333883762359619
recon_loss: 0.030283506959676743, dist_loss: 0.5256363153457642
Pre-training Epoch 33:  39%|███▉      | 144/367 [00:00<00:01, 169.03it/s]Pre-training Epoch 33:  44%|████▍     | 162/367 [00:00<00:01, 172.08it/s]Pre-training Epoch 33:  49%|████▉     | 180/367 [00:01<00:01, 174.13it/s]Pre-training Epoch 33:  54%|█████▍    | 198/367 [00:01<00:00, 175.38it/s]Pre-training Epoch 33:  59%|█████▉    | 216/367 [00:01<00:00, 176.60it/s]Pre-training Epoch 33:  64%|██████▍   | 235/367 [00:01<00:00, 177.81it/s]Pre-training Epoch 33:  69%|██████▉   | 253/367 [00:01<00:00, 174.87it/s]recon_loss: 0.030282938852906227, dist_loss: 1.258812427520752
recon_loss: 0.03028247319161892, dist_loss: 0.8197821378707886
recon_loss: 0.030282137915492058, dist_loss: 0.7808600068092346
recon_loss: 0.03028184175491333, dist_loss: 0.4368642270565033
recon_loss: 0.03028148226439953, dist_loss: 0.7449899911880493
recon_loss: 0.03028109297156334, dist_loss: 0.5479477047920227
recon_loss: 0.030280761420726776, dist_loss: 0.4116370677947998
recon_loss: 0.03028077632188797, dist_loss: 0.4115551710128784
recon_loss: 0.030280331149697304, dist_loss: 0.7182998061180115
recon_loss: 0.03027995303273201, dist_loss: 0.8596664667129517
recon_loss: 0.030279215425252914, dist_loss: 0.43365150690078735
recon_loss: 0.03027861937880516, dist_loss: 0.6511900424957275
recon_loss: 0.030278002843260765, dist_loss: 0.6671652793884277
recon_loss: 0.030277544632554054, dist_loss: 0.9211083650588989
recon_loss: 0.030277194455266, dist_loss: 0.8721383213996887
recon_loss: 0.03027700074017048, dist_loss: 0.41501176357269287
recon_loss: 0.030276626348495483, dist_loss: 0.6365346908569336
recon_loss: 0.030276302248239517, dist_loss: 0.47114890813827515
recon_loss: 0.030276188626885414, dist_loss: 1.0716230869293213
recon_loss: 0.030275408178567886, dist_loss: 0.595776379108429
recon_loss: 0.030274854972958565, dist_loss: 0.9458612203598022
recon_loss: 0.030274707823991776, dist_loss: 0.624786376953125
recon_loss: 0.030274227261543274, dist_loss: 0.9235332012176514
recon_loss: 0.03027375042438507, dist_loss: 0.7625058889389038
recon_loss: 0.03027327172458172, dist_loss: 0.4315061569213867
recon_loss: 0.030273035168647766, dist_loss: 0.647818922996521
recon_loss: 0.030272942036390305, dist_loss: 0.7031474709510803
recon_loss: 0.030272621661424637, dist_loss: 0.9534050226211548
recon_loss: 0.030272141098976135, dist_loss: 0.6861129999160767
recon_loss: 0.030271701514720917, dist_loss: 0.6818997859954834
recon_loss: 0.0302713792771101, dist_loss: 0.48327913880348206
recon_loss: 0.030270980671048164, dist_loss: 0.5372828841209412
recon_loss: 0.030270660296082497, dist_loss: 0.7733319997787476
recon_loss: 0.030270306393504143, dist_loss: 0.7911055088043213
recon_loss: 0.03026997111737728, dist_loss: 0.41861692070961
recon_loss: 0.030269647017121315, dist_loss: 0.4820071756839752
recon_loss: 0.030269358307123184, dist_loss: 0.4056282043457031
recon_loss: 0.03026912547647953, dist_loss: 0.6585123538970947
recon_loss: 0.030269110575318336, dist_loss: 0.7467464804649353
recon_loss: 0.030269576236605644, dist_loss: 0.5491175055503845
recon_loss: 0.030270127579569817, dist_loss: 1.1401033401489258
recon_loss: 0.030270034447312355, dist_loss: 0.8123282194137573
recon_loss: 0.030269520357251167, dist_loss: 0.7446699738502502
recon_loss: 0.030269358307123184, dist_loss: 0.5015220046043396
recon_loss: 0.03026905097067356, dist_loss: 0.9430832862854004
recon_loss: 0.03026844747364521, dist_loss: 0.9083665609359741
recon_loss: 0.030268065631389618, dist_loss: 0.8895158767700195
recon_loss: 0.030268250033259392, dist_loss: 0.7404754161834717
recon_loss: 0.030268320813775063, dist_loss: 0.7192726135253906
recon_loss: 0.03026825748383999, dist_loss: 0.4335542917251587
recon_loss: 0.03026845119893551, dist_loss: 0.5471735000610352
recon_loss: 0.0302679892629385, dist_loss: 0.6578880548477173
recon_loss: 0.030267003923654556, dist_loss: 0.7312515377998352
recon_loss: 0.030266065150499344, dist_loss: 0.7727450728416443
recon_loss: 0.030265631154179573, dist_loss: 0.579862117767334
recon_loss: 0.030265169218182564, dist_loss: 0.5540026426315308
recon_loss: 0.030265003442764282, dist_loss: 0.4630606174468994
recon_loss: 0.03026515245437622, dist_loss: 0.4651799201965332
recon_loss: 0.030265063047409058, dist_loss: 0.9054602384567261
recon_loss: 0.030264824628829956, dist_loss: 0.66752028465271
recon_loss: 0.03026477061212063, dist_loss: 0.6293829679489136
recon_loss: 0.03026471845805645, dist_loss: 0.8994037508964539
recon_loss: 0.03026443161070347, dist_loss: 0.4899718761444092
recon_loss: 0.03026452288031578, dist_loss: 0.8865927457809448
recon_loss: 0.030264506116509438, dist_loss: 0.3932605981826782
recon_loss: 0.03026418574154377, dist_loss: 0.5356210470199585
recon_loss: 0.030263720080256462, dist_loss: 0.8712998628616333
recon_loss: 0.03026335872709751, dist_loss: 0.5113765597343445
recon_loss: 0.030262812972068787, dist_loss: 0.7963330745697021
recon_loss: 0.030262276530265808, dist_loss: 0.908534824848175
recon_loss: 0.030261771753430367, dist_loss: 0.7817484140396118
recon_loss: 0.03026142157614231, dist_loss: 0.3963109254837036
recon_loss: 0.030261171981692314, dist_loss: 0.3135257661342621
recon_loss: 0.030261041596531868, dist_loss: 0.598845362663269
recon_loss: 0.030260741710662842, dist_loss: 0.6682536602020264
recon_loss: 0.030260248109698296, dist_loss: 0.6791160106658936
recon_loss: 0.03025973215699196, dist_loss: 0.748358964920044
recon_loss: 0.030259421095252037, dist_loss: 0.946254312992096
recon_loss: 0.03025970421731472, dist_loss: 0.7592951655387878
recon_loss: 0.030260099098086357, dist_loss: 0.4044731855392456
recon_loss: 0.030260225757956505, dist_loss: 0.7606508731842041
recon_loss: 0.030260225757956505, dist_loss: 0.4842509329319
recon_loss: 0.0302597526460886, dist_loss: 0.6661901473999023
recon_loss: 0.030259348452091217, dist_loss: 0.6594752073287964
recon_loss: 0.030258983373641968, dist_loss: 1.0161148309707642
recon_loss: 0.030258702114224434, dist_loss: 0.6163634061813354
recon_loss: 0.030258186161518097, dist_loss: 0.848800003528595
recon_loss: 0.030257904902100563, dist_loss: 0.6439778804779053
recon_loss: 0.030257448554039, dist_loss: 0.6706228852272034
recon_loss: 0.03025754727423191, dist_loss: 0.9861794710159302
recon_loss: 0.030257953330874443, dist_loss: 0.39710813760757446
recon_loss: 0.030258066952228546, dist_loss: 0.5817666053771973
recon_loss: 0.030257537961006165, dist_loss: 0.4602549076080322
recon_loss: 0.03025740385055542, dist_loss: 0.5018520951271057
recon_loss: 0.030257495120167732, dist_loss: 0.7486355304718018
recon_loss: 0.030257869511842728, dist_loss: 0.32960042357444763
recon_loss: 0.0302582997828722, dist_loss: 0.7542911767959595
recon_loss: 0.03025905415415764, dist_loss: 0.8988484144210815
recon_loss: 0.03025958314538002, dist_loss: 0.2753477692604065
recon_loss: 0.030259842053055763, dist_loss: 0.32189762592315674
recon_loss: 0.03025977872312069, dist_loss: 0.8633213043212891
recon_loss: 0.030260004103183746, dist_loss: 0.7677481174468994
recon_loss: 0.030259491875767708, dist_loss: 0.5336820483207703
recon_loss: 0.030257876962423325, dist_loss: 0.3927357792854309
recon_loss: 0.030256811529397964, dist_loss: 0.5837059020996094
recon_loss: 0.03025556169450283, dist_loss: 0.6017284393310547
recon_loss: 0.03025430627167225, dist_loss: 0.7119848728179932
recon_loss: 0.030253522098064423, dist_loss: 0.5386729836463928
recon_loss: 0.030252858996391296, dist_loss: 0.5164860486984253
recon_loss: 0.030252106487751007, dist_loss: 0.37369680404663086
recon_loss: 0.03025156818330288, dist_loss: 0.8028033375740051
recon_loss: 0.030251387506723404, dist_loss: 0.5328539609909058
recon_loss: 0.030251313000917435, dist_loss: 0.997802734375
recon_loss: 0.030251331627368927, dist_loss: 0.8151300549507141
recon_loss: 0.030251313000917435, dist_loss: 0.4085019528865814
recon_loss: 0.030251337215304375, dist_loss: 0.5216106176376343
recon_loss: 0.03025122545659542, dist_loss: 1.3536498546600342
recon_loss: 0.0302509106695652, dist_loss: 0.6569027900695801
recon_loss: 0.030250536277890205, dist_loss: 0.5956457257270813
recon_loss: 0.030250128358602524, dist_loss: 0.5482276678085327
recon_loss: 0.03024977445602417, dist_loss: 0.6562063694000244
recon_loss: 0.030249232426285744, dist_loss: 0.7423393726348877
recon_loss: 0.030248554423451424, dist_loss: 0.5643846988677979
recon_loss: 0.03024793602526188, dist_loss: 0.8514150381088257
recon_loss: 0.030247552320361137, dist_loss: 0.4216632843017578
recon_loss: 0.030247177928686142, dist_loss: 0.7987039089202881
recon_loss: 0.030246997252106667, dist_loss: 1.0786269903182983
recon_loss: 0.030246952548623085, dist_loss: 0.6427686214447021
recon_loss: 0.030246881768107414, dist_loss: 0.9145342707633972
Pre-training Epoch 33:  74%|███████▍  | 271/367 [00:01<00:00, 175.49it/s]Pre-training Epoch 33:  79%|███████▊  | 289/367 [00:01<00:00, 176.32it/s]Pre-training Epoch 33:  84%|████████▎ | 307/367 [00:01<00:00, 170.36it/s]Pre-training Epoch 33:  89%|████████▊ | 325/367 [00:01<00:00, 165.76it/s]Pre-training Epoch 33:  93%|█████████▎| 342/367 [00:02<00:00, 162.36it/s]Pre-training Epoch 33:  98%|█████████▊| 359/367 [00:02<00:00, 161.37it/s]Pre-training Epoch 33: 100%|██████████| 367/367 [00:02<00:00, 169.86it/s]
recon_loss: 0.030246881768107414, dist_loss: 0.7533375024795532
recon_loss: 0.030246688053011894, dist_loss: 0.9459960460662842
recon_loss: 0.03024664893746376, dist_loss: 0.4895417094230652
recon_loss: 0.030246471986174583, dist_loss: 1.2625617980957031
recon_loss: 0.030246281996369362, dist_loss: 0.6734983921051025
recon_loss: 0.03024616464972496, dist_loss: 0.5015915632247925
recon_loss: 0.03024592250585556, dist_loss: 0.9029370546340942
recon_loss: 0.030245525762438774, dist_loss: 0.4735676646232605
recon_loss: 0.03024517372250557, dist_loss: 0.4877490997314453
recon_loss: 0.030244987457990646, dist_loss: 0.7445014715194702
recon_loss: 0.030244842171669006, dist_loss: 0.959536075592041
recon_loss: 0.030244799330830574, dist_loss: 0.4741884171962738
recon_loss: 0.030245212838053703, dist_loss: 1.0166231393814087
recon_loss: 0.030244925990700722, dist_loss: 1.0041999816894531
recon_loss: 0.030243847519159317, dist_loss: 0.5489276051521301
recon_loss: 0.03024318814277649, dist_loss: 0.7007625102996826
recon_loss: 0.030242420732975006, dist_loss: 0.46239107847213745
recon_loss: 0.03024163842201233, dist_loss: 0.5128413438796997
recon_loss: 0.030241359025239944, dist_loss: 0.9324315786361694
recon_loss: 0.03024141862988472, dist_loss: 0.37696772813796997
recon_loss: 0.030241409316658974, dist_loss: 0.7615927457809448
recon_loss: 0.030240822583436966, dist_loss: 0.5837968587875366
recon_loss: 0.030240442603826523, dist_loss: 0.31941545009613037
recon_loss: 0.030240008607506752, dist_loss: 0.5349817872047424
recon_loss: 0.03023921512067318, dist_loss: 0.9439229965209961
recon_loss: 0.03023875504732132, dist_loss: 0.8169722557067871
recon_loss: 0.0302386786788702, dist_loss: 0.964240550994873
recon_loss: 0.030238889157772064, dist_loss: 0.6350494623184204
recon_loss: 0.030238723382353783, dist_loss: 0.2949260175228119
recon_loss: 0.030238477513194084, dist_loss: 0.9073132276535034
recon_loss: 0.03023834340274334, dist_loss: 0.4786488711833954
recon_loss: 0.03023824468255043, dist_loss: 1.0690233707427979
recon_loss: 0.030238959938287735, dist_loss: 1.0887727737426758
recon_loss: 0.030240438878536224, dist_loss: 0.6825665235519409
recon_loss: 0.03024187870323658, dist_loss: 0.5683488845825195
recon_loss: 0.030242392793297768, dist_loss: 0.7034299373626709
recon_loss: 0.030241811648011208, dist_loss: 1.229163408279419
recon_loss: 0.030240988358855247, dist_loss: 0.8048836588859558
recon_loss: 0.030240371823310852, dist_loss: 0.5717251300811768
recon_loss: 0.030240057036280632, dist_loss: 0.9108899831771851
recon_loss: 0.030239831656217575, dist_loss: 0.317607581615448
recon_loss: 0.030239831656217575, dist_loss: 0.8819187879562378
recon_loss: 0.030239958316087723, dist_loss: 0.9569411277770996
recon_loss: 0.030239764600992203, dist_loss: 0.4805450439453125
recon_loss: 0.0302394088357687, dist_loss: 0.9031816124916077
recon_loss: 0.03023906983435154, dist_loss: 0.7614033222198486
recon_loss: 0.030239081010222435, dist_loss: 0.4753587245941162
recon_loss: 0.030238600447773933, dist_loss: 0.9719862341880798
recon_loss: 0.030237389728426933, dist_loss: 0.33072802424430847
recon_loss: 0.030237143859267235, dist_loss: 1.0267688035964966
recon_loss: 0.030237263068556786, dist_loss: 0.6588546633720398
recon_loss: 0.03023727796971798, dist_loss: 0.600003719329834
recon_loss: 0.03023744560778141, dist_loss: 0.6409787535667419
recon_loss: 0.030237846076488495, dist_loss: 0.6599659323692322
recon_loss: 0.030238134786486626, dist_loss: 0.8882861733436584
recon_loss: 0.030237862840294838, dist_loss: 0.7708727121353149
recon_loss: 0.030237453058362007, dist_loss: 0.3752932846546173
recon_loss: 0.030236702412366867, dist_loss: 0.3471985459327698
recon_loss: 0.030236130580306053, dist_loss: 0.46115708351135254
recon_loss: 0.030235763639211655, dist_loss: 1.533869743347168
recon_loss: 0.03023538552224636, dist_loss: 1.3444383144378662
recon_loss: 0.030235372483730316, dist_loss: 0.8319724798202515
recon_loss: 0.03023555502295494, dist_loss: 0.47508519887924194
recon_loss: 0.030235018581151962, dist_loss: 0.9024752974510193
recon_loss: 0.030234796926379204, dist_loss: 1.2239882946014404
recon_loss: 0.030235081911087036, dist_loss: 0.5123660564422607
recon_loss: 0.0302350502461195, dist_loss: 0.6226519346237183
recon_loss: 0.03023465909063816, dist_loss: 1.1272884607315063
recon_loss: 0.030234694480895996, dist_loss: 0.5089989304542542
recon_loss: 0.03023453615605831, dist_loss: 0.59112149477005
recon_loss: 0.03023417294025421, dist_loss: 0.3576625883579254
recon_loss: 0.030233759433031082, dist_loss: 0.7232886552810669
recon_loss: 0.03023357130587101, dist_loss: 0.5955106019973755
recon_loss: 0.03023345209658146, dist_loss: 0.9502491354942322
recon_loss: 0.03023332916200161, dist_loss: 0.6150575280189514
recon_loss: 0.03023277409374714, dist_loss: 0.4456940293312073
recon_loss: 0.030232323333621025, dist_loss: 0.36441585421562195
recon_loss: 0.030232023447752, dist_loss: 0.5906543135643005
recon_loss: 0.030231380835175514, dist_loss: 0.7982906103134155
recon_loss: 0.0302309338003397, dist_loss: 0.3089281916618347
recon_loss: 0.030230816453695297, dist_loss: 0.47885555028915405
recon_loss: 0.0302304457873106, dist_loss: 0.7261753678321838
recon_loss: 0.030229933559894562, dist_loss: 0.4512448310852051
recon_loss: 0.030229518190026283, dist_loss: 0.5268555879592896
recon_loss: 0.030228985473513603, dist_loss: 0.5867938995361328
recon_loss: 0.03022889792919159, dist_loss: 0.7087852954864502
recon_loss: 0.030228180810809135, dist_loss: 0.46764621138572693
recon_loss: 0.030227821320295334, dist_loss: 0.605773389339447
recon_loss: 0.030228078365325928, dist_loss: 0.6603827476501465
recon_loss: 0.030228134244680405, dist_loss: 0.44835174083709717
recon_loss: 0.03022743947803974, dist_loss: 0.4606471359729767
recon_loss: 0.030226977542042732, dist_loss: 0.5374401807785034
recon_loss: 0.030227292329072952, dist_loss: 0.9062508344650269
recon_loss: 0.030226685106754303, dist_loss: 1.1026318073272705
recon_loss: 0.03022630326449871, dist_loss: 0.4753544330596924
recon_loss: 0.03022673726081848, dist_loss: 0.5794961452484131
recon_loss: 0.030226804316043854, dist_loss: 0.5143488049507141
recon_loss: 0.03022664226591587, dist_loss: 0.4868758022785187
recon_loss: 0.030226392671465874, dist_loss: 1.1045846939086914
recon_loss: 0.03022639825940132, dist_loss: 0.7518353462219238
recon_loss: 0.030225619673728943, dist_loss: 0.8741710782051086
recon_loss: 0.030224811285734177, dist_loss: 1.0023152828216553
recon_loss: 0.030224425718188286, dist_loss: 0.9838060736656189
recon_loss: 0.03022351674735546, dist_loss: 0.30320215225219727
recon_loss: 0.03022206574678421, dist_loss: 0.5582306385040283
recon_loss: 0.0302208811044693, dist_loss: 1.5419220924377441
recon_loss: 0.03022000938653946, dist_loss: 0.4942566454410553
recon_loss: 0.03021889738738537, dist_loss: 0.4556514024734497
recon_loss: 0.030218111351132393, dist_loss: 0.45136332511901855
recon_loss: 0.03021782822906971, dist_loss: 0.5614745020866394
Pre-training Epoch 34:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 34:   4%|▍         | 15/367 [00:00<00:02, 148.58it/s]Pre-training Epoch 34:   8%|▊         | 31/367 [00:00<00:02, 153.49it/s]Pre-training Epoch 34:  13%|█▎        | 47/367 [00:00<00:02, 153.48it/s]Pre-training Epoch 34:  17%|█▋        | 63/367 [00:00<00:01, 153.08it/s]Pre-training Epoch 34:  22%|██▏       | 79/367 [00:00<00:01, 153.07it/s]Pre-training Epoch 34:  26%|██▌       | 95/367 [00:00<00:01, 150.90it/s]Pre-training Epoch 34:  30%|███       | 111/367 [00:00<00:01, 149.06it/s]Pre-training Epoch 34:  35%|███▍      | 127/367 [00:00<00:01, 149.59it/s]recon_loss: 0.03021739050745964, dist_loss: 0.5451853275299072
recon_loss: 0.03021727129817009, dist_loss: 0.6193925142288208
recon_loss: 0.030217232182621956, dist_loss: 0.7538329362869263
recon_loss: 0.03021722100675106, dist_loss: 0.39009347558021545
recon_loss: 0.030217161402106285, dist_loss: 0.5308888554573059
recon_loss: 0.030217157676815987, dist_loss: 0.8291407227516174
recon_loss: 0.030216945335268974, dist_loss: 0.9759631156921387
recon_loss: 0.030216677114367485, dist_loss: 0.725611686706543
recon_loss: 0.030216656625270844, dist_loss: 0.7033740282058716
recon_loss: 0.030216876417398453, dist_loss: 0.8505503535270691
recon_loss: 0.030216798186302185, dist_loss: 0.3775959312915802
recon_loss: 0.03021642379462719, dist_loss: 0.5305684208869934
recon_loss: 0.030216241255402565, dist_loss: 0.5779176950454712
recon_loss: 0.030215570703148842, dist_loss: 0.6256429553031921
recon_loss: 0.030214574187994003, dist_loss: 0.6746324300765991
recon_loss: 0.030214708298444748, dist_loss: 0.7996932864189148
recon_loss: 0.0302147027105093, dist_loss: 0.6263768672943115
recon_loss: 0.030213862657546997, dist_loss: 0.6293643712997437
recon_loss: 0.030213678255677223, dist_loss: 1.0143423080444336
recon_loss: 0.03021441213786602, dist_loss: 0.8408739566802979
recon_loss: 0.030214348807930946, dist_loss: 0.7382559776306152
recon_loss: 0.030213333666324615, dist_loss: 0.6508196592330933
recon_loss: 0.030212603509426117, dist_loss: 0.6103552579879761
recon_loss: 0.030213171616196632, dist_loss: 0.5352558493614197
recon_loss: 0.030212970450520515, dist_loss: 0.5728279948234558
recon_loss: 0.030212203040719032, dist_loss: 0.6191453337669373
recon_loss: 0.030211936682462692, dist_loss: 0.8922677636146545
recon_loss: 0.030212024226784706, dist_loss: 0.3030342161655426
recon_loss: 0.030211539939045906, dist_loss: 0.8417002558708191
recon_loss: 0.03021087683737278, dist_loss: 0.5014070272445679
recon_loss: 0.03021058812737465, dist_loss: 0.7549734115600586
recon_loss: 0.03021043911576271, dist_loss: 0.7187169194221497
recon_loss: 0.030210234224796295, dist_loss: 0.735347330570221
recon_loss: 0.03021017462015152, dist_loss: 0.6234135627746582
recon_loss: 0.030210185796022415, dist_loss: 1.0722715854644775
recon_loss: 0.030210115015506744, dist_loss: 1.4929587841033936
recon_loss: 0.03020973689854145, dist_loss: 0.6875938177108765
recon_loss: 0.030209356918931007, dist_loss: 0.7422343492507935
recon_loss: 0.03020903468132019, dist_loss: 0.88782799243927
recon_loss: 0.030209137126803398, dist_loss: 0.5663009881973267
recon_loss: 0.030209366232156754, dist_loss: 0.7636963129043579
recon_loss: 0.030209681019186974, dist_loss: 0.8033382892608643
recon_loss: 0.030210161581635475, dist_loss: 0.46782436966896057
recon_loss: 0.030210059136152267, dist_loss: 0.9020018577575684
recon_loss: 0.030209116637706757, dist_loss: 1.0098778009414673
recon_loss: 0.03020847775042057, dist_loss: 0.692017674446106
recon_loss: 0.030207617208361626, dist_loss: 1.2005078792572021
recon_loss: 0.0302064660936594, dist_loss: 0.6583685278892517
recon_loss: 0.030206382274627686, dist_loss: 0.49059754610061646
recon_loss: 0.03020728938281536, dist_loss: 0.8413680791854858
recon_loss: 0.030208449810743332, dist_loss: 0.7105764150619507
recon_loss: 0.03020974062383175, dist_loss: 0.5994582176208496
recon_loss: 0.030209846794605255, dist_loss: 0.41220635175704956
recon_loss: 0.03020833246409893, dist_loss: 0.7425539493560791
recon_loss: 0.030206622555851936, dist_loss: 1.1862972974777222
recon_loss: 0.030205633491277695, dist_loss: 0.462565153837204
recon_loss: 0.030204851180315018, dist_loss: 0.7687603235244751
recon_loss: 0.030204681679606438, dist_loss: 0.7346500158309937
recon_loss: 0.03020509146153927, dist_loss: 0.5355927348136902
recon_loss: 0.030205242335796356, dist_loss: 0.537383496761322
recon_loss: 0.030204949900507927, dist_loss: 0.5137752294540405
recon_loss: 0.030205119401216507, dist_loss: 0.5103780031204224
recon_loss: 0.03020487166941166, dist_loss: 0.8231961131095886
recon_loss: 0.030203893780708313, dist_loss: 0.4691695272922516
recon_loss: 0.03020334802567959, dist_loss: 0.8429208993911743
recon_loss: 0.030203068628907204, dist_loss: 0.6151874661445618
recon_loss: 0.03020249307155609, dist_loss: 0.8437926769256592
recon_loss: 0.030202917754650116, dist_loss: 0.6200644373893738
recon_loss: 0.03020399622619152, dist_loss: 0.6907614469528198
recon_loss: 0.030204402282834053, dist_loss: 0.5072882771492004
recon_loss: 0.030203916132450104, dist_loss: 0.40907543897628784
recon_loss: 0.03020440600812435, dist_loss: 1.3740200996398926
recon_loss: 0.030203470960259438, dist_loss: 0.7353014945983887
recon_loss: 0.030201999470591545, dist_loss: 0.6229888200759888
recon_loss: 0.030201321467757225, dist_loss: 0.6309598684310913
recon_loss: 0.030201399698853493, dist_loss: 0.7189131379127502
recon_loss: 0.030201127752661705, dist_loss: 0.6747032999992371
recon_loss: 0.030200496315956116, dist_loss: 0.5779118537902832
recon_loss: 0.030200716108083725, dist_loss: 0.5566116571426392
recon_loss: 0.030200546607375145, dist_loss: 0.8147891759872437
recon_loss: 0.03019971400499344, dist_loss: 0.7193359136581421
recon_loss: 0.03019932471215725, dist_loss: 0.6130632162094116
recon_loss: 0.030199021100997925, dist_loss: 0.9103896617889404
recon_loss: 0.030198100954294205, dist_loss: 0.5798077583312988
recon_loss: 0.030197327956557274, dist_loss: 0.8452355861663818
recon_loss: 0.030197398737072945, dist_loss: 0.7705795168876648
recon_loss: 0.030197208747267723, dist_loss: 0.6887182593345642
recon_loss: 0.030196456238627434, dist_loss: 0.5761033296585083
recon_loss: 0.03019663691520691, dist_loss: 0.7587319016456604
recon_loss: 0.030196720734238625, dist_loss: 0.7243108153343201
recon_loss: 0.03019614890217781, dist_loss: 0.7377174496650696
recon_loss: 0.030195768922567368, dist_loss: 0.460528701543808
recon_loss: 0.030195852741599083, dist_loss: 0.9113898873329163
recon_loss: 0.0301956869661808, dist_loss: 1.0094499588012695
recon_loss: 0.03019515424966812, dist_loss: 0.6685358285903931
recon_loss: 0.03019525669515133, dist_loss: 0.44486385583877563
recon_loss: 0.030195271596312523, dist_loss: 1.4249969720840454
recon_loss: 0.030194668099284172, dist_loss: 0.8463130593299866
recon_loss: 0.030194170773029327, dist_loss: 0.6434007883071899
recon_loss: 0.03019382432103157, dist_loss: 0.6972911357879639
recon_loss: 0.030193516984581947, dist_loss: 0.6499377489089966
recon_loss: 0.03019329532980919, dist_loss: 0.6167077422142029
recon_loss: 0.030193474143743515, dist_loss: 0.902571976184845
recon_loss: 0.030194364488124847, dist_loss: 0.8586024045944214
recon_loss: 0.030194230377674103, dist_loss: 0.3967490792274475
recon_loss: 0.030193425714969635, dist_loss: 0.4656899869441986
recon_loss: 0.030192408710718155, dist_loss: 0.863283634185791
recon_loss: 0.030191678553819656, dist_loss: 0.7853316068649292
recon_loss: 0.030191322788596153, dist_loss: 0.546633780002594
recon_loss: 0.030191102996468544, dist_loss: 0.35452207922935486
recon_loss: 0.030191224068403244, dist_loss: 0.7755171656608582
recon_loss: 0.030191520228981972, dist_loss: 0.4968518018722534
recon_loss: 0.030191294848918915, dist_loss: 0.32022398710250854
recon_loss: 0.03019120916724205, dist_loss: 0.6694190502166748
recon_loss: 0.030190924182534218, dist_loss: 0.587726354598999
recon_loss: 0.03018978424370289, dist_loss: 0.7587316632270813
recon_loss: 0.030189428478479385, dist_loss: 1.4385024309158325
recon_loss: 0.030190056189894676, dist_loss: 0.7766484022140503
recon_loss: 0.030188923701643944, dist_loss: 0.5395828485488892
recon_loss: 0.030189555138349533, dist_loss: 0.4663281738758087
recon_loss: 0.03019101917743683, dist_loss: 0.7011764049530029
recon_loss: 0.03019060008227825, dist_loss: 0.9106820821762085
recon_loss: 0.030189109966158867, dist_loss: 0.7947515249252319
recon_loss: 0.030189141631126404, dist_loss: 0.7409626841545105
recon_loss: 0.030189163982868195, dist_loss: 0.8557161688804626
recon_loss: 0.030188171193003654, dist_loss: 0.6779831647872925
recon_loss: 0.030187934637069702, dist_loss: 0.8300671577453613
recon_loss: 0.03018789552152157, dist_loss: 0.42637091875076294
Pre-training Epoch 34:  39%|███▉      | 143/367 [00:00<00:01, 151.17it/s]Pre-training Epoch 34:  43%|████▎     | 159/367 [00:01<00:01, 149.41it/s]Pre-training Epoch 34:  48%|████▊     | 175/367 [00:01<00:01, 149.42it/s]Pre-training Epoch 34:  52%|█████▏    | 191/367 [00:01<00:01, 149.52it/s]Pre-training Epoch 34:  56%|█████▋    | 207/367 [00:01<00:01, 150.53it/s]Pre-training Epoch 34:  61%|██████    | 223/367 [00:01<00:00, 150.89it/s]Pre-training Epoch 34:  65%|██████▌   | 239/367 [00:01<00:00, 151.06it/s]Pre-training Epoch 34:  69%|██████▉   | 255/367 [00:01<00:00, 150.03it/s]recon_loss: 0.030187800526618958, dist_loss: 0.652631938457489
recon_loss: 0.03018796257674694, dist_loss: 0.6356427669525146
recon_loss: 0.03018801659345627, dist_loss: 0.733684241771698
recon_loss: 0.030187787488102913, dist_loss: 0.986149251461029
recon_loss: 0.03018725849688053, dist_loss: 0.6881247758865356
recon_loss: 0.030186383053660393, dist_loss: 0.9363515377044678
recon_loss: 0.03018537349998951, dist_loss: 0.6708775758743286
recon_loss: 0.030184399336576462, dist_loss: 0.7694729566574097
recon_loss: 0.03018368035554886, dist_loss: 0.5191023349761963
recon_loss: 0.030183354392647743, dist_loss: 0.8467369079589844
recon_loss: 0.030183440074324608, dist_loss: 0.4037303328514099
recon_loss: 0.030183203518390656, dist_loss: 0.8669463396072388
recon_loss: 0.03018304519355297, dist_loss: 0.7397983074188232
recon_loss: 0.03018282912671566, dist_loss: 0.5365819931030273
recon_loss: 0.03018265962600708, dist_loss: 0.843317985534668
recon_loss: 0.03018268570303917, dist_loss: 0.5551364421844482
recon_loss: 0.030182717368006706, dist_loss: 0.8136245012283325
recon_loss: 0.030182529240846634, dist_loss: 0.5258607268333435
recon_loss: 0.03018215298652649, dist_loss: 1.0217808485031128
recon_loss: 0.030181629583239555, dist_loss: 0.9144806265830994
recon_loss: 0.030181068927049637, dist_loss: 0.8070517778396606
recon_loss: 0.030180349946022034, dist_loss: 0.7251951098442078
recon_loss: 0.03017960861325264, dist_loss: 0.8696064352989197
recon_loss: 0.03017888031899929, dist_loss: 0.6162183880805969
recon_loss: 0.03017815388739109, dist_loss: 0.8135532140731812
recon_loss: 0.030177466571331024, dist_loss: 1.0699597597122192
recon_loss: 0.030177084729075432, dist_loss: 0.6726447343826294
recon_loss: 0.03017708845436573, dist_loss: 0.6664236783981323
recon_loss: 0.030176714062690735, dist_loss: 0.8759034276008606
recon_loss: 0.03017599508166313, dist_loss: 0.5569456219673157
recon_loss: 0.030175846070051193, dist_loss: 0.6832466721534729
recon_loss: 0.030175676569342613, dist_loss: 0.7379584908485413
recon_loss: 0.030175045132637024, dist_loss: 0.4715458154678345
recon_loss: 0.030174314975738525, dist_loss: 0.37788522243499756
recon_loss: 0.03017382137477398, dist_loss: 0.6835500001907349
recon_loss: 0.03017333894968033, dist_loss: 1.0643270015716553
recon_loss: 0.03017299622297287, dist_loss: 0.6526554822921753
recon_loss: 0.030172735452651978, dist_loss: 0.30835968255996704
recon_loss: 0.030172452330589294, dist_loss: 0.6504011154174805
recon_loss: 0.030172191560268402, dist_loss: 0.49156466126441956
recon_loss: 0.03017197921872139, dist_loss: 1.2048780918121338
recon_loss: 0.030171634629368782, dist_loss: 1.0305824279785156
recon_loss: 0.03017144277691841, dist_loss: 0.5732237100601196
recon_loss: 0.030171358957886696, dist_loss: 0.5401635766029358
recon_loss: 0.030171040445566177, dist_loss: 1.0569614171981812
recon_loss: 0.030170613899827003, dist_loss: 0.6056484580039978
recon_loss: 0.030170166864991188, dist_loss: 1.2673205137252808
recon_loss: 0.030169837176799774, dist_loss: 0.45066940784454346
recon_loss: 0.030169745907187462, dist_loss: 0.9149472117424011
recon_loss: 0.030169259756803513, dist_loss: 0.3871636688709259
recon_loss: 0.030168866738677025, dist_loss: 0.9069960117340088
recon_loss: 0.03016853518784046, dist_loss: 0.4960142970085144
recon_loss: 0.030168140307068825, dist_loss: 0.9135501384735107
recon_loss: 0.030167914927005768, dist_loss: 0.36848634481430054
recon_loss: 0.030167674645781517, dist_loss: 1.0136754512786865
recon_loss: 0.030167527496814728, dist_loss: 0.5743145942687988
recon_loss: 0.030167492106556892, dist_loss: 0.27475547790527344
recon_loss: 0.030167413875460625, dist_loss: 0.5940418243408203
recon_loss: 0.030166996642947197, dist_loss: 0.6536273956298828
recon_loss: 0.030166298151016235, dist_loss: 0.6751828789710999
recon_loss: 0.030165737494826317, dist_loss: 0.5865383148193359
recon_loss: 0.030165303498506546, dist_loss: 0.5802398324012756
recon_loss: 0.030165133997797966, dist_loss: 0.8724873065948486
recon_loss: 0.03016514889895916, dist_loss: 0.4770472049713135
recon_loss: 0.03016524761915207, dist_loss: 0.7064535021781921
recon_loss: 0.030165547505021095, dist_loss: 0.6630092263221741
recon_loss: 0.030165260657668114, dist_loss: 0.5492919087409973
recon_loss: 0.030164724215865135, dist_loss: 0.5958577990531921
recon_loss: 0.030164537951350212, dist_loss: 0.63372403383255
recon_loss: 0.030164478346705437, dist_loss: 0.8663030862808228
recon_loss: 0.030163945630192757, dist_loss: 0.73301762342453
recon_loss: 0.030163384974002838, dist_loss: 0.3861069083213806
recon_loss: 0.03016357496380806, dist_loss: 0.5624427199363708
recon_loss: 0.03016379289329052, dist_loss: 0.45625942945480347
recon_loss: 0.030163638293743134, dist_loss: 0.6654592752456665
recon_loss: 0.03016345202922821, dist_loss: 0.4602319002151489
recon_loss: 0.030163515359163284, dist_loss: 1.194023609161377
recon_loss: 0.030163059011101723, dist_loss: 0.7410492897033691
recon_loss: 0.030162746086716652, dist_loss: 0.832619845867157
recon_loss: 0.03016289696097374, dist_loss: 0.8710255026817322
recon_loss: 0.03016262874007225, dist_loss: 0.5629010796546936
recon_loss: 0.030162636190652847, dist_loss: 0.6175132989883423
recon_loss: 0.03016265109181404, dist_loss: 0.7056421637535095
recon_loss: 0.0301625095307827, dist_loss: 0.719841480255127
recon_loss: 0.030162720009684563, dist_loss: 0.8348888158798218
recon_loss: 0.03016284480690956, dist_loss: 0.5301077365875244
recon_loss: 0.030162841081619263, dist_loss: 0.8217339515686035
recon_loss: 0.03016209974884987, dist_loss: 0.9060645699501038
recon_loss: 0.030161665752530098, dist_loss: 0.5477946996688843
recon_loss: 0.030161535367369652, dist_loss: 0.819427490234375
recon_loss: 0.030161619186401367, dist_loss: 0.6599230766296387
recon_loss: 0.030161283910274506, dist_loss: 0.5038788318634033
recon_loss: 0.03016103431582451, dist_loss: 0.5138695240020752
recon_loss: 0.030160849913954735, dist_loss: 0.36352190375328064
recon_loss: 0.03016044944524765, dist_loss: 0.4783764183521271
recon_loss: 0.03015991300344467, dist_loss: 0.6250756978988647
recon_loss: 0.030159277841448784, dist_loss: 0.3059053421020508
recon_loss: 0.03015858493745327, dist_loss: 0.6635046005249023
recon_loss: 0.030158119276165962, dist_loss: 0.5662537217140198
recon_loss: 0.030157752335071564, dist_loss: 0.6933561563491821
recon_loss: 0.03015749901533127, dist_loss: 0.8873504996299744
recon_loss: 0.03015720285475254, dist_loss: 0.7829963564872742
recon_loss: 0.030156947672367096, dist_loss: 0.7740340828895569
recon_loss: 0.03015672229230404, dist_loss: 1.0163321495056152
recon_loss: 0.030156472697854042, dist_loss: 0.4728853702545166
recon_loss: 0.030156347900629044, dist_loss: 0.5277835130691528
recon_loss: 0.03015613742172718, dist_loss: 0.8936007022857666
recon_loss: 0.030155960470438004, dist_loss: 0.8219825029373169
recon_loss: 0.030155861750245094, dist_loss: 0.8389669060707092
recon_loss: 0.030155779793858528, dist_loss: 0.7615662813186646
recon_loss: 0.030155712738633156, dist_loss: 0.45428720116615295
recon_loss: 0.03015540912747383, dist_loss: 0.9685549139976501
recon_loss: 0.030155278742313385, dist_loss: 0.7893590927124023
recon_loss: 0.030155371874570847, dist_loss: 0.8404282331466675
recon_loss: 0.030155247077345848, dist_loss: 0.5259131193161011
recon_loss: 0.030154841020703316, dist_loss: 0.46013033390045166
recon_loss: 0.030155092477798462, dist_loss: 0.8693332672119141
recon_loss: 0.030154457315802574, dist_loss: 0.4401410222053528
recon_loss: 0.030154012143611908, dist_loss: 0.4927891790866852
recon_loss: 0.030153905972838402, dist_loss: 0.8152262568473816
recon_loss: 0.030153462663292885, dist_loss: 0.631945788860321
recon_loss: 0.030153166502714157, dist_loss: 0.7988735437393188
recon_loss: 0.030153194442391396, dist_loss: 0.5466985702514648
recon_loss: 0.03015296906232834, dist_loss: 0.4504753351211548
recon_loss: 0.030152251943945885, dist_loss: 0.3207132816314697
recon_loss: 0.030152058228850365, dist_loss: 0.4582163095474243
recon_loss: 0.03015241026878357, dist_loss: 0.6694377660751343
recon_loss: 0.030152270570397377, dist_loss: 0.6265920996665955
Pre-training Epoch 34:  74%|███████▍  | 271/367 [00:01<00:00, 149.15it/s]Pre-training Epoch 34:  78%|███████▊  | 287/367 [00:01<00:00, 150.78it/s]Pre-training Epoch 34:  83%|████████▎ | 303/367 [00:02<00:00, 152.24it/s]Pre-training Epoch 34:  87%|████████▋ | 319/367 [00:02<00:00, 152.14it/s]Pre-training Epoch 34:  91%|█████████▏| 335/367 [00:02<00:00, 152.75it/s]Pre-training Epoch 34:  96%|█████████▌| 351/367 [00:02<00:00, 153.12it/s]Pre-training Epoch 34: 100%|██████████| 367/367 [00:02<00:00, 153.51it/s]Pre-training Epoch 34: 100%|██████████| 367/367 [00:02<00:00, 151.36it/s]
recon_loss: 0.03015238232910633, dist_loss: 0.3910704255104065
recon_loss: 0.03015287034213543, dist_loss: 0.4782807528972626
recon_loss: 0.0301523394882679, dist_loss: 0.8133766055107117
recon_loss: 0.030150946229696274, dist_loss: 0.45733362436294556
recon_loss: 0.030150476843118668, dist_loss: 0.5634117126464844
recon_loss: 0.03015023097395897, dist_loss: 0.5736515522003174
recon_loss: 0.03014999069273472, dist_loss: 0.8439304828643799
recon_loss: 0.03014981746673584, dist_loss: 0.4412286877632141
recon_loss: 0.03014959581196308, dist_loss: 1.1547183990478516
recon_loss: 0.030148832127451897, dist_loss: 0.521285355091095
recon_loss: 0.030148275196552277, dist_loss: 0.4969022274017334
recon_loss: 0.03014792874455452, dist_loss: 0.6881514191627502
recon_loss: 0.030147410929203033, dist_loss: 0.4813677966594696
recon_loss: 0.03014683537185192, dist_loss: 0.8872111439704895
recon_loss: 0.030146751552820206, dist_loss: 0.48633426427841187
recon_loss: 0.030146483331918716, dist_loss: 0.4369966983795166
recon_loss: 0.030146140605211258, dist_loss: 0.6913431882858276
recon_loss: 0.03014569915831089, dist_loss: 0.48826298117637634
recon_loss: 0.030145395547151566, dist_loss: 0.7424681782722473
recon_loss: 0.03014548122882843, dist_loss: 0.717021107673645
recon_loss: 0.030145414173603058, dist_loss: 0.515913188457489
recon_loss: 0.030145050957798958, dist_loss: 0.674924373626709
recon_loss: 0.03014458157122135, dist_loss: 0.7935603857040405
recon_loss: 0.030144089832901955, dist_loss: 0.8752076625823975
recon_loss: 0.030143851414322853, dist_loss: 0.8216365575790405
recon_loss: 0.030143611133098602, dist_loss: 0.8410963416099548
recon_loss: 0.03014358878135681, dist_loss: 0.8876758813858032
recon_loss: 0.03014364279806614, dist_loss: 0.5202814340591431
recon_loss: 0.030143864452838898, dist_loss: 0.6845056414604187
recon_loss: 0.030144155025482178, dist_loss: 0.3355727791786194
recon_loss: 0.03014383278787136, dist_loss: 1.3528733253479004
recon_loss: 0.030143236741423607, dist_loss: 0.35569337010383606
recon_loss: 0.030142273753881454, dist_loss: 0.6310241222381592
recon_loss: 0.0301415603607893, dist_loss: 0.6370972394943237
recon_loss: 0.030141279101371765, dist_loss: 0.8788705468177795
recon_loss: 0.030141035094857216, dist_loss: 0.4931199848651886
recon_loss: 0.030140766873955727, dist_loss: 0.7246233224868774
recon_loss: 0.030140450224280357, dist_loss: 0.406968355178833
recon_loss: 0.030140111222863197, dist_loss: 0.6221941709518433
recon_loss: 0.03013966605067253, dist_loss: 0.8274089694023132
recon_loss: 0.030139263719320297, dist_loss: 0.6370595693588257
recon_loss: 0.03013921156525612, dist_loss: 0.4724636673927307
recon_loss: 0.03013882227241993, dist_loss: 0.8664398193359375
recon_loss: 0.030138486996293068, dist_loss: 0.5972943305969238
recon_loss: 0.030138112604618073, dist_loss: 0.46388375759124756
recon_loss: 0.030137717723846436, dist_loss: 0.4146455228328705
recon_loss: 0.03013746440410614, dist_loss: 0.5964953899383545
recon_loss: 0.03013729490339756, dist_loss: 0.631088376045227
recon_loss: 0.03013712167739868, dist_loss: 0.7366564273834229
recon_loss: 0.030136652290821075, dist_loss: 0.5310980677604675
recon_loss: 0.030136849731206894, dist_loss: 0.5464996099472046
recon_loss: 0.030136631801724434, dist_loss: 0.6322174668312073
recon_loss: 0.030135827139019966, dist_loss: 0.33116644620895386
recon_loss: 0.030135756358504295, dist_loss: 0.8758605718612671
recon_loss: 0.030135735869407654, dist_loss: 0.8171670436859131
recon_loss: 0.030135368928313255, dist_loss: 0.4864993691444397
recon_loss: 0.030134670436382294, dist_loss: 0.42455124855041504
recon_loss: 0.030134500935673714, dist_loss: 1.0077675580978394
recon_loss: 0.03013445809483528, dist_loss: 0.5761585831642151
recon_loss: 0.030134260654449463, dist_loss: 0.4639781713485718
recon_loss: 0.030134592205286026, dist_loss: 0.9045599102973938
recon_loss: 0.03013404831290245, dist_loss: 1.1262246370315552
recon_loss: 0.030133534222841263, dist_loss: 0.7890251874923706
recon_loss: 0.030132930725812912, dist_loss: 0.7022092342376709
recon_loss: 0.030132856220006943, dist_loss: 0.8327054977416992
recon_loss: 0.030132576823234558, dist_loss: 0.7241201400756836
recon_loss: 0.030132107436656952, dist_loss: 1.0348072052001953
recon_loss: 0.030131833627820015, dist_loss: 0.5922771692276001
recon_loss: 0.030131952837109566, dist_loss: 0.6295768618583679
recon_loss: 0.030131865292787552, dist_loss: 0.741647481918335
recon_loss: 0.03013102151453495, dist_loss: 0.8726884126663208
recon_loss: 0.030130259692668915, dist_loss: 0.7292879223823547
recon_loss: 0.030130110681056976, dist_loss: 0.7789483070373535
recon_loss: 0.030130062252283096, dist_loss: 0.4828389286994934
recon_loss: 0.03012981452047825, dist_loss: 0.46416181325912476
recon_loss: 0.03012971207499504, dist_loss: 0.9299813508987427
recon_loss: 0.03012951835989952, dist_loss: 0.18941256403923035
recon_loss: 0.030129164457321167, dist_loss: 1.0084580183029175
recon_loss: 0.030128737911581993, dist_loss: 1.1132521629333496
recon_loss: 0.030128424987196922, dist_loss: 0.7960668802261353
recon_loss: 0.030128389596939087, dist_loss: 0.5994318723678589
recon_loss: 0.030128657817840576, dist_loss: 0.8741626739501953
recon_loss: 0.03012862242758274, dist_loss: 0.18049804866313934
recon_loss: 0.03012850508093834, dist_loss: 0.44592177867889404
recon_loss: 0.030128424987196922, dist_loss: 0.44154199957847595
recon_loss: 0.0301281176507473, dist_loss: 0.3915201723575592
recon_loss: 0.03012753464281559, dist_loss: 0.45735910534858704
recon_loss: 0.030127257108688354, dist_loss: 0.5376715064048767
recon_loss: 0.03012719936668873, dist_loss: 0.7800729274749756
recon_loss: 0.030126994475722313, dist_loss: 0.5467466711997986
recon_loss: 0.030126752331852913, dist_loss: 0.5482940673828125
recon_loss: 0.03012675978243351, dist_loss: 0.8206729292869568
recon_loss: 0.030126476660370827, dist_loss: 0.32969415187835693
recon_loss: 0.030125794932246208, dist_loss: 0.44414055347442627
recon_loss: 0.030125323683023453, dist_loss: 0.6624502539634705
recon_loss: 0.03012494556605816, dist_loss: 0.9048994183540344
recon_loss: 0.030124353244900703, dist_loss: 0.561600387096405
recon_loss: 0.030124105513095856, dist_loss: 0.31768640875816345
recon_loss: 0.03012397140264511, dist_loss: 0.38470908999443054
recon_loss: 0.03012392856180668, dist_loss: 1.0392855405807495
recon_loss: 0.03012358397245407, dist_loss: 0.47344323992729187
recon_loss: 0.030123209580779076, dist_loss: 0.7036103010177612
recon_loss: 0.030123364180326462, dist_loss: 0.3289424180984497
recon_loss: 0.0301235131919384, dist_loss: 0.728435754776001
recon_loss: 0.030124062672257423, dist_loss: 1.004909873008728
recon_loss: 0.030124953016638756, dist_loss: 0.7907633185386658
recon_loss: 0.030125079676508904, dist_loss: 0.8102288842201233
recon_loss: 0.030125092715024948, dist_loss: 0.938663125038147
recon_loss: 0.03012530878186226, dist_loss: 0.875394880771637
recon_loss: 0.03012378141283989, dist_loss: 0.22322134673595428
recon_loss: 0.03012334741652012, dist_loss: 0.4872108995914459
Pre-training Epoch 35:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 35:   5%|▍         | 18/367 [00:00<00:02, 172.08it/s]Pre-training Epoch 35:  10%|▉         | 36/367 [00:00<00:01, 176.26it/s]Pre-training Epoch 35:  15%|█▍        | 54/367 [00:00<00:01, 177.59it/s]Pre-training Epoch 35:  20%|█▉        | 72/367 [00:00<00:01, 176.81it/s]Pre-training Epoch 35:  25%|██▍       | 91/367 [00:00<00:01, 179.09it/s]Pre-training Epoch 35:  30%|██▉       | 109/367 [00:00<00:01, 178.05it/s]Pre-training Epoch 35:  35%|███▍      | 127/367 [00:00<00:01, 178.61it/s]recon_loss: 0.03012327291071415, dist_loss: 0.8177706599235535
recon_loss: 0.03012332133948803, dist_loss: 0.8327928185462952
recon_loss: 0.030122719705104828, dist_loss: 0.7045615911483765
recon_loss: 0.030123025178909302, dist_loss: 0.5251222252845764
recon_loss: 0.03012336790561676, dist_loss: 0.7668964862823486
recon_loss: 0.03012249618768692, dist_loss: 0.6089088320732117
recon_loss: 0.0301215797662735, dist_loss: 0.5754560232162476
recon_loss: 0.03012123331427574, dist_loss: 0.8234859704971313
recon_loss: 0.030120689421892166, dist_loss: 0.7052956819534302
recon_loss: 0.030119942501187325, dist_loss: 0.7311201095581055
recon_loss: 0.03011949732899666, dist_loss: 0.8389046788215637
recon_loss: 0.030119087547063828, dist_loss: 0.9144423007965088
recon_loss: 0.03011847473680973, dist_loss: 0.6578576564788818
recon_loss: 0.030118608847260475, dist_loss: 1.0367294549942017
recon_loss: 0.03011872060596943, dist_loss: 0.763945460319519
recon_loss: 0.03011789545416832, dist_loss: 0.7709494233131409
recon_loss: 0.030117753893136978, dist_loss: 0.5235768556594849
recon_loss: 0.030118601396679878, dist_loss: 0.6727959513664246
recon_loss: 0.03011813573539257, dist_loss: 0.6637975573539734
recon_loss: 0.030117454007267952, dist_loss: 0.3827078342437744
recon_loss: 0.03011784888803959, dist_loss: 0.6927997469902039
recon_loss: 0.030117733404040337, dist_loss: 0.951454222202301
recon_loss: 0.030117744579911232, dist_loss: 0.4577009677886963
recon_loss: 0.030118480324745178, dist_loss: 0.5961755514144897
recon_loss: 0.030118152499198914, dist_loss: 0.7730858325958252
recon_loss: 0.030117714777588844, dist_loss: 0.5514540672302246
recon_loss: 0.030117979273200035, dist_loss: 0.6488980650901794
recon_loss: 0.030118411406874657, dist_loss: 0.3645852208137512
recon_loss: 0.030117958784103394, dist_loss: 0.6555691361427307
recon_loss: 0.03011791966855526, dist_loss: 0.3787808418273926
recon_loss: 0.030118541792035103, dist_loss: 0.612863302230835
recon_loss: 0.030117860063910484, dist_loss: 0.8855364322662354
recon_loss: 0.030117444694042206, dist_loss: 0.9391841888427734
recon_loss: 0.030117182061076164, dist_loss: 0.44299089908599854
recon_loss: 0.030115989968180656, dist_loss: 0.9956584572792053
recon_loss: 0.03011447936296463, dist_loss: 0.6374942064285278
recon_loss: 0.03011394292116165, dist_loss: 0.5715879201889038
recon_loss: 0.03011387214064598, dist_loss: 0.8212084770202637
recon_loss: 0.030113838613033295, dist_loss: 0.7296638488769531
recon_loss: 0.030113914981484413, dist_loss: 0.6887047290802002
recon_loss: 0.03011416271328926, dist_loss: 0.6253668069839478
recon_loss: 0.03011394292116165, dist_loss: 0.7395946979522705
recon_loss: 0.030113738030195236, dist_loss: 0.5137621164321899
recon_loss: 0.030113978311419487, dist_loss: 0.6629331111907959
recon_loss: 0.0301138237118721, dist_loss: 0.40201467275619507
recon_loss: 0.030113989487290382, dist_loss: 0.2858743965625763
recon_loss: 0.03011436015367508, dist_loss: 0.49146103858947754
recon_loss: 0.030114352703094482, dist_loss: 0.6997755765914917
recon_loss: 0.030114155262708664, dist_loss: 0.5553238391876221
recon_loss: 0.030113844200968742, dist_loss: 0.5824593305587769
recon_loss: 0.03011314570903778, dist_loss: 0.70252525806427
recon_loss: 0.03011191077530384, dist_loss: 0.5359064340591431
recon_loss: 0.030110564082860947, dist_loss: 1.0106149911880493
recon_loss: 0.030109768733382225, dist_loss: 0.6411721110343933
recon_loss: 0.030109046027064323, dist_loss: 0.5580621957778931
recon_loss: 0.030107790604233742, dist_loss: 0.38886886835098267
recon_loss: 0.03010677359998226, dist_loss: 0.387506902217865
recon_loss: 0.030106427147984505, dist_loss: 0.6274465322494507
recon_loss: 0.03010614961385727, dist_loss: 0.8485665917396545
recon_loss: 0.030106358230113983, dist_loss: 0.6202014684677124
recon_loss: 0.030106710270047188, dist_loss: 0.7736431360244751
recon_loss: 0.0301069188863039, dist_loss: 0.5853486061096191
recon_loss: 0.03010687232017517, dist_loss: 0.44290342926979065
recon_loss: 0.030106596648693085, dist_loss: 0.8932838439941406
recon_loss: 0.030106019228696823, dist_loss: 0.5724228024482727
recon_loss: 0.030105391517281532, dist_loss: 1.0212479829788208
recon_loss: 0.03010481223464012, dist_loss: 0.7839392423629761
recon_loss: 0.030104240402579308, dist_loss: 0.3284740447998047
recon_loss: 0.030103420838713646, dist_loss: 0.5543975234031677
recon_loss: 0.030102591961622238, dist_loss: 0.5614089369773865
recon_loss: 0.03010191209614277, dist_loss: 0.7269055843353271
recon_loss: 0.030101262032985687, dist_loss: 0.5351917147636414
recon_loss: 0.030100831761956215, dist_loss: 0.4374958872795105
recon_loss: 0.03010045364499092, dist_loss: 0.8138152956962585
recon_loss: 0.030100109055638313, dist_loss: 0.48999500274658203
recon_loss: 0.030099481344223022, dist_loss: 0.8485670685768127
recon_loss: 0.030099451541900635, dist_loss: 0.5564776659011841
recon_loss: 0.03009974956512451, dist_loss: 0.5373441576957703
recon_loss: 0.030098862946033478, dist_loss: 0.7945841550827026
recon_loss: 0.030098464339971542, dist_loss: 0.5471857786178589
recon_loss: 0.03009909950196743, dist_loss: 0.5530456304550171
recon_loss: 0.030098680406808853, dist_loss: 0.5728195905685425
recon_loss: 0.030097635462880135, dist_loss: 0.48493432998657227
recon_loss: 0.030096961185336113, dist_loss: 0.2530972361564636
recon_loss: 0.030096618458628654, dist_loss: 0.8531227707862854
recon_loss: 0.030096251517534256, dist_loss: 0.9328101873397827
recon_loss: 0.03009585291147232, dist_loss: 0.672847330570221
recon_loss: 0.030096882954239845, dist_loss: 0.35407769680023193
recon_loss: 0.030096834525465965, dist_loss: 0.8001287579536438
recon_loss: 0.030095651745796204, dist_loss: 0.7669179439544678
recon_loss: 0.030095091089606285, dist_loss: 1.329319715499878
recon_loss: 0.03009546920657158, dist_loss: 0.831436276435852
recon_loss: 0.030094875022768974, dist_loss: 0.5607973337173462
recon_loss: 0.03009413555264473, dist_loss: 0.629797101020813
recon_loss: 0.030095094814896584, dist_loss: 0.7574737071990967
recon_loss: 0.030095376074314117, dist_loss: 0.4915141463279724
recon_loss: 0.030093951150774956, dist_loss: 0.8902889490127563
recon_loss: 0.030094416812062263, dist_loss: 0.9379663467407227
recon_loss: 0.030095355585217476, dist_loss: 0.8045186996459961
recon_loss: 0.030095694586634636, dist_loss: 1.0650752782821655
recon_loss: 0.0300960224121809, dist_loss: 1.0407460927963257
recon_loss: 0.030096696689724922, dist_loss: 1.2097129821777344
recon_loss: 0.030095994472503662, dist_loss: 0.8670021295547485
recon_loss: 0.03009546548128128, dist_loss: 0.8380872011184692
recon_loss: 0.030095508322119713, dist_loss: 0.36262357234954834
recon_loss: 0.030095376074314117, dist_loss: 0.49620747566223145
recon_loss: 0.030095335096120834, dist_loss: 0.7303964495658875
recon_loss: 0.030095508322119713, dist_loss: 0.5382722616195679
recon_loss: 0.03009534440934658, dist_loss: 0.4482257068157196
recon_loss: 0.030094917863607407, dist_loss: 0.4531151056289673
recon_loss: 0.0300945732742548, dist_loss: 0.6632500886917114
recon_loss: 0.030094148591160774, dist_loss: 1.056952953338623
recon_loss: 0.03009311482310295, dist_loss: 0.9419659376144409
recon_loss: 0.030092060565948486, dist_loss: 0.9892570972442627
recon_loss: 0.030091406777501106, dist_loss: 0.5654852986335754
recon_loss: 0.030090874060988426, dist_loss: 0.734218180179596
recon_loss: 0.030090218409895897, dist_loss: 0.9482360482215881
recon_loss: 0.0300902146846056, dist_loss: 0.5221883654594421
recon_loss: 0.03009081445634365, dist_loss: 0.8423969745635986
recon_loss: 0.03009103052318096, dist_loss: 0.6055521965026855
recon_loss: 0.030090684071183205, dist_loss: 0.47349056601524353
recon_loss: 0.030091093853116035, dist_loss: 0.6403706073760986
recon_loss: 0.030091168358922005, dist_loss: 0.7070796489715576
recon_loss: 0.0300909336656332, dist_loss: 0.6332257986068726
recon_loss: 0.030090633779764175, dist_loss: 1.5382075309753418
recon_loss: 0.030090171843767166, dist_loss: 0.8391772508621216
recon_loss: 0.030089696869254112, dist_loss: 0.37670013308525085
recon_loss: 0.030089156702160835, dist_loss: 0.7690773606300354
Pre-training Epoch 35:  40%|███▉      | 145/367 [00:00<00:01, 177.73it/s]Pre-training Epoch 35:  44%|████▍     | 163/367 [00:00<00:01, 177.10it/s]Pre-training Epoch 35:  49%|████▉     | 181/367 [00:01<00:01, 176.88it/s]Pre-training Epoch 35:  54%|█████▍    | 199/367 [00:01<00:00, 177.32it/s]Pre-training Epoch 35:  59%|█████▉    | 217/367 [00:01<00:00, 175.53it/s]Pre-training Epoch 35:  64%|██████▍   | 235/367 [00:01<00:00, 176.46it/s]Pre-training Epoch 35:  69%|██████▉   | 253/367 [00:01<00:00, 176.72it/s]recon_loss: 0.030088284984230995, dist_loss: 0.4683269262313843
recon_loss: 0.030087582767009735, dist_loss: 0.6036840081214905
recon_loss: 0.030086873099207878, dist_loss: 0.4371890425682068
recon_loss: 0.03008636087179184, dist_loss: 0.9403420686721802
recon_loss: 0.030085720121860504, dist_loss: 0.2885230779647827
recon_loss: 0.030085504055023193, dist_loss: 0.7859131097793579
recon_loss: 0.03008512407541275, dist_loss: 0.48148584365844727
recon_loss: 0.030084721744060516, dist_loss: 0.6856178641319275
recon_loss: 0.0300845205783844, dist_loss: 0.5238351821899414
recon_loss: 0.030084824189543724, dist_loss: 0.5582242012023926
recon_loss: 0.030085554346442223, dist_loss: 0.6018879413604736
recon_loss: 0.030085917562246323, dist_loss: 0.798744797706604
recon_loss: 0.030085822567343712, dist_loss: 0.43059343099594116
recon_loss: 0.030085764825344086, dist_loss: 0.49870923161506653
recon_loss: 0.03008585050702095, dist_loss: 0.704658031463623
recon_loss: 0.030085599049925804, dist_loss: 0.7099262475967407
recon_loss: 0.03008495457470417, dist_loss: 0.5326895713806152
recon_loss: 0.03008430451154709, dist_loss: 1.2657755613327026
recon_loss: 0.0300836693495512, dist_loss: 0.7340850830078125
recon_loss: 0.0300831887871027, dist_loss: 0.6349883079528809
recon_loss: 0.030082805082201958, dist_loss: 0.8882381916046143
recon_loss: 0.03008284792304039, dist_loss: 1.1852961778640747
recon_loss: 0.030083555728197098, dist_loss: 0.8553881049156189
recon_loss: 0.03008352778851986, dist_loss: 0.5246672630310059
recon_loss: 0.030082596465945244, dist_loss: 0.5176414251327515
recon_loss: 0.030083689838647842, dist_loss: 0.40403681993484497
recon_loss: 0.030083464458584785, dist_loss: 0.42450085282325745
recon_loss: 0.03008273057639599, dist_loss: 0.5786498785018921
recon_loss: 0.03008359484374523, dist_loss: 0.64207923412323
recon_loss: 0.030084114521741867, dist_loss: 1.6131138801574707
recon_loss: 0.030083555728197098, dist_loss: 0.5904651880264282
recon_loss: 0.030083294957876205, dist_loss: 0.7427531480789185
recon_loss: 0.030083831399679184, dist_loss: 0.8020849227905273
recon_loss: 0.030083084478974342, dist_loss: 0.7686349153518677
recon_loss: 0.030081558972597122, dist_loss: 0.633050799369812
recon_loss: 0.030081886798143387, dist_loss: 0.878960132598877
recon_loss: 0.03008275292813778, dist_loss: 0.6360530853271484
recon_loss: 0.03008148819208145, dist_loss: 1.0409917831420898
recon_loss: 0.03008228726685047, dist_loss: 0.3924010396003723
recon_loss: 0.030084488913416862, dist_loss: 0.585149884223938
recon_loss: 0.030084533616900444, dist_loss: 0.4064599275588989
recon_loss: 0.030083302408456802, dist_loss: 0.8765367269515991
recon_loss: 0.030082378536462784, dist_loss: 0.6867977380752563
recon_loss: 0.030081918463110924, dist_loss: 0.899638831615448
recon_loss: 0.030080733820796013, dist_loss: 1.0553170442581177
recon_loss: 0.03008018620312214, dist_loss: 0.5844963788986206
recon_loss: 0.030079985037446022, dist_loss: 0.9125364422798157
recon_loss: 0.030080288648605347, dist_loss: 0.7310828566551208
recon_loss: 0.030079435557127, dist_loss: 0.516279399394989
recon_loss: 0.03007868304848671, dist_loss: 0.7141368389129639
recon_loss: 0.030078532174229622, dist_loss: 1.2909306287765503
recon_loss: 0.03007783368229866, dist_loss: 0.8431916236877441
recon_loss: 0.030076196417212486, dist_loss: 0.8251909017562866
recon_loss: 0.03007587231695652, dist_loss: 0.5793489217758179
recon_loss: 0.030075794085860252, dist_loss: 0.42030519247055054
recon_loss: 0.030075237154960632, dist_loss: 0.8944271802902222
recon_loss: 0.030075348913669586, dist_loss: 0.4475190043449402
recon_loss: 0.030074890702962875, dist_loss: 1.1703521013259888
recon_loss: 0.030074207112193108, dist_loss: 0.7651182413101196
recon_loss: 0.03007339872419834, dist_loss: 1.071587324142456
recon_loss: 0.03007427230477333, dist_loss: 0.4799763560295105
recon_loss: 0.03007478453218937, dist_loss: 0.38305553793907166
recon_loss: 0.030074721202254295, dist_loss: 0.6072289943695068
recon_loss: 0.030074626207351685, dist_loss: 0.6578109860420227
recon_loss: 0.03007465787231922, dist_loss: 0.6829004287719727
recon_loss: 0.030074065551161766, dist_loss: 0.40686070919036865
recon_loss: 0.030073091387748718, dist_loss: 0.6370894908905029
recon_loss: 0.03007233329117298, dist_loss: 0.32971811294555664
recon_loss: 0.03007189929485321, dist_loss: 0.40362969040870667
recon_loss: 0.030070515349507332, dist_loss: 0.5559005737304688
recon_loss: 0.03006940335035324, dist_loss: 0.4022252857685089
recon_loss: 0.030069032683968544, dist_loss: 1.3397181034088135
recon_loss: 0.030068762600421906, dist_loss: 0.670270562171936
recon_loss: 0.03006833791732788, dist_loss: 1.0301203727722168
recon_loss: 0.030068496242165565, dist_loss: 0.3980478048324585
recon_loss: 0.030068345367908478, dist_loss: 0.8876262903213501
recon_loss: 0.030068235471844673, dist_loss: 0.563412070274353
recon_loss: 0.030067717656493187, dist_loss: 0.5699235200881958
recon_loss: 0.030067425221204758, dist_loss: 0.7793700695037842
recon_loss: 0.030067456886172295, dist_loss: 0.7628350257873535
recon_loss: 0.03006647154688835, dist_loss: 0.6316759586334229
recon_loss: 0.030065426602959633, dist_loss: 0.7608561515808105
recon_loss: 0.030065089464187622, dist_loss: 0.6450719833374023
recon_loss: 0.030065808445215225, dist_loss: 1.1879351139068604
recon_loss: 0.030066661536693573, dist_loss: 0.7675440311431885
recon_loss: 0.030067160725593567, dist_loss: 0.5364283919334412
recon_loss: 0.03006710298359394, dist_loss: 0.5246904492378235
recon_loss: 0.030066760256886482, dist_loss: 0.5057288408279419
recon_loss: 0.03006625361740589, dist_loss: 0.4489305019378662
recon_loss: 0.030065899714827538, dist_loss: 0.6460567712783813
recon_loss: 0.03006575256586075, dist_loss: 0.5740330815315247
recon_loss: 0.030066218227148056, dist_loss: 0.36902478337287903
recon_loss: 0.030066870152950287, dist_loss: 0.4865660071372986
recon_loss: 0.030067438259720802, dist_loss: 0.5838553309440613
recon_loss: 0.030067773535847664, dist_loss: 0.34847185015678406
recon_loss: 0.030068617314100266, dist_loss: 0.6859561204910278
recon_loss: 0.030068116262555122, dist_loss: 0.444007009267807
recon_loss: 0.030066991224884987, dist_loss: 0.8239634037017822
recon_loss: 0.030065875500440598, dist_loss: 0.9472702741622925
recon_loss: 0.03006443940103054, dist_loss: 0.7021681666374207
recon_loss: 0.030062584206461906, dist_loss: 0.49580419063568115
recon_loss: 0.03006107360124588, dist_loss: 0.6060736179351807
recon_loss: 0.030059901997447014, dist_loss: 0.7969423532485962
recon_loss: 0.030059315264225006, dist_loss: 0.4841423034667969
recon_loss: 0.030059287324547768, dist_loss: 1.0455913543701172
recon_loss: 0.03005894646048546, dist_loss: 0.40662992000579834
recon_loss: 0.030058130621910095, dist_loss: 0.46246206760406494
recon_loss: 0.03005763329565525, dist_loss: 0.45750296115875244
recon_loss: 0.030056938529014587, dist_loss: 0.45818883180618286
recon_loss: 0.030056260526180267, dist_loss: 0.5877346396446228
recon_loss: 0.030055709183216095, dist_loss: 0.851414680480957
recon_loss: 0.030055325478315353, dist_loss: 0.49058759212493896
recon_loss: 0.030055036768317223, dist_loss: 0.613480806350708
recon_loss: 0.03005506843328476, dist_loss: 0.6719112992286682
recon_loss: 0.0300555732101202, dist_loss: 0.7376080751419067
recon_loss: 0.03005540743470192, dist_loss: 0.46384602785110474
recon_loss: 0.030055738985538483, dist_loss: 0.5812405943870544
recon_loss: 0.03005591779947281, dist_loss: 0.7438024282455444
recon_loss: 0.030055589973926544, dist_loss: 0.4695229232311249
recon_loss: 0.03005525842308998, dist_loss: 0.4311760663986206
recon_loss: 0.03005540370941162, dist_loss: 0.7540535926818848
recon_loss: 0.03005613386631012, dist_loss: 0.847549319267273
recon_loss: 0.03005528636276722, dist_loss: 1.1931062936782837
recon_loss: 0.030055250972509384, dist_loss: 0.4734041690826416
recon_loss: 0.03005557879805565, dist_loss: 0.9080033898353577
recon_loss: 0.030055547133088112, dist_loss: 0.6789224147796631
recon_loss: 0.030054962262511253, dist_loss: 1.3752566576004028
recon_loss: 0.030054457485675812, dist_loss: 0.5483131408691406
Pre-training Epoch 35:  74%|███████▍  | 271/367 [00:01<00:00, 174.55it/s]Pre-training Epoch 35:  79%|███████▊  | 289/367 [00:01<00:00, 175.67it/s]Pre-training Epoch 35:  84%|████████▎ | 307/367 [00:01<00:00, 176.73it/s]Pre-training Epoch 35:  89%|████████▊ | 325/367 [00:01<00:00, 175.37it/s]Pre-training Epoch 35:  93%|█████████▎| 343/367 [00:01<00:00, 167.75it/s]Pre-training Epoch 35:  98%|█████████▊| 360/367 [00:02<00:00, 163.19it/s]Pre-training Epoch 35: 100%|██████████| 367/367 [00:02<00:00, 173.41it/s]
recon_loss: 0.030054477974772453, dist_loss: 0.5946310758590698
recon_loss: 0.030054043978452682, dist_loss: 0.4995496869087219
recon_loss: 0.030053572729229927, dist_loss: 0.9537264704704285
recon_loss: 0.030052930116653442, dist_loss: 0.3989264965057373
recon_loss: 0.03005252778530121, dist_loss: 0.6604869961738586
recon_loss: 0.030051983892917633, dist_loss: 0.6540507078170776
recon_loss: 0.030051616951823235, dist_loss: 0.647273063659668
recon_loss: 0.030051305890083313, dist_loss: 0.6114602088928223
recon_loss: 0.03005065768957138, dist_loss: 0.5591793060302734
recon_loss: 0.03005061484873295, dist_loss: 0.5036484599113464
recon_loss: 0.030050717294216156, dist_loss: 0.7887466549873352
recon_loss: 0.03004983440041542, dist_loss: 0.676148533821106
recon_loss: 0.030049478635191917, dist_loss: 1.2376389503479004
recon_loss: 0.030049556866288185, dist_loss: 0.7284320592880249
recon_loss: 0.030048998072743416, dist_loss: 0.33538252115249634
recon_loss: 0.03004857525229454, dist_loss: 1.0294947624206543
recon_loss: 0.03004840575158596, dist_loss: 0.5987623333930969
recon_loss: 0.030048197135329247, dist_loss: 0.35092413425445557
recon_loss: 0.03004789724946022, dist_loss: 0.3399338722229004
recon_loss: 0.03004765883088112, dist_loss: 0.45069408416748047
recon_loss: 0.030047446489334106, dist_loss: 0.8409677743911743
recon_loss: 0.03004705160856247, dist_loss: 0.7294670343399048
recon_loss: 0.030046645551919937, dist_loss: 0.4208104610443115
recon_loss: 0.030046459287405014, dist_loss: 0.6576812267303467
recon_loss: 0.030046183615922928, dist_loss: 0.6583146452903748
recon_loss: 0.030045710504055023, dist_loss: 0.5803366899490356
recon_loss: 0.030045481398701668, dist_loss: 0.6339350342750549
recon_loss: 0.030045632272958755, dist_loss: 0.8838876485824585
recon_loss: 0.030045272782444954, dist_loss: 0.49518051743507385
recon_loss: 0.03004479967057705, dist_loss: 0.48214179277420044
recon_loss: 0.030045004561543465, dist_loss: 0.6889693140983582
recon_loss: 0.030045269057154655, dist_loss: 0.7564033269882202
recon_loss: 0.030045146122574806, dist_loss: 0.7833471298217773
recon_loss: 0.03004470095038414, dist_loss: 0.5242102146148682
recon_loss: 0.030044404789805412, dist_loss: 0.7312389016151428
recon_loss: 0.030044136568903923, dist_loss: 0.5441861748695374
recon_loss: 0.0300441924482584, dist_loss: 0.8467313051223755
recon_loss: 0.030044369399547577, dist_loss: 0.7353255748748779
recon_loss: 0.030044222250580788, dist_loss: 0.6910430192947388
recon_loss: 0.030044211074709892, dist_loss: 0.7840774059295654
recon_loss: 0.030044589191675186, dist_loss: 0.512100338935852
recon_loss: 0.030044684186577797, dist_loss: 0.6944240927696228
recon_loss: 0.03004417195916176, dist_loss: 0.721435546875
recon_loss: 0.03004343807697296, dist_loss: 1.1057560443878174
recon_loss: 0.030043091624975204, dist_loss: 0.22234103083610535
recon_loss: 0.030042648315429688, dist_loss: 1.00030517578125
recon_loss: 0.03004223108291626, dist_loss: 0.9485066533088684
recon_loss: 0.030042076483368874, dist_loss: 0.784491777420044
recon_loss: 0.030042383819818497, dist_loss: 1.4234827756881714
recon_loss: 0.030042380094528198, dist_loss: 0.7113198041915894
recon_loss: 0.030042428523302078, dist_loss: 0.3118795156478882
recon_loss: 0.030042393133044243, dist_loss: 0.7207686305046082
recon_loss: 0.030041946098208427, dist_loss: 0.8441290855407715
recon_loss: 0.03004140965640545, dist_loss: 0.4495682120323181
recon_loss: 0.030041106045246124, dist_loss: 0.8625283241271973
recon_loss: 0.030040854588150978, dist_loss: 0.840064287185669
recon_loss: 0.03004070743918419, dist_loss: 0.9985206127166748
recon_loss: 0.030040692538022995, dist_loss: 0.4831605553627014
recon_loss: 0.03004053793847561, dist_loss: 0.4674783945083618
recon_loss: 0.030040213838219643, dist_loss: 1.2760472297668457
recon_loss: 0.03003978542983532, dist_loss: 0.48493582010269165
recon_loss: 0.030039280652999878, dist_loss: 0.5140739679336548
recon_loss: 0.030038971453905106, dist_loss: 0.47260409593582153
recon_loss: 0.030039211735129356, dist_loss: 0.7724746465682983
recon_loss: 0.030039945617318153, dist_loss: 0.6529855132102966
recon_loss: 0.030041228979825974, dist_loss: 0.5070629119873047
recon_loss: 0.0300416462123394, dist_loss: 1.0319510698318481
recon_loss: 0.03004094399511814, dist_loss: 0.5268229246139526
recon_loss: 0.030040305107831955, dist_loss: 0.6357748508453369
recon_loss: 0.030039655044674873, dist_loss: 0.8414716124534607
recon_loss: 0.03003915771842003, dist_loss: 0.47971251606941223
recon_loss: 0.03003874607384205, dist_loss: 0.5306422114372253
recon_loss: 0.030038321390748024, dist_loss: 0.5492703914642334
recon_loss: 0.030038146302103996, dist_loss: 0.45198580622673035
recon_loss: 0.030037883669137955, dist_loss: 0.6141904592514038
recon_loss: 0.030037567019462585, dist_loss: 0.80292809009552
recon_loss: 0.0300372913479805, dist_loss: 0.7353737354278564
recon_loss: 0.03003714419901371, dist_loss: 0.8742671012878418
recon_loss: 0.030036451295018196, dist_loss: 0.5571691989898682
recon_loss: 0.0300357174128294, dist_loss: 0.61283278465271
recon_loss: 0.03003537282347679, dist_loss: 0.6549031138420105
recon_loss: 0.03003460355103016, dist_loss: 0.4434289336204529
recon_loss: 0.030033985152840614, dist_loss: 0.8211756944656372
recon_loss: 0.030033700168132782, dist_loss: 0.8306796550750732
recon_loss: 0.03003358654677868, dist_loss: 0.441120982170105
recon_loss: 0.03003362938761711, dist_loss: 0.9301483631134033
recon_loss: 0.030033692717552185, dist_loss: 0.7203084230422974
recon_loss: 0.030033523216843605, dist_loss: 1.1570827960968018
recon_loss: 0.03003329411149025, dist_loss: 0.6230854988098145
recon_loss: 0.030032789334654808, dist_loss: 0.8527131080627441
recon_loss: 0.030032165348529816, dist_loss: 0.7129703760147095
recon_loss: 0.03003179468214512, dist_loss: 1.023661494255066
recon_loss: 0.030031494796276093, dist_loss: 0.6866961717605591
recon_loss: 0.030030911788344383, dist_loss: 0.6159452199935913
recon_loss: 0.03003065474331379, dist_loss: 0.9321633577346802
recon_loss: 0.03003065101802349, dist_loss: 0.7677155137062073
recon_loss: 0.03003029152750969, dist_loss: 0.6570680737495422
recon_loss: 0.030029797926545143, dist_loss: 0.6167129874229431
recon_loss: 0.03002956695854664, dist_loss: 0.799322247505188
recon_loss: 0.030029140412807465, dist_loss: 0.5506150722503662
recon_loss: 0.03002876602113247, dist_loss: 0.5408110618591309
recon_loss: 0.030028710141777992, dist_loss: 0.7948819398880005
recon_loss: 0.03002859652042389, dist_loss: 1.0788862705230713
recon_loss: 0.03002811037003994, dist_loss: 0.2055802047252655
recon_loss: 0.03002803958952427, dist_loss: 0.4294065833091736
recon_loss: 0.03002818487584591, dist_loss: 1.0368413925170898
recon_loss: 0.03002765215933323, dist_loss: 0.8066563606262207
recon_loss: 0.030027277767658234, dist_loss: 0.43467891216278076
recon_loss: 0.030027328059077263, dist_loss: 0.6633129119873047
recon_loss: 0.03002699464559555, dist_loss: 0.46652552485466003
recon_loss: 0.030026674270629883, dist_loss: 0.8024924397468567
Pre-training Epoch 36:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 36:   4%|▍         | 16/367 [00:00<00:02, 157.10it/s]Pre-training Epoch 36:   9%|▉         | 34/367 [00:00<00:01, 168.39it/s]Pre-training Epoch 36:  14%|█▍        | 52/367 [00:00<00:01, 172.18it/s]Pre-training Epoch 36:  19%|█▉        | 70/367 [00:00<00:01, 173.71it/s]Pre-training Epoch 36:  24%|██▍       | 88/367 [00:00<00:01, 173.77it/s]Pre-training Epoch 36:  29%|██▉       | 106/367 [00:00<00:01, 173.13it/s]Pre-training Epoch 36:  34%|███▍      | 124/367 [00:00<00:01, 170.58it/s]recon_loss: 0.030027495697140694, dist_loss: 0.759269118309021
recon_loss: 0.030028169974684715, dist_loss: 0.5037848949432373
recon_loss: 0.030028462409973145, dist_loss: 0.5926518440246582
recon_loss: 0.03002847731113434, dist_loss: 0.3237200081348419
recon_loss: 0.030028371140360832, dist_loss: 0.5512456893920898
recon_loss: 0.030028074979782104, dist_loss: 0.37161457538604736
recon_loss: 0.03002764843404293, dist_loss: 1.0526542663574219
recon_loss: 0.030027080327272415, dist_loss: 0.6241657733917236
recon_loss: 0.030026918277144432, dist_loss: 0.5232843160629272
recon_loss: 0.030026638880372047, dist_loss: 1.1509302854537964
recon_loss: 0.030026299878954887, dist_loss: 0.46387916803359985
recon_loss: 0.030025620013475418, dist_loss: 0.5933008193969727
recon_loss: 0.03002486377954483, dist_loss: 0.5082583427429199
recon_loss: 0.03002406656742096, dist_loss: 0.5370787382125854
recon_loss: 0.030023450031876564, dist_loss: 0.4487212896347046
recon_loss: 0.030022818595170975, dist_loss: 0.5997442603111267
recon_loss: 0.030022570863366127, dist_loss: 1.0155596733093262
recon_loss: 0.030022811144590378, dist_loss: 0.6667990684509277
recon_loss: 0.030023446306586266, dist_loss: 0.8680786490440369
recon_loss: 0.03002369962632656, dist_loss: 0.36564481258392334
recon_loss: 0.030023615807294846, dist_loss: 0.5681641697883606
recon_loss: 0.03002346307039261, dist_loss: 1.2808372974395752
recon_loss: 0.03002331219613552, dist_loss: 0.4462059736251831
recon_loss: 0.030023226514458656, dist_loss: 0.6280611753463745
recon_loss: 0.030023064464330673, dist_loss: 0.928311288356781
recon_loss: 0.030022313818335533, dist_loss: 0.44991418719291687
recon_loss: 0.03002128005027771, dist_loss: 0.66325443983078
recon_loss: 0.03002074360847473, dist_loss: 0.530328094959259
recon_loss: 0.03001980111002922, dist_loss: 0.5983022451400757
recon_loss: 0.030019115656614304, dist_loss: 0.9055325984954834
recon_loss: 0.03001902811229229, dist_loss: 0.48337313532829285
recon_loss: 0.030018622055649757, dist_loss: 0.8229583501815796
recon_loss: 0.03001772239804268, dist_loss: 0.45712196826934814
recon_loss: 0.03001735545694828, dist_loss: 0.49009543657302856
recon_loss: 0.03001684695482254, dist_loss: 0.6487909555435181
recon_loss: 0.03001594729721546, dist_loss: 0.5946601629257202
recon_loss: 0.030015796422958374, dist_loss: 0.5882928967475891
recon_loss: 0.030015524476766586, dist_loss: 0.3553016185760498
recon_loss: 0.030014900490641594, dist_loss: 0.4839768707752228
recon_loss: 0.030015140771865845, dist_loss: 0.6136680841445923
recon_loss: 0.030015606433153152, dist_loss: 0.9189070463180542
recon_loss: 0.030015965923666954, dist_loss: 0.27223074436187744
recon_loss: 0.030016649514436722, dist_loss: 0.5533189177513123
recon_loss: 0.03001759573817253, dist_loss: 0.7355158925056458
recon_loss: 0.030018646270036697, dist_loss: 0.6185296773910522
recon_loss: 0.030020184814929962, dist_loss: 0.35559797286987305
recon_loss: 0.03002060204744339, dist_loss: 1.0095620155334473
recon_loss: 0.030021347105503082, dist_loss: 0.555732250213623
recon_loss: 0.030021794140338898, dist_loss: 0.7683303952217102
recon_loss: 0.030021851882338524, dist_loss: 0.43054771423339844
recon_loss: 0.030022183433175087, dist_loss: 0.7299090027809143
recon_loss: 0.030022267252206802, dist_loss: 0.8218103647232056
recon_loss: 0.030021952465176582, dist_loss: 1.1054182052612305
recon_loss: 0.030021710321307182, dist_loss: 0.5412068963050842
recon_loss: 0.03002135641872883, dist_loss: 0.6734355688095093
recon_loss: 0.030020417645573616, dist_loss: 0.5072149038314819
recon_loss: 0.030018681660294533, dist_loss: 0.4318169951438904
recon_loss: 0.030016900971531868, dist_loss: 0.8484729528427124
recon_loss: 0.03001517243683338, dist_loss: 0.729071855545044
recon_loss: 0.030013784766197205, dist_loss: 0.7445928454399109
recon_loss: 0.030013030394911766, dist_loss: 0.3802058696746826
recon_loss: 0.030012905597686768, dist_loss: 0.3416539132595062
recon_loss: 0.03001328743994236, dist_loss: 0.7553413510322571
recon_loss: 0.030013417825102806, dist_loss: 1.2904688119888306
recon_loss: 0.030013350769877434, dist_loss: 1.3465831279754639
recon_loss: 0.030013594776391983, dist_loss: 0.6913139820098877
recon_loss: 0.030013516545295715, dist_loss: 0.33530282974243164
recon_loss: 0.030013304203748703, dist_loss: 0.3677772581577301
recon_loss: 0.030013220384716988, dist_loss: 0.5194717645645142
recon_loss: 0.030012723058462143, dist_loss: 0.543677806854248
recon_loss: 0.030012154951691628, dist_loss: 0.6204692125320435
recon_loss: 0.03001159429550171, dist_loss: 0.21109424531459808
recon_loss: 0.030010884627699852, dist_loss: 0.4816620647907257
recon_loss: 0.03001011162996292, dist_loss: 0.642386257648468
recon_loss: 0.030009755864739418, dist_loss: 0.4833190441131592
recon_loss: 0.030009696260094643, dist_loss: 0.7682796716690063
recon_loss: 0.030009334906935692, dist_loss: 0.8255724906921387
recon_loss: 0.030009007081389427, dist_loss: 1.2198388576507568
recon_loss: 0.030008548870682716, dist_loss: 1.0414587259292603
recon_loss: 0.030008312314748764, dist_loss: 1.060792326927185
recon_loss: 0.03000851348042488, dist_loss: 0.6521267294883728
recon_loss: 0.030008703470230103, dist_loss: 0.4547184109687805
recon_loss: 0.03000888042151928, dist_loss: 0.5012269616127014
recon_loss: 0.030009029433131218, dist_loss: 0.4387076497077942
recon_loss: 0.030008869245648384, dist_loss: 0.9634262323379517
recon_loss: 0.030008655041456223, dist_loss: 0.8626986742019653
recon_loss: 0.030008668079972267, dist_loss: 0.5081870555877686
recon_loss: 0.030008425936102867, dist_loss: 0.3908582925796509
recon_loss: 0.030008072033524513, dist_loss: 0.42099112272262573
recon_loss: 0.030007842928171158, dist_loss: 1.1272757053375244
recon_loss: 0.030007483437657356, dist_loss: 0.6684751510620117
recon_loss: 0.030007105320692062, dist_loss: 0.598997950553894
recon_loss: 0.030006686225533485, dist_loss: 1.177392601966858
recon_loss: 0.030006559565663338, dist_loss: 0.461462140083313
recon_loss: 0.03000621311366558, dist_loss: 0.7121219635009766
recon_loss: 0.030005857348442078, dist_loss: 0.8548864126205444
recon_loss: 0.030006233602762222, dist_loss: 0.6236926317214966
recon_loss: 0.030006911605596542, dist_loss: 0.7822974920272827
recon_loss: 0.030006395652890205, dist_loss: 0.4030466377735138
recon_loss: 0.030006149783730507, dist_loss: 1.109173059463501
recon_loss: 0.030006788671016693, dist_loss: 0.5624872446060181
recon_loss: 0.03000662662088871, dist_loss: 0.6071258187294006
recon_loss: 0.030005570501089096, dist_loss: 0.6261371374130249
recon_loss: 0.030005740001797676, dist_loss: 0.5295296311378479
recon_loss: 0.030005740001797676, dist_loss: 0.9270219206809998
recon_loss: 0.030005143955349922, dist_loss: 0.740338921546936
recon_loss: 0.03000509738922119, dist_loss: 0.7091028094291687
recon_loss: 0.030005214735865593, dist_loss: 0.7947593927383423
recon_loss: 0.030004970729351044, dist_loss: 0.4751061797142029
recon_loss: 0.03000488691031933, dist_loss: 0.7801927924156189
recon_loss: 0.030004722997546196, dist_loss: 0.5866633653640747
recon_loss: 0.030004188418388367, dist_loss: 0.6213720440864563
recon_loss: 0.03000364452600479, dist_loss: 0.38633179664611816
recon_loss: 0.030002765357494354, dist_loss: 0.4796842932701111
recon_loss: 0.030002035200595856, dist_loss: 0.6855766177177429
recon_loss: 0.030001992359757423, dist_loss: 0.6591629981994629
recon_loss: 0.030002253130078316, dist_loss: 0.6536247730255127
recon_loss: 0.030002519488334656, dist_loss: 0.7085922956466675
recon_loss: 0.030002331361174583, dist_loss: 0.5675128102302551
recon_loss: 0.03000202775001526, dist_loss: 0.5759290456771851
recon_loss: 0.03000122308731079, dist_loss: 0.6629780530929565
recon_loss: 0.030000334605574608, dist_loss: 0.6929301023483276
recon_loss: 0.029999947175383568, dist_loss: 0.5948922038078308
recon_loss: 0.029999660328030586, dist_loss: 0.4840555489063263
recon_loss: 0.02999909222126007, dist_loss: 0.41735202074050903
recon_loss: 0.029998743906617165, dist_loss: 0.8825799822807312
recon_loss: 0.02999887429177761, dist_loss: 0.6980997920036316
recon_loss: 0.029998231679201126, dist_loss: 0.742276668548584
Pre-training Epoch 36:  39%|███▊      | 142/367 [00:00<00:01, 172.55it/s]Pre-training Epoch 36:  44%|████▍     | 162/367 [00:00<00:01, 178.43it/s]Pre-training Epoch 36:  49%|████▉     | 180/367 [00:01<00:01, 177.09it/s]Pre-training Epoch 36:  54%|█████▍    | 198/367 [00:01<00:00, 177.84it/s]Pre-training Epoch 36:  59%|█████▉    | 216/367 [00:01<00:00, 176.39it/s]Pre-training Epoch 36:  64%|██████▍   | 234/367 [00:01<00:00, 175.53it/s]Pre-training Epoch 36:  69%|██████▊   | 252/367 [00:01<00:00, 175.18it/s]recon_loss: 0.029997846111655235, dist_loss: 0.7258362770080566
recon_loss: 0.029997695237398148, dist_loss: 0.8505164384841919
recon_loss: 0.029996812343597412, dist_loss: 0.7607320547103882
recon_loss: 0.029996484518051147, dist_loss: 0.8557058572769165
recon_loss: 0.02999689429998398, dist_loss: 0.7060081958770752
recon_loss: 0.0299975648522377, dist_loss: 0.8295419812202454
recon_loss: 0.029997635632753372, dist_loss: 0.5673354864120483
recon_loss: 0.029997320845723152, dist_loss: 0.5391479730606079
recon_loss: 0.029996609315276146, dist_loss: 0.5263321399688721
recon_loss: 0.029996242374181747, dist_loss: 0.458328515291214
recon_loss: 0.029995402321219444, dist_loss: 0.8677124977111816
recon_loss: 0.029994992539286613, dist_loss: 1.2009313106536865
recon_loss: 0.029994893819093704, dist_loss: 0.7091982364654541
recon_loss: 0.029995447024703026, dist_loss: 0.8042833805084229
recon_loss: 0.029995881021022797, dist_loss: 0.9765671491622925
recon_loss: 0.029995840042829514, dist_loss: 0.8091186285018921
recon_loss: 0.029995013028383255, dist_loss: 0.4459547996520996
recon_loss: 0.02999456599354744, dist_loss: 0.668199360370636
recon_loss: 0.029993876814842224, dist_loss: 0.6829867959022522
recon_loss: 0.029993122443556786, dist_loss: 0.7498332262039185
recon_loss: 0.02999255061149597, dist_loss: 0.46141892671585083
recon_loss: 0.029993003234267235, dist_loss: 0.7079463005065918
recon_loss: 0.029993023723363876, dist_loss: 0.9512640237808228
recon_loss: 0.029993101954460144, dist_loss: 0.5137455463409424
recon_loss: 0.029993707314133644, dist_loss: 0.5460453033447266
recon_loss: 0.029993347823619843, dist_loss: 0.5548624992370605
recon_loss: 0.02999221906065941, dist_loss: 0.7409970760345459
recon_loss: 0.029991397634148598, dist_loss: 0.904872477054596
recon_loss: 0.0299912728369236, dist_loss: 0.6091959476470947
recon_loss: 0.029991474002599716, dist_loss: 0.6231340765953064
recon_loss: 0.029991639778017998, dist_loss: 0.7100359797477722
recon_loss: 0.029992416501045227, dist_loss: 0.9315783381462097
recon_loss: 0.02999255806207657, dist_loss: 0.4467650353908539
recon_loss: 0.0299913939088583, dist_loss: 0.5566179156303406
recon_loss: 0.02999049425125122, dist_loss: 0.5186831951141357
recon_loss: 0.02998998947441578, dist_loss: 0.3209437131881714
recon_loss: 0.02999032847583294, dist_loss: 0.8946892023086548
recon_loss: 0.029990747570991516, dist_loss: 0.8691211938858032
recon_loss: 0.029991500079631805, dist_loss: 0.8152740001678467
recon_loss: 0.02999183163046837, dist_loss: 0.4167090654373169
recon_loss: 0.029991449788212776, dist_loss: 0.7623951435089111
recon_loss: 0.029990829527378082, dist_loss: 0.41645705699920654
recon_loss: 0.02999008074402809, dist_loss: 0.6182805299758911
recon_loss: 0.02998991124331951, dist_loss: 0.5655307173728943
recon_loss: 0.02998931147158146, dist_loss: 0.4685651957988739
recon_loss: 0.029989460483193398, dist_loss: 0.775005578994751
recon_loss: 0.029989875853061676, dist_loss: 0.4460003077983856
recon_loss: 0.029990166425704956, dist_loss: 0.4176064133644104
recon_loss: 0.02999013103544712, dist_loss: 0.7295380234718323
recon_loss: 0.02999039925634861, dist_loss: 0.5568376779556274
recon_loss: 0.02999032847583294, dist_loss: 0.4270278513431549
recon_loss: 0.02998962253332138, dist_loss: 0.4653244614601135
recon_loss: 0.02998884581029415, dist_loss: 0.4930119812488556
recon_loss: 0.029988329857587814, dist_loss: 0.6229075789451599
recon_loss: 0.029987752437591553, dist_loss: 0.6318644881248474
recon_loss: 0.029987063258886337, dist_loss: 0.48454007506370544
recon_loss: 0.029986675828695297, dist_loss: 0.24161028861999512
recon_loss: 0.029986459761857986, dist_loss: 0.9380275011062622
recon_loss: 0.029986128211021423, dist_loss: 0.6503568887710571
recon_loss: 0.029985826462507248, dist_loss: 0.842943549156189
recon_loss: 0.029985720291733742, dist_loss: 0.7320858836174011
recon_loss: 0.02998541295528412, dist_loss: 0.7191125154495239
recon_loss: 0.029985271394252777, dist_loss: 0.7433500289916992
recon_loss: 0.029985196888446808, dist_loss: 0.7807673215866089
recon_loss: 0.02998480200767517, dist_loss: 0.8927001953125
recon_loss: 0.029984526336193085, dist_loss: 0.6366103887557983
recon_loss: 0.02998456172645092, dist_loss: 0.6585081219673157
recon_loss: 0.029984619468450546, dist_loss: 0.6377508640289307
recon_loss: 0.029983708634972572, dist_loss: 0.7359637022018433
recon_loss: 0.02998329885303974, dist_loss: 0.39788389205932617
recon_loss: 0.029982734471559525, dist_loss: 0.6738673448562622
recon_loss: 0.029982050880789757, dist_loss: 0.7659406065940857
recon_loss: 0.029981952160596848, dist_loss: 0.7665551900863647
recon_loss: 0.02998167648911476, dist_loss: 0.7268005013465881
recon_loss: 0.029981069266796112, dist_loss: 0.9962003231048584
recon_loss: 0.02998056821525097, dist_loss: 0.5253810286521912
recon_loss: 0.029980532824993134, dist_loss: 0.609383761882782
recon_loss: 0.029979614540934563, dist_loss: 0.7242674231529236
recon_loss: 0.029978923499584198, dist_loss: 0.6876586675643921
recon_loss: 0.029979072511196136, dist_loss: 0.7501969933509827
recon_loss: 0.02997947856783867, dist_loss: 0.8970335721969604
recon_loss: 0.029979029670357704, dist_loss: 0.4675922095775604
recon_loss: 0.02997957356274128, dist_loss: 0.5052642226219177
recon_loss: 0.029979806393384933, dist_loss: 1.056658387184143
recon_loss: 0.029978740960359573, dist_loss: 0.9517306685447693
recon_loss: 0.029978211969137192, dist_loss: 0.6203305721282959
recon_loss: 0.029977913945913315, dist_loss: 0.4299378991127014
recon_loss: 0.029977262020111084, dist_loss: 0.690623939037323
recon_loss: 0.029976775869727135, dist_loss: 0.4857657551765442
recon_loss: 0.02997691184282303, dist_loss: 0.895648181438446
recon_loss: 0.02997647225856781, dist_loss: 0.777631402015686
recon_loss: 0.02997596003115177, dist_loss: 0.5979504585266113
recon_loss: 0.029975656419992447, dist_loss: 0.5426901578903198
recon_loss: 0.029975328594446182, dist_loss: 0.6247977018356323
recon_loss: 0.02997465431690216, dist_loss: 0.5513980984687805
recon_loss: 0.029974117875099182, dist_loss: 0.6371946334838867
recon_loss: 0.029973909258842468, dist_loss: 0.9306797981262207
recon_loss: 0.02997353859245777, dist_loss: 0.502638041973114
recon_loss: 0.029973560944199562, dist_loss: 0.5350110530853271
recon_loss: 0.029974043369293213, dist_loss: 0.6345500349998474
recon_loss: 0.029974315315485, dist_loss: 0.4436829090118408
recon_loss: 0.029974104836583138, dist_loss: 1.3483726978302002
recon_loss: 0.02997424453496933, dist_loss: 0.8830691576004028
recon_loss: 0.029974238947033882, dist_loss: 0.8629188537597656
recon_loss: 0.029974089935421944, dist_loss: 1.0301464796066284
recon_loss: 0.029974104836583138, dist_loss: 0.6701997518539429
recon_loss: 0.02997397631406784, dist_loss: 0.8301202654838562
recon_loss: 0.02997363917529583, dist_loss: 1.2420552968978882
recon_loss: 0.029973363503813744, dist_loss: 0.8560813665390015
recon_loss: 0.029973099008202553, dist_loss: 1.0267492532730103
recon_loss: 0.02997276373207569, dist_loss: 0.5655774474143982
recon_loss: 0.029972368851304054, dist_loss: 1.1618316173553467
recon_loss: 0.02997194416821003, dist_loss: 0.4933707118034363
recon_loss: 0.029971707612276077, dist_loss: 0.48908519744873047
recon_loss: 0.02997138723731041, dist_loss: 0.9731159806251526
recon_loss: 0.029971027746796608, dist_loss: 0.5090234875679016
recon_loss: 0.029970567673444748, dist_loss: 0.4477420151233673
recon_loss: 0.029970230534672737, dist_loss: 0.7463840246200562
recon_loss: 0.029970042407512665, dist_loss: 0.6559336185455322
recon_loss: 0.029969876632094383, dist_loss: 0.9842352867126465
recon_loss: 0.02996954880654812, dist_loss: 0.90682452917099
recon_loss: 0.029969291761517525, dist_loss: 0.6113337278366089
recon_loss: 0.029969114810228348, dist_loss: 0.7605180144309998
recon_loss: 0.029968930408358574, dist_loss: 0.8549944758415222
recon_loss: 0.029968535527586937, dist_loss: 1.1901683807373047
recon_loss: 0.02996811270713806, dist_loss: 0.7690141201019287
recon_loss: 0.029967674985527992, dist_loss: 0.9809997081756592
recon_loss: 0.02996738627552986, dist_loss: 0.4920044243335724
Pre-training Epoch 36:  74%|███████▎  | 270/367 [00:01<00:00, 175.32it/s]Pre-training Epoch 36:  78%|███████▊  | 288/367 [00:01<00:00, 173.47it/s]Pre-training Epoch 36:  83%|████████▎ | 306/367 [00:01<00:00, 173.10it/s]Pre-training Epoch 36:  88%|████████▊ | 324/367 [00:01<00:00, 173.55it/s]Pre-training Epoch 36:  93%|█████████▎| 342/367 [00:01<00:00, 174.03it/s]Pre-training Epoch 36:  98%|█████████▊| 360/367 [00:02<00:00, 173.57it/s]Pre-training Epoch 36: 100%|██████████| 367/367 [00:02<00:00, 173.96it/s]
recon_loss: 0.029967153444886208, dist_loss: 0.7684957385063171
recon_loss: 0.02996663749217987, dist_loss: 0.5525860786437988
recon_loss: 0.029966427013278008, dist_loss: 1.0302302837371826
recon_loss: 0.029966728761792183, dist_loss: 0.5108096599578857
recon_loss: 0.029966525733470917, dist_loss: 0.5328814387321472
recon_loss: 0.029965953901410103, dist_loss: 0.4980255961418152
recon_loss: 0.029966017231345177, dist_loss: 0.7992891073226929
recon_loss: 0.029965903609991074, dist_loss: 0.6697403192520142
recon_loss: 0.029965614899992943, dist_loss: 0.5382461547851562
recon_loss: 0.029965560883283615, dist_loss: 0.899093747138977
recon_loss: 0.02996545284986496, dist_loss: 0.7347977161407471
recon_loss: 0.029965560883283615, dist_loss: 0.4580311179161072
recon_loss: 0.029965780675411224, dist_loss: 0.7249309420585632
recon_loss: 0.029966002330183983, dist_loss: 0.6348710060119629
recon_loss: 0.029966052621603012, dist_loss: 0.598833441734314
recon_loss: 0.029966361820697784, dist_loss: 1.0014896392822266
recon_loss: 0.029966814443469048, dist_loss: 1.068715214729309
recon_loss: 0.029966270551085472, dist_loss: 1.0523555278778076
recon_loss: 0.029965465888381004, dist_loss: 0.4567875266075134
recon_loss: 0.029965007677674294, dist_loss: 0.40437108278274536
recon_loss: 0.029965007677674294, dist_loss: 0.7982771396636963
recon_loss: 0.029964521527290344, dist_loss: 0.698349118232727
recon_loss: 0.02996419556438923, dist_loss: 0.8475823402404785
recon_loss: 0.02996375784277916, dist_loss: 0.8447225093841553
recon_loss: 0.029962928965687752, dist_loss: 0.7974997758865356
recon_loss: 0.029962357133626938, dist_loss: 0.8390547037124634
recon_loss: 0.029961271211504936, dist_loss: 0.5080757737159729
recon_loss: 0.029960639774799347, dist_loss: 0.8162082433700562
recon_loss: 0.0299600288271904, dist_loss: 0.4969022274017334
recon_loss: 0.02995944768190384, dist_loss: 0.6401286125183105
recon_loss: 0.029958974570035934, dist_loss: 0.993920087814331
recon_loss: 0.029958486557006836, dist_loss: 0.5151722431182861
recon_loss: 0.029958056285977364, dist_loss: 0.6047791838645935
recon_loss: 0.029957681894302368, dist_loss: 0.5036785006523132
recon_loss: 0.029957344755530357, dist_loss: 1.0441490411758423
recon_loss: 0.029957104474306107, dist_loss: 0.6683307886123657
recon_loss: 0.02995678223669529, dist_loss: 0.9438848495483398
recon_loss: 0.029956644400954247, dist_loss: 0.7699010372161865
recon_loss: 0.029956478625535965, dist_loss: 0.5311765670776367
recon_loss: 0.02995634265244007, dist_loss: 0.2480185329914093
recon_loss: 0.029955649748444557, dist_loss: 0.6466735601425171
recon_loss: 0.029955685138702393, dist_loss: 0.6367275714874268
recon_loss: 0.02995525486767292, dist_loss: 0.6481722593307495
recon_loss: 0.029955117031931877, dist_loss: 0.4647691547870636
recon_loss: 0.029955007135868073, dist_loss: 0.6954108476638794
recon_loss: 0.029954694211483, dist_loss: 0.9578111171722412
recon_loss: 0.029954545199871063, dist_loss: 0.6505590081214905
recon_loss: 0.029954418540000916, dist_loss: 0.7669306993484497
recon_loss: 0.029954474419355392, dist_loss: 0.8682703971862793
recon_loss: 0.029954535886645317, dist_loss: 0.811676025390625
recon_loss: 0.029954666271805763, dist_loss: 0.9381296038627625
recon_loss: 0.029954683035612106, dist_loss: 0.5348758101463318
recon_loss: 0.029954608529806137, dist_loss: 0.49007266759872437
recon_loss: 0.029954437166452408, dist_loss: 0.9216500520706177
recon_loss: 0.029954154044389725, dist_loss: 0.5803154706954956
recon_loss: 0.029953928664326668, dist_loss: 0.7376988530158997
recon_loss: 0.029953673481941223, dist_loss: 0.6990208029747009
recon_loss: 0.029953405261039734, dist_loss: 1.2220197916030884
recon_loss: 0.029953179880976677, dist_loss: 0.6817312836647034
recon_loss: 0.02995281293988228, dist_loss: 0.9883667230606079
recon_loss: 0.029952291399240494, dist_loss: 1.2982221841812134
recon_loss: 0.02995208650827408, dist_loss: 1.2016048431396484
recon_loss: 0.029951663687825203, dist_loss: 0.5735338926315308
recon_loss: 0.02995126135647297, dist_loss: 0.4297369122505188
recon_loss: 0.029950914904475212, dist_loss: 0.6489589214324951
recon_loss: 0.029950808733701706, dist_loss: 1.1566812992095947
recon_loss: 0.029950696974992752, dist_loss: 0.580342173576355
recon_loss: 0.029950737953186035, dist_loss: 0.5303981304168701
recon_loss: 0.029950933530926704, dist_loss: 0.7846077680587769
recon_loss: 0.029950914904475212, dist_loss: 0.4922736883163452
recon_loss: 0.029950492084026337, dist_loss: 0.3497520089149475
recon_loss: 0.029950259253382683, dist_loss: 0.6011549234390259
recon_loss: 0.02995031513273716, dist_loss: 0.46602797508239746
recon_loss: 0.029950004070997238, dist_loss: 0.508529782295227
recon_loss: 0.029949616640806198, dist_loss: 1.110294222831726
recon_loss: 0.029949799180030823, dist_loss: 0.3924393653869629
recon_loss: 0.02995016612112522, dist_loss: 0.5583795309066772
recon_loss: 0.029949605464935303, dist_loss: 0.5117791295051575
recon_loss: 0.029950875788927078, dist_loss: 0.46720096468925476
recon_loss: 0.029950875788927078, dist_loss: 0.668279767036438
recon_loss: 0.029950633645057678, dist_loss: 0.4247777462005615
recon_loss: 0.02995157055556774, dist_loss: 0.7943859100341797
recon_loss: 0.029952382668852806, dist_loss: 0.6686618328094482
recon_loss: 0.029950523748993874, dist_loss: 0.6644842028617859
recon_loss: 0.029949631541967392, dist_loss: 1.2045230865478516
recon_loss: 0.029950492084026337, dist_loss: 1.141910433769226
recon_loss: 0.02995031140744686, dist_loss: 0.828946590423584
recon_loss: 0.02994973585009575, dist_loss: 0.5051049590110779
recon_loss: 0.029950646683573723, dist_loss: 0.6625258922576904
recon_loss: 0.029950590804219246, dist_loss: 0.6652055382728577
recon_loss: 0.029949044808745384, dist_loss: 0.4947085380554199
recon_loss: 0.029948215931653976, dist_loss: 0.538664698600769
recon_loss: 0.02994752861559391, dist_loss: 0.6045489311218262
recon_loss: 0.02994614467024803, dist_loss: 0.5196526050567627
recon_loss: 0.029945623129606247, dist_loss: 0.6074142456054688
recon_loss: 0.029946018010377884, dist_loss: 0.47764158248901367
recon_loss: 0.029946235939860344, dist_loss: 0.6185430288314819
recon_loss: 0.02994653210043907, dist_loss: 0.6320978999137878
recon_loss: 0.029945990070700645, dist_loss: 1.2670516967773438
recon_loss: 0.029944606125354767, dist_loss: 0.7098398804664612
recon_loss: 0.029943829402327538, dist_loss: 0.4919581413269043
recon_loss: 0.02994338795542717, dist_loss: 0.5802802443504333
recon_loss: 0.02994283102452755, dist_loss: 0.9071922302246094
recon_loss: 0.029942326247692108, dist_loss: 0.5108388066291809
recon_loss: 0.029942065477371216, dist_loss: 0.5586281418800354
recon_loss: 0.029941868036985397, dist_loss: 0.6597164273262024
recon_loss: 0.02994171343743801, dist_loss: 0.6732988357543945
recon_loss: 0.029941575601696968, dist_loss: 0.640160083770752
recon_loss: 0.02994142659008503, dist_loss: 0.5594887733459473
recon_loss: 0.029941098764538765, dist_loss: 0.44024956226348877
recon_loss: 0.02994052693247795, dist_loss: 0.5759693384170532
Pre-training Epoch 37:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 37:   5%|▍         | 17/367 [00:00<00:02, 168.55it/s]Pre-training Epoch 37:  10%|▉         | 36/367 [00:00<00:01, 176.06it/s]Pre-training Epoch 37:  15%|█▍        | 54/367 [00:00<00:01, 175.42it/s]Pre-training Epoch 37:  20%|█▉        | 72/367 [00:00<00:01, 174.54it/s]Pre-training Epoch 37:  25%|██▍       | 90/367 [00:00<00:01, 174.68it/s]Pre-training Epoch 37:  29%|██▉       | 108/367 [00:00<00:01, 175.48it/s]Pre-training Epoch 37:  34%|███▍      | 126/367 [00:00<00:01, 175.62it/s]recon_loss: 0.029939867556095123, dist_loss: 1.0048468112945557
recon_loss: 0.029939673840999603, dist_loss: 0.7347549796104431
recon_loss: 0.029939232394099236, dist_loss: 0.5494146347045898
recon_loss: 0.02993938699364662, dist_loss: 0.4548635184764862
recon_loss: 0.029940064996480942, dist_loss: 0.7405725717544556
recon_loss: 0.029939651489257812, dist_loss: 0.613261342048645
recon_loss: 0.029939208179712296, dist_loss: 0.6673699617385864
recon_loss: 0.029938742518424988, dist_loss: 0.4052197337150574
recon_loss: 0.029937760904431343, dist_loss: 0.6145738363265991
recon_loss: 0.02993714064359665, dist_loss: 0.5759884715080261
recon_loss: 0.02993686869740486, dist_loss: 0.5837203860282898
recon_loss: 0.029936550185084343, dist_loss: 0.9726085662841797
recon_loss: 0.02993677742779255, dist_loss: 0.6586474180221558
recon_loss: 0.02993769757449627, dist_loss: 0.8767061233520508
recon_loss: 0.029939081519842148, dist_loss: 0.9724569916725159
recon_loss: 0.02993953973054886, dist_loss: 0.3638257384300232
recon_loss: 0.029939796775579453, dist_loss: 0.44553643465042114
recon_loss: 0.029940452426671982, dist_loss: 0.6916083097457886
recon_loss: 0.02993805706501007, dist_loss: 0.6719024181365967
recon_loss: 0.029937122017145157, dist_loss: 0.5542020797729492
recon_loss: 0.029936710372567177, dist_loss: 0.716145396232605
recon_loss: 0.02993694506585598, dist_loss: 0.5626341700553894
recon_loss: 0.029938004910945892, dist_loss: 0.5328174233436584
recon_loss: 0.02993963100016117, dist_loss: 0.5513230562210083
recon_loss: 0.02994074672460556, dist_loss: 0.4440852999687195
recon_loss: 0.029939906671643257, dist_loss: 0.6029638051986694
recon_loss: 0.0299384742975235, dist_loss: 0.7674615383148193
recon_loss: 0.029936786741018295, dist_loss: 0.8448011875152588
recon_loss: 0.029935425147414207, dist_loss: 0.6782758831977844
recon_loss: 0.029934734106063843, dist_loss: 0.8465516567230225
recon_loss: 0.02993457205593586, dist_loss: 0.6459800601005554
recon_loss: 0.029934845864772797, dist_loss: 0.5581397414207458
recon_loss: 0.02993539720773697, dist_loss: 0.6598953604698181
recon_loss: 0.029936010017991066, dist_loss: 0.8565317392349243
recon_loss: 0.0299364123493433, dist_loss: 0.44531455636024475
recon_loss: 0.029936209321022034, dist_loss: 0.725058376789093
recon_loss: 0.02993544191122055, dist_loss: 0.8185571432113647
recon_loss: 0.029934711754322052, dist_loss: 0.5645762085914612
recon_loss: 0.029934687539935112, dist_loss: 0.5719053745269775
recon_loss: 0.02993508242070675, dist_loss: 0.6802788972854614
recon_loss: 0.029935484752058983, dist_loss: 0.5194066762924194
recon_loss: 0.029935911297798157, dist_loss: 0.9453939199447632
recon_loss: 0.02993694879114628, dist_loss: 0.5938402414321899
recon_loss: 0.029936116188764572, dist_loss: 0.8474472761154175
recon_loss: 0.02993510104715824, dist_loss: 0.672578752040863
recon_loss: 0.029934832826256752, dist_loss: 0.6512964963912964
recon_loss: 0.029934316873550415, dist_loss: 0.5966883897781372
recon_loss: 0.029933858662843704, dist_loss: 0.5757164359092712
recon_loss: 0.029934419319033623, dist_loss: 0.5896037817001343
recon_loss: 0.02993541769683361, dist_loss: 1.0570111274719238
recon_loss: 0.029934268444776535, dist_loss: 0.6521295309066772
recon_loss: 0.029932556673884392, dist_loss: 1.1070092916488647
recon_loss: 0.029933318495750427, dist_loss: 0.77825927734375
recon_loss: 0.029932627454400063, dist_loss: 1.0418219566345215
recon_loss: 0.029930738732218742, dist_loss: 0.5334951281547546
recon_loss: 0.02993078902363777, dist_loss: 0.8971003293991089
recon_loss: 0.02993168495595455, dist_loss: 0.6026380062103271
recon_loss: 0.02993093617260456, dist_loss: 0.854649007320404
recon_loss: 0.02993054874241352, dist_loss: 0.836435854434967
recon_loss: 0.029930682852864265, dist_loss: 0.8692113757133484
recon_loss: 0.029929498210549355, dist_loss: 0.46467500925064087
recon_loss: 0.02992798015475273, dist_loss: 0.6692767143249512
recon_loss: 0.029927270486950874, dist_loss: 1.3002521991729736
recon_loss: 0.02992674522101879, dist_loss: 0.5668388605117798
recon_loss: 0.029926247894763947, dist_loss: 0.6648224592208862
recon_loss: 0.02992587722837925, dist_loss: 0.59739089012146
recon_loss: 0.02992589771747589, dist_loss: 0.7741343975067139
recon_loss: 0.029925711452960968, dist_loss: 1.0414870977401733
recon_loss: 0.02992517501115799, dist_loss: 0.6614423394203186
recon_loss: 0.029925154522061348, dist_loss: 0.5249921083450317
recon_loss: 0.02992498129606247, dist_loss: 1.1176261901855469
recon_loss: 0.02992486022412777, dist_loss: 0.4565577805042267
recon_loss: 0.029924698173999786, dist_loss: 0.6994483470916748
recon_loss: 0.029924733564257622, dist_loss: 0.5850753784179688
recon_loss: 0.02992452308535576, dist_loss: 0.5372968912124634
recon_loss: 0.029924223199486732, dist_loss: 0.47742635011672974
recon_loss: 0.029923947528004646, dist_loss: 0.8105889558792114
recon_loss: 0.029923822730779648, dist_loss: 0.6815799474716187
recon_loss: 0.029923491179943085, dist_loss: 1.1017646789550781
recon_loss: 0.02992340363562107, dist_loss: 1.119346261024475
recon_loss: 0.02992348186671734, dist_loss: 0.8135502934455872
recon_loss: 0.02992357686161995, dist_loss: 0.382005512714386
recon_loss: 0.029923520982265472, dist_loss: 0.5197508335113525
recon_loss: 0.02992343157529831, dist_loss: 0.49325039982795715
recon_loss: 0.029922662302851677, dist_loss: 1.0424325466156006
recon_loss: 0.029921963810920715, dist_loss: 0.4773207902908325
recon_loss: 0.02992161177098751, dist_loss: 1.2207759618759155
recon_loss: 0.02992153726518154, dist_loss: 0.45202356576919556
recon_loss: 0.029921311885118484, dist_loss: 0.5515746474266052
recon_loss: 0.029921339824795723, dist_loss: 0.891609787940979
recon_loss: 0.02992156520485878, dist_loss: 0.5027428269386292
recon_loss: 0.029921650886535645, dist_loss: 0.518968939781189
recon_loss: 0.02992158569395542, dist_loss: 0.5364512801170349
recon_loss: 0.02992137521505356, dist_loss: 0.3736012876033783
recon_loss: 0.02992108464241028, dist_loss: 0.9876918792724609
recon_loss: 0.0299210287630558, dist_loss: 0.5709458589553833
recon_loss: 0.0299210287630558, dist_loss: 0.5163832902908325
recon_loss: 0.02992120571434498, dist_loss: 0.46066373586654663
recon_loss: 0.029921438544988632, dist_loss: 0.575452446937561
recon_loss: 0.029921790584921837, dist_loss: 0.6616429686546326
recon_loss: 0.02992166392505169, dist_loss: 0.810727059841156
recon_loss: 0.029921719804406166, dist_loss: 0.4673120379447937
recon_loss: 0.029921244829893112, dist_loss: 0.660711944103241
recon_loss: 0.029920771718025208, dist_loss: 0.7049700617790222
recon_loss: 0.029921159148216248, dist_loss: 1.102896809577942
recon_loss: 0.029921099543571472, dist_loss: 0.5915903449058533
recon_loss: 0.029919805005192757, dist_loss: 0.350433886051178
recon_loss: 0.029919885098934174, dist_loss: 0.5009134411811829
recon_loss: 0.02992020733654499, dist_loss: 0.5953687429428101
recon_loss: 0.02991911582648754, dist_loss: 0.27274802327156067
recon_loss: 0.029918763786554337, dist_loss: 0.6888830661773682
recon_loss: 0.02991950884461403, dist_loss: 1.2048825025558472
recon_loss: 0.029919462278485298, dist_loss: 0.6599342823028564
recon_loss: 0.029918933287262917, dist_loss: 0.6461877226829529
recon_loss: 0.029919655993580818, dist_loss: 0.4143536686897278
recon_loss: 0.029920125380158424, dist_loss: 0.5638595819473267
recon_loss: 0.029919900000095367, dist_loss: 0.5420414209365845
recon_loss: 0.02992142364382744, dist_loss: 1.0865259170532227
recon_loss: 0.029921187087893486, dist_loss: 0.764804482460022
recon_loss: 0.029919935390353203, dist_loss: 0.44483035802841187
recon_loss: 0.0299198217689991, dist_loss: 1.2628891468048096
recon_loss: 0.02991950884461403, dist_loss: 0.6204560399055481
recon_loss: 0.029918573796749115, dist_loss: 0.5312238931655884
recon_loss: 0.02991868555545807, dist_loss: 0.3483494520187378
recon_loss: 0.029918981716036797, dist_loss: 0.5047324895858765
recon_loss: 0.02991797775030136, dist_loss: 0.7827736139297485
recon_loss: 0.029917070642113686, dist_loss: 0.4419770836830139
recon_loss: 0.02991640754044056, dist_loss: 0.4947223663330078
recon_loss: 0.029915401712059975, dist_loss: 0.5880224108695984
Pre-training Epoch 37:  39%|███▉      | 144/367 [00:00<00:01, 175.86it/s]Pre-training Epoch 37:  44%|████▍     | 162/367 [00:00<00:01, 172.31it/s]Pre-training Epoch 37:  49%|████▉     | 180/367 [00:01<00:01, 166.93it/s]Pre-training Epoch 37:  54%|█████▎    | 197/367 [00:01<00:01, 166.29it/s]Pre-training Epoch 37:  58%|█████▊    | 214/367 [00:01<00:00, 166.02it/s]Pre-training Epoch 37:  63%|██████▎   | 231/367 [00:01<00:00, 161.98it/s]Pre-training Epoch 37:  68%|██████▊   | 248/367 [00:01<00:00, 160.52it/s]recon_loss: 0.02991446666419506, dist_loss: 0.7312583327293396
recon_loss: 0.02991367131471634, dist_loss: 0.6481250524520874
recon_loss: 0.029913129284977913, dist_loss: 0.806218147277832
recon_loss: 0.029912864789366722, dist_loss: 0.6882542371749878
recon_loss: 0.029913075268268585, dist_loss: 0.40961265563964844
recon_loss: 0.029913682490587234, dist_loss: 1.0826060771942139
recon_loss: 0.02991333045065403, dist_loss: 0.5115911364555359
recon_loss: 0.029912877827882767, dist_loss: 0.5518377423286438
recon_loss: 0.029912786558270454, dist_loss: 0.6464792490005493
recon_loss: 0.02991279400885105, dist_loss: 0.6979670524597168
recon_loss: 0.029912814497947693, dist_loss: 0.7920250296592712
recon_loss: 0.029912836849689484, dist_loss: 0.991363525390625
recon_loss: 0.029912447556853294, dist_loss: 1.0752127170562744
recon_loss: 0.029910873621702194, dist_loss: 1.0071418285369873
recon_loss: 0.029909582808613777, dist_loss: 0.5178377628326416
recon_loss: 0.029908064752817154, dist_loss: 0.4805220365524292
recon_loss: 0.029906682670116425, dist_loss: 0.7425607442855835
recon_loss: 0.029906047508120537, dist_loss: 0.6839327812194824
recon_loss: 0.029905708506703377, dist_loss: 0.6571371555328369
recon_loss: 0.02990584261715412, dist_loss: 0.7691842317581177
recon_loss: 0.02990635111927986, dist_loss: 0.8858674764633179
recon_loss: 0.029907366260886192, dist_loss: 0.48480355739593506
recon_loss: 0.02990770898759365, dist_loss: 0.6881120204925537
recon_loss: 0.029906608164310455, dist_loss: 0.648449182510376
recon_loss: 0.029905281960964203, dist_loss: 0.39816588163375854
recon_loss: 0.0299037117511034, dist_loss: 0.7549644708633423
recon_loss: 0.029902221634984016, dist_loss: 0.7671797275543213
recon_loss: 0.029901474714279175, dist_loss: 0.4005323052406311
recon_loss: 0.0299014151096344, dist_loss: 0.4600891172885895
recon_loss: 0.02990145981311798, dist_loss: 0.3274088501930237
recon_loss: 0.029901664704084396, dist_loss: 0.7812926769256592
recon_loss: 0.0299016535282135, dist_loss: 0.6436777114868164
recon_loss: 0.02990153804421425, dist_loss: 0.42900267243385315
recon_loss: 0.029901672154664993, dist_loss: 0.6310253143310547
recon_loss: 0.029901664704084396, dist_loss: 0.5118466019630432
recon_loss: 0.029901936650276184, dist_loss: 0.6655927896499634
recon_loss: 0.029902247712016106, dist_loss: 0.822140097618103
recon_loss: 0.029901742935180664, dist_loss: 0.7506247162818909
recon_loss: 0.029901474714279175, dist_loss: 0.7284389734268188
recon_loss: 0.02990139275789261, dist_loss: 0.5678430199623108
recon_loss: 0.029900895431637764, dist_loss: 0.591810941696167
recon_loss: 0.029899582266807556, dist_loss: 0.5501140356063843
recon_loss: 0.029899178072810173, dist_loss: 0.982805073261261
recon_loss: 0.029898980632424355, dist_loss: 0.9695226550102234
recon_loss: 0.02989848144352436, dist_loss: 1.1995809078216553
recon_loss: 0.029897896572947502, dist_loss: 0.831121563911438
recon_loss: 0.029897423461079597, dist_loss: 0.43813803791999817
recon_loss: 0.029896646738052368, dist_loss: 0.6739269495010376
recon_loss: 0.029895683750510216, dist_loss: 0.4676487445831299
recon_loss: 0.029894988983869553, dist_loss: 0.7461156845092773
recon_loss: 0.029894404113292694, dist_loss: 0.5819118618965149
recon_loss: 0.029894033446907997, dist_loss: 0.4080512821674347
recon_loss: 0.029893608763813972, dist_loss: 1.116050124168396
recon_loss: 0.0298931747674942, dist_loss: 0.8417830467224121
recon_loss: 0.029892897233366966, dist_loss: 0.7875396013259888
recon_loss: 0.02989288605749607, dist_loss: 1.0246589183807373
recon_loss: 0.029892539605498314, dist_loss: 0.6754997968673706
recon_loss: 0.02989204227924347, dist_loss: 0.922774076461792
recon_loss: 0.02989201433956623, dist_loss: 0.7212469577789307
recon_loss: 0.02989239990711212, dist_loss: 0.5830209255218506
recon_loss: 0.029892250895500183, dist_loss: 0.4295080900192261
recon_loss: 0.029892606660723686, dist_loss: 0.954820454120636
recon_loss: 0.029892265796661377, dist_loss: 0.4311128854751587
recon_loss: 0.02989163063466549, dist_loss: 0.42376720905303955
recon_loss: 0.029891103506088257, dist_loss: 0.5281631946563721
recon_loss: 0.02989080734550953, dist_loss: 0.7198454737663269
recon_loss: 0.029889950528740883, dist_loss: 0.6433764100074768
recon_loss: 0.02988947369158268, dist_loss: 0.6304306983947754
recon_loss: 0.029889702796936035, dist_loss: 0.9550821781158447
recon_loss: 0.029888933524489403, dist_loss: 0.8520315885543823
recon_loss: 0.029888762161135674, dist_loss: 1.0315501689910889
recon_loss: 0.029888782650232315, dist_loss: 0.8421921133995056
recon_loss: 0.029887784272432327, dist_loss: 0.7452315092086792
recon_loss: 0.029887130483984947, dist_loss: 0.5229335427284241
recon_loss: 0.029886994510889053, dist_loss: 0.3600865602493286
recon_loss: 0.029886633157730103, dist_loss: 0.4140147566795349
recon_loss: 0.029886087402701378, dist_loss: 0.5283731818199158
recon_loss: 0.029886852949857712, dist_loss: 0.897886335849762
recon_loss: 0.029887063428759575, dist_loss: 0.6423907279968262
recon_loss: 0.02988659404218197, dist_loss: 0.595856785774231
recon_loss: 0.029887299984693527, dist_loss: 0.4810181260108948
recon_loss: 0.02988782338798046, dist_loss: 0.6309689283370972
recon_loss: 0.029887201264500618, dist_loss: 0.752324104309082
recon_loss: 0.029886813834309578, dist_loss: 0.5444504022598267
recon_loss: 0.029886990785598755, dist_loss: 0.9496738314628601
recon_loss: 0.029887232929468155, dist_loss: 0.45273977518081665
recon_loss: 0.02988719381392002, dist_loss: 0.5804929733276367
recon_loss: 0.029887402430176735, dist_loss: 0.384863018989563
recon_loss: 0.029886746779084206, dist_loss: 0.8884897232055664
recon_loss: 0.02988547272980213, dist_loss: 0.6820409297943115
recon_loss: 0.029884537681937218, dist_loss: 0.7067647576332092
recon_loss: 0.029883701354265213, dist_loss: 0.7451390027999878
recon_loss: 0.029883243143558502, dist_loss: 0.3993660509586334
recon_loss: 0.02988310158252716, dist_loss: 0.9227162599563599
recon_loss: 0.029882727190852165, dist_loss: 0.6662183403968811
recon_loss: 0.02988305501639843, dist_loss: 0.9598795771598816
recon_loss: 0.02988443896174431, dist_loss: 0.640072226524353
recon_loss: 0.0298846997320652, dist_loss: 0.7973107099533081
recon_loss: 0.029883690178394318, dist_loss: 0.5478280782699585
recon_loss: 0.029883239418268204, dist_loss: 0.3161005973815918
recon_loss: 0.029883353039622307, dist_loss: 0.527898907661438
recon_loss: 0.029883045703172684, dist_loss: 0.4849492907524109
recon_loss: 0.029883751645684242, dist_loss: 0.504704475402832
recon_loss: 0.02988462895154953, dist_loss: 0.6918168067932129
recon_loss: 0.02988407202064991, dist_loss: 0.9554951190948486
recon_loss: 0.029882628470659256, dist_loss: 1.0884634256362915
recon_loss: 0.029881708323955536, dist_loss: 0.7115511894226074
recon_loss: 0.029880883172154427, dist_loss: 0.8168740272521973
recon_loss: 0.029879743233323097, dist_loss: 1.0866315364837646
recon_loss: 0.029879877343773842, dist_loss: 0.3564227819442749
recon_loss: 0.029880138114094734, dist_loss: 0.6649461984634399
recon_loss: 0.02987944334745407, dist_loss: 0.3435610234737396
recon_loss: 0.029879046604037285, dist_loss: 0.9616237878799438
recon_loss: 0.02987798862159252, dist_loss: 0.9786701202392578
recon_loss: 0.029876740649342537, dist_loss: 0.5222492218017578
recon_loss: 0.029876338317990303, dist_loss: 0.6609604358673096
recon_loss: 0.029876405373215675, dist_loss: 0.6777164936065674
recon_loss: 0.02987566776573658, dist_loss: 0.5973911285400391
recon_loss: 0.029875215142965317, dist_loss: 0.5329671502113342
recon_loss: 0.029875285923480988, dist_loss: 0.6964918375015259
recon_loss: 0.029874855652451515, dist_loss: 0.43196871876716614
recon_loss: 0.02987380512058735, dist_loss: 0.9181585907936096
recon_loss: 0.02987365610897541, dist_loss: 0.5610930919647217
recon_loss: 0.0298735611140728, dist_loss: 0.7246735095977783
recon_loss: 0.029872795566916466, dist_loss: 0.3015158772468567
recon_loss: 0.029872603714466095, dist_loss: 0.45675551891326904
recon_loss: 0.029872871935367584, dist_loss: 0.3102248013019562
recon_loss: 0.029872428625822067, dist_loss: 0.6581649780273438
Pre-training Epoch 37:  72%|███████▏  | 265/367 [00:01<00:00, 161.79it/s]Pre-training Epoch 37:  77%|███████▋  | 282/367 [00:01<00:00, 162.81it/s]Pre-training Epoch 37:  81%|████████▏ | 299/367 [00:01<00:00, 163.42it/s]Pre-training Epoch 37:  86%|████████▌ | 316/367 [00:01<00:00, 164.01it/s]Pre-training Epoch 37:  91%|█████████ | 333/367 [00:01<00:00, 161.02it/s]Pre-training Epoch 37:  95%|█████████▌| 350/367 [00:02<00:00, 159.12it/s]Pre-training Epoch 37: 100%|█████████▉| 366/367 [00:02<00:00, 157.92it/s]Pre-training Epoch 37: 100%|██████████| 367/367 [00:02<00:00, 165.80it/s]
recon_loss: 0.029872164130210876, dist_loss: 0.909531831741333
recon_loss: 0.029871990904211998, dist_loss: 0.8678179979324341
recon_loss: 0.029871147125959396, dist_loss: 0.742863118648529
recon_loss: 0.029870670288801193, dist_loss: 0.5350263118743896
recon_loss: 0.029870420694351196, dist_loss: 0.6407284736633301
recon_loss: 0.02987036108970642, dist_loss: 0.6682554483413696
recon_loss: 0.02987012453377247, dist_loss: 0.7217390537261963
recon_loss: 0.029869994148612022, dist_loss: 0.5570456981658936
recon_loss: 0.02986995130777359, dist_loss: 0.7059993147850037
recon_loss: 0.029869699850678444, dist_loss: 0.8116797208786011
recon_loss: 0.029869599267840385, dist_loss: 0.9487025737762451
recon_loss: 0.02986958436667919, dist_loss: 0.6591818332672119
recon_loss: 0.029869358986616135, dist_loss: 0.2957230806350708
recon_loss: 0.029869457706809044, dist_loss: 0.5211243033409119
recon_loss: 0.029869532212615013, dist_loss: 0.5948861837387085
recon_loss: 0.02986956387758255, dist_loss: 1.072754144668579
recon_loss: 0.029869336634874344, dist_loss: 0.7611991167068481
recon_loss: 0.029869528487324715, dist_loss: 0.6915897130966187
recon_loss: 0.02986910752952099, dist_loss: 1.1640727519989014
recon_loss: 0.029868511483073235, dist_loss: 0.8255093097686768
recon_loss: 0.029868362471461296, dist_loss: 0.6965851783752441
recon_loss: 0.02986922487616539, dist_loss: 0.498402863740921
recon_loss: 0.029870934784412384, dist_loss: 0.8550432920455933
recon_loss: 0.029872002080082893, dist_loss: 0.6715230941772461
recon_loss: 0.029871726408600807, dist_loss: 0.3777018189430237
recon_loss: 0.029870953410863876, dist_loss: 0.9536958336830139
recon_loss: 0.029870333150029182, dist_loss: 0.9432655572891235
recon_loss: 0.029870811849832535, dist_loss: 0.5732440948486328
recon_loss: 0.029870981350541115, dist_loss: 0.560071587562561
recon_loss: 0.02987099252641201, dist_loss: 0.6599562764167786
recon_loss: 0.02987142652273178, dist_loss: 0.9159989356994629
recon_loss: 0.029871821403503418, dist_loss: 0.6351343989372253
recon_loss: 0.029871726408600807, dist_loss: 0.9467828273773193
recon_loss: 0.02987181767821312, dist_loss: 0.748711347579956
recon_loss: 0.029871605336666107, dist_loss: 0.6738640069961548
recon_loss: 0.029870621860027313, dist_loss: 0.5563547611236572
recon_loss: 0.02986982837319374, dist_loss: 1.3774827718734741
recon_loss: 0.029869599267840385, dist_loss: 0.5803965926170349
recon_loss: 0.02986813709139824, dist_loss: 0.9847412705421448
recon_loss: 0.02986696921288967, dist_loss: 1.3620285987854004
recon_loss: 0.029865847900509834, dist_loss: 0.5600990056991577
recon_loss: 0.029864517971873283, dist_loss: 0.9334122538566589
recon_loss: 0.029863815754652023, dist_loss: 0.56028813123703
recon_loss: 0.02986426278948784, dist_loss: 0.5184507966041565
recon_loss: 0.029863832518458366, dist_loss: 0.5098997354507446
recon_loss: 0.029864344745874405, dist_loss: 0.5363777279853821
recon_loss: 0.02986530400812626, dist_loss: 0.42365896701812744
recon_loss: 0.029864566400647163, dist_loss: 0.5089497566223145
recon_loss: 0.029864192008972168, dist_loss: 0.5091744661331177
recon_loss: 0.02986575849354267, dist_loss: 0.5346758365631104
recon_loss: 0.02986585907638073, dist_loss: 0.7607755661010742
recon_loss: 0.02986539900302887, dist_loss: 0.722265362739563
recon_loss: 0.029866570606827736, dist_loss: 0.6661604642868042
recon_loss: 0.029866578057408333, dist_loss: 0.5078456997871399
recon_loss: 0.029865287244319916, dist_loss: 0.5821641683578491
recon_loss: 0.029866104945540428, dist_loss: 0.6771416664123535
recon_loss: 0.029866056516766548, dist_loss: 0.893281102180481
recon_loss: 0.029864368960261345, dist_loss: 0.5242424607276917
recon_loss: 0.029863638803362846, dist_loss: 0.7041339874267578
recon_loss: 0.02986392192542553, dist_loss: 0.5359476804733276
recon_loss: 0.02986264042556286, dist_loss: 1.5211470127105713
recon_loss: 0.02986110933125019, dist_loss: 0.32457810640335083
recon_loss: 0.029860982671380043, dist_loss: 0.4667803943157196
recon_loss: 0.02986026555299759, dist_loss: 0.880720853805542
recon_loss: 0.029859164729714394, dist_loss: 0.7632476687431335
recon_loss: 0.02985907718539238, dist_loss: 0.5268875956535339
recon_loss: 0.029859034344553947, dist_loss: 0.4322398900985718
recon_loss: 0.029857760295271873, dist_loss: 0.4209299683570862
recon_loss: 0.029857302084565163, dist_loss: 0.5001310110092163
recon_loss: 0.029857739806175232, dist_loss: 0.5334237813949585
recon_loss: 0.029856443405151367, dist_loss: 0.4685966372489929
recon_loss: 0.029856031760573387, dist_loss: 0.8318086266517639
recon_loss: 0.029856648296117783, dist_loss: 1.0321884155273438
recon_loss: 0.02985568158328533, dist_loss: 1.0945308208465576
recon_loss: 0.02985490672290325, dist_loss: 0.34827497601509094
recon_loss: 0.02985517494380474, dist_loss: 0.558062732219696
recon_loss: 0.02985462360084057, dist_loss: 0.528160810470581
recon_loss: 0.029854414984583855, dist_loss: 0.4762588441371918
recon_loss: 0.029854638502001762, dist_loss: 0.5080978870391846
recon_loss: 0.02985457330942154, dist_loss: 0.7806806564331055
recon_loss: 0.029854174703359604, dist_loss: 0.503176748752594
recon_loss: 0.029854200780391693, dist_loss: 1.0219494104385376
recon_loss: 0.029854334890842438, dist_loss: 0.772500216960907
recon_loss: 0.029854390770196915, dist_loss: 0.6315853595733643
recon_loss: 0.029854340478777885, dist_loss: 0.9932249188423157
recon_loss: 0.02985391765832901, dist_loss: 0.5238004922866821
recon_loss: 0.02985360473394394, dist_loss: 0.6806079149246216
recon_loss: 0.029853451997041702, dist_loss: 0.7431259751319885
recon_loss: 0.02985302172601223, dist_loss: 0.639733612537384
recon_loss: 0.029852837324142456, dist_loss: 0.6730565428733826
recon_loss: 0.02985367737710476, dist_loss: 0.6232500076293945
recon_loss: 0.029854383319616318, dist_loss: 1.0676310062408447
recon_loss: 0.029854407534003258, dist_loss: 0.39334428310394287
recon_loss: 0.02985425293445587, dist_loss: 0.5902659893035889
recon_loss: 0.0298538189381361, dist_loss: 0.5828898549079895
recon_loss: 0.029854070395231247, dist_loss: 0.37348127365112305
recon_loss: 0.029854126274585724, dist_loss: 0.769889771938324
recon_loss: 0.029854504391551018, dist_loss: 0.9072147011756897
recon_loss: 0.029854733496904373, dist_loss: 0.447679340839386
recon_loss: 0.02985505387187004, dist_loss: 0.6774104833602905
recon_loss: 0.029855569824576378, dist_loss: 0.2825230360031128
recon_loss: 0.029855936765670776, dist_loss: 0.3462625741958618
recon_loss: 0.02985564060509205, dist_loss: 1.0599621534347534
recon_loss: 0.029854390770196915, dist_loss: 0.6490771174430847
recon_loss: 0.029853077605366707, dist_loss: 0.8309881687164307
recon_loss: 0.02985159307718277, dist_loss: 0.8846622109413147
recon_loss: 0.029850607737898827, dist_loss: 0.6360273361206055
recon_loss: 0.029850566759705544, dist_loss: 1.2881392240524292
recon_loss: 0.029851578176021576, dist_loss: 0.5123292803764343
recon_loss: 0.029853057116270065, dist_loss: 1.1601167917251587
Pre-training Epoch 38:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 38:   4%|▍         | 16/367 [00:00<00:02, 151.19it/s]Pre-training Epoch 38:   9%|▉         | 34/367 [00:00<00:02, 163.00it/s]Pre-training Epoch 38:  14%|█▍        | 53/367 [00:00<00:01, 172.95it/s]Pre-training Epoch 38:  19%|█▉        | 71/367 [00:00<00:01, 173.34it/s]Pre-training Epoch 38:  25%|██▍       | 91/367 [00:00<00:01, 179.78it/s]Pre-training Epoch 38:  30%|███       | 111/367 [00:00<00:01, 184.12it/s]recon_loss: 0.029855739325284958, dist_loss: 0.5361264944076538
recon_loss: 0.02985682524740696, dist_loss: 0.4344392418861389
recon_loss: 0.029856504872441292, dist_loss: 1.0364060401916504
recon_loss: 0.029854673892259598, dist_loss: 0.7714807987213135
recon_loss: 0.02985193580389023, dist_loss: 0.7674685120582581
recon_loss: 0.029849782586097717, dist_loss: 0.5568073391914368
recon_loss: 0.029849451035261154, dist_loss: 0.5494261384010315
recon_loss: 0.029850110411643982, dist_loss: 0.4479536712169647
recon_loss: 0.029850760474801064, dist_loss: 0.5802721977233887
recon_loss: 0.029851313680410385, dist_loss: 0.7262119650840759
recon_loss: 0.029851341620087624, dist_loss: 0.48419588804244995
recon_loss: 0.029850291088223457, dist_loss: 0.9531543254852295
recon_loss: 0.029849372804164886, dist_loss: 0.5918093323707581
recon_loss: 0.029848456382751465, dist_loss: 0.4836537539958954
recon_loss: 0.029847754165530205, dist_loss: 0.5773356556892395
recon_loss: 0.02984732948243618, dist_loss: 0.9169578552246094
recon_loss: 0.029847336933016777, dist_loss: 0.5839598178863525
recon_loss: 0.0298476479947567, dist_loss: 0.46491891145706177
recon_loss: 0.029848571866750717, dist_loss: 1.124248743057251
recon_loss: 0.029849309474229813, dist_loss: 0.47285059094429016
recon_loss: 0.029849601909518242, dist_loss: 0.7494508624076843
recon_loss: 0.02985013835132122, dist_loss: 0.6116107106208801
recon_loss: 0.02985130064189434, dist_loss: 0.4509405195713043
recon_loss: 0.029851730912923813, dist_loss: 0.4882050156593323
recon_loss: 0.029851363971829414, dist_loss: 0.6404686570167542
recon_loss: 0.02985086664557457, dist_loss: 0.4999936819076538
recon_loss: 0.029850346967577934, dist_loss: 0.6593572497367859
recon_loss: 0.029849877581000328, dist_loss: 0.560585618019104
recon_loss: 0.02984924614429474, dist_loss: 0.8602780103683472
recon_loss: 0.029848657548427582, dist_loss: 0.5593451857566833
recon_loss: 0.029848074540495872, dist_loss: 0.4522170126438141
recon_loss: 0.029847072437405586, dist_loss: 0.9920707941055298
recon_loss: 0.02984628640115261, dist_loss: 0.4874346852302551
recon_loss: 0.029845478013157845, dist_loss: 0.9416276812553406
recon_loss: 0.02984480746090412, dist_loss: 0.5405824780464172
recon_loss: 0.02984447591006756, dist_loss: 0.9522135257720947
recon_loss: 0.029844515025615692, dist_loss: 0.574032187461853
recon_loss: 0.02984444797039032, dist_loss: 0.5273353457450867
recon_loss: 0.029844295233488083, dist_loss: 1.1956768035888672
recon_loss: 0.029844550415873528, dist_loss: 0.4348337650299072
recon_loss: 0.029844969511032104, dist_loss: 0.7252711057662964
recon_loss: 0.02984573133289814, dist_loss: 0.5181300640106201
recon_loss: 0.02984696999192238, dist_loss: 0.9562951326370239
recon_loss: 0.029848575592041016, dist_loss: 0.4109894037246704
recon_loss: 0.02984941191971302, dist_loss: 0.4492870569229126
recon_loss: 0.029849719256162643, dist_loss: 0.3347463309764862
recon_loss: 0.02984982542693615, dist_loss: 0.5665160417556763
recon_loss: 0.02984936535358429, dist_loss: 0.5217893123626709
recon_loss: 0.029848966747522354, dist_loss: 0.9891587495803833
recon_loss: 0.02984892949461937, dist_loss: 0.7695260047912598
recon_loss: 0.029849091544747353, dist_loss: 0.37273022532463074
recon_loss: 0.02984856255352497, dist_loss: 0.3764243721961975
recon_loss: 0.029848070815205574, dist_loss: 0.5063769817352295
recon_loss: 0.029847588390111923, dist_loss: 0.8018574118614197
recon_loss: 0.029846610501408577, dist_loss: 0.4433383643627167
recon_loss: 0.02984599582850933, dist_loss: 0.22719252109527588
recon_loss: 0.029845478013157845, dist_loss: 0.5250361561775208
recon_loss: 0.029844680801033974, dist_loss: 0.3606948256492615
recon_loss: 0.029843656346201897, dist_loss: 0.6362601518630981
recon_loss: 0.029843127354979515, dist_loss: 0.5230851173400879
recon_loss: 0.02984248660504818, dist_loss: 0.4764587879180908
recon_loss: 0.02984151802957058, dist_loss: 0.7246696352958679
recon_loss: 0.029841221868991852, dist_loss: 0.4806879758834839
recon_loss: 0.02984066866338253, dist_loss: 0.7216533422470093
recon_loss: 0.02984013594686985, dist_loss: 0.7373563051223755
recon_loss: 0.02984032593667507, dist_loss: 0.3445861339569092
recon_loss: 0.029840219765901566, dist_loss: 0.9165976047515869
recon_loss: 0.029839275404810905, dist_loss: 0.6671258211135864
recon_loss: 0.02983919344842434, dist_loss: 0.7711730003356934
recon_loss: 0.029838869348168373, dist_loss: 0.7706881761550903
recon_loss: 0.029838480055332184, dist_loss: 0.8605691194534302
recon_loss: 0.029838837683200836, dist_loss: 0.7896949648857117
recon_loss: 0.029840100556612015, dist_loss: 0.7688390016555786
recon_loss: 0.029840601608157158, dist_loss: 0.7623367309570312
recon_loss: 0.029840344563126564, dist_loss: 0.7956660389900208
recon_loss: 0.029842661693692207, dist_loss: 0.4276755154132843
recon_loss: 0.02984405867755413, dist_loss: 1.129305124282837
recon_loss: 0.029843445867300034, dist_loss: 0.8169811964035034
recon_loss: 0.02984386868774891, dist_loss: 1.304667592048645
recon_loss: 0.029843954369425774, dist_loss: 0.6866358518600464
recon_loss: 0.029842866584658623, dist_loss: 0.750012993812561
recon_loss: 0.029842711985111237, dist_loss: 0.989058256149292
recon_loss: 0.029843060299754143, dist_loss: 0.5671794414520264
recon_loss: 0.02984156832098961, dist_loss: 0.7009169459342957
recon_loss: 0.029839973896741867, dist_loss: 0.6464781761169434
recon_loss: 0.02984054572880268, dist_loss: 0.5468496680259705
recon_loss: 0.029839571565389633, dist_loss: 0.32029032707214355
recon_loss: 0.029836971312761307, dist_loss: 0.8533316254615784
recon_loss: 0.0298368688672781, dist_loss: 0.4231351912021637
recon_loss: 0.029836706817150116, dist_loss: 0.7470980882644653
recon_loss: 0.02983355149626732, dist_loss: 0.7570856809616089
recon_loss: 0.02983229234814644, dist_loss: 0.4908478856086731
recon_loss: 0.029833566397428513, dist_loss: 0.7973278760910034
recon_loss: 0.029832035303115845, dist_loss: 0.8709819316864014
recon_loss: 0.02983085997402668, dist_loss: 0.7282935976982117
recon_loss: 0.029833318665623665, dist_loss: 1.0423848628997803
recon_loss: 0.029833558946847916, dist_loss: 0.5490618348121643
recon_loss: 0.02983139269053936, dist_loss: 0.5947750806808472
recon_loss: 0.029833167791366577, dist_loss: 0.9749308228492737
recon_loss: 0.029834073036909103, dist_loss: 0.5797145366668701
recon_loss: 0.029831169173121452, dist_loss: 0.793549656867981
recon_loss: 0.02983112446963787, dist_loss: 0.9801664352416992
recon_loss: 0.029832379892468452, dist_loss: 1.012618064880371
recon_loss: 0.029830651357769966, dist_loss: 0.403250515460968
recon_loss: 0.029829232022166252, dist_loss: 0.6696906089782715
recon_loss: 0.02983045019209385, dist_loss: 0.6831851005554199
recon_loss: 0.02983040362596512, dist_loss: 0.8254948854446411
recon_loss: 0.029828527942299843, dist_loss: 0.44944968819618225
recon_loss: 0.0298282653093338, dist_loss: 0.43483036756515503
recon_loss: 0.02982906438410282, dist_loss: 1.6274312734603882
recon_loss: 0.029828395694494247, dist_loss: 0.7604197859764099
recon_loss: 0.029826663434505463, dist_loss: 0.3225930333137512
recon_loss: 0.029827704653143883, dist_loss: 0.8135824203491211
recon_loss: 0.029827436432242393, dist_loss: 0.40180569887161255
recon_loss: 0.029825083911418915, dist_loss: 0.853422224521637
recon_loss: 0.029825810343027115, dist_loss: 0.8075995445251465
recon_loss: 0.029826615005731583, dist_loss: 0.9801595211029053
recon_loss: 0.02982526645064354, dist_loss: 0.8804571032524109
recon_loss: 0.029824938625097275, dist_loss: 0.6455605030059814
recon_loss: 0.029824674129486084, dist_loss: 1.1166799068450928
recon_loss: 0.029823975637555122, dist_loss: 0.7905470728874207
recon_loss: 0.02982303313910961, dist_loss: 0.3748002052307129
recon_loss: 0.029823383316397667, dist_loss: 0.9633821249008179
recon_loss: 0.02982386201620102, dist_loss: 0.6037867069244385
recon_loss: 0.029823463410139084, dist_loss: 1.0064373016357422
recon_loss: 0.029823968186974525, dist_loss: 0.5900955200195312
recon_loss: 0.029824426397681236, dist_loss: 0.39963388442993164
recon_loss: 0.02982337214052677, dist_loss: 0.5726358294487
Pre-training Epoch 38:  35%|███▌      | 130/367 [00:00<00:01, 185.72it/s]Pre-training Epoch 38:  41%|████      | 150/367 [00:00<00:01, 188.57it/s]Pre-training Epoch 38:  46%|████▋     | 170/367 [00:00<00:01, 190.49it/s]Pre-training Epoch 38:  52%|█████▏    | 190/367 [00:01<00:00, 184.81it/s]Pre-training Epoch 38:  57%|█████▋    | 209/367 [00:01<00:00, 174.09it/s]Pre-training Epoch 38:  62%|██████▏   | 227/367 [00:01<00:00, 171.27it/s]Pre-training Epoch 38:  67%|██████▋   | 245/367 [00:01<00:00, 167.80it/s]recon_loss: 0.029823418706655502, dist_loss: 0.575803816318512
recon_loss: 0.029823439195752144, dist_loss: 0.39440086483955383
recon_loss: 0.029821852222085, dist_loss: 0.7600466012954712
recon_loss: 0.029820997267961502, dist_loss: 1.1348987817764282
recon_loss: 0.02982097677886486, dist_loss: 0.6313393115997314
recon_loss: 0.02982068620622158, dist_loss: 0.5533646941184998
recon_loss: 0.029820602387189865, dist_loss: 0.6111141443252563
recon_loss: 0.02982131578028202, dist_loss: 0.6921148896217346
recon_loss: 0.0298210009932518, dist_loss: 0.5824027061462402
recon_loss: 0.029820570722222328, dist_loss: 0.7856490612030029
recon_loss: 0.029820216819643974, dist_loss: 0.5921356081962585
recon_loss: 0.029820118099451065, dist_loss: 0.6989871263504028
recon_loss: 0.029819127172231674, dist_loss: 0.5501761436462402
recon_loss: 0.029818175360560417, dist_loss: 0.8962838649749756
recon_loss: 0.02981734834611416, dist_loss: 0.6129616498947144
recon_loss: 0.029816770926117897, dist_loss: 0.7389305830001831
recon_loss: 0.02981666475534439, dist_loss: 0.6292893886566162
recon_loss: 0.029816940426826477, dist_loss: 1.0843918323516846
recon_loss: 0.0298174899071455, dist_loss: 0.5396895408630371
recon_loss: 0.02981722168624401, dist_loss: 1.1551833152770996
recon_loss: 0.029816515743732452, dist_loss: 0.9103794693946838
recon_loss: 0.029815683141350746, dist_loss: 0.5756019353866577
recon_loss: 0.02981507033109665, dist_loss: 0.5892985463142395
recon_loss: 0.029814640060067177, dist_loss: 1.0105998516082764
recon_loss: 0.02981465682387352, dist_loss: 0.3082399368286133
recon_loss: 0.029814857989549637, dist_loss: 1.0507200956344604
recon_loss: 0.029814353212714195, dist_loss: 1.0358644723892212
recon_loss: 0.029813678935170174, dist_loss: 0.9993234276771545
recon_loss: 0.029812945052981377, dist_loss: 0.564064621925354
recon_loss: 0.029812881723046303, dist_loss: 0.5648316144943237
recon_loss: 0.029812904074788094, dist_loss: 0.7458968162536621
recon_loss: 0.02981266938149929, dist_loss: 0.5877758860588074
recon_loss: 0.02981214039027691, dist_loss: 0.6711394786834717
recon_loss: 0.02981180138885975, dist_loss: 0.7278234958648682
recon_loss: 0.02981150895357132, dist_loss: 0.6766638159751892
recon_loss: 0.02981116808950901, dist_loss: 0.6029765605926514
recon_loss: 0.029811033979058266, dist_loss: 0.776727557182312
recon_loss: 0.029811035841703415, dist_loss: 0.683081328868866
recon_loss: 0.029810873791575432, dist_loss: 0.8706161379814148
recon_loss: 0.029810285195708275, dist_loss: 0.8137457370758057
recon_loss: 0.029810020700097084, dist_loss: 0.9780780673027039
recon_loss: 0.029810506850481033, dist_loss: 0.5377482175827026
recon_loss: 0.029810966923832893, dist_loss: 0.6668834686279297
recon_loss: 0.02981175296008587, dist_loss: 0.5719373226165771
recon_loss: 0.029812172055244446, dist_loss: 0.5918009281158447
recon_loss: 0.02981233224272728, dist_loss: 0.4705597460269928
recon_loss: 0.029812274500727654, dist_loss: 0.5931153893470764
recon_loss: 0.029811106622219086, dist_loss: 0.7144118547439575
recon_loss: 0.029810506850481033, dist_loss: 0.6343517899513245
recon_loss: 0.0298101045191288, dist_loss: 0.8430048823356628
recon_loss: 0.02980993129312992, dist_loss: 0.5169883370399475
recon_loss: 0.029810002073645592, dist_loss: 0.7293452024459839
recon_loss: 0.029810087755322456, dist_loss: 0.41068774461746216
recon_loss: 0.02981005236506462, dist_loss: 0.6065813302993774
recon_loss: 0.02980939671397209, dist_loss: 1.025831937789917
recon_loss: 0.02980847842991352, dist_loss: 0.897201418876648
recon_loss: 0.029807962477207184, dist_loss: 0.6490317583084106
recon_loss: 0.0298078004270792, dist_loss: 0.29303768277168274
recon_loss: 0.02980775199830532, dist_loss: 0.8452593088150024
recon_loss: 0.0298075620085001, dist_loss: 0.5584186315536499
recon_loss: 0.029807260259985924, dist_loss: 0.5798385739326477
recon_loss: 0.0298071950674057, dist_loss: 0.6610592007637024
recon_loss: 0.029806600883603096, dist_loss: 0.7611506581306458
recon_loss: 0.02980622462928295, dist_loss: 0.5956196784973145
recon_loss: 0.029806163161993027, dist_loss: 0.6003167629241943
recon_loss: 0.029806245118379593, dist_loss: 0.7718400955200195
recon_loss: 0.029806600883603096, dist_loss: 0.6807120442390442
recon_loss: 0.02980647422373295, dist_loss: 0.6613438725471497
recon_loss: 0.029806291684508324, dist_loss: 0.8898631930351257
recon_loss: 0.029806092381477356, dist_loss: 0.4289286136627197
recon_loss: 0.029805898666381836, dist_loss: 0.40724754333496094
recon_loss: 0.029806340113282204, dist_loss: 0.6524260640144348
recon_loss: 0.029807966202497482, dist_loss: 0.7404972314834595
recon_loss: 0.029808569699525833, dist_loss: 0.6077462434768677
recon_loss: 0.029808396473526955, dist_loss: 0.728449821472168
recon_loss: 0.02980857342481613, dist_loss: 0.6980989575386047
recon_loss: 0.029808703809976578, dist_loss: 0.8290766477584839
recon_loss: 0.02980903536081314, dist_loss: 0.5225266218185425
recon_loss: 0.029810214415192604, dist_loss: 0.8431230187416077
recon_loss: 0.029810672625899315, dist_loss: 0.7894173860549927
recon_loss: 0.029810620471835136, dist_loss: 0.4781413674354553
recon_loss: 0.029811251908540726, dist_loss: 0.851460874080658
recon_loss: 0.029812036082148552, dist_loss: 0.5677375197410583
recon_loss: 0.029811516404151917, dist_loss: 1.0162229537963867
recon_loss: 0.02981075830757618, dist_loss: 0.6072984933853149
recon_loss: 0.0298104677349329, dist_loss: 0.8650161027908325
recon_loss: 0.029809432104229927, dist_loss: 0.5457174777984619
recon_loss: 0.029808301478624344, dist_loss: 0.336597740650177
recon_loss: 0.029807385057210922, dist_loss: 0.5357412099838257
recon_loss: 0.02980632334947586, dist_loss: 0.3307894766330719
recon_loss: 0.02980480156838894, dist_loss: 0.8066340088844299
recon_loss: 0.029804453253746033, dist_loss: 0.4254198372364044
recon_loss: 0.029804067686200142, dist_loss: 0.7819018363952637
recon_loss: 0.029803317040205002, dist_loss: 0.4677801728248596
recon_loss: 0.029802914708852768, dist_loss: 0.9847519993782043
recon_loss: 0.029802152886986732, dist_loss: 0.5495745539665222
recon_loss: 0.029801273718476295, dist_loss: 0.8582502007484436
recon_loss: 0.029800793156027794, dist_loss: 0.7773275375366211
recon_loss: 0.02980061061680317, dist_loss: 0.8566602468490601
recon_loss: 0.02980039082467556, dist_loss: 0.49112367630004883
recon_loss: 0.029800977557897568, dist_loss: 0.7313052415847778
recon_loss: 0.0298024732619524, dist_loss: 0.5275305509567261
recon_loss: 0.029803285375237465, dist_loss: 0.7239735126495361
recon_loss: 0.02980411797761917, dist_loss: 0.5768826007843018
recon_loss: 0.029804572463035583, dist_loss: 0.6678797006607056
recon_loss: 0.02980552799999714, dist_loss: 0.45468732714653015
recon_loss: 0.029805969446897507, dist_loss: 0.38515740633010864
recon_loss: 0.02980595827102661, dist_loss: 1.3487123250961304
recon_loss: 0.02980552427470684, dist_loss: 0.7217656373977661
recon_loss: 0.029805492609739304, dist_loss: 0.7997459173202515
recon_loss: 0.029805168509483337, dist_loss: 0.4723834991455078
recon_loss: 0.02980492264032364, dist_loss: 0.8041995763778687
recon_loss: 0.029804766178131104, dist_loss: 0.6225311756134033
recon_loss: 0.02980424463748932, dist_loss: 0.3355666995048523
recon_loss: 0.029802974313497543, dist_loss: 0.9270820021629333
recon_loss: 0.029801160097122192, dist_loss: 0.46044668555259705
recon_loss: 0.029799481853842735, dist_loss: 0.5680952072143555
recon_loss: 0.0297970250248909, dist_loss: 0.6241070032119751
recon_loss: 0.029794767498970032, dist_loss: 1.276674509048462
recon_loss: 0.029794365167617798, dist_loss: 0.799344003200531
recon_loss: 0.029795872047543526, dist_loss: 0.6499941349029541
recon_loss: 0.029796771705150604, dist_loss: 0.6426214575767517
recon_loss: 0.029797596856951714, dist_loss: 0.35056108236312866
recon_loss: 0.029797427356243134, dist_loss: 0.4376841187477112
recon_loss: 0.02979569137096405, dist_loss: 0.859176516532898
recon_loss: 0.029793059453368187, dist_loss: 0.8140223026275635
recon_loss: 0.02979154884815216, dist_loss: 0.39812731742858887
recon_loss: 0.02979147806763649, dist_loss: 0.7239861488342285
Pre-training Epoch 38:  71%|███████▏  | 262/367 [00:01<00:00, 166.07it/s]Pre-training Epoch 38:  76%|███████▌  | 279/367 [00:01<00:00, 164.46it/s]Pre-training Epoch 38:  81%|████████  | 296/367 [00:01<00:00, 164.68it/s]Pre-training Epoch 38:  85%|████████▌ | 313/367 [00:01<00:00, 164.94it/s]Pre-training Epoch 38:  90%|████████▉ | 330/367 [00:01<00:00, 164.82it/s]Pre-training Epoch 38:  95%|█████████▍| 347/367 [00:02<00:00, 161.56it/s]Pre-training Epoch 38:  99%|█████████▉| 364/367 [00:02<00:00, 156.07it/s]Pre-training Epoch 38: 100%|██████████| 367/367 [00:02<00:00, 169.84it/s]
recon_loss: 0.029791492968797684, dist_loss: 0.923216700553894
recon_loss: 0.02979203499853611, dist_loss: 0.7605396509170532
recon_loss: 0.02979263663291931, dist_loss: 0.8492225408554077
recon_loss: 0.02979329600930214, dist_loss: 0.4549626111984253
recon_loss: 0.029792575165629387, dist_loss: 0.6445721387863159
recon_loss: 0.029792441055178642, dist_loss: 0.8467563986778259
recon_loss: 0.029791340231895447, dist_loss: 1.3172194957733154
recon_loss: 0.02979023940861225, dist_loss: 0.7020076513290405
recon_loss: 0.029790475964546204, dist_loss: 0.7678892612457275
recon_loss: 0.029790392145514488, dist_loss: 1.3008294105529785
recon_loss: 0.029789205640554428, dist_loss: 0.7943952083587646
recon_loss: 0.02978953719139099, dist_loss: 0.450996994972229
recon_loss: 0.029790665954351425, dist_loss: 0.5402873158454895
recon_loss: 0.02979040890932083, dist_loss: 0.399975448846817
recon_loss: 0.029790066182613373, dist_loss: 0.21456041932106018
recon_loss: 0.029789626598358154, dist_loss: 0.8168946504592896
recon_loss: 0.029788020998239517, dist_loss: 0.7831082940101624
recon_loss: 0.029786361381411552, dist_loss: 0.43377652764320374
recon_loss: 0.029785437509417534, dist_loss: 0.5649940967559814
recon_loss: 0.029784491285681725, dist_loss: 0.5094789266586304
recon_loss: 0.029784509912133217, dist_loss: 0.4505446255207062
recon_loss: 0.029784904792904854, dist_loss: 0.6331191658973694
recon_loss: 0.029784556478261948, dist_loss: 0.6604510545730591
recon_loss: 0.02978433668613434, dist_loss: 0.6532962322235107
recon_loss: 0.029784047976136208, dist_loss: 0.6846071481704712
recon_loss: 0.02978288009762764, dist_loss: 0.7473647594451904
recon_loss: 0.029782000929117203, dist_loss: 1.291616439819336
recon_loss: 0.02978166937828064, dist_loss: 0.5213910341262817
recon_loss: 0.029781267046928406, dist_loss: 0.9238117933273315
recon_loss: 0.029780762270092964, dist_loss: 1.0600926876068115
recon_loss: 0.029780525714159012, dist_loss: 0.6982999444007874
recon_loss: 0.029780279844999313, dist_loss: 0.6404461860656738
recon_loss: 0.029779989272356033, dist_loss: 0.3507876396179199
recon_loss: 0.029779918491840363, dist_loss: 0.7307128310203552
recon_loss: 0.02977997623383999, dist_loss: 0.6494038105010986
recon_loss: 0.029779961332678795, dist_loss: 0.5319997072219849
recon_loss: 0.029779883101582527, dist_loss: 0.6257208585739136
recon_loss: 0.029780017212033272, dist_loss: 0.6445999145507812
recon_loss: 0.02977968566119671, dist_loss: 0.5487009286880493
recon_loss: 0.029779400676488876, dist_loss: 0.6778515577316284
recon_loss: 0.029780181124806404, dist_loss: 0.6545113921165466
recon_loss: 0.02977984957396984, dist_loss: 0.6244540810585022
recon_loss: 0.029779376462101936, dist_loss: 0.7355906963348389
recon_loss: 0.029779799282550812, dist_loss: 0.5841808915138245
recon_loss: 0.02977946773171425, dist_loss: 0.6766788959503174
recon_loss: 0.029780082404613495, dist_loss: 0.8317765593528748
recon_loss: 0.029781941324472427, dist_loss: 1.0294883251190186
recon_loss: 0.029782449826598167, dist_loss: 0.5496340990066528
recon_loss: 0.029782051220536232, dist_loss: 0.8723922967910767
recon_loss: 0.0297818873077631, dist_loss: 0.8882919549942017
recon_loss: 0.029782438650727272, dist_loss: 0.6651430130004883
recon_loss: 0.029782868921756744, dist_loss: 0.7375233173370361
recon_loss: 0.029782734811306, dist_loss: 1.0019513368606567
recon_loss: 0.029781874269247055, dist_loss: 0.6767555475234985
recon_loss: 0.02978125587105751, dist_loss: 0.4976121485233307
recon_loss: 0.029781421646475792, dist_loss: 0.34935101866722107
recon_loss: 0.029781725257635117, dist_loss: 0.5085923671722412
recon_loss: 0.02978123165667057, dist_loss: 0.5888531804084778
recon_loss: 0.029780399054288864, dist_loss: 1.3761804103851318
recon_loss: 0.02977912873029709, dist_loss: 0.9232921600341797
recon_loss: 0.02977766841650009, dist_loss: 0.8256776928901672
recon_loss: 0.029775971546769142, dist_loss: 0.7211136817932129
recon_loss: 0.02977530099451542, dist_loss: 0.34498149156570435
recon_loss: 0.029775608330965042, dist_loss: 1.0377986431121826
recon_loss: 0.029775917530059814, dist_loss: 0.7021442651748657
recon_loss: 0.029775621369481087, dist_loss: 0.6765729188919067
recon_loss: 0.029775530099868774, dist_loss: 0.7886082530021667
recon_loss: 0.02977553755044937, dist_loss: 0.8022449016571045
recon_loss: 0.029774989932775497, dist_loss: 0.46278828382492065
recon_loss: 0.029774406924843788, dist_loss: 0.5278612375259399
recon_loss: 0.02977500483393669, dist_loss: 0.8217528462409973
recon_loss: 0.029774252325296402, dist_loss: 0.5201616287231445
recon_loss: 0.029773807153105736, dist_loss: 0.373172402381897
recon_loss: 0.029773853719234467, dist_loss: 0.6313930749893188
recon_loss: 0.029773112386465073, dist_loss: 0.8983025550842285
recon_loss: 0.029772065579891205, dist_loss: 0.5890279412269592
recon_loss: 0.029771916568279266, dist_loss: 0.6240478754043579
recon_loss: 0.02977106347680092, dist_loss: 0.6582860946655273
recon_loss: 0.0297704990953207, dist_loss: 0.804416835308075
recon_loss: 0.029770342633128166, dist_loss: 0.46114808320999146
recon_loss: 0.029770074412226677, dist_loss: 0.4876200556755066
recon_loss: 0.029769446700811386, dist_loss: 0.6723091006278992
recon_loss: 0.029769087210297585, dist_loss: 0.5603944063186646
recon_loss: 0.029769182205200195, dist_loss: 0.4344579577445984
recon_loss: 0.029769284650683403, dist_loss: 0.6017202138900757
recon_loss: 0.029769090935587883, dist_loss: 0.36275291442871094
recon_loss: 0.029768776148557663, dist_loss: 0.5127919912338257
recon_loss: 0.029768148437142372, dist_loss: 0.5251449346542358
recon_loss: 0.029767939820885658, dist_loss: 0.5819136500358582
recon_loss: 0.02976805716753006, dist_loss: 0.8486926555633545
recon_loss: 0.029768330976366997, dist_loss: 0.7580653429031372
recon_loss: 0.02976856380701065, dist_loss: 0.6886770129203796
recon_loss: 0.029768696054816246, dist_loss: 0.5808670520782471
recon_loss: 0.02976856380701065, dist_loss: 0.49381789565086365
recon_loss: 0.02976824715733528, dist_loss: 0.5272328853607178
recon_loss: 0.029767928645014763, dist_loss: 0.8398327827453613
recon_loss: 0.029767584055662155, dist_loss: 0.8603503108024597
recon_loss: 0.029767485335469246, dist_loss: 0.7566956281661987
recon_loss: 0.029767358675599098, dist_loss: 0.41001439094543457
recon_loss: 0.029767202213406563, dist_loss: 0.6578124761581421
recon_loss: 0.029767202213406563, dist_loss: 1.568298578262329
recon_loss: 0.029767213389277458, dist_loss: 0.626860499382019
recon_loss: 0.029767083004117012, dist_loss: 0.4112880229949951
recon_loss: 0.02976689301431179, dist_loss: 0.6076688766479492
recon_loss: 0.029766825959086418, dist_loss: 0.5702030658721924
recon_loss: 0.029766913503408432, dist_loss: 0.5390363335609436
recon_loss: 0.029766691848635674, dist_loss: 0.5879797339439392
recon_loss: 0.029766550287604332, dist_loss: 0.3587545156478882
recon_loss: 0.029766451567411423, dist_loss: 0.5035820007324219
recon_loss: 0.02976643666625023, dist_loss: 1.075482726097107
recon_loss: 0.02976652793586254, dist_loss: 0.6615843176841736
Pre-training Epoch 39:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 39:   5%|▍         | 18/367 [00:00<00:02, 171.47it/s]Pre-training Epoch 39:  10%|▉         | 36/367 [00:00<00:01, 171.00it/s]Pre-training Epoch 39:  15%|█▍        | 54/367 [00:00<00:01, 166.28it/s]Pre-training Epoch 39:  19%|█▉        | 71/367 [00:00<00:01, 165.81it/s]Pre-training Epoch 39:  24%|██▍       | 88/367 [00:00<00:01, 165.96it/s]Pre-training Epoch 39:  29%|██▊       | 105/367 [00:00<00:01, 162.61it/s]Pre-training Epoch 39:  33%|███▎      | 122/367 [00:00<00:01, 163.09it/s]recon_loss: 0.02976660616695881, dist_loss: 0.5956746935844421
recon_loss: 0.029766621068120003, dist_loss: 0.897959291934967
recon_loss: 0.029766669496893883, dist_loss: 0.9584624171257019
recon_loss: 0.029767068102955818, dist_loss: 0.4595382511615753
recon_loss: 0.029767287895083427, dist_loss: 0.6940968632698059
recon_loss: 0.029767706990242004, dist_loss: 0.9481963515281677
recon_loss: 0.029767876490950584, dist_loss: 0.6418130993843079
recon_loss: 0.029768945649266243, dist_loss: 1.0625065565109253
recon_loss: 0.029769206419587135, dist_loss: 0.8571428060531616
recon_loss: 0.0297688040882349, dist_loss: 0.5550253987312317
recon_loss: 0.029769213870167732, dist_loss: 0.7570115923881531
recon_loss: 0.029769739136099815, dist_loss: 0.9368104934692383
recon_loss: 0.029769711196422577, dist_loss: 0.7573202848434448
recon_loss: 0.02977013774216175, dist_loss: 0.861096978187561
recon_loss: 0.02977088652551174, dist_loss: 0.6170059442520142
recon_loss: 0.02977054752409458, dist_loss: 0.2887866795063019
recon_loss: 0.02977003902196884, dist_loss: 0.4775243401527405
recon_loss: 0.02976996824145317, dist_loss: 0.8925951719284058
recon_loss: 0.02976975031197071, dist_loss: 0.6413180828094482
recon_loss: 0.029769044369459152, dist_loss: 0.4617946147918701
recon_loss: 0.029769008979201317, dist_loss: 0.7502307891845703
recon_loss: 0.029768938198685646, dist_loss: 0.8884545564651489
recon_loss: 0.029768599197268486, dist_loss: 0.5297167301177979
recon_loss: 0.029767639935016632, dist_loss: 0.7964317798614502
recon_loss: 0.029767008498311043, dist_loss: 0.6173328161239624
recon_loss: 0.029766885563731194, dist_loss: 0.830551028251648
recon_loss: 0.029766447842121124, dist_loss: 0.5060438513755798
recon_loss: 0.029765544459223747, dist_loss: 0.7762060761451721
recon_loss: 0.029765544459223747, dist_loss: 0.6634211540222168
recon_loss: 0.029765678569674492, dist_loss: 0.5467253923416138
recon_loss: 0.02976476028561592, dist_loss: 0.49065709114074707
recon_loss: 0.029763903468847275, dist_loss: 0.5782458186149597
recon_loss: 0.029765233397483826, dist_loss: 0.6747035980224609
recon_loss: 0.0297638438642025, dist_loss: 0.9991065263748169
recon_loss: 0.02976320870220661, dist_loss: 0.7595504522323608
recon_loss: 0.0297642033547163, dist_loss: 0.7212534546852112
recon_loss: 0.029764167964458466, dist_loss: 0.9091253280639648
recon_loss: 0.02976291999220848, dist_loss: 0.44166892766952515
recon_loss: 0.029763568192720413, dist_loss: 0.3296765089035034
recon_loss: 0.02976389229297638, dist_loss: 0.6031560897827148
recon_loss: 0.02976279892027378, dist_loss: 0.5703296065330505
recon_loss: 0.029762841761112213, dist_loss: 0.7337548732757568
recon_loss: 0.029763158410787582, dist_loss: 0.34916508197784424
recon_loss: 0.02976286970078945, dist_loss: 0.6518024206161499
recon_loss: 0.029762767255306244, dist_loss: 1.3694586753845215
recon_loss: 0.029763031750917435, dist_loss: 0.8193306922912598
recon_loss: 0.02976258657872677, dist_loss: 0.7889586091041565
recon_loss: 0.029762940481305122, dist_loss: 0.3942444622516632
recon_loss: 0.029763152822852135, dist_loss: 0.7189490795135498
recon_loss: 0.029762128368020058, dist_loss: 1.1895735263824463
recon_loss: 0.02976168505847454, dist_loss: 0.6965289115905762
recon_loss: 0.02976173721253872, dist_loss: 0.6024917364120483
recon_loss: 0.02976127155125141, dist_loss: 0.9892846345901489
recon_loss: 0.029761042445898056, dist_loss: 0.44293975830078125
recon_loss: 0.02976060099899769, dist_loss: 0.948495626449585
recon_loss: 0.029760640114545822, dist_loss: 0.6663973331451416
recon_loss: 0.029760202392935753, dist_loss: 0.7062656879425049
recon_loss: 0.029760215431451797, dist_loss: 0.6753588914871216
recon_loss: 0.02976039983332157, dist_loss: 0.6414017677307129
recon_loss: 0.02975955605506897, dist_loss: 1.082732915878296
recon_loss: 0.02975890040397644, dist_loss: 0.3915259838104248
recon_loss: 0.029758840799331665, dist_loss: 0.8063901662826538
recon_loss: 0.029758865013718605, dist_loss: 0.5387992262840271
recon_loss: 0.02975849062204361, dist_loss: 0.7017619013786316
recon_loss: 0.029758311808109283, dist_loss: 0.4446223974227905
recon_loss: 0.02975860796868801, dist_loss: 0.6079158782958984
recon_loss: 0.029758719727396965, dist_loss: 0.44704777002334595
recon_loss: 0.0297588799148798, dist_loss: 0.7416259050369263
recon_loss: 0.029759852215647697, dist_loss: 0.8331295847892761
recon_loss: 0.029760336503386497, dist_loss: 0.7746400237083435
recon_loss: 0.0297611802816391, dist_loss: 0.9175721406936646
recon_loss: 0.029762692749500275, dist_loss: 0.810086727142334
recon_loss: 0.029763134196400642, dist_loss: 0.7966251373291016
recon_loss: 0.029764167964458466, dist_loss: 0.7540937662124634
recon_loss: 0.0297652967274189, dist_loss: 0.8680523037910461
recon_loss: 0.029765311628580093, dist_loss: 0.49451178312301636
recon_loss: 0.029765304177999496, dist_loss: 0.4757128953933716
recon_loss: 0.02976468950510025, dist_loss: 0.6516204476356506
recon_loss: 0.029763836413621902, dist_loss: 0.5643420815467834
recon_loss: 0.029763469472527504, dist_loss: 0.8613940477371216
recon_loss: 0.02976304665207863, dist_loss: 0.6637834310531616
recon_loss: 0.0297622699290514, dist_loss: 0.8796878457069397
recon_loss: 0.02976198121905327, dist_loss: 0.4360329210758209
recon_loss: 0.029761902987957, dist_loss: 0.5995074510574341
recon_loss: 0.02976073883473873, dist_loss: 0.7673255801200867
recon_loss: 0.029759125784039497, dist_loss: 0.4047260284423828
recon_loss: 0.029758652672171593, dist_loss: 0.5255179405212402
recon_loss: 0.029758675023913383, dist_loss: 0.6840081810951233
recon_loss: 0.029757870361208916, dist_loss: 0.5082539319992065
recon_loss: 0.029757866635918617, dist_loss: 1.379601240158081
recon_loss: 0.029758434742689133, dist_loss: 1.093876600265503
recon_loss: 0.029758557677268982, dist_loss: 0.6342000961303711
recon_loss: 0.029758581891655922, dist_loss: 0.9761401414871216
recon_loss: 0.02975848689675331, dist_loss: 0.6490858197212219
recon_loss: 0.02975792996585369, dist_loss: 0.7991726398468018
recon_loss: 0.029757283627986908, dist_loss: 0.6416289806365967
recon_loss: 0.029756948351860046, dist_loss: 0.5357435941696167
recon_loss: 0.029756616801023483, dist_loss: 0.5100923776626587
recon_loss: 0.029755879193544388, dist_loss: 0.7257301807403564
recon_loss: 0.029755594208836555, dist_loss: 0.550020158290863
recon_loss: 0.029755152761936188, dist_loss: 0.7347196340560913
recon_loss: 0.029754340648651123, dist_loss: 1.0427978038787842
recon_loss: 0.029753709211945534, dist_loss: 0.7226006984710693
recon_loss: 0.029753342270851135, dist_loss: 0.5212304592132568
recon_loss: 0.029753180220723152, dist_loss: 0.8309903740882874
recon_loss: 0.029753001406788826, dist_loss: 0.8306726217269897
recon_loss: 0.029752615839242935, dist_loss: 0.6042839288711548
recon_loss: 0.029752418398857117, dist_loss: 0.6530632972717285
recon_loss: 0.029752302914857864, dist_loss: 0.336564302444458
recon_loss: 0.02975214272737503, dist_loss: 0.6658487915992737
recon_loss: 0.029751913622021675, dist_loss: 0.43348923325538635
recon_loss: 0.029752232134342194, dist_loss: 0.9221476316452026
recon_loss: 0.02975231222808361, dist_loss: 0.6146273612976074
recon_loss: 0.029751945286989212, dist_loss: 0.5637109279632568
recon_loss: 0.02975228801369667, dist_loss: 0.7112314701080322
recon_loss: 0.029752139002084732, dist_loss: 0.7069800496101379
recon_loss: 0.029751278460025787, dist_loss: 0.7570926547050476
recon_loss: 0.029751069843769073, dist_loss: 1.0203611850738525
recon_loss: 0.02975083701312542, dist_loss: 0.6578016877174377
recon_loss: 0.02975025586783886, dist_loss: 1.2305763959884644
recon_loss: 0.02975023165345192, dist_loss: 0.48358964920043945
recon_loss: 0.029750294983386993, dist_loss: 0.7235243320465088
recon_loss: 0.02974984608590603, dist_loss: 0.5832700729370117
recon_loss: 0.029749514535069466, dist_loss: 0.8086677193641663
recon_loss: 0.029749959707260132, dist_loss: 0.4727417826652527
recon_loss: 0.029750000685453415, dist_loss: 0.6556059122085571
recon_loss: 0.029749687761068344, dist_loss: 0.5246297121047974
recon_loss: 0.02974940463900566, dist_loss: 0.8095321655273438
Pre-training Epoch 39:  38%|███▊      | 139/367 [00:00<00:01, 163.16it/s]Pre-training Epoch 39:  43%|████▎     | 156/367 [00:00<00:01, 163.51it/s]Pre-training Epoch 39:  47%|████▋     | 173/367 [00:01<00:01, 164.03it/s]Pre-training Epoch 39:  52%|█████▏    | 190/367 [00:01<00:01, 164.10it/s]Pre-training Epoch 39:  56%|█████▋    | 207/367 [00:01<00:00, 161.15it/s]Pre-training Epoch 39:  61%|██████    | 224/367 [00:01<00:00, 157.33it/s]Pre-training Epoch 39:  66%|██████▌   | 241/367 [00:01<00:00, 158.39it/s]recon_loss: 0.029748953878879547, dist_loss: 0.5582983493804932
recon_loss: 0.02974809519946575, dist_loss: 0.5528906583786011
recon_loss: 0.029748085886240005, dist_loss: 0.5822242498397827
recon_loss: 0.02974783070385456, dist_loss: 0.8094888925552368
recon_loss: 0.029747411608695984, dist_loss: 0.4291474223136902
recon_loss: 0.029747428372502327, dist_loss: 0.5991023778915405
recon_loss: 0.029747799038887024, dist_loss: 0.847878098487854
recon_loss: 0.029747119173407555, dist_loss: 0.9051120281219482
recon_loss: 0.0297464020550251, dist_loss: 0.6489806771278381
recon_loss: 0.0297465268522501, dist_loss: 0.7629756927490234
recon_loss: 0.02974582090973854, dist_loss: 0.7472796440124512
recon_loss: 0.029744938015937805, dist_loss: 0.7493348121643066
recon_loss: 0.02974510006606579, dist_loss: 0.757163405418396
recon_loss: 0.029745537787675858, dist_loss: 0.7021239995956421
recon_loss: 0.02974524162709713, dist_loss: 0.4252406656742096
recon_loss: 0.029745526611804962, dist_loss: 0.7537293434143066
recon_loss: 0.0297451913356781, dist_loss: 0.6543182730674744
recon_loss: 0.029744479805231094, dist_loss: 0.7258232831954956
recon_loss: 0.0297442227602005, dist_loss: 0.6330419778823853
recon_loss: 0.029744045808911324, dist_loss: 0.4951726794242859
recon_loss: 0.02974342741072178, dist_loss: 0.6122431755065918
recon_loss: 0.02974287047982216, dist_loss: 0.3891734182834625
recon_loss: 0.029742715880274773, dist_loss: 0.6532957553863525
recon_loss: 0.029742831364274025, dist_loss: 0.47366294264793396
recon_loss: 0.02974296174943447, dist_loss: 0.6728262901306152
recon_loss: 0.029743120074272156, dist_loss: 0.6291353106498718
recon_loss: 0.02974390797317028, dist_loss: 0.3341046869754791
recon_loss: 0.02974342741072178, dist_loss: 0.748245120048523
recon_loss: 0.029741808772087097, dist_loss: 0.47922271490097046
recon_loss: 0.02974063716828823, dist_loss: 0.4829561114311218
recon_loss: 0.029739847406744957, dist_loss: 0.4440651535987854
recon_loss: 0.02973947674036026, dist_loss: 0.5050771832466125
recon_loss: 0.029739821329712868, dist_loss: 1.0290290117263794
recon_loss: 0.029740404337644577, dist_loss: 1.0034599304199219
recon_loss: 0.029740866273641586, dist_loss: 0.9005476236343384
recon_loss: 0.029740499332547188, dist_loss: 0.33285653591156006
recon_loss: 0.029740210622549057, dist_loss: 0.6260460615158081
recon_loss: 0.029739059507846832, dist_loss: 1.0533300638198853
recon_loss: 0.029737867414951324, dist_loss: 0.5983290076255798
recon_loss: 0.029737086966633797, dist_loss: 0.7307305335998535
recon_loss: 0.029736822471022606, dist_loss: 0.4767622947692871
recon_loss: 0.02973623014986515, dist_loss: 0.7658599615097046
recon_loss: 0.029735708609223366, dist_loss: 0.8121317028999329
recon_loss: 0.029735488817095757, dist_loss: 0.46217983961105347
recon_loss: 0.02973531186580658, dist_loss: 0.5996013283729553
recon_loss: 0.02973514050245285, dist_loss: 0.5813890695571899
recon_loss: 0.02973494865000248, dist_loss: 0.6151430010795593
recon_loss: 0.029734624549746513, dist_loss: 0.6073740124702454
recon_loss: 0.02973434142768383, dist_loss: 0.6468554735183716
recon_loss: 0.02973402477800846, dist_loss: 0.4956602454185486
recon_loss: 0.029733732342720032, dist_loss: 0.9109547138214111
recon_loss: 0.02973320335149765, dist_loss: 0.7501561045646667
recon_loss: 0.02973254583775997, dist_loss: 0.7190301418304443
recon_loss: 0.02973218634724617, dist_loss: 0.5832069516181946
recon_loss: 0.029732009395956993, dist_loss: 0.46549659967422485
recon_loss: 0.029731834307312965, dist_loss: 0.7846011519432068
recon_loss: 0.029731854796409607, dist_loss: 0.5469472408294678
recon_loss: 0.029732288792729378, dist_loss: 0.5880122184753418
recon_loss: 0.029732489958405495, dist_loss: 0.7218232154846191
recon_loss: 0.029732273891568184, dist_loss: 0.6073547601699829
recon_loss: 0.02973182313144207, dist_loss: 0.5785795450210571
recon_loss: 0.029731953516602516, dist_loss: 0.7277035713195801
recon_loss: 0.029732072725892067, dist_loss: 0.9170553684234619
recon_loss: 0.029732171446084976, dist_loss: 0.6180626749992371
recon_loss: 0.02973242662847042, dist_loss: 1.3341985940933228
recon_loss: 0.029732786118984222, dist_loss: 0.7263736128807068
recon_loss: 0.029732786118984222, dist_loss: 1.1330955028533936
recon_loss: 0.029732536524534225, dist_loss: 0.7382960915565491
recon_loss: 0.02973189763724804, dist_loss: 0.5478354096412659
recon_loss: 0.02973121590912342, dist_loss: 1.1382209062576294
recon_loss: 0.02973056025803089, dist_loss: 0.7114471197128296
recon_loss: 0.029730193316936493, dist_loss: 0.8373803496360779
recon_loss: 0.029730210080742836, dist_loss: 0.651614248752594
recon_loss: 0.029730407521128654, dist_loss: 0.6091514825820923
recon_loss: 0.02973046712577343, dist_loss: 0.6892731189727783
recon_loss: 0.029730722308158875, dist_loss: 0.47310325503349304
recon_loss: 0.0297305379062891, dist_loss: 0.7204841375350952
recon_loss: 0.02972990646958351, dist_loss: 0.7403472661972046
recon_loss: 0.029728997498750687, dist_loss: 0.8232054114341736
recon_loss: 0.029728079214692116, dist_loss: 0.8023900389671326
recon_loss: 0.029727712273597717, dist_loss: 0.5818430185317993
recon_loss: 0.0297282412648201, dist_loss: 0.950337290763855
recon_loss: 0.029728805646300316, dist_loss: 0.9368699789047241
recon_loss: 0.029728496447205544, dist_loss: 0.6475323438644409
recon_loss: 0.02972760610282421, dist_loss: 0.7445067763328552
recon_loss: 0.02972676046192646, dist_loss: 0.765703558921814
recon_loss: 0.02972569316625595, dist_loss: 0.9606490731239319
recon_loss: 0.02972458302974701, dist_loss: 0.39284247159957886
recon_loss: 0.02972445636987686, dist_loss: 0.9964590072631836
recon_loss: 0.029724860563874245, dist_loss: 0.7513078451156616
recon_loss: 0.02972516417503357, dist_loss: 0.695431113243103
recon_loss: 0.029724761843681335, dist_loss: 1.1147487163543701
recon_loss: 0.02972467802464962, dist_loss: 0.4405493140220642
recon_loss: 0.02972419746220112, dist_loss: 0.4330865442752838
recon_loss: 0.029723290354013443, dist_loss: 0.5836331844329834
recon_loss: 0.02972256764769554, dist_loss: 0.46684160828590393
recon_loss: 0.02972261793911457, dist_loss: 0.9470615386962891
recon_loss: 0.029722362756729126, dist_loss: 0.5249056816101074
recon_loss: 0.029722020030021667, dist_loss: 0.5013177394866943
recon_loss: 0.02972201071679592, dist_loss: 0.45417147874832153
recon_loss: 0.02972262352705002, dist_loss: 0.403836727142334
recon_loss: 0.029722733423113823, dist_loss: 0.7948735952377319
recon_loss: 0.02972226031124592, dist_loss: 0.49393266439437866
recon_loss: 0.029722003266215324, dist_loss: 0.4826287627220154
recon_loss: 0.029721403494477272, dist_loss: 0.43367651104927063
recon_loss: 0.029720760881900787, dist_loss: 1.0039807558059692
recon_loss: 0.029720552265644073, dist_loss: 0.8661073446273804
recon_loss: 0.02972063422203064, dist_loss: 0.5151270031929016
recon_loss: 0.029720686376094818, dist_loss: 0.6916036605834961
recon_loss: 0.029720550402998924, dist_loss: 0.5484431385993958
recon_loss: 0.02971986122429371, dist_loss: 0.8469319343566895
recon_loss: 0.029718590900301933, dist_loss: 0.674087643623352
recon_loss: 0.029718326404690742, dist_loss: 0.9931957721710205
recon_loss: 0.029718570411205292, dist_loss: 0.5116158127784729
recon_loss: 0.02971874736249447, dist_loss: 0.44978469610214233
recon_loss: 0.029719190672039986, dist_loss: 0.3526819348335266
recon_loss: 0.02971947006881237, dist_loss: 0.5318881273269653
recon_loss: 0.029719611629843712, dist_loss: 0.551796555519104
recon_loss: 0.029719483107328415, dist_loss: 0.7147583961486816
recon_loss: 0.029718847945332527, dist_loss: 0.3682032823562622
recon_loss: 0.02971860207617283, dist_loss: 0.43183472752571106
recon_loss: 0.02971840463578701, dist_loss: 0.4320460557937622
recon_loss: 0.029718322679400444, dist_loss: 0.7171585559844971
recon_loss: 0.029718076810240746, dist_loss: 0.787089467048645
recon_loss: 0.029718009755015373, dist_loss: 0.6112629175186157
recon_loss: 0.029717974364757538, dist_loss: 0.7111272811889648
recon_loss: 0.029717426747083664, dist_loss: 0.43802252411842346
recon_loss: 0.029716724529862404, dist_loss: 0.4937971830368042
Pre-training Epoch 39:  70%|███████   | 258/367 [00:01<00:00, 160.49it/s]Pre-training Epoch 39:  75%|███████▍  | 275/367 [00:01<00:00, 161.09it/s]Pre-training Epoch 39:  80%|███████▉  | 292/367 [00:01<00:00, 162.50it/s]Pre-training Epoch 39:  84%|████████▍ | 309/367 [00:01<00:00, 163.33it/s]Pre-training Epoch 39:  89%|████████▉ | 326/367 [00:01<00:00, 164.14it/s]Pre-training Epoch 39:  93%|█████████▎| 343/367 [00:02<00:00, 164.60it/s]Pre-training Epoch 39:  98%|█████████▊| 360/367 [00:02<00:00, 165.20it/s]Pre-training Epoch 39: 100%|██████████| 367/367 [00:02<00:00, 163.04it/s]
recon_loss: 0.029715683311223984, dist_loss: 1.2531816959381104
recon_loss: 0.02971474453806877, dist_loss: 0.7017562389373779
recon_loss: 0.029713965952396393, dist_loss: 0.4259456396102905
recon_loss: 0.02971324510872364, dist_loss: 0.6812833547592163
recon_loss: 0.02971256896853447, dist_loss: 0.5627421140670776
recon_loss: 0.029711835086345673, dist_loss: 0.34560173749923706
recon_loss: 0.029711216688156128, dist_loss: 1.0284792184829712
recon_loss: 0.029710490256547928, dist_loss: 0.986305296421051
recon_loss: 0.0297097060829401, dist_loss: 0.6423450112342834
recon_loss: 0.02970917336642742, dist_loss: 0.8819358944892883
recon_loss: 0.02970884181559086, dist_loss: 0.6954281330108643
recon_loss: 0.029708312824368477, dist_loss: 0.545261561870575
recon_loss: 0.029707804322242737, dist_loss: 1.0649739503860474
recon_loss: 0.02970811538398266, dist_loss: 0.9282899498939514
recon_loss: 0.029708119109272957, dist_loss: 0.556816577911377
recon_loss: 0.029707031324505806, dist_loss: 0.48611193895339966
recon_loss: 0.029706880450248718, dist_loss: 0.479836642742157
recon_loss: 0.029707496985793114, dist_loss: 0.8979922533035278
recon_loss: 0.029706766828894615, dist_loss: 0.7065126299858093
recon_loss: 0.029705867171287537, dist_loss: 0.5011048316955566
recon_loss: 0.02970675379037857, dist_loss: 0.5325509309768677
recon_loss: 0.02970653772354126, dist_loss: 0.5384951233863831
recon_loss: 0.029705286026000977, dist_loss: 0.9680484533309937
recon_loss: 0.029705271124839783, dist_loss: 0.4482349157333374
recon_loss: 0.029705356806516647, dist_loss: 0.770262598991394
recon_loss: 0.02970481663942337, dist_loss: 0.6460983753204346
recon_loss: 0.02970505878329277, dist_loss: 0.5509599447250366
recon_loss: 0.029704825952649117, dist_loss: 0.7783670425415039
recon_loss: 0.029704390093684196, dist_loss: 0.5347031950950623
recon_loss: 0.029704205691814423, dist_loss: 0.4466637372970581
recon_loss: 0.029703818261623383, dist_loss: 0.7147177457809448
recon_loss: 0.029703393578529358, dist_loss: 0.5235785245895386
recon_loss: 0.029702674597501755, dist_loss: 0.34061554074287415
recon_loss: 0.029702166095376015, dist_loss: 0.4874196946620941
recon_loss: 0.029702186584472656, dist_loss: 0.7573214769363403
recon_loss: 0.029701953753829002, dist_loss: 0.7358134388923645
recon_loss: 0.029701443389058113, dist_loss: 0.5991426110267639
recon_loss: 0.029701432213187218, dist_loss: 1.6161235570907593
recon_loss: 0.029701728373765945, dist_loss: 0.41302865743637085
recon_loss: 0.02970108576118946, dist_loss: 0.5715154409408569
recon_loss: 0.029700931161642075, dist_loss: 0.2726411819458008
recon_loss: 0.029701218008995056, dist_loss: 0.5709867477416992
recon_loss: 0.02970135025680065, dist_loss: 0.683495283126831
recon_loss: 0.029700761660933495, dist_loss: 1.0564484596252441
recon_loss: 0.029700955376029015, dist_loss: 0.6319711804389954
recon_loss: 0.029701625928282738, dist_loss: 0.5135990977287292
recon_loss: 0.029701298102736473, dist_loss: 0.5840089321136475
recon_loss: 0.02970138005912304, dist_loss: 0.5400664806365967
recon_loss: 0.029702145606279373, dist_loss: 0.5108723640441895
recon_loss: 0.02970205247402191, dist_loss: 0.28848785161972046
recon_loss: 0.029701771214604378, dist_loss: 0.32154813408851624
recon_loss: 0.029701683670282364, dist_loss: 0.7000129222869873
recon_loss: 0.029701383784413338, dist_loss: 0.6995375156402588
recon_loss: 0.029700733721256256, dist_loss: 1.0397757291793823
recon_loss: 0.029700102284550667, dist_loss: 0.40122586488723755
recon_loss: 0.029699381440877914, dist_loss: 0.8382627367973328
recon_loss: 0.029698848724365234, dist_loss: 0.7901169657707214
recon_loss: 0.029698489233851433, dist_loss: 0.7686318159103394
recon_loss: 0.029698306694626808, dist_loss: 0.7865005731582642
recon_loss: 0.029698137193918228, dist_loss: 0.7074131965637207
recon_loss: 0.029698051512241364, dist_loss: 0.5282033085823059
recon_loss: 0.029698077589273453, dist_loss: 0.8623610138893127
recon_loss: 0.029697949066758156, dist_loss: 0.7637165784835815
recon_loss: 0.02969776652753353, dist_loss: 0.34081077575683594
recon_loss: 0.029697509482502937, dist_loss: 0.44459664821624756
recon_loss: 0.02969716303050518, dist_loss: 0.7037445306777954
recon_loss: 0.029696915298700333, dist_loss: 0.7771242260932922
recon_loss: 0.029696542769670486, dist_loss: 0.9281612634658813
recon_loss: 0.0296962708234787, dist_loss: 0.6165997385978699
recon_loss: 0.02969672903418541, dist_loss: 1.2282040119171143
recon_loss: 0.02969650737941265, dist_loss: 0.5688464045524597
recon_loss: 0.029695482924580574, dist_loss: 1.3972111940383911
recon_loss: 0.02969450317323208, dist_loss: 0.6062393188476562
recon_loss: 0.029693765565752983, dist_loss: 0.48528048396110535
recon_loss: 0.029693296179175377, dist_loss: 0.8975643515586853
recon_loss: 0.029693573713302612, dist_loss: 0.3493514955043793
recon_loss: 0.029693663120269775, dist_loss: 0.7018346786499023
recon_loss: 0.029692957177758217, dist_loss: 0.9906244874000549
recon_loss: 0.029692361131310463, dist_loss: 0.5609499216079712
recon_loss: 0.029692286625504494, dist_loss: 0.8680890798568726
recon_loss: 0.02969222702085972, dist_loss: 0.7761251926422119
recon_loss: 0.029692547395825386, dist_loss: 0.42440691590309143
recon_loss: 0.02969289757311344, dist_loss: 0.5508614182472229
recon_loss: 0.02969323843717575, dist_loss: 1.1470866203308105
recon_loss: 0.02969304844737053, dist_loss: 0.4151223599910736
recon_loss: 0.029692957177758217, dist_loss: 0.46096253395080566
recon_loss: 0.029692700132727623, dist_loss: 0.625443160533905
recon_loss: 0.029692301526665688, dist_loss: 0.6077719926834106
recon_loss: 0.029691848903894424, dist_loss: 0.512855052947998
recon_loss: 0.02969130128622055, dist_loss: 0.877057671546936
recon_loss: 0.029691264033317566, dist_loss: 1.1692891120910645
recon_loss: 0.029691185802221298, dist_loss: 0.6467486619949341
recon_loss: 0.029690956696867943, dist_loss: 0.5582200288772583
recon_loss: 0.02969043143093586, dist_loss: 1.2166341543197632
recon_loss: 0.029689820483326912, dist_loss: 0.5823125243186951
recon_loss: 0.02968938648700714, dist_loss: 0.809107780456543
recon_loss: 0.029688503593206406, dist_loss: 0.30776679515838623
recon_loss: 0.029687868431210518, dist_loss: 0.6089630126953125
recon_loss: 0.02968760021030903, dist_loss: 0.4370196461677551
recon_loss: 0.029687657952308655, dist_loss: 0.8480494022369385
recon_loss: 0.0296877883374691, dist_loss: 0.4174705147743225
recon_loss: 0.02968800999224186, dist_loss: 1.0575807094573975
recon_loss: 0.029688088223338127, dist_loss: 1.0282518863677979
recon_loss: 0.0296876709908247, dist_loss: 0.6392143964767456
recon_loss: 0.02968701533973217, dist_loss: 1.0215175151824951
recon_loss: 0.02968634106218815, dist_loss: 0.33517950773239136
recon_loss: 0.029685815796256065, dist_loss: 0.6381660103797913
recon_loss: 0.029685890302062035, dist_loss: 0.5007109642028809
recon_loss: 0.02968592196702957, dist_loss: 0.28521066904067993
recon_loss: 0.029685378074645996, dist_loss: 0.42363566160202026
recon_loss: 0.02968559041619301, dist_loss: 0.6247014403343201
Pre-training Epoch 40:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 40:   5%|▌         | 19/367 [00:00<00:01, 184.93it/s]Pre-training Epoch 40:  11%|█         | 39/367 [00:00<00:01, 189.89it/s]Pre-training Epoch 40:  16%|█▌        | 58/367 [00:00<00:01, 186.94it/s]Pre-training Epoch 40:  21%|██        | 77/367 [00:00<00:01, 172.07it/s]Pre-training Epoch 40:  26%|██▌       | 95/367 [00:00<00:01, 170.12it/s]Pre-training Epoch 40:  31%|███       | 113/367 [00:00<00:01, 169.57it/s]recon_loss: 0.0296862181276083, dist_loss: 0.5101367235183716
recon_loss: 0.029685627669095993, dist_loss: 1.3829920291900635
recon_loss: 0.029685134068131447, dist_loss: 0.4638843536376953
recon_loss: 0.02968529984354973, dist_loss: 0.9749664068222046
recon_loss: 0.029685257002711296, dist_loss: 0.6749995946884155
recon_loss: 0.029684940353035927, dist_loss: 0.9508782625198364
recon_loss: 0.029685424640774727, dist_loss: 0.9522049427032471
recon_loss: 0.029685847461223602, dist_loss: 0.9802458882331848
recon_loss: 0.02968563139438629, dist_loss: 0.3840756416320801
recon_loss: 0.029685331508517265, dist_loss: 0.7402522563934326
recon_loss: 0.02968606911599636, dist_loss: 0.993454098701477
recon_loss: 0.029686348512768745, dist_loss: 0.7430883049964905
recon_loss: 0.029686711728572845, dist_loss: 0.4652179181575775
recon_loss: 0.02968723699450493, dist_loss: 0.4735199809074402
recon_loss: 0.02968708984553814, dist_loss: 0.4295719563961029
recon_loss: 0.029686691239476204, dist_loss: 0.8956260681152344
recon_loss: 0.029686475172638893, dist_loss: 0.7838793396949768
recon_loss: 0.02968599461019039, dist_loss: 1.0282762050628662
recon_loss: 0.02968559041619301, dist_loss: 0.7212485074996948
recon_loss: 0.02968529611825943, dist_loss: 0.29787588119506836
recon_loss: 0.029684489592909813, dist_loss: 0.3768616318702698
recon_loss: 0.029683422297239304, dist_loss: 1.1106183528900146
recon_loss: 0.029682675376534462, dist_loss: 0.5745192170143127
recon_loss: 0.029682273045182228, dist_loss: 0.8132565021514893
recon_loss: 0.02968212403357029, dist_loss: 0.6168355345726013
recon_loss: 0.029682083055377007, dist_loss: 0.7890667915344238
recon_loss: 0.029682625085115433, dist_loss: 0.788127601146698
recon_loss: 0.029683299362659454, dist_loss: 0.6559333801269531
recon_loss: 0.029683366417884827, dist_loss: 0.7341845035552979
recon_loss: 0.029683811590075493, dist_loss: 0.6950588822364807
recon_loss: 0.029683444648981094, dist_loss: 0.9958270192146301
recon_loss: 0.029682191088795662, dist_loss: 0.5264143943786621
recon_loss: 0.029681496322155, dist_loss: 0.6858538389205933
recon_loss: 0.029681149870157242, dist_loss: 0.6099189519882202
recon_loss: 0.02968013472855091, dist_loss: 0.5335068702697754
recon_loss: 0.029679689556360245, dist_loss: 1.0549896955490112
recon_loss: 0.02968043088912964, dist_loss: 0.4828419089317322
recon_loss: 0.02968105860054493, dist_loss: 0.3040928840637207
recon_loss: 0.029680782929062843, dist_loss: 0.5387327671051025
recon_loss: 0.029680388048291206, dist_loss: 1.2314140796661377
recon_loss: 0.02968013845384121, dist_loss: 0.6295578479766846
recon_loss: 0.029679475352168083, dist_loss: 1.1106430292129517
recon_loss: 0.02967800386250019, dist_loss: 0.911785900592804
recon_loss: 0.029677806422114372, dist_loss: 0.8244519233703613
recon_loss: 0.0296779815107584, dist_loss: 0.7260115146636963
recon_loss: 0.02967786230146885, dist_loss: 0.6073979735374451
recon_loss: 0.029678260907530785, dist_loss: 0.5540661811828613
recon_loss: 0.029678378254175186, dist_loss: 0.44887298345565796
recon_loss: 0.02967756614089012, dist_loss: 0.6027421951293945
recon_loss: 0.029677340760827065, dist_loss: 0.6604644656181335
recon_loss: 0.029677152633666992, dist_loss: 0.9371620416641235
recon_loss: 0.029676267877221107, dist_loss: 0.9515249729156494
recon_loss: 0.029676543548703194, dist_loss: 0.645413875579834
recon_loss: 0.029677530750632286, dist_loss: 0.6991031169891357
recon_loss: 0.029677625745534897, dist_loss: 0.9199420213699341
recon_loss: 0.029678240418434143, dist_loss: 0.45462340116500854
recon_loss: 0.029679443687200546, dist_loss: 0.9461617469787598
recon_loss: 0.02968018315732479, dist_loss: 0.6329125761985779
recon_loss: 0.02967965044081211, dist_loss: 0.7853097915649414
recon_loss: 0.029679492115974426, dist_loss: 0.5709804892539978
recon_loss: 0.02967974729835987, dist_loss: 0.7301226854324341
recon_loss: 0.029679160565137863, dist_loss: 0.7475165128707886
recon_loss: 0.029678916558623314, dist_loss: 0.6644957065582275
recon_loss: 0.02967996895313263, dist_loss: 0.5260014533996582
recon_loss: 0.029680000618100166, dist_loss: 1.118288516998291
recon_loss: 0.029679613187909126, dist_loss: 0.33011817932128906
recon_loss: 0.029679950326681137, dist_loss: 0.7359532117843628
recon_loss: 0.029679443687200546, dist_loss: 0.621957540512085
recon_loss: 0.02967817895114422, dist_loss: 0.8032443523406982
recon_loss: 0.029677357524633408, dist_loss: 0.4802161455154419
recon_loss: 0.029677309095859528, dist_loss: 0.6683914065361023
recon_loss: 0.029676303267478943, dist_loss: 0.450472354888916
recon_loss: 0.02967405505478382, dist_loss: 0.47612330317497253
recon_loss: 0.029673226177692413, dist_loss: 0.5275925397872925
recon_loss: 0.02967333234846592, dist_loss: 0.8855650424957275
recon_loss: 0.02967195212841034, dist_loss: 0.5087472200393677
recon_loss: 0.029671411961317062, dist_loss: 0.6974146962165833
recon_loss: 0.02967175841331482, dist_loss: 0.5425847172737122
recon_loss: 0.029671285301446915, dist_loss: 0.4717967212200165
recon_loss: 0.02967044524848461, dist_loss: 0.6325564384460449
recon_loss: 0.029670903459191322, dist_loss: 0.801677405834198
recon_loss: 0.02967154234647751, dist_loss: 0.48554369807243347
recon_loss: 0.029670681804418564, dist_loss: 0.8693109750747681
recon_loss: 0.02967146225273609, dist_loss: 0.41198569536209106
recon_loss: 0.029672784730792046, dist_loss: 0.47991183400154114
recon_loss: 0.029673606157302856, dist_loss: 0.8450784683227539
recon_loss: 0.029674489051103592, dist_loss: 0.8421163558959961
recon_loss: 0.029675297439098358, dist_loss: 0.5364584922790527
recon_loss: 0.029675953090190887, dist_loss: 0.9536099433898926
recon_loss: 0.029675723984837532, dist_loss: 0.4628858268260956
recon_loss: 0.029675574973225594, dist_loss: 0.4652319848537445
recon_loss: 0.029676295816898346, dist_loss: 0.6775501370429993
recon_loss: 0.02967599220573902, dist_loss: 0.6627506613731384
recon_loss: 0.02967519871890545, dist_loss: 0.703454852104187
recon_loss: 0.029674706980586052, dist_loss: 0.544959545135498
recon_loss: 0.02967403084039688, dist_loss: 0.8580256104469299
recon_loss: 0.02967315912246704, dist_loss: 0.6812318563461304
recon_loss: 0.02967219240963459, dist_loss: 0.7028943300247192
recon_loss: 0.02967100217938423, dist_loss: 0.5368144512176514
recon_loss: 0.02966954931616783, dist_loss: 0.4521457552909851
recon_loss: 0.029668061062693596, dist_loss: 0.7124824523925781
recon_loss: 0.029666930437088013, dist_loss: 0.7495602369308472
recon_loss: 0.029665999114513397, dist_loss: 0.5708666443824768
recon_loss: 0.02966519445180893, dist_loss: 0.5831849575042725
recon_loss: 0.02966475673019886, dist_loss: 0.5540657043457031
recon_loss: 0.029664598405361176, dist_loss: 0.5967420339584351
recon_loss: 0.029664581641554832, dist_loss: 0.5509090423583984
recon_loss: 0.029664909467101097, dist_loss: 0.49488112330436707
recon_loss: 0.029665252193808556, dist_loss: 0.6035102605819702
recon_loss: 0.02966558374464512, dist_loss: 0.7002999782562256
recon_loss: 0.029665734618902206, dist_loss: 0.8388744592666626
recon_loss: 0.029665794223546982, dist_loss: 0.6540487408638
recon_loss: 0.029665963724255562, dist_loss: 0.8674591779708862
recon_loss: 0.029665332287549973, dist_loss: 0.655206561088562
recon_loss: 0.02966460958123207, dist_loss: 0.8508131504058838
recon_loss: 0.029664460569620132, dist_loss: 0.9234073758125305
recon_loss: 0.029664412140846252, dist_loss: 0.6295875906944275
recon_loss: 0.02966383658349514, dist_loss: 1.085079550743103
recon_loss: 0.029663318768143654, dist_loss: 0.5033302307128906
recon_loss: 0.029662922024726868, dist_loss: 0.599568247795105
recon_loss: 0.02966262586414814, dist_loss: 0.6922420859336853
recon_loss: 0.029662668704986572, dist_loss: 0.48707616329193115
recon_loss: 0.02966281957924366, dist_loss: 0.6151531338691711
recon_loss: 0.02966303937137127, dist_loss: 1.023695707321167
recon_loss: 0.029663098976016045, dist_loss: 0.43394380807876587
recon_loss: 0.029663000255823135, dist_loss: 0.5374475717544556
recon_loss: 0.029662365093827248, dist_loss: 0.511991024017334
recon_loss: 0.02966208942234516, dist_loss: 0.9690758585929871
Pre-training Epoch 40:  36%|███▌      | 131/367 [00:00<00:01, 167.79it/s]Pre-training Epoch 40:  40%|████      | 148/367 [00:00<00:01, 166.87it/s]Pre-training Epoch 40:  45%|████▍     | 165/367 [00:00<00:01, 166.29it/s]Pre-training Epoch 40:  50%|████▉     | 182/367 [00:01<00:01, 165.28it/s]Pre-training Epoch 40:  54%|█████▍    | 199/367 [00:01<00:01, 164.50it/s]Pre-training Epoch 40:  59%|█████▉    | 216/367 [00:01<00:00, 164.04it/s]Pre-training Epoch 40:  63%|██████▎   | 233/367 [00:01<00:00, 164.23it/s]Pre-training Epoch 40:  68%|██████▊   | 250/367 [00:01<00:00, 162.74it/s]recon_loss: 0.029661910608410835, dist_loss: 0.5092196464538574
recon_loss: 0.029661789536476135, dist_loss: 0.9368143081665039
recon_loss: 0.02966170944273472, dist_loss: 0.5870903730392456
recon_loss: 0.02966185100376606, dist_loss: 0.4842182993888855
recon_loss: 0.029662683606147766, dist_loss: 0.42106878757476807
recon_loss: 0.029663776978850365, dist_loss: 1.0622717142105103
recon_loss: 0.029663726687431335, dist_loss: 0.8175547122955322
recon_loss: 0.029663505032658577, dist_loss: 1.265512466430664
recon_loss: 0.029663244262337685, dist_loss: 0.4990054666996002
recon_loss: 0.029663190245628357, dist_loss: 0.7735408544540405
recon_loss: 0.02966265380382538, dist_loss: 0.5041046738624573
recon_loss: 0.029662389308214188, dist_loss: 0.7509236931800842
recon_loss: 0.029662329703569412, dist_loss: 0.33626729249954224
recon_loss: 0.02966226637363434, dist_loss: 1.2826144695281982
recon_loss: 0.02966175228357315, dist_loss: 0.6026611924171448
recon_loss: 0.029661448672413826, dist_loss: 1.0925581455230713
recon_loss: 0.029661349952220917, dist_loss: 0.335163950920105
recon_loss: 0.029661081731319427, dist_loss: 0.6693035364151001
recon_loss: 0.029661117121577263, dist_loss: 0.523396372795105
recon_loss: 0.02966116927564144, dist_loss: 0.9469033479690552
recon_loss: 0.029660001397132874, dist_loss: 0.6485879421234131
recon_loss: 0.029658885672688484, dist_loss: 0.6049132943153381
recon_loss: 0.029658237472176552, dist_loss: 0.933073103427887
recon_loss: 0.029657887294888496, dist_loss: 0.41768530011177063
recon_loss: 0.029657425358891487, dist_loss: 0.7328155040740967
recon_loss: 0.02965746819972992, dist_loss: 0.7907378077507019
recon_loss: 0.029656698927283287, dist_loss: 0.6281047463417053
recon_loss: 0.02965615503489971, dist_loss: 0.653931736946106
recon_loss: 0.02965577505528927, dist_loss: 0.4544786810874939
recon_loss: 0.029655752703547478, dist_loss: 0.6817363500595093
recon_loss: 0.029655562713742256, dist_loss: 0.5968812108039856
recon_loss: 0.029655911028385162, dist_loss: 0.98385089635849
recon_loss: 0.02965600974857807, dist_loss: 0.6602358222007751
recon_loss: 0.02965565398335457, dist_loss: 1.0643963813781738
recon_loss: 0.029655637219548225, dist_loss: 1.1241786479949951
recon_loss: 0.02965557388961315, dist_loss: 0.7410977482795715
recon_loss: 0.029655219987034798, dist_loss: 0.2845820486545563
recon_loss: 0.029654892161488533, dist_loss: 0.8366468548774719
recon_loss: 0.02965451031923294, dist_loss: 0.6216192841529846
recon_loss: 0.029654059559106827, dist_loss: 0.8230989575386047
recon_loss: 0.029653705656528473, dist_loss: 0.5967365503311157
recon_loss: 0.029652951285243034, dist_loss: 0.5776610374450684
recon_loss: 0.029652627184987068, dist_loss: 0.6247831583023071
recon_loss: 0.029652651399374008, dist_loss: 0.5074270963668823
recon_loss: 0.029651617631316185, dist_loss: 0.3877291679382324
recon_loss: 0.02965204045176506, dist_loss: 1.131943941116333
recon_loss: 0.029653053730726242, dist_loss: 0.5523682236671448
recon_loss: 0.02965274639427662, dist_loss: 0.6515442132949829
recon_loss: 0.029651956632733345, dist_loss: 0.5214294195175171
recon_loss: 0.029651504009962082, dist_loss: 0.6153771877288818
recon_loss: 0.029650362208485603, dist_loss: 1.0293991565704346
recon_loss: 0.02964966371655464, dist_loss: 0.3965604603290558
recon_loss: 0.029650099575519562, dist_loss: 0.696140706539154
recon_loss: 0.02964981086552143, dist_loss: 0.39411690831184387
recon_loss: 0.02964910864830017, dist_loss: 0.6418468952178955
recon_loss: 0.02964949421584606, dist_loss: 0.6490034461021423
recon_loss: 0.02965005487203598, dist_loss: 0.8408889770507812
recon_loss: 0.029648523777723312, dist_loss: 0.5360537171363831
recon_loss: 0.02964845672249794, dist_loss: 0.6278715133666992
recon_loss: 0.029648682102560997, dist_loss: 0.5112638473510742
recon_loss: 0.029647814109921455, dist_loss: 0.8206676840782166
recon_loss: 0.029647186398506165, dist_loss: 0.9789583086967468
recon_loss: 0.02964761294424534, dist_loss: 0.5992965698242188
recon_loss: 0.02964775823056698, dist_loss: 0.41422924399375916
recon_loss: 0.0296467337757349, dist_loss: 0.6909136772155762
recon_loss: 0.029646338894963264, dist_loss: 0.48428860306739807
recon_loss: 0.029646791517734528, dist_loss: 0.580694854259491
recon_loss: 0.029647136107087135, dist_loss: 1.0102636814117432
recon_loss: 0.029647214338183403, dist_loss: 0.5009891986846924
recon_loss: 0.02964763343334198, dist_loss: 0.6325992345809937
recon_loss: 0.029648931697010994, dist_loss: 0.7534748315811157
recon_loss: 0.029648737981915474, dist_loss: 0.5813779830932617
recon_loss: 0.02964823693037033, dist_loss: 0.9055155515670776
recon_loss: 0.0296486746519804, dist_loss: 0.4916938543319702
recon_loss: 0.029647763818502426, dist_loss: 0.6921722888946533
recon_loss: 0.029646875336766243, dist_loss: 0.7068989872932434
recon_loss: 0.0296471007168293, dist_loss: 0.5329236388206482
recon_loss: 0.029646823182702065, dist_loss: 0.9283854365348816
recon_loss: 0.029645707458257675, dist_loss: 0.36638185381889343
recon_loss: 0.029645057395100594, dist_loss: 0.6268208026885986
recon_loss: 0.029644200578331947, dist_loss: 0.5878506898880005
recon_loss: 0.029642432928085327, dist_loss: 0.6056156754493713
recon_loss: 0.029641462489962578, dist_loss: 0.886696457862854
recon_loss: 0.029641257598996162, dist_loss: 0.5598980188369751
recon_loss: 0.02964075095951557, dist_loss: 0.3285372257232666
recon_loss: 0.02964075654745102, dist_loss: 0.49663054943084717
recon_loss: 0.029640644788742065, dist_loss: 0.9134404063224792
recon_loss: 0.029639655724167824, dist_loss: 0.7474966049194336
recon_loss: 0.029638901352882385, dist_loss: 0.6781203746795654
recon_loss: 0.029638439416885376, dist_loss: 0.5405376553535461
recon_loss: 0.029637843370437622, dist_loss: 0.5751535296440125
recon_loss: 0.029637454077601433, dist_loss: 0.6763266921043396
recon_loss: 0.029637642204761505, dist_loss: 0.8459394574165344
recon_loss: 0.029637757688760757, dist_loss: 0.48369085788726807
recon_loss: 0.029637277126312256, dist_loss: 0.6943564414978027
recon_loss: 0.02963661029934883, dist_loss: 0.6554838418960571
recon_loss: 0.029636120423674583, dist_loss: 1.0174500942230225
recon_loss: 0.029635926708579063, dist_loss: 0.8793612718582153
recon_loss: 0.029635708779096603, dist_loss: 0.4189120829105377
recon_loss: 0.02963554486632347, dist_loss: 0.8409421443939209
recon_loss: 0.029635006561875343, dist_loss: 0.7923731803894043
recon_loss: 0.02963501214981079, dist_loss: 0.6324515342712402
recon_loss: 0.0296347476541996, dist_loss: 0.9169203042984009
recon_loss: 0.029634518548846245, dist_loss: 0.8036668300628662
recon_loss: 0.029634155333042145, dist_loss: 0.5792354941368103
recon_loss: 0.029633650556206703, dist_loss: 0.938525915145874
recon_loss: 0.029633019119501114, dist_loss: 0.733950138092041
recon_loss: 0.029632501304149628, dist_loss: 0.8934972286224365
recon_loss: 0.029632568359375, dist_loss: 0.30409350991249084
recon_loss: 0.029632704332470894, dist_loss: 0.5038710236549377
recon_loss: 0.029632268473505974, dist_loss: 0.6283570528030396
recon_loss: 0.029631780460476875, dist_loss: 0.6095280647277832
recon_loss: 0.029631290584802628, dist_loss: 0.6242498159408569
recon_loss: 0.02963096834719181, dist_loss: 0.725525438785553
recon_loss: 0.0296306312084198, dist_loss: 0.8333333730697632
recon_loss: 0.029630189761519432, dist_loss: 0.4646907448768616
recon_loss: 0.02962995320558548, dist_loss: 0.7639310956001282
recon_loss: 0.029629787430167198, dist_loss: 1.3201818466186523
recon_loss: 0.02962956763803959, dist_loss: 0.44847047328948975
recon_loss: 0.02962937392294407, dist_loss: 0.6274843215942383
recon_loss: 0.029629239812493324, dist_loss: 0.8214157819747925
recon_loss: 0.029629169031977654, dist_loss: 0.5274519920349121
recon_loss: 0.029628951102495193, dist_loss: 0.7355747222900391
recon_loss: 0.029628777876496315, dist_loss: 0.8340818881988525
recon_loss: 0.02962876297533512, dist_loss: 0.4924539029598236
recon_loss: 0.029628731310367584, dist_loss: 0.47233593463897705
recon_loss: 0.029628422111272812, dist_loss: 0.9217471480369568
recon_loss: 0.029628435149788857, dist_loss: 0.42411524057388306
Pre-training Epoch 40:  73%|███████▎  | 268/367 [00:01<00:00, 167.03it/s]Pre-training Epoch 40:  78%|███████▊  | 286/367 [00:01<00:00, 169.48it/s]Pre-training Epoch 40:  83%|████████▎ | 303/367 [00:01<00:00, 164.85it/s]Pre-training Epoch 40:  87%|████████▋ | 320/367 [00:01<00:00, 160.80it/s]Pre-training Epoch 40:  92%|█████████▏| 337/367 [00:02<00:00, 159.13it/s]Pre-training Epoch 40:  96%|█████████▌| 353/367 [00:02<00:00, 158.25it/s]Pre-training Epoch 40: 100%|██████████| 367/367 [00:02<00:00, 166.50it/s]
recon_loss: 0.029628446325659752, dist_loss: 0.817995548248291
recon_loss: 0.02962813526391983, dist_loss: 0.8154181838035583
recon_loss: 0.029628103598952293, dist_loss: 0.99998939037323
recon_loss: 0.029627708718180656, dist_loss: 0.8812456130981445
recon_loss: 0.02962743304669857, dist_loss: 0.7933809161186218
recon_loss: 0.02962799184024334, dist_loss: 0.38739755749702454
recon_loss: 0.02962816320359707, dist_loss: 0.8139500617980957
recon_loss: 0.029628746211528778, dist_loss: 0.36881792545318604
recon_loss: 0.02962988242506981, dist_loss: 0.7637356519699097
recon_loss: 0.029629262164235115, dist_loss: 0.8421694040298462
recon_loss: 0.029628032818436623, dist_loss: 0.6474183201789856
recon_loss: 0.029628051444888115, dist_loss: 0.5894737839698792
recon_loss: 0.02962777204811573, dist_loss: 0.43047022819519043
recon_loss: 0.029627595096826553, dist_loss: 0.9555433988571167
recon_loss: 0.029628029093146324, dist_loss: 0.9463794827461243
recon_loss: 0.029628252610564232, dist_loss: 0.5012836456298828
recon_loss: 0.02962818555533886, dist_loss: 0.942651629447937
recon_loss: 0.029628029093146324, dist_loss: 0.3928295373916626
recon_loss: 0.029627906158566475, dist_loss: 0.45315515995025635
recon_loss: 0.029627807438373566, dist_loss: 0.8284886479377747
recon_loss: 0.02962746098637581, dist_loss: 0.5556958913803101
recon_loss: 0.02962709777057171, dist_loss: 0.8649109601974487
recon_loss: 0.02962687611579895, dist_loss: 0.3689596354961395
recon_loss: 0.029626674950122833, dist_loss: 0.7407495975494385
recon_loss: 0.029626745730638504, dist_loss: 0.7490051984786987
recon_loss: 0.02962709404528141, dist_loss: 0.6873421669006348
recon_loss: 0.029627863317728043, dist_loss: 0.723365306854248
recon_loss: 0.029627680778503418, dist_loss: 0.6210335493087769
recon_loss: 0.029627172276377678, dist_loss: 0.33575743436813354
recon_loss: 0.029627203941345215, dist_loss: 0.9258345365524292
recon_loss: 0.029627526178956032, dist_loss: 0.3862783908843994
recon_loss: 0.02962753176689148, dist_loss: 0.9722054600715637
recon_loss: 0.029628103598952293, dist_loss: 0.9628176689147949
recon_loss: 0.02962915599346161, dist_loss: 0.6365774869918823
recon_loss: 0.02963016740977764, dist_loss: 0.5484204888343811
recon_loss: 0.029630856588482857, dist_loss: 0.9237813949584961
recon_loss: 0.029630446806550026, dist_loss: 0.4302578568458557
recon_loss: 0.02962934598326683, dist_loss: 0.4865860641002655
recon_loss: 0.02962859719991684, dist_loss: 0.59327632188797
recon_loss: 0.029628407210111618, dist_loss: 0.8126629590988159
recon_loss: 0.029628580436110497, dist_loss: 0.5806261301040649
recon_loss: 0.029628725722432137, dist_loss: 0.8303656578063965
recon_loss: 0.029629060998558998, dist_loss: 0.825057864189148
recon_loss: 0.02962884120643139, dist_loss: 0.7698465585708618
recon_loss: 0.029628640040755272, dist_loss: 0.9429152011871338
recon_loss: 0.029628312215209007, dist_loss: 0.37530434131622314
recon_loss: 0.029627444222569466, dist_loss: 1.5901062488555908
recon_loss: 0.029626579955220222, dist_loss: 0.4519018530845642
recon_loss: 0.029626626521348953, dist_loss: 0.7523518800735474
recon_loss: 0.029626229777932167, dist_loss: 0.42409345507621765
recon_loss: 0.02962668612599373, dist_loss: 1.0430262088775635
recon_loss: 0.029627515003085136, dist_loss: 0.9381155967712402
recon_loss: 0.02962837927043438, dist_loss: 0.8952527046203613
recon_loss: 0.029628703370690346, dist_loss: 0.6679699420928955
recon_loss: 0.029628785327076912, dist_loss: 0.5234014987945557
recon_loss: 0.029628802090883255, dist_loss: 0.7645096182823181
recon_loss: 0.029628466814756393, dist_loss: 0.5937169790267944
recon_loss: 0.029628166928887367, dist_loss: 0.5211758017539978
recon_loss: 0.02962811104953289, dist_loss: 0.758010745048523
recon_loss: 0.029628202319145203, dist_loss: 0.6639225482940674
recon_loss: 0.029628364369273186, dist_loss: 0.342311292886734
recon_loss: 0.029627962037920952, dist_loss: 0.6043903231620789
recon_loss: 0.029627352952957153, dist_loss: 0.8538316488265991
recon_loss: 0.029626276344060898, dist_loss: 0.4312087297439575
recon_loss: 0.029625218361616135, dist_loss: 0.3668334484100342
recon_loss: 0.029624300077557564, dist_loss: 1.075913906097412
recon_loss: 0.029624074697494507, dist_loss: 0.4069254398345947
recon_loss: 0.02962399274110794, dist_loss: 0.647346019744873
recon_loss: 0.029623249545693398, dist_loss: 0.6520714163780212
recon_loss: 0.029622599482536316, dist_loss: 0.799324631690979
recon_loss: 0.029621830210089684, dist_loss: 0.5627843737602234
recon_loss: 0.029621418565511703, dist_loss: 0.4414687156677246
recon_loss: 0.029621491208672523, dist_loss: 0.5174672603607178
recon_loss: 0.02962149865925312, dist_loss: 0.8266829252243042
recon_loss: 0.029621616005897522, dist_loss: 0.8714723587036133
recon_loss: 0.02962207794189453, dist_loss: 0.5614815950393677
recon_loss: 0.02962178736925125, dist_loss: 0.6489560604095459
recon_loss: 0.029620913788676262, dist_loss: 0.6065325736999512
recon_loss: 0.02962137944996357, dist_loss: 0.38085484504699707
recon_loss: 0.02962111122906208, dist_loss: 0.47147783637046814
recon_loss: 0.029620042070746422, dist_loss: 1.1031017303466797
recon_loss: 0.029621301218867302, dist_loss: 1.0840446949005127
recon_loss: 0.029622500762343407, dist_loss: 0.7219612002372742
recon_loss: 0.029621096327900887, dist_loss: 0.6965190768241882
recon_loss: 0.02962077222764492, dist_loss: 0.551577627658844
recon_loss: 0.02962135151028633, dist_loss: 0.6124565005302429
recon_loss: 0.029619982466101646, dist_loss: 0.4201357066631317
recon_loss: 0.029619339853525162, dist_loss: 0.26162052154541016
recon_loss: 0.02961960807442665, dist_loss: 0.7286123037338257
recon_loss: 0.02961941994726658, dist_loss: 0.5773639678955078
recon_loss: 0.02961885929107666, dist_loss: 0.456587553024292
recon_loss: 0.02961905300617218, dist_loss: 0.509522020816803
recon_loss: 0.02961881272494793, dist_loss: 0.6384231448173523
recon_loss: 0.0296174269169569, dist_loss: 0.4097980558872223
recon_loss: 0.029616858810186386, dist_loss: 0.4822780191898346
recon_loss: 0.02961646020412445, dist_loss: 0.5569353103637695
recon_loss: 0.02961573749780655, dist_loss: 0.9861630201339722
recon_loss: 0.029615577310323715, dist_loss: 0.6437026858329773
recon_loss: 0.02961568348109722, dist_loss: 0.713834822177887
recon_loss: 0.02961552143096924, dist_loss: 0.8039538860321045
recon_loss: 0.029614822939038277, dist_loss: 0.4581274390220642
recon_loss: 0.02961454726755619, dist_loss: 0.4736759662628174
recon_loss: 0.029614156112074852, dist_loss: 0.7717489004135132
recon_loss: 0.029613742604851723, dist_loss: 0.5267916321754456
recon_loss: 0.029613757506012917, dist_loss: 0.5005764365196228
recon_loss: 0.029614029452204704, dist_loss: 0.5035796165466309
recon_loss: 0.029614420607686043, dist_loss: 0.681776762008667
recon_loss: 0.029614688828587532, dist_loss: 0.6929469704627991
recon_loss: 0.029614759609103203, dist_loss: 0.3106346130371094
recon_loss: 0.029614081606268883, dist_loss: 0.8472566604614258
recon_loss: 0.029613496735692024, dist_loss: 0.4085383117198944
Pre-train Epoch: 40
Train - Total Loss: 0.0975, Recon Loss: 0.0297, Dist Loss: 0.6786, l1 regularization: 0.0000
Val - Total Loss: 0.1016, Recon Loss: 0.0296, Dist Loss: 0.7201, l1 regularization: 0.0000
Pre-training Epoch 41:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 41:   5%|▍         | 18/367 [00:00<00:02, 172.29it/s]Pre-training Epoch 41:  10%|▉         | 36/367 [00:00<00:01, 176.03it/s]Pre-training Epoch 41:  15%|█▍        | 55/367 [00:00<00:01, 177.77it/s]Pre-training Epoch 41:  20%|█▉        | 73/367 [00:00<00:01, 176.99it/s]Pre-training Epoch 41:  25%|██▌       | 92/367 [00:00<00:01, 179.34it/s]Pre-training Epoch 41:  30%|██▉       | 110/367 [00:00<00:01, 174.48it/s]Pre-training Epoch 41:  35%|███▍      | 128/367 [00:00<00:01, 162.72it/s]recon_loss: 0.029612762853503227, dist_loss: 0.4049038887023926
recon_loss: 0.029612649232149124, dist_loss: 0.5860511064529419
recon_loss: 0.02961275912821293, dist_loss: 0.984026312828064
recon_loss: 0.029613027349114418, dist_loss: 1.1091023683547974
recon_loss: 0.02961329184472561, dist_loss: 0.7248479127883911
recon_loss: 0.0296128261834383, dist_loss: 0.7048397064208984
recon_loss: 0.029612641781568527, dist_loss: 0.8106845617294312
recon_loss: 0.029612664133310318, dist_loss: 0.7610870599746704
recon_loss: 0.029612628743052483, dist_loss: 0.8090038299560547
recon_loss: 0.029612606391310692, dist_loss: 0.5539729595184326
recon_loss: 0.029611831530928612, dist_loss: 0.595750093460083
recon_loss: 0.0296119786798954, dist_loss: 0.8937731385231018
recon_loss: 0.029612377285957336, dist_loss: 0.5054155588150024
recon_loss: 0.029612945392727852, dist_loss: 0.7261191010475159
recon_loss: 0.029613643884658813, dist_loss: 0.7898248434066772
recon_loss: 0.02961375005543232, dist_loss: 0.5154798626899719
recon_loss: 0.0296131931245327, dist_loss: 0.534830629825592
recon_loss: 0.02961208112537861, dist_loss: 0.4755284786224365
recon_loss: 0.029611118137836456, dist_loss: 0.6151019930839539
recon_loss: 0.029610799625515938, dist_loss: 0.7627098560333252
recon_loss: 0.029610613361001015, dist_loss: 0.6507915258407593
recon_loss: 0.029610032215714455, dist_loss: 0.5753276348114014
recon_loss: 0.02960941009223461, dist_loss: 0.32167595624923706
recon_loss: 0.029608450829982758, dist_loss: 0.7200495004653931
recon_loss: 0.02960740588605404, dist_loss: 0.5587775707244873
recon_loss: 0.029606852680444717, dist_loss: 0.5277058482170105
recon_loss: 0.029606813564896584, dist_loss: 0.6076352000236511
recon_loss: 0.029607193544507027, dist_loss: 0.48005998134613037
recon_loss: 0.029607737436890602, dist_loss: 0.37862056493759155
recon_loss: 0.029608052223920822, dist_loss: 0.5368728637695312
recon_loss: 0.02960803732275963, dist_loss: 0.5438799858093262
recon_loss: 0.029607445001602173, dist_loss: 0.6099448800086975
recon_loss: 0.029607240110635757, dist_loss: 1.062239170074463
recon_loss: 0.0296068973839283, dist_loss: 0.5629801154136658
recon_loss: 0.029606690630316734, dist_loss: 1.3716063499450684
recon_loss: 0.029606711119413376, dist_loss: 0.2431817650794983
recon_loss: 0.029606813564896584, dist_loss: 0.3733026683330536
recon_loss: 0.02960587479174137, dist_loss: 0.6887905597686768
recon_loss: 0.029605258256196976, dist_loss: 0.5212101340293884
recon_loss: 0.029604805633425713, dist_loss: 0.448392391204834
recon_loss: 0.02960333414375782, dist_loss: 0.595673680305481
recon_loss: 0.02960299514234066, dist_loss: 0.5615373849868774
recon_loss: 0.029603496193885803, dist_loss: 0.6177965402603149
recon_loss: 0.029602861031889915, dist_loss: 0.5857035517692566
recon_loss: 0.029602954164147377, dist_loss: 1.072468638420105
recon_loss: 0.029603566974401474, dist_loss: 0.6669694185256958
recon_loss: 0.029602954164147377, dist_loss: 0.5651354193687439
recon_loss: 0.02960207872092724, dist_loss: 0.5711835622787476
recon_loss: 0.029601287096738815, dist_loss: 0.5588213801383972
recon_loss: 0.029600949957966805, dist_loss: 0.3795464038848877
recon_loss: 0.029600942507386208, dist_loss: 0.5676641464233398
recon_loss: 0.029600651934742928, dist_loss: 0.7611365914344788
recon_loss: 0.02960098162293434, dist_loss: 0.8039844036102295
recon_loss: 0.029600780457258224, dist_loss: 0.43068721890449524
recon_loss: 0.029600180685520172, dist_loss: 0.44242724776268005
recon_loss: 0.029599759727716446, dist_loss: 0.5826624631881714
recon_loss: 0.02959940768778324, dist_loss: 1.0558594465255737
recon_loss: 0.029599282890558243, dist_loss: 0.8460607528686523
recon_loss: 0.02959979884326458, dist_loss: 1.230036735534668
recon_loss: 0.02959936484694481, dist_loss: 0.5258026123046875
recon_loss: 0.029598930850625038, dist_loss: 0.7977811694145203
recon_loss: 0.029599905014038086, dist_loss: 0.48566144704818726
recon_loss: 0.0295999888330698, dist_loss: 0.7612606287002563
recon_loss: 0.029598981142044067, dist_loss: 0.4774026870727539
recon_loss: 0.02959941141307354, dist_loss: 1.1269973516464233
recon_loss: 0.029599707573652267, dist_loss: 1.0538499355316162
recon_loss: 0.029598543420433998, dist_loss: 0.7724133729934692
recon_loss: 0.029598254710435867, dist_loss: 0.7336764931678772
recon_loss: 0.029598714783787727, dist_loss: 0.36736762523651123
recon_loss: 0.0295988991856575, dist_loss: 0.7500852942466736
recon_loss: 0.029598049819469452, dist_loss: 0.73769611120224
recon_loss: 0.02959861233830452, dist_loss: 0.6222845315933228
recon_loss: 0.029598742723464966, dist_loss: 0.4763084053993225
recon_loss: 0.029598310589790344, dist_loss: 0.43782973289489746
recon_loss: 0.029598340392112732, dist_loss: 0.9198567867279053
recon_loss: 0.029598480090498924, dist_loss: 0.8617838621139526
recon_loss: 0.029598074033856392, dist_loss: 0.887795627117157
recon_loss: 0.029597848653793335, dist_loss: 0.7681615352630615
recon_loss: 0.02959802746772766, dist_loss: 0.4767057001590729
recon_loss: 0.029598303139209747, dist_loss: 0.410054087638855
recon_loss: 0.029598193243145943, dist_loss: 0.3867589235305786
recon_loss: 0.029598074033856392, dist_loss: 0.9429818391799927
recon_loss: 0.029598820954561234, dist_loss: 0.29286348819732666
recon_loss: 0.029599538072943687, dist_loss: 0.6620047092437744
recon_loss: 0.02959955483675003, dist_loss: 0.37890100479125977
recon_loss: 0.029599174857139587, dist_loss: 0.9711600542068481
recon_loss: 0.029598137363791466, dist_loss: 0.5601959228515625
recon_loss: 0.029597049579024315, dist_loss: 0.3797881305217743
recon_loss: 0.02959665283560753, dist_loss: 0.8442264795303345
recon_loss: 0.029596859589219093, dist_loss: 0.7406319975852966
recon_loss: 0.029598308727145195, dist_loss: 0.7302911281585693
recon_loss: 0.029599681496620178, dist_loss: 0.3861381411552429
recon_loss: 0.029599085450172424, dist_loss: 0.7579447031021118
recon_loss: 0.02959866262972355, dist_loss: 0.46529620885849
recon_loss: 0.029597966000437737, dist_loss: 0.9451229572296143
recon_loss: 0.029597539454698563, dist_loss: 0.6876188516616821
recon_loss: 0.029597796499729156, dist_loss: 0.7214500308036804
recon_loss: 0.029598437249660492, dist_loss: 0.38267701864242554
recon_loss: 0.029599474743008614, dist_loss: 0.39525166153907776
recon_loss: 0.02960064634680748, dist_loss: 1.0859253406524658
recon_loss: 0.029601160436868668, dist_loss: 0.6058304309844971
recon_loss: 0.029599932953715324, dist_loss: 0.7493546605110168
recon_loss: 0.02959820069372654, dist_loss: 0.4183100461959839
recon_loss: 0.02959652803838253, dist_loss: 0.6514409780502319
recon_loss: 0.029595308005809784, dist_loss: 0.6977270841598511
recon_loss: 0.029594160616397858, dist_loss: 1.0895419120788574
recon_loss: 0.02959337830543518, dist_loss: 0.738008975982666
recon_loss: 0.029592715203762054, dist_loss: 0.6408617496490479
recon_loss: 0.02959233522415161, dist_loss: 0.5028671026229858
recon_loss: 0.029591627418994904, dist_loss: 1.2845739126205444
recon_loss: 0.02959134615957737, dist_loss: 0.8585718870162964
recon_loss: 0.029591098427772522, dist_loss: 0.527748703956604
recon_loss: 0.02959047630429268, dist_loss: 0.6749758720397949
recon_loss: 0.02959003672003746, dist_loss: 0.7407056093215942
recon_loss: 0.029589522629976273, dist_loss: 0.6520715951919556
recon_loss: 0.029589110985398293, dist_loss: 0.7575442790985107
recon_loss: 0.02958856336772442, dist_loss: 1.1402111053466797
recon_loss: 0.029587939381599426, dist_loss: 0.5437780618667603
recon_loss: 0.029587633907794952, dist_loss: 0.4352353811264038
recon_loss: 0.0295872762799263, dist_loss: 0.5814694166183472
recon_loss: 0.029586996883153915, dist_loss: 0.9593377709388733
recon_loss: 0.029586778953671455, dist_loss: 1.0351386070251465
recon_loss: 0.029586225748062134, dist_loss: 0.8503173589706421
recon_loss: 0.02958601899445057, dist_loss: 0.8868005275726318
recon_loss: 0.0295864287763834, dist_loss: 0.82099848985672
recon_loss: 0.029586629942059517, dist_loss: 0.3135834336280823
recon_loss: 0.02958652563393116, dist_loss: 0.4446452856063843
recon_loss: 0.02958603762090206, dist_loss: 0.9844099879264832
Pre-training Epoch 41:  40%|███▉      | 145/367 [00:00<00:01, 158.73it/s]Pre-training Epoch 41:  44%|████▍     | 162/367 [00:00<00:01, 159.98it/s]Pre-training Epoch 41:  50%|████▉     | 182/367 [00:01<00:01, 170.10it/s]Pre-training Epoch 41:  55%|█████▌    | 202/367 [00:01<00:00, 177.28it/s]Pre-training Epoch 41:  60%|██████    | 222/367 [00:01<00:00, 182.32it/s]Pre-training Epoch 41:  66%|██████▌   | 242/367 [00:01<00:00, 185.95it/s]recon_loss: 0.02958575449883938, dist_loss: 0.9867632389068604
recon_loss: 0.029585247859358788, dist_loss: 0.33575722575187683
recon_loss: 0.029584713280200958, dist_loss: 0.8352197408676147
recon_loss: 0.02958526834845543, dist_loss: 0.6109920740127563
recon_loss: 0.029585685580968857, dist_loss: 1.0354301929473877
recon_loss: 0.029584569856524467, dist_loss: 0.7125656604766846
recon_loss: 0.029585067182779312, dist_loss: 0.5664548873901367
recon_loss: 0.02958543784916401, dist_loss: 0.511320948600769
recon_loss: 0.029583368450403214, dist_loss: 0.6115531921386719
recon_loss: 0.029583651572465897, dist_loss: 0.7163026928901672
recon_loss: 0.029584325850009918, dist_loss: 0.8439273834228516
recon_loss: 0.029583169147372246, dist_loss: 0.8188455104827881
recon_loss: 0.02958332560956478, dist_loss: 0.699964702129364
recon_loss: 0.029583772644400597, dist_loss: 0.49424487352371216
recon_loss: 0.0295830387622118, dist_loss: 0.5005236864089966
recon_loss: 0.029583236202597618, dist_loss: 0.9596129655838013
recon_loss: 0.02958368882536888, dist_loss: 0.5891722440719604
recon_loss: 0.029583508148789406, dist_loss: 0.7148171663284302
recon_loss: 0.02958380989730358, dist_loss: 0.8728656768798828
recon_loss: 0.02958410046994686, dist_loss: 0.581747829914093
recon_loss: 0.029584305360913277, dist_loss: 0.41122016310691833
recon_loss: 0.029584087431430817, dist_loss: 0.35710906982421875
recon_loss: 0.02958395518362522, dist_loss: 0.9137550592422485
recon_loss: 0.02958359569311142, dist_loss: 0.5077317953109741
recon_loss: 0.02958250790834427, dist_loss: 0.6943602561950684
recon_loss: 0.029581626877188683, dist_loss: 0.473854124546051
recon_loss: 0.029581278562545776, dist_loss: 0.9147483706474304
recon_loss: 0.02957976423203945, dist_loss: 0.5883105993270874
recon_loss: 0.02957908622920513, dist_loss: 1.2025995254516602
recon_loss: 0.029579365625977516, dist_loss: 0.829891562461853
recon_loss: 0.029578503221273422, dist_loss: 0.6885574460029602
recon_loss: 0.029578249901533127, dist_loss: 0.5738353729248047
recon_loss: 0.029579197987914085, dist_loss: 0.4543560743331909
recon_loss: 0.029579870402812958, dist_loss: 0.522926926612854
recon_loss: 0.02958000637590885, dist_loss: 0.40789541602134705
recon_loss: 0.029580634087324142, dist_loss: 0.7003145217895508
recon_loss: 0.02958051674067974, dist_loss: 0.3481241464614868
recon_loss: 0.02957957051694393, dist_loss: 0.8623987436294556
recon_loss: 0.02957983873784542, dist_loss: 0.3926084637641907
recon_loss: 0.029579896479845047, dist_loss: 0.6423954963684082
recon_loss: 0.02957949973642826, dist_loss: 0.6250060200691223
recon_loss: 0.02957950532436371, dist_loss: 0.47209110856056213
recon_loss: 0.029579708352684975, dist_loss: 0.6805680990219116
recon_loss: 0.029579369351267815, dist_loss: 0.6597533226013184
recon_loss: 0.029579050838947296, dist_loss: 0.9744617938995361
recon_loss: 0.029578441753983498, dist_loss: 0.571639895439148
recon_loss: 0.02957781031727791, dist_loss: 0.8518906235694885
recon_loss: 0.029577212408185005, dist_loss: 0.3154352009296417
recon_loss: 0.02957640029489994, dist_loss: 0.48248791694641113
recon_loss: 0.029576081782579422, dist_loss: 0.5870794653892517
recon_loss: 0.029575427994132042, dist_loss: 0.6356593370437622
recon_loss: 0.029574742540717125, dist_loss: 0.8385948538780212
recon_loss: 0.029574468731880188, dist_loss: 0.40017470717430115
recon_loss: 0.029574129730463028, dist_loss: 0.7005932331085205
recon_loss: 0.029573805630207062, dist_loss: 0.8339265584945679
recon_loss: 0.02957383170723915, dist_loss: 0.6713066101074219
recon_loss: 0.029573801904916763, dist_loss: 0.769115686416626
recon_loss: 0.029574021697044373, dist_loss: 0.5422067046165466
recon_loss: 0.029574701562523842, dist_loss: 0.4036274552345276
recon_loss: 0.02957434207201004, dist_loss: 0.7496926784515381
recon_loss: 0.02957344427704811, dist_loss: 0.8157987594604492
recon_loss: 0.029572637751698494, dist_loss: 0.8164963722229004
recon_loss: 0.02957213670015335, dist_loss: 0.420089453458786
recon_loss: 0.029572568833827972, dist_loss: 1.2780544757843018
recon_loss: 0.02957327477633953, dist_loss: 0.7325135469436646
recon_loss: 0.02957349270582199, dist_loss: 0.5842291712760925
recon_loss: 0.029572874307632446, dist_loss: 1.0659817457199097
recon_loss: 0.029572781175374985, dist_loss: 1.1886221170425415
recon_loss: 0.02957182750105858, dist_loss: 0.5378974080085754
recon_loss: 0.029570424929261208, dist_loss: 0.6431903839111328
recon_loss: 0.029570166021585464, dist_loss: 0.5118237733840942
recon_loss: 0.02957003191113472, dist_loss: 0.6101828217506409
recon_loss: 0.02956985868513584, dist_loss: 0.38512346148490906
recon_loss: 0.02956998720765114, dist_loss: 0.6325805187225342
recon_loss: 0.02957030013203621, dist_loss: 0.4496089220046997
recon_loss: 0.029570581391453743, dist_loss: 0.7649873495101929
recon_loss: 0.029570188373327255, dist_loss: 0.5543704032897949
recon_loss: 0.029569676145911217, dist_loss: 0.5315531492233276
recon_loss: 0.029568856582045555, dist_loss: 0.6590401530265808
recon_loss: 0.02956811711192131, dist_loss: 0.6086994409561157
recon_loss: 0.029567746445536613, dist_loss: 0.562186598777771
recon_loss: 0.029567668214440346, dist_loss: 0.6955375671386719
recon_loss: 0.029567809775471687, dist_loss: 0.6721839904785156
recon_loss: 0.02956799976527691, dist_loss: 0.7874671816825867
recon_loss: 0.029568254947662354, dist_loss: 0.6377374529838562
recon_loss: 0.029568396508693695, dist_loss: 0.824771523475647
recon_loss: 0.029568202793598175, dist_loss: 1.2881481647491455
recon_loss: 0.029567914083600044, dist_loss: 1.03534734249115
recon_loss: 0.029567424207925797, dist_loss: 0.7645928859710693
recon_loss: 0.029566828161478043, dist_loss: 0.30831921100616455
recon_loss: 0.02956617809832096, dist_loss: 0.6198304891586304
recon_loss: 0.029565658420324326, dist_loss: 0.7048802971839905
recon_loss: 0.02956554666161537, dist_loss: 0.46224498748779297
recon_loss: 0.02956521138548851, dist_loss: 0.7213000059127808
recon_loss: 0.0295648705214262, dist_loss: 0.35756734013557434
recon_loss: 0.02956525608897209, dist_loss: 0.7487660050392151
recon_loss: 0.02956514246761799, dist_loss: 0.8351366519927979
recon_loss: 0.029564736410975456, dist_loss: 0.28982609510421753
recon_loss: 0.02956455759704113, dist_loss: 0.7762075662612915
recon_loss: 0.029564548283815384, dist_loss: 0.6220964789390564
recon_loss: 0.029564224183559418, dist_loss: 0.46450716257095337
recon_loss: 0.029563898220658302, dist_loss: 1.0681326389312744
recon_loss: 0.029564356431365013, dist_loss: 1.0229440927505493
recon_loss: 0.02956417389214039, dist_loss: 0.889432430267334
recon_loss: 0.02956344000995159, dist_loss: 0.6227224469184875
recon_loss: 0.029563572257757187, dist_loss: 0.46618062257766724
recon_loss: 0.029563430696725845, dist_loss: 0.3773224353790283
recon_loss: 0.029563069343566895, dist_loss: 0.3502272069454193
recon_loss: 0.029562830924987793, dist_loss: 0.4145420491695404
recon_loss: 0.029562626034021378, dist_loss: 0.7044402956962585
recon_loss: 0.029562219977378845, dist_loss: 0.47306984663009644
recon_loss: 0.02956174872815609, dist_loss: 0.6298457384109497
recon_loss: 0.029561366885900497, dist_loss: 0.5632111430168152
recon_loss: 0.02956099435687065, dist_loss: 0.5808303952217102
recon_loss: 0.029560629278421402, dist_loss: 0.6535069346427917
recon_loss: 0.029560498893260956, dist_loss: 0.5578944683074951
recon_loss: 0.029560476541519165, dist_loss: 0.4719088673591614
recon_loss: 0.029560541734099388, dist_loss: 0.441100537776947
recon_loss: 0.029560191556811333, dist_loss: 0.6530054807662964
recon_loss: 0.029559679329395294, dist_loss: 0.6878703832626343
recon_loss: 0.029559414833784103, dist_loss: 0.5984759330749512
recon_loss: 0.029558980837464333, dist_loss: 0.7830361127853394
recon_loss: 0.02955862134695053, dist_loss: 0.6384856700897217
recon_loss: 0.02955859713256359, dist_loss: 0.7663682699203491
recon_loss: 0.029557909816503525, dist_loss: 0.43817222118377686
recon_loss: 0.02955767884850502, dist_loss: 0.7705253958702087
recon_loss: 0.029557453468441963, dist_loss: 0.6408525705337524
recon_loss: 0.029557472094893456, dist_loss: 0.40874120593070984
Pre-training Epoch 41:  71%|███████▏  | 262/367 [00:01<00:00, 188.63it/s]Pre-training Epoch 41:  77%|███████▋  | 281/367 [00:01<00:00, 183.12it/s]Pre-training Epoch 41:  82%|████████▏ | 300/367 [00:01<00:00, 168.03it/s]Pre-training Epoch 41:  87%|████████▋ | 318/367 [00:01<00:00, 162.37it/s]Pre-training Epoch 41:  91%|█████████▏| 335/367 [00:01<00:00, 158.13it/s]Pre-training Epoch 41:  96%|█████████▌| 351/367 [00:02<00:00, 157.15it/s]Pre-training Epoch 41: 100%|██████████| 367/367 [00:02<00:00, 156.39it/s]Pre-training Epoch 41: 100%|██████████| 367/367 [00:02<00:00, 168.97it/s]
recon_loss: 0.02955782599747181, dist_loss: 0.6677286624908447
recon_loss: 0.029557449743151665, dist_loss: 0.9686498045921326
recon_loss: 0.02955661341547966, dist_loss: 1.0831239223480225
recon_loss: 0.029556432738900185, dist_loss: 0.6601633429527283
recon_loss: 0.029556142166256905, dist_loss: 0.4898689091205597
recon_loss: 0.02955533005297184, dist_loss: 0.43415647745132446
recon_loss: 0.029554923996329308, dist_loss: 0.6707516312599182
recon_loss: 0.02955462783575058, dist_loss: 0.7588086128234863
recon_loss: 0.029554374516010284, dist_loss: 0.6545045971870422
recon_loss: 0.029554171487689018, dist_loss: 0.94593346118927
recon_loss: 0.029553810134530067, dist_loss: 0.5221909284591675
recon_loss: 0.02955334633588791, dist_loss: 1.0924227237701416
recon_loss: 0.02955257147550583, dist_loss: 0.4690167009830475
recon_loss: 0.029552102088928223, dist_loss: 0.6099258661270142
recon_loss: 0.029551800340414047, dist_loss: 0.744287371635437
recon_loss: 0.02955181896686554, dist_loss: 1.2752974033355713
recon_loss: 0.02955140545964241, dist_loss: 0.4638477563858032
recon_loss: 0.029551196843385696, dist_loss: 1.0191054344177246
recon_loss: 0.029551832005381584, dist_loss: 0.903618335723877
recon_loss: 0.02955126203596592, dist_loss: 0.819706380367279
recon_loss: 0.029550494626164436, dist_loss: 0.8903094530105591
recon_loss: 0.029550807550549507, dist_loss: 0.9763299226760864
recon_loss: 0.029550693929195404, dist_loss: 0.731529951095581
recon_loss: 0.029550019651651382, dist_loss: 0.5321397185325623
recon_loss: 0.029549526050686836, dist_loss: 1.0947710275650024
recon_loss: 0.029549244791269302, dist_loss: 0.8324512839317322
recon_loss: 0.02954912558197975, dist_loss: 0.46973955631256104
recon_loss: 0.029549039900302887, dist_loss: 1.143824815750122
recon_loss: 0.02954891324043274, dist_loss: 0.6985572576522827
recon_loss: 0.02954896166920662, dist_loss: 1.2074275016784668
recon_loss: 0.029548877850174904, dist_loss: 0.5223256349563599
recon_loss: 0.029548464342951775, dist_loss: 1.2057790756225586
recon_loss: 0.029548335820436478, dist_loss: 0.2754019498825073
recon_loss: 0.029548265039920807, dist_loss: 0.44212955236434937
recon_loss: 0.029548149555921555, dist_loss: 1.4068715572357178
recon_loss: 0.02954796329140663, dist_loss: 0.9422822594642639
recon_loss: 0.02954799309372902, dist_loss: 0.6978681087493896
recon_loss: 0.029547736048698425, dist_loss: 0.7320080399513245
recon_loss: 0.029547588899731636, dist_loss: 0.5909878015518188
recon_loss: 0.029547667130827904, dist_loss: 0.49122101068496704
recon_loss: 0.02954789437353611, dist_loss: 0.5943677425384521
recon_loss: 0.02954810857772827, dist_loss: 0.6736801266670227
recon_loss: 0.029548808932304382, dist_loss: 0.840803861618042
recon_loss: 0.029549414291977882, dist_loss: 0.712101399898529
recon_loss: 0.02954934723675251, dist_loss: 0.4162803292274475
recon_loss: 0.029549164697527885, dist_loss: 0.5109956860542297
recon_loss: 0.029548751190304756, dist_loss: 0.4623703360557556
recon_loss: 0.029548404738307, dist_loss: 0.36410608887672424
recon_loss: 0.029548173770308495, dist_loss: 0.6388200521469116
recon_loss: 0.02954818494617939, dist_loss: 0.7084976434707642
recon_loss: 0.02954781986773014, dist_loss: 0.6657454967498779
recon_loss: 0.0295474324375391, dist_loss: 0.5044664144515991
recon_loss: 0.02954675443470478, dist_loss: 0.6093238592147827
recon_loss: 0.029545878991484642, dist_loss: 1.1819267272949219
recon_loss: 0.02954503707587719, dist_loss: 0.9741141200065613
recon_loss: 0.029544208198785782, dist_loss: 0.5629321932792664
recon_loss: 0.029543591663241386, dist_loss: 0.5316716432571411
recon_loss: 0.029542915523052216, dist_loss: 0.6950641870498657
recon_loss: 0.029542623087763786, dist_loss: 0.6899636387825012
recon_loss: 0.0295424684882164, dist_loss: 0.6309165358543396
recon_loss: 0.02954251505434513, dist_loss: 0.3435891270637512
recon_loss: 0.02954268641769886, dist_loss: 1.1139717102050781
recon_loss: 0.02954324148595333, dist_loss: 0.516424834728241
recon_loss: 0.029543522745370865, dist_loss: 0.6522440314292908
recon_loss: 0.02954394929111004, dist_loss: 0.3262070417404175
recon_loss: 0.029544105753302574, dist_loss: 0.807889997959137
recon_loss: 0.029544351622462273, dist_loss: 0.7462713718414307
recon_loss: 0.029544591903686523, dist_loss: 0.7739437818527222
recon_loss: 0.02954467199742794, dist_loss: 0.6016335487365723
recon_loss: 0.029544416815042496, dist_loss: 1.0500373840332031
recon_loss: 0.02954387664794922, dist_loss: 0.6335824728012085
recon_loss: 0.02954322099685669, dist_loss: 1.3735005855560303
recon_loss: 0.029542816802859306, dist_loss: 0.8273247480392456
recon_loss: 0.02954244427382946, dist_loss: 0.770033061504364
recon_loss: 0.029541853815317154, dist_loss: 0.4322245121002197
recon_loss: 0.029541106894612312, dist_loss: 0.4730638861656189
recon_loss: 0.029540810734033585, dist_loss: 0.3733401894569397
recon_loss: 0.029540840536355972, dist_loss: 0.5520792007446289
recon_loss: 0.029540248215198517, dist_loss: 1.0371031761169434
recon_loss: 0.02954043261706829, dist_loss: 1.2884061336517334
recon_loss: 0.029540633782744408, dist_loss: 0.4432031214237213
recon_loss: 0.02954084612429142, dist_loss: 0.41897711157798767
recon_loss: 0.029541347175836563, dist_loss: 1.093211054801941
recon_loss: 0.0295419879257679, dist_loss: 0.8340842723846436
recon_loss: 0.029542138800024986, dist_loss: 0.5951179265975952
recon_loss: 0.02954181656241417, dist_loss: 0.7444366216659546
recon_loss: 0.02954135648906231, dist_loss: 0.8161447048187256
recon_loss: 0.02954030968248844, dist_loss: 0.6544454097747803
recon_loss: 0.02953905425965786, dist_loss: 0.45959198474884033
recon_loss: 0.029537877067923546, dist_loss: 0.6618823409080505
recon_loss: 0.029536966234445572, dist_loss: 0.770196259021759
recon_loss: 0.02953667752444744, dist_loss: 0.44785094261169434
recon_loss: 0.0295368991792202, dist_loss: 0.7028674483299255
recon_loss: 0.029537735506892204, dist_loss: 0.8773073554039001
recon_loss: 0.029539208859205246, dist_loss: 0.5745937824249268
recon_loss: 0.029539553448557854, dist_loss: 0.3862350583076477
recon_loss: 0.029539473354816437, dist_loss: 0.5440707802772522
recon_loss: 0.029538635164499283, dist_loss: 0.699090301990509
recon_loss: 0.029537172988057137, dist_loss: 0.5751216411590576
recon_loss: 0.029536787420511246, dist_loss: 0.6351771354675293
recon_loss: 0.029536643996834755, dist_loss: 0.8101520538330078
recon_loss: 0.029536237940192223, dist_loss: 0.43995586037635803
recon_loss: 0.029536934569478035, dist_loss: 0.47329089045524597
recon_loss: 0.029537172988057137, dist_loss: 0.598142147064209
recon_loss: 0.029537072405219078, dist_loss: 0.9943724870681763
recon_loss: 0.029536787420511246, dist_loss: 0.5890579223632812
recon_loss: 0.029536742717027664, dist_loss: 0.4938088357448578
recon_loss: 0.029536375775933266, dist_loss: 0.6263981461524963
recon_loss: 0.029535381123423576, dist_loss: 0.5841645002365112
recon_loss: 0.029534487053751945, dist_loss: 0.6744959950447083
recon_loss: 0.02953498624265194, dist_loss: 0.9493550658226013
Pre-training Epoch 42:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 42:   4%|▍         | 16/367 [00:00<00:02, 154.60it/s]Pre-training Epoch 42:   9%|▊         | 32/367 [00:00<00:02, 151.38it/s]Pre-training Epoch 42:  13%|█▎        | 48/367 [00:00<00:02, 151.04it/s]Pre-training Epoch 42:  17%|█▋        | 64/367 [00:00<00:01, 151.81it/s]Pre-training Epoch 42:  22%|██▏       | 80/367 [00:00<00:01, 151.48it/s]Pre-training Epoch 42:  26%|██▌       | 96/367 [00:00<00:01, 151.53it/s]Pre-training Epoch 42:  31%|███       | 113/367 [00:00<00:01, 155.08it/s]recon_loss: 0.02953530289232731, dist_loss: 1.0384918451309204
recon_loss: 0.02953607775270939, dist_loss: 0.5282593369483948
recon_loss: 0.029536893591284752, dist_loss: 0.9459776878356934
recon_loss: 0.029537655413150787, dist_loss: 0.8763343095779419
recon_loss: 0.029537970200181007, dist_loss: 0.7015411853790283
recon_loss: 0.02953774854540825, dist_loss: 0.5812283754348755
recon_loss: 0.029536576941609383, dist_loss: 0.7847230434417725
recon_loss: 0.029534747824072838, dist_loss: 0.8015823364257812
recon_loss: 0.029532788321375847, dist_loss: 1.0620002746582031
recon_loss: 0.029532385990023613, dist_loss: 0.6069447994232178
recon_loss: 0.02953226864337921, dist_loss: 0.4418705701828003
recon_loss: 0.029532568529248238, dist_loss: 0.38633155822753906
recon_loss: 0.02953382395207882, dist_loss: 0.5375884771347046
recon_loss: 0.029534151777625084, dist_loss: 0.8333449363708496
recon_loss: 0.029532073065638542, dist_loss: 0.5945348739624023
recon_loss: 0.02953031286597252, dist_loss: 0.6855116486549377
recon_loss: 0.029529891908168793, dist_loss: 0.48176485300064087
recon_loss: 0.029528362676501274, dist_loss: 0.9861406087875366
recon_loss: 0.029527870938181877, dist_loss: 0.36559709906578064
recon_loss: 0.029529215767979622, dist_loss: 0.48089632391929626
recon_loss: 0.029528962448239326, dist_loss: 0.38136810064315796
recon_loss: 0.029528332874178886, dist_loss: 0.9816260933876038
recon_loss: 0.029527341946959496, dist_loss: 0.49816274642944336
recon_loss: 0.029526181519031525, dist_loss: 0.7768843770027161
recon_loss: 0.02952527068555355, dist_loss: 1.0968440771102905
recon_loss: 0.029525840654969215, dist_loss: 0.5938619375228882
recon_loss: 0.02952643670141697, dist_loss: 0.5159210562705994
recon_loss: 0.02952725626528263, dist_loss: 0.5091308951377869
recon_loss: 0.02952767163515091, dist_loss: 0.4290648102760315
recon_loss: 0.029526950791478157, dist_loss: 1.0284234285354614
recon_loss: 0.02952570840716362, dist_loss: 0.5107113122940063
recon_loss: 0.029524700716137886, dist_loss: 0.5533982515335083
recon_loss: 0.029524248093366623, dist_loss: 0.5290647745132446
recon_loss: 0.029524412006139755, dist_loss: 0.3155994415283203
recon_loss: 0.02952491119503975, dist_loss: 0.4471219778060913
recon_loss: 0.029525544494390488, dist_loss: 0.46433404088020325
recon_loss: 0.029525557532906532, dist_loss: 0.7223607897758484
recon_loss: 0.029525021091103554, dist_loss: 0.2499048262834549
recon_loss: 0.029523996636271477, dist_loss: 0.4027114808559418
recon_loss: 0.029523232951760292, dist_loss: 0.5302368998527527
recon_loss: 0.029523154720664024, dist_loss: 0.8888434171676636
recon_loss: 0.029523057863116264, dist_loss: 0.6151812076568604
recon_loss: 0.029523298144340515, dist_loss: 0.49778416752815247
recon_loss: 0.029523681849241257, dist_loss: 0.36413174867630005
recon_loss: 0.029524395242333412, dist_loss: 0.4627876281738281
recon_loss: 0.02952483296394348, dist_loss: 0.38816937804222107
recon_loss: 0.02952575497329235, dist_loss: 0.5034044981002808
recon_loss: 0.029526038095355034, dist_loss: 0.8715473413467407
recon_loss: 0.029526401311159134, dist_loss: 0.540813684463501
recon_loss: 0.029526297003030777, dist_loss: 1.1388559341430664
recon_loss: 0.029526473954319954, dist_loss: 0.5851539969444275
recon_loss: 0.029526378959417343, dist_loss: 0.3461649417877197
recon_loss: 0.02952643670141697, dist_loss: 0.5450459718704224
recon_loss: 0.029525984078645706, dist_loss: 0.8186922669410706
recon_loss: 0.029525166377425194, dist_loss: 0.6997752785682678
recon_loss: 0.02952442690730095, dist_loss: 0.6586184501647949
recon_loss: 0.029523679986596107, dist_loss: 0.6316466927528381
recon_loss: 0.029522890225052834, dist_loss: 0.732597827911377
recon_loss: 0.02952193282544613, dist_loss: 0.8930162787437439
recon_loss: 0.029521077871322632, dist_loss: 1.0290662050247192
recon_loss: 0.029520682990550995, dist_loss: 0.6947027444839478
recon_loss: 0.02952050045132637, dist_loss: 0.7014996409416199
recon_loss: 0.02951992116868496, dist_loss: 0.8200104832649231
recon_loss: 0.029519060626626015, dist_loss: 1.4432040452957153
recon_loss: 0.029518846422433853, dist_loss: 0.4269028902053833
recon_loss: 0.029518766328692436, dist_loss: 0.9652520418167114
recon_loss: 0.029518894851207733, dist_loss: 0.5643333196640015
recon_loss: 0.029519090428948402, dist_loss: 0.7294424772262573
recon_loss: 0.029519418254494667, dist_loss: 0.6189775466918945
recon_loss: 0.029519617557525635, dist_loss: 0.44436556100845337
recon_loss: 0.029519710689783096, dist_loss: 0.4632209837436676
recon_loss: 0.02951979450881481, dist_loss: 0.5852004289627075
recon_loss: 0.02951980195939541, dist_loss: 0.5090181231498718
recon_loss: 0.029519962146878242, dist_loss: 0.31406068801879883
recon_loss: 0.029520168900489807, dist_loss: 0.9756819605827332
recon_loss: 0.029520155861973763, dist_loss: 0.7896685004234314
recon_loss: 0.029519738629460335, dist_loss: 0.784449577331543
recon_loss: 0.02951967716217041, dist_loss: 0.6455302238464355
recon_loss: 0.029519546777009964, dist_loss: 0.5633312463760376
recon_loss: 0.02951914444565773, dist_loss: 0.4018075168132782
recon_loss: 0.02951814979314804, dist_loss: 0.46455350518226624
recon_loss: 0.029517069458961487, dist_loss: 0.9089071750640869
recon_loss: 0.029516596347093582, dist_loss: 0.6516228914260864
recon_loss: 0.029516560956835747, dist_loss: 0.6124892234802246
recon_loss: 0.02951653301715851, dist_loss: 0.43556541204452515
recon_loss: 0.029516512528061867, dist_loss: 0.7255605459213257
recon_loss: 0.029516475275158882, dist_loss: 1.3365916013717651
recon_loss: 0.02951635979115963, dist_loss: 1.456827163696289
recon_loss: 0.029515519738197327, dist_loss: 0.8585753440856934
recon_loss: 0.02951517514884472, dist_loss: 0.38910192251205444
recon_loss: 0.029515422880649567, dist_loss: 0.6367368102073669
recon_loss: 0.02951579913496971, dist_loss: 0.6471096873283386
recon_loss: 0.029516248032450676, dist_loss: 0.6934077143669128
recon_loss: 0.029516518115997314, dist_loss: 0.4791317284107208
recon_loss: 0.029516493901610374, dist_loss: 0.5836057066917419
recon_loss: 0.029516123235225677, dist_loss: 0.7477330565452576
recon_loss: 0.029515406116843224, dist_loss: 0.4753468632698059
recon_loss: 0.029514338821172714, dist_loss: 0.9592775106430054
recon_loss: 0.029513200744986534, dist_loss: 0.604699969291687
recon_loss: 0.029512161388993263, dist_loss: 1.2022976875305176
recon_loss: 0.029511479660868645, dist_loss: 1.018935203552246
recon_loss: 0.0295109786093235, dist_loss: 0.45259910821914673
recon_loss: 0.02951069176197052, dist_loss: 0.38112103939056396
recon_loss: 0.029510265216231346, dist_loss: 0.7925609350204468
recon_loss: 0.029509926214814186, dist_loss: 0.2870686650276184
recon_loss: 0.029509464278817177, dist_loss: 0.7449803352355957
recon_loss: 0.029508929699659348, dist_loss: 1.1822800636291504
recon_loss: 0.029508648440241814, dist_loss: 0.6401400566101074
recon_loss: 0.029508253559470177, dist_loss: 1.1368162631988525
recon_loss: 0.029508009552955627, dist_loss: 0.8068287372589111
recon_loss: 0.029507951810956, dist_loss: 0.8158602714538574
recon_loss: 0.029507780447602272, dist_loss: 0.5106340646743774
recon_loss: 0.029507772997021675, dist_loss: 0.7720358371734619
recon_loss: 0.029508186504244804, dist_loss: 0.5621405839920044
recon_loss: 0.02950771525502205, dist_loss: 0.7567412853240967
recon_loss: 0.02950761653482914, dist_loss: 0.7474744319915771
recon_loss: 0.029507234692573547, dist_loss: 0.32261231541633606
recon_loss: 0.02950679138302803, dist_loss: 0.9515941143035889
recon_loss: 0.02950667217373848, dist_loss: 0.49655529856681824
recon_loss: 0.029506511986255646, dist_loss: 0.8050289154052734
recon_loss: 0.029506122693419456, dist_loss: 0.3430148959159851
recon_loss: 0.029506118968129158, dist_loss: 0.7550605535507202
recon_loss: 0.029506364837288857, dist_loss: 0.6391334533691406
recon_loss: 0.029506279155611992, dist_loss: 0.7680318355560303
recon_loss: 0.029506130144000053, dist_loss: 1.0647034645080566
recon_loss: 0.029505647718906403, dist_loss: 0.7156555652618408
recon_loss: 0.029504960402846336, dist_loss: 0.9670604467391968
recon_loss: 0.029504600912332535, dist_loss: 1.0469895601272583
Pre-training Epoch 42:  35%|███▌      | 129/367 [00:00<00:01, 156.06it/s]Pre-training Epoch 42:  40%|████      | 147/367 [00:00<00:01, 162.17it/s]Pre-training Epoch 42:  45%|████▍     | 165/367 [00:01<00:01, 166.40it/s]Pre-training Epoch 42:  50%|████▉     | 182/367 [00:01<00:01, 162.59it/s]Pre-training Epoch 42:  54%|█████▍    | 199/367 [00:01<00:01, 160.74it/s]Pre-training Epoch 42:  59%|█████▉    | 216/367 [00:01<00:00, 157.46it/s]Pre-training Epoch 42:  63%|██████▎   | 232/367 [00:01<00:00, 156.31it/s]Pre-training Epoch 42:  68%|██████▊   | 248/367 [00:01<00:00, 155.81it/s]recon_loss: 0.02950441837310791, dist_loss: 0.6672008037567139
recon_loss: 0.029504355043172836, dist_loss: 0.4776556193828583
recon_loss: 0.029504282400012016, dist_loss: 0.7099571228027344
recon_loss: 0.029504038393497467, dist_loss: 0.8341837525367737
recon_loss: 0.029503846541047096, dist_loss: 0.46364626288414
recon_loss: 0.02950352430343628, dist_loss: 0.5651074647903442
recon_loss: 0.029503054916858673, dist_loss: 0.8858675360679626
recon_loss: 0.02950284071266651, dist_loss: 0.7286039590835571
recon_loss: 0.029502620920538902, dist_loss: 0.5021461248397827
recon_loss: 0.029502440243959427, dist_loss: 1.2127232551574707
recon_loss: 0.02950296737253666, dist_loss: 0.781548023223877
recon_loss: 0.029502419754862785, dist_loss: 0.6229796409606934
recon_loss: 0.029501445591449738, dist_loss: 0.6564558148384094
recon_loss: 0.02950158528983593, dist_loss: 0.5313897132873535
recon_loss: 0.029501229524612427, dist_loss: 0.5584595799446106
recon_loss: 0.029500534757971764, dist_loss: 0.9693414568901062
recon_loss: 0.02950092777609825, dist_loss: 0.517451286315918
recon_loss: 0.02950110472738743, dist_loss: 0.7751435041427612
recon_loss: 0.02950030378997326, dist_loss: 0.7311985492706299
recon_loss: 0.029501158744096756, dist_loss: 0.4472144544124603
recon_loss: 0.02950078435242176, dist_loss: 0.3315921127796173
recon_loss: 0.02949943207204342, dist_loss: 0.6374061107635498
recon_loss: 0.029499614611268044, dist_loss: 0.5691674947738647
recon_loss: 0.02950013428926468, dist_loss: 0.4199727177619934
recon_loss: 0.029498884454369545, dist_loss: 0.49799972772598267
recon_loss: 0.02949906513094902, dist_loss: 0.49624258279800415
recon_loss: 0.02949995920062065, dist_loss: 0.9926544427871704
recon_loss: 0.029498936608433723, dist_loss: 0.6679303646087646
recon_loss: 0.029498524963855743, dist_loss: 0.7983351945877075
recon_loss: 0.02949955314397812, dist_loss: 0.46430733799934387
recon_loss: 0.029499080032110214, dist_loss: 1.0734503269195557
recon_loss: 0.029498504474759102, dist_loss: 0.6399059295654297
recon_loss: 0.029500074684619904, dist_loss: 0.8523969650268555
recon_loss: 0.029499076306819916, dist_loss: 0.8817788362503052
recon_loss: 0.029498504474759102, dist_loss: 0.7645764350891113
recon_loss: 0.02949945256114006, dist_loss: 0.42344141006469727
recon_loss: 0.02949863113462925, dist_loss: 0.42520809173583984
recon_loss: 0.029498064890503883, dist_loss: 0.4188287854194641
recon_loss: 0.029498601332306862, dist_loss: 0.7424607276916504
recon_loss: 0.029498567804694176, dist_loss: 0.43680545687675476
recon_loss: 0.02949824556708336, dist_loss: 0.41153281927108765
recon_loss: 0.029498502612113953, dist_loss: 0.7354704141616821
recon_loss: 0.02949841134250164, dist_loss: 1.0704140663146973
recon_loss: 0.029498104006052017, dist_loss: 0.5943139791488647
recon_loss: 0.029497716575860977, dist_loss: 0.4837000370025635
recon_loss: 0.029497578740119934, dist_loss: 0.7136490345001221
recon_loss: 0.029497547075152397, dist_loss: 0.7031683325767517
recon_loss: 0.029497142881155014, dist_loss: 0.9235657453536987
recon_loss: 0.029496924951672554, dist_loss: 0.5204997062683105
recon_loss: 0.029497576877474785, dist_loss: 0.6907654404640198
recon_loss: 0.029497703537344933, dist_loss: 0.4203212857246399
recon_loss: 0.02949627861380577, dist_loss: 0.537221372127533
recon_loss: 0.029496101662516594, dist_loss: 0.56166672706604
recon_loss: 0.029496530070900917, dist_loss: 0.7705700397491455
recon_loss: 0.029495954513549805, dist_loss: 0.44799017906188965
recon_loss: 0.02949516661465168, dist_loss: 0.6888011693954468
recon_loss: 0.02949613332748413, dist_loss: 0.3086993098258972
recon_loss: 0.029496654868125916, dist_loss: 0.643720269203186
recon_loss: 0.029495947062969208, dist_loss: 0.3405812084674835
recon_loss: 0.029496565461158752, dist_loss: 1.0043866634368896
recon_loss: 0.029496893286705017, dist_loss: 0.44794124364852905
recon_loss: 0.02949638105928898, dist_loss: 0.6774742603302002
recon_loss: 0.02949637547135353, dist_loss: 0.530052900314331
recon_loss: 0.029496464878320694, dist_loss: 0.5265684127807617
recon_loss: 0.029495544731616974, dist_loss: 0.5349125266075134
recon_loss: 0.02949479967355728, dist_loss: 0.7156435251235962
recon_loss: 0.02949448861181736, dist_loss: 0.4633328318595886
recon_loss: 0.0294937863945961, dist_loss: 0.5463051795959473
recon_loss: 0.029493223875761032, dist_loss: 1.083709716796875
recon_loss: 0.02949293702840805, dist_loss: 0.7821382880210876
recon_loss: 0.029491934925317764, dist_loss: 0.453691303730011
recon_loss: 0.02949133701622486, dist_loss: 0.5578722357749939
recon_loss: 0.029491577297449112, dist_loss: 0.6815758943557739
recon_loss: 0.029491154477000237, dist_loss: 0.5842199921607971
recon_loss: 0.02949107438325882, dist_loss: 0.6862604022026062
recon_loss: 0.029490994289517403, dist_loss: 0.5065892934799194
recon_loss: 0.029490750283002853, dist_loss: 0.49208322167396545
recon_loss: 0.029490571469068527, dist_loss: 0.8284679055213928
recon_loss: 0.029490888118743896, dist_loss: 0.7453382015228271
recon_loss: 0.02949151024222374, dist_loss: 0.5388156175613403
recon_loss: 0.029491769149899483, dist_loss: 0.7501435875892639
recon_loss: 0.02949165552854538, dist_loss: 0.6887381076812744
recon_loss: 0.02949173003435135, dist_loss: 0.747888445854187
recon_loss: 0.029491908848285675, dist_loss: 0.7042752504348755
recon_loss: 0.02949194423854351, dist_loss: 0.7812624573707581
recon_loss: 0.029491785913705826, dist_loss: 0.942633867263794
recon_loss: 0.029491668567061424, dist_loss: 0.6113430261611938
recon_loss: 0.02949102781713009, dist_loss: 0.6219415068626404
recon_loss: 0.029490983113646507, dist_loss: 0.6522253155708313
recon_loss: 0.02949116751551628, dist_loss: 0.3951084613800049
recon_loss: 0.029491303488612175, dist_loss: 0.5581169128417969
recon_loss: 0.029490943998098373, dist_loss: 0.8454214930534363
recon_loss: 0.029491111636161804, dist_loss: 0.8629814386367798
recon_loss: 0.029490523040294647, dist_loss: 0.42607179284095764
recon_loss: 0.029489651322364807, dist_loss: 0.4242972433567047
recon_loss: 0.029489649459719658, dist_loss: 0.8183313012123108
recon_loss: 0.02948899008333683, dist_loss: 0.7628315687179565
recon_loss: 0.029488524422049522, dist_loss: 0.8185301423072815
recon_loss: 0.029488585889339447, dist_loss: 0.45195141434669495
recon_loss: 0.029488105326890945, dist_loss: 0.6368483304977417
recon_loss: 0.02948734536767006, dist_loss: 0.7729040384292603
recon_loss: 0.029487216845154762, dist_loss: 0.7823994159698486
recon_loss: 0.02948867715895176, dist_loss: 0.34760385751724243
recon_loss: 0.02948867715895176, dist_loss: 0.6832503080368042
recon_loss: 0.029488028958439827, dist_loss: 0.7973068952560425
recon_loss: 0.029489172622561455, dist_loss: 0.4253666400909424
recon_loss: 0.029489418491721153, dist_loss: 1.256337285041809
recon_loss: 0.029488222673535347, dist_loss: 0.7542097568511963
recon_loss: 0.029488109052181244, dist_loss: 0.9729011654853821
recon_loss: 0.029489200562238693, dist_loss: 0.7042937278747559
recon_loss: 0.029489679262042046, dist_loss: 1.0981444120407104
recon_loss: 0.02948913164436817, dist_loss: 0.5557514429092407
recon_loss: 0.029490478336811066, dist_loss: 0.8396892547607422
recon_loss: 0.02949085272848606, dist_loss: 0.7521822452545166
recon_loss: 0.02948867902159691, dist_loss: 0.2737092673778534
recon_loss: 0.02948814257979393, dist_loss: 0.48905348777770996
recon_loss: 0.029488956555724144, dist_loss: 0.7031341791152954
recon_loss: 0.02948630414903164, dist_loss: 1.1523267030715942
recon_loss: 0.029486948624253273, dist_loss: 0.572534441947937
recon_loss: 0.02948807179927826, dist_loss: 0.3597654700279236
recon_loss: 0.029484447091817856, dist_loss: 0.5035812854766846
recon_loss: 0.029484689235687256, dist_loss: 1.1685541868209839
recon_loss: 0.02948729693889618, dist_loss: 1.0615038871765137
recon_loss: 0.029486477375030518, dist_loss: 0.6704404950141907
recon_loss: 0.029483716934919357, dist_loss: 0.6706938743591309
recon_loss: 0.029483109712600708, dist_loss: 0.6882337331771851
recon_loss: 0.02948380447924137, dist_loss: 0.48977041244506836
recon_loss: 0.02948332577943802, dist_loss: 0.856855034828186
Pre-training Epoch 42:  72%|███████▏  | 265/367 [00:01<00:00, 159.76it/s]Pre-training Epoch 42:  77%|███████▋  | 282/367 [00:01<00:00, 160.94it/s]Pre-training Epoch 42:  81%|████████▏ | 299/367 [00:01<00:00, 159.86it/s]Pre-training Epoch 42:  86%|████████▌ | 316/367 [00:01<00:00, 161.57it/s]Pre-training Epoch 42:  91%|█████████ | 333/367 [00:02<00:00, 163.41it/s]Pre-training Epoch 42:  96%|█████████▌| 353/367 [00:02<00:00, 172.40it/s]Pre-training Epoch 42: 100%|██████████| 367/367 [00:02<00:00, 161.27it/s]
recon_loss: 0.029482748359441757, dist_loss: 0.6109258532524109
recon_loss: 0.029483720660209656, dist_loss: 0.3979385495185852
recon_loss: 0.029483405873179436, dist_loss: 0.8583251237869263
recon_loss: 0.029482034966349602, dist_loss: 0.818159818649292
recon_loss: 0.029481761157512665, dist_loss: 0.784327507019043
recon_loss: 0.02948164753615856, dist_loss: 0.8057102560997009
recon_loss: 0.029480839148163795, dist_loss: 0.7668284177780151
recon_loss: 0.0294808242470026, dist_loss: 0.7181116938591003
recon_loss: 0.02948148362338543, dist_loss: 0.7343875169754028
recon_loss: 0.02948177047073841, dist_loss: 0.8104023933410645
recon_loss: 0.029481224715709686, dist_loss: 0.5013306140899658
recon_loss: 0.029480867087841034, dist_loss: 0.26909106969833374
recon_loss: 0.02948058769106865, dist_loss: 0.4874475300312042
recon_loss: 0.029480360448360443, dist_loss: 0.516738772392273
recon_loss: 0.029480569064617157, dist_loss: 0.9475734829902649
recon_loss: 0.029480744153261185, dist_loss: 0.47750455141067505
recon_loss: 0.02948039211332798, dist_loss: 1.0401098728179932
recon_loss: 0.029480159282684326, dist_loss: 0.6770113706588745
recon_loss: 0.029480013996362686, dist_loss: 0.4713103175163269
recon_loss: 0.029479747638106346, dist_loss: 0.5179611444473267
recon_loss: 0.029479313641786575, dist_loss: 0.376451313495636
recon_loss: 0.029478907585144043, dist_loss: 0.778630256652832
recon_loss: 0.02947862260043621, dist_loss: 0.5971945524215698
recon_loss: 0.029478875920176506, dist_loss: 0.5088743567466736
recon_loss: 0.02947944775223732, dist_loss: 0.9119566679000854
recon_loss: 0.02948044426739216, dist_loss: 0.6420063972473145
recon_loss: 0.029481351375579834, dist_loss: 0.7780721783638
recon_loss: 0.0294813085347414, dist_loss: 0.6290289163589478
recon_loss: 0.02948066219687462, dist_loss: 0.5009018182754517
recon_loss: 0.02947988361120224, dist_loss: 0.645714282989502
recon_loss: 0.029479477554559708, dist_loss: 0.7968443632125854
recon_loss: 0.0294785313308239, dist_loss: 0.44772660732269287
recon_loss: 0.02947889268398285, dist_loss: 0.3914579451084137
recon_loss: 0.02947966568171978, dist_loss: 0.9034366607666016
recon_loss: 0.0294796135276556, dist_loss: 0.48746639490127563
recon_loss: 0.02947959490120411, dist_loss: 0.386271595954895
recon_loss: 0.02947831153869629, dist_loss: 0.6602216958999634
recon_loss: 0.02947653830051422, dist_loss: 0.42746686935424805
recon_loss: 0.029474448412656784, dist_loss: 0.6283426880836487
recon_loss: 0.029473794624209404, dist_loss: 0.46843478083610535
recon_loss: 0.02947336807847023, dist_loss: 0.8678817749023438
recon_loss: 0.029473798349499702, dist_loss: 0.4665248394012451
recon_loss: 0.02947520837187767, dist_loss: 0.7197225689888
recon_loss: 0.029474902898073196, dist_loss: 0.6575934886932373
recon_loss: 0.02947487123310566, dist_loss: 0.5865263938903809
recon_loss: 0.029474934563040733, dist_loss: 0.28341636061668396
recon_loss: 0.029473571106791496, dist_loss: 0.5037735104560852
recon_loss: 0.029471732676029205, dist_loss: 1.0339312553405762
recon_loss: 0.02947208471596241, dist_loss: 0.6983683705329895
recon_loss: 0.029470913112163544, dist_loss: 1.1982505321502686
recon_loss: 0.02947002649307251, dist_loss: 0.6612114906311035
recon_loss: 0.02947044000029564, dist_loss: 0.41740643978118896
recon_loss: 0.029469456523656845, dist_loss: 0.6036880016326904
recon_loss: 0.02946896106004715, dist_loss: 0.694290816783905
recon_loss: 0.029468916356563568, dist_loss: 0.6587166786193848
recon_loss: 0.029468433931469917, dist_loss: 0.625293493270874
recon_loss: 0.029467759653925896, dist_loss: 0.8518078923225403
recon_loss: 0.029467422515153885, dist_loss: 0.5079712867736816
recon_loss: 0.029467158019542694, dist_loss: 0.7300108075141907
recon_loss: 0.029466617852449417, dist_loss: 0.811123251914978
recon_loss: 0.029466060921549797, dist_loss: 0.5697179436683655
recon_loss: 0.02946583181619644, dist_loss: 0.5512732267379761
recon_loss: 0.02946561947464943, dist_loss: 0.8565854430198669
recon_loss: 0.0294653233140707, dist_loss: 0.4821500778198242
recon_loss: 0.029465332627296448, dist_loss: 1.081449270248413
recon_loss: 0.029464641585946083, dist_loss: 0.7443460822105408
recon_loss: 0.0294639989733696, dist_loss: 0.883159339427948
recon_loss: 0.029463766142725945, dist_loss: 0.8133206367492676
recon_loss: 0.029463913291692734, dist_loss: 0.9115538597106934
recon_loss: 0.029463479295372963, dist_loss: 0.9961749911308289
recon_loss: 0.029463931918144226, dist_loss: 0.7853344082832336
recon_loss: 0.02946465276181698, dist_loss: 0.8006402254104614
recon_loss: 0.029464419931173325, dist_loss: 0.606306791305542
recon_loss: 0.02946392260491848, dist_loss: 0.6395310759544373
recon_loss: 0.029463810846209526, dist_loss: 1.0208649635314941
recon_loss: 0.029463335871696472, dist_loss: 0.6758421659469604
recon_loss: 0.029462546110153198, dist_loss: 0.79690021276474
recon_loss: 0.029462561011314392, dist_loss: 0.7064557075500488
recon_loss: 0.029462184756994247, dist_loss: 0.9291694164276123
recon_loss: 0.0294613316655159, dist_loss: 0.5082037448883057
recon_loss: 0.02946081943809986, dist_loss: 0.5315849184989929
recon_loss: 0.029460128396749496, dist_loss: 0.6125842928886414
recon_loss: 0.029459409415721893, dist_loss: 0.5984811186790466
recon_loss: 0.029458830133080482, dist_loss: 0.8788564205169678
recon_loss: 0.02945828251540661, dist_loss: 1.014049768447876
recon_loss: 0.02945813164114952, dist_loss: 0.9125467538833618
recon_loss: 0.029457801952958107, dist_loss: 0.8045690655708313
recon_loss: 0.029457397758960724, dist_loss: 0.640263020992279
recon_loss: 0.029457150027155876, dist_loss: 0.6124088764190674
recon_loss: 0.02945692278444767, dist_loss: 1.1232388019561768
recon_loss: 0.029456717893481255, dist_loss: 0.7413997650146484
recon_loss: 0.02945745550096035, dist_loss: 0.6081730127334595
recon_loss: 0.029457591474056244, dist_loss: 0.6096978187561035
recon_loss: 0.029457271099090576, dist_loss: 0.6834331750869751
recon_loss: 0.02945738099515438, dist_loss: 0.5273110866546631
recon_loss: 0.02945784293115139, dist_loss: 1.2572789192199707
recon_loss: 0.0294575784355402, dist_loss: 0.7315598130226135
recon_loss: 0.02945728600025177, dist_loss: 0.5656589269638062
recon_loss: 0.029457135125994682, dist_loss: 0.5388129949569702
recon_loss: 0.02945702336728573, dist_loss: 0.7174965739250183
recon_loss: 0.029457341879606247, dist_loss: 0.479749470949173
recon_loss: 0.02945743314921856, dist_loss: 0.8425710797309875
recon_loss: 0.02945723757147789, dist_loss: 0.7766329050064087
recon_loss: 0.029457328841090202, dist_loss: 0.5543177723884583
recon_loss: 0.029457056894898415, dist_loss: 0.5992121696472168
recon_loss: 0.029456688091158867, dist_loss: 0.7254308462142944
recon_loss: 0.029456857591867447, dist_loss: 0.8265007734298706
recon_loss: 0.02945682220160961, dist_loss: 0.43786776065826416
recon_loss: 0.029456570744514465, dist_loss: 0.9298787117004395
recon_loss: 0.029456807300448418, dist_loss: 0.9003546237945557
recon_loss: 0.029459010809659958, dist_loss: 0.9822536706924438
Pre-training Epoch 43:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 43:   5%|▌         | 19/367 [00:00<00:01, 186.17it/s]Pre-training Epoch 43:  11%|█         | 39/367 [00:00<00:01, 190.10it/s]Pre-training Epoch 43:  16%|█▌        | 59/367 [00:00<00:01, 176.51it/s]Pre-training Epoch 43:  21%|██        | 77/367 [00:00<00:01, 172.14it/s]Pre-training Epoch 43:  26%|██▌       | 95/367 [00:00<00:01, 169.90it/s]Pre-training Epoch 43:  31%|███       | 113/367 [00:00<00:01, 168.16it/s]recon_loss: 0.029460184276103973, dist_loss: 0.4163280129432678
recon_loss: 0.029459966346621513, dist_loss: 0.9352509379386902
recon_loss: 0.029461435973644257, dist_loss: 1.8737084865570068
recon_loss: 0.029462601989507675, dist_loss: 0.4410359859466553
recon_loss: 0.029462182894349098, dist_loss: 0.5518054962158203
recon_loss: 0.029462141916155815, dist_loss: 0.4305484890937805
recon_loss: 0.029462626203894615, dist_loss: 0.7532846331596375
recon_loss: 0.029462072998285294, dist_loss: 0.5064318180084229
recon_loss: 0.029460985213518143, dist_loss: 0.8167781829833984
recon_loss: 0.029460428282618523, dist_loss: 0.850651741027832
recon_loss: 0.029459292069077492, dist_loss: 0.6316003203392029
recon_loss: 0.029457831755280495, dist_loss: 0.4739127457141876
recon_loss: 0.02945677936077118, dist_loss: 0.5679515600204468
recon_loss: 0.029455630108714104, dist_loss: 0.5764682292938232
recon_loss: 0.029454143717885017, dist_loss: 0.9566857814788818
recon_loss: 0.029452955350279808, dist_loss: 0.9728916883468628
recon_loss: 0.029452603310346603, dist_loss: 0.9619311094284058
recon_loss: 0.02945207804441452, dist_loss: 0.6529683470726013
recon_loss: 0.029451996088027954, dist_loss: 0.5377953052520752
recon_loss: 0.0294526144862175, dist_loss: 0.6001902222633362
recon_loss: 0.029453307390213013, dist_loss: 0.5606058835983276
recon_loss: 0.029453719034790993, dist_loss: 0.5354436635971069
recon_loss: 0.02945457026362419, dist_loss: 1.1598734855651855
recon_loss: 0.029455838724970818, dist_loss: 0.6142065525054932
recon_loss: 0.02945605292916298, dist_loss: 0.46826955676078796
recon_loss: 0.02945653907954693, dist_loss: 0.449165940284729
recon_loss: 0.029457461088895798, dist_loss: 0.3763401210308075
recon_loss: 0.029456794261932373, dist_loss: 0.6135936975479126
recon_loss: 0.029455551877617836, dist_loss: 0.7412400841712952
recon_loss: 0.029455093666911125, dist_loss: 0.880577564239502
recon_loss: 0.029453905299305916, dist_loss: 0.38904672861099243
recon_loss: 0.029452433809638023, dist_loss: 0.6721643209457397
recon_loss: 0.029451534152030945, dist_loss: 1.081365704536438
recon_loss: 0.029450558125972748, dist_loss: 0.6623202562332153
recon_loss: 0.029449567198753357, dist_loss: 0.5267847776412964
recon_loss: 0.029448678717017174, dist_loss: 0.3777243494987488
recon_loss: 0.029447924345731735, dist_loss: 0.7807961702346802
recon_loss: 0.029447324573993683, dist_loss: 0.6495386362075806
recon_loss: 0.029446633532643318, dist_loss: 0.8132529258728027
recon_loss: 0.029446125030517578, dist_loss: 0.8309060335159302
recon_loss: 0.02944607473909855, dist_loss: 0.4578702449798584
recon_loss: 0.029445964843034744, dist_loss: 0.8302059173583984
recon_loss: 0.029446063563227654, dist_loss: 0.5543638467788696
recon_loss: 0.029446501284837723, dist_loss: 0.6543529033660889
recon_loss: 0.029447007924318314, dist_loss: 0.7917743921279907
recon_loss: 0.02944708801805973, dist_loss: 0.6529386043548584
recon_loss: 0.029446614906191826, dist_loss: 0.6585830450057983
recon_loss: 0.02944629266858101, dist_loss: 0.5527305603027344
recon_loss: 0.029446395114064217, dist_loss: 0.7505186796188354
recon_loss: 0.029446568340063095, dist_loss: 0.8693374395370483
recon_loss: 0.02944633923470974, dist_loss: 0.786746621131897
recon_loss: 0.029445722699165344, dist_loss: 0.5161319971084595
recon_loss: 0.029444722458720207, dist_loss: 0.6999775171279907
recon_loss: 0.029444141313433647, dist_loss: 0.5861526727676392
recon_loss: 0.02944435365498066, dist_loss: 0.6502013206481934
recon_loss: 0.02944476157426834, dist_loss: 0.5559983253479004
recon_loss: 0.029445407912135124, dist_loss: 0.23409152030944824
recon_loss: 0.029445474967360497, dist_loss: 0.5564301013946533
recon_loss: 0.029444877058267593, dist_loss: 0.6024326086044312
recon_loss: 0.029444023966789246, dist_loss: 0.7405552268028259
recon_loss: 0.029443316161632538, dist_loss: 0.8329080939292908
recon_loss: 0.029443107545375824, dist_loss: 0.641880989074707
recon_loss: 0.0294431671500206, dist_loss: 0.5704127550125122
recon_loss: 0.02944331243634224, dist_loss: 0.8994893431663513
recon_loss: 0.029443539679050446, dist_loss: 0.9154480695724487
recon_loss: 0.029443947598338127, dist_loss: 0.2706066966056824
recon_loss: 0.029444057494401932, dist_loss: 0.6811108589172363
recon_loss: 0.029443876817822456, dist_loss: 0.7669904828071594
recon_loss: 0.02944376692175865, dist_loss: 0.5803894996643066
recon_loss: 0.02944355458021164, dist_loss: 0.5859673023223877
recon_loss: 0.0294431671500206, dist_loss: 0.9880857467651367
recon_loss: 0.02944258600473404, dist_loss: 0.7563627362251282
recon_loss: 0.029442083090543747, dist_loss: 0.8774579167366028
recon_loss: 0.029441701248288155, dist_loss: 0.668255090713501
recon_loss: 0.029441241174936295, dist_loss: 0.615387499332428
recon_loss: 0.029440736398100853, dist_loss: 0.4105076193809509
recon_loss: 0.029440756887197495, dist_loss: 0.9589152336120605
recon_loss: 0.029441216960549355, dist_loss: 0.3454868197441101
recon_loss: 0.029441818594932556, dist_loss: 0.3932039737701416
recon_loss: 0.02944234572350979, dist_loss: 0.816185712814331
recon_loss: 0.029442042112350464, dist_loss: 1.4369664192199707
recon_loss: 0.029441040009260178, dist_loss: 0.7216627597808838
recon_loss: 0.029440557584166527, dist_loss: 0.7026063799858093
recon_loss: 0.029439810663461685, dist_loss: 0.6006585359573364
recon_loss: 0.0294400192797184, dist_loss: 0.6532450914382935
recon_loss: 0.029440825805068016, dist_loss: 0.6021585464477539
recon_loss: 0.029440633952617645, dist_loss: 0.5501137375831604
recon_loss: 0.02944016642868519, dist_loss: 0.5882300138473511
recon_loss: 0.029440516605973244, dist_loss: 0.7062152624130249
recon_loss: 0.029440881684422493, dist_loss: 1.0565605163574219
recon_loss: 0.029440682381391525, dist_loss: 0.7345399260520935
recon_loss: 0.029439888894557953, dist_loss: 1.0388092994689941
recon_loss: 0.029440749436616898, dist_loss: 0.6208603978157043
recon_loss: 0.029441572725772858, dist_loss: 0.585037350654602
recon_loss: 0.029440945014357567, dist_loss: 0.6342645883560181
recon_loss: 0.029440825805068016, dist_loss: 0.8829362392425537
recon_loss: 0.029441053047776222, dist_loss: 0.3935610055923462
recon_loss: 0.02944036014378071, dist_loss: 0.5092542171478271
recon_loss: 0.02944006584584713, dist_loss: 0.5398329496383667
recon_loss: 0.029440101236104965, dist_loss: 0.34352150559425354
recon_loss: 0.029439134523272514, dist_loss: 0.7861684560775757
recon_loss: 0.029439490288496017, dist_loss: 1.2809514999389648
recon_loss: 0.029439497739076614, dist_loss: 0.8864651918411255
recon_loss: 0.029439907521009445, dist_loss: 0.3809526562690735
recon_loss: 0.029439613223075867, dist_loss: 0.9635933637619019
recon_loss: 0.029439833015203476, dist_loss: 0.5742935538291931
recon_loss: 0.029440710321068764, dist_loss: 0.7145227193832397
recon_loss: 0.029441094025969505, dist_loss: 0.8532371520996094
recon_loss: 0.029441747814416885, dist_loss: 0.4766179919242859
recon_loss: 0.02944239042699337, dist_loss: 0.4484478533267975
recon_loss: 0.029441477730870247, dist_loss: 0.7024358510971069
recon_loss: 0.029440002515912056, dist_loss: 1.2500369548797607
recon_loss: 0.029438478872179985, dist_loss: 0.5657093524932861
recon_loss: 0.029437091201543808, dist_loss: 0.6653276681900024
recon_loss: 0.029435407370328903, dist_loss: 0.6516814827919006
recon_loss: 0.029434582218527794, dist_loss: 0.7406076192855835
recon_loss: 0.029434558004140854, dist_loss: 0.55634605884552
recon_loss: 0.029434286057949066, dist_loss: 0.8300248384475708
recon_loss: 0.029434049502015114, dist_loss: 0.6832925081253052
recon_loss: 0.029434537515044212, dist_loss: 0.47905969619750977
recon_loss: 0.02943475916981697, dist_loss: 0.8050022721290588
recon_loss: 0.029434261843562126, dist_loss: 0.5515297651290894
recon_loss: 0.029434625059366226, dist_loss: 0.5440382957458496
recon_loss: 0.02943536825478077, dist_loss: 0.5219874978065491
recon_loss: 0.02943512611091137, dist_loss: 0.9070901870727539
recon_loss: 0.02943585254251957, dist_loss: 0.3258756995201111
recon_loss: 0.029437096789479256, dist_loss: 0.779495894908905
recon_loss: 0.02943732775747776, dist_loss: 0.4154077172279358
Pre-training Epoch 43:  35%|███▌      | 130/367 [00:00<00:01, 167.33it/s]Pre-training Epoch 43:  40%|████      | 147/367 [00:00<00:01, 166.44it/s]Pre-training Epoch 43:  45%|████▍     | 164/367 [00:00<00:01, 155.07it/s]Pre-training Epoch 43:  49%|████▉     | 181/367 [00:01<00:01, 157.37it/s]Pre-training Epoch 43:  54%|█████▍    | 198/367 [00:01<00:01, 159.49it/s]Pre-training Epoch 43:  59%|█████▉    | 216/367 [00:01<00:00, 164.45it/s]Pre-training Epoch 43:  64%|██████▍   | 236/367 [00:01<00:00, 172.81it/s]Pre-training Epoch 43:  70%|██████▉   | 256/367 [00:01<00:00, 178.60it/s]recon_loss: 0.02943701110780239, dist_loss: 0.8878260850906372
recon_loss: 0.029436742886900902, dist_loss: 0.655978798866272
recon_loss: 0.02943636104464531, dist_loss: 0.9594221115112305
recon_loss: 0.029435470700263977, dist_loss: 0.9264352321624756
recon_loss: 0.029435260221362114, dist_loss: 0.8659212589263916
recon_loss: 0.02943524904549122, dist_loss: 0.7019206285476685
recon_loss: 0.029434235766530037, dist_loss: 0.6317803859710693
recon_loss: 0.02943328395485878, dist_loss: 0.7463998794555664
recon_loss: 0.029432501643896103, dist_loss: 0.33475568890571594
recon_loss: 0.029431266710162163, dist_loss: 0.4120185375213623
recon_loss: 0.02943020686507225, dist_loss: 0.5162091255187988
recon_loss: 0.029429621994495392, dist_loss: 0.336131751537323
recon_loss: 0.029429655522108078, dist_loss: 0.42333662509918213
recon_loss: 0.029429858550429344, dist_loss: 0.8721435070037842
recon_loss: 0.02942989394068718, dist_loss: 1.1893712282180786
recon_loss: 0.02942994236946106, dist_loss: 0.9441574811935425
recon_loss: 0.029430627822875977, dist_loss: 0.7070163488388062
recon_loss: 0.029430173337459564, dist_loss: 0.4266512393951416
recon_loss: 0.02943006530404091, dist_loss: 0.8907628655433655
recon_loss: 0.029431074857711792, dist_loss: 1.4747340679168701
recon_loss: 0.02943066693842411, dist_loss: 0.740639328956604
recon_loss: 0.029429998248815536, dist_loss: 0.39916160702705383
recon_loss: 0.029430123046040535, dist_loss: 1.0877068042755127
recon_loss: 0.029429255053400993, dist_loss: 0.7212325930595398
recon_loss: 0.029428301379084587, dist_loss: 0.617491602897644
recon_loss: 0.0294297207146883, dist_loss: 0.37566137313842773
recon_loss: 0.02942926250398159, dist_loss: 0.4771508276462555
recon_loss: 0.029427791014313698, dist_loss: 0.4763794541358948
recon_loss: 0.029428798705339432, dist_loss: 1.0899138450622559
recon_loss: 0.02942846342921257, dist_loss: 0.8816444277763367
recon_loss: 0.029426833614706993, dist_loss: 0.6400832533836365
recon_loss: 0.029427044093608856, dist_loss: 0.9797835946083069
recon_loss: 0.029426857829093933, dist_loss: 0.4433083236217499
recon_loss: 0.02942618913948536, dist_loss: 1.1040936708450317
recon_loss: 0.02942686527967453, dist_loss: 0.7216924428939819
recon_loss: 0.0294272992759943, dist_loss: 0.7532926797866821
recon_loss: 0.02942598983645439, dist_loss: 0.9567316174507141
recon_loss: 0.0294266939163208, dist_loss: 0.429385244846344
recon_loss: 0.02942635305225849, dist_loss: 0.8968449831008911
recon_loss: 0.029425859451293945, dist_loss: 0.8626316785812378
recon_loss: 0.029427727684378624, dist_loss: 0.8151386976242065
recon_loss: 0.029429057613015175, dist_loss: 0.4883788228034973
recon_loss: 0.029427891597151756, dist_loss: 0.47023338079452515
recon_loss: 0.029429292306303978, dist_loss: 0.7487785816192627
recon_loss: 0.029430661350488663, dist_loss: 0.5823982357978821
recon_loss: 0.029428904876112938, dist_loss: 0.37842926383018494
recon_loss: 0.029427312314510345, dist_loss: 0.8077881336212158
recon_loss: 0.029428094625473022, dist_loss: 0.5515081286430359
recon_loss: 0.029427943751215935, dist_loss: 0.6152439117431641
recon_loss: 0.02942679263651371, dist_loss: 0.7937595844268799
recon_loss: 0.029427384957671165, dist_loss: 0.5087832808494568
recon_loss: 0.029426926746964455, dist_loss: 1.0973931550979614
recon_loss: 0.029425660148262978, dist_loss: 0.7806717157363892
recon_loss: 0.029424998909235, dist_loss: 0.7361224889755249
recon_loss: 0.029424240812659264, dist_loss: 0.6151683330535889
recon_loss: 0.029423478990793228, dist_loss: 0.3757597804069519
recon_loss: 0.029422955587506294, dist_loss: 0.3534402847290039
recon_loss: 0.029422391206026077, dist_loss: 0.532521665096283
recon_loss: 0.029421649873256683, dist_loss: 0.34262651205062866
recon_loss: 0.0294207651168108, dist_loss: 0.4564845561981201
recon_loss: 0.02942024916410446, dist_loss: 0.5630478262901306
recon_loss: 0.029419992119073868, dist_loss: 0.6325414180755615
recon_loss: 0.029419414699077606, dist_loss: 0.8265093564987183
recon_loss: 0.029419058933854103, dist_loss: 0.9797044396400452
recon_loss: 0.02942013181746006, dist_loss: 0.7369349598884583
recon_loss: 0.029421202838420868, dist_loss: 0.4285396933555603
recon_loss: 0.02942103147506714, dist_loss: 0.6832310557365417
recon_loss: 0.029422102496027946, dist_loss: 0.6791340112686157
recon_loss: 0.029422353953123093, dist_loss: 0.7327491044998169
recon_loss: 0.029421232640743256, dist_loss: 0.494781494140625
recon_loss: 0.029420461505651474, dist_loss: 0.3712853789329529
recon_loss: 0.029420532286167145, dist_loss: 0.85934978723526
recon_loss: 0.02942034974694252, dist_loss: 0.47491344809532166
recon_loss: 0.029419884085655212, dist_loss: 0.4343569576740265
recon_loss: 0.029419591650366783, dist_loss: 0.48532235622406006
recon_loss: 0.02941916324198246, dist_loss: 0.3523736894130707
recon_loss: 0.029418380931019783, dist_loss: 0.5389938354492188
recon_loss: 0.029417797923088074, dist_loss: 0.6707302331924438
recon_loss: 0.02941807731986046, dist_loss: 0.493427038192749
recon_loss: 0.029417719691991806, dist_loss: 0.8428646326065063
recon_loss: 0.029417891055345535, dist_loss: 0.28270694613456726
recon_loss: 0.029418785125017166, dist_loss: 0.5836451649665833
recon_loss: 0.029419558122754097, dist_loss: 0.4960785508155823
recon_loss: 0.0294189453125, dist_loss: 0.8926934599876404
recon_loss: 0.029418358579277992, dist_loss: 0.4570755958557129
recon_loss: 0.029418157413601875, dist_loss: 0.5847246646881104
recon_loss: 0.029417552053928375, dist_loss: 0.8142646551132202
recon_loss: 0.029416920617222786, dist_loss: 0.5994436144828796
recon_loss: 0.029416963458061218, dist_loss: 0.6415094137191772
recon_loss: 0.029417160898447037, dist_loss: 0.3678806722164154
recon_loss: 0.029417086392641068, dist_loss: 0.39373889565467834
recon_loss: 0.029416734352707863, dist_loss: 0.5743979215621948
recon_loss: 0.029416030272841454, dist_loss: 0.5015207529067993
recon_loss: 0.02941499650478363, dist_loss: 0.5619860887527466
recon_loss: 0.029414216056466103, dist_loss: 0.33364737033843994
recon_loss: 0.029413852840662003, dist_loss: 0.4220468997955322
recon_loss: 0.029413660988211632, dist_loss: 1.4762723445892334
recon_loss: 0.029413651674985886, dist_loss: 0.5637156367301941
recon_loss: 0.029414091259241104, dist_loss: 0.4000142812728882
recon_loss: 0.029414137825369835, dist_loss: 0.44501006603240967
recon_loss: 0.029414067044854164, dist_loss: 0.8859452605247498
recon_loss: 0.02941351756453514, dist_loss: 0.8574316501617432
recon_loss: 0.02941306307911873, dist_loss: 0.7429335117340088
recon_loss: 0.029413830488920212, dist_loss: 0.5998938083648682
recon_loss: 0.029415758326649666, dist_loss: 0.8028858304023743
recon_loss: 0.029417863115668297, dist_loss: 0.8447718620300293
recon_loss: 0.029419461265206337, dist_loss: 0.8713308572769165
recon_loss: 0.029419617727398872, dist_loss: 0.5666614770889282
recon_loss: 0.029417824000120163, dist_loss: 0.6249529123306274
recon_loss: 0.029416289180517197, dist_loss: 0.8430954813957214
recon_loss: 0.029415389522910118, dist_loss: 1.1443977355957031
recon_loss: 0.029415316879749298, dist_loss: 1.1221423149108887
recon_loss: 0.02941538579761982, dist_loss: 0.720104992389679
recon_loss: 0.02941633015871048, dist_loss: 0.5504186153411865
recon_loss: 0.02941644750535488, dist_loss: 0.6745516061782837
recon_loss: 0.029415031895041466, dist_loss: 0.8002268075942993
recon_loss: 0.029413573443889618, dist_loss: 0.7749976515769958
recon_loss: 0.029411714524030685, dist_loss: 0.7551710605621338
recon_loss: 0.0294102244079113, dist_loss: 0.3676072657108307
recon_loss: 0.02941006049513817, dist_loss: 0.5136010646820068
recon_loss: 0.029409924522042274, dist_loss: 0.6658010482788086
recon_loss: 0.029410280287265778, dist_loss: 0.5401158332824707
recon_loss: 0.029410479590296745, dist_loss: 0.8547234535217285
recon_loss: 0.029410094022750854, dist_loss: 0.7077541947364807
recon_loss: 0.02940995618700981, dist_loss: 0.7422317862510681
recon_loss: 0.029409626498818398, dist_loss: 0.6772786378860474
recon_loss: 0.029408862814307213, dist_loss: 0.9153778553009033
recon_loss: 0.02940819226205349, dist_loss: 0.4738292396068573
Pre-training Epoch 43:  75%|███████▌  | 276/367 [00:01<00:00, 182.88it/s]Pre-training Epoch 43:  81%|████████  | 296/367 [00:01<00:00, 185.93it/s]Pre-training Epoch 43:  86%|████████▌ | 316/367 [00:01<00:00, 188.19it/s]Pre-training Epoch 43:  91%|█████████▏| 335/367 [00:01<00:00, 184.61it/s]Pre-training Epoch 43:  96%|█████████▋| 354/367 [00:02<00:00, 175.33it/s]Pre-training Epoch 43: 100%|██████████| 367/367 [00:02<00:00, 172.31it/s]
recon_loss: 0.029408074915409088, dist_loss: 0.6538777351379395
recon_loss: 0.029407238587737083, dist_loss: 0.8945910334587097
recon_loss: 0.029408806934952736, dist_loss: 0.5362640023231506
recon_loss: 0.029409898445010185, dist_loss: 0.24223074316978455
recon_loss: 0.029408592730760574, dist_loss: 0.7426958084106445
recon_loss: 0.029409343376755714, dist_loss: 0.5652745962142944
recon_loss: 0.029409855604171753, dist_loss: 0.6172305345535278
recon_loss: 0.029409267008304596, dist_loss: 0.6098392009735107
recon_loss: 0.02940768003463745, dist_loss: 0.8373634815216064
recon_loss: 0.029406659305095673, dist_loss: 0.7547502517700195
recon_loss: 0.02940637245774269, dist_loss: 0.7174509167671204
recon_loss: 0.029406554996967316, dist_loss: 0.8266909122467041
recon_loss: 0.02940705418586731, dist_loss: 0.466339111328125
recon_loss: 0.029407618567347527, dist_loss: 0.627435028553009
recon_loss: 0.029405934736132622, dist_loss: 0.4833443760871887
recon_loss: 0.029404738917946815, dist_loss: 0.8112313151359558
recon_loss: 0.02940422110259533, dist_loss: 0.6559940576553345
recon_loss: 0.029403168708086014, dist_loss: 0.9229798913002014
recon_loss: 0.0294033270329237, dist_loss: 0.37634819746017456
recon_loss: 0.029404323548078537, dist_loss: 0.7172314524650574
recon_loss: 0.02940377965569496, dist_loss: 0.5867043137550354
recon_loss: 0.029403183609247208, dist_loss: 0.7500011324882507
recon_loss: 0.029404159635305405, dist_loss: 0.7803761959075928
recon_loss: 0.02940414659678936, dist_loss: 0.6174303889274597
recon_loss: 0.029402274638414383, dist_loss: 0.8327902555465698
recon_loss: 0.029402505606412888, dist_loss: 0.5139620304107666
recon_loss: 0.02940361015498638, dist_loss: 0.42588216066360474
recon_loss: 0.029404325410723686, dist_loss: 0.8168800473213196
recon_loss: 0.029403232038021088, dist_loss: 0.8682762384414673
recon_loss: 0.0294038038700819, dist_loss: 0.8446722030639648
recon_loss: 0.029402952641248703, dist_loss: 0.4872026741504669
recon_loss: 0.029401009902358055, dist_loss: 0.34918880462646484
recon_loss: 0.029400965198874474, dist_loss: 0.9256802797317505
recon_loss: 0.0294011402875185, dist_loss: 0.737619936466217
recon_loss: 0.02940133400261402, dist_loss: 0.8053842186927795
recon_loss: 0.029402216896414757, dist_loss: 0.5433660745620728
recon_loss: 0.02940371073782444, dist_loss: 1.0060946941375732
recon_loss: 0.029403764754533768, dist_loss: 0.7154237031936646
recon_loss: 0.02940475568175316, dist_loss: 0.5787556171417236
recon_loss: 0.029405653476715088, dist_loss: 0.6992963552474976
recon_loss: 0.029405660927295685, dist_loss: 0.6368382573127747
recon_loss: 0.02940610982477665, dist_loss: 0.7780313491821289
recon_loss: 0.029408229514956474, dist_loss: 0.48683643341064453
recon_loss: 0.029410207644104958, dist_loss: 0.5646820664405823
recon_loss: 0.029410364106297493, dist_loss: 0.4105495810508728
recon_loss: 0.029412219300866127, dist_loss: 0.8253756761550903
recon_loss: 0.029413269832730293, dist_loss: 0.7243081331253052
recon_loss: 0.029411932453513145, dist_loss: 0.4510357975959778
recon_loss: 0.02941044606268406, dist_loss: 0.946098268032074
recon_loss: 0.029409969225525856, dist_loss: 0.6406159400939941
recon_loss: 0.029408445581793785, dist_loss: 1.2800496816635132
recon_loss: 0.02940540574491024, dist_loss: 0.8684078454971313
recon_loss: 0.029404297471046448, dist_loss: 0.4621051251888275
recon_loss: 0.029403453692793846, dist_loss: 1.2274583578109741
recon_loss: 0.02940073423087597, dist_loss: 0.5765328407287598
recon_loss: 0.029398908838629723, dist_loss: 0.43463173508644104
recon_loss: 0.029398655518889427, dist_loss: 0.721717357635498
recon_loss: 0.029397981241345406, dist_loss: 0.6391175985336304
recon_loss: 0.02939748205244541, dist_loss: 0.728816032409668
recon_loss: 0.029397418722510338, dist_loss: 0.578296959400177
recon_loss: 0.02939714305102825, dist_loss: 0.6159346103668213
recon_loss: 0.02939709834754467, dist_loss: 0.9209290146827698
recon_loss: 0.029397273436188698, dist_loss: 0.9051011800765991
recon_loss: 0.02939733862876892, dist_loss: 1.1891371011734009
recon_loss: 0.029397251084446907, dist_loss: 0.3575187921524048
recon_loss: 0.029396964237093925, dist_loss: 0.7274046540260315
recon_loss: 0.029396576806902885, dist_loss: 0.5906800031661987
recon_loss: 0.029395759105682373, dist_loss: 0.7064025402069092
recon_loss: 0.0293948445469141, dist_loss: 0.5227793455123901
recon_loss: 0.029393786564469337, dist_loss: 0.7961196899414062
recon_loss: 0.02939298190176487, dist_loss: 0.6708974838256836
recon_loss: 0.029392216354608536, dist_loss: 0.4223112463951111
recon_loss: 0.029391860589385033, dist_loss: 0.3968421220779419
recon_loss: 0.029391620308160782, dist_loss: 0.9182875156402588
recon_loss: 0.029391150921583176, dist_loss: 0.4319413900375366
recon_loss: 0.029390789568424225, dist_loss: 0.47599250078201294
recon_loss: 0.02939070388674736, dist_loss: 0.460637629032135
recon_loss: 0.029390685260295868, dist_loss: 0.6191253662109375
recon_loss: 0.029390579089522362, dist_loss: 0.8226786851882935
recon_loss: 0.029390398412942886, dist_loss: 0.47017982602119446
recon_loss: 0.02939028851687908, dist_loss: 0.6127592325210571
recon_loss: 0.029390040785074234, dist_loss: 0.5548804402351379
recon_loss: 0.02938961237668991, dist_loss: 1.2106094360351562
recon_loss: 0.02938922680914402, dist_loss: 0.6967542171478271
recon_loss: 0.029388831928372383, dist_loss: 0.5848754048347473
recon_loss: 0.029388144612312317, dist_loss: 0.5221689939498901
recon_loss: 0.029387686401605606, dist_loss: 0.3420187532901764
recon_loss: 0.02938743494451046, dist_loss: 0.8968409299850464
recon_loss: 0.029387127608060837, dist_loss: 0.8048648834228516
recon_loss: 0.029386859387159348, dist_loss: 0.6713163256645203
recon_loss: 0.029386650770902634, dist_loss: 0.6423739194869995
recon_loss: 0.029386429116129875, dist_loss: 0.7398695945739746
recon_loss: 0.029386259615421295, dist_loss: 0.806229829788208
recon_loss: 0.029385896399617195, dist_loss: 0.6339229941368103
recon_loss: 0.02938574180006981, dist_loss: 0.8628405332565308
recon_loss: 0.02938612923026085, dist_loss: 0.7603912949562073
recon_loss: 0.02938592992722988, dist_loss: 0.6785095930099487
recon_loss: 0.029385793954133987, dist_loss: 0.5388794541358948
recon_loss: 0.029386183246970177, dist_loss: 0.4919087588787079
recon_loss: 0.02938668429851532, dist_loss: 0.6858675479888916
recon_loss: 0.029386838898062706, dist_loss: 0.6485192179679871
recon_loss: 0.0293868575245142, dist_loss: 0.9810885190963745
recon_loss: 0.029386987909674644, dist_loss: 0.6911864280700684
recon_loss: 0.029386814683675766, dist_loss: 0.6439318656921387
recon_loss: 0.02938629314303398, dist_loss: 1.123627781867981
recon_loss: 0.029386667534708977, dist_loss: 0.4214271903038025
recon_loss: 0.029386678710579872, dist_loss: 0.5272308588027954
recon_loss: 0.029386211186647415, dist_loss: 0.9664427638053894
recon_loss: 0.029385745525360107, dist_loss: 0.6098610162734985
recon_loss: 0.029385194182395935, dist_loss: 0.6087472438812256
recon_loss: 0.029384655877947807, dist_loss: 1.3808622360229492
Pre-training Epoch 44:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 44:   5%|▍         | 17/367 [00:00<00:02, 166.90it/s]Pre-training Epoch 44:  10%|█         | 37/367 [00:00<00:01, 181.94it/s]Pre-training Epoch 44:  16%|█▌        | 57/367 [00:00<00:01, 186.68it/s]Pre-training Epoch 44:  21%|██        | 77/367 [00:00<00:01, 189.02it/s]Pre-training Epoch 44:  26%|██▋       | 97/367 [00:00<00:01, 190.32it/s]Pre-training Epoch 44:  32%|███▏      | 117/367 [00:00<00:01, 191.05it/s]recon_loss: 0.029384057968854904, dist_loss: 0.7079821825027466
recon_loss: 0.02938363514840603, dist_loss: 0.3681786358356476
recon_loss: 0.029383281245827675, dist_loss: 0.554082989692688
recon_loss: 0.029382705688476562, dist_loss: 1.451397180557251
recon_loss: 0.029382798820734024, dist_loss: 0.5880463123321533
recon_loss: 0.029382597655057907, dist_loss: 0.5967190861701965
recon_loss: 0.02938246913254261, dist_loss: 0.6720736026763916
recon_loss: 0.029382716864347458, dist_loss: 0.9690237045288086
recon_loss: 0.02938285656273365, dist_loss: 0.6711665391921997
recon_loss: 0.029382921755313873, dist_loss: 0.42277824878692627
recon_loss: 0.029383113607764244, dist_loss: 0.7706454396247864
recon_loss: 0.029383404180407524, dist_loss: 0.42852193117141724
recon_loss: 0.029384013265371323, dist_loss: 0.3400312066078186
recon_loss: 0.029384594410657883, dist_loss: 0.5916205644607544
recon_loss: 0.029386159032583237, dist_loss: 0.41445258259773254
recon_loss: 0.029387619346380234, dist_loss: 1.0341763496398926
recon_loss: 0.029388315975666046, dist_loss: 0.48072561621665955
recon_loss: 0.0293887909501791, dist_loss: 1.2783162593841553
recon_loss: 0.029387308284640312, dist_loss: 0.39505237340927124
recon_loss: 0.029386071488261223, dist_loss: 0.5250300168991089
recon_loss: 0.029386106878519058, dist_loss: 0.5395554304122925
recon_loss: 0.029385555535554886, dist_loss: 0.5110946893692017
recon_loss: 0.02938491851091385, dist_loss: 0.4305400848388672
recon_loss: 0.02938506007194519, dist_loss: 0.31473779678344727
recon_loss: 0.029384087771177292, dist_loss: 0.5545997023582458
recon_loss: 0.0293822530657053, dist_loss: 0.563974916934967
recon_loss: 0.02938218228518963, dist_loss: 0.7196240425109863
recon_loss: 0.029382409527897835, dist_loss: 0.6976919174194336
recon_loss: 0.029380926862359047, dist_loss: 0.4008912742137909
recon_loss: 0.02938171848654747, dist_loss: 0.6920183897018433
recon_loss: 0.02938210405409336, dist_loss: 0.7589756846427917
recon_loss: 0.029380591586232185, dist_loss: 0.6438697576522827
recon_loss: 0.029380597174167633, dist_loss: 0.5497410893440247
recon_loss: 0.029381074011325836, dist_loss: 0.33668968081474304
recon_loss: 0.029380328953266144, dist_loss: 0.876446008682251
recon_loss: 0.029379861429333687, dist_loss: 0.843336820602417
recon_loss: 0.029379671439528465, dist_loss: 0.8372916579246521
recon_loss: 0.029379472136497498, dist_loss: 0.3360510766506195
recon_loss: 0.02937908284366131, dist_loss: 0.544980525970459
recon_loss: 0.02937891334295273, dist_loss: 0.7887417078018188
recon_loss: 0.029378943145275116, dist_loss: 0.33869701623916626
recon_loss: 0.029378846287727356, dist_loss: 0.6674036979675293
recon_loss: 0.029378244653344154, dist_loss: 0.6577690839767456
recon_loss: 0.029378315433859825, dist_loss: 0.5911644101142883
recon_loss: 0.029378646984696388, dist_loss: 0.4534652829170227
recon_loss: 0.029377812519669533, dist_loss: 0.5413016676902771
recon_loss: 0.029377158731222153, dist_loss: 0.5078052282333374
recon_loss: 0.029377499595284462, dist_loss: 0.7670879364013672
recon_loss: 0.02937708981335163, dist_loss: 0.47155073285102844
recon_loss: 0.02937622182071209, dist_loss: 0.6357973217964172
recon_loss: 0.02937617339193821, dist_loss: 0.7542177438735962
recon_loss: 0.029376253485679626, dist_loss: 0.7302478551864624
recon_loss: 0.029375270009040833, dist_loss: 0.8287448883056641
recon_loss: 0.029374880716204643, dist_loss: 0.5088491439819336
recon_loss: 0.02937510795891285, dist_loss: 0.9407072067260742
recon_loss: 0.029374996200203896, dist_loss: 1.4691941738128662
recon_loss: 0.02937427908182144, dist_loss: 0.33656346797943115
recon_loss: 0.02937418594956398, dist_loss: 0.6765300631523132
recon_loss: 0.02937435172498226, dist_loss: 0.5534046292304993
recon_loss: 0.029373981058597565, dist_loss: 0.6704598069190979
recon_loss: 0.029373418539762497, dist_loss: 0.9895480871200562
recon_loss: 0.02937370538711548, dist_loss: 0.9225549697875977
recon_loss: 0.029374288395047188, dist_loss: 0.5462949275970459
recon_loss: 0.02937430329620838, dist_loss: 0.44191038608551025
recon_loss: 0.02937452681362629, dist_loss: 0.5948818922042847
recon_loss: 0.029374660924077034, dist_loss: 1.0401499271392822
recon_loss: 0.02937404066324234, dist_loss: 0.9899739623069763
recon_loss: 0.029373934492468834, dist_loss: 0.675605058670044
recon_loss: 0.029373740777373314, dist_loss: 0.4929088056087494
recon_loss: 0.029373399913311005, dist_loss: 0.5565305948257446
recon_loss: 0.029373355209827423, dist_loss: 0.7377763986587524
recon_loss: 0.029373420402407646, dist_loss: 0.5163653492927551
recon_loss: 0.029372885823249817, dist_loss: 0.49048835039138794
recon_loss: 0.029372818768024445, dist_loss: 0.959753155708313
recon_loss: 0.029372582212090492, dist_loss: 0.48441895842552185
recon_loss: 0.029372259974479675, dist_loss: 0.514755129814148
recon_loss: 0.029372503980994225, dist_loss: 0.5294845104217529
recon_loss: 0.029372679069638252, dist_loss: 0.4924418032169342
recon_loss: 0.02937266044318676, dist_loss: 0.5010406374931335
recon_loss: 0.029372980818152428, dist_loss: 0.4777850806713104
recon_loss: 0.02937331609427929, dist_loss: 0.7928339838981628
recon_loss: 0.029373763129115105, dist_loss: 0.5233744978904724
recon_loss: 0.02937394566833973, dist_loss: 0.5798428058624268
recon_loss: 0.029373783618211746, dist_loss: 0.8561173677444458
recon_loss: 0.02937324345111847, dist_loss: 0.8577963709831238
recon_loss: 0.029372582212090492, dist_loss: 0.3402855694293976
recon_loss: 0.02937205508351326, dist_loss: 0.664070725440979
recon_loss: 0.02937151864171028, dist_loss: 1.2392925024032593
recon_loss: 0.029370877891778946, dist_loss: 0.737923264503479
recon_loss: 0.029370613396167755, dist_loss: 0.555618941783905
recon_loss: 0.02937030792236328, dist_loss: 0.8042004108428955
recon_loss: 0.029370028525590897, dist_loss: 0.5732084512710571
recon_loss: 0.02936992421746254, dist_loss: 1.215409278869629
recon_loss: 0.029369866475462914, dist_loss: 0.5940464735031128
recon_loss: 0.029369676485657692, dist_loss: 1.2566192150115967
recon_loss: 0.029369380325078964, dist_loss: 0.5022355318069458
recon_loss: 0.029369091615080833, dist_loss: 0.4219277799129486
recon_loss: 0.029368774965405464, dist_loss: 0.7254505157470703
recon_loss: 0.029368488118052483, dist_loss: 0.5620220899581909
recon_loss: 0.02936825156211853, dist_loss: 0.5086530447006226
recon_loss: 0.0293680839240551, dist_loss: 0.7248606085777283
recon_loss: 0.029367942363023758, dist_loss: 0.9502255916595459
recon_loss: 0.02936801314353943, dist_loss: 0.9014080166816711
recon_loss: 0.029368678107857704, dist_loss: 0.9631465673446655
recon_loss: 0.029368175193667412, dist_loss: 0.6310866475105286
recon_loss: 0.029368475079536438, dist_loss: 0.5199617743492126
recon_loss: 0.029368245974183083, dist_loss: 0.9360564947128296
recon_loss: 0.029367435723543167, dist_loss: 0.5183494091033936
recon_loss: 0.029367497190833092, dist_loss: 0.6133561134338379
recon_loss: 0.029367594048380852, dist_loss: 0.3403865694999695
recon_loss: 0.029367126524448395, dist_loss: 0.3526034951210022
recon_loss: 0.029367227107286453, dist_loss: 1.069538950920105
recon_loss: 0.029367104172706604, dist_loss: 0.7330571413040161
recon_loss: 0.029366541653871536, dist_loss: 0.5079009532928467
recon_loss: 0.02936646342277527, dist_loss: 0.2943683862686157
recon_loss: 0.029366716742515564, dist_loss: 0.8491491675376892
recon_loss: 0.02936633862555027, dist_loss: 0.7988219261169434
recon_loss: 0.029365932568907738, dist_loss: 0.7217509150505066
recon_loss: 0.029366573318839073, dist_loss: 0.7948123216629028
recon_loss: 0.029366226866841316, dist_loss: 0.920202374458313
recon_loss: 0.029365412890911102, dist_loss: 0.9804076552391052
recon_loss: 0.02936633862555027, dist_loss: 0.8983141183853149
recon_loss: 0.029367618262767792, dist_loss: 0.386530339717865
recon_loss: 0.029368365183472633, dist_loss: 1.0499120950698853
recon_loss: 0.02936871163547039, dist_loss: 0.4587666690349579
recon_loss: 0.029368970543146133, dist_loss: 0.7731407880783081
recon_loss: 0.029367897659540176, dist_loss: 0.6352375745773315
recon_loss: 0.029367640614509583, dist_loss: 0.8441160321235657
Pre-training Epoch 44:  37%|███▋      | 137/367 [00:00<00:01, 191.60it/s]Pre-training Epoch 44:  43%|████▎     | 157/367 [00:00<00:01, 192.06it/s]Pre-training Epoch 44:  48%|████▊     | 177/367 [00:00<00:00, 191.52it/s]Pre-training Epoch 44:  54%|█████▎    | 197/367 [00:01<00:00, 191.75it/s]Pre-training Epoch 44:  59%|█████▉    | 217/367 [00:01<00:00, 192.06it/s]Pre-training Epoch 44:  65%|██████▍   | 237/367 [00:01<00:00, 192.00it/s]recon_loss: 0.029368042945861816, dist_loss: 0.4342479705810547
recon_loss: 0.029367825016379356, dist_loss: 0.5126110315322876
recon_loss: 0.029367830604314804, dist_loss: 0.5107853412628174
recon_loss: 0.02936793491244316, dist_loss: 1.0576329231262207
recon_loss: 0.02936732955276966, dist_loss: 0.537970244884491
recon_loss: 0.029366161674261093, dist_loss: 0.657313883304596
recon_loss: 0.02936440147459507, dist_loss: 0.8112671375274658
recon_loss: 0.029363324865698814, dist_loss: 1.2084263563156128
recon_loss: 0.029362890869379044, dist_loss: 0.8493762016296387
recon_loss: 0.029362622648477554, dist_loss: 0.6322128772735596
recon_loss: 0.02936234138906002, dist_loss: 0.4666331708431244
recon_loss: 0.029362492263317108, dist_loss: 0.6401145458221436
recon_loss: 0.029362408444285393, dist_loss: 0.4844592809677124
recon_loss: 0.029362380504608154, dist_loss: 0.6822988986968994
recon_loss: 0.029362531378865242, dist_loss: 0.8402764201164246
recon_loss: 0.02936265617609024, dist_loss: 0.8464376926422119
recon_loss: 0.029362952336668968, dist_loss: 0.5166901350021362
recon_loss: 0.02936406247317791, dist_loss: 0.7253005504608154
recon_loss: 0.029365742579102516, dist_loss: 0.5910332798957825
recon_loss: 0.02936866134405136, dist_loss: 0.7763104438781738
recon_loss: 0.029370078817009926, dist_loss: 1.0313562154769897
recon_loss: 0.029369542375206947, dist_loss: 0.8422224521636963
recon_loss: 0.02936864271759987, dist_loss: 0.8988865613937378
recon_loss: 0.029368089511990547, dist_loss: 0.5507829785346985
recon_loss: 0.029367927461862564, dist_loss: 0.6188148260116577
recon_loss: 0.029368020594120026, dist_loss: 0.33748701214790344
recon_loss: 0.029368050396442413, dist_loss: 0.5898380279541016
recon_loss: 0.029367635026574135, dist_loss: 0.7728694677352905
recon_loss: 0.029367005452513695, dist_loss: 0.9993857145309448
recon_loss: 0.029365941882133484, dist_loss: 0.5962883234024048
recon_loss: 0.02936406433582306, dist_loss: 0.6661030650138855
recon_loss: 0.029362747445702553, dist_loss: 0.6824088096618652
recon_loss: 0.029361918568611145, dist_loss: 0.9336811304092407
recon_loss: 0.029360683634877205, dist_loss: 0.5454286336898804
recon_loss: 0.029360001906752586, dist_loss: 1.0128289461135864
recon_loss: 0.029360191896557808, dist_loss: 0.6342812776565552
recon_loss: 0.02935997024178505, dist_loss: 0.646683394908905
recon_loss: 0.029360054060816765, dist_loss: 0.7944746017456055
recon_loss: 0.02936054952442646, dist_loss: 0.5406535267829895
recon_loss: 0.029359593987464905, dist_loss: 1.0839763879776
recon_loss: 0.02935933880507946, dist_loss: 0.5302438735961914
recon_loss: 0.02935957722365856, dist_loss: 0.8873616456985474
recon_loss: 0.029358813539147377, dist_loss: 0.7478147745132446
recon_loss: 0.029358774423599243, dist_loss: 0.5392933487892151
recon_loss: 0.029360026121139526, dist_loss: 0.6032072901725769
recon_loss: 0.029360199347138405, dist_loss: 0.713081955909729
recon_loss: 0.029360773041844368, dist_loss: 0.4448884129524231
recon_loss: 0.02936176210641861, dist_loss: 0.5497671961784363
recon_loss: 0.02936159446835518, dist_loss: 0.44280266761779785
recon_loss: 0.02936043031513691, dist_loss: 0.8597276210784912
recon_loss: 0.02936062589287758, dist_loss: 0.8361003994941711
recon_loss: 0.029360588639974594, dist_loss: 0.6185053586959839
recon_loss: 0.029360435903072357, dist_loss: 1.3331547975540161
recon_loss: 0.029361482709646225, dist_loss: 0.4087144732475281
recon_loss: 0.029361383989453316, dist_loss: 1.2487990856170654
recon_loss: 0.029360590502619743, dist_loss: 0.8164567947387695
recon_loss: 0.029360389336943626, dist_loss: 0.6103910207748413
recon_loss: 0.029359398409724236, dist_loss: 1.0041377544403076
recon_loss: 0.029357770457863808, dist_loss: 0.5391390323638916
recon_loss: 0.029357001185417175, dist_loss: 0.4889845550060272
recon_loss: 0.029355870559811592, dist_loss: 0.9913976192474365
recon_loss: 0.029355095699429512, dist_loss: 0.6643331050872803
recon_loss: 0.02935478650033474, dist_loss: 0.7040767669677734
recon_loss: 0.02935447357594967, dist_loss: 0.8137577772140503
recon_loss: 0.029354002326726913, dist_loss: 0.6046218872070312
recon_loss: 0.02935393713414669, dist_loss: 1.0640281438827515
recon_loss: 0.02935483492910862, dist_loss: 0.8141969442367554
recon_loss: 0.029355529695749283, dist_loss: 0.6269416809082031
recon_loss: 0.029354939237236977, dist_loss: 0.6716663837432861
recon_loss: 0.02935483306646347, dist_loss: 0.4991241693496704
recon_loss: 0.029354242607951164, dist_loss: 0.9416220188140869
recon_loss: 0.029353395104408264, dist_loss: 0.5157690644264221
recon_loss: 0.029353590682148933, dist_loss: 0.7880357503890991
recon_loss: 0.029353538528084755, dist_loss: 0.47418224811553955
recon_loss: 0.029352407902479172, dist_loss: 0.34183377027511597
recon_loss: 0.029351776465773582, dist_loss: 0.6678125858306885
recon_loss: 0.02935137413442135, dist_loss: 0.6463286876678467
recon_loss: 0.029350411146879196, dist_loss: 0.8469721674919128
recon_loss: 0.02934987097978592, dist_loss: 0.40748727321624756
recon_loss: 0.029349803924560547, dist_loss: 0.6838703751564026
recon_loss: 0.029349366202950478, dist_loss: 1.0301902294158936
recon_loss: 0.02934885211288929, dist_loss: 0.6183357238769531
recon_loss: 0.02934868261218071, dist_loss: 0.5131466388702393
recon_loss: 0.02934836782515049, dist_loss: 1.1383111476898193
recon_loss: 0.029348094016313553, dist_loss: 0.5705524682998657
recon_loss: 0.029347961768507957, dist_loss: 0.7013373970985413
recon_loss: 0.029347846284508705, dist_loss: 0.33058664202690125
recon_loss: 0.029347635805606842, dist_loss: 0.5587345361709595
recon_loss: 0.02934737130999565, dist_loss: 0.6191955208778381
recon_loss: 0.029347263276576996, dist_loss: 0.8395759463310242
recon_loss: 0.02934708259999752, dist_loss: 1.4159197807312012
recon_loss: 0.029347388073801994, dist_loss: 0.7420123219490051
recon_loss: 0.029347525909543037, dist_loss: 0.632478654384613
recon_loss: 0.029347214847803116, dist_loss: 1.403694748878479
recon_loss: 0.029346683993935585, dist_loss: 0.8349044322967529
recon_loss: 0.029346439987421036, dist_loss: 1.1726551055908203
recon_loss: 0.029346991330385208, dist_loss: 0.7046158313751221
recon_loss: 0.0293474942445755, dist_loss: 0.3497697710990906
recon_loss: 0.029347216710448265, dist_loss: 0.42056509852409363
recon_loss: 0.029347799718379974, dist_loss: 0.5650827884674072
recon_loss: 0.029347971081733704, dist_loss: 0.8892560601234436
recon_loss: 0.02934795804321766, dist_loss: 1.1172996759414673
recon_loss: 0.029347408562898636, dist_loss: 0.6981428861618042
recon_loss: 0.029347704723477364, dist_loss: 0.5239286422729492
recon_loss: 0.02934790961444378, dist_loss: 0.6373298168182373
recon_loss: 0.02934758923947811, dist_loss: 0.612973690032959
recon_loss: 0.029348431155085564, dist_loss: 0.7078852653503418
recon_loss: 0.0293493140488863, dist_loss: 0.8766945600509644
recon_loss: 0.029348406940698624, dist_loss: 0.40521931648254395
recon_loss: 0.02934868633747101, dist_loss: 0.4518447518348694
recon_loss: 0.02934856340289116, dist_loss: 0.9980882406234741
recon_loss: 0.029347671195864677, dist_loss: 0.7461334466934204
recon_loss: 0.02934710681438446, dist_loss: 0.7524842023849487
recon_loss: 0.02934657223522663, dist_loss: 0.9842472672462463
recon_loss: 0.029345441609621048, dist_loss: 0.4935755133628845
recon_loss: 0.02934492751955986, dist_loss: 0.4352690279483795
recon_loss: 0.02934434451162815, dist_loss: 0.9378844499588013
recon_loss: 0.029343731701374054, dist_loss: 0.5212373733520508
recon_loss: 0.029343636706471443, dist_loss: 0.9115118980407715
recon_loss: 0.0293433740735054, dist_loss: 0.7239578366279602
recon_loss: 0.029342498630285263, dist_loss: 0.4999866485595703
recon_loss: 0.02934213913977146, dist_loss: 0.6343469023704529
recon_loss: 0.02934226766228676, dist_loss: 0.8479220271110535
recon_loss: 0.029342886060476303, dist_loss: 0.9012621641159058
recon_loss: 0.02934269793331623, dist_loss: 0.742406964302063
recon_loss: 0.02934219315648079, dist_loss: 0.5225059390068054
recon_loss: 0.02934233658015728, dist_loss: 0.819846510887146
recon_loss: 0.02934272401034832, dist_loss: 0.8610827326774597
Pre-training Epoch 44:  70%|███████   | 257/367 [00:01<00:00, 192.04it/s]Pre-training Epoch 44:  75%|███████▌  | 277/367 [00:01<00:00, 191.34it/s]Pre-training Epoch 44:  81%|████████  | 297/367 [00:01<00:00, 191.10it/s]Pre-training Epoch 44:  86%|████████▋ | 317/367 [00:01<00:00, 191.35it/s]Pre-training Epoch 44:  92%|█████████▏| 337/367 [00:01<00:00, 191.42it/s]Pre-training Epoch 44:  97%|█████████▋| 357/367 [00:01<00:00, 188.60it/s]Pre-training Epoch 44: 100%|██████████| 367/367 [00:01<00:00, 190.03it/s]
recon_loss: 0.02934175357222557, dist_loss: 0.5445961952209473
recon_loss: 0.02934105508029461, dist_loss: 0.8583306074142456
recon_loss: 0.029340991750359535, dist_loss: 0.844139575958252
recon_loss: 0.029340505599975586, dist_loss: 0.6070604920387268
recon_loss: 0.029339848086237907, dist_loss: 0.42288637161254883
recon_loss: 0.02933986485004425, dist_loss: 0.8617854714393616
recon_loss: 0.02934051863849163, dist_loss: 0.5006393790245056
recon_loss: 0.02934088371694088, dist_loss: 0.6124118566513062
recon_loss: 0.02934153378009796, dist_loss: 0.4844099283218384
recon_loss: 0.02934160642325878, dist_loss: 0.4465838372707367
recon_loss: 0.02934093028306961, dist_loss: 0.5842463970184326
recon_loss: 0.02933966927230358, dist_loss: 0.7471535205841064
recon_loss: 0.02933950163424015, dist_loss: 0.5882835388183594
recon_loss: 0.029339242726564407, dist_loss: 1.281410574913025
recon_loss: 0.029339386150240898, dist_loss: 0.631043553352356
recon_loss: 0.029339348897337914, dist_loss: 0.5547893643379211
recon_loss: 0.029339084401726723, dist_loss: 0.4609503149986267
recon_loss: 0.02933855913579464, dist_loss: 0.5689505934715271
recon_loss: 0.029337836429476738, dist_loss: 0.6660611629486084
recon_loss: 0.029336899518966675, dist_loss: 0.9328194260597229
recon_loss: 0.02933635003864765, dist_loss: 0.45412537455558777
recon_loss: 0.02933560498058796, dist_loss: 0.9687032103538513
recon_loss: 0.029335089027881622, dist_loss: 0.9456605911254883
recon_loss: 0.029334984719753265, dist_loss: 0.341435045003891
recon_loss: 0.029335282742977142, dist_loss: 0.5237683057785034
recon_loss: 0.029335875064134598, dist_loss: 0.570576548576355
recon_loss: 0.02933659590780735, dist_loss: 0.5873775482177734
recon_loss: 0.029336778447031975, dist_loss: 0.5178574323654175
recon_loss: 0.029336530715227127, dist_loss: 0.4568563401699066
recon_loss: 0.029336776584386826, dist_loss: 0.732555091381073
recon_loss: 0.029336275532841682, dist_loss: 0.7123007774353027
recon_loss: 0.02933543361723423, dist_loss: 0.5428483486175537
recon_loss: 0.029335394501686096, dist_loss: 0.5910012722015381
recon_loss: 0.029335984960198402, dist_loss: 0.8936407566070557
recon_loss: 0.02933577448129654, dist_loss: 0.5508937239646912
recon_loss: 0.029334980994462967, dist_loss: 0.7545764446258545
recon_loss: 0.02933668904006481, dist_loss: 0.725646436214447
recon_loss: 0.02933661825954914, dist_loss: 0.5980380177497864
recon_loss: 0.029335271567106247, dist_loss: 0.5970088839530945
recon_loss: 0.029334697872400284, dist_loss: 0.6672918200492859
recon_loss: 0.02933400124311447, dist_loss: 0.7738779187202454
recon_loss: 0.029333453625440598, dist_loss: 0.5848478674888611
recon_loss: 0.029332347214221954, dist_loss: 1.1081440448760986
recon_loss: 0.029333537444472313, dist_loss: 0.34168851375579834
recon_loss: 0.029333779588341713, dist_loss: 0.6459226012229919
recon_loss: 0.029333002865314484, dist_loss: 0.38409775495529175
recon_loss: 0.02933346852660179, dist_loss: 0.6503500938415527
recon_loss: 0.02933419682085514, dist_loss: 0.6834997534751892
recon_loss: 0.029333265498280525, dist_loss: 0.45157837867736816
recon_loss: 0.029332170262932777, dist_loss: 0.49143972992897034
recon_loss: 0.02933168224990368, dist_loss: 0.543782114982605
recon_loss: 0.029332110658288002, dist_loss: 0.6753094792366028
recon_loss: 0.029332192614674568, dist_loss: 0.7016032934188843
recon_loss: 0.029333537444472313, dist_loss: 0.706619381904602
recon_loss: 0.029334278777241707, dist_loss: 0.6667699217796326
recon_loss: 0.029332999140024185, dist_loss: 0.6285655498504639
recon_loss: 0.029331684112548828, dist_loss: 0.3803730607032776
recon_loss: 0.029330551624298096, dist_loss: 0.5566053986549377
recon_loss: 0.029329270124435425, dist_loss: 0.9682296514511108
recon_loss: 0.029328754171729088, dist_loss: 0.3609596788883209
recon_loss: 0.02932862751185894, dist_loss: 0.5539624691009521
recon_loss: 0.0293279942125082, dist_loss: 0.8751051425933838
recon_loss: 0.02932717651128769, dist_loss: 0.39316949248313904
recon_loss: 0.029326284304261208, dist_loss: 0.9348993301391602
recon_loss: 0.02932540327310562, dist_loss: 0.5445126891136169
recon_loss: 0.02932494692504406, dist_loss: 0.4235927164554596
recon_loss: 0.029324987903237343, dist_loss: 0.4894527792930603
recon_loss: 0.029325274750590324, dist_loss: 0.7463871240615845
recon_loss: 0.029325639829039574, dist_loss: 0.5669805407524109
recon_loss: 0.02932577393949032, dist_loss: 0.35849910974502563
recon_loss: 0.029325272887945175, dist_loss: 0.6244895458221436
recon_loss: 0.029324868693947792, dist_loss: 0.5611778497695923
recon_loss: 0.029324976727366447, dist_loss: 1.0370450019836426
recon_loss: 0.029326068237423897, dist_loss: 0.6969715356826782
recon_loss: 0.02932530641555786, dist_loss: 0.9413810968399048
recon_loss: 0.02932531200349331, dist_loss: 0.3800203800201416
recon_loss: 0.029326092451810837, dist_loss: 0.5716058611869812
recon_loss: 0.029325099661946297, dist_loss: 0.6127033233642578
recon_loss: 0.0293243657797575, dist_loss: 0.9587129950523376
recon_loss: 0.0293241236358881, dist_loss: 0.41482773423194885
recon_loss: 0.029323246330022812, dist_loss: 0.9868251085281372
recon_loss: 0.029323309659957886, dist_loss: 0.495708703994751
recon_loss: 0.029323354363441467, dist_loss: 0.4085661768913269
recon_loss: 0.02932267263531685, dist_loss: 0.8510040640830994
recon_loss: 0.029322829097509384, dist_loss: 0.7414044737815857
recon_loss: 0.02932368963956833, dist_loss: 0.7242417931556702
recon_loss: 0.02932492457330227, dist_loss: 0.7263449430465698
recon_loss: 0.029325757175683975, dist_loss: 0.45260512828826904
recon_loss: 0.02932719886302948, dist_loss: 1.122840404510498
recon_loss: 0.029328929260373116, dist_loss: 0.5771166086196899
recon_loss: 0.029329126700758934, dist_loss: 0.3944624364376068
recon_loss: 0.029329195618629456, dist_loss: 0.4349866211414337
recon_loss: 0.029329711571335793, dist_loss: 0.5369876027107239
recon_loss: 0.029329849407076836, dist_loss: 0.47642946243286133
recon_loss: 0.029329586774110794, dist_loss: 0.8185968399047852
recon_loss: 0.02932877093553543, dist_loss: 0.7527669072151184
recon_loss: 0.029327621683478355, dist_loss: 0.5800967812538147
recon_loss: 0.029326092451810837, dist_loss: 0.46824824810028076
recon_loss: 0.029324490576982498, dist_loss: 0.2801082134246826
recon_loss: 0.029322965070605278, dist_loss: 0.6155111193656921
recon_loss: 0.029321735724806786, dist_loss: 0.9096893072128296
recon_loss: 0.029320737347006798, dist_loss: 0.5236478447914124
recon_loss: 0.029319975525140762, dist_loss: 1.217745304107666
recon_loss: 0.029319975525140762, dist_loss: 0.430774986743927
recon_loss: 0.0293203666806221, dist_loss: 0.4503101110458374
recon_loss: 0.02932099811732769, dist_loss: 0.6484092473983765
recon_loss: 0.029321499168872833, dist_loss: 0.4478778839111328
recon_loss: 0.029321733862161636, dist_loss: 0.562217116355896
recon_loss: 0.02932262234389782, dist_loss: 0.6746881604194641
recon_loss: 0.02932404726743698, dist_loss: 0.6777361631393433
recon_loss: 0.02932494319975376, dist_loss: 1.2463665008544922
Pre-training Epoch 45:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 45:   5%|▌         | 20/367 [00:00<00:01, 191.08it/s]Pre-training Epoch 45:  11%|█         | 40/367 [00:00<00:01, 192.89it/s]Pre-training Epoch 45:  16%|█▋        | 60/367 [00:00<00:01, 193.77it/s]Pre-training Epoch 45:  22%|██▏       | 80/367 [00:00<00:01, 194.11it/s]Pre-training Epoch 45:  27%|██▋       | 100/367 [00:00<00:01, 194.15it/s]Pre-training Epoch 45:  33%|███▎      | 120/367 [00:00<00:01, 194.35it/s]recon_loss: 0.02932499721646309, dist_loss: 0.5180591344833374
recon_loss: 0.029325881972908974, dist_loss: 0.6534470319747925
recon_loss: 0.029326312243938446, dist_loss: 0.6938797235488892
recon_loss: 0.02932572551071644, dist_loss: 0.6430919170379639
recon_loss: 0.02932574972510338, dist_loss: 0.7944578528404236
recon_loss: 0.029325366020202637, dist_loss: 0.7694335579872131
recon_loss: 0.029325196519494057, dist_loss: 0.6089462637901306
recon_loss: 0.029325250536203384, dist_loss: 0.6195629835128784
recon_loss: 0.029324714094400406, dist_loss: 0.8245043754577637
recon_loss: 0.029322385787963867, dist_loss: 1.1073838472366333
recon_loss: 0.029321258887648582, dist_loss: 0.5221295952796936
recon_loss: 0.029322436079382896, dist_loss: 0.9815535545349121
recon_loss: 0.02932066284120083, dist_loss: 0.9621368646621704
recon_loss: 0.029318546876311302, dist_loss: 0.4243709146976471
recon_loss: 0.02931956574320793, dist_loss: 0.8437968492507935
recon_loss: 0.029318735003471375, dist_loss: 0.4484127461910248
recon_loss: 0.029316840693354607, dist_loss: 0.5138912200927734
recon_loss: 0.029316609725356102, dist_loss: 0.7212339043617249
recon_loss: 0.029316015541553497, dist_loss: 0.5254537463188171
recon_loss: 0.029315907508134842, dist_loss: 0.7351895570755005
recon_loss: 0.02931700088083744, dist_loss: 0.43083080649375916
recon_loss: 0.029317021369934082, dist_loss: 1.1858757734298706
recon_loss: 0.029317380860447884, dist_loss: 0.42939919233322144
recon_loss: 0.029318679124116898, dist_loss: 0.9625811576843262
recon_loss: 0.029318958520889282, dist_loss: 0.4629879593849182
recon_loss: 0.02931947261095047, dist_loss: 0.883656919002533
recon_loss: 0.029319865629076958, dist_loss: 0.5844852924346924
recon_loss: 0.029319781810045242, dist_loss: 0.6741489171981812
recon_loss: 0.02931920997798443, dist_loss: 0.855586051940918
recon_loss: 0.02931888774037361, dist_loss: 0.7876248955726624
recon_loss: 0.029318327084183693, dist_loss: 0.992343008518219
recon_loss: 0.02931765653192997, dist_loss: 0.4886265993118286
recon_loss: 0.029317360371351242, dist_loss: 1.1406890153884888
recon_loss: 0.029316332191228867, dist_loss: 0.5256928205490112
recon_loss: 0.029315708205103874, dist_loss: 0.7224164009094238
recon_loss: 0.029315248131752014, dist_loss: 1.3790086507797241
recon_loss: 0.029315121471881866, dist_loss: 0.40707165002822876
recon_loss: 0.02931484393775463, dist_loss: 0.7386161088943481
recon_loss: 0.029314372688531876, dist_loss: 0.6900069117546082
recon_loss: 0.029313262552022934, dist_loss: 0.771114706993103
recon_loss: 0.029312504455447197, dist_loss: 0.7139403820037842
recon_loss: 0.02931196615099907, dist_loss: 0.4840744733810425
recon_loss: 0.029311619699001312, dist_loss: 0.43098562955856323
recon_loss: 0.029311586171388626, dist_loss: 0.6952351331710815
recon_loss: 0.02931123413145542, dist_loss: 0.6714404821395874
recon_loss: 0.0293105598539114, dist_loss: 1.127619981765747
recon_loss: 0.02931045927107334, dist_loss: 1.5042272806167603
recon_loss: 0.02931066043674946, dist_loss: 0.48275500535964966
recon_loss: 0.029310589656233788, dist_loss: 0.7686589956283569
recon_loss: 0.029310110956430435, dist_loss: 0.4252071976661682
recon_loss: 0.029310019686818123, dist_loss: 0.7895306348800659
recon_loss: 0.029310422018170357, dist_loss: 0.3739356994628906
recon_loss: 0.029309947043657303, dist_loss: 0.6084951162338257
recon_loss: 0.0293098334223032, dist_loss: 0.7698909044265747
recon_loss: 0.0293095912784338, dist_loss: 0.5687491297721863
recon_loss: 0.029309473931789398, dist_loss: 0.5685999393463135
recon_loss: 0.029309235513210297, dist_loss: 0.7899861931800842
recon_loss: 0.02930917963385582, dist_loss: 0.5401895642280579
recon_loss: 0.029309047386050224, dist_loss: 0.5443383455276489
recon_loss: 0.029308419674634933, dist_loss: 0.8425662517547607
recon_loss: 0.0293080136179924, dist_loss: 0.7935149669647217
recon_loss: 0.029307570308446884, dist_loss: 0.8846663236618042
recon_loss: 0.02930697239935398, dist_loss: 0.47812357544898987
recon_loss: 0.029306691139936447, dist_loss: 0.6601248979568481
recon_loss: 0.02930653840303421, dist_loss: 0.9383382797241211
recon_loss: 0.029305705800652504, dist_loss: 0.7144597172737122
recon_loss: 0.02930542640388012, dist_loss: 0.485628217458725
recon_loss: 0.029305554926395416, dist_loss: 0.48117756843566895
recon_loss: 0.02930549532175064, dist_loss: 0.3354015350341797
recon_loss: 0.029305193573236465, dist_loss: 0.9485511183738708
recon_loss: 0.0293049868196249, dist_loss: 0.5829762816429138
recon_loss: 0.02930455282330513, dist_loss: 0.5671179294586182
recon_loss: 0.0293040219694376, dist_loss: 0.8674858808517456
recon_loss: 0.029303930699825287, dist_loss: 0.5167348384857178
recon_loss: 0.029304105788469315, dist_loss: 0.45780491828918457
recon_loss: 0.029304061084985733, dist_loss: 0.49254149198532104
recon_loss: 0.029303619638085365, dist_loss: 0.9611738324165344
recon_loss: 0.029303085058927536, dist_loss: 0.34988492727279663
recon_loss: 0.02930261939764023, dist_loss: 0.6693918108940125
recon_loss: 0.029302388429641724, dist_loss: 0.5262032747268677
recon_loss: 0.02930217608809471, dist_loss: 0.5890371799468994
recon_loss: 0.029301941394805908, dist_loss: 0.5612335205078125
recon_loss: 0.029301641508936882, dist_loss: 0.3551379442214966
recon_loss: 0.02930118888616562, dist_loss: 0.5560879111289978
recon_loss: 0.02930072322487831, dist_loss: 0.7161773443222046
recon_loss: 0.029300842434167862, dist_loss: 0.6250076293945312
recon_loss: 0.0293007493019104, dist_loss: 0.4629502296447754
recon_loss: 0.029300682246685028, dist_loss: 0.49361658096313477
recon_loss: 0.02930128015577793, dist_loss: 0.5551446080207825
recon_loss: 0.029300516471266747, dist_loss: 0.8419135808944702
recon_loss: 0.029299883171916008, dist_loss: 0.36720117926597595
recon_loss: 0.029299713671207428, dist_loss: 0.8802013397216797
recon_loss: 0.029299421235919, dist_loss: 0.3853892683982849
recon_loss: 0.029299037531018257, dist_loss: 0.7361581921577454
recon_loss: 0.029298990964889526, dist_loss: 1.2603321075439453
recon_loss: 0.02929895929992199, dist_loss: 0.7136905193328857
recon_loss: 0.02929864637553692, dist_loss: 1.2329270839691162
recon_loss: 0.02929815463721752, dist_loss: 0.7837464213371277
recon_loss: 0.02929801121354103, dist_loss: 0.8190604448318481
recon_loss: 0.02929798699915409, dist_loss: 0.8890748023986816
recon_loss: 0.02929837256669998, dist_loss: 0.43278542160987854
recon_loss: 0.029298750683665276, dist_loss: 0.40012025833129883
recon_loss: 0.02929903008043766, dist_loss: 0.5552020072937012
recon_loss: 0.02929948829114437, dist_loss: 0.3841480016708374
recon_loss: 0.029299795627593994, dist_loss: 0.2297120839357376
recon_loss: 0.029299726709723473, dist_loss: 0.40804582834243774
recon_loss: 0.029299743473529816, dist_loss: 0.8435606360435486
recon_loss: 0.02930021472275257, dist_loss: 0.5011869072914124
recon_loss: 0.029300248250365257, dist_loss: 0.8964460492134094
recon_loss: 0.029300067573785782, dist_loss: 0.7034048438072205
recon_loss: 0.029299382120370865, dist_loss: 0.4069380760192871
recon_loss: 0.029298698529601097, dist_loss: 0.46698683500289917
recon_loss: 0.029298145323991776, dist_loss: 0.40573883056640625
recon_loss: 0.02929762937128544, dist_loss: 0.45883116126060486
recon_loss: 0.029297087341547012, dist_loss: 0.49789297580718994
recon_loss: 0.02929648943245411, dist_loss: 1.2033050060272217
recon_loss: 0.029295897111296654, dist_loss: 0.6986033320426941
recon_loss: 0.02929569035768509, dist_loss: 0.6417529582977295
recon_loss: 0.029295379295945168, dist_loss: 0.5614246129989624
recon_loss: 0.02929556742310524, dist_loss: 0.5453272461891174
recon_loss: 0.02929581142961979, dist_loss: 0.570682942867279
recon_loss: 0.029295941814780235, dist_loss: 0.47044503688812256
recon_loss: 0.029296161606907845, dist_loss: 0.8834563493728638
recon_loss: 0.029296603053808212, dist_loss: 0.7837282419204712
recon_loss: 0.02929694764316082, dist_loss: 0.48034924268722534
recon_loss: 0.029297541826963425, dist_loss: 0.4911971092224121
recon_loss: 0.029297614470124245, dist_loss: 0.9675307273864746
recon_loss: 0.029297534376382828, dist_loss: 0.7230166792869568
Pre-training Epoch 45:  38%|███▊      | 140/367 [00:00<00:01, 189.32it/s]Pre-training Epoch 45:  43%|████▎     | 159/367 [00:00<00:01, 182.02it/s]Pre-training Epoch 45:  49%|████▊     | 178/367 [00:00<00:01, 176.00it/s]Pre-training Epoch 45:  53%|█████▎    | 196/367 [00:01<00:01, 169.04it/s]Pre-training Epoch 45:  58%|█████▊    | 213/367 [00:01<00:00, 165.24it/s]Pre-training Epoch 45:  63%|██████▎   | 230/367 [00:01<00:00, 162.32it/s]Pre-training Epoch 45:  67%|██████▋   | 247/367 [00:01<00:00, 161.19it/s]recon_loss: 0.02929701656103134, dist_loss: 0.5160714983940125
recon_loss: 0.029296880587935448, dist_loss: 0.9470435976982117
recon_loss: 0.02929675206542015, dist_loss: 0.8084504008293152
recon_loss: 0.029296191409230232, dist_loss: 0.5196350812911987
recon_loss: 0.029295720160007477, dist_loss: 0.4598979353904724
recon_loss: 0.02929549850523472, dist_loss: 0.7629269361495972
recon_loss: 0.029295364394783974, dist_loss: 0.463730126619339
recon_loss: 0.02929508499801159, dist_loss: 0.8426121473312378
recon_loss: 0.029294580221176147, dist_loss: 0.47444987297058105
recon_loss: 0.02929416112601757, dist_loss: 0.7653650045394897
recon_loss: 0.029293499886989594, dist_loss: 0.5890498161315918
recon_loss: 0.02929307334125042, dist_loss: 0.8818816542625427
recon_loss: 0.02929304912686348, dist_loss: 0.834675669670105
recon_loss: 0.02929317206144333, dist_loss: 0.7803784608840942
recon_loss: 0.02929283119738102, dist_loss: 0.8080968856811523
recon_loss: 0.029292726889252663, dist_loss: 0.35356366634368896
recon_loss: 0.029292361810803413, dist_loss: 0.4564553499221802
recon_loss: 0.029292091727256775, dist_loss: 0.5490334630012512
recon_loss: 0.029292283579707146, dist_loss: 0.7180894613265991
recon_loss: 0.029292365536093712, dist_loss: 0.5338563323020935
recon_loss: 0.029292302206158638, dist_loss: 1.1015567779541016
recon_loss: 0.029292568564414978, dist_loss: 0.6192518472671509
recon_loss: 0.029292182996869087, dist_loss: 0.8852407336235046
recon_loss: 0.029291508719325066, dist_loss: 0.7857639193534851
recon_loss: 0.029291994869709015, dist_loss: 0.6649916172027588
recon_loss: 0.02929157204926014, dist_loss: 0.2913517951965332
recon_loss: 0.02929110825061798, dist_loss: 0.4929506182670593
recon_loss: 0.029291637241840363, dist_loss: 0.7015707492828369
recon_loss: 0.029291383922100067, dist_loss: 0.5079225301742554
recon_loss: 0.029291067272424698, dist_loss: 0.4479042887687683
recon_loss: 0.02929132990539074, dist_loss: 0.702832043170929
recon_loss: 0.029291285201907158, dist_loss: 1.1564737558364868
recon_loss: 0.029291123151779175, dist_loss: 0.42197051644325256
recon_loss: 0.02929186075925827, dist_loss: 0.4164726436138153
recon_loss: 0.0292917862534523, dist_loss: 0.7060446739196777
recon_loss: 0.02929135225713253, dist_loss: 0.5728292465209961
recon_loss: 0.02929135598242283, dist_loss: 0.6406606435775757
recon_loss: 0.029291464015841484, dist_loss: 0.6909546852111816
recon_loss: 0.02929154597222805, dist_loss: 0.812159538269043
recon_loss: 0.029291868209838867, dist_loss: 0.860447108745575
recon_loss: 0.02929188869893551, dist_loss: 0.5868462920188904
recon_loss: 0.029292061924934387, dist_loss: 0.6506853103637695
recon_loss: 0.02929213084280491, dist_loss: 0.582029402256012
recon_loss: 0.029292026534676552, dist_loss: 0.45465779304504395
recon_loss: 0.02929176576435566, dist_loss: 1.0583155155181885
recon_loss: 0.029291605576872826, dist_loss: 0.6760782599449158
recon_loss: 0.029290925711393356, dist_loss: 0.8088246583938599
recon_loss: 0.029290515929460526, dist_loss: 0.8634988069534302
recon_loss: 0.029290180653333664, dist_loss: 1.0971968173980713
recon_loss: 0.02928999811410904, dist_loss: 0.5459814071655273
recon_loss: 0.029289601370692253, dist_loss: 0.3278288245201111
recon_loss: 0.029288912191987038, dist_loss: 0.6471431255340576
recon_loss: 0.029288485646247864, dist_loss: 0.5596540570259094
recon_loss: 0.02928829938173294, dist_loss: 0.47549450397491455
recon_loss: 0.02928793989121914, dist_loss: 0.4923871159553528
recon_loss: 0.029287738725543022, dist_loss: 0.41806280612945557
recon_loss: 0.029287714511156082, dist_loss: 0.5982490181922913
recon_loss: 0.02928798645734787, dist_loss: 0.2971283793449402
recon_loss: 0.029288576915860176, dist_loss: 0.529238760471344
recon_loss: 0.0292890053242445, dist_loss: 1.0177578926086426
recon_loss: 0.029289379715919495, dist_loss: 0.629770040512085
recon_loss: 0.029289167374372482, dist_loss: 0.9653315544128418
recon_loss: 0.029289672151207924, dist_loss: 0.6897953152656555
recon_loss: 0.029291115701198578, dist_loss: 0.6055518984794617
recon_loss: 0.029291613027453423, dist_loss: 0.6666854619979858
recon_loss: 0.029292481020092964, dist_loss: 0.3894006609916687
recon_loss: 0.02929331734776497, dist_loss: 1.0134408473968506
recon_loss: 0.0292932391166687, dist_loss: 0.530762791633606
recon_loss: 0.029293203726410866, dist_loss: 0.7952417135238647
recon_loss: 0.02929297462105751, dist_loss: 0.4185551404953003
recon_loss: 0.02929265983402729, dist_loss: 0.5521050691604614
recon_loss: 0.029291998594999313, dist_loss: 1.1666889190673828
recon_loss: 0.029291443526744843, dist_loss: 0.438190221786499
recon_loss: 0.029289916157722473, dist_loss: 0.6837602853775024
recon_loss: 0.02928812801837921, dist_loss: 0.6534659266471863
recon_loss: 0.02928774617612362, dist_loss: 0.6091818809509277
recon_loss: 0.02928685024380684, dist_loss: 0.5420252084732056
recon_loss: 0.029285673052072525, dist_loss: 0.5094520449638367
recon_loss: 0.029285525903105736, dist_loss: 0.594779372215271
recon_loss: 0.029285583645105362, dist_loss: 0.8548334240913391
recon_loss: 0.029284823685884476, dist_loss: 0.894273579120636
recon_loss: 0.029285211116075516, dist_loss: 0.5473073720932007
recon_loss: 0.029286492615938187, dist_loss: 0.9405145645141602
recon_loss: 0.029287351295351982, dist_loss: 0.5503522753715515
recon_loss: 0.029287662357091904, dist_loss: 1.0224575996398926
recon_loss: 0.02928753010928631, dist_loss: 0.3682326078414917
recon_loss: 0.02928789146244526, dist_loss: 0.6056340932846069
recon_loss: 0.02928761951625347, dist_loss: 0.44435709714889526
recon_loss: 0.029287178069353104, dist_loss: 0.7556013464927673
recon_loss: 0.02928699553012848, dist_loss: 0.8776318430900574
recon_loss: 0.029286973178386688, dist_loss: 0.3881320357322693
recon_loss: 0.0292863380163908, dist_loss: 0.43819063901901245
recon_loss: 0.02928582951426506, dist_loss: 0.6827829480171204
recon_loss: 0.029284879565238953, dist_loss: 0.6259298324584961
recon_loss: 0.029283631592988968, dist_loss: 0.6137034893035889
recon_loss: 0.0292827021330595, dist_loss: 0.5143876671791077
recon_loss: 0.029281891882419586, dist_loss: 0.6406634449958801
recon_loss: 0.02928115427494049, dist_loss: 1.02659273147583
recon_loss: 0.029280811548233032, dist_loss: 0.6649532318115234
recon_loss: 0.029280396178364754, dist_loss: 0.5580227971076965
recon_loss: 0.029280349612236023, dist_loss: 0.7240965366363525
recon_loss: 0.029280349612236023, dist_loss: 0.4639776349067688
recon_loss: 0.029280491173267365, dist_loss: 0.7838073968887329
recon_loss: 0.029280833899974823, dist_loss: 1.072710394859314
recon_loss: 0.029281260445713997, dist_loss: 0.45604172348976135
recon_loss: 0.029281210154294968, dist_loss: 0.641649603843689
recon_loss: 0.029280776157975197, dist_loss: 0.5014187097549438
recon_loss: 0.02928023785352707, dist_loss: 0.5258364677429199
recon_loss: 0.029279090464115143, dist_loss: 0.9474017024040222
recon_loss: 0.029277807101607323, dist_loss: 0.379207581281662
recon_loss: 0.02927730418741703, dist_loss: 1.2713408470153809
recon_loss: 0.029277587309479713, dist_loss: 0.7994113564491272
recon_loss: 0.029278328642249107, dist_loss: 0.9267233610153198
recon_loss: 0.029279042035341263, dist_loss: 0.42770764231681824
recon_loss: 0.029280269518494606, dist_loss: 0.8480170965194702
recon_loss: 0.029279962182044983, dist_loss: 0.4704996645450592
recon_loss: 0.029279008507728577, dist_loss: 0.807151734828949
recon_loss: 0.02927853725850582, dist_loss: 1.1344493627548218
recon_loss: 0.02927791140973568, dist_loss: 0.719265341758728
recon_loss: 0.02927851304411888, dist_loss: 0.8193879723548889
recon_loss: 0.029279479756951332, dist_loss: 0.603737473487854
recon_loss: 0.029279856011271477, dist_loss: 0.36647552251815796
recon_loss: 0.029280468821525574, dist_loss: 0.8459599018096924
recon_loss: 0.029280684888362885, dist_loss: 0.8466542959213257
recon_loss: 0.029279658570885658, dist_loss: 0.791701078414917
recon_loss: 0.02927875518798828, dist_loss: 0.6171338558197021
recon_loss: 0.029277943074703217, dist_loss: 0.8524545431137085
recon_loss: 0.029276840388774872, dist_loss: 0.8754464983940125
Pre-training Epoch 45:  72%|███████▏  | 264/367 [00:01<00:00, 160.32it/s]Pre-training Epoch 45:  77%|███████▋  | 281/367 [00:01<00:00, 159.18it/s]Pre-training Epoch 45:  81%|████████  | 297/367 [00:01<00:00, 155.33it/s]Pre-training Epoch 45:  85%|████████▌ | 313/367 [00:01<00:00, 154.32it/s]Pre-training Epoch 45:  90%|████████▉ | 330/367 [00:01<00:00, 157.47it/s]Pre-training Epoch 45:  95%|█████████▍| 347/367 [00:02<00:00, 159.73it/s]Pre-training Epoch 45: 100%|█████████▉| 366/367 [00:02<00:00, 167.96it/s]Pre-training Epoch 45: 100%|██████████| 367/367 [00:02<00:00, 171.10it/s]
recon_loss: 0.029276007786393166, dist_loss: 1.037000298500061
recon_loss: 0.029275914654135704, dist_loss: 0.5411183834075928
recon_loss: 0.029276130720973015, dist_loss: 0.7928491234779358
recon_loss: 0.029276825487613678, dist_loss: 1.0430406332015991
recon_loss: 0.029278581961989403, dist_loss: 0.43881967663764954
recon_loss: 0.029279842972755432, dist_loss: 0.7301622629165649
recon_loss: 0.029281314462423325, dist_loss: 1.108327865600586
recon_loss: 0.02928154170513153, dist_loss: 0.8582718372344971
recon_loss: 0.029280852526426315, dist_loss: 0.6307876110076904
recon_loss: 0.02928067557513714, dist_loss: 1.0337119102478027
recon_loss: 0.029280364513397217, dist_loss: 0.4155188202857971
recon_loss: 0.029280133545398712, dist_loss: 0.7611857652664185
recon_loss: 0.029280750080943108, dist_loss: 0.6310064792633057
recon_loss: 0.029279937967658043, dist_loss: 0.45187991857528687
recon_loss: 0.029278412461280823, dist_loss: 0.9381227493286133
recon_loss: 0.029277514666318893, dist_loss: 0.5878254175186157
recon_loss: 0.02927599661052227, dist_loss: 0.5330417156219482
recon_loss: 0.029274338856339455, dist_loss: 0.5310977101325989
recon_loss: 0.029273977503180504, dist_loss: 0.7545723915100098
recon_loss: 0.029274284839630127, dist_loss: 0.5416364669799805
recon_loss: 0.029273847118020058, dist_loss: 0.7724517583847046
recon_loss: 0.02927422896027565, dist_loss: 0.7451890707015991
recon_loss: 0.029275687411427498, dist_loss: 0.6882376670837402
recon_loss: 0.029275432229042053, dist_loss: 1.0407527685165405
recon_loss: 0.02927550859749317, dist_loss: 0.3687509000301361
recon_loss: 0.029276423156261444, dist_loss: 0.895559549331665
recon_loss: 0.029275953769683838, dist_loss: 0.45322319865226746
recon_loss: 0.02927529625594616, dist_loss: 0.29704171419143677
recon_loss: 0.029275184497237206, dist_loss: 0.5126663446426392
recon_loss: 0.029274899512529373, dist_loss: 0.6183264255523682
recon_loss: 0.029274147003889084, dist_loss: 0.5924205780029297
recon_loss: 0.029273172840476036, dist_loss: 0.6714768409729004
recon_loss: 0.02927285246551037, dist_loss: 0.834190845489502
recon_loss: 0.029272204264998436, dist_loss: 0.5407330989837646
recon_loss: 0.029270732775330544, dist_loss: 0.5040361285209656
recon_loss: 0.029270345345139503, dist_loss: 0.7040717005729675
recon_loss: 0.02927025593817234, dist_loss: 0.916810154914856
recon_loss: 0.02926953136920929, dist_loss: 0.8397061824798584
recon_loss: 0.029268914833664894, dist_loss: 0.3499929904937744
recon_loss: 0.02926873043179512, dist_loss: 0.3851057291030884
recon_loss: 0.02926870808005333, dist_loss: 0.8946353197097778
recon_loss: 0.029268590733408928, dist_loss: 1.272766351699829
recon_loss: 0.029268044978380203, dist_loss: 0.5973942279815674
recon_loss: 0.029267676174640656, dist_loss: 0.43274495005607605
recon_loss: 0.029267707839608192, dist_loss: 1.0185930728912354
recon_loss: 0.0292679276317358, dist_loss: 0.6406283378601074
recon_loss: 0.02926846221089363, dist_loss: 0.8046472072601318
recon_loss: 0.02926919050514698, dist_loss: 0.44800978899002075
recon_loss: 0.02926885336637497, dist_loss: 0.9352515935897827
recon_loss: 0.029268275946378708, dist_loss: 1.0717191696166992
recon_loss: 0.02926810458302498, dist_loss: 0.6734915971755981
recon_loss: 0.029267122969031334, dist_loss: 0.8581589460372925
recon_loss: 0.029266733676195145, dist_loss: 0.8096140623092651
recon_loss: 0.029266733676195145, dist_loss: 0.7193112373352051
recon_loss: 0.029266219586133957, dist_loss: 0.9260138273239136
recon_loss: 0.029265157878398895, dist_loss: 0.608352780342102
recon_loss: 0.029264742508530617, dist_loss: 0.8129066228866577
recon_loss: 0.029264412820339203, dist_loss: 0.4079017639160156
recon_loss: 0.029263775795698166, dist_loss: 0.9078033566474915
recon_loss: 0.029263682663440704, dist_loss: 0.2897121012210846
recon_loss: 0.029263751581311226, dist_loss: 0.5302110314369202
recon_loss: 0.029263626784086227, dist_loss: 0.46001380681991577
recon_loss: 0.029263552278280258, dist_loss: 0.8035438060760498
recon_loss: 0.029263608157634735, dist_loss: 0.6134592294692993
recon_loss: 0.029263194650411606, dist_loss: 0.6809816360473633
recon_loss: 0.029262680560350418, dist_loss: 0.5710574388504028
recon_loss: 0.029262175783514977, dist_loss: 0.4314480423927307
recon_loss: 0.02926166169345379, dist_loss: 0.762701153755188
recon_loss: 0.029261646792292595, dist_loss: 0.4960251450538635
recon_loss: 0.02926192432641983, dist_loss: 0.6488592624664307
recon_loss: 0.02926202490925789, dist_loss: 0.6438514590263367
recon_loss: 0.029261834919452667, dist_loss: 0.7153369188308716
recon_loss: 0.029261598363518715, dist_loss: 0.6903107762336731
recon_loss: 0.02926161140203476, dist_loss: 0.5126551389694214
recon_loss: 0.029261097311973572, dist_loss: 0.9126909971237183
recon_loss: 0.029260708019137383, dist_loss: 1.164630651473999
recon_loss: 0.029260577633976936, dist_loss: 0.5660439729690552
recon_loss: 0.029260823503136635, dist_loss: 0.5448470115661621
recon_loss: 0.029261169955134392, dist_loss: 0.589099645614624
recon_loss: 0.02926122583448887, dist_loss: 0.5642685890197754
recon_loss: 0.029261257499456406, dist_loss: 0.5351971387863159
recon_loss: 0.0292609091848135, dist_loss: 0.6051639914512634
recon_loss: 0.029260436072945595, dist_loss: 0.6960416436195374
recon_loss: 0.029259948059916496, dist_loss: 0.43654075264930725
recon_loss: 0.02926003560423851, dist_loss: 0.8911441564559937
recon_loss: 0.029260313138365746, dist_loss: 0.5433087348937988
recon_loss: 0.029260337352752686, dist_loss: 0.5944749116897583
recon_loss: 0.029260143637657166, dist_loss: 0.5499542951583862
recon_loss: 0.029260313138365746, dist_loss: 0.5604381561279297
recon_loss: 0.029260465875267982, dist_loss: 1.1356145143508911
recon_loss: 0.029261356219649315, dist_loss: 1.3828266859054565
recon_loss: 0.029262196272611618, dist_loss: 0.46060216426849365
recon_loss: 0.02926197461783886, dist_loss: 0.7621782422065735
recon_loss: 0.02926277555525303, dist_loss: 0.6358873844146729
recon_loss: 0.029263626784086227, dist_loss: 0.6166776418685913
recon_loss: 0.029263131320476532, dist_loss: 0.6988853216171265
recon_loss: 0.029262734577059746, dist_loss: 0.812917172908783
recon_loss: 0.029263241216540337, dist_loss: 0.38982468843460083
recon_loss: 0.029262255877256393, dist_loss: 0.7610682249069214
recon_loss: 0.02926197461783886, dist_loss: 0.6728760004043579
recon_loss: 0.02926216460764408, dist_loss: 0.9922682046890259
recon_loss: 0.029261691495776176, dist_loss: 0.564502477645874
recon_loss: 0.029260562732815742, dist_loss: 0.8294724822044373
recon_loss: 0.029260022565722466, dist_loss: 0.6298236846923828
recon_loss: 0.029259508475661278, dist_loss: 0.8457036018371582
recon_loss: 0.02925890125334263, dist_loss: 0.5900477170944214
recon_loss: 0.02925906889140606, dist_loss: 0.6489535570144653
recon_loss: 0.02925930544734001, dist_loss: 0.5574277639389038
recon_loss: 0.029259013012051582, dist_loss: 0.586396336555481
recon_loss: 0.029259514063596725, dist_loss: 0.34079933166503906
recon_loss: 0.02926056832075119, dist_loss: 0.2829454243183136
Pre-training Epoch 46:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 46:   5%|▍         | 17/367 [00:00<00:02, 167.28it/s]Pre-training Epoch 46:   9%|▉         | 34/367 [00:00<00:02, 166.01it/s]Pre-training Epoch 46:  14%|█▍        | 51/367 [00:00<00:01, 165.49it/s]Pre-training Epoch 46:  19%|█▊        | 68/367 [00:00<00:01, 165.32it/s]Pre-training Epoch 46:  23%|██▎       | 85/367 [00:00<00:01, 165.79it/s]Pre-training Epoch 46:  28%|██▊       | 102/367 [00:00<00:01, 165.81it/s]Pre-training Epoch 46:  32%|███▏      | 119/367 [00:00<00:01, 164.91it/s]recon_loss: 0.02926165796816349, dist_loss: 0.8510357141494751
recon_loss: 0.02926156111061573, dist_loss: 0.9739345908164978
recon_loss: 0.029261654242873192, dist_loss: 0.5111457109451294
recon_loss: 0.02926211804151535, dist_loss: 0.5851724743843079
recon_loss: 0.029262743890285492, dist_loss: 0.7939385175704956
recon_loss: 0.029262468218803406, dist_loss: 1.1150404214859009
recon_loss: 0.029262760654091835, dist_loss: 0.9844386577606201
recon_loss: 0.02926328405737877, dist_loss: 0.8347557187080383
recon_loss: 0.029263600707054138, dist_loss: 0.54815673828125
recon_loss: 0.029264302924275398, dist_loss: 0.3230798840522766
recon_loss: 0.029263820499181747, dist_loss: 0.6742781400680542
recon_loss: 0.0292628426104784, dist_loss: 0.556861162185669
recon_loss: 0.029261784628033638, dist_loss: 1.153925895690918
recon_loss: 0.029260901734232903, dist_loss: 0.8795816898345947
recon_loss: 0.029259512200951576, dist_loss: 0.4893815517425537
recon_loss: 0.02925877459347248, dist_loss: 0.7490663528442383
recon_loss: 0.02925744280219078, dist_loss: 0.3966984152793884
recon_loss: 0.029256660491228104, dist_loss: 1.3491477966308594
recon_loss: 0.02925594337284565, dist_loss: 0.5648177266120911
recon_loss: 0.02925509586930275, dist_loss: 1.0635972023010254
recon_loss: 0.02925448678433895, dist_loss: 0.8446934223175049
recon_loss: 0.029254276305437088, dist_loss: 0.9020988345146179
recon_loss: 0.02925410494208336, dist_loss: 0.8685804605484009
recon_loss: 0.02925395406782627, dist_loss: 0.40342020988464355
recon_loss: 0.02925395779311657, dist_loss: 0.9581995606422424
recon_loss: 0.0292538832873106, dist_loss: 0.789944052696228
recon_loss: 0.029254507273435593, dist_loss: 0.30009201169013977
recon_loss: 0.02925458922982216, dist_loss: 0.7709954380989075
recon_loss: 0.029254084452986717, dist_loss: 0.5727143883705139
recon_loss: 0.029254306107759476, dist_loss: 0.31705981492996216
recon_loss: 0.029254214838147163, dist_loss: 0.7999429702758789
recon_loss: 0.029254108667373657, dist_loss: 0.36228418350219727
recon_loss: 0.029254727065563202, dist_loss: 0.8366009593009949
recon_loss: 0.029255464673042297, dist_loss: 0.6235204935073853
recon_loss: 0.029255054891109467, dist_loss: 0.8072435855865479
recon_loss: 0.029255453497171402, dist_loss: 0.8843334913253784
recon_loss: 0.029256293550133705, dist_loss: 0.969363272190094
recon_loss: 0.029256276786327362, dist_loss: 0.5373602509498596
recon_loss: 0.029256541281938553, dist_loss: 0.5187132358551025
recon_loss: 0.029257647693157196, dist_loss: 0.6605389714241028
recon_loss: 0.029258044436573982, dist_loss: 0.7566119432449341
recon_loss: 0.029256971552968025, dist_loss: 0.7736371159553528
recon_loss: 0.029255714267492294, dist_loss: 0.6577396392822266
recon_loss: 0.029255922883749008, dist_loss: 0.7675405144691467
recon_loss: 0.029255341738462448, dist_loss: 0.4804385006427765
recon_loss: 0.02925393357872963, dist_loss: 0.951996922492981
recon_loss: 0.029253337532281876, dist_loss: 0.7003810405731201
recon_loss: 0.029251491650938988, dist_loss: 0.4531705379486084
recon_loss: 0.029250245541334152, dist_loss: 0.7365998029708862
recon_loss: 0.029250305145978928, dist_loss: 0.9166854619979858
recon_loss: 0.029250048100948334, dist_loss: 0.5690579414367676
recon_loss: 0.029249362647533417, dist_loss: 0.6578642129898071
recon_loss: 0.02925008535385132, dist_loss: 0.7682763934135437
recon_loss: 0.029250726103782654, dist_loss: 0.6559292078018188
recon_loss: 0.02925034612417221, dist_loss: 0.9253106713294983
recon_loss: 0.029250921681523323, dist_loss: 1.102009654045105
recon_loss: 0.029252387583255768, dist_loss: 0.6643253564834595
recon_loss: 0.02925272099673748, dist_loss: 0.523216724395752
recon_loss: 0.029253222048282623, dist_loss: 0.8166911005973816
recon_loss: 0.02925386279821396, dist_loss: 0.5898457765579224
recon_loss: 0.029252752661705017, dist_loss: 0.8825340270996094
recon_loss: 0.0292515829205513, dist_loss: 0.8706701993942261
recon_loss: 0.029251081869006157, dist_loss: 0.6537599563598633
recon_loss: 0.02925041876733303, dist_loss: 0.3043069839477539
recon_loss: 0.029249846935272217, dist_loss: 0.5551521182060242
recon_loss: 0.029249127954244614, dist_loss: 0.43108850717544556
recon_loss: 0.029247796162962914, dist_loss: 0.657876193523407
recon_loss: 0.029246533289551735, dist_loss: 0.6580130457878113
recon_loss: 0.029245657846331596, dist_loss: 0.7244983315467834
recon_loss: 0.029244951903820038, dist_loss: 0.5694291591644287
recon_loss: 0.029245246201753616, dist_loss: 0.6997028589248657
recon_loss: 0.02924562431871891, dist_loss: 1.0074069499969482
recon_loss: 0.029245078563690186, dist_loss: 0.4356822967529297
recon_loss: 0.029244381934404373, dist_loss: 0.486686110496521
recon_loss: 0.029244907200336456, dist_loss: 0.6896089315414429
recon_loss: 0.029244106262922287, dist_loss: 1.0582093000411987
recon_loss: 0.02924422360956669, dist_loss: 0.5640710592269897
recon_loss: 0.029245084151625633, dist_loss: 0.7226604223251343
recon_loss: 0.02924405224621296, dist_loss: 0.96941077709198
recon_loss: 0.029244177043437958, dist_loss: 0.5610628128051758
recon_loss: 0.029244448989629745, dist_loss: 0.7005109786987305
recon_loss: 0.02924398146569729, dist_loss: 0.48837462067604065
recon_loss: 0.02924405410885811, dist_loss: 0.6530056595802307
recon_loss: 0.029244283214211464, dist_loss: 0.8891238570213318
recon_loss: 0.029244087636470795, dist_loss: 0.8391886353492737
recon_loss: 0.02924381196498871, dist_loss: 0.7184303998947144
recon_loss: 0.029244314879179, dist_loss: 0.606352686882019
recon_loss: 0.029244087636470795, dist_loss: 0.8305423855781555
recon_loss: 0.029243312776088715, dist_loss: 0.5856875777244568
recon_loss: 0.02924315445125103, dist_loss: 0.4504995346069336
recon_loss: 0.02924306131899357, dist_loss: 0.530798077583313
recon_loss: 0.029242459684610367, dist_loss: 0.4586962163448334
recon_loss: 0.0292423814535141, dist_loss: 0.672484278678894
recon_loss: 0.029241545125842094, dist_loss: 0.5334038734436035
recon_loss: 0.029240867123007774, dist_loss: 0.7060694098472595
recon_loss: 0.029241258278489113, dist_loss: 0.6520642042160034
recon_loss: 0.029241079464554787, dist_loss: 0.7874549627304077
recon_loss: 0.029240485280752182, dist_loss: 0.6233190298080444
recon_loss: 0.029240449890494347, dist_loss: 0.6925557851791382
recon_loss: 0.02924078330397606, dist_loss: 0.5037119388580322
recon_loss: 0.029240133240818977, dist_loss: 0.842383623123169
recon_loss: 0.02924003079533577, dist_loss: 0.44126302003860474
recon_loss: 0.029240574687719345, dist_loss: 0.7786074876785278
recon_loss: 0.02924000658094883, dist_loss: 0.6057132482528687
recon_loss: 0.029239596799016, dist_loss: 0.3549894094467163
recon_loss: 0.029239488765597343, dist_loss: 0.38535743951797485
recon_loss: 0.029239017516374588, dist_loss: 0.5341562628746033
recon_loss: 0.029238680377602577, dist_loss: 0.5725727081298828
recon_loss: 0.0292387455701828, dist_loss: 0.8248082399368286
recon_loss: 0.02923872508108616, dist_loss: 0.6692650318145752
recon_loss: 0.029238609597086906, dist_loss: 0.509567141532898
recon_loss: 0.029238570481538773, dist_loss: 0.7697134017944336
recon_loss: 0.029238618910312653, dist_loss: 1.566589593887329
recon_loss: 0.029238838702440262, dist_loss: 0.47115668654441833
recon_loss: 0.029238585382699966, dist_loss: 0.5043039321899414
recon_loss: 0.029238112270832062, dist_loss: 0.29766517877578735
recon_loss: 0.02923794835805893, dist_loss: 0.7618108987808228
recon_loss: 0.029237907379865646, dist_loss: 0.504279613494873
recon_loss: 0.02923784963786602, dist_loss: 0.9593098163604736
recon_loss: 0.029238201677799225, dist_loss: 0.8261622786521912
recon_loss: 0.029238207265734673, dist_loss: 0.533642053604126
recon_loss: 0.02923768386244774, dist_loss: 0.3302186131477356
recon_loss: 0.02923753298819065, dist_loss: 0.8867236375808716
recon_loss: 0.02923772670328617, dist_loss: 0.928194522857666
recon_loss: 0.029237860813736916, dist_loss: 0.5758668184280396
recon_loss: 0.029237711802124977, dist_loss: 0.6169703006744385
recon_loss: 0.029237478971481323, dist_loss: 0.6856188774108887
recon_loss: 0.02923758141696453, dist_loss: 0.8699272871017456
recon_loss: 0.029237208887934685, dist_loss: 0.6999320387840271
Pre-training Epoch 46:  37%|███▋      | 136/367 [00:00<00:01, 164.67it/s]Pre-training Epoch 46:  42%|████▏     | 153/367 [00:00<00:01, 164.89it/s]Pre-training Epoch 46:  46%|████▋     | 170/367 [00:01<00:01, 160.70it/s]Pre-training Epoch 46:  51%|█████     | 187/367 [00:01<00:01, 156.86it/s]Pre-training Epoch 46:  56%|█████▌    | 204/367 [00:01<00:01, 159.34it/s]Pre-training Epoch 46:  60%|██████    | 221/367 [00:01<00:00, 159.88it/s]Pre-training Epoch 46:  65%|██████▍   | 238/367 [00:01<00:00, 161.60it/s]Pre-training Epoch 46:  69%|██████▉   | 255/367 [00:01<00:00, 163.05it/s]recon_loss: 0.02923661842942238, dist_loss: 0.7559348344802856
recon_loss: 0.02923675999045372, dist_loss: 0.406469464302063
recon_loss: 0.02923659048974514, dist_loss: 0.6152066588401794
recon_loss: 0.02923610806465149, dist_loss: 0.650619626045227
recon_loss: 0.029236262664198875, dist_loss: 0.7627027034759521
recon_loss: 0.029235849156975746, dist_loss: 0.8864099979400635
recon_loss: 0.029235390946269035, dist_loss: 0.7165480852127075
recon_loss: 0.029234878718852997, dist_loss: 0.5617043375968933
recon_loss: 0.02923433855175972, dist_loss: 0.5631846785545349
recon_loss: 0.029233865439891815, dist_loss: 0.971558153629303
recon_loss: 0.02923380769789219, dist_loss: 1.127408504486084
recon_loss: 0.029233889654278755, dist_loss: 0.8208125829696655
recon_loss: 0.02923411875963211, dist_loss: 0.657884955406189
recon_loss: 0.029234226793050766, dist_loss: 0.44560712575912476
recon_loss: 0.029234036803245544, dist_loss: 0.3832196593284607
recon_loss: 0.029234061017632484, dist_loss: 0.5171530842781067
recon_loss: 0.02923412434756756, dist_loss: 0.6255103945732117
recon_loss: 0.02923298068344593, dist_loss: 0.7438284158706665
recon_loss: 0.02923271246254444, dist_loss: 0.4434778690338135
recon_loss: 0.029232991859316826, dist_loss: 0.7388425469398499
recon_loss: 0.029232939705252647, dist_loss: 0.5127732753753662
recon_loss: 0.029233157634735107, dist_loss: 0.9402030110359192
recon_loss: 0.029232943430542946, dist_loss: 0.40796101093292236
recon_loss: 0.029232416301965714, dist_loss: 0.7492357492446899
recon_loss: 0.029232239350676537, dist_loss: 1.0098260641098022
recon_loss: 0.029232807457447052, dist_loss: 0.49361008405685425
recon_loss: 0.029231997206807137, dist_loss: 0.45314666628837585
recon_loss: 0.029231635853648186, dist_loss: 0.6456308364868164
recon_loss: 0.029231522232294083, dist_loss: 0.6056803464889526
recon_loss: 0.029231268912553787, dist_loss: 0.3878035247325897
recon_loss: 0.029230814427137375, dist_loss: 0.7437587976455688
recon_loss: 0.029230952262878418, dist_loss: 0.7137150764465332
recon_loss: 0.0292306300252676, dist_loss: 0.495503306388855
recon_loss: 0.029230372980237007, dist_loss: 0.6545331478118896
recon_loss: 0.029230521991848946, dist_loss: 0.7121209502220154
recon_loss: 0.02923051454126835, dist_loss: 0.4208260476589203
recon_loss: 0.02923073247075081, dist_loss: 0.7136811017990112
recon_loss: 0.029231034219264984, dist_loss: 0.9890628457069397
recon_loss: 0.02923109009861946, dist_loss: 0.6895450949668884
recon_loss: 0.029230628162622452, dist_loss: 0.4310045838356018
recon_loss: 0.029230719432234764, dist_loss: 0.5051143765449524
recon_loss: 0.029230685904622078, dist_loss: 1.0174630880355835
recon_loss: 0.029230428859591484, dist_loss: 0.3487124443054199
recon_loss: 0.02923053503036499, dist_loss: 1.036120057106018
recon_loss: 0.029230190441012383, dist_loss: 0.704047679901123
recon_loss: 0.02922992594540119, dist_loss: 0.27004748582839966
recon_loss: 0.02923000603914261, dist_loss: 0.4975528120994568
recon_loss: 0.029229503124952316, dist_loss: 0.5505936145782471
recon_loss: 0.029229100793600082, dist_loss: 0.582905650138855
recon_loss: 0.029229285195469856, dist_loss: 0.6248279809951782
recon_loss: 0.02922927960753441, dist_loss: 0.7435241341590881
recon_loss: 0.029228797182440758, dist_loss: 0.536691427230835
recon_loss: 0.0292288176715374, dist_loss: 0.5688810348510742
recon_loss: 0.029229138046503067, dist_loss: 0.9181926250457764
recon_loss: 0.02922884188592434, dist_loss: 0.4993671774864197
recon_loss: 0.02922847680747509, dist_loss: 0.7726532220840454
recon_loss: 0.02922923117876053, dist_loss: 0.7391124963760376
recon_loss: 0.029229603707790375, dist_loss: 0.5845015645027161
recon_loss: 0.02922898903489113, dist_loss: 0.54165118932724
recon_loss: 0.02922968566417694, dist_loss: 0.5670719146728516
recon_loss: 0.029230739921331406, dist_loss: 0.8762879371643066
recon_loss: 0.029230991378426552, dist_loss: 0.7500196695327759
recon_loss: 0.029231950640678406, dist_loss: 0.603644609451294
recon_loss: 0.02923346869647503, dist_loss: 0.9154161214828491
recon_loss: 0.029233228415250778, dist_loss: 0.8865119814872742
recon_loss: 0.029232626780867577, dist_loss: 0.7539128065109253
recon_loss: 0.029232533648610115, dist_loss: 0.8206929564476013
recon_loss: 0.029231728985905647, dist_loss: 0.7301068305969238
recon_loss: 0.029231389984488487, dist_loss: 0.5057525634765625
recon_loss: 0.029231470078229904, dist_loss: 1.079641580581665
recon_loss: 0.029230905696749687, dist_loss: 0.4613429307937622
recon_loss: 0.029229797422885895, dist_loss: 0.7937060594558716
recon_loss: 0.029228802770376205, dist_loss: 0.5477878451347351
recon_loss: 0.029227787628769875, dist_loss: 0.22747790813446045
recon_loss: 0.02922702021896839, dist_loss: 0.8408364057540894
recon_loss: 0.029226291924715042, dist_loss: 0.8670188188552856
recon_loss: 0.02922641858458519, dist_loss: 0.7169387340545654
recon_loss: 0.029226768761873245, dist_loss: 0.5882247686386108
recon_loss: 0.02922707051038742, dist_loss: 0.46023476123809814
recon_loss: 0.029226932674646378, dist_loss: 0.7690747976303101
recon_loss: 0.02922711707651615, dist_loss: 0.591642439365387
recon_loss: 0.029226766899228096, dist_loss: 0.5355014204978943
recon_loss: 0.029226725921034813, dist_loss: 0.7689591646194458
recon_loss: 0.02922721579670906, dist_loss: 0.6566026210784912
recon_loss: 0.029227616265416145, dist_loss: 0.7772581577301025
recon_loss: 0.029227690771222115, dist_loss: 0.7263758182525635
recon_loss: 0.029227374121546745, dist_loss: 0.7981231212615967
recon_loss: 0.02922716923058033, dist_loss: 0.6819747090339661
recon_loss: 0.02922712452709675, dist_loss: 0.5444443821907043
recon_loss: 0.029226647689938545, dist_loss: 0.9366208910942078
recon_loss: 0.02922666072845459, dist_loss: 0.561722457408905
recon_loss: 0.02922622673213482, dist_loss: 1.028759479522705
recon_loss: 0.02922515943646431, dist_loss: 0.7644256353378296
recon_loss: 0.029224660247564316, dist_loss: 0.4560479521751404
recon_loss: 0.029224393889307976, dist_loss: 0.47375068068504333
recon_loss: 0.029223980382084846, dist_loss: 0.7466338872909546
recon_loss: 0.029223639518022537, dist_loss: 0.5246236324310303
recon_loss: 0.029223615303635597, dist_loss: 0.4480147659778595
recon_loss: 0.029223607853055, dist_loss: 0.43431782722473145
recon_loss: 0.029223620891571045, dist_loss: 0.47006118297576904
recon_loss: 0.029223749414086342, dist_loss: 0.2647603154182434
recon_loss: 0.029224291443824768, dist_loss: 0.830708384513855
recon_loss: 0.02922426350414753, dist_loss: 0.5897765755653381
recon_loss: 0.029224278405308723, dist_loss: 0.652515172958374
recon_loss: 0.029224371537566185, dist_loss: 0.9090263843536377
recon_loss: 0.02922436222434044, dist_loss: 0.5537736415863037
recon_loss: 0.029224121943116188, dist_loss: 0.330744206905365
recon_loss: 0.029223719611763954, dist_loss: 0.6574448943138123
recon_loss: 0.02922341227531433, dist_loss: 0.958418607711792
recon_loss: 0.029223013669252396, dist_loss: 0.3287762999534607
recon_loss: 0.029222585260868073, dist_loss: 0.5257676839828491
recon_loss: 0.02922278456389904, dist_loss: 0.816059947013855
recon_loss: 0.029222780838608742, dist_loss: 0.3485139012336731
recon_loss: 0.029222317039966583, dist_loss: 0.7039543390274048
recon_loss: 0.029223009943962097, dist_loss: 0.5618373155593872
recon_loss: 0.02922239899635315, dist_loss: 0.8895804286003113
recon_loss: 0.029220882803201675, dist_loss: 0.526833176612854
recon_loss: 0.029221078380942345, dist_loss: 0.4331241250038147
recon_loss: 0.029220523312687874, dist_loss: 0.5433187484741211
recon_loss: 0.029219556599855423, dist_loss: 0.6300962567329407
recon_loss: 0.02921968884766102, dist_loss: 0.7598173022270203
recon_loss: 0.029219267889857292, dist_loss: 0.7820430994033813
recon_loss: 0.02921871840953827, dist_loss: 0.44661203026771545
recon_loss: 0.029218465089797974, dist_loss: 0.6326971650123596
recon_loss: 0.02921895869076252, dist_loss: 0.8705936670303345
recon_loss: 0.02921832911670208, dist_loss: 0.4663708209991455
recon_loss: 0.02921798825263977, dist_loss: 0.8365273475646973
recon_loss: 0.02921779453754425, dist_loss: 0.7204465270042419
recon_loss: 0.029217470437288284, dist_loss: 0.3343604803085327Pre-training Epoch 46:  74%|███████▍  | 272/367 [00:01<00:00, 164.06it/s]Pre-training Epoch 46:  79%|███████▊  | 289/367 [00:01<00:00, 164.73it/s]Pre-training Epoch 46:  83%|████████▎ | 306/367 [00:01<00:00, 165.08it/s]Pre-training Epoch 46:  88%|████████▊ | 323/367 [00:01<00:00, 165.54it/s]Pre-training Epoch 46:  93%|█████████▎| 340/367 [00:02<00:00, 161.15it/s]Pre-training Epoch 46:  97%|█████████▋| 357/367 [00:02<00:00, 159.24it/s]Pre-training Epoch 46: 100%|██████████| 367/367 [00:02<00:00, 162.66it/s]

recon_loss: 0.029217593371868134, dist_loss: 0.2969382405281067
recon_loss: 0.02921750769019127, dist_loss: 0.7247099876403809
recon_loss: 0.029217151924967766, dist_loss: 0.5934506058692932
recon_loss: 0.029216792434453964, dist_loss: 0.7264797687530518
recon_loss: 0.029216591268777847, dist_loss: 0.95887291431427
recon_loss: 0.029216216877102852, dist_loss: 0.5919268131256104
recon_loss: 0.02921605482697487, dist_loss: 0.466865599155426
recon_loss: 0.029215974733233452, dist_loss: 0.699874222278595
recon_loss: 0.029215998947620392, dist_loss: 0.5014116764068604
recon_loss: 0.02921590954065323, dist_loss: 0.437059223651886
recon_loss: 0.029216034337878227, dist_loss: 1.09856379032135
recon_loss: 0.029216047376394272, dist_loss: 0.3643844723701477
recon_loss: 0.029215805232524872, dist_loss: 0.42690885066986084
recon_loss: 0.029215915128588676, dist_loss: 0.6468141078948975
recon_loss: 0.029215652495622635, dist_loss: 1.0125226974487305
recon_loss: 0.02921580709517002, dist_loss: 0.3955678343772888
recon_loss: 0.029216250404715538, dist_loss: 0.5478943586349487
recon_loss: 0.029215704649686813, dist_loss: 0.652862012386322
recon_loss: 0.029215889051556587, dist_loss: 0.2968265116214752
recon_loss: 0.0292156133800745, dist_loss: 1.3330868482589722
recon_loss: 0.029214629903435707, dist_loss: 0.6514269113540649
recon_loss: 0.02921442501246929, dist_loss: 0.6448788642883301
recon_loss: 0.029216041788458824, dist_loss: 0.5349873304367065
recon_loss: 0.029216600582003593, dist_loss: 0.7240616083145142
recon_loss: 0.02921598218381405, dist_loss: 0.41056883335113525
recon_loss: 0.029216298833489418, dist_loss: 0.6807962656021118
recon_loss: 0.029216358438134193, dist_loss: 0.8392385244369507
recon_loss: 0.02921697497367859, dist_loss: 1.6719387769699097
recon_loss: 0.029217194765806198, dist_loss: 1.4450280666351318
recon_loss: 0.029217783361673355, dist_loss: 0.9203261137008667
recon_loss: 0.02921789325773716, dist_loss: 0.9192479848861694
recon_loss: 0.02921799011528492, dist_loss: 0.4099377691745758
recon_loss: 0.029218746349215508, dist_loss: 0.5479342341423035
recon_loss: 0.029218623414635658, dist_loss: 0.7829769849777222
recon_loss: 0.02921774797141552, dist_loss: 0.7560460567474365
recon_loss: 0.02921765111386776, dist_loss: 0.4672955572605133
recon_loss: 0.029218150302767754, dist_loss: 0.4980550706386566
recon_loss: 0.029217474162578583, dist_loss: 0.7852411270141602
recon_loss: 0.029216505587100983, dist_loss: 0.8109601736068726
recon_loss: 0.02921588160097599, dist_loss: 0.4540725350379944
recon_loss: 0.029215743765234947, dist_loss: 0.9079741835594177
recon_loss: 0.029214007779955864, dist_loss: 0.46710479259490967
recon_loss: 0.029213637113571167, dist_loss: 0.6663298606872559
recon_loss: 0.029213644564151764, dist_loss: 0.9953123331069946
recon_loss: 0.02921304665505886, dist_loss: 0.9014225006103516
recon_loss: 0.029212748631834984, dist_loss: 0.7668353319168091
recon_loss: 0.02921283431351185, dist_loss: 0.5750131607055664
recon_loss: 0.029212642461061478, dist_loss: 0.5304111838340759
recon_loss: 0.02921268902719021, dist_loss: 0.8020316958427429
recon_loss: 0.029212966561317444, dist_loss: 0.8420965075492859
recon_loss: 0.0292133130133152, dist_loss: 0.5747295618057251
recon_loss: 0.029213901609182358, dist_loss: 0.7491310834884644
recon_loss: 0.029214562848210335, dist_loss: 0.8374171853065491
recon_loss: 0.02921566367149353, dist_loss: 0.6827044486999512
recon_loss: 0.02921661175787449, dist_loss: 1.342621922492981
recon_loss: 0.029217157512903214, dist_loss: 0.3452957272529602
recon_loss: 0.029217779636383057, dist_loss: 0.542426347732544
recon_loss: 0.029218174517154694, dist_loss: 0.6232165098190308
recon_loss: 0.02921806275844574, dist_loss: 0.44603681564331055
recon_loss: 0.02921764738857746, dist_loss: 0.8057631850242615
recon_loss: 0.029216863214969635, dist_loss: 0.5441803336143494
recon_loss: 0.029216088354587555, dist_loss: 0.518970251083374
recon_loss: 0.029215341433882713, dist_loss: 0.3654623031616211
recon_loss: 0.02921430580317974, dist_loss: 0.2495504468679428
recon_loss: 0.02921327017247677, dist_loss: 0.6797702312469482
recon_loss: 0.02921219915151596, dist_loss: 1.0181984901428223
recon_loss: 0.0292110163718462, dist_loss: 0.37565797567367554
recon_loss: 0.02921028807759285, dist_loss: 0.4370116591453552
recon_loss: 0.029209725558757782, dist_loss: 0.6441564559936523
recon_loss: 0.029209362342953682, dist_loss: 1.1292399168014526
recon_loss: 0.029209375381469727, dist_loss: 0.47546690702438354
recon_loss: 0.02920949086546898, dist_loss: 0.63316410779953
recon_loss: 0.0292092002928257, dist_loss: 0.6431382894515991
recon_loss: 0.02920893393456936, dist_loss: 0.6798447370529175
recon_loss: 0.0292088370770216, dist_loss: 0.5348275303840637
recon_loss: 0.02920876443386078, dist_loss: 0.3952452540397644
recon_loss: 0.02920842170715332, dist_loss: 0.718368411064148
recon_loss: 0.029207898303866386, dist_loss: 1.4438283443450928
recon_loss: 0.029207473620772362, dist_loss: 0.6151169538497925
recon_loss: 0.029206469655036926, dist_loss: 0.8776522874832153
recon_loss: 0.02920612506568432, dist_loss: 0.5824949145317078
recon_loss: 0.029206417500972748, dist_loss: 0.5386615991592407
recon_loss: 0.02920617163181305, dist_loss: 0.589154839515686
recon_loss: 0.02920551970601082, dist_loss: 1.012658715248108
recon_loss: 0.02920520305633545, dist_loss: 0.70255446434021
recon_loss: 0.029204463586211205, dist_loss: 0.5748701095581055
recon_loss: 0.02920401096343994, dist_loss: 0.40614503622055054
recon_loss: 0.029203664511442184, dist_loss: 0.7902539968490601
recon_loss: 0.029203565791249275, dist_loss: 1.2712883949279785
recon_loss: 0.029203588142991066, dist_loss: 0.4466729164123535
recon_loss: 0.029203521087765694, dist_loss: 0.4714556932449341
recon_loss: 0.029203537851572037, dist_loss: 0.6696363687515259
recon_loss: 0.02920311689376831, dist_loss: 0.7984700798988342
recon_loss: 0.029202673584222794, dist_loss: 0.7053747773170471
recon_loss: 0.029202280566096306, dist_loss: 0.4740406572818756
recon_loss: 0.02920202910900116, dist_loss: 1.2995493412017822
recon_loss: 0.029202021658420563, dist_loss: 0.493710994720459
recon_loss: 0.029202032834291458, dist_loss: 0.32282769680023193
recon_loss: 0.02920183166861534, dist_loss: 0.5672941207885742
recon_loss: 0.029201501980423927, dist_loss: 0.8802050352096558
recon_loss: 0.029201122000813484, dist_loss: 0.4601750075817108
recon_loss: 0.029200900346040726, dist_loss: 0.9743223190307617
recon_loss: 0.02920115925371647, dist_loss: 0.4380449056625366
recon_loss: 0.02920197881758213, dist_loss: 0.7303104400634766
recon_loss: 0.029203420504927635, dist_loss: 0.7623024582862854
recon_loss: 0.029204465448856354, dist_loss: 0.4907994270324707
recon_loss: 0.02920529432594776, dist_loss: 1.0448133945465088
recon_loss: 0.029205244034528732, dist_loss: 0.6228021383285522
recon_loss: 0.029204923659563065, dist_loss: 0.7936946153640747
Pre-training Epoch 47:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 47:   5%|▌         | 19/367 [00:00<00:01, 188.99it/s]Pre-training Epoch 47:  11%|█         | 39/367 [00:00<00:01, 191.68it/s]Pre-training Epoch 47:  16%|█▌        | 59/367 [00:00<00:01, 192.40it/s]Pre-training Epoch 47:  22%|██▏       | 79/367 [00:00<00:01, 193.31it/s]Pre-training Epoch 47:  27%|██▋       | 99/367 [00:00<00:01, 187.66it/s]Pre-training Epoch 47:  32%|███▏      | 118/367 [00:00<00:01, 182.42it/s]recon_loss: 0.02920396998524666, dist_loss: 0.4372568726539612
recon_loss: 0.029204171150922775, dist_loss: 0.533416748046875
recon_loss: 0.0292037483304739, dist_loss: 0.47350600361824036
recon_loss: 0.02920396253466606, dist_loss: 0.6769068837165833
recon_loss: 0.02920428477227688, dist_loss: 0.46287018060684204
recon_loss: 0.029203135520219803, dist_loss: 0.9294426441192627
recon_loss: 0.029201582074165344, dist_loss: 0.5747681260108948
recon_loss: 0.029200540855526924, dist_loss: 0.49909138679504395
recon_loss: 0.02919945865869522, dist_loss: 1.0361900329589844
recon_loss: 0.029199114069342613, dist_loss: 0.7961366176605225
recon_loss: 0.02919945865869522, dist_loss: 0.5594095587730408
recon_loss: 0.029200000688433647, dist_loss: 0.441448450088501
recon_loss: 0.029200561344623566, dist_loss: 0.795856773853302
recon_loss: 0.029200153425335884, dist_loss: 0.42096108198165894
recon_loss: 0.02919967658817768, dist_loss: 0.7211483716964722
recon_loss: 0.029199143871665, dist_loss: 0.609896719455719
recon_loss: 0.029198603704571724, dist_loss: 0.9291436672210693
recon_loss: 0.029198355972766876, dist_loss: 0.3260698914527893
recon_loss: 0.029198402538895607, dist_loss: 0.713900089263916
recon_loss: 0.02919858880341053, dist_loss: 0.40070539712905884
recon_loss: 0.029198292642831802, dist_loss: 0.9282671213150024
recon_loss: 0.029197636991739273, dist_loss: 0.4767764210700989
recon_loss: 0.02919723652303219, dist_loss: 0.7259258031845093
recon_loss: 0.0291968435049057, dist_loss: 0.5717272162437439
recon_loss: 0.02919633872807026, dist_loss: 0.2955070734024048
recon_loss: 0.029196541756391525, dist_loss: 0.6398725509643555
recon_loss: 0.02919740416109562, dist_loss: 0.5321072340011597
recon_loss: 0.029198411852121353, dist_loss: 0.8631439208984375
recon_loss: 0.029200369492173195, dist_loss: 0.49496084451675415
recon_loss: 0.02920026145875454, dist_loss: 0.9159441590309143
recon_loss: 0.02919946424663067, dist_loss: 0.6370459794998169
recon_loss: 0.02919885888695717, dist_loss: 0.5356672406196594
recon_loss: 0.029199143871665, dist_loss: 0.568712592124939
recon_loss: 0.02919922024011612, dist_loss: 1.0546526908874512
recon_loss: 0.02919953130185604, dist_loss: 0.4517304301261902
recon_loss: 0.029199831187725067, dist_loss: 0.7767429947853088
recon_loss: 0.029199369251728058, dist_loss: 0.9384083151817322
recon_loss: 0.02919831871986389, dist_loss: 0.8637839555740356
recon_loss: 0.029197413474321365, dist_loss: 0.6148959398269653
recon_loss: 0.029195964336395264, dist_loss: 0.7190932035446167
recon_loss: 0.02919505350291729, dist_loss: 0.5953394770622253
recon_loss: 0.02919476293027401, dist_loss: 0.6974800825119019
recon_loss: 0.0291941799223423, dist_loss: 0.8521335124969482
recon_loss: 0.02919449470937252, dist_loss: 0.4939858913421631
recon_loss: 0.029194707050919533, dist_loss: 0.6632601618766785
recon_loss: 0.02919461950659752, dist_loss: 0.9528237581253052
recon_loss: 0.029195060953497887, dist_loss: 0.6168692111968994
recon_loss: 0.02919659949839115, dist_loss: 0.9585128426551819
recon_loss: 0.02919762209057808, dist_loss: 0.7146831154823303
recon_loss: 0.02919861115515232, dist_loss: 0.9628409147262573
recon_loss: 0.029200084507465363, dist_loss: 0.7118130922317505
recon_loss: 0.029200797900557518, dist_loss: 0.6813060641288757
recon_loss: 0.029201330617070198, dist_loss: 0.6227685809135437
recon_loss: 0.029201800003647804, dist_loss: 0.8515427708625793
recon_loss: 0.02920161560177803, dist_loss: 0.3902120888233185
recon_loss: 0.029200801625847816, dist_loss: 0.7106892466545105
recon_loss: 0.029200904071331024, dist_loss: 0.5924202799797058
recon_loss: 0.029200803488492966, dist_loss: 0.8941454887390137
recon_loss: 0.02919958345592022, dist_loss: 0.533305823802948
recon_loss: 0.029198698699474335, dist_loss: 0.5960953235626221
recon_loss: 0.02919805981218815, dist_loss: 1.1242526769638062
recon_loss: 0.0291962418705225, dist_loss: 0.35627123713493347
recon_loss: 0.0291944220662117, dist_loss: 0.7758731842041016
recon_loss: 0.029193229973316193, dist_loss: 0.2884601950645447
recon_loss: 0.029192473739385605, dist_loss: 0.5389597415924072
recon_loss: 0.029192546382546425, dist_loss: 0.974927544593811
recon_loss: 0.029193570837378502, dist_loss: 0.7511661052703857
recon_loss: 0.02919459156692028, dist_loss: 0.7435211539268494
recon_loss: 0.029194632545113564, dist_loss: 0.9211778044700623
recon_loss: 0.02919364906847477, dist_loss: 0.438331663608551
recon_loss: 0.029192540794610977, dist_loss: 0.7291603088378906
recon_loss: 0.029191462323069572, dist_loss: 0.5370676517486572
recon_loss: 0.02919113077223301, dist_loss: 0.6944735050201416
recon_loss: 0.02919183485209942, dist_loss: 0.6500189900398254
recon_loss: 0.029191968962550163, dist_loss: 0.9820712804794312
recon_loss: 0.029192382469773293, dist_loss: 0.7290931344032288
recon_loss: 0.029192768037319183, dist_loss: 0.3043282628059387
recon_loss: 0.029192455112934113, dist_loss: 0.7558335065841675
recon_loss: 0.02919098176062107, dist_loss: 0.4879935085773468
recon_loss: 0.02919011563062668, dist_loss: 0.6138061285018921
recon_loss: 0.029190005734562874, dist_loss: 0.43812981247901917
recon_loss: 0.029190124943852425, dist_loss: 0.5015086531639099
recon_loss: 0.029190313071012497, dist_loss: 0.7694087624549866
recon_loss: 0.029190365225076675, dist_loss: 0.7246111631393433
recon_loss: 0.029189731925725937, dist_loss: 0.3979906439781189
recon_loss: 0.029189085587859154, dist_loss: 0.5220898389816284
recon_loss: 0.029188740998506546, dist_loss: 0.5747666358947754
recon_loss: 0.029188113287091255, dist_loss: 0.826700747013092
recon_loss: 0.029187770560383797, dist_loss: 0.8016346096992493
recon_loss: 0.029187798500061035, dist_loss: 0.7376216650009155
recon_loss: 0.02918773517012596, dist_loss: 0.8085771799087524
recon_loss: 0.02918732911348343, dist_loss: 0.38695767521858215
recon_loss: 0.029187293723225594, dist_loss: 0.6357100605964661
recon_loss: 0.029186993837356567, dist_loss: 1.0252512693405151
recon_loss: 0.029186993837356567, dist_loss: 0.9346554279327393
recon_loss: 0.029186967760324478, dist_loss: 0.5924197435379028
recon_loss: 0.029186658561229706, dist_loss: 0.5337998270988464
recon_loss: 0.029186462983489037, dist_loss: 0.3015449047088623
recon_loss: 0.029186109080910683, dist_loss: 0.5286701321601868
recon_loss: 0.029185784980654716, dist_loss: 0.7501358389854431
recon_loss: 0.029185472056269646, dist_loss: 0.6095632314682007
recon_loss: 0.029185254126787186, dist_loss: 0.5979523658752441
recon_loss: 0.02918512374162674, dist_loss: 0.8331663608551025
recon_loss: 0.029184997081756592, dist_loss: 0.774738609790802
recon_loss: 0.029184943065047264, dist_loss: 0.9038243889808655
recon_loss: 0.029185332357883453, dist_loss: 0.6767512559890747
recon_loss: 0.029186097905039787, dist_loss: 0.5017170310020447
recon_loss: 0.029186991974711418, dist_loss: 0.852985143661499
recon_loss: 0.029186774045228958, dist_loss: 0.4863668978214264
recon_loss: 0.02918708324432373, dist_loss: 0.9121388792991638
recon_loss: 0.029187025502324104, dist_loss: 1.3622429370880127
recon_loss: 0.02918691746890545, dist_loss: 0.64887535572052
recon_loss: 0.029186731204390526, dist_loss: 1.057273507118225
recon_loss: 0.029187066480517387, dist_loss: 0.6885530352592468
recon_loss: 0.029187548905611038, dist_loss: 0.7102522850036621
recon_loss: 0.02918751910328865, dist_loss: 0.5700592994689941
recon_loss: 0.029186712577939034, dist_loss: 1.4027272462844849
recon_loss: 0.029185600578784943, dist_loss: 0.506814181804657
recon_loss: 0.029184740036725998, dist_loss: 0.5018253922462463
recon_loss: 0.029184428974986076, dist_loss: 0.6592760682106018
recon_loss: 0.029184455052018166, dist_loss: 0.9236001968383789
recon_loss: 0.029184741899371147, dist_loss: 0.9400942921638489
recon_loss: 0.029184818267822266, dist_loss: 0.7026442885398865
recon_loss: 0.02918502688407898, dist_loss: 0.4095878601074219
recon_loss: 0.029184790328145027, dist_loss: 0.799780547618866
recon_loss: 0.029184652492403984, dist_loss: 0.6389137506484985
recon_loss: 0.02918461710214615, dist_loss: 1.0577409267425537
recon_loss: 0.029184598475694656, dist_loss: 0.4791271984577179
recon_loss: 0.02918461337685585, dist_loss: 0.6770364046096802
Pre-training Epoch 47:  37%|███▋      | 137/367 [00:00<00:01, 180.89it/s]Pre-training Epoch 47:  43%|████▎     | 156/367 [00:00<00:01, 179.84it/s]Pre-training Epoch 47:  48%|████▊     | 175/367 [00:00<00:01, 180.09it/s]Pre-training Epoch 47:  53%|█████▎    | 194/367 [00:01<00:00, 180.18it/s]Pre-training Epoch 47:  58%|█████▊    | 213/367 [00:01<00:00, 179.59it/s]Pre-training Epoch 47:  63%|██████▎   | 232/367 [00:01<00:00, 179.97it/s]Pre-training Epoch 47:  68%|██████▊   | 251/367 [00:01<00:00, 180.15it/s]recon_loss: 0.02918451838195324, dist_loss: 0.646655797958374
recon_loss: 0.029184488579630852, dist_loss: 0.8381322622299194
recon_loss: 0.02918446995317936, dist_loss: 0.7408162355422974
recon_loss: 0.029184317216277122, dist_loss: 0.6944475173950195
recon_loss: 0.029184194281697273, dist_loss: 0.3382275700569153
recon_loss: 0.02918393723666668, dist_loss: 0.31862878799438477
recon_loss: 0.029183682054281235, dist_loss: 0.7175256013870239
recon_loss: 0.029183348640799522, dist_loss: 0.6814553141593933
recon_loss: 0.02918311022222042, dist_loss: 0.30307450890541077
recon_loss: 0.0291829202324152, dist_loss: 0.7698686122894287
recon_loss: 0.02918267995119095, dist_loss: 0.41260024905204773
recon_loss: 0.029182787984609604, dist_loss: 0.506303608417511
recon_loss: 0.029182622209191322, dist_loss: 0.9877678155899048
recon_loss: 0.029182208701968193, dist_loss: 0.5545468330383301
recon_loss: 0.029181504622101784, dist_loss: 0.5153011083602905
recon_loss: 0.029181277379393578, dist_loss: 0.46988388895988464
recon_loss: 0.029180824756622314, dist_loss: 1.1072306632995605
recon_loss: 0.029180316254496574, dist_loss: 0.5909346342086792
recon_loss: 0.029180604964494705, dist_loss: 0.9351091980934143
recon_loss: 0.02918100729584694, dist_loss: 0.48888522386550903
recon_loss: 0.029180636629462242, dist_loss: 0.7370996475219727
recon_loss: 0.029179709032177925, dist_loss: 0.854433536529541
recon_loss: 0.029178621247410774, dist_loss: 0.5128142237663269
recon_loss: 0.029178332537412643, dist_loss: 0.535563588142395
recon_loss: 0.029178639873862267, dist_loss: 0.4077014923095703
recon_loss: 0.029179012402892113, dist_loss: 0.41580110788345337
recon_loss: 0.029179278761148453, dist_loss: 0.8151112794876099
recon_loss: 0.02917875163257122, dist_loss: 0.570663571357727
recon_loss: 0.02917807549238205, dist_loss: 1.1570820808410645
recon_loss: 0.029177291318774223, dist_loss: 0.7285544872283936
recon_loss: 0.029177753254771233, dist_loss: 0.657395601272583
recon_loss: 0.02917797863483429, dist_loss: 0.5026624202728271
recon_loss: 0.029177792370319366, dist_loss: 0.42892366647720337
recon_loss: 0.029178133234381676, dist_loss: 0.9161131381988525
recon_loss: 0.029177481308579445, dist_loss: 0.4590950310230255
recon_loss: 0.029176533222198486, dist_loss: 0.5617672204971313
recon_loss: 0.029176684096455574, dist_loss: 0.6674127578735352
recon_loss: 0.02917696163058281, dist_loss: 0.7726435661315918
recon_loss: 0.029176989570260048, dist_loss: 0.47138696908950806
recon_loss: 0.029177075251936913, dist_loss: 0.9155795574188232
recon_loss: 0.02917688898742199, dist_loss: 0.5831493139266968
recon_loss: 0.029176166281104088, dist_loss: 0.642577052116394
recon_loss: 0.02917604148387909, dist_loss: 0.8626986742019653
recon_loss: 0.02917596325278282, dist_loss: 0.478030264377594
recon_loss: 0.02917657420039177, dist_loss: 0.6414646506309509
recon_loss: 0.029178280383348465, dist_loss: 0.7687979340553284
recon_loss: 0.029181042686104774, dist_loss: 0.8905016779899597
recon_loss: 0.029183655977249146, dist_loss: 0.5504247546195984
recon_loss: 0.029185229912400246, dist_loss: 0.35535386204719543
recon_loss: 0.02918638288974762, dist_loss: 0.6360411643981934
recon_loss: 0.0291867908090353, dist_loss: 0.7685743570327759
recon_loss: 0.029187336564064026, dist_loss: 0.4444015324115753
recon_loss: 0.029188938438892365, dist_loss: 0.5941057801246643
recon_loss: 0.029189826920628548, dist_loss: 0.6247454285621643
recon_loss: 0.02919110469520092, dist_loss: 0.453792542219162
recon_loss: 0.029191594570875168, dist_loss: 0.8338102698326111
recon_loss: 0.02919117547571659, dist_loss: 0.5668191313743591
recon_loss: 0.029189664870500565, dist_loss: 0.8818284273147583
recon_loss: 0.029187360778450966, dist_loss: 0.9369844794273376
recon_loss: 0.0291848536580801, dist_loss: 0.654780387878418
recon_loss: 0.029182251542806625, dist_loss: 1.1131476163864136
recon_loss: 0.029180068522691727, dist_loss: 0.952522873878479
recon_loss: 0.029178561642766, dist_loss: 0.5733699798583984
recon_loss: 0.029177619144320488, dist_loss: 0.551661491394043
recon_loss: 0.02917701005935669, dist_loss: 0.7061460018157959
recon_loss: 0.029176954180002213, dist_loss: 0.6730563640594482
recon_loss: 0.02917710319161415, dist_loss: 0.3673648238182068
recon_loss: 0.029177917167544365, dist_loss: 0.5839239358901978
recon_loss: 0.02917894348502159, dist_loss: 0.4261944890022278
recon_loss: 0.029179301112890244, dist_loss: 0.8833928108215332
recon_loss: 0.02918017841875553, dist_loss: 0.4733201265335083
recon_loss: 0.029180778190493584, dist_loss: 0.38171643018722534
recon_loss: 0.029180917888879776, dist_loss: 0.45488035678863525
recon_loss: 0.029181024059653282, dist_loss: 0.5508084893226624
recon_loss: 0.02918093092739582, dist_loss: 0.696212887763977
recon_loss: 0.02918091230094433, dist_loss: 0.7214295864105225
recon_loss: 0.02918044850230217, dist_loss: 0.6129803657531738
recon_loss: 0.029179489240050316, dist_loss: 0.6005748510360718
recon_loss: 0.029179062694311142, dist_loss: 0.6230246424674988
recon_loss: 0.029177946969866753, dist_loss: 0.5945634245872498
recon_loss: 0.02917705848813057, dist_loss: 0.514996349811554
recon_loss: 0.029176875948905945, dist_loss: 0.7174515128135681
recon_loss: 0.02917632833123207, dist_loss: 0.7343847751617432
recon_loss: 0.029175108298659325, dist_loss: 1.061710000038147
recon_loss: 0.029174501076340675, dist_loss: 1.015000343322754
recon_loss: 0.029173534363508224, dist_loss: 0.6757460832595825
recon_loss: 0.02917269431054592, dist_loss: 0.357082724571228
recon_loss: 0.02917235903441906, dist_loss: 0.4001731276512146
recon_loss: 0.029172081500291824, dist_loss: 0.7542638778686523
recon_loss: 0.029171807691454887, dist_loss: 0.7378415465354919
recon_loss: 0.029171768575906754, dist_loss: 0.5372158885002136
recon_loss: 0.02917182259261608, dist_loss: 0.8904402256011963
recon_loss: 0.029171526432037354, dist_loss: 0.8268142342567444
recon_loss: 0.02917192131280899, dist_loss: 1.099102258682251
recon_loss: 0.029172580689191818, dist_loss: 0.6683560013771057
recon_loss: 0.029172774404287338, dist_loss: 0.6007285118103027
recon_loss: 0.029172735288739204, dist_loss: 0.5733449459075928
recon_loss: 0.029172440990805626, dist_loss: 0.39302295446395874
recon_loss: 0.029172033071517944, dist_loss: 0.7847371697425842
recon_loss: 0.029171530157327652, dist_loss: 0.9768295884132385
recon_loss: 0.02917097508907318, dist_loss: 1.177550196647644
recon_loss: 0.029170453548431396, dist_loss: 0.46023818850517273
recon_loss: 0.02917020209133625, dist_loss: 0.28526556491851807
recon_loss: 0.02916991338133812, dist_loss: 0.522457480430603
recon_loss: 0.029169464483857155, dist_loss: 1.0705437660217285
recon_loss: 0.02916933037340641, dist_loss: 0.5865572690963745
recon_loss: 0.029169218614697456, dist_loss: 0.751213014125824
recon_loss: 0.02916889823973179, dist_loss: 0.5320786237716675
recon_loss: 0.029168730601668358, dist_loss: 0.6801683902740479
recon_loss: 0.02916841395199299, dist_loss: 0.7335062026977539
recon_loss: 0.02916826866567135, dist_loss: 0.6907254457473755
recon_loss: 0.029168084263801575, dist_loss: 0.6787099838256836
recon_loss: 0.029168153181672096, dist_loss: 0.5115036964416504
recon_loss: 0.029167959466576576, dist_loss: 0.3882860541343689
recon_loss: 0.02916775830090046, dist_loss: 0.36288097500801086
recon_loss: 0.029167715460062027, dist_loss: 0.4221477508544922
recon_loss: 0.029167262837290764, dist_loss: 0.8680785894393921
recon_loss: 0.029167193919420242, dist_loss: 0.9494267106056213
recon_loss: 0.029167380183935165, dist_loss: 0.5305715799331665
recon_loss: 0.029166942462325096, dist_loss: 0.9984235763549805
recon_loss: 0.029166720807552338, dist_loss: 0.31624817848205566
recon_loss: 0.029166927561163902, dist_loss: 0.559302568435669
recon_loss: 0.02916715480387211, dist_loss: 0.5048387050628662
recon_loss: 0.02916695363819599, dist_loss: 0.45736998319625854
recon_loss: 0.02916686236858368, dist_loss: 0.9312750101089478
recon_loss: 0.029166733846068382, dist_loss: 0.7872014045715332
recon_loss: 0.029166406020522118, dist_loss: 0.9066916704177856
recon_loss: 0.029166381806135178, dist_loss: 0.7164124250411987
Pre-training Epoch 47:  74%|███████▎  | 270/367 [00:01<00:00, 179.28it/s]Pre-training Epoch 47:  78%|███████▊  | 288/367 [00:01<00:00, 177.43it/s]Pre-training Epoch 47:  83%|████████▎ | 306/367 [00:01<00:00, 170.85it/s]Pre-training Epoch 47:  88%|████████▊ | 324/367 [00:01<00:00, 165.00it/s]Pre-training Epoch 47:  93%|█████████▎| 341/367 [00:01<00:00, 157.71it/s]Pre-training Epoch 47:  97%|█████████▋| 357/367 [00:02<00:00, 155.95it/s]Pre-training Epoch 47: 100%|██████████| 367/367 [00:02<00:00, 173.95it/s]
recon_loss: 0.029166333377361298, dist_loss: 0.3712998032569885
recon_loss: 0.02916586585342884, dist_loss: 0.3387661576271057
recon_loss: 0.02916570007801056, dist_loss: 0.821260929107666
recon_loss: 0.029165858402848244, dist_loss: 0.7185838222503662
recon_loss: 0.029165253043174744, dist_loss: 1.1104228496551514
recon_loss: 0.029165061190724373, dist_loss: 0.4010808765888214
recon_loss: 0.02916480228304863, dist_loss: 0.8435633182525635
recon_loss: 0.02916439063847065, dist_loss: 0.6440606117248535
recon_loss: 0.029164263978600502, dist_loss: 0.24069371819496155
recon_loss: 0.029164528474211693, dist_loss: 1.0876933336257935
recon_loss: 0.029164740815758705, dist_loss: 0.9759204387664795
recon_loss: 0.029164476320147514, dist_loss: 0.68086177110672
recon_loss: 0.029164530336856842, dist_loss: 0.35236650705337524
recon_loss: 0.029164232313632965, dist_loss: 0.719574511051178
recon_loss: 0.029163889586925507, dist_loss: 1.0430257320404053
recon_loss: 0.029163416475057602, dist_loss: 0.40140414237976074
recon_loss: 0.02916305512189865, dist_loss: 0.47051650285720825
recon_loss: 0.029162824153900146, dist_loss: 1.5287649631500244
recon_loss: 0.02916289120912552, dist_loss: 1.1423207521438599
recon_loss: 0.029162654653191566, dist_loss: 0.8016911745071411
recon_loss: 0.029162580147385597, dist_loss: 0.9546289443969727
recon_loss: 0.02916223742067814, dist_loss: 0.9346851110458374
recon_loss: 0.02916187234222889, dist_loss: 0.9610219597816467
recon_loss: 0.029161600396037102, dist_loss: 0.377380907535553
recon_loss: 0.02916148118674755, dist_loss: 1.1334872245788574
recon_loss: 0.029161855578422546, dist_loss: 0.656296968460083
recon_loss: 0.029161931946873665, dist_loss: 0.8163533806800842
recon_loss: 0.029162252321839333, dist_loss: 0.8187785148620605
recon_loss: 0.02916301041841507, dist_loss: 0.9996340870857239
recon_loss: 0.029164066538214684, dist_loss: 0.5639076232910156
recon_loss: 0.029162820428609848, dist_loss: 0.4687872529029846
recon_loss: 0.029161572456359863, dist_loss: 0.7073904871940613
recon_loss: 0.029162123799324036, dist_loss: 0.6395101547241211
recon_loss: 0.029162826016545296, dist_loss: 0.5513427257537842
recon_loss: 0.02916141226887703, dist_loss: 0.5861817002296448
recon_loss: 0.029161812737584114, dist_loss: 0.5112448334693909
recon_loss: 0.029162490740418434, dist_loss: 0.6262770295143127
recon_loss: 0.029161008074879646, dist_loss: 0.7159036993980408
recon_loss: 0.029160520061850548, dist_loss: 1.1625438928604126
recon_loss: 0.02916104719042778, dist_loss: 0.6377564668655396
recon_loss: 0.029161585494875908, dist_loss: 0.6200284957885742
recon_loss: 0.029161738231778145, dist_loss: 0.6521445512771606
recon_loss: 0.029161717742681503, dist_loss: 1.1535251140594482
recon_loss: 0.029161155223846436, dist_loss: 0.5912610292434692
recon_loss: 0.029160739853978157, dist_loss: 0.3582567572593689
recon_loss: 0.029161132872104645, dist_loss: 0.5953866243362427
recon_loss: 0.02916119433939457, dist_loss: 0.830039381980896
recon_loss: 0.029161566868424416, dist_loss: 1.1514861583709717
recon_loss: 0.02916198968887329, dist_loss: 0.555855393409729
recon_loss: 0.029160887002944946, dist_loss: 0.7026008367538452
recon_loss: 0.029160210862755775, dist_loss: 0.799517035484314
recon_loss: 0.0291600301861763, dist_loss: 0.5119521021842957
recon_loss: 0.02915911376476288, dist_loss: 0.6901615858078003
recon_loss: 0.029158491641283035, dist_loss: 0.8765497207641602
recon_loss: 0.02915864624083042, dist_loss: 1.04767644405365
recon_loss: 0.029158957302570343, dist_loss: 0.4055739641189575
recon_loss: 0.029158230870962143, dist_loss: 0.38955605030059814
recon_loss: 0.02915794961154461, dist_loss: 0.5624625086784363
recon_loss: 0.02915865369141102, dist_loss: 0.4495297074317932
recon_loss: 0.029158279299736023, dist_loss: 0.7183668613433838
recon_loss: 0.029157839715480804, dist_loss: 0.41002315282821655
recon_loss: 0.029158301651477814, dist_loss: 0.33929967880249023
recon_loss: 0.0291585735976696, dist_loss: 0.8172941207885742
recon_loss: 0.029157644137740135, dist_loss: 0.5150074362754822
recon_loss: 0.029157500714063644, dist_loss: 0.8124683499336243
recon_loss: 0.02915908768773079, dist_loss: 0.9403076767921448
recon_loss: 0.029158787801861763, dist_loss: 0.7256084084510803
recon_loss: 0.029156964272260666, dist_loss: 1.1009584665298462
recon_loss: 0.029158879071474075, dist_loss: 0.5855259895324707
recon_loss: 0.029159419238567352, dist_loss: 0.4469919204711914
recon_loss: 0.029156072065234184, dist_loss: 0.3950718343257904
recon_loss: 0.029157644137740135, dist_loss: 0.9481993913650513
recon_loss: 0.029158391058444977, dist_loss: 1.2571802139282227
recon_loss: 0.02915654145181179, dist_loss: 0.6840111017227173
recon_loss: 0.02915908768773079, dist_loss: 0.8682743310928345
recon_loss: 0.029157759621739388, dist_loss: 0.7708034515380859
recon_loss: 0.0291554257273674, dist_loss: 0.42596638202667236
recon_loss: 0.029157433658838272, dist_loss: 0.6039431095123291
recon_loss: 0.02915811911225319, dist_loss: 0.49767130613327026
recon_loss: 0.029155919328331947, dist_loss: 0.5765939354896545
recon_loss: 0.029155978932976723, dist_loss: 0.7584569454193115
recon_loss: 0.02915733866393566, dist_loss: 0.7194530963897705
recon_loss: 0.029155438765883446, dist_loss: 0.5229684114456177
recon_loss: 0.029154334217309952, dist_loss: 0.6877559423446655
recon_loss: 0.029155472293496132, dist_loss: 0.8265434503555298
recon_loss: 0.029155034571886063, dist_loss: 0.45658421516418457
recon_loss: 0.029154011979699135, dist_loss: 0.7639060020446777
recon_loss: 0.029154691845178604, dist_loss: 0.47474879026412964
recon_loss: 0.02915540710091591, dist_loss: 0.6557236313819885
recon_loss: 0.029153602197766304, dist_loss: 0.6790128946304321
recon_loss: 0.029154250398278236, dist_loss: 0.3712189197540283
recon_loss: 0.02915498986840248, dist_loss: 0.5892375707626343
recon_loss: 0.02915404923260212, dist_loss: 0.3533465266227722
recon_loss: 0.029153965413570404, dist_loss: 0.6694276928901672
recon_loss: 0.029155666008591652, dist_loss: 0.5034469366073608
recon_loss: 0.029154814779758453, dist_loss: 0.6114178895950317
recon_loss: 0.029153844341635704, dist_loss: 0.8074822425842285
recon_loss: 0.029154105111956596, dist_loss: 1.001758337020874
recon_loss: 0.02915402688086033, dist_loss: 0.5717921257019043
recon_loss: 0.029153361916542053, dist_loss: 0.7906874418258667
recon_loss: 0.02915433794260025, dist_loss: 0.4899899661540985
recon_loss: 0.029154960066080093, dist_loss: 0.7507127523422241
recon_loss: 0.029153069481253624, dist_loss: 0.3944509029388428
recon_loss: 0.029152600094676018, dist_loss: 0.32481563091278076
recon_loss: 0.029153071343898773, dist_loss: 0.48929375410079956
recon_loss: 0.029151365160942078, dist_loss: 0.6669067144393921
recon_loss: 0.02915184758603573, dist_loss: 0.5071237087249756
recon_loss: 0.029152335599064827, dist_loss: 0.8977231979370117
recon_loss: 0.029151389375329018, dist_loss: 0.6566675901412964
recon_loss: 0.029151594266295433, dist_loss: 0.5504875183105469
Pre-training Epoch 48:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 48:   4%|▍         | 15/367 [00:00<00:02, 147.16it/s]Pre-training Epoch 48:   8%|▊         | 31/367 [00:00<00:02, 149.95it/s]Pre-training Epoch 48:  13%|█▎        | 46/367 [00:00<00:02, 148.72it/s]Pre-training Epoch 48:  17%|█▋        | 61/367 [00:00<00:02, 148.31it/s]Pre-training Epoch 48:  21%|██        | 77/367 [00:00<00:01, 149.11it/s]Pre-training Epoch 48:  26%|██▌       | 94/367 [00:00<00:01, 153.64it/s]Pre-training Epoch 48:  30%|███       | 111/367 [00:00<00:01, 156.50it/s]recon_loss: 0.029152048751711845, dist_loss: 0.5136128664016724
recon_loss: 0.029151566326618195, dist_loss: 0.5315287113189697
recon_loss: 0.02915146015584469, dist_loss: 0.4537484645843506
recon_loss: 0.02915175072848797, dist_loss: 0.5876442193984985
recon_loss: 0.02915145643055439, dist_loss: 0.9048843383789062
recon_loss: 0.029151052236557007, dist_loss: 0.6319215893745422
recon_loss: 0.029151076450943947, dist_loss: 0.7337784171104431
recon_loss: 0.029150905087590218, dist_loss: 0.6581991910934448
recon_loss: 0.029151322320103645, dist_loss: 0.7504982948303223
recon_loss: 0.02915165014564991, dist_loss: 0.6828337907791138
recon_loss: 0.029151009395718575, dist_loss: 0.7634578943252563
recon_loss: 0.02915058843791485, dist_loss: 0.421323299407959
recon_loss: 0.02914998307824135, dist_loss: 0.7674705982208252
recon_loss: 0.029149731621146202, dist_loss: 0.39504343271255493
recon_loss: 0.02914947085082531, dist_loss: 0.6943730711936951
recon_loss: 0.029149165377020836, dist_loss: 0.8181347250938416
recon_loss: 0.029148822650313377, dist_loss: 0.4176877737045288
recon_loss: 0.02914859540760517, dist_loss: 0.9976807832717896
recon_loss: 0.029148265719413757, dist_loss: 0.3348420262336731
recon_loss: 0.029147934168577194, dist_loss: 0.9161016941070557
recon_loss: 0.029147814959287643, dist_loss: 0.44099849462509155
recon_loss: 0.029147673398256302, dist_loss: 0.6207826137542725
recon_loss: 0.029147494584321976, dist_loss: 0.8151021003723145
recon_loss: 0.029147591441869736, dist_loss: 0.793010950088501
recon_loss: 0.029148045927286148, dist_loss: 0.8508552312850952
recon_loss: 0.029148055240511894, dist_loss: 0.9759493470191956
recon_loss: 0.02914755791425705, dist_loss: 1.0005531311035156
recon_loss: 0.029147226363420486, dist_loss: 0.723626971244812
recon_loss: 0.02914675511419773, dist_loss: 0.6879428625106812
recon_loss: 0.02914651297032833, dist_loss: 0.4241885542869568
recon_loss: 0.02914641797542572, dist_loss: 0.8436743021011353
recon_loss: 0.029146332293748856, dist_loss: 1.3230104446411133
recon_loss: 0.029146943241357803, dist_loss: 0.6194321513175964
recon_loss: 0.0291470717638731, dist_loss: 0.3952796459197998
recon_loss: 0.029146505519747734, dist_loss: 0.7325214147567749
recon_loss: 0.029146259650588036, dist_loss: 0.5215714573860168
recon_loss: 0.029145842418074608, dist_loss: 0.6920841336250305
recon_loss: 0.029145218431949615, dist_loss: 0.8250613212585449
recon_loss: 0.029145166277885437, dist_loss: 0.5378668308258057
recon_loss: 0.02914540469646454, dist_loss: 1.3031681776046753
recon_loss: 0.029145503416657448, dist_loss: 0.5019888877868652
recon_loss: 0.029144955798983574, dist_loss: 0.5545810461044312
recon_loss: 0.02914576418697834, dist_loss: 0.5257918834686279
recon_loss: 0.029146671295166016, dist_loss: 1.0237696170806885
recon_loss: 0.029146118089556694, dist_loss: 0.7374506592750549
recon_loss: 0.029146801680326462, dist_loss: 0.45196452736854553
recon_loss: 0.029147831723093987, dist_loss: 0.42792749404907227
recon_loss: 0.029147373512387276, dist_loss: 0.7604594230651855
recon_loss: 0.02914949506521225, dist_loss: 0.520933985710144
recon_loss: 0.02915164828300476, dist_loss: 0.6259598731994629
recon_loss: 0.029151879251003265, dist_loss: 0.5600358247756958
recon_loss: 0.02915259823203087, dist_loss: 1.0603951215744019
recon_loss: 0.029154105111956596, dist_loss: 0.9693451523780823
recon_loss: 0.02915368601679802, dist_loss: 0.41396936774253845
recon_loss: 0.029150618240237236, dist_loss: 0.8145146369934082
recon_loss: 0.029149651527404785, dist_loss: 0.5831517577171326
recon_loss: 0.02914951741695404, dist_loss: 0.6056238412857056
recon_loss: 0.029147988185286522, dist_loss: 0.5142215490341187
recon_loss: 0.02914785034954548, dist_loss: 0.913303017616272
recon_loss: 0.029148655012249947, dist_loss: 0.80028235912323
recon_loss: 0.029146019369363785, dist_loss: 0.31830593943595886
recon_loss: 0.029145682230591774, dist_loss: 0.35169461369514465
recon_loss: 0.029147835448384285, dist_loss: 0.5170168876647949
recon_loss: 0.029147231951355934, dist_loss: 0.6388828158378601
recon_loss: 0.029147697612643242, dist_loss: 0.6227129697799683
recon_loss: 0.029149318113923073, dist_loss: 0.7769705057144165
recon_loss: 0.029148422181606293, dist_loss: 0.9515308141708374
recon_loss: 0.029146907851099968, dist_loss: 0.6293240785598755
recon_loss: 0.02914641797542572, dist_loss: 1.0936344861984253
recon_loss: 0.029144886881113052, dist_loss: 0.3816378116607666
recon_loss: 0.029143473133444786, dist_loss: 0.5664018988609314
recon_loss: 0.029143212363123894, dist_loss: 1.1088380813598633
recon_loss: 0.029143240302801132, dist_loss: 0.788558840751648
recon_loss: 0.029142042621970177, dist_loss: 1.1124365329742432
recon_loss: 0.02914181724190712, dist_loss: 0.5147838592529297
recon_loss: 0.029141878709197044, dist_loss: 0.8668713569641113
recon_loss: 0.02914167009294033, dist_loss: 0.7293118238449097
recon_loss: 0.02914133295416832, dist_loss: 0.5062568187713623
recon_loss: 0.029141046106815338, dist_loss: 0.8074365258216858
recon_loss: 0.02914126217365265, dist_loss: 0.4209364950656891
recon_loss: 0.0291416235268116, dist_loss: 0.8318294286727905
recon_loss: 0.02914188615977764, dist_loss: 0.6026021242141724
recon_loss: 0.029142191633582115, dist_loss: 0.4071163833141327
recon_loss: 0.02914237789809704, dist_loss: 0.7037354707717896
recon_loss: 0.029142452403903008, dist_loss: 0.362549364566803
recon_loss: 0.029142502695322037, dist_loss: 1.0826494693756104
recon_loss: 0.029142236337065697, dist_loss: 1.0884077548980713
recon_loss: 0.029141956940293312, dist_loss: 0.5813013315200806
recon_loss: 0.029141684994101524, dist_loss: 0.36848950386047363
recon_loss: 0.029141198843717575, dist_loss: 0.9422560334205627
recon_loss: 0.029140880331397057, dist_loss: 1.3435509204864502
recon_loss: 0.029140682891011238, dist_loss: 1.1188414096832275
recon_loss: 0.029140524566173553, dist_loss: 0.6942228078842163
recon_loss: 0.02914070524275303, dist_loss: 0.5110390782356262
recon_loss: 0.029141206294298172, dist_loss: 0.9676539897918701
recon_loss: 0.029141241684556007, dist_loss: 0.7172316312789917
recon_loss: 0.029141085222363472, dist_loss: 0.7399749755859375
recon_loss: 0.029140327125787735, dist_loss: 0.8365757465362549
recon_loss: 0.029140373691916466, dist_loss: 0.5744867324829102
recon_loss: 0.02914070151746273, dist_loss: 0.8236631155014038
recon_loss: 0.029141506180167198, dist_loss: 0.754294753074646
recon_loss: 0.029142087325453758, dist_loss: 0.5316336154937744
recon_loss: 0.029142653569579124, dist_loss: 0.9307937622070312
recon_loss: 0.029143009334802628, dist_loss: 0.654323935508728
recon_loss: 0.02914288267493248, dist_loss: 0.7213044166564941
recon_loss: 0.029142271727323532, dist_loss: 0.5439200401306152
recon_loss: 0.02914188615977764, dist_loss: 0.659886360168457
recon_loss: 0.029141170904040337, dist_loss: 0.4772767424583435
recon_loss: 0.029140330851078033, dist_loss: 1.1348836421966553
recon_loss: 0.029139423742890358, dist_loss: 0.9381287693977356
recon_loss: 0.029138879850506783, dist_loss: 0.5882107615470886
recon_loss: 0.029138190671801567, dist_loss: 0.7923449277877808
recon_loss: 0.029137544333934784, dist_loss: 0.40025731921195984
recon_loss: 0.029138118028640747, dist_loss: 0.6023998260498047
recon_loss: 0.029137974604964256, dist_loss: 0.3435790538787842
recon_loss: 0.029137494042515755, dist_loss: 0.4792809784412384
recon_loss: 0.029137659817934036, dist_loss: 0.47808361053466797
recon_loss: 0.0291376244276762, dist_loss: 0.41846853494644165
recon_loss: 0.02913692221045494, dist_loss: 0.4611241817474365
recon_loss: 0.029136834666132927, dist_loss: 1.3152045011520386
recon_loss: 0.029137106612324715, dist_loss: 1.2695852518081665
recon_loss: 0.029136186465620995, dist_loss: 0.41256123781204224
recon_loss: 0.029135994613170624, dist_loss: 0.8443479537963867
recon_loss: 0.029136160388588905, dist_loss: 0.32279279828071594
recon_loss: 0.029135670512914658, dist_loss: 1.1901609897613525
recon_loss: 0.029135454446077347, dist_loss: 0.6711562871932983
recon_loss: 0.029135718941688538, dist_loss: 0.42374640703201294
recon_loss: 0.029135767370462418, dist_loss: 1.0023176670074463
Pre-training Epoch 48:  35%|███▌      | 130/367 [00:00<00:01, 164.70it/s]Pre-training Epoch 48:  41%|████      | 150/367 [00:00<00:01, 173.22it/s]Pre-training Epoch 48:  46%|████▋     | 170/367 [00:01<00:01, 178.92it/s]Pre-training Epoch 48:  52%|█████▏    | 190/367 [00:01<00:00, 183.10it/s]Pre-training Epoch 48:  57%|█████▋    | 210/367 [00:01<00:00, 186.05it/s]Pre-training Epoch 48:  63%|██████▎   | 230/367 [00:01<00:00, 188.12it/s]Pre-training Epoch 48:  68%|██████▊   | 250/367 [00:01<00:00, 189.54it/s]recon_loss: 0.029135683551430702, dist_loss: 0.3979945778846741
recon_loss: 0.029136240482330322, dist_loss: 1.254298448562622
recon_loss: 0.029136477038264275, dist_loss: 0.7901750802993774
recon_loss: 0.02913701720535755, dist_loss: 0.9229942560195923
recon_loss: 0.029137304052710533, dist_loss: 0.8718698024749756
recon_loss: 0.029137054458260536, dist_loss: 0.8015986084938049
recon_loss: 0.029137253761291504, dist_loss: 0.685158371925354
recon_loss: 0.0291375070810318, dist_loss: 0.5461916923522949
recon_loss: 0.029137825593352318, dist_loss: 0.4732591509819031
recon_loss: 0.029137924313545227, dist_loss: 0.8189241886138916
recon_loss: 0.029137205332517624, dist_loss: 0.8184013366699219
recon_loss: 0.02913653291761875, dist_loss: 0.4503480792045593
recon_loss: 0.02913612499833107, dist_loss: 0.3924137353897095
recon_loss: 0.029135607182979584, dist_loss: 0.5955690145492554
recon_loss: 0.0291348397731781, dist_loss: 0.7540536522865295
recon_loss: 0.029134392738342285, dist_loss: 0.5219048261642456
recon_loss: 0.029133843258023262, dist_loss: 1.2959359884262085
recon_loss: 0.02913345955312252, dist_loss: 1.1272244453430176
recon_loss: 0.0291338749229908, dist_loss: 0.8311142921447754
recon_loss: 0.029134785756468773, dist_loss: 0.5213634967803955
recon_loss: 0.029135020449757576, dist_loss: 0.6116885542869568
recon_loss: 0.029134735465049744, dist_loss: 0.5425068140029907
recon_loss: 0.02913464605808258, dist_loss: 0.40373536944389343
recon_loss: 0.029134605079889297, dist_loss: 0.6833778023719788
recon_loss: 0.029134156182408333, dist_loss: 0.42969509959220886
recon_loss: 0.02913408912718296, dist_loss: 0.502950131893158
recon_loss: 0.02913365513086319, dist_loss: 0.6082273125648499
recon_loss: 0.02913299761712551, dist_loss: 0.8369746208190918
recon_loss: 0.029132487252354622, dist_loss: 0.676938533782959
recon_loss: 0.02913176454603672, dist_loss: 0.8932321071624756
recon_loss: 0.029131319373846054, dist_loss: 0.41114115715026855
recon_loss: 0.029131241142749786, dist_loss: 0.7944201231002808
recon_loss: 0.029130985960364342, dist_loss: 0.6631035804748535
recon_loss: 0.02913031354546547, dist_loss: 0.49817314743995667
recon_loss: 0.02913009002804756, dist_loss: 0.695031464099884
recon_loss: 0.02913021855056286, dist_loss: 0.5767916440963745
recon_loss: 0.0291303601115942, dist_loss: 1.1020997762680054
recon_loss: 0.029130054637789726, dist_loss: 0.44385722279548645
recon_loss: 0.02913016453385353, dist_loss: 0.5225661396980286
recon_loss: 0.029129961505532265, dist_loss: 1.141696810722351
recon_loss: 0.0291295126080513, dist_loss: 0.7783644199371338
recon_loss: 0.02912984974682331, dist_loss: 0.4673041105270386
recon_loss: 0.029130645096302032, dist_loss: 0.9799392223358154
recon_loss: 0.02913024090230465, dist_loss: 0.8369609713554382
recon_loss: 0.02912965416908264, dist_loss: 0.5344101786613464
recon_loss: 0.029129644855856895, dist_loss: 0.8280579447746277
recon_loss: 0.029129646718502045, dist_loss: 0.5190809965133667
recon_loss: 0.0291287899017334, dist_loss: 0.7148300409317017
recon_loss: 0.029128987342119217, dist_loss: 0.7301253080368042
recon_loss: 0.02912900783121586, dist_loss: 0.6658963561058044
recon_loss: 0.029128942638635635, dist_loss: 0.600651741027832
recon_loss: 0.029129453003406525, dist_loss: 0.7449334263801575
recon_loss: 0.029129117727279663, dist_loss: 1.0120928287506104
recon_loss: 0.029128611087799072, dist_loss: 0.4621458053588867
recon_loss: 0.029128963127732277, dist_loss: 0.531459391117096
recon_loss: 0.029128218069672585, dist_loss: 0.7646666169166565
recon_loss: 0.029127290472388268, dist_loss: 0.9947463274002075
recon_loss: 0.029127636924386024, dist_loss: 0.8987761735916138
recon_loss: 0.02912771701812744, dist_loss: 0.5650807619094849
recon_loss: 0.029127297922968864, dist_loss: 0.7318053841590881
recon_loss: 0.029127461835741997, dist_loss: 0.4447234272956848
recon_loss: 0.0291280597448349, dist_loss: 0.543118953704834
recon_loss: 0.02912798896431923, dist_loss: 0.5333404541015625
recon_loss: 0.02912752889096737, dist_loss: 0.5324053168296814
recon_loss: 0.029127802699804306, dist_loss: 1.0231508016586304
recon_loss: 0.029127374291419983, dist_loss: 0.6275098323822021
recon_loss: 0.02912667952477932, dist_loss: 0.578889787197113
recon_loss: 0.02912650629878044, dist_loss: 0.521976888179779
recon_loss: 0.029126087203621864, dist_loss: 0.4618281424045563
recon_loss: 0.029125496745109558, dist_loss: 0.6736650466918945
recon_loss: 0.029124710708856583, dist_loss: 1.0452678203582764
recon_loss: 0.029124325141310692, dist_loss: 0.4798046350479126
recon_loss: 0.029124055057764053, dist_loss: 1.115447998046875
recon_loss: 0.029124265536665916, dist_loss: 0.3791772723197937
recon_loss: 0.029123814776539803, dist_loss: 0.8691227436065674
recon_loss: 0.02912372164428234, dist_loss: 0.6597922444343567
recon_loss: 0.029124004766345024, dist_loss: 0.8169385194778442
recon_loss: 0.02912364900112152, dist_loss: 0.3840864300727844
recon_loss: 0.02912346087396145, dist_loss: 0.429490327835083
recon_loss: 0.029123663902282715, dist_loss: 0.2659710645675659
recon_loss: 0.0291236974298954, dist_loss: 0.42678767442703247
recon_loss: 0.029123518615961075, dist_loss: 0.6524073481559753
recon_loss: 0.029123684391379356, dist_loss: 0.9999542236328125
recon_loss: 0.029123760759830475, dist_loss: 0.6642438769340515
recon_loss: 0.02912282943725586, dist_loss: 0.3534480333328247
recon_loss: 0.029122596606612206, dist_loss: 0.8031059503555298
recon_loss: 0.029123587533831596, dist_loss: 0.26316213607788086
recon_loss: 0.029123052954673767, dist_loss: 0.6206191778182983
recon_loss: 0.029122604057192802, dist_loss: 0.6892862319946289
recon_loss: 0.02912318706512451, dist_loss: 0.5478438138961792
recon_loss: 0.029123177751898766, dist_loss: 0.6531015634536743
recon_loss: 0.029123062267899513, dist_loss: 0.3978942632675171
recon_loss: 0.029123498126864433, dist_loss: 0.7430156469345093
recon_loss: 0.029123496264219284, dist_loss: 0.5321022272109985
recon_loss: 0.029122471809387207, dist_loss: 0.5408619046211243
recon_loss: 0.029122155159711838, dist_loss: 0.5606764554977417
recon_loss: 0.029122794046998024, dist_loss: 0.605171799659729
recon_loss: 0.029122857376933098, dist_loss: 0.8600306510925293
recon_loss: 0.029122406616806984, dist_loss: 0.6997919082641602
recon_loss: 0.029121680185198784, dist_loss: 0.4249621331691742
recon_loss: 0.029121018946170807, dist_loss: 0.372225284576416
recon_loss: 0.029120471328496933, dist_loss: 0.47277623414993286
recon_loss: 0.02912072092294693, dist_loss: 0.7510052919387817
recon_loss: 0.029121218249201775, dist_loss: 0.8134886026382446
recon_loss: 0.02912210300564766, dist_loss: 1.1998401880264282
recon_loss: 0.02912275306880474, dist_loss: 0.6866490244865417
recon_loss: 0.02912275306880474, dist_loss: 0.7685492038726807
recon_loss: 0.029122088104486465, dist_loss: 0.4339953064918518
recon_loss: 0.02912181057035923, dist_loss: 0.7712458968162537
recon_loss: 0.029122281819581985, dist_loss: 0.7594427466392517
recon_loss: 0.029123196378350258, dist_loss: 0.5022604465484619
recon_loss: 0.029123788699507713, dist_loss: 0.8134428262710571
recon_loss: 0.029124511405825615, dist_loss: 0.8836069107055664
recon_loss: 0.02912505343556404, dist_loss: 0.39190444350242615
recon_loss: 0.029125023633241653, dist_loss: 0.516761064529419
recon_loss: 0.029124939814209938, dist_loss: 0.391555517911911
recon_loss: 0.029124395921826363, dist_loss: 0.6790612936019897
recon_loss: 0.029123246669769287, dist_loss: 0.5553808212280273
recon_loss: 0.02912244014441967, dist_loss: 0.8367293477058411
recon_loss: 0.029121538624167442, dist_loss: 0.876400351524353
recon_loss: 0.029120614752173424, dist_loss: 0.5970103740692139
recon_loss: 0.029119929298758507, dist_loss: 0.6728845238685608
recon_loss: 0.029119357466697693, dist_loss: 0.802854597568512
recon_loss: 0.029118524864315987, dist_loss: 0.7610242366790771
recon_loss: 0.029118232429027557, dist_loss: 0.8419575691223145
recon_loss: 0.02911781333386898, dist_loss: 0.6380266547203064
recon_loss: 0.02911711297929287, dist_loss: 0.7020817995071411
recon_loss: 0.029117532074451447, dist_loss: 0.8435972332954407
Pre-training Epoch 48:  74%|███████▎  | 270/367 [00:01<00:00, 190.53it/s]Pre-training Epoch 48:  79%|███████▉  | 290/367 [00:01<00:00, 191.23it/s]Pre-training Epoch 48:  84%|████████▍ | 310/367 [00:01<00:00, 191.35it/s]Pre-training Epoch 48:  90%|████████▉ | 330/367 [00:01<00:00, 189.65it/s]Pre-training Epoch 48:  95%|█████████▌| 350/367 [00:01<00:00, 190.56it/s]Pre-training Epoch 48: 100%|██████████| 367/367 [00:02<00:00, 177.46it/s]
recon_loss: 0.029117893427610397, dist_loss: 0.6678748726844788
recon_loss: 0.029117954894900322, dist_loss: 0.8236386179924011
recon_loss: 0.029117604717612267, dist_loss: 0.5062658190727234
recon_loss: 0.029117412865161896, dist_loss: 0.5994677543640137
recon_loss: 0.02911701612174511, dist_loss: 0.45329898595809937
recon_loss: 0.02911662869155407, dist_loss: 0.8960126638412476
recon_loss: 0.029116496443748474, dist_loss: 0.6904094219207764
recon_loss: 0.029116341844201088, dist_loss: 0.9295485019683838
recon_loss: 0.029115814715623856, dist_loss: 0.6310966610908508
recon_loss: 0.029115628451108932, dist_loss: 0.3570966124534607
recon_loss: 0.02911537140607834, dist_loss: 1.0884487628936768
recon_loss: 0.029115168377757072, dist_loss: 0.9516102075576782
recon_loss: 0.029114969074726105, dist_loss: 0.26666128635406494
recon_loss: 0.02911495603621006, dist_loss: 0.7911732196807861
recon_loss: 0.029114477336406708, dist_loss: 0.4862353801727295
recon_loss: 0.0291140154004097, dist_loss: 0.543040931224823
recon_loss: 0.029113711789250374, dist_loss: 0.6633168458938599
recon_loss: 0.0291135236620903, dist_loss: 0.8113169074058533
recon_loss: 0.029113713651895523, dist_loss: 0.7355046272277832
recon_loss: 0.029114089906215668, dist_loss: 0.6022987365722656
recon_loss: 0.02911471202969551, dist_loss: 0.7619460821151733
recon_loss: 0.029114793986082077, dist_loss: 0.6402254104614258
recon_loss: 0.029114441946148872, dist_loss: 0.6832400560379028
recon_loss: 0.02911422774195671, dist_loss: 0.6976794004440308
recon_loss: 0.02911420352756977, dist_loss: 0.6407470703125
recon_loss: 0.02911432646214962, dist_loss: 0.7447872757911682
recon_loss: 0.029114773496985435, dist_loss: 0.3841022253036499
recon_loss: 0.029114803299307823, dist_loss: 0.5078078508377075
recon_loss: 0.0291146170347929, dist_loss: 0.31323814392089844
recon_loss: 0.029114488512277603, dist_loss: 0.57744961977005
recon_loss: 0.02911333739757538, dist_loss: 0.6973096132278442
recon_loss: 0.029112601652741432, dist_loss: 0.5575386881828308
recon_loss: 0.029112480580806732, dist_loss: 0.815153956413269
recon_loss: 0.029111912474036217, dist_loss: 0.5891748666763306
recon_loss: 0.029111193493008614, dist_loss: 0.7737888097763062
recon_loss: 0.029111362993717194, dist_loss: 0.762024998664856
recon_loss: 0.029111506417393684, dist_loss: 0.9005230665206909
recon_loss: 0.029110953211784363, dist_loss: 0.6472858190536499
recon_loss: 0.02911113016307354, dist_loss: 0.612023115158081
recon_loss: 0.029110826551914215, dist_loss: 0.9160634279251099
recon_loss: 0.02911032922565937, dist_loss: 0.7717189192771912
recon_loss: 0.02911023050546646, dist_loss: 0.8080742359161377
recon_loss: 0.02911016345024109, dist_loss: 0.7124539017677307
recon_loss: 0.029109900817275047, dist_loss: 0.8673036098480225
recon_loss: 0.02911006659269333, dist_loss: 1.1505420207977295
recon_loss: 0.02911035157740116, dist_loss: 0.4188350439071655
recon_loss: 0.029110349714756012, dist_loss: 0.9404721856117249
recon_loss: 0.029110180214047432, dist_loss: 0.42125508189201355
recon_loss: 0.02911020815372467, dist_loss: 0.5285528898239136
recon_loss: 0.029110420495271683, dist_loss: 0.30086809396743774
recon_loss: 0.029110755771398544, dist_loss: 0.38247352838516235
recon_loss: 0.02911139279603958, dist_loss: 0.417807936668396
recon_loss: 0.029112495481967926, dist_loss: 0.3923298120498657
recon_loss: 0.02911257930099964, dist_loss: 0.4566551446914673
recon_loss: 0.029111593961715698, dist_loss: 0.5850816965103149
recon_loss: 0.029111173003911972, dist_loss: 0.3496738374233246
recon_loss: 0.02911110781133175, dist_loss: 0.6394908428192139
recon_loss: 0.02911153808236122, dist_loss: 0.7953265905380249
recon_loss: 0.029111960902810097, dist_loss: 1.0174915790557861
recon_loss: 0.029112108051776886, dist_loss: 0.4124450981616974
recon_loss: 0.029111968353390694, dist_loss: 0.554364800453186
recon_loss: 0.029111526906490326, dist_loss: 0.7727416753768921
recon_loss: 0.029111020267009735, dist_loss: 0.6552540063858032
recon_loss: 0.029110660776495934, dist_loss: 0.42279577255249023
recon_loss: 0.029110165312886238, dist_loss: 0.49519604444503784
recon_loss: 0.029109841212630272, dist_loss: 1.1044739484786987
recon_loss: 0.029109658673405647, dist_loss: 0.43158620595932007
recon_loss: 0.029109440743923187, dist_loss: 0.36619988083839417
recon_loss: 0.029108963906764984, dist_loss: 0.47482380270957947
recon_loss: 0.02910873293876648, dist_loss: 0.9341345429420471
recon_loss: 0.029108740389347076, dist_loss: 0.7120000123977661
recon_loss: 0.02910890243947506, dist_loss: 0.6977345943450928
recon_loss: 0.0291097741574049, dist_loss: 0.42103010416030884
recon_loss: 0.02910974994301796, dist_loss: 0.5938007831573486
recon_loss: 0.029109463095664978, dist_loss: 0.6422783136367798
recon_loss: 0.029109597206115723, dist_loss: 0.5728397369384766
recon_loss: 0.029109148308634758, dist_loss: 1.204749584197998
recon_loss: 0.029109584167599678, dist_loss: 0.45220136642456055
recon_loss: 0.029110100120306015, dist_loss: 0.9935323596000671
recon_loss: 0.029109671711921692, dist_loss: 0.4724622964859009
recon_loss: 0.029109714552760124, dist_loss: 1.0226085186004639
recon_loss: 0.02910899557173252, dist_loss: 0.46360164880752563
recon_loss: 0.029107792302966118, dist_loss: 0.25687849521636963
recon_loss: 0.029107268899679184, dist_loss: 0.8913048505783081
recon_loss: 0.029107561334967613, dist_loss: 0.6427297592163086
recon_loss: 0.029107626527547836, dist_loss: 0.7119555473327637
recon_loss: 0.02910708263516426, dist_loss: 0.8504887223243713
recon_loss: 0.029107162728905678, dist_loss: 0.8852356672286987
recon_loss: 0.029106834903359413, dist_loss: 0.556786060333252
recon_loss: 0.02910609357059002, dist_loss: 0.5959492921829224
recon_loss: 0.02910606749355793, dist_loss: 0.4298202097415924
recon_loss: 0.029106106609106064, dist_loss: 0.8561854362487793
recon_loss: 0.02910587377846241, dist_loss: 0.3507964611053467
recon_loss: 0.029105691239237785, dist_loss: 0.6190073490142822
recon_loss: 0.029105449095368385, dist_loss: 0.29867345094680786
recon_loss: 0.029104899615049362, dist_loss: 0.8388144969940186
recon_loss: 0.029104722663760185, dist_loss: 0.44348928332328796
recon_loss: 0.02910492941737175, dist_loss: 0.4625402092933655
recon_loss: 0.029104651883244514, dist_loss: 0.5380243062973022
recon_loss: 0.029104679822921753, dist_loss: 0.31455299258232117
recon_loss: 0.029104817658662796, dist_loss: 0.4947945177555084
recon_loss: 0.02910400927066803, dist_loss: 0.4850620627403259
recon_loss: 0.02910366654396057, dist_loss: 0.6402075290679932
recon_loss: 0.029103968292474747, dist_loss: 0.4969509243965149
recon_loss: 0.029103633016347885, dist_loss: 0.9904876947402954
recon_loss: 0.0291034784168005, dist_loss: 1.1056745052337646
recon_loss: 0.029103953391313553, dist_loss: 0.7046236991882324
recon_loss: 0.029103847220540047, dist_loss: 0.5387020111083984
recon_loss: 0.0291032325476408, dist_loss: 0.3863009810447693
recon_loss: 0.02910362370312214, dist_loss: 0.8560004830360413
recon_loss: 0.029103165492415428, dist_loss: 1.1671193838119507
Pre-training Epoch 49:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 49:   5%|▌         | 19/367 [00:00<00:01, 187.44it/s]Pre-training Epoch 49:  11%|█         | 39/367 [00:00<00:01, 189.49it/s]Pre-training Epoch 49:  16%|█▌        | 59/367 [00:00<00:01, 190.88it/s]Pre-training Epoch 49:  22%|██▏       | 79/367 [00:00<00:01, 191.41it/s]Pre-training Epoch 49:  27%|██▋       | 99/367 [00:00<00:01, 191.77it/s]Pre-training Epoch 49:  32%|███▏      | 119/367 [00:00<00:01, 192.06it/s]recon_loss: 0.02910381741821766, dist_loss: 0.8020159006118774
recon_loss: 0.02910509705543518, dist_loss: 0.5027427673339844
recon_loss: 0.029103610664606094, dist_loss: 0.635073184967041
recon_loss: 0.029103221371769905, dist_loss: 0.6426114439964294
recon_loss: 0.029104091227054596, dist_loss: 0.6682242751121521
recon_loss: 0.029103925451636314, dist_loss: 0.5686633586883545
recon_loss: 0.029103290289640427, dist_loss: 0.6329715251922607
recon_loss: 0.029104124754667282, dist_loss: 1.1095435619354248
recon_loss: 0.029104556888341904, dist_loss: 0.5818138718605042
recon_loss: 0.029103776440024376, dist_loss: 0.478874146938324
recon_loss: 0.02910306304693222, dist_loss: 0.6878255605697632
recon_loss: 0.029101500287652016, dist_loss: 0.5831224322319031
recon_loss: 0.029100731015205383, dist_loss: 0.5093892812728882
recon_loss: 0.029100550338625908, dist_loss: 0.4657541811466217
recon_loss: 0.029100554063916206, dist_loss: 0.6677085757255554
recon_loss: 0.02910039573907852, dist_loss: 0.973233163356781
recon_loss: 0.029099954292178154, dist_loss: 0.4933759570121765
recon_loss: 0.029099714010953903, dist_loss: 0.9677005410194397
recon_loss: 0.029099836945533752, dist_loss: 0.4735430181026459
recon_loss: 0.02910015732049942, dist_loss: 1.0088071823120117
recon_loss: 0.02910125069320202, dist_loss: 0.6588627099990845
recon_loss: 0.02910248562693596, dist_loss: 0.8606257438659668
recon_loss: 0.02910369448363781, dist_loss: 0.6609212160110474
recon_loss: 0.029104826971888542, dist_loss: 0.5558713674545288
recon_loss: 0.029105618596076965, dist_loss: 0.6135364770889282
recon_loss: 0.02910560928285122, dist_loss: 0.6151067614555359
recon_loss: 0.029105180874466896, dist_loss: 0.8707731366157532
recon_loss: 0.02910500019788742, dist_loss: 0.531177282333374
recon_loss: 0.029106052592396736, dist_loss: 1.0421843528747559
recon_loss: 0.029106520116329193, dist_loss: 0.9460435509681702
recon_loss: 0.02910558506846428, dist_loss: 0.5513603091239929
recon_loss: 0.029105642810463905, dist_loss: 0.2835692763328552
recon_loss: 0.029104581102728844, dist_loss: 0.6117293834686279
recon_loss: 0.02910306677222252, dist_loss: 1.136490821838379
recon_loss: 0.029102127999067307, dist_loss: 1.105218529701233
recon_loss: 0.029101284220814705, dist_loss: 0.5495494604110718
recon_loss: 0.029099835082888603, dist_loss: 0.5614390969276428
recon_loss: 0.02909904718399048, dist_loss: 0.7775141596794128
recon_loss: 0.02909831330180168, dist_loss: 0.4640689492225647
recon_loss: 0.029097558930516243, dist_loss: 1.0369303226470947
recon_loss: 0.029097145423293114, dist_loss: 0.4751613140106201
recon_loss: 0.02909783087670803, dist_loss: 0.4842158257961273
recon_loss: 0.029097914695739746, dist_loss: 0.5196627378463745
recon_loss: 0.029097843915224075, dist_loss: 0.7391396760940552
recon_loss: 0.02909884974360466, dist_loss: 1.2088887691497803
recon_loss: 0.029098639264702797, dist_loss: 0.4858601987361908
recon_loss: 0.029098419472575188, dist_loss: 0.5418657064437866
recon_loss: 0.029098911210894585, dist_loss: 0.480598509311676
recon_loss: 0.02909911423921585, dist_loss: 0.6898078918457031
recon_loss: 0.029099024832248688, dist_loss: 0.5958224534988403
recon_loss: 0.02909918501973152, dist_loss: 0.5022996664047241
recon_loss: 0.029099082574248314, dist_loss: 1.2813246250152588
recon_loss: 0.029098043218255043, dist_loss: 0.7702485918998718
recon_loss: 0.029097873717546463, dist_loss: 0.5601177215576172
recon_loss: 0.0290970541536808, dist_loss: 0.6540749073028564
recon_loss: 0.02909577451646328, dist_loss: 0.6758456230163574
recon_loss: 0.0290953628718853, dist_loss: 0.4640856981277466
recon_loss: 0.02909471094608307, dist_loss: 1.1138880252838135
recon_loss: 0.029094455763697624, dist_loss: 0.8946438431739807
recon_loss: 0.029094142839312553, dist_loss: 0.9018739461898804
recon_loss: 0.02909398078918457, dist_loss: 0.7734453678131104
recon_loss: 0.029093734920024872, dist_loss: 0.357774019241333
recon_loss: 0.02909340336918831, dist_loss: 0.6652902364730835
recon_loss: 0.029093310236930847, dist_loss: 0.6256251335144043
recon_loss: 0.029093271121382713, dist_loss: 0.9333446025848389
recon_loss: 0.02909320779144764, dist_loss: 0.4966343939304352
recon_loss: 0.02909313142299652, dist_loss: 0.5877391695976257
recon_loss: 0.02909298613667488, dist_loss: 0.5941480398178101
recon_loss: 0.029092703014612198, dist_loss: 0.6376344561576843
recon_loss: 0.029092444106936455, dist_loss: 0.42014583945274353
recon_loss: 0.029092315584421158, dist_loss: 0.4142377972602844
recon_loss: 0.029092218726873398, dist_loss: 0.7367051243782043
recon_loss: 0.029092133045196533, dist_loss: 0.6207417845726013
recon_loss: 0.029091820120811462, dist_loss: 0.38893070816993713
recon_loss: 0.029092181473970413, dist_loss: 0.993769645690918
recon_loss: 0.02909196726977825, dist_loss: 0.49896764755249023
recon_loss: 0.029091861099004745, dist_loss: 0.5309886932373047
recon_loss: 0.02909187786281109, dist_loss: 0.7592034339904785
recon_loss: 0.029091492295265198, dist_loss: 0.4829612970352173
recon_loss: 0.02909131348133087, dist_loss: 0.5443534255027771
recon_loss: 0.029091712087392807, dist_loss: 1.0855047702789307
recon_loss: 0.029091814532876015, dist_loss: 0.738233208656311
recon_loss: 0.029091160744428635, dist_loss: 0.4237223267555237
recon_loss: 0.029091041535139084, dist_loss: 0.4028155207633972
recon_loss: 0.02909093163907528, dist_loss: 0.34200236201286316
recon_loss: 0.029090940952301025, dist_loss: 0.6419574022293091
recon_loss: 0.0290916059166193, dist_loss: 1.0458661317825317
recon_loss: 0.02909184619784355, dist_loss: 0.5376719832420349
recon_loss: 0.029091084375977516, dist_loss: 0.672015368938446
recon_loss: 0.029090801253914833, dist_loss: 0.8489788770675659
recon_loss: 0.02909027971327305, dist_loss: 0.7070732116699219
recon_loss: 0.029089929535984993, dist_loss: 0.5440587997436523
recon_loss: 0.02909017726778984, dist_loss: 0.41486650705337524
recon_loss: 0.029089845716953278, dist_loss: 0.4027303457260132
recon_loss: 0.029089458286762238, dist_loss: 0.41772711277008057
recon_loss: 0.029089251533150673, dist_loss: 0.5063855648040771
recon_loss: 0.029089100658893585, dist_loss: 0.6718440651893616
recon_loss: 0.029088839888572693, dist_loss: 1.1101248264312744
recon_loss: 0.02908901311457157, dist_loss: 0.5297082662582397
recon_loss: 0.029089175164699554, dist_loss: 1.170578956604004
recon_loss: 0.029089394956827164, dist_loss: 0.4586460292339325
recon_loss: 0.029089676216244698, dist_loss: 0.5857713222503662
recon_loss: 0.029089856892824173, dist_loss: 0.4751879870891571
recon_loss: 0.02908960171043873, dist_loss: 1.08853018283844
recon_loss: 0.029089633375406265, dist_loss: 0.7253641486167908
recon_loss: 0.029089637100696564, dist_loss: 0.7731830477714539
recon_loss: 0.029090166091918945, dist_loss: 0.5976361632347107
recon_loss: 0.02909027226269245, dist_loss: 0.5866180658340454
recon_loss: 0.029090004041790962, dist_loss: 0.3934422731399536
recon_loss: 0.029090547934174538, dist_loss: 0.6050523519515991
recon_loss: 0.029090426862239838, dist_loss: 0.6665318012237549
recon_loss: 0.029089998453855515, dist_loss: 0.5458744168281555
recon_loss: 0.029090069234371185, dist_loss: 0.8944195508956909
recon_loss: 0.029089419171214104, dist_loss: 0.5002907514572144
recon_loss: 0.029089229181408882, dist_loss: 0.8803995847702026
recon_loss: 0.02908947505056858, dist_loss: 1.0641907453536987
recon_loss: 0.02908977121114731, dist_loss: 0.43436163663864136
recon_loss: 0.02909000590443611, dist_loss: 1.0262720584869385
recon_loss: 0.029090043157339096, dist_loss: 0.8753793239593506
recon_loss: 0.029090354219079018, dist_loss: 0.6569423675537109
recon_loss: 0.02909059077501297, dist_loss: 0.8777430057525635
recon_loss: 0.029091060161590576, dist_loss: 0.619928240776062
recon_loss: 0.02909141220152378, dist_loss: 0.9428632855415344
recon_loss: 0.029091915115714073, dist_loss: 0.6372220516204834
recon_loss: 0.02909194491803646, dist_loss: 0.3875058591365814
recon_loss: 0.029091384261846542, dist_loss: 0.8905668258666992
recon_loss: 0.02909068949520588, dist_loss: 0.6323355436325073
recon_loss: 0.02909024804830551, dist_loss: 0.6333069801330566
Pre-training Epoch 49:  38%|███▊      | 139/367 [00:00<00:01, 192.23it/s]Pre-training Epoch 49:  43%|████▎     | 159/367 [00:00<00:01, 192.29it/s]Pre-training Epoch 49:  49%|████▉     | 179/367 [00:00<00:00, 192.48it/s]Pre-training Epoch 49:  54%|█████▍    | 199/367 [00:01<00:00, 192.54it/s]Pre-training Epoch 49:  60%|█████▉    | 219/367 [00:01<00:00, 192.37it/s]Pre-training Epoch 49:  65%|██████▌   | 239/367 [00:01<00:00, 192.16it/s]recon_loss: 0.029089132323861122, dist_loss: 0.7572383880615234
recon_loss: 0.029088638722896576, dist_loss: 0.6031894683837891
recon_loss: 0.029088106006383896, dist_loss: 0.7301577925682068
recon_loss: 0.0290873683989048, dist_loss: 0.426138311624527
recon_loss: 0.029086727648973465, dist_loss: 1.0234105587005615
recon_loss: 0.029086213558912277, dist_loss: 0.7171314358711243
recon_loss: 0.029085855931043625, dist_loss: 0.6264391541481018
recon_loss: 0.0290855523198843, dist_loss: 0.6325260996818542
recon_loss: 0.029085423797369003, dist_loss: 0.8712259531021118
recon_loss: 0.029085488989949226, dist_loss: 0.6526678800582886
recon_loss: 0.02908562496304512, dist_loss: 0.5834266543388367
recon_loss: 0.02908536046743393, dist_loss: 0.6122825145721436
recon_loss: 0.029085488989949226, dist_loss: 0.749503493309021
recon_loss: 0.029085572808980942, dist_loss: 0.7000818252563477
recon_loss: 0.029085392132401466, dist_loss: 0.7258396744728088
recon_loss: 0.02908501774072647, dist_loss: 0.5654468536376953
recon_loss: 0.029085427522659302, dist_loss: 0.6819638013839722
recon_loss: 0.029085280373692513, dist_loss: 0.6461814045906067
recon_loss: 0.02908489853143692, dist_loss: 0.5675916075706482
recon_loss: 0.029085122048854828, dist_loss: 0.6919224262237549
recon_loss: 0.029085231944918633, dist_loss: 0.48342472314834595
recon_loss: 0.029084863141179085, dist_loss: 0.5915955305099487
recon_loss: 0.029085157439112663, dist_loss: 0.6824290156364441
recon_loss: 0.02908528968691826, dist_loss: 0.6750741004943848
recon_loss: 0.029084937646985054, dist_loss: 0.6137663722038269
recon_loss: 0.029085461050271988, dist_loss: 0.45106685161590576
recon_loss: 0.02908485382795334, dist_loss: 0.5152159929275513
recon_loss: 0.0290849506855011, dist_loss: 0.5290555357933044
recon_loss: 0.029085351154208183, dist_loss: 1.0144596099853516
recon_loss: 0.02908477559685707, dist_loss: 0.7398971915245056
recon_loss: 0.02908492088317871, dist_loss: 0.7832608819007874
recon_loss: 0.029084615409374237, dist_loss: 0.7272478342056274
recon_loss: 0.029084280133247375, dist_loss: 0.5470921993255615
recon_loss: 0.029084274545311928, dist_loss: 0.8852700591087341
recon_loss: 0.029085179790854454, dist_loss: 0.6867247819900513
recon_loss: 0.029084518551826477, dist_loss: 0.6860978603363037
recon_loss: 0.029084108769893646, dist_loss: 0.6329759955406189
recon_loss: 0.029084879904985428, dist_loss: 0.5599651336669922
recon_loss: 0.0290842242538929, dist_loss: 0.7430257797241211
recon_loss: 0.029083140194416046, dist_loss: 0.5277217030525208
recon_loss: 0.02908444032073021, dist_loss: 0.5306514501571655
recon_loss: 0.029083745554089546, dist_loss: 0.4956601858139038
recon_loss: 0.02908257022500038, dist_loss: 0.4903576076030731
recon_loss: 0.029083317145705223, dist_loss: 0.7682726383209229
recon_loss: 0.029082736000418663, dist_loss: 1.3908053636550903
recon_loss: 0.02908218465745449, dist_loss: 0.7045289278030396
recon_loss: 0.029082398861646652, dist_loss: 0.8734484910964966
recon_loss: 0.02908184379339218, dist_loss: 0.7216517329216003
recon_loss: 0.029081866145133972, dist_loss: 0.8807482719421387
recon_loss: 0.02908298559486866, dist_loss: 1.1448307037353516
recon_loss: 0.029082708060741425, dist_loss: 0.5389814376831055
recon_loss: 0.029081756249070168, dist_loss: 0.3556332588195801
recon_loss: 0.029082799330353737, dist_loss: 0.9328197836875916
recon_loss: 0.029082605615258217, dist_loss: 1.3733317852020264
recon_loss: 0.029081884771585464, dist_loss: 0.7889375686645508
recon_loss: 0.029083047062158585, dist_loss: 0.3751545250415802
recon_loss: 0.029083404690027237, dist_loss: 0.3864096403121948
recon_loss: 0.029082316905260086, dist_loss: 0.7220814824104309
recon_loss: 0.029083408415317535, dist_loss: 0.29750949144363403
recon_loss: 0.029082922264933586, dist_loss: 0.6732709407806396
recon_loss: 0.029082374647259712, dist_loss: 0.954738199710846
recon_loss: 0.029083119705319405, dist_loss: 0.619215726852417
recon_loss: 0.02908281981945038, dist_loss: 0.356320321559906
recon_loss: 0.029081616550683975, dist_loss: 0.3173609972000122
recon_loss: 0.029081469401717186, dist_loss: 0.7636860609054565
recon_loss: 0.029080625623464584, dist_loss: 1.1462953090667725
recon_loss: 0.029079744592308998, dist_loss: 0.38203760981559753
recon_loss: 0.02908010222017765, dist_loss: 0.8621546626091003
recon_loss: 0.029080713167786598, dist_loss: 0.6083292961120605
recon_loss: 0.029080254957079887, dist_loss: 0.6348814368247986
recon_loss: 0.029080329462885857, dist_loss: 0.43753862380981445
recon_loss: 0.029079526662826538, dist_loss: 0.4315989911556244
recon_loss: 0.029078012332320213, dist_loss: 0.36373305320739746
recon_loss: 0.029079144820570946, dist_loss: 0.6832481622695923
recon_loss: 0.02907944656908512, dist_loss: 0.4237239360809326
recon_loss: 0.029079299420118332, dist_loss: 0.5793664455413818
recon_loss: 0.029079489409923553, dist_loss: 0.4435294270515442
recon_loss: 0.029079848900437355, dist_loss: 1.0085546970367432
recon_loss: 0.029079316183924675, dist_loss: 1.0795605182647705
recon_loss: 0.029079494997859, dist_loss: 0.41816574335098267
recon_loss: 0.029079800471663475, dist_loss: 0.7285673022270203
recon_loss: 0.029080165550112724, dist_loss: 0.5654337406158447
recon_loss: 0.02908017300069332, dist_loss: 0.530306339263916
recon_loss: 0.02908078208565712, dist_loss: 0.6538227200508118
recon_loss: 0.02908041700720787, dist_loss: 0.9185167551040649
recon_loss: 0.02908000536262989, dist_loss: 0.8104724884033203
recon_loss: 0.029079319909214973, dist_loss: 0.4364997148513794
recon_loss: 0.02907835878431797, dist_loss: 0.5377711653709412
recon_loss: 0.02907724305987358, dist_loss: 0.5311676859855652
recon_loss: 0.029076270759105682, dist_loss: 1.1179311275482178
recon_loss: 0.029075700789690018, dist_loss: 0.471118688583374
recon_loss: 0.029075372964143753, dist_loss: 0.6995611786842346
recon_loss: 0.02907516062259674, dist_loss: 0.5836688280105591
recon_loss: 0.029074817895889282, dist_loss: 0.463792085647583
recon_loss: 0.029074689373373985, dist_loss: 0.5153933763504028
recon_loss: 0.02907554805278778, dist_loss: 0.9147504568099976
recon_loss: 0.029076164588332176, dist_loss: 0.9422488212585449
recon_loss: 0.02907704934477806, dist_loss: 0.9942775368690491
recon_loss: 0.029078146442770958, dist_loss: 0.4607623219490051
recon_loss: 0.02907855063676834, dist_loss: 1.3248765468597412
recon_loss: 0.029078707098960876, dist_loss: 0.6629796028137207
recon_loss: 0.02907901257276535, dist_loss: 0.8117828369140625
recon_loss: 0.029079599305987358, dist_loss: 0.6035510897636414
recon_loss: 0.029079535976052284, dist_loss: 0.6154485940933228
recon_loss: 0.029079722240567207, dist_loss: 0.5199441313743591
recon_loss: 0.029079532250761986, dist_loss: 0.4472184479236603
recon_loss: 0.02907821722328663, dist_loss: 1.1276702880859375
recon_loss: 0.029077015817165375, dist_loss: 0.4354844093322754
recon_loss: 0.029076289385557175, dist_loss: 0.408904492855072
recon_loss: 0.029074907302856445, dist_loss: 0.6461328268051147
recon_loss: 0.029073528945446014, dist_loss: 0.8644077777862549
recon_loss: 0.029072679579257965, dist_loss: 0.5726141929626465
recon_loss: 0.02907266654074192, dist_loss: 0.8270584344863892
recon_loss: 0.029072213917970657, dist_loss: 0.5724284648895264
recon_loss: 0.029071900993585587, dist_loss: 0.9376903772354126
recon_loss: 0.029072444885969162, dist_loss: 0.7550022602081299
recon_loss: 0.029072877019643784, dist_loss: 0.6823084354400635
recon_loss: 0.029072577133774757, dist_loss: 0.8073861002922058
recon_loss: 0.029072655364871025, dist_loss: 0.3933614492416382
recon_loss: 0.02907302975654602, dist_loss: 0.6257134079933167
recon_loss: 0.029073353856801987, dist_loss: 0.6586316227912903
recon_loss: 0.02907385490834713, dist_loss: 0.747427225112915
recon_loss: 0.02907460369169712, dist_loss: 0.6279518604278564
recon_loss: 0.029075192287564278, dist_loss: 0.8644813895225525
recon_loss: 0.02907591685652733, dist_loss: 1.1017065048217773
recon_loss: 0.029075732454657555, dist_loss: 0.6289108395576477
recon_loss: 0.029075216501951218, dist_loss: 0.7058031558990479
recon_loss: 0.029075194150209427, dist_loss: 0.8420277833938599
Pre-training Epoch 49:  71%|███████   | 259/367 [00:01<00:00, 192.22it/s]Pre-training Epoch 49:  76%|███████▌  | 279/367 [00:01<00:00, 192.21it/s]Pre-training Epoch 49:  81%|████████▏ | 299/367 [00:01<00:00, 192.30it/s]Pre-training Epoch 49:  87%|████████▋ | 319/367 [00:01<00:00, 192.40it/s]Pre-training Epoch 49:  92%|█████████▏| 339/367 [00:01<00:00, 192.50it/s]Pre-training Epoch 49:  98%|█████████▊| 359/367 [00:01<00:00, 192.62it/s]Pre-training Epoch 49: 100%|██████████| 367/367 [00:01<00:00, 192.05it/s]
recon_loss: 0.029075169935822487, dist_loss: 0.6545528173446655
recon_loss: 0.029074575752019882, dist_loss: 0.48205411434173584
recon_loss: 0.029074016958475113, dist_loss: 0.5075860619544983
recon_loss: 0.029073314741253853, dist_loss: 0.47634172439575195
recon_loss: 0.029072348028421402, dist_loss: 0.9898797273635864
recon_loss: 0.029071317985653877, dist_loss: 0.4340716600418091
recon_loss: 0.029070379212498665, dist_loss: 1.0098457336425781
recon_loss: 0.02906971238553524, dist_loss: 0.6478473544120789
recon_loss: 0.029069222509860992, dist_loss: 0.47378087043762207
recon_loss: 0.029069021344184875, dist_loss: 0.7116862535476685
recon_loss: 0.02906898967921734, dist_loss: 0.7092236280441284
recon_loss: 0.029068876057863235, dist_loss: 0.781342625617981
recon_loss: 0.02906872145831585, dist_loss: 0.523314356803894
recon_loss: 0.029068579897284508, dist_loss: 0.973483145236969
recon_loss: 0.02906840667128563, dist_loss: 0.8526996374130249
recon_loss: 0.029068268835544586, dist_loss: 0.5850778222084045
recon_loss: 0.02906814217567444, dist_loss: 0.6686895489692688
recon_loss: 0.02906816639006138, dist_loss: 0.5841705799102783
recon_loss: 0.029068181291222572, dist_loss: 0.5616220831871033
recon_loss: 0.029068054631352425, dist_loss: 0.561463475227356
recon_loss: 0.02906787395477295, dist_loss: 0.9487650990486145
recon_loss: 0.02906770072877407, dist_loss: 0.4290601909160614
recon_loss: 0.02906743809580803, dist_loss: 0.45310673117637634
recon_loss: 0.02906710095703602, dist_loss: 0.32676103711128235
recon_loss: 0.02906687743961811, dist_loss: 0.6088162660598755
recon_loss: 0.02906676009297371, dist_loss: 0.7696718573570251
recon_loss: 0.02906658686697483, dist_loss: 0.46241462230682373
recon_loss: 0.02906634844839573, dist_loss: 0.5486555099487305
recon_loss: 0.029066357761621475, dist_loss: 0.37499600648880005
recon_loss: 0.029065923765301704, dist_loss: 0.6744745969772339
recon_loss: 0.029065735638141632, dist_loss: 0.4437643587589264
recon_loss: 0.02906583808362484, dist_loss: 0.7798247337341309
recon_loss: 0.029065577313303947, dist_loss: 0.6060879826545715
recon_loss: 0.029066015034914017, dist_loss: 0.7321349382400513
recon_loss: 0.029065990820527077, dist_loss: 0.7605802416801453
recon_loss: 0.029065951704978943, dist_loss: 0.2721989154815674
recon_loss: 0.029066063463687897, dist_loss: 0.6924702525138855
recon_loss: 0.02906585857272148, dist_loss: 0.8837541341781616
recon_loss: 0.029065590351819992, dist_loss: 0.6557736396789551
recon_loss: 0.029065880924463272, dist_loss: 0.8197059631347656
recon_loss: 0.029065841808915138, dist_loss: 0.7059510946273804
recon_loss: 0.02906562201678753, dist_loss: 0.7006127834320068
recon_loss: 0.02906549908220768, dist_loss: 0.7160233855247498
recon_loss: 0.02906479686498642, dist_loss: 0.4549599587917328
recon_loss: 0.029064331203699112, dist_loss: 0.611129641532898
recon_loss: 0.02906418778002262, dist_loss: 0.5794417858123779
recon_loss: 0.02906453236937523, dist_loss: 0.8276338577270508
recon_loss: 0.029065033420920372, dist_loss: 0.7791587710380554
recon_loss: 0.029065608978271484, dist_loss: 0.6102927923202515
recon_loss: 0.029065605252981186, dist_loss: 0.6159697771072388
recon_loss: 0.029065655544400215, dist_loss: 0.5598540306091309
recon_loss: 0.029065852984786034, dist_loss: 0.5034981966018677
recon_loss: 0.029066015034914017, dist_loss: 1.5738847255706787
recon_loss: 0.02906622365117073, dist_loss: 0.42628180980682373
recon_loss: 0.029066026210784912, dist_loss: 0.3478529453277588
recon_loss: 0.0290659312158823, dist_loss: 0.7443128824234009
recon_loss: 0.02906659245491028, dist_loss: 0.5781496167182922
recon_loss: 0.02906634286046028, dist_loss: 0.6008332371711731
recon_loss: 0.029066255316138268, dist_loss: 0.5091246366500854
recon_loss: 0.029065901413559914, dist_loss: 0.7721350193023682
recon_loss: 0.029065189883112907, dist_loss: 0.37145793437957764
recon_loss: 0.029064703732728958, dist_loss: 0.7847574353218079
recon_loss: 0.029063956812024117, dist_loss: 0.5251616835594177
recon_loss: 0.02906356193125248, dist_loss: 0.5664230585098267
recon_loss: 0.029063312336802483, dist_loss: 0.39766043424606323
recon_loss: 0.029063047841191292, dist_loss: 0.8447585105895996
recon_loss: 0.02906309999525547, dist_loss: 0.7003589272499084
recon_loss: 0.029063431546092033, dist_loss: 0.6001521944999695
recon_loss: 0.029063601046800613, dist_loss: 0.6814807057380676
recon_loss: 0.029064225032925606, dist_loss: 0.8911638855934143
recon_loss: 0.02906491421163082, dist_loss: 0.49353376030921936
recon_loss: 0.029065720736980438, dist_loss: 0.6445345878601074
recon_loss: 0.02906622551381588, dist_loss: 1.0560815334320068
recon_loss: 0.029065534472465515, dist_loss: 0.9633594751358032
recon_loss: 0.029065556824207306, dist_loss: 0.4767267107963562
recon_loss: 0.029065445065498352, dist_loss: 1.0633659362792969
recon_loss: 0.029065268114209175, dist_loss: 1.281482458114624
recon_loss: 0.029065238311886787, dist_loss: 0.7193063497543335
recon_loss: 0.029065174981951714, dist_loss: 0.6036662459373474
recon_loss: 0.029064299538731575, dist_loss: 0.914008378982544
recon_loss: 0.029063841328024864, dist_loss: 0.4351760745048523
recon_loss: 0.02906383015215397, dist_loss: 0.6623421907424927
recon_loss: 0.029062844812870026, dist_loss: 0.7606422901153564
recon_loss: 0.02906201221048832, dist_loss: 0.834847629070282
recon_loss: 0.02906150557100773, dist_loss: 0.4767012596130371
recon_loss: 0.02906091697514057, dist_loss: 0.5282492637634277
recon_loss: 0.02906068228185177, dist_loss: 0.5270555019378662
recon_loss: 0.02906074933707714, dist_loss: 0.5591894388198853
recon_loss: 0.02906103804707527, dist_loss: 0.43835702538490295
recon_loss: 0.029060930013656616, dist_loss: 0.9245378971099854
recon_loss: 0.02906067855656147, dist_loss: 0.5740524530410767
recon_loss: 0.029060615226626396, dist_loss: 0.4838795065879822
recon_loss: 0.02906063385307789, dist_loss: 0.6459924578666687
recon_loss: 0.02906065061688423, dist_loss: 0.882038950920105
recon_loss: 0.029060525819659233, dist_loss: 0.9956859946250916
recon_loss: 0.029060283675789833, dist_loss: 0.5542635321617126
recon_loss: 0.02906019426882267, dist_loss: 0.5221774578094482
recon_loss: 0.02906022034585476, dist_loss: 0.8437855243682861
recon_loss: 0.02905981056392193, dist_loss: 0.6420929431915283
recon_loss: 0.029059920459985733, dist_loss: 0.5057065486907959
recon_loss: 0.029059186577796936, dist_loss: 0.5566862225532532
recon_loss: 0.02905885875225067, dist_loss: 0.4671103060245514
recon_loss: 0.029058901593089104, dist_loss: 1.145118236541748
recon_loss: 0.029058076441287994, dist_loss: 0.7074944376945496
recon_loss: 0.029058650135993958, dist_loss: 0.9249235391616821
recon_loss: 0.02905913069844246, dist_loss: 0.3312702178955078
recon_loss: 0.029059723019599915, dist_loss: 0.5351061820983887
recon_loss: 0.02906135655939579, dist_loss: 0.6693379878997803
recon_loss: 0.029061952605843544, dist_loss: 0.7951495051383972
recon_loss: 0.029062464833259583, dist_loss: 0.6467211246490479
recon_loss: 0.029062693938612938, dist_loss: 0.48431673645973206
Pre-training Epoch 50:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 50:   5%|▍         | 18/367 [00:00<00:01, 178.16it/s]Pre-training Epoch 50:  10%|█         | 38/367 [00:00<00:01, 186.22it/s]Pre-training Epoch 50:  16%|█▌        | 58/367 [00:00<00:01, 188.57it/s]Pre-training Epoch 50:  21%|██        | 77/367 [00:00<00:01, 188.76it/s]Pre-training Epoch 50:  26%|██▋       | 97/367 [00:00<00:01, 190.77it/s]Pre-training Epoch 50:  32%|███▏      | 117/367 [00:00<00:01, 192.13it/s]recon_loss: 0.029062913730740547, dist_loss: 0.5829482674598694
recon_loss: 0.029062945395708084, dist_loss: 0.5809007883071899
recon_loss: 0.029063161462545395, dist_loss: 0.7817627191543579
recon_loss: 0.029063159599900246, dist_loss: 0.49899840354919434
recon_loss: 0.02906281128525734, dist_loss: 0.8021596670150757
recon_loss: 0.02906198613345623, dist_loss: 0.5487338900566101
recon_loss: 0.02906106412410736, dist_loss: 0.6844851970672607
recon_loss: 0.029059896245598793, dist_loss: 0.5328875780105591
recon_loss: 0.02905881032347679, dist_loss: 0.8645904064178467
recon_loss: 0.02905811183154583, dist_loss: 0.5000638961791992
recon_loss: 0.029058219864964485, dist_loss: 0.7943271994590759
recon_loss: 0.029057586565613747, dist_loss: 0.6116422414779663
recon_loss: 0.029056716710329056, dist_loss: 0.5558749437332153
recon_loss: 0.029057035222649574, dist_loss: 0.6643529534339905
recon_loss: 0.029057256877422333, dist_loss: 0.5871094465255737
recon_loss: 0.029057053849101067, dist_loss: 0.547893762588501
recon_loss: 0.02905663289129734, dist_loss: 0.5341216325759888
recon_loss: 0.029056141152977943, dist_loss: 0.6010617017745972
recon_loss: 0.029055561870336533, dist_loss: 0.4056003987789154
recon_loss: 0.029055781662464142, dist_loss: 1.0775970220565796
recon_loss: 0.02905557118356228, dist_loss: 0.7467190027236938
recon_loss: 0.02905525267124176, dist_loss: 0.9547516703605652
recon_loss: 0.029055241495370865, dist_loss: 0.4496917724609375
recon_loss: 0.02905508503317833, dist_loss: 0.40074479579925537
recon_loss: 0.029054610058665276, dist_loss: 1.0495573282241821
recon_loss: 0.02905416302382946, dist_loss: 0.7404953241348267
recon_loss: 0.029054848477244377, dist_loss: 0.6396153569221497
recon_loss: 0.0290550347417593, dist_loss: 0.7387351393699646
recon_loss: 0.029054919257760048, dist_loss: 1.159927487373352
recon_loss: 0.029056057333946228, dist_loss: 0.7160269021987915
recon_loss: 0.029055876657366753, dist_loss: 0.5119350552558899
recon_loss: 0.029054692015051842, dist_loss: 0.8795660138130188
recon_loss: 0.029054531827569008, dist_loss: 0.5432572364807129
recon_loss: 0.029054343700408936, dist_loss: 0.8034903407096863
recon_loss: 0.029054056853055954, dist_loss: 0.7559139728546143
recon_loss: 0.029054073616862297, dist_loss: 0.46222609281539917
recon_loss: 0.029054759070277214, dist_loss: 0.30959755182266235
recon_loss: 0.02905459702014923, dist_loss: 0.44786179065704346
recon_loss: 0.029054317623376846, dist_loss: 0.7414126396179199
recon_loss: 0.0290538277477026, dist_loss: 0.529902458190918
recon_loss: 0.029053736478090286, dist_loss: 0.716334342956543
recon_loss: 0.029053812846541405, dist_loss: 0.6917843222618103
recon_loss: 0.02905365265905857, dist_loss: 0.6917362213134766
recon_loss: 0.029053494334220886, dist_loss: 0.490217924118042
recon_loss: 0.02905317395925522, dist_loss: 0.5855374932289124
recon_loss: 0.029052745550870895, dist_loss: 0.6238455772399902
recon_loss: 0.02905254438519478, dist_loss: 0.7890591025352478
recon_loss: 0.029052430763840675, dist_loss: 0.47762325406074524
recon_loss: 0.02905234880745411, dist_loss: 0.7097691297531128
recon_loss: 0.029052220284938812, dist_loss: 0.39589548110961914
recon_loss: 0.029052123427391052, dist_loss: 0.594436526298523
recon_loss: 0.02905210107564926, dist_loss: 0.4141816794872284
recon_loss: 0.02905230037868023, dist_loss: 0.7625284790992737
recon_loss: 0.029051875695586205, dist_loss: 0.6475776433944702
recon_loss: 0.029051752761006355, dist_loss: 0.5378468036651611
recon_loss: 0.02905135601758957, dist_loss: 0.7156330347061157
recon_loss: 0.02905101142823696, dist_loss: 0.5547988414764404
recon_loss: 0.0290511641651392, dist_loss: 0.7774907350540161
recon_loss: 0.029050927609205246, dist_loss: 1.2099180221557617
recon_loss: 0.029050474986433983, dist_loss: 1.1457252502441406
recon_loss: 0.029050230979919434, dist_loss: 0.8244823217391968
recon_loss: 0.02904989756643772, dist_loss: 0.3645009398460388
recon_loss: 0.029049543663859367, dist_loss: 0.6474665403366089
recon_loss: 0.029049336910247803, dist_loss: 0.690840482711792
recon_loss: 0.02904929779469967, dist_loss: 0.6790837645530701
recon_loss: 0.029049407690763474, dist_loss: 0.6744388341903687
recon_loss: 0.029049456119537354, dist_loss: 0.5851114392280579
recon_loss: 0.02904948778450489, dist_loss: 0.6650623679161072
recon_loss: 0.029049459844827652, dist_loss: 0.6080577373504639
recon_loss: 0.0290490984916687, dist_loss: 0.7869324088096619
recon_loss: 0.02904890477657318, dist_loss: 0.5678304433822632
recon_loss: 0.029048992320895195, dist_loss: 0.38168054819107056
recon_loss: 0.029049087315797806, dist_loss: 0.6001840829849243
recon_loss: 0.029048655182123184, dist_loss: 0.7575413584709167
recon_loss: 0.029048189520835876, dist_loss: 0.5407902598381042
recon_loss: 0.029047925025224686, dist_loss: 0.6189256310462952
recon_loss: 0.02904757298529148, dist_loss: 0.5983976125717163
recon_loss: 0.029047725722193718, dist_loss: 0.6814947128295898
recon_loss: 0.02904767543077469, dist_loss: 0.4582962393760681
recon_loss: 0.029047593474388123, dist_loss: 0.8193570971488953
recon_loss: 0.029047725722193718, dist_loss: 0.8175186514854431
recon_loss: 0.029047831892967224, dist_loss: 0.9581727981567383
recon_loss: 0.02904769405722618, dist_loss: 0.8792356252670288
recon_loss: 0.029048332944512367, dist_loss: 0.4264768958091736
recon_loss: 0.029047494754195213, dist_loss: 1.052870273590088
recon_loss: 0.029047125950455666, dist_loss: 0.754827082157135
recon_loss: 0.029047198593616486, dist_loss: 0.5328131914138794
recon_loss: 0.029046859592199326, dist_loss: 0.4254400432109833
recon_loss: 0.029046978801488876, dist_loss: 0.7159201502799988
recon_loss: 0.0290469191968441, dist_loss: 0.6306001543998718
recon_loss: 0.029046498239040375, dist_loss: 0.6051064729690552
recon_loss: 0.02904604747891426, dist_loss: 1.0897434949874878
recon_loss: 0.029046054929494858, dist_loss: 0.5900573134422302
recon_loss: 0.02904568798840046, dist_loss: 0.44428449869155884
recon_loss: 0.029045386239886284, dist_loss: 0.7327551245689392
recon_loss: 0.029045606032013893, dist_loss: 0.6849455833435059
recon_loss: 0.02904506027698517, dist_loss: 0.6776492595672607
recon_loss: 0.029044801369309425, dist_loss: 0.8015799522399902
recon_loss: 0.029044922441244125, dist_loss: 0.7281851768493652
recon_loss: 0.029044780880212784, dist_loss: 0.7386846542358398
recon_loss: 0.029044482856988907, dist_loss: 0.7206284999847412
recon_loss: 0.0290446188300848, dist_loss: 0.8613295555114746
recon_loss: 0.029044289141893387, dist_loss: 1.232914924621582
recon_loss: 0.029044322669506073, dist_loss: 0.5592081546783447
recon_loss: 0.029044684022665024, dist_loss: 0.7311341166496277
recon_loss: 0.029044529423117638, dist_loss: 0.8818015456199646
recon_loss: 0.02904445491731167, dist_loss: 0.6896092295646667
recon_loss: 0.029044723138213158, dist_loss: 0.44583532214164734
recon_loss: 0.02904484048485756, dist_loss: 0.6063469648361206
recon_loss: 0.02904440276324749, dist_loss: 0.36643844842910767
recon_loss: 0.02904416434466839, dist_loss: 0.4456274211406708
recon_loss: 0.02904411032795906, dist_loss: 0.5404172539710999
recon_loss: 0.02904404327273369, dist_loss: 0.8380985856056213
recon_loss: 0.029044007882475853, dist_loss: 0.591514527797699
recon_loss: 0.029043907299637794, dist_loss: 0.6031596660614014
recon_loss: 0.02904355339705944, dist_loss: 0.5631269812583923
recon_loss: 0.02904318831861019, dist_loss: 0.8735601902008057
recon_loss: 0.029042890295386314, dist_loss: 0.7423511147499084
recon_loss: 0.029042553156614304, dist_loss: 1.0176681280136108
recon_loss: 0.029042530804872513, dist_loss: 0.7079348564147949
recon_loss: 0.029042821377515793, dist_loss: 0.5494917035102844
recon_loss: 0.029043277725577354, dist_loss: 0.9158645272254944
recon_loss: 0.029043659567832947, dist_loss: 0.6151212453842163
recon_loss: 0.029042797163128853, dist_loss: 0.7128636837005615
recon_loss: 0.029042987152934074, dist_loss: 0.5821679830551147
recon_loss: 0.029044149443507195, dist_loss: 0.5012759566307068
recon_loss: 0.029044993221759796, dist_loss: 0.6499720811843872
recon_loss: 0.029045602306723595, dist_loss: 0.48843133449554443
Pre-training Epoch 50:  37%|███▋      | 137/367 [00:00<00:01, 192.75it/s]Pre-training Epoch 50:  43%|████▎     | 157/367 [00:00<00:01, 192.91it/s]Pre-training Epoch 50:  48%|████▊     | 177/367 [00:00<00:00, 192.49it/s]Pre-training Epoch 50:  54%|█████▎    | 197/367 [00:01<00:00, 192.20it/s]Pre-training Epoch 50:  59%|█████▉    | 217/367 [00:01<00:00, 192.01it/s]Pre-training Epoch 50:  65%|██████▍   | 237/367 [00:01<00:00, 192.08it/s]recon_loss: 0.029045438393950462, dist_loss: 0.7234904766082764
recon_loss: 0.029045483097434044, dist_loss: 0.5459913015365601
recon_loss: 0.02904541790485382, dist_loss: 0.4772711992263794
recon_loss: 0.029045524075627327, dist_loss: 0.5822088718414307
recon_loss: 0.029045799747109413, dist_loss: 0.9300549626350403
recon_loss: 0.0290457084774971, dist_loss: 0.7278584241867065
recon_loss: 0.02904568612575531, dist_loss: 0.6968392133712769
recon_loss: 0.029045866802334785, dist_loss: 0.6823384761810303
recon_loss: 0.02904551848769188, dist_loss: 0.5490515232086182
recon_loss: 0.02904452197253704, dist_loss: 0.7079753875732422
recon_loss: 0.02904360741376877, dist_loss: 0.41958093643188477
recon_loss: 0.029042711481451988, dist_loss: 0.6870417594909668
recon_loss: 0.029042242094874382, dist_loss: 0.5398990511894226
recon_loss: 0.029042048379778862, dist_loss: 1.9891893863677979
recon_loss: 0.02904241904616356, dist_loss: 0.7269680500030518
recon_loss: 0.029042908921837807, dist_loss: 0.7606587409973145
recon_loss: 0.029043735936284065, dist_loss: 0.5555689930915833
recon_loss: 0.02904369682073593, dist_loss: 1.1491992473602295
recon_loss: 0.029043354094028473, dist_loss: 0.687787652015686
recon_loss: 0.029043132439255714, dist_loss: 0.556236743927002
recon_loss: 0.029042923822999, dist_loss: 0.4819839298725128
recon_loss: 0.029042314738035202, dist_loss: 0.8449090719223022
recon_loss: 0.02904156967997551, dist_loss: 0.8374189734458923
recon_loss: 0.029041366651654243, dist_loss: 0.5566433668136597
recon_loss: 0.029041435569524765, dist_loss: 0.9047186970710754
recon_loss: 0.029041951522231102, dist_loss: 0.95355224609375
recon_loss: 0.029042696580290794, dist_loss: 0.5820426940917969
recon_loss: 0.02904355898499489, dist_loss: 0.4423322081565857
recon_loss: 0.029044141992926598, dist_loss: 0.5056707262992859
recon_loss: 0.029044248163700104, dist_loss: 0.6499970555305481
recon_loss: 0.029044674709439278, dist_loss: 0.5296140909194946
recon_loss: 0.029044564813375473, dist_loss: 0.6699931025505066
recon_loss: 0.02904353104531765, dist_loss: 0.6676877737045288
recon_loss: 0.029042480513453484, dist_loss: 0.45894014835357666
recon_loss: 0.02904195338487625, dist_loss: 0.5444113612174988
recon_loss: 0.02904115803539753, dist_loss: 0.4505343437194824
recon_loss: 0.029040295630693436, dist_loss: 0.587640643119812
recon_loss: 0.029039723798632622, dist_loss: 0.8199483752250671
recon_loss: 0.029039280489087105, dist_loss: 0.6537384390830994
recon_loss: 0.02903898060321808, dist_loss: 0.5813946723937988
recon_loss: 0.0290390532463789, dist_loss: 0.7671751976013184
recon_loss: 0.029039165005087852, dist_loss: 0.7792468070983887
recon_loss: 0.029039476066827774, dist_loss: 1.0464324951171875
recon_loss: 0.029039742425084114, dist_loss: 0.5731527805328369
recon_loss: 0.02903994917869568, dist_loss: 0.7780604362487793
recon_loss: 0.029039988294243813, dist_loss: 0.5450749397277832
recon_loss: 0.029039781540632248, dist_loss: 0.8964570760726929
recon_loss: 0.029039571061730385, dist_loss: 0.8282438516616821
recon_loss: 0.029039040207862854, dist_loss: 0.35725122690200806
recon_loss: 0.029038432985544205, dist_loss: 0.5856257677078247
recon_loss: 0.029038256034255028, dist_loss: 0.4712105095386505
recon_loss: 0.029038244858384132, dist_loss: 0.6003364324569702
recon_loss: 0.029037659987807274, dist_loss: 0.7563755512237549
recon_loss: 0.029037604108452797, dist_loss: 0.9276261925697327
recon_loss: 0.02903764881193638, dist_loss: 0.42778414487838745
recon_loss: 0.02903732843697071, dist_loss: 0.8607268333435059
recon_loss: 0.02903716266155243, dist_loss: 1.1338814496994019
recon_loss: 0.029037222266197205, dist_loss: 0.43002820014953613
recon_loss: 0.029036981984972954, dist_loss: 0.5957378149032593
recon_loss: 0.029036782681941986, dist_loss: 0.3740730285644531
recon_loss: 0.029036814346909523, dist_loss: 0.9957956075668335
recon_loss: 0.02903648465871811, dist_loss: 1.0281779766082764
recon_loss: 0.02903631143271923, dist_loss: 0.7220242023468018
recon_loss: 0.029036441817879677, dist_loss: 0.6831389665603638
recon_loss: 0.02903616428375244, dist_loss: 0.5269749164581299
recon_loss: 0.029036056250333786, dist_loss: 0.40356355905532837
recon_loss: 0.029036013409495354, dist_loss: 0.6195886135101318
recon_loss: 0.02903573215007782, dist_loss: 0.6417852640151978
recon_loss: 0.029035277664661407, dist_loss: 0.39395254850387573
recon_loss: 0.029035156592726707, dist_loss: 0.8458489179611206
recon_loss: 0.02903495728969574, dist_loss: 0.5040690898895264
recon_loss: 0.029034437611699104, dist_loss: 0.7775413990020752
recon_loss: 0.02903410978615284, dist_loss: 0.7088232636451721
recon_loss: 0.02903374284505844, dist_loss: 0.6509741544723511
recon_loss: 0.02903331257402897, dist_loss: 0.8809797167778015
recon_loss: 0.02903309091925621, dist_loss: 1.2942283153533936
recon_loss: 0.029033223167061806, dist_loss: 0.7249433994293213
recon_loss: 0.029033375903964043, dist_loss: 0.9336004257202148
recon_loss: 0.02903355285525322, dist_loss: 0.7248260378837585
recon_loss: 0.029034074395895004, dist_loss: 0.6926339864730835
recon_loss: 0.0290352925658226, dist_loss: 0.8112564086914062
recon_loss: 0.029036542400717735, dist_loss: 0.4625808000564575
recon_loss: 0.02903607301414013, dist_loss: 0.9434560537338257
recon_loss: 0.029036495834589005, dist_loss: 0.7429578304290771
recon_loss: 0.02903609350323677, dist_loss: 0.3001946210861206
recon_loss: 0.029035979881882668, dist_loss: 1.0557096004486084
recon_loss: 0.02903677150607109, dist_loss: 0.4315345287322998
recon_loss: 0.02903718873858452, dist_loss: 0.5696635246276855
recon_loss: 0.029036745429039, dist_loss: 1.0535767078399658
recon_loss: 0.02903604321181774, dist_loss: 0.808297872543335
recon_loss: 0.029035545885562897, dist_loss: 0.5859453678131104
recon_loss: 0.02903454564511776, dist_loss: 0.691135823726654
recon_loss: 0.02903355285525322, dist_loss: 0.7659660577774048
recon_loss: 0.02903323620557785, dist_loss: 0.716262698173523
recon_loss: 0.029032569378614426, dist_loss: 0.7281665205955505
recon_loss: 0.029032239690423012, dist_loss: 0.9983862042427063
recon_loss: 0.029032504186034203, dist_loss: 0.7920311689376831
recon_loss: 0.029032353311777115, dist_loss: 0.7182657122612
recon_loss: 0.029031937941908836, dist_loss: 0.6006078720092773
recon_loss: 0.029031844809651375, dist_loss: 0.6521235108375549
recon_loss: 0.02903127111494541, dist_loss: 0.3734012842178345
recon_loss: 0.02903130277991295, dist_loss: 0.5317063331604004
recon_loss: 0.02903219312429428, dist_loss: 0.5239220261573792
recon_loss: 0.029031919315457344, dist_loss: 0.6416950225830078
recon_loss: 0.02903146855533123, dist_loss: 0.6374976634979248
recon_loss: 0.02903163619339466, dist_loss: 0.7830069661140442
recon_loss: 0.029030796140432358, dist_loss: 1.0848448276519775
recon_loss: 0.02903049997985363, dist_loss: 0.28988802433013916
recon_loss: 0.0290303323417902, dist_loss: 0.8658060431480408
recon_loss: 0.029030296951532364, dist_loss: 0.3381463885307312
recon_loss: 0.029030317440629005, dist_loss: 0.5208287835121155
recon_loss: 0.029030289500951767, dist_loss: 0.8316161632537842
recon_loss: 0.02903033420443535, dist_loss: 0.5066570043563843
recon_loss: 0.02903047390282154, dist_loss: 0.6955574154853821
recon_loss: 0.029030701145529747, dist_loss: 0.7834849953651428
recon_loss: 0.029031608253717422, dist_loss: 0.6608218550682068
recon_loss: 0.02903197519481182, dist_loss: 0.5392856001853943
recon_loss: 0.029032211750745773, dist_loss: 0.6417109966278076
recon_loss: 0.02903156168758869, dist_loss: 0.38098010420799255
recon_loss: 0.029031123965978622, dist_loss: 0.4322686195373535
recon_loss: 0.029030632227659225, dist_loss: 0.7580443620681763
recon_loss: 0.029030419886112213, dist_loss: 0.5377169847488403
recon_loss: 0.029030565172433853, dist_loss: 0.7043861150741577
recon_loss: 0.029030293226242065, dist_loss: 0.6314011812210083
recon_loss: 0.02902997098863125, dist_loss: 0.4139057695865631
recon_loss: 0.029029548168182373, dist_loss: 0.6344894170761108
recon_loss: 0.02902892418205738, dist_loss: 0.5085049271583557
recon_loss: 0.029028914868831635, dist_loss: 0.29078346490859985
Pre-training Epoch 50:  70%|███████   | 257/367 [00:01<00:00, 192.14it/s]Pre-training Epoch 50:  75%|███████▌  | 277/367 [00:01<00:00, 192.24it/s]Pre-training Epoch 50:  81%|████████  | 297/367 [00:01<00:00, 192.01it/s]Pre-training Epoch 50:  86%|████████▋ | 317/367 [00:01<00:00, 192.07it/s]Pre-training Epoch 50:  92%|█████████▏| 337/367 [00:01<00:00, 192.11it/s]Pre-training Epoch 50:  97%|█████████▋| 357/367 [00:01<00:00, 192.17it/s]Pre-training Epoch 50: 100%|██████████| 367/367 [00:01<00:00, 191.46it/s]
recon_loss: 0.029029374942183495, dist_loss: 0.4431774616241455
recon_loss: 0.02902943082153797, dist_loss: 0.83855801820755
recon_loss: 0.029029130935668945, dist_loss: 0.8306577801704407
recon_loss: 0.02902873419225216, dist_loss: 0.9566815495491028
recon_loss: 0.029028328135609627, dist_loss: 0.6747661232948303
recon_loss: 0.029027728363871574, dist_loss: 0.44741806387901306
recon_loss: 0.029027791693806648, dist_loss: 1.077834129333496
recon_loss: 0.02902800589799881, dist_loss: 0.9659465551376343
recon_loss: 0.029028207063674927, dist_loss: 0.8961554765701294
recon_loss: 0.02902786247432232, dist_loss: 0.9388080835342407
recon_loss: 0.029027484357357025, dist_loss: 0.40059563517570496
recon_loss: 0.02902763895690441, dist_loss: 0.4866585433483124
recon_loss: 0.02902740240097046, dist_loss: 0.42394912242889404
recon_loss: 0.02902684174478054, dist_loss: 0.5034916400909424
recon_loss: 0.029026687145233154, dist_loss: 0.6848517656326294
recon_loss: 0.029026735574007034, dist_loss: 1.0880765914916992
recon_loss: 0.029026346281170845, dist_loss: 0.5873286724090576
recon_loss: 0.029027240350842476, dist_loss: 0.31831905245780945
recon_loss: 0.029027173295617104, dist_loss: 0.4904046952724457
recon_loss: 0.02902699075639248, dist_loss: 0.21522201597690582
recon_loss: 0.029027223587036133, dist_loss: 0.9423626661300659
recon_loss: 0.029026983305811882, dist_loss: 0.6318262219429016
recon_loss: 0.029026340693235397, dist_loss: 0.6824225187301636
recon_loss: 0.02902621403336525, dist_loss: 0.9759138226509094
recon_loss: 0.029026640579104424, dist_loss: 0.7998160123825073
recon_loss: 0.029026083648204803, dist_loss: 0.4199650287628174
recon_loss: 0.029025716707110405, dist_loss: 0.4995182156562805
recon_loss: 0.029025930911302567, dist_loss: 0.7303171157836914
recon_loss: 0.029025495052337646, dist_loss: 0.8829795718193054
recon_loss: 0.02902483008801937, dist_loss: 0.7520787715911865
recon_loss: 0.029024923220276833, dist_loss: 0.45841991901397705
recon_loss: 0.02902468480169773, dist_loss: 0.554663360118866
recon_loss: 0.02902434580028057, dist_loss: 0.47624915838241577
recon_loss: 0.029024990275502205, dist_loss: 0.2984263300895691
recon_loss: 0.02902430295944214, dist_loss: 1.3085321187973022
recon_loss: 0.02902413159608841, dist_loss: 0.6643657684326172
recon_loss: 0.029024790972471237, dist_loss: 0.4960123896598816
recon_loss: 0.029024723917245865, dist_loss: 1.0589491128921509
recon_loss: 0.02902451902627945, dist_loss: 0.41062888503074646
recon_loss: 0.02902490831911564, dist_loss: 0.6373190879821777
recon_loss: 0.0290248803794384, dist_loss: 0.6948230266571045
recon_loss: 0.029024241492152214, dist_loss: 0.37365323305130005
recon_loss: 0.02902447059750557, dist_loss: 0.7221474647521973
recon_loss: 0.0290241502225399, dist_loss: 0.5899207592010498
recon_loss: 0.029023271054029465, dist_loss: 0.37812545895576477
recon_loss: 0.029023362323641777, dist_loss: 0.4786537289619446
recon_loss: 0.02902318723499775, dist_loss: 0.7815437316894531
recon_loss: 0.02902263216674328, dist_loss: 0.9154644012451172
recon_loss: 0.029022781178355217, dist_loss: 0.5772994160652161
recon_loss: 0.029023179784417152, dist_loss: 0.671604335308075
recon_loss: 0.029022635892033577, dist_loss: 0.46381109952926636
recon_loss: 0.029023081064224243, dist_loss: 1.1508835554122925
recon_loss: 0.02902332693338394, dist_loss: 0.5050855875015259
recon_loss: 0.029022984206676483, dist_loss: 0.5565598011016846
recon_loss: 0.029023708775639534, dist_loss: 0.5358707904815674
recon_loss: 0.02902386337518692, dist_loss: 0.9454652070999146
recon_loss: 0.029023902490735054, dist_loss: 0.9930080771446228
recon_loss: 0.029024813324213028, dist_loss: 0.6975253820419312
recon_loss: 0.029026294127106667, dist_loss: 0.864654541015625
recon_loss: 0.02902568317949772, dist_loss: 0.7086851596832275
recon_loss: 0.029024647548794746, dist_loss: 0.45881134271621704
recon_loss: 0.029024407267570496, dist_loss: 0.8049757480621338
recon_loss: 0.029023094102740288, dist_loss: 0.8830237984657288
recon_loss: 0.029023511335253716, dist_loss: 0.7173562049865723
recon_loss: 0.029023731127381325, dist_loss: 0.8120765686035156
recon_loss: 0.029023129492998123, dist_loss: 0.8338580131530762
recon_loss: 0.029023274779319763, dist_loss: 0.3178689479827881
recon_loss: 0.02902289852499962, dist_loss: 0.9322345852851868
recon_loss: 0.02902195230126381, dist_loss: 0.6438693404197693
recon_loss: 0.02902206964790821, dist_loss: 0.6451402902603149
recon_loss: 0.029022185131907463, dist_loss: 0.6817073822021484
recon_loss: 0.02902274951338768, dist_loss: 0.6917442083358765
recon_loss: 0.029023252427577972, dist_loss: 0.6370105743408203
recon_loss: 0.029023468494415283, dist_loss: 0.5425783395767212
recon_loss: 0.02902328409254551, dist_loss: 0.6778241991996765
recon_loss: 0.02902272157371044, dist_loss: 0.38113903999328613
recon_loss: 0.029022367671132088, dist_loss: 0.5328827500343323
recon_loss: 0.029022064059972763, dist_loss: 0.38506799936294556
recon_loss: 0.02902146428823471, dist_loss: 0.5119155049324036
recon_loss: 0.02902105823159218, dist_loss: 0.5632151961326599
recon_loss: 0.029020316898822784, dist_loss: 0.46210113167762756
recon_loss: 0.029019685462117195, dist_loss: 0.6688880920410156
recon_loss: 0.029018988832831383, dist_loss: 0.6348862051963806
recon_loss: 0.029018646106123924, dist_loss: 0.7660564184188843
recon_loss: 0.02901839092373848, dist_loss: 0.9370904564857483
recon_loss: 0.029018135741353035, dist_loss: 0.41684120893478394
recon_loss: 0.029017947614192963, dist_loss: 0.8344363570213318
recon_loss: 0.029017848894000053, dist_loss: 0.34147191047668457
recon_loss: 0.029017740860581398, dist_loss: 0.5503877997398376
recon_loss: 0.029018042609095573, dist_loss: 0.5762850642204285
recon_loss: 0.029018554836511612, dist_loss: 0.4650910794734955
recon_loss: 0.029019305482506752, dist_loss: 0.7689312696456909
recon_loss: 0.029020149260759354, dist_loss: 0.7034754753112793
recon_loss: 0.029021451249718666, dist_loss: 0.9919241070747375
recon_loss: 0.029022036120295525, dist_loss: 0.6023575663566589
recon_loss: 0.02902214787900448, dist_loss: 0.8605338931083679
recon_loss: 0.02902250736951828, dist_loss: 1.0516088008880615
recon_loss: 0.02902335673570633, dist_loss: 0.9842396378517151
recon_loss: 0.029024990275502205, dist_loss: 0.2896044850349426
recon_loss: 0.029026608914136887, dist_loss: 0.853130042552948
recon_loss: 0.029027409851551056, dist_loss: 0.5489703416824341
recon_loss: 0.029027584940195084, dist_loss: 0.4500734806060791
recon_loss: 0.029026517644524574, dist_loss: 0.9146774411201477
recon_loss: 0.029024967923760414, dist_loss: 0.5589073896408081
recon_loss: 0.029023397713899612, dist_loss: 0.723649263381958
recon_loss: 0.02902228944003582, dist_loss: 0.5930222272872925
recon_loss: 0.02902083285152912, dist_loss: 0.48261505365371704
recon_loss: 0.02901967242360115, dist_loss: 0.6269289255142212
recon_loss: 0.02901906706392765, dist_loss: 0.8189030885696411
recon_loss: 0.029018115252256393, dist_loss: 0.9973982572555542
recon_loss: 0.02901807799935341, dist_loss: 0.2650345265865326
Pre-train Epoch: 50
Train - Total Loss: 0.0962, Recon Loss: 0.0290, Dist Loss: 0.6718, l1 regularization: 0.0000
Val - Total Loss: 0.1004, Recon Loss: 0.0290, Dist Loss: 0.7142, l1 regularization: 0.0000
Pre-training Epoch 51:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 51:   5%|▌         | 19/367 [00:00<00:01, 188.82it/s]Pre-training Epoch 51:  11%|█         | 39/367 [00:00<00:01, 190.74it/s]Pre-training Epoch 51:  16%|█▌        | 59/367 [00:00<00:01, 191.51it/s]Pre-training Epoch 51:  22%|██▏       | 79/367 [00:00<00:01, 191.89it/s]Pre-training Epoch 51:  27%|██▋       | 99/367 [00:00<00:01, 191.43it/s]Pre-training Epoch 51:  32%|███▏      | 119/367 [00:00<00:01, 184.63it/s]recon_loss: 0.02901778556406498, dist_loss: 0.5776363611221313
recon_loss: 0.029018227010965347, dist_loss: 0.6430433392524719
recon_loss: 0.029018793255090714, dist_loss: 1.044006586074829
recon_loss: 0.029019014909863472, dist_loss: 0.45973992347717285
recon_loss: 0.02901935763657093, dist_loss: 0.616309404373169
recon_loss: 0.029020145535469055, dist_loss: 0.8381797075271606
recon_loss: 0.029020017012953758, dist_loss: 0.8026500344276428
recon_loss: 0.029020020738244057, dist_loss: 0.6499218940734863
recon_loss: 0.029019994661211967, dist_loss: 0.45339861512184143
recon_loss: 0.029019439592957497, dist_loss: 0.7573489546775818
recon_loss: 0.02901919186115265, dist_loss: 1.010677695274353
recon_loss: 0.029018541797995567, dist_loss: 0.694628119468689
recon_loss: 0.029018303379416466, dist_loss: 0.6075267195701599
recon_loss: 0.029017893597483635, dist_loss: 0.6673927307128906
recon_loss: 0.029017843306064606, dist_loss: 1.0812304019927979
recon_loss: 0.029017223045229912, dist_loss: 0.40373891592025757
recon_loss: 0.02901633270084858, dist_loss: 0.4632134437561035
recon_loss: 0.02901552803814411, dist_loss: 0.7473905086517334
recon_loss: 0.02901533618569374, dist_loss: 0.6078665256500244
recon_loss: 0.029015101492404938, dist_loss: 0.7213832139968872
recon_loss: 0.02901463769376278, dist_loss: 0.6926425099372864
recon_loss: 0.029014315456151962, dist_loss: 0.422035276889801
recon_loss: 0.02901400625705719, dist_loss: 0.8326956033706665
recon_loss: 0.029013991355895996, dist_loss: 0.5455284714698792
recon_loss: 0.029014181345701218, dist_loss: 0.5634075999259949
recon_loss: 0.02901438996195793, dist_loss: 0.832970380783081
recon_loss: 0.029014572501182556, dist_loss: 0.4789091646671295
recon_loss: 0.029014375060796738, dist_loss: 1.3528051376342773
recon_loss: 0.02901383303105831, dist_loss: 0.40849000215530396
recon_loss: 0.029013587161898613, dist_loss: 0.49811485409736633
recon_loss: 0.02901300974190235, dist_loss: 0.9736955165863037
recon_loss: 0.029012417420744896, dist_loss: 0.4624026417732239
recon_loss: 0.029012629762291908, dist_loss: 0.9079187512397766
recon_loss: 0.02901250310242176, dist_loss: 0.5110851526260376
recon_loss: 0.029011934995651245, dist_loss: 0.9654972553253174
recon_loss: 0.029012292623519897, dist_loss: 0.6489859819412231
recon_loss: 0.02901255153119564, dist_loss: 0.8865340948104858
recon_loss: 0.029011862352490425, dist_loss: 0.7659479379653931
recon_loss: 0.02901182509958744, dist_loss: 0.5627691745758057
recon_loss: 0.029012350365519524, dist_loss: 0.8588979244232178
recon_loss: 0.02901199460029602, dist_loss: 0.3876315653324127
recon_loss: 0.0290111992508173, dist_loss: 0.6941444873809814
recon_loss: 0.029012007638812065, dist_loss: 0.6584707498550415
recon_loss: 0.029012106359004974, dist_loss: 0.40397411584854126
recon_loss: 0.029011595994234085, dist_loss: 0.5222097635269165
recon_loss: 0.029012804850935936, dist_loss: 0.545307993888855
recon_loss: 0.029012039303779602, dist_loss: 0.7867823243141174
recon_loss: 0.029011612758040428, dist_loss: 0.4953375458717346
recon_loss: 0.029011592268943787, dist_loss: 0.7261381149291992
recon_loss: 0.02901099994778633, dist_loss: 0.5234043002128601
recon_loss: 0.029010886326432228, dist_loss: 0.6501739025115967
recon_loss: 0.029011396691203117, dist_loss: 0.6511448621749878
recon_loss: 0.029011577367782593, dist_loss: 0.5032568573951721
recon_loss: 0.02901141345500946, dist_loss: 0.5841814279556274
recon_loss: 0.029011474922299385, dist_loss: 0.8877445459365845
recon_loss: 0.029011249542236328, dist_loss: 0.7468420267105103
recon_loss: 0.029010968282818794, dist_loss: 0.4302315413951874
recon_loss: 0.029010821133852005, dist_loss: 0.4187247157096863
recon_loss: 0.029010556638240814, dist_loss: 0.8112396001815796
recon_loss: 0.029010141268372536, dist_loss: 0.3410232663154602
recon_loss: 0.029009521007537842, dist_loss: 0.6606521606445312
recon_loss: 0.029009226709604263, dist_loss: 0.447762131690979
recon_loss: 0.02900908701121807, dist_loss: 0.6969186067581177
recon_loss: 0.029008779674768448, dist_loss: 0.6072988510131836
recon_loss: 0.02900836244225502, dist_loss: 0.49966704845428467
recon_loss: 0.029008030891418457, dist_loss: 0.7563976049423218
recon_loss: 0.02900778502225876, dist_loss: 0.4478302597999573
recon_loss: 0.029007593169808388, dist_loss: 0.6631323099136353
recon_loss: 0.029007457196712494, dist_loss: 0.7302454710006714
recon_loss: 0.02900731936097145, dist_loss: 1.0348551273345947
recon_loss: 0.02900724485516548, dist_loss: 1.1597692966461182
recon_loss: 0.029007187113165855, dist_loss: 0.566074788570404
recon_loss: 0.029006987810134888, dist_loss: 0.8246549367904663
recon_loss: 0.02900678850710392, dist_loss: 0.9124428629875183
recon_loss: 0.029006659984588623, dist_loss: 0.8343631029129028
recon_loss: 0.02900647558271885, dist_loss: 0.5773987770080566
recon_loss: 0.029006468132138252, dist_loss: 0.39810046553611755
recon_loss: 0.029006266966462135, dist_loss: 0.7134173512458801
recon_loss: 0.029006507247686386, dist_loss: 0.4241792857646942
recon_loss: 0.02900613471865654, dist_loss: 0.7603334784507751
recon_loss: 0.029005907475948334, dist_loss: 0.606964111328125
recon_loss: 0.029005970805883408, dist_loss: 0.712607741355896
recon_loss: 0.02900567278265953, dist_loss: 0.8879691362380981
recon_loss: 0.02900540456175804, dist_loss: 0.6174275875091553
recon_loss: 0.02900536358356476, dist_loss: 1.159820795059204
recon_loss: 0.02900521829724312, dist_loss: 0.7109335660934448
recon_loss: 0.02900512143969536, dist_loss: 0.8276762962341309
recon_loss: 0.029004817828536034, dist_loss: 0.3778690695762634
recon_loss: 0.02900456264615059, dist_loss: 0.36776477098464966
recon_loss: 0.029004450887441635, dist_loss: 0.8828953504562378
recon_loss: 0.029004322364926338, dist_loss: 0.5071021914482117
recon_loss: 0.029004167765378952, dist_loss: 0.8334063291549683
recon_loss: 0.029004164040088654, dist_loss: 0.5782085061073303
recon_loss: 0.029004128649830818, dist_loss: 0.4009692668914795
recon_loss: 0.029004234820604324, dist_loss: 0.49789589643478394
recon_loss: 0.029004523530602455, dist_loss: 1.1229814291000366
recon_loss: 0.02900508977472782, dist_loss: 0.7474185228347778
recon_loss: 0.029005780816078186, dist_loss: 0.6329006552696228
recon_loss: 0.02900581620633602, dist_loss: 0.9165626764297485
recon_loss: 0.029005691409111023, dist_loss: 0.4036679267883301
recon_loss: 0.029005398973822594, dist_loss: 0.6884512901306152
recon_loss: 0.029005063697695732, dist_loss: 0.36720430850982666
recon_loss: 0.02900485135614872, dist_loss: 0.7245640754699707
recon_loss: 0.029004791751503944, dist_loss: 0.701418936252594
recon_loss: 0.029004665091633797, dist_loss: 1.0742617845535278
recon_loss: 0.02900448441505432, dist_loss: 0.8813244104385376
recon_loss: 0.029004018753767014, dist_loss: 0.5339164733886719
recon_loss: 0.029003575444221497, dist_loss: 0.7327387928962708
recon_loss: 0.029003500938415527, dist_loss: 0.7915530204772949
recon_loss: 0.029003219678997993, dist_loss: 0.7036595344543457
recon_loss: 0.02900322712957859, dist_loss: 0.4384564757347107
recon_loss: 0.029003610834479332, dist_loss: 0.7007125616073608
recon_loss: 0.029004106298089027, dist_loss: 0.6419456005096436
recon_loss: 0.02900409698486328, dist_loss: 0.7316133975982666
recon_loss: 0.0290042906999588, dist_loss: 0.3336501121520996
recon_loss: 0.029004264622926712, dist_loss: 0.4764162302017212
recon_loss: 0.029004180803894997, dist_loss: 0.568182110786438
recon_loss: 0.02900419570505619, dist_loss: 0.6566317081451416
recon_loss: 0.029004015028476715, dist_loss: 0.5983240008354187
recon_loss: 0.029003620147705078, dist_loss: 0.8207955360412598
recon_loss: 0.029003221541643143, dist_loss: 0.972644567489624
recon_loss: 0.029002802446484566, dist_loss: 0.7502450346946716
recon_loss: 0.029002392664551735, dist_loss: 0.9058277010917664
recon_loss: 0.02900194376707077, dist_loss: 0.5615838766098022
recon_loss: 0.029001718387007713, dist_loss: 0.7120052576065063
recon_loss: 0.029001524671912193, dist_loss: 0.4481866955757141
recon_loss: 0.029001357033848763, dist_loss: 0.9829396605491638
recon_loss: 0.02900117076933384, dist_loss: 0.5332779288291931
Pre-training Epoch 51:  38%|███▊      | 138/367 [00:00<00:01, 177.75it/s]Pre-training Epoch 51:  43%|████▎     | 158/367 [00:00<00:01, 181.83it/s]Pre-training Epoch 51:  49%|████▊     | 178/367 [00:00<00:01, 185.01it/s]Pre-training Epoch 51:  54%|█████▍    | 198/367 [00:01<00:00, 187.15it/s]Pre-training Epoch 51:  59%|█████▉    | 218/367 [00:01<00:00, 188.68it/s]Pre-training Epoch 51:  65%|██████▍   | 238/367 [00:01<00:00, 189.70it/s]recon_loss: 0.029000988230109215, dist_loss: 0.43580126762390137
recon_loss: 0.029000917449593544, dist_loss: 0.5412858724594116
recon_loss: 0.029000695794820786, dist_loss: 0.6120527982711792
recon_loss: 0.02900063619017601, dist_loss: 0.5137011408805847
recon_loss: 0.029000448063015938, dist_loss: 0.5896134376525879
recon_loss: 0.02900031767785549, dist_loss: 0.41993477940559387
recon_loss: 0.02900027297437191, dist_loss: 0.5866907238960266
recon_loss: 0.0290005374699831, dist_loss: 0.982025146484375
recon_loss: 0.02900058776140213, dist_loss: 1.1737722158432007
recon_loss: 0.02900087647140026, dist_loss: 0.9290152788162231
recon_loss: 0.02900114841759205, dist_loss: 0.7761900424957275
recon_loss: 0.02900100313127041, dist_loss: 0.7120665311813354
recon_loss: 0.029001150280237198, dist_loss: 1.1273746490478516
recon_loss: 0.02900121547281742, dist_loss: 0.5171003937721252
recon_loss: 0.029000887647271156, dist_loss: 0.7279869318008423
recon_loss: 0.02900092303752899, dist_loss: 0.8845877647399902
recon_loss: 0.029001249000430107, dist_loss: 0.7047944664955139
recon_loss: 0.02900080569088459, dist_loss: 0.40462785959243774
recon_loss: 0.029000211507081985, dist_loss: 0.5747441053390503
recon_loss: 0.02900029718875885, dist_loss: 0.7266453504562378
recon_loss: 0.02899945341050625, dist_loss: 0.4735039472579956
recon_loss: 0.028999436646699905, dist_loss: 0.2951868772506714
recon_loss: 0.028999896720051765, dist_loss: 0.7919945120811462
recon_loss: 0.028999831527471542, dist_loss: 0.9037513136863708
recon_loss: 0.028999540954828262, dist_loss: 0.8258980512619019
recon_loss: 0.02899913117289543, dist_loss: 0.9626752138137817
recon_loss: 0.0289986040443182, dist_loss: 0.5437101125717163
recon_loss: 0.028998134657740593, dist_loss: 0.8069432973861694
recon_loss: 0.028998255729675293, dist_loss: 0.816923201084137
recon_loss: 0.02899804897606373, dist_loss: 0.8633079528808594
recon_loss: 0.028997838497161865, dist_loss: 0.7112908363342285
recon_loss: 0.02899819239974022, dist_loss: 0.4638711214065552
recon_loss: 0.02899858169257641, dist_loss: 0.6252536177635193
recon_loss: 0.02899838425219059, dist_loss: 0.7653404474258423
recon_loss: 0.028998643159866333, dist_loss: 0.8203904032707214
recon_loss: 0.028998173773288727, dist_loss: 0.40786194801330566
recon_loss: 0.028997905552387238, dist_loss: 0.6975183486938477
recon_loss: 0.02899855561554432, dist_loss: 0.5294550657272339
recon_loss: 0.02899804711341858, dist_loss: 0.48378801345825195
recon_loss: 0.02899773232638836, dist_loss: 0.6763125061988831
recon_loss: 0.0289984829723835, dist_loss: 0.2966998219490051
recon_loss: 0.02899761311709881, dist_loss: 0.4874400496482849
recon_loss: 0.028997037559747696, dist_loss: 0.6842458248138428
recon_loss: 0.028996501117944717, dist_loss: 0.5271328091621399
recon_loss: 0.028996272012591362, dist_loss: 0.7355207800865173
recon_loss: 0.0289965458214283, dist_loss: 0.7995486259460449
recon_loss: 0.02899681031703949, dist_loss: 0.4166141152381897
recon_loss: 0.02899669110774994, dist_loss: 0.7856261134147644
recon_loss: 0.02899635024368763, dist_loss: 0.5693603157997131
recon_loss: 0.028996510431170464, dist_loss: 0.5273837447166443
recon_loss: 0.028996098786592484, dist_loss: 0.7189512252807617
recon_loss: 0.028996624052524567, dist_loss: 0.6098764538764954
recon_loss: 0.02899685874581337, dist_loss: 1.3423404693603516
recon_loss: 0.02899596467614174, dist_loss: 0.581308126449585
recon_loss: 0.028995735570788383, dist_loss: 0.6022195816040039
recon_loss: 0.02899571694433689, dist_loss: 0.7557083368301392
recon_loss: 0.028995515778660774, dist_loss: 0.9448117017745972
recon_loss: 0.02899579331278801, dist_loss: 0.5294216871261597
recon_loss: 0.028995607048273087, dist_loss: 0.9110772609710693
recon_loss: 0.02899523265659809, dist_loss: 0.5805730223655701
recon_loss: 0.028995174914598465, dist_loss: 0.8475643992424011
recon_loss: 0.028995012864470482, dist_loss: 0.7081013917922974
recon_loss: 0.028994912281632423, dist_loss: 0.45204871892929077
recon_loss: 0.02899491973221302, dist_loss: 0.7005046606063843
recon_loss: 0.028995105996727943, dist_loss: 0.6166995763778687
recon_loss: 0.028995290398597717, dist_loss: 0.5782861709594727
recon_loss: 0.028995446860790253, dist_loss: 0.5828755497932434
recon_loss: 0.028995554894208908, dist_loss: 0.46039408445358276
recon_loss: 0.02899513952434063, dist_loss: 0.47093337774276733
recon_loss: 0.028994623571634293, dist_loss: 0.6213799715042114
recon_loss: 0.028995046392083168, dist_loss: 0.979662299156189
recon_loss: 0.02899487316608429, dist_loss: 0.5052413940429688
recon_loss: 0.02899426966905594, dist_loss: 1.021535038948059
recon_loss: 0.028994228690862656, dist_loss: 0.4481844902038574
recon_loss: 0.02899450622498989, dist_loss: 0.5120061039924622
recon_loss: 0.028993923217058182, dist_loss: 0.4132039546966553
recon_loss: 0.028993822634220123, dist_loss: 0.690800666809082
recon_loss: 0.028994252905249596, dist_loss: 0.7478800415992737
recon_loss: 0.028993705287575722, dist_loss: 0.620593786239624
recon_loss: 0.028993621468544006, dist_loss: 0.8053244948387146
recon_loss: 0.02899402752518654, dist_loss: 0.6151351928710938
recon_loss: 0.028993934392929077, dist_loss: 0.8138256072998047
recon_loss: 0.028993289917707443, dist_loss: 0.7194367051124573
recon_loss: 0.02899305522441864, dist_loss: 0.7966978549957275
recon_loss: 0.028992725536227226, dist_loss: 0.6527608633041382
recon_loss: 0.028992757201194763, dist_loss: 0.6903241276741028
recon_loss: 0.02899288572371006, dist_loss: 0.9657196998596191
recon_loss: 0.02899249829351902, dist_loss: 0.8082316517829895
recon_loss: 0.028992407023906708, dist_loss: 0.556526780128479
recon_loss: 0.02899240329861641, dist_loss: 0.6846503019332886
recon_loss: 0.02899206429719925, dist_loss: 0.4721679091453552
recon_loss: 0.02899191714823246, dist_loss: 0.34143373370170593
recon_loss: 0.028992092236876488, dist_loss: 1.0791704654693604
recon_loss: 0.028991878032684326, dist_loss: 0.5812532305717468
recon_loss: 0.028991688042879105, dist_loss: 0.5854002237319946
recon_loss: 0.028991933912038803, dist_loss: 0.6145695447921753
recon_loss: 0.028992008417844772, dist_loss: 1.0516053438186646
recon_loss: 0.028991715982556343, dist_loss: 0.6724417209625244
recon_loss: 0.02899119257926941, dist_loss: 0.9248980283737183
recon_loss: 0.028991637751460075, dist_loss: 0.49651700258255005
recon_loss: 0.028991814702749252, dist_loss: 0.7702414989471436
recon_loss: 0.028991471976041794, dist_loss: 0.6664847731590271
recon_loss: 0.028991952538490295, dist_loss: 0.989361047744751
recon_loss: 0.02899187058210373, dist_loss: 0.906713604927063
recon_loss: 0.028991229832172394, dist_loss: 0.7683680057525635
recon_loss: 0.028990738093852997, dist_loss: 0.7001259922981262
recon_loss: 0.02899048663675785, dist_loss: 0.7995496988296509
recon_loss: 0.028991132974624634, dist_loss: 0.29030168056488037
recon_loss: 0.028992144390940666, dist_loss: 0.42755332589149475
recon_loss: 0.02899220399558544, dist_loss: 0.8348159790039062
recon_loss: 0.028991814702749252, dist_loss: 0.7511588931083679
recon_loss: 0.028991632163524628, dist_loss: 0.6955794095993042
recon_loss: 0.02899079956114292, dist_loss: 0.962026834487915
recon_loss: 0.02899104356765747, dist_loss: 0.5189162492752075
recon_loss: 0.0289919376373291, dist_loss: 0.6259543299674988
recon_loss: 0.028992045670747757, dist_loss: 0.750860333442688
recon_loss: 0.028992140665650368, dist_loss: 0.9122879505157471
recon_loss: 0.02899244613945484, dist_loss: 0.6748158931732178
recon_loss: 0.02899186499416828, dist_loss: 0.5275125503540039
recon_loss: 0.028991663828492165, dist_loss: 0.9641244411468506
recon_loss: 0.02899170108139515, dist_loss: 0.2978273332118988
recon_loss: 0.028991755098104477, dist_loss: 0.7562234401702881
recon_loss: 0.02899187058210373, dist_loss: 0.6265881657600403
recon_loss: 0.028992455452680588, dist_loss: 0.6563331484794617
recon_loss: 0.028991172090172768, dist_loss: 0.6155602931976318
recon_loss: 0.028990594670176506, dist_loss: 0.8128620386123657
recon_loss: 0.028990188613533974, dist_loss: 0.5208479166030884
recon_loss: 0.028989624232053757, dist_loss: 0.44055086374282837
Pre-training Epoch 51:  70%|███████   | 258/367 [00:01<00:00, 190.43it/s]Pre-training Epoch 51:  76%|███████▌  | 278/367 [00:01<00:00, 190.97it/s]Pre-training Epoch 51:  81%|████████  | 298/367 [00:01<00:00, 190.84it/s]Pre-training Epoch 51:  87%|████████▋ | 318/367 [00:01<00:00, 181.00it/s]Pre-training Epoch 51:  92%|█████████▏| 337/367 [00:01<00:00, 175.19it/s]Pre-training Epoch 51:  97%|█████████▋| 355/367 [00:01<00:00, 172.51it/s]Pre-training Epoch 51: 100%|██████████| 367/367 [00:02<00:00, 183.01it/s]
recon_loss: 0.028989657759666443, dist_loss: 0.6140280365943909
recon_loss: 0.028990838676691055, dist_loss: 0.5151084661483765
recon_loss: 0.02899022586643696, dist_loss: 0.7608456015586853
recon_loss: 0.028990209102630615, dist_loss: 0.9868669509887695
recon_loss: 0.028990497812628746, dist_loss: 0.5697682499885559
recon_loss: 0.02899009920656681, dist_loss: 0.7946197390556335
recon_loss: 0.028990764170885086, dist_loss: 0.644967257976532
recon_loss: 0.028992682695388794, dist_loss: 0.9201221466064453
recon_loss: 0.02899244986474514, dist_loss: 0.7872728705406189
recon_loss: 0.028993448242545128, dist_loss: 0.6899369955062866
recon_loss: 0.028994567692279816, dist_loss: 0.9197704195976257
recon_loss: 0.0289948470890522, dist_loss: 0.7897592782974243
recon_loss: 0.028995929285883904, dist_loss: 0.5326575040817261
recon_loss: 0.028996994718909264, dist_loss: 0.8130519390106201
recon_loss: 0.028996219858527184, dist_loss: 0.6189425587654114
recon_loss: 0.028995560482144356, dist_loss: 0.6512233018875122
recon_loss: 0.02899445779621601, dist_loss: 0.7272423505783081
recon_loss: 0.028992755338549614, dist_loss: 0.5849282741546631
recon_loss: 0.028991688042879105, dist_loss: 0.439202219247818
recon_loss: 0.028990736231207848, dist_loss: 0.6839523315429688
recon_loss: 0.02898966334760189, dist_loss: 0.4075530171394348
recon_loss: 0.02898865006864071, dist_loss: 0.8611665964126587
recon_loss: 0.02898799441754818, dist_loss: 0.46159201860427856
recon_loss: 0.028987528756260872, dist_loss: 0.9813050031661987
recon_loss: 0.02898758463561535, dist_loss: 0.43707096576690674
recon_loss: 0.02898796834051609, dist_loss: 0.4017660319805145
recon_loss: 0.028988070785999298, dist_loss: 0.72608482837677
recon_loss: 0.028988204896450043, dist_loss: 0.6609947085380554
recon_loss: 0.028988277539610863, dist_loss: 0.7341687679290771
recon_loss: 0.028988149017095566, dist_loss: 0.7738063335418701
recon_loss: 0.028987832367420197, dist_loss: 0.7705864310264587
recon_loss: 0.028987295925617218, dist_loss: 0.6227386593818665
recon_loss: 0.028986893594264984, dist_loss: 0.7622858881950378
recon_loss: 0.028986148536205292, dist_loss: 0.8622643351554871
recon_loss: 0.02898534946143627, dist_loss: 0.5903658866882324
recon_loss: 0.028985021635890007, dist_loss: 0.31357496976852417
recon_loss: 0.028984783217310905, dist_loss: 0.9164648056030273
recon_loss: 0.028984658420085907, dist_loss: 0.46362394094467163
recon_loss: 0.028984980657696724, dist_loss: 0.7157886624336243
recon_loss: 0.028985675424337387, dist_loss: 0.6186084151268005
recon_loss: 0.028985703364014626, dist_loss: 0.7305548191070557
recon_loss: 0.028986070305109024, dist_loss: 0.7158094644546509
recon_loss: 0.02898618020117283, dist_loss: 0.4857746362686157
recon_loss: 0.028986040502786636, dist_loss: 0.3278845548629761
recon_loss: 0.02898566797375679, dist_loss: 0.6033157706260681
recon_loss: 0.028985297307372093, dist_loss: 0.3685489892959595
recon_loss: 0.0289850402623415, dist_loss: 0.5809687376022339
recon_loss: 0.02898435853421688, dist_loss: 0.9121832847595215
recon_loss: 0.02898358553647995, dist_loss: 0.6797346472740173
recon_loss: 0.02898300811648369, dist_loss: 1.2182765007019043
recon_loss: 0.0289822556078434, dist_loss: 0.575633704662323
recon_loss: 0.028981883078813553, dist_loss: 0.5547471642494202
recon_loss: 0.028981812298297882, dist_loss: 0.53934645652771
recon_loss: 0.028981775045394897, dist_loss: 0.6328903436660767
recon_loss: 0.02898181788623333, dist_loss: 0.8960809707641602
recon_loss: 0.028982013463974, dist_loss: 0.48273447155952454
recon_loss: 0.028982117772102356, dist_loss: 0.7867874503135681
recon_loss: 0.028982579708099365, dist_loss: 0.5126628279685974
recon_loss: 0.028982562944293022, dist_loss: 0.4146212637424469
recon_loss: 0.028982561081647873, dist_loss: 0.497383177280426
recon_loss: 0.028982670977711678, dist_loss: 0.5771365165710449
recon_loss: 0.028982918709516525, dist_loss: 0.49637743830680847
recon_loss: 0.028982913121581078, dist_loss: 0.6226900815963745
recon_loss: 0.028982888907194138, dist_loss: 0.5145730972290039
recon_loss: 0.028982890769839287, dist_loss: 1.1446300745010376
recon_loss: 0.028982803225517273, dist_loss: 0.42937958240509033
recon_loss: 0.028982115909457207, dist_loss: 0.5980165004730225
recon_loss: 0.028981350362300873, dist_loss: 0.49610936641693115
recon_loss: 0.028980782255530357, dist_loss: 0.7517311573028564
recon_loss: 0.028980160132050514, dist_loss: 0.4902070164680481
recon_loss: 0.028979752212762833, dist_loss: 0.9314600229263306
recon_loss: 0.02897956408560276, dist_loss: 0.569491982460022
recon_loss: 0.028979239985346794, dist_loss: 1.011674404144287
recon_loss: 0.028978850692510605, dist_loss: 0.6850835084915161
recon_loss: 0.02897888980805874, dist_loss: 0.924647331237793
recon_loss: 0.02897881530225277, dist_loss: 0.4148481488227844
recon_loss: 0.028978310525417328, dist_loss: 0.6047532558441162
recon_loss: 0.028978247195482254, dist_loss: 0.3966296911239624
recon_loss: 0.02897828444838524, dist_loss: 0.4154326021671295
recon_loss: 0.028978021815419197, dist_loss: 0.4035908877849579
recon_loss: 0.028977567330002785, dist_loss: 0.8008872270584106
recon_loss: 0.02897711470723152, dist_loss: 0.581762969493866
recon_loss: 0.028976809233427048, dist_loss: 0.6960211992263794
recon_loss: 0.02897646091878414, dist_loss: 1.0442062616348267
recon_loss: 0.02897661365568638, dist_loss: 0.41223037242889404
recon_loss: 0.02897694893181324, dist_loss: 0.8121784329414368
recon_loss: 0.028977351263165474, dist_loss: 0.8274508714675903
recon_loss: 0.0289777759462595, dist_loss: 0.21479754149913788
recon_loss: 0.028976857662200928, dist_loss: 0.5222336053848267
recon_loss: 0.02897569350898266, dist_loss: 0.556434154510498
recon_loss: 0.0289766825735569, dist_loss: 0.4407913386821747
recon_loss: 0.02897643856704235, dist_loss: 0.5675684809684753
recon_loss: 0.02897542528808117, dist_loss: 1.006059169769287
recon_loss: 0.028975656256079674, dist_loss: 0.80792236328125
recon_loss: 0.028975531458854675, dist_loss: 1.0024181604385376
recon_loss: 0.028975950554013252, dist_loss: 0.6514350175857544
recon_loss: 0.028976276516914368, dist_loss: 0.40548062324523926
recon_loss: 0.028976066038012505, dist_loss: 0.9884122610092163
recon_loss: 0.02897581085562706, dist_loss: 0.8359940052032471
recon_loss: 0.028975453227758408, dist_loss: 0.6597715616226196
recon_loss: 0.02897525578737259, dist_loss: 0.7168670892715454
recon_loss: 0.028975339606404305, dist_loss: 0.6567233800888062
recon_loss: 0.028975410386919975, dist_loss: 0.8129752278327942
recon_loss: 0.028975211083889008, dist_loss: 0.6217950582504272
recon_loss: 0.02897501550614834, dist_loss: 0.7148022651672363
recon_loss: 0.028974778950214386, dist_loss: 0.4580202102661133
recon_loss: 0.02897423878312111, dist_loss: 0.9185519814491272
recon_loss: 0.028973868116736412, dist_loss: 0.3544214367866516
recon_loss: 0.028973596170544624, dist_loss: 0.7296070456504822
recon_loss: 0.028973346576094627, dist_loss: 0.7845706939697266
recon_loss: 0.028973547741770744, dist_loss: 0.28633415699005127
Pre-training Epoch 52:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 52:   4%|▍         | 16/367 [00:00<00:02, 154.52it/s]Pre-training Epoch 52:   9%|▉         | 33/367 [00:00<00:02, 160.44it/s]Pre-training Epoch 52:  14%|█▍        | 53/367 [00:00<00:01, 174.54it/s]Pre-training Epoch 52:  20%|█▉        | 73/367 [00:00<00:01, 181.44it/s]Pre-training Epoch 52:  25%|██▌       | 92/367 [00:00<00:01, 178.02it/s]Pre-training Epoch 52:  30%|██▉       | 110/367 [00:00<00:01, 173.65it/s]Pre-training Epoch 52:  35%|███▍      | 128/367 [00:00<00:01, 170.81it/s]recon_loss: 0.028973428532481194, dist_loss: 0.3698651194572449
recon_loss: 0.028973668813705444, dist_loss: 0.7918708324432373
recon_loss: 0.02897414192557335, dist_loss: 0.5903337001800537
recon_loss: 0.028974182903766632, dist_loss: 0.5935401320457458
recon_loss: 0.028974004089832306, dist_loss: 0.6801338195800781
recon_loss: 0.02897406928241253, dist_loss: 0.585851788520813
recon_loss: 0.028973788022994995, dist_loss: 0.9004901051521301
recon_loss: 0.028973503038287163, dist_loss: 0.5793535709381104
recon_loss: 0.028973625972867012, dist_loss: 0.2439088374376297
recon_loss: 0.028973432257771492, dist_loss: 0.6112831234931946
recon_loss: 0.028973007574677467, dist_loss: 0.3379155993461609
recon_loss: 0.028973082080483437, dist_loss: 0.7883526086807251
recon_loss: 0.02897246554493904, dist_loss: 0.9204214811325073
recon_loss: 0.028972119092941284, dist_loss: 1.0862038135528564
recon_loss: 0.02897193655371666, dist_loss: 0.9170902371406555
recon_loss: 0.028971867635846138, dist_loss: 1.7745479345321655
recon_loss: 0.028971705585718155, dist_loss: 0.47493237257003784
recon_loss: 0.028971543535590172, dist_loss: 0.5531984567642212
recon_loss: 0.02897142432630062, dist_loss: 0.7476286292076111
recon_loss: 0.028971461579203606, dist_loss: 0.4758889079093933
recon_loss: 0.028971342369914055, dist_loss: 0.647624135017395
recon_loss: 0.0289714764803648, dist_loss: 1.045743465423584
recon_loss: 0.028971601277589798, dist_loss: 0.5211294889450073
recon_loss: 0.028971172869205475, dist_loss: 0.4502100348472595
recon_loss: 0.028971660882234573, dist_loss: 0.3327018618583679
recon_loss: 0.02897234819829464, dist_loss: 1.2313934564590454
recon_loss: 0.028972981497645378, dist_loss: 0.6667543649673462
recon_loss: 0.028973489999771118, dist_loss: 0.6998721361160278
recon_loss: 0.028973594307899475, dist_loss: 0.2354382872581482
recon_loss: 0.028973599895834923, dist_loss: 0.6180175542831421
recon_loss: 0.028973309323191643, dist_loss: 0.7366145849227905
recon_loss: 0.028973251581192017, dist_loss: 0.516743540763855
recon_loss: 0.028973164036870003, dist_loss: 0.566769540309906
recon_loss: 0.028972923755645752, dist_loss: 0.5096560120582581
recon_loss: 0.02897253818809986, dist_loss: 0.7551183700561523
recon_loss: 0.028972122818231583, dist_loss: 0.6076309680938721
recon_loss: 0.028971774503588676, dist_loss: 0.4553690552711487
recon_loss: 0.02897108905017376, dist_loss: 0.9146219491958618
recon_loss: 0.028970418497920036, dist_loss: 0.342210590839386
recon_loss: 0.02897026017308235, dist_loss: 0.7193232774734497
recon_loss: 0.028970448300242424, dist_loss: 0.6174929738044739
recon_loss: 0.02897082269191742, dist_loss: 0.426405131816864
recon_loss: 0.02897106111049652, dist_loss: 1.1442252397537231
recon_loss: 0.028970832005143166, dist_loss: 0.8196495771408081
recon_loss: 0.028970323503017426, dist_loss: 0.788912832736969
recon_loss: 0.0289699025452137, dist_loss: 0.7605195045471191
recon_loss: 0.028969818726181984, dist_loss: 0.49722325801849365
recon_loss: 0.028970198705792427, dist_loss: 0.5621342658996582
recon_loss: 0.02897036261856556, dist_loss: 0.6459221839904785
recon_loss: 0.028970971703529358, dist_loss: 0.4648783206939697
recon_loss: 0.02897060662508011, dist_loss: 0.5992194414138794
recon_loss: 0.028970083221793175, dist_loss: 0.5663216710090637
recon_loss: 0.028969602659344673, dist_loss: 0.8932844400405884
recon_loss: 0.028969308361411095, dist_loss: 0.5409590005874634
recon_loss: 0.028969531878829002, dist_loss: 0.4178787171840668
recon_loss: 0.028969839215278625, dist_loss: 0.6570844054222107
recon_loss: 0.028969546779990196, dist_loss: 0.44408684968948364
recon_loss: 0.028969168663024902, dist_loss: 0.9042991399765015
recon_loss: 0.028969306498765945, dist_loss: 0.6554053425788879
recon_loss: 0.028969086706638336, dist_loss: 0.468563437461853
recon_loss: 0.028968248516321182, dist_loss: 0.7903136014938354
recon_loss: 0.02896827645599842, dist_loss: 0.5159223079681396
recon_loss: 0.02896811068058014, dist_loss: 0.3692741394042969
recon_loss: 0.02896767295897007, dist_loss: 1.4432880878448486
recon_loss: 0.02896769344806671, dist_loss: 0.7701101303100586
recon_loss: 0.028967857360839844, dist_loss: 0.5045059323310852
recon_loss: 0.028967469930648804, dist_loss: 0.3076964318752289
recon_loss: 0.028967425227165222, dist_loss: 0.818534255027771
recon_loss: 0.02896777167916298, dist_loss: 0.5795246362686157
recon_loss: 0.028967030346393585, dist_loss: 0.5328748822212219
recon_loss: 0.028966696932911873, dist_loss: 0.5061242580413818
recon_loss: 0.028966914862394333, dist_loss: 1.0567320585250854
recon_loss: 0.028966832906007767, dist_loss: 0.5859431028366089
recon_loss: 0.028965869918465614, dist_loss: 0.620506763458252
recon_loss: 0.02896646037697792, dist_loss: 0.8467411994934082
recon_loss: 0.028965836390852928, dist_loss: 0.8828805685043335
recon_loss: 0.028965573757886887, dist_loss: 0.8147130608558655
recon_loss: 0.028965886682271957, dist_loss: 0.7247095108032227
recon_loss: 0.02896467037498951, dist_loss: 0.4785047769546509
recon_loss: 0.02896469458937645, dist_loss: 0.32646042108535767
recon_loss: 0.02896486036479473, dist_loss: 0.45258253812789917
recon_loss: 0.028964297845959663, dist_loss: 0.6790367364883423
recon_loss: 0.028964437544345856, dist_loss: 0.6088811159133911
recon_loss: 0.02896452136337757, dist_loss: 0.6555843353271484
recon_loss: 0.02896394021809101, dist_loss: 0.5342894196510315
recon_loss: 0.028965434059500694, dist_loss: 0.4877302348613739
recon_loss: 0.028966613113880157, dist_loss: 0.39615732431411743
recon_loss: 0.028967952355742455, dist_loss: 0.3226626515388489
recon_loss: 0.028968364000320435, dist_loss: 0.5047062635421753
recon_loss: 0.028967183083295822, dist_loss: 0.6518670320510864
recon_loss: 0.028966911137104034, dist_loss: 0.8413047790527344
recon_loss: 0.028967056423425674, dist_loss: 0.7895424365997314
recon_loss: 0.02896662801504135, dist_loss: 0.42216289043426514
recon_loss: 0.0289669930934906, dist_loss: 0.49731630086898804
recon_loss: 0.028966791927814484, dist_loss: 0.5309487581253052
recon_loss: 0.028965940698981285, dist_loss: 0.9272942543029785
recon_loss: 0.028965340927243233, dist_loss: 0.7869500517845154
recon_loss: 0.028964783996343613, dist_loss: 0.7851592898368835
recon_loss: 0.02896432764828205, dist_loss: 0.8567254543304443
recon_loss: 0.02896447665989399, dist_loss: 0.3819372355937958
recon_loss: 0.028964726254343987, dist_loss: 0.5459672212600708
recon_loss: 0.028965167701244354, dist_loss: 0.8628501892089844
recon_loss: 0.028965674340724945, dist_loss: 0.7541876435279846
recon_loss: 0.028965957462787628, dist_loss: 0.6853461265563965
recon_loss: 0.028966914862394333, dist_loss: 0.9236682653427124
recon_loss: 0.028966031968593597, dist_loss: 0.752487301826477
recon_loss: 0.028965817764401436, dist_loss: 0.4370434284210205
recon_loss: 0.0289653018116951, dist_loss: 1.0049118995666504
recon_loss: 0.028963258489966393, dist_loss: 0.5375221967697144
recon_loss: 0.02896265685558319, dist_loss: 0.7408345937728882
recon_loss: 0.028962157666683197, dist_loss: 0.6264153122901917
recon_loss: 0.028961632400751114, dist_loss: 0.9949790835380554
recon_loss: 0.028961727395653725, dist_loss: 0.832594096660614
recon_loss: 0.02896171808242798, dist_loss: 0.8411965370178223
recon_loss: 0.028961801901459694, dist_loss: 0.8989206552505493
recon_loss: 0.028961993753910065, dist_loss: 0.4867886006832123
recon_loss: 0.028961826115846634, dist_loss: 0.7082406282424927
recon_loss: 0.02896154671907425, dist_loss: 0.4574415683746338
recon_loss: 0.02896122634410858, dist_loss: 0.7548593282699585
recon_loss: 0.028960809111595154, dist_loss: 0.7205765247344971
recon_loss: 0.0289604552090168, dist_loss: 0.47281959652900696
recon_loss: 0.028960010036826134, dist_loss: 0.8713839054107666
recon_loss: 0.028960157185792923, dist_loss: 0.8542957901954651
recon_loss: 0.028959695249795914, dist_loss: 0.8457788228988647
recon_loss: 0.02895907498896122, dist_loss: 0.6280441284179688
recon_loss: 0.028959212824702263, dist_loss: 0.8893663287162781
recon_loss: 0.028958778828382492, dist_loss: 0.3787994384765625
recon_loss: 0.028958819806575775, dist_loss: 0.2731342911720276
Pre-training Epoch 52:  40%|███▉      | 146/367 [00:00<00:01, 168.84it/s]Pre-training Epoch 52:  44%|████▍     | 163/367 [00:00<00:01, 167.62it/s]Pre-training Epoch 52:  49%|████▉     | 180/367 [00:01<00:01, 166.76it/s]Pre-training Epoch 52:  54%|█████▎    | 197/367 [00:01<00:01, 165.80it/s]Pre-training Epoch 52:  59%|█████▊    | 215/367 [00:01<00:00, 169.82it/s]Pre-training Epoch 52:  64%|██████▍   | 234/367 [00:01<00:00, 173.31it/s]Pre-training Epoch 52:  69%|██████▉   | 254/367 [00:01<00:00, 178.56it/s]recon_loss: 0.028958972543478012, dist_loss: 0.6000866889953613
recon_loss: 0.028958676382899284, dist_loss: 0.5322368144989014
recon_loss: 0.02895861677825451, dist_loss: 0.9121243953704834
recon_loss: 0.028958551585674286, dist_loss: 0.8548568487167358
recon_loss: 0.028958424925804138, dist_loss: 0.30729252099990845
recon_loss: 0.028958110138773918, dist_loss: 0.5725870728492737
recon_loss: 0.02895800583064556, dist_loss: 0.8331453800201416
recon_loss: 0.02895755134522915, dist_loss: 0.3189747631549835
recon_loss: 0.0289573036134243, dist_loss: 0.6937072277069092
recon_loss: 0.02895716205239296, dist_loss: 0.7628856897354126
recon_loss: 0.028957266360521317, dist_loss: 0.7626109719276428
recon_loss: 0.02895776741206646, dist_loss: 1.1029694080352783
recon_loss: 0.028957532718777657, dist_loss: 0.3655780255794525
recon_loss: 0.028957832604646683, dist_loss: 0.7503819465637207
recon_loss: 0.02895781397819519, dist_loss: 0.6326497197151184
recon_loss: 0.028957586735486984, dist_loss: 0.7529395818710327
recon_loss: 0.028957508504390717, dist_loss: 0.879898190498352
recon_loss: 0.028957493603229523, dist_loss: 0.6296215653419495
recon_loss: 0.028957923874258995, dist_loss: 0.4039148688316345
recon_loss: 0.028958061710000038, dist_loss: 0.5112981796264648
recon_loss: 0.028958262875676155, dist_loss: 1.0535191297531128
recon_loss: 0.028957990929484367, dist_loss: 0.6519069671630859
recon_loss: 0.028957916423678398, dist_loss: 0.43604156374931335
recon_loss: 0.028958044946193695, dist_loss: 0.7329736351966858
recon_loss: 0.02895834483206272, dist_loss: 1.0529427528381348
recon_loss: 0.02895854227244854, dist_loss: 0.5201991200447083
recon_loss: 0.028958545997738838, dist_loss: 0.7208759784698486
recon_loss: 0.028958262875676155, dist_loss: 1.2269618511199951
recon_loss: 0.028957853093743324, dist_loss: 0.6071146726608276
recon_loss: 0.028957899659872055, dist_loss: 0.7020632028579712
recon_loss: 0.028958112001419067, dist_loss: 0.2957689166069031
recon_loss: 0.02895807847380638, dist_loss: 0.7087714672088623
recon_loss: 0.02895803563296795, dist_loss: 0.8744728565216064
recon_loss: 0.028958136215806007, dist_loss: 0.623377799987793
recon_loss: 0.028957944363355637, dist_loss: 0.8339078426361084
recon_loss: 0.028957415372133255, dist_loss: 0.5881671905517578
recon_loss: 0.028956953436136246, dist_loss: 0.6412206888198853
recon_loss: 0.02895686961710453, dist_loss: 0.43785732984542847
recon_loss: 0.02895686775445938, dist_loss: 0.6231746077537537
recon_loss: 0.02895660698413849, dist_loss: 0.6302104592323303
recon_loss: 0.028956254944205284, dist_loss: 1.1984429359436035
recon_loss: 0.028955725952982903, dist_loss: 0.8613241910934448
recon_loss: 0.02895568683743477, dist_loss: 0.5728206634521484
recon_loss: 0.02895590290427208, dist_loss: 0.6924817562103271
recon_loss: 0.028956042602658272, dist_loss: 0.5829448699951172
recon_loss: 0.02895575761795044, dist_loss: 0.5993309020996094
recon_loss: 0.02895543724298477, dist_loss: 1.011730432510376
recon_loss: 0.028955180197954178, dist_loss: 0.8738874197006226
recon_loss: 0.02895492874085903, dist_loss: 0.5759565234184265
recon_loss: 0.028954947367310524, dist_loss: 0.5839849710464478
recon_loss: 0.028955047950148582, dist_loss: 0.9076290130615234
recon_loss: 0.028954919427633286, dist_loss: 0.7975005507469177
recon_loss: 0.02895502746105194, dist_loss: 0.469906747341156
recon_loss: 0.028954822570085526, dist_loss: 1.1841254234313965
recon_loss: 0.028954461216926575, dist_loss: 0.6924177408218384
recon_loss: 0.028954574838280678, dist_loss: 0.7347545623779297
recon_loss: 0.028954386711120605, dist_loss: 0.7712941765785217
recon_loss: 0.028954116627573967, dist_loss: 1.0706859827041626
recon_loss: 0.028954267501831055, dist_loss: 0.49546778202056885
recon_loss: 0.028954047709703445, dist_loss: 0.4138970375061035
recon_loss: 0.028954198583960533, dist_loss: 1.0230140686035156
recon_loss: 0.02895430102944374, dist_loss: 1.1104767322540283
recon_loss: 0.02895423024892807, dist_loss: 0.5362154841423035
recon_loss: 0.028954653069376945, dist_loss: 0.51532381772995
recon_loss: 0.028954604640603065, dist_loss: 0.9552968740463257
recon_loss: 0.028954071924090385, dist_loss: 0.8243391513824463
recon_loss: 0.028954265639185905, dist_loss: 0.8029391765594482
recon_loss: 0.028953807428479195, dist_loss: 0.5476154088973999
recon_loss: 0.028953764587640762, dist_loss: 0.5232250690460205
recon_loss: 0.028954127803444862, dist_loss: 0.3800988495349884
recon_loss: 0.028953535482287407, dist_loss: 0.7065078020095825
recon_loss: 0.02895345725119114, dist_loss: 1.0689561367034912
recon_loss: 0.028954006731510162, dist_loss: 0.32452958822250366
recon_loss: 0.02895347774028778, dist_loss: 0.6301541328430176
recon_loss: 0.02895311452448368, dist_loss: 0.6693927049636841
recon_loss: 0.028954103589057922, dist_loss: 0.768759548664093
recon_loss: 0.028953641653060913, dist_loss: 0.7154867649078369
recon_loss: 0.028952987864613533, dist_loss: 0.9416379332542419
recon_loss: 0.02895461767911911, dist_loss: 0.9057185649871826
recon_loss: 0.02895328775048256, dist_loss: 0.41598278284072876
recon_loss: 0.028953244909644127, dist_loss: 0.7251741886138916
recon_loss: 0.028953615576028824, dist_loss: 0.656707227230072
recon_loss: 0.02895323559641838, dist_loss: 0.5117560625076294
recon_loss: 0.0289541594684124, dist_loss: 0.4146844148635864
recon_loss: 0.028953785076737404, dist_loss: 0.6070477366447449
recon_loss: 0.028953086584806442, dist_loss: 0.7794703245162964
recon_loss: 0.028953228145837784, dist_loss: 0.639496386051178
recon_loss: 0.028952190652489662, dist_loss: 0.6326620578765869
recon_loss: 0.028951594606041908, dist_loss: 0.5459678173065186
recon_loss: 0.02895263396203518, dist_loss: 0.71133953332901
recon_loss: 0.028951099142432213, dist_loss: 0.42262569069862366
recon_loss: 0.028951220214366913, dist_loss: 1.0439112186431885
recon_loss: 0.02895117551088333, dist_loss: 0.5277527570724487
recon_loss: 0.028950722888112068, dist_loss: 0.6516110897064209
recon_loss: 0.028950432315468788, dist_loss: 0.42934727668762207
recon_loss: 0.0289518591016531, dist_loss: 0.7371920347213745
recon_loss: 0.02895163930952549, dist_loss: 0.6132422685623169
recon_loss: 0.028951819986104965, dist_loss: 0.36294102668762207
recon_loss: 0.02895275689661503, dist_loss: 0.7277330160140991
recon_loss: 0.028951840475201607, dist_loss: 0.8990589380264282
recon_loss: 0.028952110558748245, dist_loss: 0.9560200572013855
recon_loss: 0.028952214866876602, dist_loss: 0.645272970199585
recon_loss: 0.028951358050107956, dist_loss: 0.8267518281936646
recon_loss: 0.028951281681656837, dist_loss: 0.7918590903282166
recon_loss: 0.028951644897460938, dist_loss: 0.9207845330238342
recon_loss: 0.028951214626431465, dist_loss: 0.5722646713256836
recon_loss: 0.02895161136984825, dist_loss: 0.27634626626968384
recon_loss: 0.028951801359653473, dist_loss: 0.42371395230293274
recon_loss: 0.028951473534107208, dist_loss: 0.4175216257572174
recon_loss: 0.028950799256563187, dist_loss: 0.8451995849609375
recon_loss: 0.02895049937069416, dist_loss: 0.5890466570854187
recon_loss: 0.028950313106179237, dist_loss: 0.6229684948921204
recon_loss: 0.028950072824954987, dist_loss: 0.629278838634491
recon_loss: 0.028949784114956856, dist_loss: 0.5223395228385925
recon_loss: 0.028949279338121414, dist_loss: 0.6219481229782104
recon_loss: 0.02894880250096321, dist_loss: 0.7928186655044556
recon_loss: 0.02894863486289978, dist_loss: 0.5085561871528625
recon_loss: 0.02894807793200016, dist_loss: 0.7501510977745056
recon_loss: 0.028947701677680016, dist_loss: 0.5679160356521606
recon_loss: 0.028947744518518448, dist_loss: 0.6469666957855225
recon_loss: 0.02894759364426136, dist_loss: 0.5709919929504395
recon_loss: 0.028947334736585617, dist_loss: 0.42198508977890015
recon_loss: 0.028946954756975174, dist_loss: 0.48475295305252075
recon_loss: 0.02894662506878376, dist_loss: 0.373349666595459
recon_loss: 0.02894645370543003, dist_loss: 0.5319419503211975
recon_loss: 0.028946438804268837, dist_loss: 0.44325071573257446
recon_loss: 0.028946373611688614, dist_loss: 1.4628956317901611
recon_loss: 0.02894653007388115, dist_loss: 0.5920507907867432
Pre-training Epoch 52:  75%|███████▍  | 274/367 [00:01<00:00, 182.48it/s]Pre-training Epoch 52:  80%|████████  | 294/367 [00:01<00:00, 185.47it/s]Pre-training Epoch 52:  86%|████████▌ | 314/367 [00:01<00:00, 187.38it/s]Pre-training Epoch 52:  91%|█████████ | 334/367 [00:01<00:00, 188.88it/s]Pre-training Epoch 52:  96%|█████████▋| 354/367 [00:01<00:00, 189.95it/s]Pre-training Epoch 52: 100%|██████████| 367/367 [00:02<00:00, 177.95it/s]
recon_loss: 0.028946809470653534, dist_loss: 0.47469884157180786
recon_loss: 0.028946528211236, dist_loss: 0.34638574719429016
recon_loss: 0.028946150094270706, dist_loss: 0.6484423279762268
recon_loss: 0.02894592471420765, dist_loss: 0.6871613264083862
recon_loss: 0.02894587442278862, dist_loss: 0.6507798433303833
recon_loss: 0.02894587442278862, dist_loss: 0.9979194402694702
recon_loss: 0.02894550748169422, dist_loss: 0.6770769357681274
recon_loss: 0.02894517220556736, dist_loss: 0.8023017048835754
recon_loss: 0.028944991528987885, dist_loss: 0.7059908509254456
recon_loss: 0.028944727033376694, dist_loss: 0.884533166885376
recon_loss: 0.028944622725248337, dist_loss: 0.6141270399093628
recon_loss: 0.028944721445441246, dist_loss: 0.7545366287231445
recon_loss: 0.028945041820406914, dist_loss: 0.49614882469177246
recon_loss: 0.028944889083504677, dist_loss: 0.4919031262397766
recon_loss: 0.02894463576376438, dist_loss: 0.41166675090789795
recon_loss: 0.02894444577395916, dist_loss: 0.8138017058372498
recon_loss: 0.028944049030542374, dist_loss: 1.0016542673110962
recon_loss: 0.02894400805234909, dist_loss: 0.9837596416473389
recon_loss: 0.028944674879312515, dist_loss: 0.462854266166687
recon_loss: 0.02894505299627781, dist_loss: 0.6428201198577881
recon_loss: 0.02894498221576214, dist_loss: 0.43973779678344727
recon_loss: 0.028945263475179672, dist_loss: 0.6967412829399109
recon_loss: 0.028944484889507294, dist_loss: 0.4357356131076813
recon_loss: 0.02894405461847782, dist_loss: 0.4486117362976074
recon_loss: 0.028944216668605804, dist_loss: 0.7635663151741028
recon_loss: 0.028944477438926697, dist_loss: 0.4655526876449585
recon_loss: 0.028944632038474083, dist_loss: 0.5373727083206177
recon_loss: 0.02894468978047371, dist_loss: 0.9846720695495605
recon_loss: 0.02894454076886177, dist_loss: 0.8649038672447205
recon_loss: 0.028944289311766624, dist_loss: 0.8418198823928833
recon_loss: 0.028944378718733788, dist_loss: 0.5107161998748779
recon_loss: 0.028944145888090134, dist_loss: 1.2040085792541504
recon_loss: 0.028943587094545364, dist_loss: 0.5224494934082031
recon_loss: 0.028943143784999847, dist_loss: 0.5066200494766235
recon_loss: 0.028942571952939034, dist_loss: 0.680359959602356
recon_loss: 0.028942283242940903, dist_loss: 0.5477499961853027
recon_loss: 0.02894241362810135, dist_loss: 0.7427999973297119
recon_loss: 0.028942164033651352, dist_loss: 0.5325908064842224
recon_loss: 0.028941934928297997, dist_loss: 0.41594767570495605
recon_loss: 0.02894185483455658, dist_loss: 0.8586513996124268
recon_loss: 0.0289416816085577, dist_loss: 0.7631826400756836
recon_loss: 0.028941795229911804, dist_loss: 0.49933096766471863
recon_loss: 0.0289419274777174, dist_loss: 0.4550181031227112
recon_loss: 0.028941724449396133, dist_loss: 0.754153847694397
recon_loss: 0.028941884636878967, dist_loss: 0.5637096166610718
recon_loss: 0.02894253470003605, dist_loss: 0.3797720670700073
recon_loss: 0.02894267812371254, dist_loss: 0.478150337934494
recon_loss: 0.028943173587322235, dist_loss: 0.4727918207645416
recon_loss: 0.02894439548254013, dist_loss: 0.9625505208969116
recon_loss: 0.028945544734597206, dist_loss: 0.5253130197525024
recon_loss: 0.02894764579832554, dist_loss: 0.6484256386756897
recon_loss: 0.028947962448000908, dist_loss: 0.7340986728668213
recon_loss: 0.02894909866154194, dist_loss: 0.5096777081489563
recon_loss: 0.02895038016140461, dist_loss: 0.6377536654472351
recon_loss: 0.028951607644557953, dist_loss: 1.1043890714645386
recon_loss: 0.028951816260814667, dist_loss: 0.7653204202651978
recon_loss: 0.028951646760106087, dist_loss: 0.7533917427062988
recon_loss: 0.028951508924365044, dist_loss: 0.747312605381012
recon_loss: 0.02895086258649826, dist_loss: 0.5875287055969238
recon_loss: 0.028949813917279243, dist_loss: 0.6003381013870239
recon_loss: 0.028948500752449036, dist_loss: 0.5826838612556458
recon_loss: 0.02894684486091137, dist_loss: 0.7348484396934509
recon_loss: 0.028945038095116615, dist_loss: 0.594935417175293
recon_loss: 0.02894415706396103, dist_loss: 0.5991451144218445
recon_loss: 0.028943704441189766, dist_loss: 0.5404255390167236
recon_loss: 0.028942694887518883, dist_loss: 1.2905105352401733
recon_loss: 0.028942393139004707, dist_loss: 0.6452921628952026
recon_loss: 0.0289425328373909, dist_loss: 0.6290431618690491
recon_loss: 0.028943393379449844, dist_loss: 0.870735764503479
recon_loss: 0.028944455087184906, dist_loss: 0.6047663688659668
recon_loss: 0.02894563041627407, dist_loss: 0.45801854133605957
recon_loss: 0.028946509584784508, dist_loss: 0.6561260223388672
recon_loss: 0.02894720807671547, dist_loss: 0.7110947966575623
recon_loss: 0.028947778046131134, dist_loss: 0.7892191410064697
recon_loss: 0.028948573395609856, dist_loss: 0.6746833920478821
recon_loss: 0.028949925675988197, dist_loss: 0.3376014530658722
recon_loss: 0.028950916603207588, dist_loss: 0.704398512840271
recon_loss: 0.028951695188879967, dist_loss: 0.9637336134910583
recon_loss: 0.028952928259968758, dist_loss: 0.8051287531852722
recon_loss: 0.028952227905392647, dist_loss: 0.7838989496231079
recon_loss: 0.028952017426490784, dist_loss: 0.33979135751724243
recon_loss: 0.028951682150363922, dist_loss: 0.9142798185348511
recon_loss: 0.028951138257980347, dist_loss: 0.5682713389396667
recon_loss: 0.02895003743469715, dist_loss: 0.27082452178001404
recon_loss: 0.028948917984962463, dist_loss: 0.6967660188674927
recon_loss: 0.028947332873940468, dist_loss: 0.7160507440567017
recon_loss: 0.028945667669177055, dist_loss: 0.7170007228851318
recon_loss: 0.028943754732608795, dist_loss: 0.653160810470581
recon_loss: 0.028941940516233444, dist_loss: 0.9992673397064209
recon_loss: 0.02894079126417637, dist_loss: 1.0214511156082153
recon_loss: 0.02893979288637638, dist_loss: 0.5432483553886414
recon_loss: 0.028938964009284973, dist_loss: 0.3399934470653534
recon_loss: 0.028938107192516327, dist_loss: 0.5366581678390503
recon_loss: 0.028937144204974174, dist_loss: 0.68731689453125
recon_loss: 0.028936581686139107, dist_loss: 0.4066692292690277
recon_loss: 0.02893662266433239, dist_loss: 0.8799318075180054
recon_loss: 0.028937233611941338, dist_loss: 0.8205621242523193
recon_loss: 0.028938105329871178, dist_loss: 0.36078667640686035
recon_loss: 0.028939008712768555, dist_loss: 0.9098906517028809
recon_loss: 0.028938857838511467, dist_loss: 0.7932048439979553
recon_loss: 0.02893790788948536, dist_loss: 0.6563332676887512
recon_loss: 0.028937561437487602, dist_loss: 0.47049370408058167
recon_loss: 0.02893768809735775, dist_loss: 0.6152459979057312
recon_loss: 0.028937961906194687, dist_loss: 1.1775617599487305
recon_loss: 0.0289378110319376, dist_loss: 0.6236834526062012
recon_loss: 0.028936661779880524, dist_loss: 0.8095647096633911
recon_loss: 0.028935877606272697, dist_loss: 0.4952126443386078
recon_loss: 0.028934650123119354, dist_loss: 0.6187668442726135
recon_loss: 0.02893427200615406, dist_loss: 0.9160171151161194
recon_loss: 0.02893497236073017, dist_loss: 0.7580413818359375
recon_loss: 0.028936009854078293, dist_loss: 0.6605210900306702
Pre-training Epoch 53:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 53:   5%|▌         | 20/367 [00:00<00:01, 190.31it/s]Pre-training Epoch 53:  11%|█         | 40/367 [00:00<00:01, 191.27it/s]Pre-training Epoch 53:  16%|█▋        | 60/367 [00:00<00:01, 191.66it/s]Pre-training Epoch 53:  22%|██▏       | 80/367 [00:00<00:01, 191.88it/s]Pre-training Epoch 53:  27%|██▋       | 100/367 [00:00<00:01, 192.06it/s]Pre-training Epoch 53:  33%|███▎      | 120/367 [00:00<00:01, 192.05it/s]recon_loss: 0.028937382623553276, dist_loss: 0.4378697872161865
recon_loss: 0.02893705479800701, dist_loss: 1.1475789546966553
recon_loss: 0.02893643267452717, dist_loss: 0.40633881092071533
recon_loss: 0.02893543615937233, dist_loss: 0.9392050504684448
recon_loss: 0.028934672474861145, dist_loss: 0.7981370687484741
recon_loss: 0.028934305533766747, dist_loss: 0.5560005903244019
recon_loss: 0.028934966772794724, dist_loss: 0.5256229639053345
recon_loss: 0.0289358738809824, dist_loss: 0.7180968523025513
recon_loss: 0.028935512527823448, dist_loss: 0.45746365189552307
recon_loss: 0.02893434651196003, dist_loss: 0.5748133063316345
recon_loss: 0.028932936489582062, dist_loss: 0.2383272647857666
recon_loss: 0.02893207035958767, dist_loss: 0.7715643644332886
recon_loss: 0.02893264964222908, dist_loss: 0.7250416874885559
recon_loss: 0.02893318235874176, dist_loss: 0.8843517303466797
recon_loss: 0.028933890163898468, dist_loss: 0.9229883551597595
recon_loss: 0.028934158384799957, dist_loss: 0.6605116128921509
recon_loss: 0.028933485969901085, dist_loss: 0.734460711479187
recon_loss: 0.028932645916938782, dist_loss: 0.5031313896179199
recon_loss: 0.02893243171274662, dist_loss: 0.6036269664764404
recon_loss: 0.028931742534041405, dist_loss: 0.8788536787033081
recon_loss: 0.02893196791410446, dist_loss: 0.891740083694458
recon_loss: 0.02893150970339775, dist_loss: 0.5346980094909668
recon_loss: 0.02893066592514515, dist_loss: 0.7272977232933044
recon_loss: 0.02893034741282463, dist_loss: 0.6048200130462646
recon_loss: 0.028929952532052994, dist_loss: 0.5186922550201416
recon_loss: 0.028929345309734344, dist_loss: 0.9551463723182678
recon_loss: 0.028929486870765686, dist_loss: 0.5824363231658936
recon_loss: 0.028929397463798523, dist_loss: 0.5283334255218506
recon_loss: 0.02892957255244255, dist_loss: 1.0121949911117554
recon_loss: 0.02892988547682762, dist_loss: 0.6992377042770386
recon_loss: 0.028929946944117546, dist_loss: 1.2562693357467651
recon_loss: 0.028929883614182472, dist_loss: 0.41719090938568115
recon_loss: 0.028929730877280235, dist_loss: 1.1076537370681763
recon_loss: 0.028929943218827248, dist_loss: 0.713302493095398
recon_loss: 0.028930313885211945, dist_loss: 0.6627064943313599
recon_loss: 0.02892974019050598, dist_loss: 0.8332716226577759
recon_loss: 0.02892918512225151, dist_loss: 0.5407083034515381
recon_loss: 0.02892882004380226, dist_loss: 0.7681682705879211
recon_loss: 0.028927825391292572, dist_loss: 0.8605901002883911
recon_loss: 0.028927836567163467, dist_loss: 0.4765423536300659
recon_loss: 0.02892775647342205, dist_loss: 0.7803421020507812
recon_loss: 0.0289279967546463, dist_loss: 0.38213661313056946
recon_loss: 0.028928443789482117, dist_loss: 0.5509200692176819
recon_loss: 0.028928302228450775, dist_loss: 0.5704192519187927
recon_loss: 0.028927896171808243, dist_loss: 0.6698855757713318
recon_loss: 0.0289277546107769, dist_loss: 0.8499374389648438
recon_loss: 0.028927462175488472, dist_loss: 0.8222945332527161
recon_loss: 0.02892695553600788, dist_loss: 0.6169920563697815
recon_loss: 0.028927111998200417, dist_loss: 0.7468733787536621
recon_loss: 0.028927208855748177, dist_loss: 0.482150137424469
recon_loss: 0.028927763924002647, dist_loss: 0.4568208158016205
recon_loss: 0.02892877534031868, dist_loss: 0.5262064933776855
recon_loss: 0.028928279876708984, dist_loss: 0.5971577763557434
recon_loss: 0.02892746590077877, dist_loss: 0.7150759100914001
recon_loss: 0.02892695553600788, dist_loss: 0.40050944685935974
recon_loss: 0.02892657369375229, dist_loss: 0.8237936496734619
recon_loss: 0.028927095234394073, dist_loss: 0.5371608734130859
recon_loss: 0.028927842155098915, dist_loss: 0.5466769337654114
recon_loss: 0.028928108513355255, dist_loss: 0.4756603240966797
recon_loss: 0.02892812341451645, dist_loss: 0.4305019974708557
recon_loss: 0.02892736718058586, dist_loss: 0.6721400618553162
recon_loss: 0.028925821185112, dist_loss: 0.661480188369751
recon_loss: 0.02892548032104969, dist_loss: 0.6372394561767578
recon_loss: 0.028925776481628418, dist_loss: 0.5141717195510864
recon_loss: 0.028926433995366096, dist_loss: 0.5946449637413025
recon_loss: 0.028926832601428032, dist_loss: 1.1172451972961426
recon_loss: 0.028926851227879524, dist_loss: 0.500457763671875
recon_loss: 0.02892649918794632, dist_loss: 0.6672484278678894
recon_loss: 0.02892620675265789, dist_loss: 0.7754331231117249
recon_loss: 0.02892618626356125, dist_loss: 0.5300706028938293
recon_loss: 0.02892621047794819, dist_loss: 0.7121865749359131
recon_loss: 0.028926821425557137, dist_loss: 0.6266165375709534
recon_loss: 0.028927404433488846, dist_loss: 0.9031357169151306
recon_loss: 0.028927648440003395, dist_loss: 0.5989830493927002
recon_loss: 0.02892778441309929, dist_loss: 0.4738994836807251
recon_loss: 0.028927424922585487, dist_loss: 0.6282929182052612
recon_loss: 0.028926469385623932, dist_loss: 0.6290128231048584
recon_loss: 0.02892536111176014, dist_loss: 0.6272222995758057
recon_loss: 0.028924454003572464, dist_loss: 0.5168824195861816
recon_loss: 0.028924081474542618, dist_loss: 0.27455490827560425
recon_loss: 0.028924116864800453, dist_loss: 1.0726090669631958
recon_loss: 0.028924403712153435, dist_loss: 0.4354557394981384
recon_loss: 0.028924524784088135, dist_loss: 0.6099215149879456
recon_loss: 0.028924278914928436, dist_loss: 0.4229716360569
recon_loss: 0.02892380766570568, dist_loss: 0.7994680404663086
recon_loss: 0.028923414647579193, dist_loss: 0.6082616448402405
recon_loss: 0.028923042118549347, dist_loss: 0.6202113032341003
recon_loss: 0.02892296016216278, dist_loss: 0.845820963382721
recon_loss: 0.028923247009515762, dist_loss: 0.9290364980697632
recon_loss: 0.02892320044338703, dist_loss: 0.4807480573654175
recon_loss: 0.028923192992806435, dist_loss: 0.6343483924865723
recon_loss: 0.02892311103641987, dist_loss: 1.0876986980438232
recon_loss: 0.028922593221068382, dist_loss: 0.5251575112342834
recon_loss: 0.02892235666513443, dist_loss: 0.5363231897354126
recon_loss: 0.028922293335199356, dist_loss: 0.7547149062156677
recon_loss: 0.02892230823636055, dist_loss: 0.7959085702896118
recon_loss: 0.028922276571393013, dist_loss: 0.7800866365432739
recon_loss: 0.028922101482748985, dist_loss: 0.45273441076278687
recon_loss: 0.028921907767653465, dist_loss: 0.9849682450294495
recon_loss: 0.028921769931912422, dist_loss: 0.8163394331932068
recon_loss: 0.02892119437456131, dist_loss: 0.6822265982627869
recon_loss: 0.028921227902173996, dist_loss: 0.5778176188468933
recon_loss: 0.028921887278556824, dist_loss: 0.504825234413147
recon_loss: 0.028921807184815407, dist_loss: 0.40703460574150085
recon_loss: 0.02892151288688183, dist_loss: 0.5571836233139038
recon_loss: 0.02892152965068817, dist_loss: 0.8985705971717834
recon_loss: 0.02892112359404564, dist_loss: 0.9784703254699707
recon_loss: 0.028920652344822884, dist_loss: 0.8720651268959045
recon_loss: 0.028920646756887436, dist_loss: 0.5285959243774414
recon_loss: 0.028920939192175865, dist_loss: 0.3930460214614868
recon_loss: 0.028921032324433327, dist_loss: 0.4329162538051605
recon_loss: 0.028920846059918404, dist_loss: 0.8289086818695068
recon_loss: 0.0289204940199852, dist_loss: 0.6619828343391418
recon_loss: 0.028920141980051994, dist_loss: 0.9547326564788818
recon_loss: 0.028919711709022522, dist_loss: 0.8443092107772827
recon_loss: 0.028919795528054237, dist_loss: 0.6320003271102905
recon_loss: 0.028920024633407593, dist_loss: 0.8751941919326782
recon_loss: 0.02891993708908558, dist_loss: 0.5750187039375305
recon_loss: 0.028919842094182968, dist_loss: 0.39523813128471375
recon_loss: 0.02891959249973297, dist_loss: 0.5260725021362305
recon_loss: 0.02891944721341133, dist_loss: 0.9200703501701355
recon_loss: 0.02891922928392887, dist_loss: 0.5666066408157349
recon_loss: 0.028919070959091187, dist_loss: 0.38864150643348694
recon_loss: 0.028919344767928123, dist_loss: 0.8093193769454956
recon_loss: 0.028920335695147514, dist_loss: 0.6957718133926392
recon_loss: 0.028921570628881454, dist_loss: 0.7529542446136475
recon_loss: 0.02892265096306801, dist_loss: 0.5114959478378296
recon_loss: 0.028923267498612404, dist_loss: 0.57203608751297
Pre-training Epoch 53:  38%|███▊      | 140/367 [00:00<00:01, 192.18it/s]Pre-training Epoch 53:  44%|████▎     | 160/367 [00:00<00:01, 192.24it/s]Pre-training Epoch 53:  49%|████▉     | 180/367 [00:00<00:00, 191.80it/s]Pre-training Epoch 53:  54%|█████▍    | 200/367 [00:01<00:00, 191.74it/s]Pre-training Epoch 53:  60%|█████▉    | 220/367 [00:01<00:00, 191.85it/s]Pre-training Epoch 53:  65%|██████▌   | 240/367 [00:01<00:00, 192.01it/s]recon_loss: 0.028923658654093742, dist_loss: 0.34100475907325745
recon_loss: 0.028924087062478065, dist_loss: 0.5038567185401917
recon_loss: 0.028925176709890366, dist_loss: 0.8603497743606567
recon_loss: 0.02892671525478363, dist_loss: 0.5779188871383667
recon_loss: 0.028927812352776527, dist_loss: 0.6444555521011353
recon_loss: 0.02892904542386532, dist_loss: 0.45399048924446106
recon_loss: 0.028929758816957474, dist_loss: 0.4137178063392639
recon_loss: 0.02893027663230896, dist_loss: 0.6516036987304688
recon_loss: 0.028930699452757835, dist_loss: 1.0215450525283813
recon_loss: 0.028931405395269394, dist_loss: 0.7823355793952942
recon_loss: 0.0289313904941082, dist_loss: 0.21001914143562317
recon_loss: 0.028930697590112686, dist_loss: 0.7341582179069519
recon_loss: 0.028929417952895164, dist_loss: 0.6451556086540222
recon_loss: 0.028928302228450775, dist_loss: 0.6843122243881226
recon_loss: 0.028927035629749298, dist_loss: 0.8145419359207153
recon_loss: 0.028925195336341858, dist_loss: 0.6772050857543945
recon_loss: 0.028924239799380302, dist_loss: 0.5174363255500793
recon_loss: 0.028923386707901955, dist_loss: 1.0312049388885498
recon_loss: 0.028922567144036293, dist_loss: 1.2821214199066162
recon_loss: 0.02892150729894638, dist_loss: 0.391984760761261
recon_loss: 0.02892090193927288, dist_loss: 1.203285574913025
recon_loss: 0.028921334072947502, dist_loss: 0.8238426446914673
recon_loss: 0.028922419995069504, dist_loss: 0.6076401472091675
recon_loss: 0.028923476114869118, dist_loss: 0.5086630582809448
recon_loss: 0.028925547376275063, dist_loss: 0.3914564549922943
recon_loss: 0.028927646577358246, dist_loss: 0.7131798267364502
recon_loss: 0.028928935527801514, dist_loss: 1.1355777978897095
recon_loss: 0.02892983704805374, dist_loss: 0.5251910090446472
recon_loss: 0.028930751606822014, dist_loss: 0.8558382987976074
recon_loss: 0.028930749744176865, dist_loss: 0.5388504266738892
recon_loss: 0.028929900377988815, dist_loss: 0.5231348872184753
recon_loss: 0.02892903983592987, dist_loss: 0.5616000890731812
recon_loss: 0.028928054496645927, dist_loss: 0.6399168372154236
recon_loss: 0.028926044702529907, dist_loss: 0.39346590638160706
recon_loss: 0.028924832120537758, dist_loss: 0.5940907001495361
recon_loss: 0.028923653066158295, dist_loss: 0.7408183813095093
recon_loss: 0.028922218829393387, dist_loss: 0.6555712223052979
recon_loss: 0.028920577839016914, dist_loss: 0.46857592463493347
recon_loss: 0.0289192795753479, dist_loss: 0.6663462519645691
recon_loss: 0.028918297961354256, dist_loss: 0.7840609550476074
recon_loss: 0.028917590156197548, dist_loss: 0.8113706111907959
recon_loss: 0.028917018324136734, dist_loss: 0.397541880607605
recon_loss: 0.02891661785542965, dist_loss: 0.6732488870620728
recon_loss: 0.028916316106915474, dist_loss: 0.6531614661216736
recon_loss: 0.028916124254465103, dist_loss: 0.31877750158309937
recon_loss: 0.02891591377556324, dist_loss: 0.4537724554538727
recon_loss: 0.028915707021951675, dist_loss: 0.7822979688644409
recon_loss: 0.02891533449292183, dist_loss: 0.395760715007782
recon_loss: 0.028915081173181534, dist_loss: 0.5589216947555542
recon_loss: 0.028914978727698326, dist_loss: 0.7507050037384033
recon_loss: 0.028915243223309517, dist_loss: 0.9564610123634338
recon_loss: 0.028915001079440117, dist_loss: 1.3955612182617188
recon_loss: 0.028914690017700195, dist_loss: 0.4373756945133209
recon_loss: 0.028914805501699448, dist_loss: 0.8322415947914124
recon_loss: 0.02891518548130989, dist_loss: 0.8408117890357971
recon_loss: 0.028915373608469963, dist_loss: 0.5861219763755798
recon_loss: 0.02891564555466175, dist_loss: 1.1179745197296143
recon_loss: 0.02891545556485653, dist_loss: 0.6585677266120911
recon_loss: 0.028915226459503174, dist_loss: 0.7446069717407227
recon_loss: 0.028914975002408028, dist_loss: 0.4678608775138855
recon_loss: 0.028914710506796837, dist_loss: 0.6236281394958496
recon_loss: 0.02891429141163826, dist_loss: 0.43098825216293335
recon_loss: 0.028913838788866997, dist_loss: 0.6454300880432129
recon_loss: 0.028913531452417374, dist_loss: 0.7769666910171509
recon_loss: 0.02891327068209648, dist_loss: 0.9778931736946106
recon_loss: 0.028913337737321854, dist_loss: 0.40637338161468506
recon_loss: 0.028913529589772224, dist_loss: 0.5823292136192322
recon_loss: 0.028913991525769234, dist_loss: 0.7465296983718872
recon_loss: 0.02891446463763714, dist_loss: 1.0869250297546387
recon_loss: 0.028914926573634148, dist_loss: 0.8741388320922852
recon_loss: 0.028915444388985634, dist_loss: 0.8965421915054321
recon_loss: 0.028915956616401672, dist_loss: 0.9174573421478271
recon_loss: 0.0289163775742054, dist_loss: 0.7702182531356812
recon_loss: 0.028916003182530403, dist_loss: 0.22964569926261902
recon_loss: 0.02891540713608265, dist_loss: 0.44406944513320923
recon_loss: 0.028914792463183403, dist_loss: 0.6527551412582397
recon_loss: 0.028913719579577446, dist_loss: 0.6790478229522705
recon_loss: 0.02891312725841999, dist_loss: 0.565447211265564
recon_loss: 0.028912674635648727, dist_loss: 0.43634241819381714
recon_loss: 0.028911788016557693, dist_loss: 0.5494922995567322
recon_loss: 0.028911743313074112, dist_loss: 0.6006402969360352
recon_loss: 0.028911909088492393, dist_loss: 0.579068660736084
recon_loss: 0.02891133725643158, dist_loss: 0.5049748420715332
recon_loss: 0.02891075238585472, dist_loss: 0.5568224191665649
recon_loss: 0.02891056053340435, dist_loss: 1.0408751964569092
recon_loss: 0.028910314664244652, dist_loss: 0.4074627757072449
recon_loss: 0.02890985645353794, dist_loss: 0.5465110540390015
recon_loss: 0.02891007997095585, dist_loss: 1.0112770795822144
recon_loss: 0.02891060709953308, dist_loss: 0.5116756558418274
recon_loss: 0.028909536078572273, dist_loss: 1.0681474208831787
recon_loss: 0.02890959568321705, dist_loss: 0.4946756362915039
recon_loss: 0.028909895569086075, dist_loss: 0.59038245677948
recon_loss: 0.0289092306047678, dist_loss: 0.5142264366149902
recon_loss: 0.02891009859740734, dist_loss: 0.579789400100708
recon_loss: 0.028910333290696144, dist_loss: 0.6561528444290161
recon_loss: 0.028909413143992424, dist_loss: 0.6983063817024231
recon_loss: 0.028910256922245026, dist_loss: 0.33220332860946655
recon_loss: 0.02891063503921032, dist_loss: 0.5934957265853882
recon_loss: 0.028911028057336807, dist_loss: 0.4022851586341858
recon_loss: 0.028911635279655457, dist_loss: 0.5348151922225952
recon_loss: 0.02891203574836254, dist_loss: 0.6304445266723633
recon_loss: 0.028911961242556572, dist_loss: 1.3124361038208008
recon_loss: 0.028912002220749855, dist_loss: 1.1555854082107544
recon_loss: 0.028911054134368896, dist_loss: 0.44492194056510925
recon_loss: 0.028910530731081963, dist_loss: 0.42764759063720703
recon_loss: 0.02891032211482525, dist_loss: 0.6094842553138733
recon_loss: 0.0289094690233469, dist_loss: 0.5588102340698242
recon_loss: 0.02890891022980213, dist_loss: 0.6882283091545105
recon_loss: 0.02890811115503311, dist_loss: 0.43258094787597656
recon_loss: 0.028907477855682373, dist_loss: 0.7100319266319275
recon_loss: 0.028907306492328644, dist_loss: 0.8231778144836426
recon_loss: 0.02890719845890999, dist_loss: 0.771273136138916
recon_loss: 0.028907660394906998, dist_loss: 0.48586100339889526
recon_loss: 0.02890808880329132, dist_loss: 0.4225989580154419
recon_loss: 0.028908418491482735, dist_loss: 0.906501829624176
recon_loss: 0.028909016400575638, dist_loss: 0.6956511735916138
recon_loss: 0.028909819200634956, dist_loss: 0.3690405488014221
recon_loss: 0.02891061082482338, dist_loss: 0.4843079149723053
recon_loss: 0.0289111640304327, dist_loss: 0.7745166420936584
recon_loss: 0.028911130502820015, dist_loss: 0.5333296060562134
recon_loss: 0.02891054004430771, dist_loss: 0.7655341625213623
recon_loss: 0.028910046443343163, dist_loss: 0.5080093145370483
recon_loss: 0.028909221291542053, dist_loss: 0.5499107837677002
recon_loss: 0.02890874817967415, dist_loss: 0.6194229125976562
recon_loss: 0.028908170759677887, dist_loss: 0.7468959093093872
recon_loss: 0.028907418251037598, dist_loss: 0.5604293942451477
recon_loss: 0.028906701132655144, dist_loss: 1.0687501430511475
recon_loss: 0.028905825689435005, dist_loss: 0.52616947889328
Pre-training Epoch 53:  71%|███████   | 260/367 [00:01<00:00, 190.64it/s]Pre-training Epoch 53:  76%|███████▋  | 280/367 [00:01<00:00, 179.41it/s]Pre-training Epoch 53:  81%|████████▏ | 299/367 [00:01<00:00, 175.21it/s]Pre-training Epoch 53:  86%|████████▋ | 317/367 [00:01<00:00, 172.10it/s]Pre-training Epoch 53:  91%|█████████▏| 335/367 [00:01<00:00, 170.02it/s]Pre-training Epoch 53:  96%|█████████▌| 353/367 [00:01<00:00, 170.95it/s]Pre-training Epoch 53: 100%|██████████| 367/367 [00:01<00:00, 184.01it/s]
recon_loss: 0.028905421495437622, dist_loss: 0.6386991739273071
recon_loss: 0.02890491858124733, dist_loss: 0.7898940443992615
recon_loss: 0.02890464849770069, dist_loss: 0.9490747451782227
recon_loss: 0.028904641047120094, dist_loss: 0.7005350589752197
recon_loss: 0.028904400765895844, dist_loss: 0.5033912658691406
recon_loss: 0.028904449194669724, dist_loss: 0.8422379493713379
recon_loss: 0.028904153034090996, dist_loss: 0.5979485511779785
recon_loss: 0.028903990983963013, dist_loss: 0.442635178565979
recon_loss: 0.028904033824801445, dist_loss: 0.539715588092804
recon_loss: 0.02890370599925518, dist_loss: 0.5066293478012085
recon_loss: 0.028903815895318985, dist_loss: 0.8148164749145508
recon_loss: 0.028903795406222343, dist_loss: 0.486449271440506
recon_loss: 0.028903653845191002, dist_loss: 0.7087418437004089
recon_loss: 0.02890406921505928, dist_loss: 0.4825860857963562
recon_loss: 0.028904598206281662, dist_loss: 0.8616482615470886
recon_loss: 0.028904497623443604, dist_loss: 0.6795200109481812
recon_loss: 0.028904370963573456, dist_loss: 0.7921125888824463
recon_loss: 0.028904855251312256, dist_loss: 0.5528794527053833
recon_loss: 0.02890552394092083, dist_loss: 1.3944807052612305
recon_loss: 0.028905706480145454, dist_loss: 0.4384661614894867
recon_loss: 0.02890567108988762, dist_loss: 0.4830198287963867
recon_loss: 0.028905829414725304, dist_loss: 0.48804593086242676
recon_loss: 0.028905518352985382, dist_loss: 1.03373384475708
recon_loss: 0.02890515699982643, dist_loss: 0.6846832633018494
recon_loss: 0.02890445478260517, dist_loss: 0.5997339487075806
recon_loss: 0.028904007747769356, dist_loss: 0.7240281105041504
recon_loss: 0.028903473168611526, dist_loss: 0.4077973961830139
recon_loss: 0.028902968391776085, dist_loss: 0.5466911792755127
recon_loss: 0.02890276350080967, dist_loss: 0.9181312918663025
recon_loss: 0.028903208673000336, dist_loss: 0.807004451751709
recon_loss: 0.028903434053063393, dist_loss: 0.723890483379364
recon_loss: 0.028903154656291008, dist_loss: 0.45924338698387146
recon_loss: 0.02890278957784176, dist_loss: 1.29850172996521
recon_loss: 0.028903070837259293, dist_loss: 0.4305298328399658
recon_loss: 0.028903458267450333, dist_loss: 0.6318032741546631
recon_loss: 0.0289028137922287, dist_loss: 0.6714168190956116
recon_loss: 0.02890275977551937, dist_loss: 0.5760451555252075
recon_loss: 0.02890285663306713, dist_loss: 0.9250903725624084
recon_loss: 0.028902482241392136, dist_loss: 0.9603990316390991
recon_loss: 0.028902558609843254, dist_loss: 0.5113694667816162
recon_loss: 0.028902621939778328, dist_loss: 0.7000142335891724
recon_loss: 0.028902921825647354, dist_loss: 0.6725413203239441
recon_loss: 0.028904233127832413, dist_loss: 0.8697910904884338
recon_loss: 0.028905868530273438, dist_loss: 0.9233405590057373
recon_loss: 0.02890688180923462, dist_loss: 0.5530369877815247
recon_loss: 0.028908025473356247, dist_loss: 0.3864145278930664
recon_loss: 0.0289088636636734, dist_loss: 0.7337551116943359
recon_loss: 0.028909865766763687, dist_loss: 0.29654914140701294
recon_loss: 0.028910567983984947, dist_loss: 0.37774789333343506
recon_loss: 0.028910676017403603, dist_loss: 0.8881747722625732
recon_loss: 0.028910303488373756, dist_loss: 0.3342134952545166
recon_loss: 0.028908902779221535, dist_loss: 0.7525800466537476
recon_loss: 0.028907746076583862, dist_loss: 0.8183065056800842
recon_loss: 0.02890629507601261, dist_loss: 0.6487826108932495
recon_loss: 0.028905270621180534, dist_loss: 0.4527265429496765
recon_loss: 0.02890430949628353, dist_loss: 0.760765790939331
recon_loss: 0.028902925550937653, dist_loss: 0.8060897588729858
recon_loss: 0.02890174835920334, dist_loss: 0.99042147397995
recon_loss: 0.02890084497630596, dist_loss: 0.5158829092979431
recon_loss: 0.02890007756650448, dist_loss: 0.43195539712905884
recon_loss: 0.028899677097797394, dist_loss: 1.146255373954773
recon_loss: 0.028898945078253746, dist_loss: 0.46177351474761963
recon_loss: 0.028898702934384346, dist_loss: 0.7045204639434814
recon_loss: 0.028898732736706734, dist_loss: 0.4416220784187317
recon_loss: 0.0288984552025795, dist_loss: 0.7083845138549805
recon_loss: 0.02889828383922577, dist_loss: 0.5104062557220459
recon_loss: 0.028898579999804497, dist_loss: 0.5683209896087646
recon_loss: 0.02889864146709442, dist_loss: 0.7093223333358765
recon_loss: 0.028899013996124268, dist_loss: 0.8923959732055664
recon_loss: 0.028899909928441048, dist_loss: 0.3503381609916687
recon_loss: 0.02889997698366642, dist_loss: 0.520240306854248
recon_loss: 0.028900237753987312, dist_loss: 0.7139990329742432
recon_loss: 0.028900591656565666, dist_loss: 0.46892157196998596
recon_loss: 0.028900135308504105, dist_loss: 0.7868838310241699
recon_loss: 0.02890058048069477, dist_loss: 0.5980211496353149
recon_loss: 0.02890007570385933, dist_loss: 0.527024507522583
recon_loss: 0.028899045661091805, dist_loss: 0.8342772722244263
recon_loss: 0.02889869175851345, dist_loss: 0.5243011713027954
recon_loss: 0.028898246586322784, dist_loss: 0.7401764392852783
recon_loss: 0.02889745682477951, dist_loss: 1.0114637613296509
recon_loss: 0.028897933661937714, dist_loss: 0.6529783010482788
recon_loss: 0.02889721281826496, dist_loss: 0.3616437017917633
recon_loss: 0.028896642848849297, dist_loss: 0.27750831842422485
recon_loss: 0.02889730967581272, dist_loss: 0.5782984495162964
recon_loss: 0.02889607474207878, dist_loss: 0.6022966504096985
recon_loss: 0.028896328061819077, dist_loss: 1.083983302116394
recon_loss: 0.02889602817595005, dist_loss: 1.0069714784622192
recon_loss: 0.028895530849695206, dist_loss: 0.45483461022377014
recon_loss: 0.028895322233438492, dist_loss: 0.6550933122634888
recon_loss: 0.028895260766148567, dist_loss: 1.0474330186843872
recon_loss: 0.028894944116473198, dist_loss: 0.7062005996704102
recon_loss: 0.02889523096382618, dist_loss: 0.7433605194091797
recon_loss: 0.028894860297441483, dist_loss: 1.0767645835876465
recon_loss: 0.028894273564219475, dist_loss: 0.8793144226074219
recon_loss: 0.028894659131765366, dist_loss: 1.1019105911254883
recon_loss: 0.028893882408738136, dist_loss: 0.508833110332489
recon_loss: 0.028894195333123207, dist_loss: 1.0221443176269531
recon_loss: 0.028894620016217232, dist_loss: 0.8302792310714722
recon_loss: 0.028894105926156044, dist_loss: 0.6258302927017212
recon_loss: 0.02889500930905342, dist_loss: 0.6023985147476196
recon_loss: 0.02889535017311573, dist_loss: 1.0335767269134521
recon_loss: 0.02889525331556797, dist_loss: 0.6552484035491943
recon_loss: 0.02889544889330864, dist_loss: 0.7762336134910583
recon_loss: 0.028895506635308266, dist_loss: 0.7128000259399414
recon_loss: 0.02889483980834484, dist_loss: 0.6719710826873779
recon_loss: 0.028895214200019836, dist_loss: 0.6891972422599792
recon_loss: 0.028894735500216484, dist_loss: 0.5198728442192078
recon_loss: 0.028894508257508278, dist_loss: 0.2309330403804779
recon_loss: 0.0288943350315094, dist_loss: 0.7350587844848633
recon_loss: 0.028894098475575447, dist_loss: 0.939156711101532
recon_loss: 0.02889416366815567, dist_loss: 0.6437573432922363
Pre-training Epoch 54:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 54:   5%|▌         | 19/367 [00:00<00:01, 189.50it/s]Pre-training Epoch 54:  11%|█         | 39/367 [00:00<00:01, 190.11it/s]Pre-training Epoch 54:  16%|█▌        | 59/367 [00:00<00:01, 191.35it/s]Pre-training Epoch 54:  22%|██▏       | 79/367 [00:00<00:01, 190.77it/s]Pre-training Epoch 54:  27%|██▋       | 99/367 [00:00<00:01, 191.38it/s]Pre-training Epoch 54:  32%|███▏      | 119/367 [00:00<00:01, 191.69it/s]recon_loss: 0.0288943313062191, dist_loss: 0.6729044914245605
recon_loss: 0.028893886134028435, dist_loss: 0.7440698146820068
recon_loss: 0.028894152492284775, dist_loss: 0.46247684955596924
recon_loss: 0.028893837705254555, dist_loss: 0.4269445240497589
recon_loss: 0.02889321558177471, dist_loss: 0.876481294631958
recon_loss: 0.02889331616461277, dist_loss: 0.5136697292327881
recon_loss: 0.02889430895447731, dist_loss: 0.6796518564224243
recon_loss: 0.02889411896467209, dist_loss: 0.40102460980415344
recon_loss: 0.028895093128085136, dist_loss: 0.43065840005874634
recon_loss: 0.028895670548081398, dist_loss: 0.5517797470092773
recon_loss: 0.028895262628793716, dist_loss: 0.4578929543495178
recon_loss: 0.028895551338791847, dist_loss: 0.29728448390960693
recon_loss: 0.028896687552332878, dist_loss: 0.9000047445297241
recon_loss: 0.02889692410826683, dist_loss: 0.553412139415741
recon_loss: 0.028897898271679878, dist_loss: 0.9805690050125122
recon_loss: 0.028898080810904503, dist_loss: 0.7596657276153564
recon_loss: 0.028896724805235863, dist_loss: 0.9090285301208496
recon_loss: 0.028895605355501175, dist_loss: 0.9511176347732544
recon_loss: 0.028893787413835526, dist_loss: 0.8790302276611328
recon_loss: 0.028892483562231064, dist_loss: 0.4437031149864197
recon_loss: 0.028892088681459427, dist_loss: 0.5385798215866089
recon_loss: 0.028891973197460175, dist_loss: 0.9977790117263794
recon_loss: 0.028892360627651215, dist_loss: 0.5601019859313965
recon_loss: 0.02889244258403778, dist_loss: 0.5824711918830872
recon_loss: 0.028891881927847862, dist_loss: 0.7686941623687744
recon_loss: 0.028891364112496376, dist_loss: 0.4537292718887329
recon_loss: 0.02889086678624153, dist_loss: 0.45454829931259155
recon_loss: 0.02889060229063034, dist_loss: 0.6205082535743713
recon_loss: 0.028890635818243027, dist_loss: 0.6982476115226746
recon_loss: 0.02889084257185459, dist_loss: 0.48932135105133057
recon_loss: 0.028890982270240784, dist_loss: 0.39305609464645386
recon_loss: 0.028890816494822502, dist_loss: 0.695064902305603
recon_loss: 0.028890326619148254, dist_loss: 0.5550304651260376
recon_loss: 0.028889747336506844, dist_loss: 0.7086934447288513
recon_loss: 0.02888968028128147, dist_loss: 0.6921619772911072
recon_loss: 0.028890177607536316, dist_loss: 0.9452855587005615
recon_loss: 0.02889050729572773, dist_loss: 0.9760770201683044
recon_loss: 0.028890537098050117, dist_loss: 0.6984363198280334
recon_loss: 0.02889104187488556, dist_loss: 0.4586651623249054
recon_loss: 0.028890492394566536, dist_loss: 0.5570093393325806
recon_loss: 0.028890138491988182, dist_loss: 0.924687385559082
recon_loss: 0.028889797627925873, dist_loss: 0.6272566318511963
recon_loss: 0.028889250010252, dist_loss: 0.44734886288642883
recon_loss: 0.028889065608382225, dist_loss: 0.4479580521583557
recon_loss: 0.028888914734125137, dist_loss: 0.5891456604003906
recon_loss: 0.028888974338769913, dist_loss: 1.1323435306549072
recon_loss: 0.028889114037156105, dist_loss: 0.5876891613006592
recon_loss: 0.02888905629515648, dist_loss: 0.26378631591796875
recon_loss: 0.02888915129005909, dist_loss: 0.5328894853591919
recon_loss: 0.028888922184705734, dist_loss: 0.8209715485572815
recon_loss: 0.028888247907161713, dist_loss: 1.1129558086395264
recon_loss: 0.028888249769806862, dist_loss: 0.5670130848884583
recon_loss: 0.028888700529932976, dist_loss: 0.820442795753479
recon_loss: 0.028888991102576256, dist_loss: 0.4126441180706024
recon_loss: 0.02888922207057476, dist_loss: 0.515038788318634
recon_loss: 0.028889747336506844, dist_loss: 0.5547012090682983
recon_loss: 0.02888992242515087, dist_loss: 0.2974560856819153
recon_loss: 0.02889026515185833, dist_loss: 0.43513810634613037
recon_loss: 0.028890525922179222, dist_loss: 0.44703322649002075
recon_loss: 0.028890814632177353, dist_loss: 0.5787019729614258
recon_loss: 0.028891602531075478, dist_loss: 0.9280110597610474
recon_loss: 0.02889232710003853, dist_loss: 0.4512653052806854
recon_loss: 0.02889181859791279, dist_loss: 0.592900812625885
recon_loss: 0.028891514986753464, dist_loss: 0.5658072233200073
recon_loss: 0.02889070473611355, dist_loss: 0.6247707605361938
recon_loss: 0.02888963185250759, dist_loss: 1.0146530866622925
recon_loss: 0.028888950124382973, dist_loss: 0.6686131954193115
recon_loss: 0.028888460248708725, dist_loss: 0.3544514775276184
recon_loss: 0.02888764813542366, dist_loss: 1.0032329559326172
recon_loss: 0.028887202963232994, dist_loss: 0.5160844326019287
recon_loss: 0.0288868248462677, dist_loss: 0.6120582818984985
recon_loss: 0.02888592518866062, dist_loss: 0.5973296761512756
recon_loss: 0.028885647654533386, dist_loss: 0.5740172266960144
recon_loss: 0.028885314241051674, dist_loss: 0.569391131401062
recon_loss: 0.028885284438729286, dist_loss: 1.0910950899124146
recon_loss: 0.02888597920536995, dist_loss: 0.9135352373123169
recon_loss: 0.028885753825306892, dist_loss: 1.004190444946289
recon_loss: 0.028885599225759506, dist_loss: 0.7298933863639832
recon_loss: 0.028885258361697197, dist_loss: 0.6236214637756348
recon_loss: 0.028884928673505783, dist_loss: 0.6341378688812256
recon_loss: 0.02888519875705242, dist_loss: 0.5468718409538269
recon_loss: 0.028885481879115105, dist_loss: 0.3348044753074646
recon_loss: 0.028885355219244957, dist_loss: 0.768007755279541
recon_loss: 0.028885507956147194, dist_loss: 0.7162680625915527
recon_loss: 0.028885163366794586, dist_loss: 0.8152980804443359
recon_loss: 0.02888503298163414, dist_loss: 0.6259488463401794
recon_loss: 0.02888452634215355, dist_loss: 0.5364686846733093
recon_loss: 0.028884245082736015, dist_loss: 0.764252245426178
recon_loss: 0.02888379991054535, dist_loss: 0.7039562463760376
recon_loss: 0.02888369932770729, dist_loss: 0.4010024666786194
recon_loss: 0.028883473947644234, dist_loss: 0.8942444324493408
recon_loss: 0.02888340689241886, dist_loss: 0.5769851207733154
recon_loss: 0.02888334169983864, dist_loss: 0.336311012506485
recon_loss: 0.028883446007966995, dist_loss: 0.5594995021820068
recon_loss: 0.02888382598757744, dist_loss: 0.3695247769355774
recon_loss: 0.02888467162847519, dist_loss: 0.7145964503288269
recon_loss: 0.028886187821626663, dist_loss: 0.5477962493896484
recon_loss: 0.02888697199523449, dist_loss: 0.5255122184753418
recon_loss: 0.028887437656521797, dist_loss: 0.7029295563697815
recon_loss: 0.028887245804071426, dist_loss: 1.0634453296661377
recon_loss: 0.0288869459182024, dist_loss: 1.090306043624878
recon_loss: 0.02888709306716919, dist_loss: 0.7507620453834534
recon_loss: 0.028886914253234863, dist_loss: 0.5077884197235107
recon_loss: 0.02888619340956211, dist_loss: 0.738085925579071
recon_loss: 0.028885290026664734, dist_loss: 1.0284149646759033
recon_loss: 0.028884265571832657, dist_loss: 0.7494068145751953
recon_loss: 0.02888328768312931, dist_loss: 0.7495969533920288
recon_loss: 0.028882496058940887, dist_loss: 1.0855566263198853
recon_loss: 0.028881860896945, dist_loss: 0.8161989450454712
recon_loss: 0.028881506994366646, dist_loss: 1.2793097496032715
recon_loss: 0.02888132445514202, dist_loss: 0.4121343791484833
recon_loss: 0.028881145641207695, dist_loss: 0.9161697626113892
recon_loss: 0.028881149366497993, dist_loss: 0.4753711521625519
recon_loss: 0.028881173580884933, dist_loss: 0.7419853210449219
recon_loss: 0.028881411999464035, dist_loss: 0.5955670475959778
recon_loss: 0.02888205647468567, dist_loss: 0.7218356132507324
recon_loss: 0.028882531449198723, dist_loss: 0.7163881659507751
recon_loss: 0.02888348139822483, dist_loss: 0.5959875583648682
recon_loss: 0.0288842786103487, dist_loss: 0.7379633784294128
recon_loss: 0.02888440527021885, dist_loss: 0.6109626293182373
recon_loss: 0.028885001316666603, dist_loss: 0.9390864968299866
recon_loss: 0.028885316103696823, dist_loss: 0.8167771100997925
recon_loss: 0.028885269537568092, dist_loss: 0.7651635408401489
recon_loss: 0.02888507768511772, dist_loss: 0.6619176864624023
recon_loss: 0.028884680941700935, dist_loss: 0.599484920501709
recon_loss: 0.028884006664156914, dist_loss: 0.3575909733772278
recon_loss: 0.02888301946222782, dist_loss: 0.7824514508247375
recon_loss: 0.028882013633847237, dist_loss: 0.6764969825744629
Pre-training Epoch 54:  38%|███▊      | 139/367 [00:00<00:01, 191.89it/s]Pre-training Epoch 54:  43%|████▎     | 159/367 [00:00<00:01, 192.12it/s]Pre-training Epoch 54:  49%|████▉     | 179/367 [00:00<00:00, 192.24it/s]Pre-training Epoch 54:  54%|█████▍    | 199/367 [00:01<00:00, 192.40it/s]Pre-training Epoch 54:  60%|█████▉    | 219/367 [00:01<00:00, 192.55it/s]Pre-training Epoch 54:  65%|██████▌   | 239/367 [00:01<00:00, 192.69it/s]recon_loss: 0.02888079360127449, dist_loss: 0.9604271054267883
recon_loss: 0.028879599645733833, dist_loss: 0.3875255584716797
recon_loss: 0.02887897752225399, dist_loss: 0.8625340461730957
recon_loss: 0.028878385201096535, dist_loss: 0.780165433883667
recon_loss: 0.028878431767225266, dist_loss: 0.5956974029541016
recon_loss: 0.02887887880206108, dist_loss: 0.6111184358596802
recon_loss: 0.028878645971417427, dist_loss: 0.70408034324646
recon_loss: 0.028878526762127876, dist_loss: 0.6734000444412231
recon_loss: 0.028878452256321907, dist_loss: 1.0342987775802612
recon_loss: 0.028878280892968178, dist_loss: 0.7219997644424438
recon_loss: 0.028878116980195045, dist_loss: 1.1570279598236084
recon_loss: 0.028878511860966682, dist_loss: 0.9520941972732544
recon_loss: 0.028878262266516685, dist_loss: 0.5630017518997192
recon_loss: 0.02887827903032303, dist_loss: 0.7230309247970581
recon_loss: 0.02887779287993908, dist_loss: 0.7821905612945557
recon_loss: 0.028877170756459236, dist_loss: 0.524259626865387
recon_loss: 0.028876546770334244, dist_loss: 0.5218701958656311
recon_loss: 0.02887680009007454, dist_loss: 0.5867831707000732
recon_loss: 0.02887645922601223, dist_loss: 1.0468682050704956
recon_loss: 0.02887599915266037, dist_loss: 0.39378175139427185
recon_loss: 0.028876138851046562, dist_loss: 0.6133252382278442
recon_loss: 0.02887583337724209, dist_loss: 0.6833693981170654
recon_loss: 0.02887556701898575, dist_loss: 0.6381992101669312
recon_loss: 0.028875481337308884, dist_loss: 0.5295292139053345
recon_loss: 0.02887532114982605, dist_loss: 0.8502942323684692
recon_loss: 0.028875181451439857, dist_loss: 1.1400800943374634
recon_loss: 0.028875520452857018, dist_loss: 0.564338743686676
recon_loss: 0.028875915333628654, dist_loss: 0.5154392719268799
recon_loss: 0.028876230120658875, dist_loss: 0.8938326239585876
recon_loss: 0.02887662500143051, dist_loss: 0.5480544567108154
recon_loss: 0.028877388685941696, dist_loss: 0.706956148147583
recon_loss: 0.0288785919547081, dist_loss: 0.5054047107696533
recon_loss: 0.02887921780347824, dist_loss: 0.7699211835861206
recon_loss: 0.028879744932055473, dist_loss: 0.6067907810211182
recon_loss: 0.028880368918180466, dist_loss: 0.8109848499298096
recon_loss: 0.028880281373858452, dist_loss: 0.5721862316131592
recon_loss: 0.028880372643470764, dist_loss: 0.6268038749694824
recon_loss: 0.028879892081022263, dist_loss: 0.47324955463409424
recon_loss: 0.028879139572381973, dist_loss: 0.36994031071662903
recon_loss: 0.028878765180706978, dist_loss: 0.7141074538230896
recon_loss: 0.02887749671936035, dist_loss: 1.0950146913528442
recon_loss: 0.028876474127173424, dist_loss: 0.6512592434883118
recon_loss: 0.02887594699859619, dist_loss: 0.9056628942489624
recon_loss: 0.028874889016151428, dist_loss: 0.5512548685073853
recon_loss: 0.02887517400085926, dist_loss: 0.8297713994979858
recon_loss: 0.02887551113963127, dist_loss: 0.464102566242218
recon_loss: 0.028875114396214485, dist_loss: 0.647014319896698
recon_loss: 0.02887667529284954, dist_loss: 0.9211456775665283
recon_loss: 0.02887698821723461, dist_loss: 0.3911649286746979
recon_loss: 0.028876876458525658, dist_loss: 0.525134265422821
recon_loss: 0.028876937925815582, dist_loss: 0.5283759832382202
recon_loss: 0.028876861557364464, dist_loss: 0.8354156017303467
recon_loss: 0.028876937925815582, dist_loss: 0.39783939719200134
recon_loss: 0.02887694351375103, dist_loss: 0.6823253631591797
recon_loss: 0.028876621276140213, dist_loss: 0.7326632738113403
recon_loss: 0.028876081109046936, dist_loss: 0.7851521968841553
recon_loss: 0.028875764459371567, dist_loss: 0.5768148303031921
recon_loss: 0.028875485062599182, dist_loss: 0.5685411691665649
recon_loss: 0.02887469343841076, dist_loss: 0.40133416652679443
recon_loss: 0.028874050825834274, dist_loss: 0.4455548822879791
recon_loss: 0.028873156756162643, dist_loss: 0.493450403213501
recon_loss: 0.028872806578874588, dist_loss: 0.4803656339645386
recon_loss: 0.02887261100113392, dist_loss: 0.5077829360961914
recon_loss: 0.028872545808553696, dist_loss: 0.8090790510177612
recon_loss: 0.028872400522232056, dist_loss: 0.5017573237419128
recon_loss: 0.02887214533984661, dist_loss: 0.7683162093162537
recon_loss: 0.028872186318039894, dist_loss: 0.9882056713104248
recon_loss: 0.028872458264231682, dist_loss: 0.6649717092514038
recon_loss: 0.028872469440102577, dist_loss: 0.4522779583930969
recon_loss: 0.02887243777513504, dist_loss: 0.387487530708313
recon_loss: 0.02887224778532982, dist_loss: 1.116131067276001
recon_loss: 0.028871914371848106, dist_loss: 1.2593202590942383
recon_loss: 0.028871674090623856, dist_loss: 0.6391869783401489
recon_loss: 0.028871579095721245, dist_loss: 0.6922234892845154
recon_loss: 0.028871290385723114, dist_loss: 0.45515602827072144
recon_loss: 0.028871111571788788, dist_loss: 0.8410575985908508
recon_loss: 0.028870834037661552, dist_loss: 0.6984864473342896
recon_loss: 0.028870398178696632, dist_loss: 0.9294342994689941
recon_loss: 0.02887030877172947, dist_loss: 0.732608437538147
recon_loss: 0.028870120644569397, dist_loss: 0.5330864191055298
recon_loss: 0.028869956731796265, dist_loss: 0.4390862286090851
recon_loss: 0.02886982634663582, dist_loss: 0.31616896390914917
recon_loss: 0.02886958234012127, dist_loss: 0.32587945461273193
recon_loss: 0.028869617730379105, dist_loss: 0.4872990846633911
recon_loss: 0.02886933460831642, dist_loss: 0.6838276386260986
recon_loss: 0.028869207948446274, dist_loss: 0.5184515714645386
recon_loss: 0.02886933460831642, dist_loss: 0.2963493764400482
recon_loss: 0.02886907197535038, dist_loss: 0.8466720581054688
recon_loss: 0.028869807720184326, dist_loss: 0.8677408695220947
recon_loss: 0.02887020632624626, dist_loss: 0.8395360112190247
recon_loss: 0.028870711103081703, dist_loss: 0.8710940480232239
recon_loss: 0.0288704764097929, dist_loss: 0.47871899604797363
recon_loss: 0.028870418667793274, dist_loss: 0.344160795211792
recon_loss: 0.02887038327753544, dist_loss: 0.4069194793701172
recon_loss: 0.02887069806456566, dist_loss: 0.5573385953903198
recon_loss: 0.028870977461338043, dist_loss: 0.6930437088012695
recon_loss: 0.028870685026049614, dist_loss: 0.5029389262199402
recon_loss: 0.02887042984366417, dist_loss: 0.5271854996681213
recon_loss: 0.028869153931736946, dist_loss: 0.5618399977684021
recon_loss: 0.02886863611638546, dist_loss: 0.7670182585716248
recon_loss: 0.028869103640317917, dist_loss: 0.3581363558769226
recon_loss: 0.028869513422250748, dist_loss: 0.7305883169174194
recon_loss: 0.02886923775076866, dist_loss: 0.23809894919395447
recon_loss: 0.0288687814027071, dist_loss: 0.6304929256439209
recon_loss: 0.02886800467967987, dist_loss: 0.8668593168258667
recon_loss: 0.02886739745736122, dist_loss: 0.43277403712272644
recon_loss: 0.02886730618774891, dist_loss: 0.7417984008789062
recon_loss: 0.02886740118265152, dist_loss: 1.0348787307739258
recon_loss: 0.028867634013295174, dist_loss: 0.3061121702194214
recon_loss: 0.028867648914456367, dist_loss: 0.7552321553230286
recon_loss: 0.028867093846201897, dist_loss: 0.7468125224113464
recon_loss: 0.028866225853562355, dist_loss: 0.8104215860366821
recon_loss: 0.0288663562387228, dist_loss: 0.38692328333854675
recon_loss: 0.028866639360785484, dist_loss: 0.6536576747894287
recon_loss: 0.02886689268052578, dist_loss: 0.4684807062149048
recon_loss: 0.028866887092590332, dist_loss: 0.7286246418952942
recon_loss: 0.028866568580269814, dist_loss: 0.6805129647254944
recon_loss: 0.028866223990917206, dist_loss: 0.6743747591972351
recon_loss: 0.02886587753891945, dist_loss: 0.3613334894180298
recon_loss: 0.02886553853750229, dist_loss: 0.7264701724052429
recon_loss: 0.028865301981568336, dist_loss: 0.4637299180030823
recon_loss: 0.028865309432148933, dist_loss: 0.4083488881587982
recon_loss: 0.028865132480859756, dist_loss: 1.1120468378067017
recon_loss: 0.02886524610221386, dist_loss: 0.6413021087646484
recon_loss: 0.02886522002518177, dist_loss: 0.8983296155929565
recon_loss: 0.028865084052085876, dist_loss: 0.6953223943710327
recon_loss: 0.028865061700344086, dist_loss: 1.0603718757629395
recon_loss: 0.028865471482276917, dist_loss: 0.4547685384750366
Pre-training Epoch 54:  71%|███████   | 259/367 [00:01<00:00, 192.50it/s]Pre-training Epoch 54:  76%|███████▌  | 279/367 [00:01<00:00, 191.51it/s]Pre-training Epoch 54:  81%|████████▏ | 299/367 [00:01<00:00, 191.11it/s]Pre-training Epoch 54:  87%|████████▋ | 319/367 [00:01<00:00, 191.07it/s]Pre-training Epoch 54:  92%|█████████▏| 339/367 [00:01<00:00, 191.49it/s]Pre-training Epoch 54:  98%|█████████▊| 359/367 [00:01<00:00, 191.80it/s]Pre-training Epoch 54: 100%|██████████| 367/367 [00:01<00:00, 191.65it/s]
recon_loss: 0.02886555902659893, dist_loss: 0.5784445405006409
recon_loss: 0.02886546589434147, dist_loss: 0.7020975351333618
recon_loss: 0.02886560931801796, dist_loss: 0.744568943977356
recon_loss: 0.028865637257695198, dist_loss: 0.7355672717094421
recon_loss: 0.02886560931801796, dist_loss: 0.6845427751541138
recon_loss: 0.028865518048405647, dist_loss: 0.6897974014282227
recon_loss: 0.028865516185760498, dist_loss: 1.3780076503753662
recon_loss: 0.02886534109711647, dist_loss: 0.7416490316390991
recon_loss: 0.028865136206150055, dist_loss: 0.42331603169441223
recon_loss: 0.02886519953608513, dist_loss: 0.5943735241889954
recon_loss: 0.02886488474905491, dist_loss: 0.9800996780395508
recon_loss: 0.028864972293376923, dist_loss: 0.619517982006073
recon_loss: 0.028865396976470947, dist_loss: 0.6519775390625
recon_loss: 0.028864853084087372, dist_loss: 0.8918502330780029
recon_loss: 0.028864899650216103, dist_loss: 0.8641784191131592
recon_loss: 0.028864895924925804, dist_loss: 0.6436470746994019
recon_loss: 0.028864437714219093, dist_loss: 0.9183130264282227
recon_loss: 0.0288645438849926, dist_loss: 0.632472038269043
recon_loss: 0.028864188119769096, dist_loss: 0.6750086545944214
recon_loss: 0.02886425517499447, dist_loss: 0.6386715173721313
recon_loss: 0.02886415831744671, dist_loss: 0.5315406918525696
recon_loss: 0.028864210471510887, dist_loss: 0.9725317358970642
recon_loss: 0.028864257037639618, dist_loss: 0.3402124047279358
recon_loss: 0.02886427938938141, dist_loss: 0.8429862260818481
recon_loss: 0.028864184394478798, dist_loss: 0.5078754425048828
recon_loss: 0.028864243999123573, dist_loss: 0.6335133910179138
recon_loss: 0.0288644228130579, dist_loss: 1.2869668006896973
recon_loss: 0.028864257037639618, dist_loss: 0.7013527154922485
recon_loss: 0.028864186257123947, dist_loss: 0.9959940314292908
recon_loss: 0.028863903135061264, dist_loss: 0.4529128670692444
recon_loss: 0.028863107785582542, dist_loss: 0.8490933179855347
recon_loss: 0.0288628488779068, dist_loss: 0.7259366512298584
recon_loss: 0.0288627240806818, dist_loss: 0.6165763735771179
recon_loss: 0.0288627240806818, dist_loss: 0.5968887805938721
recon_loss: 0.02886250428855419, dist_loss: 0.8093447685241699
recon_loss: 0.0288617592304945, dist_loss: 0.5257121324539185
recon_loss: 0.028861049562692642, dist_loss: 0.4747687876224518
recon_loss: 0.028861116617918015, dist_loss: 0.26471570134162903
recon_loss: 0.028861718252301216, dist_loss: 0.8290750980377197
recon_loss: 0.028861679136753082, dist_loss: 0.3108704686164856
recon_loss: 0.028861500322818756, dist_loss: 0.5063868761062622
recon_loss: 0.028861114755272865, dist_loss: 0.7967081069946289
recon_loss: 0.02886080928146839, dist_loss: 0.47338566184043884
recon_loss: 0.02886083535850048, dist_loss: 0.4763586223125458
recon_loss: 0.028860922902822495, dist_loss: 0.9685888886451721
recon_loss: 0.028861183673143387, dist_loss: 0.8802158832550049
recon_loss: 0.028860922902822495, dist_loss: 0.6002612709999084
recon_loss: 0.02886037342250347, dist_loss: 0.7735338807106018
recon_loss: 0.028860656544566154, dist_loss: 0.7788547277450562
recon_loss: 0.028859948739409447, dist_loss: 0.6570148468017578
recon_loss: 0.028859445825219154, dist_loss: 0.6542460322380066
recon_loss: 0.02885921485722065, dist_loss: 0.8587332963943481
recon_loss: 0.028858674690127373, dist_loss: 0.5981221795082092
recon_loss: 0.028859151527285576, dist_loss: 0.4864218831062317
recon_loss: 0.028860028833150864, dist_loss: 0.472790390253067
recon_loss: 0.028859900310635567, dist_loss: 0.6581425666809082
recon_loss: 0.028861423954367638, dist_loss: 1.1861144304275513
recon_loss: 0.028861917555332184, dist_loss: 0.7183361053466797
recon_loss: 0.028861964121460915, dist_loss: 0.5674971342086792
recon_loss: 0.028862671926617622, dist_loss: 0.8028976917266846
recon_loss: 0.02886291593313217, dist_loss: 0.7188089489936829
recon_loss: 0.028862696141004562, dist_loss: 0.5571900606155396
recon_loss: 0.02886267378926277, dist_loss: 0.6608492732048035
recon_loss: 0.02886202745139599, dist_loss: 0.6330392360687256
recon_loss: 0.02886086516082287, dist_loss: 0.49463021755218506
recon_loss: 0.028859544545412064, dist_loss: 0.46509867906570435
recon_loss: 0.028858721256256104, dist_loss: 0.9787259101867676
recon_loss: 0.028858210891485214, dist_loss: 0.5120898485183716
recon_loss: 0.02885785698890686, dist_loss: 0.45946642756462097
recon_loss: 0.02885899879038334, dist_loss: 0.7920337319374084
recon_loss: 0.028859177604317665, dist_loss: 0.9898902773857117
recon_loss: 0.02885988913476467, dist_loss: 0.8437850475311279
recon_loss: 0.028861762955784798, dist_loss: 0.2581578493118286
recon_loss: 0.028863998129963875, dist_loss: 0.8356115221977234
recon_loss: 0.028867334127426147, dist_loss: 0.9556450843811035
recon_loss: 0.028869345784187317, dist_loss: 0.7049850225448608
recon_loss: 0.02887054719030857, dist_loss: 0.7757744789123535
recon_loss: 0.028871450573205948, dist_loss: 0.8790096044540405
recon_loss: 0.028871480375528336, dist_loss: 0.5089001655578613
recon_loss: 0.02887219749391079, dist_loss: 0.6083797216415405
recon_loss: 0.028871551156044006, dist_loss: 0.6805833578109741
recon_loss: 0.028871653601527214, dist_loss: 0.8068149089813232
recon_loss: 0.0288698710501194, dist_loss: 0.7043269872665405
recon_loss: 0.02886699140071869, dist_loss: 1.1916712522506714
recon_loss: 0.028866112232208252, dist_loss: 0.8647500872612
recon_loss: 0.02886403165757656, dist_loss: 0.49010252952575684
recon_loss: 0.028861982747912407, dist_loss: 0.4426322281360626
recon_loss: 0.028861399739980698, dist_loss: 0.8062069416046143
recon_loss: 0.02885950729250908, dist_loss: 0.8212615847587585
recon_loss: 0.02885848470032215, dist_loss: 1.134461522102356
recon_loss: 0.028858108446002007, dist_loss: 0.747101902961731
recon_loss: 0.028857726603746414, dist_loss: 0.6473426818847656
recon_loss: 0.028857961297035217, dist_loss: 0.7601995468139648
recon_loss: 0.028858114033937454, dist_loss: 0.4490872919559479
recon_loss: 0.02885853871703148, dist_loss: 0.711470365524292
recon_loss: 0.028859755024313927, dist_loss: 0.5612517595291138
recon_loss: 0.028861653059720993, dist_loss: 0.43504494428634644
recon_loss: 0.028863634914159775, dist_loss: 0.3392072021961212
recon_loss: 0.028865819796919823, dist_loss: 0.8304625749588013
recon_loss: 0.028867002576589584, dist_loss: 0.5315060615539551
recon_loss: 0.028868116438388824, dist_loss: 0.8338574171066284
recon_loss: 0.028868762776255608, dist_loss: 0.6242047548294067
recon_loss: 0.028867870569229126, dist_loss: 0.3840758800506592
recon_loss: 0.02886713668704033, dist_loss: 0.384370893239975
recon_loss: 0.028866050764918327, dist_loss: 0.8315936326980591
recon_loss: 0.028864221647381783, dist_loss: 0.7284674644470215
recon_loss: 0.028862377628684044, dist_loss: 0.44500619173049927
recon_loss: 0.02886096015572548, dist_loss: 0.40186136960983276
recon_loss: 0.02885936014354229, dist_loss: 1.1799755096435547
recon_loss: 0.028858114033937454, dist_loss: 0.7258979082107544
recon_loss: 0.028856905177235603, dist_loss: 0.6947501301765442
Pre-training Epoch 55:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 55:   5%|▌         | 19/367 [00:00<00:01, 188.52it/s]Pre-training Epoch 55:  10%|█         | 38/367 [00:00<00:01, 187.17it/s]Pre-training Epoch 55:  16%|█▌        | 58/367 [00:00<00:01, 189.68it/s]Pre-training Epoch 55:  21%|██▏       | 78/367 [00:00<00:01, 191.48it/s]Pre-training Epoch 55:  27%|██▋       | 98/367 [00:00<00:01, 192.46it/s]Pre-training Epoch 55:  32%|███▏      | 118/367 [00:00<00:01, 193.39it/s]recon_loss: 0.02885562740266323, dist_loss: 0.691240668296814
recon_loss: 0.02885502390563488, dist_loss: 0.8371282815933228
recon_loss: 0.02885444089770317, dist_loss: 0.5284769535064697
recon_loss: 0.028853876516222954, dist_loss: 0.46841055154800415
recon_loss: 0.028853684663772583, dist_loss: 0.941990852355957
recon_loss: 0.028853850439190865, dist_loss: 0.3899071216583252
recon_loss: 0.028854254633188248, dist_loss: 0.5366300344467163
recon_loss: 0.02885468304157257, dist_loss: 0.6485934257507324
recon_loss: 0.028855983167886734, dist_loss: 1.1857423782348633
recon_loss: 0.02885637804865837, dist_loss: 0.5805816650390625
recon_loss: 0.028855351731181145, dist_loss: 0.9302085638046265
recon_loss: 0.02885610982775688, dist_loss: 0.6755931973457336
recon_loss: 0.028855733573436737, dist_loss: 0.7594064474105835
recon_loss: 0.02885565720498562, dist_loss: 0.6561675071716309
recon_loss: 0.02885562740266323, dist_loss: 0.8922951221466064
recon_loss: 0.028854917734861374, dist_loss: 0.9687663316726685
recon_loss: 0.028853852301836014, dist_loss: 0.19261042773723602
recon_loss: 0.02885298803448677, dist_loss: 0.599054217338562
recon_loss: 0.02885223925113678, dist_loss: 1.0289407968521118
recon_loss: 0.02885163575410843, dist_loss: 0.42341452836990356
recon_loss: 0.028851429000496864, dist_loss: 1.02154541015625
recon_loss: 0.02885151468217373, dist_loss: 0.5021198391914368
recon_loss: 0.028851274400949478, dist_loss: 0.6714717745780945
recon_loss: 0.02885104902088642, dist_loss: 1.179073691368103
recon_loss: 0.028851119801402092, dist_loss: 0.6259901523590088
recon_loss: 0.028850669041275978, dist_loss: 0.5088595747947693
recon_loss: 0.028850555419921875, dist_loss: 0.8517230749130249
recon_loss: 0.028850767761468887, dist_loss: 0.5228562355041504
recon_loss: 0.028850264847278595, dist_loss: 0.9316068887710571
recon_loss: 0.028849679976701736, dist_loss: 0.8794152736663818
recon_loss: 0.028849169611930847, dist_loss: 0.8314394354820251
recon_loss: 0.028848916292190552, dist_loss: 0.5901215076446533
recon_loss: 0.028849156573414803, dist_loss: 0.4693737328052521
recon_loss: 0.028849078342318535, dist_loss: 0.8275567293167114
recon_loss: 0.028848513960838318, dist_loss: 0.7621190547943115
recon_loss: 0.02884857915341854, dist_loss: 0.9003399610519409
recon_loss: 0.02884826250374317, dist_loss: 0.5480647087097168
recon_loss: 0.02884835936129093, dist_loss: 0.6505413055419922
recon_loss: 0.028848722577095032, dist_loss: 0.5157438516616821
recon_loss: 0.028848333284258842, dist_loss: 0.644726037979126
recon_loss: 0.02884856052696705, dist_loss: 0.7757676243782043
recon_loss: 0.02884860895574093, dist_loss: 0.6789170503616333
recon_loss: 0.02884822152554989, dist_loss: 0.5218997597694397
recon_loss: 0.028847994282841682, dist_loss: 0.5885525941848755
recon_loss: 0.02884768694639206, dist_loss: 0.5713161826133728
recon_loss: 0.028847625479102135, dist_loss: 1.2124882936477661
recon_loss: 0.028847509995102882, dist_loss: 0.8137291073799133
recon_loss: 0.02884823828935623, dist_loss: 0.5586164593696594
recon_loss: 0.028848964720964432, dist_loss: 0.5694835186004639
recon_loss: 0.028849417343735695, dist_loss: 0.9344865679740906
recon_loss: 0.028850078582763672, dist_loss: 0.9587479829788208
recon_loss: 0.028850246220827103, dist_loss: 0.37301701307296753
recon_loss: 0.028849637135863304, dist_loss: 0.3650343418121338
recon_loss: 0.028849110007286072, dist_loss: 0.4352778196334839
recon_loss: 0.028848828747868538, dist_loss: 0.4141424298286438
recon_loss: 0.028847914189100266, dist_loss: 0.5947805643081665
recon_loss: 0.02884727343916893, dist_loss: 0.7271467447280884
recon_loss: 0.028846759349107742, dist_loss: 0.46494120359420776
recon_loss: 0.02884589694440365, dist_loss: 0.6657912731170654
recon_loss: 0.028845958411693573, dist_loss: 0.7139955759048462
recon_loss: 0.028845973312854767, dist_loss: 0.8337065577507019
recon_loss: 0.02884557843208313, dist_loss: 0.5200937986373901
recon_loss: 0.028846001252532005, dist_loss: 0.4956091046333313
recon_loss: 0.028845038264989853, dist_loss: 0.624320387840271
recon_loss: 0.02884504571557045, dist_loss: 0.7060825824737549
recon_loss: 0.0288455281406641, dist_loss: 0.8101626634597778
recon_loss: 0.028845101594924927, dist_loss: 0.698036789894104
recon_loss: 0.028846532106399536, dist_loss: 0.7446603775024414
recon_loss: 0.02884681522846222, dist_loss: 0.703937828540802
recon_loss: 0.028845977038145065, dist_loss: 0.6992783546447754
recon_loss: 0.028846997767686844, dist_loss: 1.1475826501846313
recon_loss: 0.028846630826592445, dist_loss: 0.6870190501213074
recon_loss: 0.02884492464363575, dist_loss: 0.7344925403594971
recon_loss: 0.028846774250268936, dist_loss: 0.8088206648826599
recon_loss: 0.02884589321911335, dist_loss: 0.7240794897079468
recon_loss: 0.02884438820183277, dist_loss: 0.742557168006897
recon_loss: 0.0288448054343462, dist_loss: 0.7290408611297607
recon_loss: 0.028844265267252922, dist_loss: 0.7176491618156433
recon_loss: 0.028844082728028297, dist_loss: 0.6457522511482239
recon_loss: 0.02884502150118351, dist_loss: 0.8984363079071045
recon_loss: 0.028844520449638367, dist_loss: 0.85234135389328
recon_loss: 0.02884434349834919, dist_loss: 0.6157294511795044
recon_loss: 0.028844239190220833, dist_loss: 1.000665307044983
recon_loss: 0.02884325385093689, dist_loss: 0.39540863037109375
recon_loss: 0.02884325385093689, dist_loss: 0.9446181058883667
recon_loss: 0.028843682259321213, dist_loss: 0.8140859603881836
recon_loss: 0.028843466192483902, dist_loss: 0.5537706613540649
recon_loss: 0.028843609616160393, dist_loss: 0.4305822551250458
recon_loss: 0.028842829167842865, dist_loss: 0.46669286489486694
recon_loss: 0.028842229396104813, dist_loss: 0.5872489213943481
recon_loss: 0.02884220890700817, dist_loss: 0.9865109920501709
recon_loss: 0.028842315077781677, dist_loss: 0.3181301951408386
recon_loss: 0.028842493891716003, dist_loss: 0.5430600643157959
recon_loss: 0.028842343017458916, dist_loss: 0.8717866539955139
recon_loss: 0.028842847794294357, dist_loss: 0.9129819869995117
recon_loss: 0.028844060376286507, dist_loss: 0.4368249773979187
recon_loss: 0.028845056891441345, dist_loss: 0.5983365774154663
recon_loss: 0.02884504571557045, dist_loss: 0.7190431356430054
recon_loss: 0.028844520449638367, dist_loss: 0.48033037781715393
recon_loss: 0.02884438820183277, dist_loss: 0.9091783165931702
recon_loss: 0.028844209387898445, dist_loss: 0.44972020387649536
recon_loss: 0.02884438820183277, dist_loss: 0.48377925157546997
recon_loss: 0.028845196589827538, dist_loss: 0.652603268623352
recon_loss: 0.02884570136666298, dist_loss: 0.5739742517471313
recon_loss: 0.028844427317380905, dist_loss: 0.6847390532493591
recon_loss: 0.028843333944678307, dist_loss: 0.9309629201889038
recon_loss: 0.028842676430940628, dist_loss: 0.6346710324287415
recon_loss: 0.028843577951192856, dist_loss: 0.517686128616333
recon_loss: 0.02884572744369507, dist_loss: 0.5786953568458557
recon_loss: 0.02884591370820999, dist_loss: 1.003195881843567
recon_loss: 0.0288445595651865, dist_loss: 0.9740136861801147
recon_loss: 0.028842195868492126, dist_loss: 0.7548171281814575
recon_loss: 0.028841450810432434, dist_loss: 0.8023446798324585
recon_loss: 0.028842652216553688, dist_loss: 0.7427994012832642
recon_loss: 0.028844036161899567, dist_loss: 0.5471198558807373
recon_loss: 0.02884475328028202, dist_loss: 0.5781813263893127
recon_loss: 0.028844071552157402, dist_loss: 0.7401620149612427
recon_loss: 0.028842702507972717, dist_loss: 0.9463776350021362
recon_loss: 0.028841985389590263, dist_loss: 0.5057142376899719
recon_loss: 0.028841586783528328, dist_loss: 0.3747185468673706
recon_loss: 0.028842071071267128, dist_loss: 0.6321521997451782
recon_loss: 0.028842942789196968, dist_loss: 0.7706128358840942
recon_loss: 0.02884339541196823, dist_loss: 0.4932931065559387
recon_loss: 0.02884291298687458, dist_loss: 0.6168336868286133
recon_loss: 0.028841588646173477, dist_loss: 0.9284812808036804
recon_loss: 0.028840357437729836, dist_loss: 1.647641897201538
recon_loss: 0.02884068340063095, dist_loss: 0.486052542924881
recon_loss: 0.028841305524110794, dist_loss: 0.7327735424041748
Pre-training Epoch 55:  38%|███▊      | 138/367 [00:00<00:01, 193.46it/s]Pre-training Epoch 55:  43%|████▎     | 158/367 [00:00<00:01, 193.70it/s]Pre-training Epoch 55:  49%|████▊     | 178/367 [00:00<00:01, 185.04it/s]Pre-training Epoch 55:  54%|█████▎    | 197/367 [00:01<00:00, 175.47it/s]Pre-training Epoch 55:  59%|█████▊    | 215/367 [00:01<00:00, 171.04it/s]Pre-training Epoch 55:  63%|██████▎   | 233/367 [00:01<00:00, 164.84it/s]Pre-training Epoch 55:  68%|██████▊   | 250/367 [00:01<00:00, 161.22it/s]recon_loss: 0.028841957449913025, dist_loss: 0.32094183564186096
recon_loss: 0.028843453153967857, dist_loss: 1.00710928440094
recon_loss: 0.028843246400356293, dist_loss: 0.5731205940246582
recon_loss: 0.028842125087976456, dist_loss: 0.7974539995193481
recon_loss: 0.028841732069849968, dist_loss: 0.33802586793899536
recon_loss: 0.02884039282798767, dist_loss: 0.5716080665588379
recon_loss: 0.02883937396109104, dist_loss: 0.48676586151123047
recon_loss: 0.028839748352766037, dist_loss: 0.8182153701782227
recon_loss: 0.028840065002441406, dist_loss: 0.5746001601219177
recon_loss: 0.02884053625166416, dist_loss: 0.5327518582344055
recon_loss: 0.028841383755207062, dist_loss: 0.8513283729553223
recon_loss: 0.028842318803071976, dist_loss: 0.8605843782424927
recon_loss: 0.02884325385093689, dist_loss: 0.490191251039505
recon_loss: 0.02884388156235218, dist_loss: 0.7711118459701538
recon_loss: 0.028844138607382774, dist_loss: 0.4971766471862793
recon_loss: 0.028844226151704788, dist_loss: 0.9188159108161926
recon_loss: 0.028843954205513, dist_loss: 1.057310938835144
recon_loss: 0.02884392999112606, dist_loss: 0.8773550391197205
recon_loss: 0.028843803331255913, dist_loss: 0.46840447187423706
recon_loss: 0.028842872008681297, dist_loss: 0.7503217458724976
recon_loss: 0.02884267456829548, dist_loss: 0.7477608919143677
recon_loss: 0.028841590508818626, dist_loss: 0.6305555701255798
recon_loss: 0.028841054067015648, dist_loss: 0.6222445964813232
recon_loss: 0.028841013088822365, dist_loss: 0.5057156085968018
recon_loss: 0.02883918210864067, dist_loss: 0.38628852367401123
recon_loss: 0.02883976697921753, dist_loss: 0.5354823470115662
recon_loss: 0.028839856386184692, dist_loss: 0.4733928442001343
recon_loss: 0.0288383848965168, dist_loss: 0.43503111600875854
recon_loss: 0.02883821725845337, dist_loss: 0.5924931764602661
recon_loss: 0.02883751690387726, dist_loss: 0.5474386215209961
recon_loss: 0.028836961835622787, dist_loss: 0.6128575801849365
recon_loss: 0.028836669400334358, dist_loss: 0.359474241733551
recon_loss: 0.028836393728852272, dist_loss: 0.2949434518814087
recon_loss: 0.028836689889431, dist_loss: 0.46635833382606506
recon_loss: 0.02883671410381794, dist_loss: 0.689880907535553
recon_loss: 0.02883642166852951, dist_loss: 0.7821800708770752
recon_loss: 0.028836673125624657, dist_loss: 0.674458920955658
recon_loss: 0.028836697340011597, dist_loss: 0.5446379780769348
recon_loss: 0.028836512938141823, dist_loss: 1.0163915157318115
recon_loss: 0.028836721554398537, dist_loss: 0.8923901319503784
recon_loss: 0.028836853802204132, dist_loss: 0.7470196485519409
recon_loss: 0.02883695811033249, dist_loss: 0.5177258253097534
recon_loss: 0.028836743906140327, dist_loss: 0.42553427815437317
recon_loss: 0.028836634010076523, dist_loss: 0.7235037684440613
recon_loss: 0.0288360845297575, dist_loss: 0.7026402950286865
recon_loss: 0.028835907578468323, dist_loss: 0.8511165976524353
recon_loss: 0.028836160898208618, dist_loss: 0.3387869596481323
recon_loss: 0.028836093842983246, dist_loss: 0.6462318301200867
recon_loss: 0.02883591502904892, dist_loss: 0.8021366000175476
recon_loss: 0.02883557230234146, dist_loss: 0.5647878050804138
recon_loss: 0.028834344819188118, dist_loss: 0.6633004546165466
recon_loss: 0.02883460931479931, dist_loss: 0.5775613784790039
recon_loss: 0.028834279626607895, dist_loss: 0.37195733189582825
recon_loss: 0.028833430260419846, dist_loss: 0.6171157360076904
recon_loss: 0.028833581134676933, dist_loss: 0.7156085968017578
recon_loss: 0.028832921758294106, dist_loss: 0.8311864733695984
recon_loss: 0.028833333402872086, dist_loss: 0.28240957856178284
recon_loss: 0.028833651915192604, dist_loss: 0.6920534372329712
recon_loss: 0.028832925483584404, dist_loss: 0.5647484660148621
recon_loss: 0.028832320123910904, dist_loss: 0.649539589881897
recon_loss: 0.028832094743847847, dist_loss: 0.753787100315094
recon_loss: 0.028832415118813515, dist_loss: 0.49640360474586487
recon_loss: 0.02883259207010269, dist_loss: 0.8719984889030457
recon_loss: 0.02883297950029373, dist_loss: 0.597912073135376
recon_loss: 0.02883300557732582, dist_loss: 0.759626567363739
recon_loss: 0.028832843527197838, dist_loss: 0.6460036039352417
recon_loss: 0.028834106400609016, dist_loss: 0.7047604918479919
recon_loss: 0.028833672404289246, dist_loss: 0.34482190012931824
recon_loss: 0.02883422002196312, dist_loss: 0.3601871728897095
recon_loss: 0.02883535623550415, dist_loss: 0.4995534121990204
recon_loss: 0.02883504144847393, dist_loss: 0.6383709907531738
recon_loss: 0.028834642842411995, dist_loss: 0.6031928062438965
recon_loss: 0.028834261000156403, dist_loss: 0.8485682010650635
recon_loss: 0.028833813965320587, dist_loss: 0.5079078674316406
recon_loss: 0.028833474963903427, dist_loss: 0.5231016874313354
recon_loss: 0.02883378602564335, dist_loss: 0.616805374622345
recon_loss: 0.028833337128162384, dist_loss: 0.969638466835022
recon_loss: 0.0288329366594553, dist_loss: 0.7392795085906982
recon_loss: 0.02883324772119522, dist_loss: 0.7318615913391113
recon_loss: 0.028832653537392616, dist_loss: 0.7220032215118408
recon_loss: 0.02883240021765232, dist_loss: 0.47424954175949097
recon_loss: 0.028832565993070602, dist_loss: 1.0587551593780518
recon_loss: 0.02883262187242508, dist_loss: 0.4384215176105499
recon_loss: 0.028833212330937386, dist_loss: 0.8474841117858887
recon_loss: 0.028833208605647087, dist_loss: 0.44424110651016235
recon_loss: 0.028832871466875076, dist_loss: 1.3032954931259155
recon_loss: 0.02883283607661724, dist_loss: 0.6720871925354004
recon_loss: 0.028832215815782547, dist_loss: 0.3208478093147278
recon_loss: 0.02883180044591427, dist_loss: 0.6748782396316528
recon_loss: 0.028832178562879562, dist_loss: 0.5430772304534912
recon_loss: 0.028832215815782547, dist_loss: 0.7509120106697083
recon_loss: 0.028832625597715378, dist_loss: 0.5510300397872925
recon_loss: 0.02883274480700493, dist_loss: 0.65242999792099
recon_loss: 0.02883143164217472, dist_loss: 0.9018121957778931
recon_loss: 0.028830699622631073, dist_loss: 0.5099846124649048
recon_loss: 0.028830448165535927, dist_loss: 0.8259629607200623
recon_loss: 0.028830401599407196, dist_loss: 0.8404679298400879
recon_loss: 0.02883116714656353, dist_loss: 0.6325664520263672
recon_loss: 0.028831548988819122, dist_loss: 0.5186653137207031
recon_loss: 0.02883116714656353, dist_loss: 0.5621126890182495
recon_loss: 0.02883169800043106, dist_loss: 0.5134243965148926
recon_loss: 0.02883213944733143, dist_loss: 0.5165882110595703
recon_loss: 0.0288332998752594, dist_loss: 0.3882863223552704
recon_loss: 0.028835197910666466, dist_loss: 0.47734713554382324
recon_loss: 0.028836648911237717, dist_loss: 1.595462679862976
recon_loss: 0.028838129714131355, dist_loss: 0.8294455409049988
recon_loss: 0.028840133920311928, dist_loss: 0.8781890273094177
recon_loss: 0.02884051203727722, dist_loss: 0.48781293630599976
recon_loss: 0.028840815648436546, dist_loss: 0.7940293550491333
recon_loss: 0.028839565813541412, dist_loss: 0.6401065587997437
recon_loss: 0.028838669881224632, dist_loss: 0.4316990375518799
recon_loss: 0.02883792109787464, dist_loss: 0.7048395872116089
recon_loss: 0.028835628181695938, dist_loss: 0.8605791330337524
recon_loss: 0.02883422188460827, dist_loss: 0.9411758780479431
recon_loss: 0.02883276715874672, dist_loss: 0.9908704161643982
recon_loss: 0.028831299394369125, dist_loss: 0.47357177734375
recon_loss: 0.0288307536393404, dist_loss: 0.38020384311676025
recon_loss: 0.02882985956966877, dist_loss: 0.4105880558490753
recon_loss: 0.028828900307416916, dist_loss: 0.4419865608215332
recon_loss: 0.02882925048470497, dist_loss: 0.49376434087753296
recon_loss: 0.02882852405309677, dist_loss: 0.62179034948349
recon_loss: 0.028828101232647896, dist_loss: 0.635357677936554
recon_loss: 0.028828473761677742, dist_loss: 0.5970221161842346
recon_loss: 0.028827233240008354, dist_loss: 0.5743207931518555
recon_loss: 0.028827527537941933, dist_loss: 0.8405051231384277
recon_loss: 0.02882823348045349, dist_loss: 0.3365247845649719
recon_loss: 0.028826987370848656, dist_loss: 0.46576789021492004
recon_loss: 0.028827466070652008, dist_loss: 0.8476006984710693
Pre-training Epoch 55:  73%|███████▎  | 267/367 [00:01<00:00, 158.75it/s]Pre-training Epoch 55:  77%|███████▋  | 283/367 [00:01<00:00, 157.39it/s]Pre-training Epoch 55:  81%|████████▏ | 299/367 [00:01<00:00, 156.81it/s]Pre-training Epoch 55:  86%|████████▌ | 315/367 [00:01<00:00, 156.19it/s]Pre-training Epoch 55:  90%|█████████ | 331/367 [00:01<00:00, 155.90it/s]Pre-training Epoch 55:  95%|█████████▍| 347/367 [00:02<00:00, 155.47it/s]Pre-training Epoch 55:  99%|█████████▉| 363/367 [00:02<00:00, 155.38it/s]Pre-training Epoch 55: 100%|██████████| 367/367 [00:02<00:00, 169.81it/s]
recon_loss: 0.028827520087361336, dist_loss: 0.4872850775718689
recon_loss: 0.028826512396335602, dist_loss: 0.49404478073120117
recon_loss: 0.028826884925365448, dist_loss: 0.6764136552810669
recon_loss: 0.028826894238591194, dist_loss: 0.5331624150276184
recon_loss: 0.02882644720375538, dist_loss: 0.42842918634414673
recon_loss: 0.02882666327059269, dist_loss: 0.8075556755065918
recon_loss: 0.02882634848356247, dist_loss: 0.4287262558937073
recon_loss: 0.028826076537370682, dist_loss: 1.0470073223114014
recon_loss: 0.028826044872403145, dist_loss: 0.2969931662082672
recon_loss: 0.02882559597492218, dist_loss: 0.8392828702926636
recon_loss: 0.02882586047053337, dist_loss: 0.5609581470489502
recon_loss: 0.028826119378209114, dist_loss: 0.4989162087440491
recon_loss: 0.02882583998143673, dist_loss: 0.47589313983917236
recon_loss: 0.028825918212532997, dist_loss: 0.7130905389785767
recon_loss: 0.02882518246769905, dist_loss: 0.47492730617523193
recon_loss: 0.02882460318505764, dist_loss: 0.9632662534713745
recon_loss: 0.028824588283896446, dist_loss: 0.4838723838329315
recon_loss: 0.02882438711822033, dist_loss: 0.7547966837882996
recon_loss: 0.02882428839802742, dist_loss: 0.5881271362304688
recon_loss: 0.02882426604628563, dist_loss: 0.907955527305603
recon_loss: 0.02882411703467369, dist_loss: 0.5491345524787903
recon_loss: 0.028823720291256905, dist_loss: 0.46159183979034424
recon_loss: 0.028823452070355415, dist_loss: 0.42444485425949097
recon_loss: 0.028823452070355415, dist_loss: 0.5380992889404297
recon_loss: 0.028823405504226685, dist_loss: 1.0024763345718384
recon_loss: 0.028823543339967728, dist_loss: 0.45385998487472534
recon_loss: 0.02882341295480728, dist_loss: 0.6237625479698181
recon_loss: 0.028823232278227806, dist_loss: 0.7848628759384155
recon_loss: 0.02882302924990654, dist_loss: 0.5040676593780518
recon_loss: 0.02882297895848751, dist_loss: 1.1302169561386108
recon_loss: 0.028822971507906914, dist_loss: 0.6175289154052734
recon_loss: 0.028822900727391243, dist_loss: 0.2762552797794342
recon_loss: 0.028822945430874825, dist_loss: 0.7882184386253357
recon_loss: 0.02882271446287632, dist_loss: 0.577932596206665
recon_loss: 0.028822636231780052, dist_loss: 0.7727373838424683
recon_loss: 0.0288224034011364, dist_loss: 0.7832286357879639
recon_loss: 0.02882218174636364, dist_loss: 0.3127235770225525
recon_loss: 0.02882208675146103, dist_loss: 0.38528820872306824
recon_loss: 0.028822092339396477, dist_loss: 0.36636513471603394
recon_loss: 0.028821945190429688, dist_loss: 0.5257827639579773
recon_loss: 0.02882183901965618, dist_loss: 0.8149181604385376
recon_loss: 0.028821809217333794, dist_loss: 0.4905531108379364
recon_loss: 0.02882159687578678, dist_loss: 0.43271371722221375
recon_loss: 0.028821595013141632, dist_loss: 1.0201070308685303
recon_loss: 0.028821637853980064, dist_loss: 0.7145590782165527
recon_loss: 0.028821393847465515, dist_loss: 0.8765859603881836
recon_loss: 0.02882152423262596, dist_loss: 0.31309211254119873
recon_loss: 0.028821876272559166, dist_loss: 0.5009450912475586
recon_loss: 0.028821740299463272, dist_loss: 0.7377592325210571
recon_loss: 0.028822075575590134, dist_loss: 0.829107403755188
recon_loss: 0.028822151944041252, dist_loss: 0.5739531517028809
recon_loss: 0.028821555897593498, dist_loss: 0.6084900498390198
recon_loss: 0.02882179245352745, dist_loss: 1.1003944873809814
recon_loss: 0.028822006657719612, dist_loss: 0.38813549280166626
recon_loss: 0.02882155030965805, dist_loss: 0.4569774270057678
recon_loss: 0.028821593150496483, dist_loss: 1.3333747386932373
recon_loss: 0.028821300715208054, dist_loss: 0.6940908432006836
recon_loss: 0.02882114052772522, dist_loss: 0.7397236824035645
recon_loss: 0.02882125787436962, dist_loss: 1.0214436054229736
recon_loss: 0.028821071609854698, dist_loss: 0.8054643869400024
recon_loss: 0.02882152423262596, dist_loss: 0.7059528231620789
recon_loss: 0.028822090476751328, dist_loss: 0.6766595840454102
recon_loss: 0.02882251888513565, dist_loss: 1.2233989238739014
recon_loss: 0.028823453933000565, dist_loss: 0.6858565807342529
recon_loss: 0.028823165223002434, dist_loss: 0.45420050621032715
recon_loss: 0.02882375381886959, dist_loss: 0.4338059425354004
recon_loss: 0.028823500499129295, dist_loss: 0.7786883115768433
recon_loss: 0.02882269397377968, dist_loss: 0.6887089014053345
recon_loss: 0.02882329747080803, dist_loss: 0.7273858189582825
recon_loss: 0.02882290631532669, dist_loss: 0.6110013127326965
recon_loss: 0.02882186323404312, dist_loss: 0.919111430644989
recon_loss: 0.02882113680243492, dist_loss: 0.34583497047424316
recon_loss: 0.028820648789405823, dist_loss: 1.0758416652679443
recon_loss: 0.028820093721151352, dist_loss: 0.46281692385673523
recon_loss: 0.028820976614952087, dist_loss: 0.8347271680831909
recon_loss: 0.028821807354688644, dist_loss: 1.116680383682251
recon_loss: 0.02882257103919983, dist_loss: 0.7022008299827576
recon_loss: 0.02882373332977295, dist_loss: 0.9117739200592041
recon_loss: 0.028824206441640854, dist_loss: 0.6537335515022278
recon_loss: 0.028823452070355415, dist_loss: 0.5816980600357056
recon_loss: 0.028822682797908783, dist_loss: 0.6973658204078674
recon_loss: 0.028821850195527077, dist_loss: 0.8212655186653137
recon_loss: 0.028820723295211792, dist_loss: 0.7918679714202881
recon_loss: 0.028819827362895012, dist_loss: 0.7258511781692505
recon_loss: 0.02881896309554577, dist_loss: 0.67707359790802
recon_loss: 0.028818465769290924, dist_loss: 0.43147069215774536
recon_loss: 0.028818752616643906, dist_loss: 0.522505521774292
recon_loss: 0.028818469494581223, dist_loss: 0.6276125311851501
recon_loss: 0.028818607330322266, dist_loss: 0.3617815375328064
recon_loss: 0.02881919965147972, dist_loss: 0.5799391269683838
recon_loss: 0.028818991035223007, dist_loss: 0.8063548803329468
recon_loss: 0.028819123283028603, dist_loss: 0.7934224605560303
recon_loss: 0.028819279745221138, dist_loss: 0.8389745950698853
recon_loss: 0.028820935636758804, dist_loss: 0.9732406139373779
recon_loss: 0.028821753337979317, dist_loss: 0.4625534117221832
recon_loss: 0.028822386637330055, dist_loss: 0.6779909133911133
recon_loss: 0.0288230013102293, dist_loss: 0.5671049952507019
recon_loss: 0.02882125973701477, dist_loss: 0.8728740811347961
recon_loss: 0.028819842264056206, dist_loss: 0.46975696086883545
recon_loss: 0.028819506987929344, dist_loss: 0.638289749622345
recon_loss: 0.02881852723658085, dist_loss: 0.9738982915878296
recon_loss: 0.028818514198064804, dist_loss: 0.45892131328582764
recon_loss: 0.028817692771553993, dist_loss: 1.1848849058151245
recon_loss: 0.028816161677241325, dist_loss: 0.3038891851902008
recon_loss: 0.028815755620598793, dist_loss: 0.6941846609115601
recon_loss: 0.02881539613008499, dist_loss: 0.4750248193740845
recon_loss: 0.028815224766731262, dist_loss: 0.6567356586456299
recon_loss: 0.028815558180212975, dist_loss: 1.0952141284942627
recon_loss: 0.028816234320402145, dist_loss: 0.49631890654563904
recon_loss: 0.028816038742661476, dist_loss: 0.5683902502059937
recon_loss: 0.028816305100917816, dist_loss: 0.8190646171569824
Pre-training Epoch 56:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 56:   5%|▍         | 18/367 [00:00<00:02, 172.53it/s]Pre-training Epoch 56:  10%|█         | 37/367 [00:00<00:01, 182.56it/s]Pre-training Epoch 56:  16%|█▌        | 57/367 [00:00<00:01, 186.32it/s]Pre-training Epoch 56:  21%|██        | 77/367 [00:00<00:01, 188.70it/s]Pre-training Epoch 56:  26%|██▋       | 97/367 [00:00<00:01, 190.08it/s]Pre-training Epoch 56:  32%|███▏      | 117/367 [00:00<00:01, 190.88it/s]recon_loss: 0.02881659008562565, dist_loss: 1.0682697296142578
recon_loss: 0.028816595673561096, dist_loss: 1.079456090927124
recon_loss: 0.028816433623433113, dist_loss: 0.8698879480361938
recon_loss: 0.02881600707769394, dist_loss: 1.158219337463379
recon_loss: 0.028815653175115585, dist_loss: 0.9220899343490601
recon_loss: 0.02881547436118126, dist_loss: 0.518278956413269
recon_loss: 0.028814729303121567, dist_loss: 0.5346440672874451
recon_loss: 0.028814705088734627, dist_loss: 0.416916161775589
recon_loss: 0.028814472258090973, dist_loss: 0.4719352126121521
recon_loss: 0.028814073652029037, dist_loss: 0.7749209403991699
recon_loss: 0.02881440706551075, dist_loss: 0.32658302783966064
recon_loss: 0.028814546763896942, dist_loss: 0.3827720284461975
recon_loss: 0.02881399542093277, dist_loss: 0.6862050294876099
recon_loss: 0.028813645243644714, dist_loss: 0.6215328574180603
recon_loss: 0.028813250362873077, dist_loss: 0.7721251249313354
recon_loss: 0.028812803328037262, dist_loss: 0.5763633251190186
recon_loss: 0.028812862932682037, dist_loss: 0.7994763851165771
recon_loss: 0.02881278283894062, dist_loss: 0.5758680701255798
recon_loss: 0.028812473639845848, dist_loss: 0.5149359107017517
recon_loss: 0.028812624514102936, dist_loss: 0.8507488369941711
recon_loss: 0.028812559321522713, dist_loss: 0.8005672693252563
recon_loss: 0.02881230227649212, dist_loss: 0.5101343393325806
recon_loss: 0.028812145814299583, dist_loss: 0.6739230155944824
recon_loss: 0.02881203405559063, dist_loss: 0.38371992111206055
recon_loss: 0.0288119837641716, dist_loss: 0.37455642223358154
recon_loss: 0.0288119837641716, dist_loss: 1.1300840377807617
recon_loss: 0.028811955824494362, dist_loss: 0.619744598865509
recon_loss: 0.028812086209654808, dist_loss: 0.6494593620300293
recon_loss: 0.028812335804104805, dist_loss: 1.0155693292617798
recon_loss: 0.02881290763616562, dist_loss: 0.5663076043128967
recon_loss: 0.028813811019062996, dist_loss: 0.9593098163604736
recon_loss: 0.028813714161515236, dist_loss: 1.3597943782806396
recon_loss: 0.028813572600483894, dist_loss: 0.6429046392440796
recon_loss: 0.02881321869790554, dist_loss: 0.4519732594490051
recon_loss: 0.028812898322939873, dist_loss: 0.8507553935050964
recon_loss: 0.028812868520617485, dist_loss: 0.6498993039131165
recon_loss: 0.028812972828745842, dist_loss: 0.4677269160747528
recon_loss: 0.02881273254752159, dist_loss: 0.26529693603515625
recon_loss: 0.0288119837641716, dist_loss: 0.620419979095459
recon_loss: 0.028811832889914513, dist_loss: 0.5998082160949707
recon_loss: 0.028812026605010033, dist_loss: 0.6804938316345215
recon_loss: 0.02881261147558689, dist_loss: 0.46917611360549927
recon_loss: 0.028813855722546577, dist_loss: 1.0612382888793945
recon_loss: 0.028814811259508133, dist_loss: 1.2662546634674072
recon_loss: 0.028816143050789833, dist_loss: 0.5933338403701782
recon_loss: 0.02881637029349804, dist_loss: 0.46627628803253174
recon_loss: 0.028816670179367065, dist_loss: 0.65120929479599
recon_loss: 0.028816532343626022, dist_loss: 1.1675783395767212
recon_loss: 0.028815463185310364, dist_loss: 0.6290207505226135
recon_loss: 0.028814654797315598, dist_loss: 1.013818621635437
recon_loss: 0.02881377376616001, dist_loss: 0.4810604155063629
recon_loss: 0.0288129523396492, dist_loss: 0.5654770135879517
recon_loss: 0.028811968863010406, dist_loss: 0.4811604619026184
recon_loss: 0.028811320662498474, dist_loss: 0.6062612533569336
recon_loss: 0.02881072834134102, dist_loss: 0.6131773591041565
recon_loss: 0.028810661286115646, dist_loss: 0.7184959650039673
recon_loss: 0.028810665011405945, dist_loss: 0.4312542676925659
recon_loss: 0.028810370713472366, dist_loss: 0.7381561398506165
recon_loss: 0.02881055325269699, dist_loss: 0.47857415676116943
recon_loss: 0.028810638934373856, dist_loss: 0.5560287833213806
recon_loss: 0.028810271993279457, dist_loss: 0.9220592975616455
recon_loss: 0.028810204938054085, dist_loss: 0.7201350927352905
recon_loss: 0.02880966290831566, dist_loss: 0.5598331689834595
recon_loss: 0.02880912274122238, dist_loss: 0.6206880807876587
recon_loss: 0.028808828443288803, dist_loss: 0.9345634579658508
recon_loss: 0.028808651491999626, dist_loss: 0.9592215418815613
recon_loss: 0.02880866639316082, dist_loss: 0.7965208292007446
recon_loss: 0.028808822855353355, dist_loss: 0.5282443165779114
recon_loss: 0.028808770701289177, dist_loss: 0.4118468463420868
recon_loss: 0.028808563947677612, dist_loss: 0.6238133907318115
recon_loss: 0.02880832552909851, dist_loss: 0.7054101228713989
recon_loss: 0.02880793996155262, dist_loss: 0.7407852411270142
recon_loss: 0.028808066621422768, dist_loss: 0.6201683282852173
recon_loss: 0.028808239847421646, dist_loss: 0.9477764368057251
recon_loss: 0.028808236122131348, dist_loss: 0.7300617098808289
recon_loss: 0.028808213770389557, dist_loss: 0.3681543171405792
recon_loss: 0.02880801446735859, dist_loss: 0.7646132111549377
recon_loss: 0.02880762331187725, dist_loss: 0.4688265323638916
recon_loss: 0.02880753204226494, dist_loss: 0.8122386336326599
recon_loss: 0.028807679191231728, dist_loss: 0.6280643343925476
recon_loss: 0.02880777046084404, dist_loss: 0.9350372552871704
recon_loss: 0.02880769409239292, dist_loss: 0.6160754561424255
recon_loss: 0.028807304799556732, dist_loss: 0.8215632438659668
recon_loss: 0.02880648337304592, dist_loss: 0.575840950012207
recon_loss: 0.02880600094795227, dist_loss: 0.6808956265449524
recon_loss: 0.028805917128920555, dist_loss: 0.5176329016685486
recon_loss: 0.028805414214730263, dist_loss: 0.8017799258232117
recon_loss: 0.028805630281567574, dist_loss: 0.8087568283081055
recon_loss: 0.028805986046791077, dist_loss: 0.6553096175193787
recon_loss: 0.02880527637898922, dist_loss: 1.1195693016052246
recon_loss: 0.028805958107113838, dist_loss: 0.640998125076294
recon_loss: 0.028806569054722786, dist_loss: 0.3784782588481903
recon_loss: 0.028806405141949654, dist_loss: 0.5088627934455872
recon_loss: 0.028806839138269424, dist_loss: 0.6139470934867859
recon_loss: 0.02880697138607502, dist_loss: 0.8756545782089233
recon_loss: 0.028807489201426506, dist_loss: 0.6333208680152893
recon_loss: 0.028807293623685837, dist_loss: 1.2836885452270508
recon_loss: 0.02880772575736046, dist_loss: 0.9454242587089539
recon_loss: 0.028808148577809334, dist_loss: 0.7505659461021423
recon_loss: 0.028808629140257835, dist_loss: 0.8251587152481079
recon_loss: 0.028809333220124245, dist_loss: 0.48870840668678284
recon_loss: 0.02880963124334812, dist_loss: 0.32483357191085815
recon_loss: 0.028809696435928345, dist_loss: 0.5143914222717285
recon_loss: 0.028809573501348495, dist_loss: 0.36534354090690613
recon_loss: 0.028809119015932083, dist_loss: 0.4386902451515198
recon_loss: 0.02880842052400112, dist_loss: 0.8708556890487671
recon_loss: 0.028807561844587326, dist_loss: 0.805051326751709
recon_loss: 0.028807271271944046, dist_loss: 0.8905149698257446
recon_loss: 0.028806785121560097, dist_loss: 0.6080939173698425
recon_loss: 0.028806263580918312, dist_loss: 0.3528252840042114
recon_loss: 0.0288059264421463, dist_loss: 0.4989857077598572
recon_loss: 0.028805557638406754, dist_loss: 0.6859778165817261
recon_loss: 0.02880638651549816, dist_loss: 0.37381935119628906
recon_loss: 0.02880697138607502, dist_loss: 0.5646096467971802
recon_loss: 0.028807656839489937, dist_loss: 0.8795797824859619
recon_loss: 0.028808413073420525, dist_loss: 0.8632662296295166
recon_loss: 0.02880907990038395, dist_loss: 0.6241137981414795
recon_loss: 0.0288081094622612, dist_loss: 0.6798000335693359
recon_loss: 0.028807561844587326, dist_loss: 0.6909749507904053
recon_loss: 0.028807606548070908, dist_loss: 0.6559034585952759
recon_loss: 0.028806352987885475, dist_loss: 0.5512092709541321
recon_loss: 0.028805924579501152, dist_loss: 0.44166702032089233
recon_loss: 0.028805823996663094, dist_loss: 0.6045154333114624
recon_loss: 0.028804542496800423, dist_loss: 0.6057604551315308
recon_loss: 0.028805064037442207, dist_loss: 0.5661970376968384
recon_loss: 0.02880421094596386, dist_loss: 0.85760498046875
recon_loss: 0.02880333736538887, dist_loss: 0.614793598651886
recon_loss: 0.02880380116403103, dist_loss: 0.5277079343795776
Pre-training Epoch 56:  37%|███▋      | 137/367 [00:00<00:01, 191.36it/s]Pre-training Epoch 56:  43%|████▎     | 157/367 [00:00<00:01, 191.66it/s]Pre-training Epoch 56:  48%|████▊     | 177/367 [00:00<00:00, 191.83it/s]Pre-training Epoch 56:  54%|█████▎    | 197/367 [00:01<00:00, 191.95it/s]Pre-training Epoch 56:  59%|█████▉    | 217/367 [00:01<00:00, 191.77it/s]Pre-training Epoch 56:  65%|██████▍   | 237/367 [00:01<00:00, 191.92it/s]recon_loss: 0.02880284935235977, dist_loss: 0.8044909238815308
recon_loss: 0.028802834451198578, dist_loss: 0.6109124422073364
recon_loss: 0.028802968561649323, dist_loss: 0.3772194981575012
recon_loss: 0.028802206739783287, dist_loss: 0.44279876351356506
recon_loss: 0.028801899403333664, dist_loss: 0.49313801527023315
recon_loss: 0.02880176156759262, dist_loss: 0.5283686518669128
recon_loss: 0.02880167029798031, dist_loss: 0.6134054660797119
recon_loss: 0.028802156448364258, dist_loss: 0.5769445896148682
recon_loss: 0.028802242130041122, dist_loss: 0.3583945035934448
recon_loss: 0.028801875188946724, dist_loss: 0.4402605891227722
recon_loss: 0.028801437467336655, dist_loss: 0.759272575378418
recon_loss: 0.02880074456334114, dist_loss: 0.4543209373950958
recon_loss: 0.028800617903470993, dist_loss: 0.30804121494293213
recon_loss: 0.02880117855966091, dist_loss: 1.0792882442474365
recon_loss: 0.028801433742046356, dist_loss: 1.0008492469787598
recon_loss: 0.02880133129656315, dist_loss: 0.5467004776000977
recon_loss: 0.028801431879401207, dist_loss: 1.1119494438171387
recon_loss: 0.02880086749792099, dist_loss: 0.9734665751457214
recon_loss: 0.028800280764698982, dist_loss: 0.6787980794906616
recon_loss: 0.028800837695598602, dist_loss: 0.36535388231277466
recon_loss: 0.02880154736340046, dist_loss: 0.9717644453048706
recon_loss: 0.028802048414945602, dist_loss: 0.7627460956573486
recon_loss: 0.028802096843719482, dist_loss: 0.5069661736488342
recon_loss: 0.02880076691508293, dist_loss: 0.8000032901763916
recon_loss: 0.02880220301449299, dist_loss: 0.3654358685016632
recon_loss: 0.02880270779132843, dist_loss: 1.0534133911132812
recon_loss: 0.02880227193236351, dist_loss: 0.4597195088863373
recon_loss: 0.028802985325455666, dist_loss: 0.8071607351303101
recon_loss: 0.028803043067455292, dist_loss: 0.8466967344284058
recon_loss: 0.028802530840039253, dist_loss: 0.40032029151916504
recon_loss: 0.028803205117583275, dist_loss: 0.5248372554779053
recon_loss: 0.028803199529647827, dist_loss: 0.5353056192398071
recon_loss: 0.0288031417876482, dist_loss: 0.7836015224456787
recon_loss: 0.028803320601582527, dist_loss: 0.515256941318512
recon_loss: 0.02880307473242283, dist_loss: 0.434222549200058
recon_loss: 0.028802810236811638, dist_loss: 0.48432478308677673
recon_loss: 0.02880222350358963, dist_loss: 0.4615580439567566
recon_loss: 0.028801126405596733, dist_loss: 0.4925060272216797
recon_loss: 0.028800899162888527, dist_loss: 1.0003920793533325
recon_loss: 0.028800619766116142, dist_loss: 0.3382478356361389
recon_loss: 0.028800148516893387, dist_loss: 0.7047542929649353
recon_loss: 0.028800079599022865, dist_loss: 0.5875918865203857
recon_loss: 0.028799882158637047, dist_loss: 0.39116787910461426
recon_loss: 0.028799615800380707, dist_loss: 0.6370009183883667
recon_loss: 0.02879941277205944, dist_loss: 1.4284648895263672
recon_loss: 0.02879902347922325, dist_loss: 0.6803162693977356
recon_loss: 0.028798896819353104, dist_loss: 0.8633762001991272
recon_loss: 0.028798693791031837, dist_loss: 0.8559560179710388
recon_loss: 0.028798429295420647, dist_loss: 0.7188990712165833
recon_loss: 0.02879844419658184, dist_loss: 0.5537047386169434
recon_loss: 0.02879830077290535, dist_loss: 1.0600138902664185
recon_loss: 0.028798094019293785, dist_loss: 0.5924360752105713
recon_loss: 0.028797943145036697, dist_loss: 0.7019867897033691
recon_loss: 0.028798092156648636, dist_loss: 0.9823028445243835
recon_loss: 0.028798846527934074, dist_loss: 0.686297595500946
recon_loss: 0.028798779472708702, dist_loss: 1.3449413776397705
recon_loss: 0.028798533603549004, dist_loss: 0.5621553659439087
recon_loss: 0.028798745945096016, dist_loss: 0.8889951109886169
recon_loss: 0.028798239305615425, dist_loss: 0.8318262100219727
recon_loss: 0.028798621147871017, dist_loss: 0.8351741433143616
recon_loss: 0.02879815176129341, dist_loss: 0.5946530103683472
recon_loss: 0.028797736391425133, dist_loss: 0.6768490076065063
recon_loss: 0.02879783883690834, dist_loss: 0.5434954166412354
recon_loss: 0.028797835111618042, dist_loss: 0.6917181015014648
recon_loss: 0.028797820210456848, dist_loss: 0.5275261402130127
recon_loss: 0.028797697275877, dist_loss: 0.6568377017974854
recon_loss: 0.02879764325916767, dist_loss: 0.5067125558853149
recon_loss: 0.028797419741749763, dist_loss: 0.8581563830375671
recon_loss: 0.028797117993235588, dist_loss: 0.42333459854125977
recon_loss: 0.028796600177884102, dist_loss: 0.6394801139831543
recon_loss: 0.02879626676440239, dist_loss: 0.5976094007492065
recon_loss: 0.028796430677175522, dist_loss: 0.4746353328227997
recon_loss: 0.028797030448913574, dist_loss: 0.8927220106124878
recon_loss: 0.028797680512070656, dist_loss: 0.7510926723480225
recon_loss: 0.028798621147871017, dist_loss: 0.6621602773666382
recon_loss: 0.02879943512380123, dist_loss: 0.6863582134246826
recon_loss: 0.028800392523407936, dist_loss: 0.7007915377616882
recon_loss: 0.028801843523979187, dist_loss: 0.47230595350265503
recon_loss: 0.02880399487912655, dist_loss: 0.3519722521305084
recon_loss: 0.028805112466216087, dist_loss: 0.8216625452041626
recon_loss: 0.028805790469050407, dist_loss: 0.5918729305267334
recon_loss: 0.028806215152144432, dist_loss: 0.5403670072555542
recon_loss: 0.028806084766983986, dist_loss: 0.603962779045105
recon_loss: 0.028804956004023552, dist_loss: 0.6381559371948242
recon_loss: 0.028803126886487007, dist_loss: 0.5402487516403198
recon_loss: 0.02880116179585457, dist_loss: 0.7099012732505798
recon_loss: 0.02880002371966839, dist_loss: 0.8593022227287292
recon_loss: 0.028798328712582588, dist_loss: 0.37777161598205566
recon_loss: 0.028797244653105736, dist_loss: 0.35116368532180786
recon_loss: 0.028796741738915443, dist_loss: 0.45002418756484985
recon_loss: 0.028796158730983734, dist_loss: 0.7002736330032349
recon_loss: 0.028796670958399773, dist_loss: 0.5246926546096802
recon_loss: 0.028796516358852386, dist_loss: 0.48428279161453247
recon_loss: 0.0287967287003994, dist_loss: 0.8857711553573608
recon_loss: 0.028797101229429245, dist_loss: 1.570358157157898
recon_loss: 0.028797119855880737, dist_loss: 0.5815252661705017
recon_loss: 0.028797192499041557, dist_loss: 0.4441838264465332
recon_loss: 0.02879711054265499, dist_loss: 0.5664713382720947
recon_loss: 0.028796253725886345, dist_loss: 0.6913461685180664
recon_loss: 0.028795743361115456, dist_loss: 0.6442794799804688
recon_loss: 0.02879553660750389, dist_loss: 0.6780048608779907
recon_loss: 0.02879442274570465, dist_loss: 0.8219057321548462
recon_loss: 0.028794020414352417, dist_loss: 0.36379677057266235
recon_loss: 0.02879420481622219, dist_loss: 0.9801107048988342
recon_loss: 0.028793657198548317, dist_loss: 0.5887508392333984
recon_loss: 0.028793180361390114, dist_loss: 1.0439398288726807
recon_loss: 0.028792710974812508, dist_loss: 0.43359819054603577
recon_loss: 0.028792334720492363, dist_loss: 0.44753944873809814
recon_loss: 0.02879253588616848, dist_loss: 1.0318984985351562
recon_loss: 0.02879287116229534, dist_loss: 0.7298538684844971
recon_loss: 0.02879246138036251, dist_loss: 0.842122495174408
recon_loss: 0.028792383149266243, dist_loss: 1.114018440246582
recon_loss: 0.028792094439268112, dist_loss: 0.7188378572463989
recon_loss: 0.028792107477784157, dist_loss: 0.429506778717041
recon_loss: 0.028792139142751694, dist_loss: 0.7005051374435425
recon_loss: 0.028792690485715866, dist_loss: 0.6982408761978149
recon_loss: 0.02879323624074459, dist_loss: 0.6482499837875366
recon_loss: 0.02879306674003601, dist_loss: 1.195589542388916
recon_loss: 0.028794806450605392, dist_loss: 1.0015310049057007
recon_loss: 0.028794648125767708, dist_loss: 0.523711085319519
recon_loss: 0.028793156147003174, dist_loss: 0.8989419341087341
recon_loss: 0.028795301914215088, dist_loss: 1.0230759382247925
recon_loss: 0.028793882578611374, dist_loss: 0.5922393798828125
recon_loss: 0.02879280038177967, dist_loss: 0.7782355546951294
recon_loss: 0.028793485835194588, dist_loss: 0.45475560426712036
recon_loss: 0.02879216894507408, dist_loss: 0.25924015045166016
recon_loss: 0.02879195660352707, dist_loss: 0.4512619972229004
recon_loss: 0.0287922415882349, dist_loss: 0.7144176363945007
Pre-training Epoch 56:  70%|███████   | 257/367 [00:01<00:00, 190.65it/s]Pre-training Epoch 56:  75%|███████▌  | 277/367 [00:01<00:00, 186.67it/s]Pre-training Epoch 56:  81%|████████  | 296/367 [00:01<00:00, 183.98it/s]Pre-training Epoch 56:  86%|████████▌ | 315/367 [00:01<00:00, 182.51it/s]Pre-training Epoch 56:  91%|█████████ | 334/367 [00:01<00:00, 181.16it/s]Pre-training Epoch 56:  96%|█████████▌| 353/367 [00:01<00:00, 178.80it/s]Pre-training Epoch 56: 100%|██████████| 367/367 [00:01<00:00, 186.00it/s]
recon_loss: 0.028791267424821854, dist_loss: 0.9189115762710571
recon_loss: 0.0287906713783741, dist_loss: 0.7803314924240112
recon_loss: 0.02879071608185768, dist_loss: 0.6063944697380066
recon_loss: 0.02878977544605732, dist_loss: 0.7700153589248657
recon_loss: 0.028790371492505074, dist_loss: 0.5914574861526489
recon_loss: 0.02879001945257187, dist_loss: 0.46969491243362427
recon_loss: 0.02878950722515583, dist_loss: 0.8508687615394592
recon_loss: 0.028789430856704712, dist_loss: 0.721055805683136
recon_loss: 0.02878890559077263, dist_loss: 0.704945981502533
recon_loss: 0.028788920491933823, dist_loss: 0.3767068386077881
recon_loss: 0.028789909556508064, dist_loss: 0.6542612910270691
recon_loss: 0.028789881616830826, dist_loss: 0.5463525056838989
recon_loss: 0.028789430856704712, dist_loss: 0.6024532318115234
recon_loss: 0.028790347278118134, dist_loss: 0.48734045028686523
recon_loss: 0.028789855539798737, dist_loss: 0.723060131072998
recon_loss: 0.028790872544050217, dist_loss: 0.6147012114524841
recon_loss: 0.028790852054953575, dist_loss: 0.7421921491622925
recon_loss: 0.028789905831217766, dist_loss: 0.34113597869873047
recon_loss: 0.02879045531153679, dist_loss: 0.4215075373649597
recon_loss: 0.028790313750505447, dist_loss: 0.7302144765853882
recon_loss: 0.02878982201218605, dist_loss: 0.4662233889102936
recon_loss: 0.02878955379128456, dist_loss: 0.6676203012466431
recon_loss: 0.028789062052965164, dist_loss: 0.7257950305938721
recon_loss: 0.028789084404706955, dist_loss: 0.4448239207267761
recon_loss: 0.028789430856704712, dist_loss: 0.36706140637397766
recon_loss: 0.028789076954126358, dist_loss: 1.0189838409423828
recon_loss: 0.028788724914193153, dist_loss: 1.0212035179138184
recon_loss: 0.028788013383746147, dist_loss: 0.5993473529815674
recon_loss: 0.028788140043616295, dist_loss: 0.759645938873291
recon_loss: 0.0287876445800066, dist_loss: 0.7461117506027222
recon_loss: 0.028787342831492424, dist_loss: 0.5080718994140625
recon_loss: 0.028787262737751007, dist_loss: 0.6354480981826782
recon_loss: 0.028787024319171906, dist_loss: 1.2829771041870117
recon_loss: 0.028787048533558846, dist_loss: 0.6735512018203735
recon_loss: 0.028787171468138695, dist_loss: 0.6923167705535889
recon_loss: 0.02878664992749691, dist_loss: 0.586435079574585
recon_loss: 0.02878645807504654, dist_loss: 0.26989278197288513
recon_loss: 0.028786219656467438, dist_loss: 0.5930583477020264
recon_loss: 0.028786424547433853, dist_loss: 0.5297134518623352
recon_loss: 0.028786540031433105, dist_loss: 0.5058717727661133
recon_loss: 0.028786495327949524, dist_loss: 0.4297128915786743
recon_loss: 0.02878621779382229, dist_loss: 0.29628559947013855
recon_loss: 0.028785845264792442, dist_loss: 0.6191806197166443
recon_loss: 0.0287854615598917, dist_loss: 0.47685927152633667
recon_loss: 0.02878531627357006, dist_loss: 0.6309995651245117
recon_loss: 0.028784839436411858, dist_loss: 0.6621981859207153
recon_loss: 0.02878473699092865, dist_loss: 0.33649492263793945
recon_loss: 0.028784839436411858, dist_loss: 0.44877713918685913
recon_loss: 0.02878470905125141, dist_loss: 0.6094333529472351
recon_loss: 0.028784682974219322, dist_loss: 0.5833284258842468
recon_loss: 0.028784776106476784, dist_loss: 0.8348789215087891
recon_loss: 0.028784455731511116, dist_loss: 0.650149941444397
recon_loss: 0.028784355148673058, dist_loss: 0.5252965688705444
recon_loss: 0.028784239664673805, dist_loss: 0.46961724758148193
recon_loss: 0.02878386899828911, dist_loss: 0.7809205651283264
recon_loss: 0.028783781453967094, dist_loss: 0.7716337442398071
recon_loss: 0.028783787041902542, dist_loss: 0.7667384147644043
recon_loss: 0.02878398448228836, dist_loss: 0.7377477288246155
recon_loss: 0.028784381225705147, dist_loss: 0.7696852684020996
recon_loss: 0.028784077614545822, dist_loss: 0.36898964643478394
recon_loss: 0.02878403477370739, dist_loss: 0.6314362287521362
recon_loss: 0.02878452092409134, dist_loss: 0.49051469564437866
recon_loss: 0.028785057365894318, dist_loss: 0.33319127559661865
recon_loss: 0.02878519892692566, dist_loss: 0.6810996532440186
recon_loss: 0.028785573318600655, dist_loss: 0.49944064021110535
recon_loss: 0.028785355389118195, dist_loss: 0.42680299282073975
recon_loss: 0.028785457834601402, dist_loss: 0.6546976566314697
recon_loss: 0.02878541126847267, dist_loss: 0.8391131162643433
recon_loss: 0.02878437004983425, dist_loss: 0.9844527244567871
recon_loss: 0.02878437004983425, dist_loss: 1.2926298379898071
recon_loss: 0.02878406271338463, dist_loss: 0.3384178876876831
recon_loss: 0.028783686459064484, dist_loss: 0.775912880897522
recon_loss: 0.028784211724996567, dist_loss: 0.5778684616088867
recon_loss: 0.028784388676285744, dist_loss: 0.4822376072406769
recon_loss: 0.02878379262983799, dist_loss: 1.2969844341278076
recon_loss: 0.028784355148673058, dist_loss: 0.5646318793296814
recon_loss: 0.028784453868865967, dist_loss: 0.42471930384635925
recon_loss: 0.02878475748002529, dist_loss: 0.7270153760910034
recon_loss: 0.028785081580281258, dist_loss: 1.1403539180755615
recon_loss: 0.0287846140563488, dist_loss: 0.5432003736495972
recon_loss: 0.0287840086966753, dist_loss: 0.560753583908081
recon_loss: 0.02878318540751934, dist_loss: 0.448655366897583
recon_loss: 0.028782309964299202, dist_loss: 0.6708987355232239
recon_loss: 0.028781747445464134, dist_loss: 0.500698447227478
recon_loss: 0.02878163568675518, dist_loss: 0.6674306392669678
recon_loss: 0.028782084584236145, dist_loss: 1.0793988704681396
recon_loss: 0.028782207518815994, dist_loss: 0.5934164524078369
recon_loss: 0.028781916946172714, dist_loss: 0.666102409362793
recon_loss: 0.028781620785593987, dist_loss: 0.5669407248497009
recon_loss: 0.028781307861208916, dist_loss: 0.3820827603340149
recon_loss: 0.028781717643141747, dist_loss: 0.5839113593101501
recon_loss: 0.028782416135072708, dist_loss: 0.7205571532249451
recon_loss: 0.028782453387975693, dist_loss: 0.29303476214408875
recon_loss: 0.02878226898610592, dist_loss: 0.4876560866832733
recon_loss: 0.02878176048398018, dist_loss: 0.6917210221290588
recon_loss: 0.028781244531273842, dist_loss: 1.3216595649719238
recon_loss: 0.028781181201338768, dist_loss: 0.8210530877113342
recon_loss: 0.02878100425004959, dist_loss: 0.6529378890991211
recon_loss: 0.028781229630112648, dist_loss: 0.7370116710662842
recon_loss: 0.02878090925514698, dist_loss: 0.45227304100990295
recon_loss: 0.028780074790120125, dist_loss: 0.4147939682006836
recon_loss: 0.028780097141861916, dist_loss: 0.7576919794082642
recon_loss: 0.028780026361346245, dist_loss: 1.0055891275405884
recon_loss: 0.028780506923794746, dist_loss: 0.9654316306114197
recon_loss: 0.028781287372112274, dist_loss: 0.3544985055923462
recon_loss: 0.028781048953533173, dist_loss: 0.6414636373519897
recon_loss: 0.028780117630958557, dist_loss: 1.180626630783081
recon_loss: 0.028779281303286552, dist_loss: 0.9092161059379578
recon_loss: 0.028779352083802223, dist_loss: 0.9916515350341797
recon_loss: 0.028779881075024605, dist_loss: 1.0473803281784058
recon_loss: 0.028780337423086166, dist_loss: 1.0670925378799438
Pre-training Epoch 57:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 57:   5%|▍         | 18/367 [00:00<00:02, 171.08it/s]Pre-training Epoch 57:  10%|█         | 37/367 [00:00<00:01, 177.04it/s]Pre-training Epoch 57:  15%|█▌        | 56/367 [00:00<00:01, 178.66it/s]Pre-training Epoch 57:  20%|██        | 75/367 [00:00<00:01, 179.97it/s]Pre-training Epoch 57:  26%|██▌       | 94/367 [00:00<00:01, 180.10it/s]Pre-training Epoch 57:  31%|███       | 113/367 [00:00<00:01, 169.99it/s]recon_loss: 0.028780357912182808, dist_loss: 0.6183305978775024
recon_loss: 0.02878023497760296, dist_loss: 0.45546862483024597
recon_loss: 0.028779728338122368, dist_loss: 0.3173637092113495
recon_loss: 0.028779715299606323, dist_loss: 0.4378640651702881
recon_loss: 0.02877972647547722, dist_loss: 0.48877865076065063
recon_loss: 0.028779955580830574, dist_loss: 0.4279709458351135
recon_loss: 0.02878018468618393, dist_loss: 0.5595510005950928
recon_loss: 0.02878021076321602, dist_loss: 0.6721856594085693
recon_loss: 0.028779935091733932, dist_loss: 0.7103112936019897
recon_loss: 0.02877957746386528, dist_loss: 1.2534258365631104
recon_loss: 0.028779475018382072, dist_loss: 0.7269059419631958
recon_loss: 0.02877894602715969, dist_loss: 0.8673084378242493
recon_loss: 0.028778979554772377, dist_loss: 0.8340574502944946
recon_loss: 0.028778713196516037, dist_loss: 0.8237335085868835
recon_loss: 0.0287784431129694, dist_loss: 0.41438984870910645
recon_loss: 0.02877875044941902, dist_loss: 0.6822893023490906
recon_loss: 0.028778664767742157, dist_loss: 0.7920628786087036
recon_loss: 0.028778547421097755, dist_loss: 0.7843537330627441
recon_loss: 0.028778377920389175, dist_loss: 1.1311430931091309
recon_loss: 0.028777966275811195, dist_loss: 0.7587836384773254
recon_loss: 0.028777938336133957, dist_loss: 0.5351167321205139
recon_loss: 0.028777970001101494, dist_loss: 0.9546453356742859
recon_loss: 0.02877751924097538, dist_loss: 0.7728380560874939
recon_loss: 0.028777888044714928, dist_loss: 0.6175023913383484
recon_loss: 0.028779296204447746, dist_loss: 0.4725547134876251
recon_loss: 0.02877824380993843, dist_loss: 0.7050966024398804
recon_loss: 0.0287786852568388, dist_loss: 0.653437077999115
recon_loss: 0.02877877466380596, dist_loss: 0.618053674697876
recon_loss: 0.028777511790394783, dist_loss: 0.5768568515777588
recon_loss: 0.028778480365872383, dist_loss: 0.5807909369468689
recon_loss: 0.02877803146839142, dist_loss: 0.8741742968559265
recon_loss: 0.02877751737833023, dist_loss: 0.4694373607635498
recon_loss: 0.028777863830327988, dist_loss: 0.6491582989692688
recon_loss: 0.028777582570910454, dist_loss: 0.4709729552268982
recon_loss: 0.02877636067569256, dist_loss: 0.6326853036880493
recon_loss: 0.02877693809568882, dist_loss: 1.0756362676620483
recon_loss: 0.028777360916137695, dist_loss: 0.6352867484092712
recon_loss: 0.028776301071047783, dist_loss: 0.57845538854599
recon_loss: 0.028777875006198883, dist_loss: 0.5802792906761169
recon_loss: 0.02877739444375038, dist_loss: 0.5879976749420166
recon_loss: 0.028776751831173897, dist_loss: 0.5574802160263062
recon_loss: 0.02877717837691307, dist_loss: 0.5078299045562744
recon_loss: 0.028776593506336212, dist_loss: 0.7407916784286499
recon_loss: 0.02877611480653286, dist_loss: 0.4999735355377197
recon_loss: 0.02877737395465374, dist_loss: 0.49535131454467773
recon_loss: 0.028776703402400017, dist_loss: 0.6400871276855469
recon_loss: 0.02877570316195488, dist_loss: 0.8840115070343018
recon_loss: 0.028776085004210472, dist_loss: 0.7402805685997009
recon_loss: 0.028776219114661217, dist_loss: 0.34906449913978577
recon_loss: 0.02877575159072876, dist_loss: 0.628862738609314
recon_loss: 0.028775719925761223, dist_loss: 0.7718901634216309
recon_loss: 0.028775567188858986, dist_loss: 0.7129737138748169
recon_loss: 0.028775567188858986, dist_loss: 0.8291075229644775
recon_loss: 0.02877560816705227, dist_loss: 0.7533757090568542
recon_loss: 0.02877543494105339, dist_loss: 0.6979309320449829
recon_loss: 0.028775908052921295, dist_loss: 0.6636935472488403
recon_loss: 0.02877652272582054, dist_loss: 0.7916274070739746
recon_loss: 0.028776947408914566, dist_loss: 0.9321708679199219
recon_loss: 0.0287762563675642, dist_loss: 0.8300298452377319
recon_loss: 0.028775880113244057, dist_loss: 0.5792924165725708
recon_loss: 0.028775710612535477, dist_loss: 0.5045891404151917
recon_loss: 0.028776001185178757, dist_loss: 0.5724914073944092
recon_loss: 0.02877608872950077, dist_loss: 1.0211195945739746
recon_loss: 0.02877553179860115, dist_loss: 0.28336817026138306
recon_loss: 0.02877541445195675, dist_loss: 0.49550795555114746
recon_loss: 0.028775224462151527, dist_loss: 0.6559261679649353
recon_loss: 0.028774557635188103, dist_loss: 0.8247309923171997
recon_loss: 0.028774073347449303, dist_loss: 0.33771422505378723
recon_loss: 0.028773842379450798, dist_loss: 0.8964031934738159
recon_loss: 0.02877364121377468, dist_loss: 0.29977357387542725
recon_loss: 0.028773603960871696, dist_loss: 0.5831340551376343
recon_loss: 0.02877359837293625, dist_loss: 0.4523864984512329
recon_loss: 0.028773559257388115, dist_loss: 0.3301222324371338
recon_loss: 0.028773661702871323, dist_loss: 0.893086314201355
recon_loss: 0.028773808851838112, dist_loss: 0.4586119055747986
recon_loss: 0.028773989528417587, dist_loss: 0.5542919635772705
recon_loss: 0.02877398207783699, dist_loss: 0.8691476583480835
recon_loss: 0.028773875907063484, dist_loss: 0.6264162063598633
recon_loss: 0.028773553669452667, dist_loss: 0.9373646378517151
recon_loss: 0.02877318486571312, dist_loss: 0.7909412384033203
recon_loss: 0.028772860765457153, dist_loss: 0.5190227031707764
recon_loss: 0.028772810474038124, dist_loss: 0.9561904668807983
recon_loss: 0.028773121535778046, dist_loss: 0.49483442306518555
recon_loss: 0.028773333877325058, dist_loss: 0.8185954093933105
recon_loss: 0.028774045407772064, dist_loss: 0.6460666656494141
recon_loss: 0.028774190694093704, dist_loss: 0.51343834400177
recon_loss: 0.028773413971066475, dist_loss: 0.5477983951568604
recon_loss: 0.028772929683327675, dist_loss: 0.6460769176483154
recon_loss: 0.02877277508378029, dist_loss: 1.2000689506530762
recon_loss: 0.02877286821603775, dist_loss: 0.5647196173667908
recon_loss: 0.028773365542292595, dist_loss: 0.726294755935669
recon_loss: 0.028772640973329544, dist_loss: 1.3128188848495483
recon_loss: 0.028771961107850075, dist_loss: 0.6366145610809326
recon_loss: 0.02877080626785755, dist_loss: 0.6568611860275269
recon_loss: 0.028770651668310165, dist_loss: 0.8175735473632812
recon_loss: 0.028771454468369484, dist_loss: 0.47287416458129883
recon_loss: 0.028771061450242996, dist_loss: 0.412858247756958
recon_loss: 0.028771456331014633, dist_loss: 0.6162487268447876
recon_loss: 0.028771325945854187, dist_loss: 0.6901059150695801
recon_loss: 0.028770726174116135, dist_loss: 0.6573532819747925
recon_loss: 0.028771400451660156, dist_loss: 0.5218469500541687
recon_loss: 0.028771687299013138, dist_loss: 0.5478030443191528
recon_loss: 0.028771301731467247, dist_loss: 1.005458116531372
recon_loss: 0.028771724551916122, dist_loss: 0.7958642244338989
recon_loss: 0.028771353885531425, dist_loss: 0.741919994354248
recon_loss: 0.028770659118890762, dist_loss: 0.7604254484176636
recon_loss: 0.028770066797733307, dist_loss: 0.6891564130783081
recon_loss: 0.02876974828541279, dist_loss: 0.43499475717544556
recon_loss: 0.028769854456186295, dist_loss: 0.8893705010414124
recon_loss: 0.02876996621489525, dist_loss: 0.60002601146698
recon_loss: 0.02877040207386017, dist_loss: 0.5680012702941895
recon_loss: 0.028770646080374718, dist_loss: 0.787932276725769
recon_loss: 0.028770804405212402, dist_loss: 0.7482362389564514
recon_loss: 0.028771478682756424, dist_loss: 0.4370219111442566
recon_loss: 0.02877279371023178, dist_loss: 0.6234428882598877
recon_loss: 0.028774302452802658, dist_loss: 0.7316904067993164
recon_loss: 0.02877586893737316, dist_loss: 1.0084044933319092
recon_loss: 0.028776729479432106, dist_loss: 0.47495803236961365
recon_loss: 0.02877715416252613, dist_loss: 1.0346322059631348
recon_loss: 0.028776658698916435, dist_loss: 0.4109691083431244
recon_loss: 0.028776174411177635, dist_loss: 0.8580328226089478
recon_loss: 0.0287749283015728, dist_loss: 0.9388365149497986
recon_loss: 0.028773685917258263, dist_loss: 1.4915134906768799
recon_loss: 0.028772801160812378, dist_loss: 0.4690600037574768
recon_loss: 0.02877209149301052, dist_loss: 0.7966843247413635
recon_loss: 0.02877150848507881, dist_loss: 0.5647258758544922
recon_loss: 0.028770988807082176, dist_loss: 1.0282697677612305
recon_loss: 0.0287698395550251, dist_loss: 0.5799728035926819
Pre-training Epoch 57:  36%|███▌      | 131/367 [00:00<00:01, 164.78it/s]Pre-training Epoch 57:  40%|████      | 148/367 [00:00<00:01, 159.12it/s]Pre-training Epoch 57:  45%|████▍     | 164/367 [00:00<00:01, 157.62it/s]Pre-training Epoch 57:  49%|████▉     | 180/367 [00:01<00:01, 156.65it/s]Pre-training Epoch 57:  53%|█████▎    | 196/367 [00:01<00:01, 155.94it/s]Pre-training Epoch 57:  58%|█████▊    | 212/367 [00:01<00:00, 155.40it/s]Pre-training Epoch 57:  62%|██████▏   | 228/367 [00:01<00:00, 155.05it/s]Pre-training Epoch 57:  66%|██████▋   | 244/367 [00:01<00:00, 156.15it/s]recon_loss: 0.02876902185380459, dist_loss: 0.8678677678108215
recon_loss: 0.02876870706677437, dist_loss: 0.8231337666511536
recon_loss: 0.028768453747034073, dist_loss: 0.3905598819255829
recon_loss: 0.028768975287675858, dist_loss: 0.6709607839584351
recon_loss: 0.02876889333128929, dist_loss: 0.5928699970245361
recon_loss: 0.02876870334148407, dist_loss: 0.979461133480072
recon_loss: 0.028769467025995255, dist_loss: 0.5597295165061951
recon_loss: 0.02876993641257286, dist_loss: 0.8308680057525635
recon_loss: 0.028771700337529182, dist_loss: 0.7429665923118591
recon_loss: 0.028773730620741844, dist_loss: 0.8628372550010681
recon_loss: 0.028775643557310104, dist_loss: 0.7719961404800415
recon_loss: 0.028777150437235832, dist_loss: 0.4225482642650604
recon_loss: 0.02877749688923359, dist_loss: 0.7351114153862
recon_loss: 0.02877727523446083, dist_loss: 0.5348562598228455
recon_loss: 0.02877667173743248, dist_loss: 0.6862264275550842
recon_loss: 0.028776127845048904, dist_loss: 0.5179515480995178
recon_loss: 0.02877531200647354, dist_loss: 0.5101209878921509
recon_loss: 0.028774412348866463, dist_loss: 0.9879109263420105
recon_loss: 0.028773287311196327, dist_loss: 0.5480503439903259
recon_loss: 0.02877207286655903, dist_loss: 0.5282270312309265
recon_loss: 0.028770707547664642, dist_loss: 0.5268186330795288
recon_loss: 0.028769494965672493, dist_loss: 0.704804539680481
recon_loss: 0.028768816962838173, dist_loss: 0.5521969199180603
recon_loss: 0.02876814641058445, dist_loss: 0.3078572154045105
recon_loss: 0.028767693787813187, dist_loss: 1.125699520111084
recon_loss: 0.028767196461558342, dist_loss: 0.8871312141418457
recon_loss: 0.028766872361302376, dist_loss: 0.455539345741272
recon_loss: 0.028766725212335587, dist_loss: 0.6304560303688049
recon_loss: 0.028766531497240067, dist_loss: 0.8969607353210449
recon_loss: 0.028766389936208725, dist_loss: 0.4894329011440277
recon_loss: 0.028766067698597908, dist_loss: 0.3705756664276123
recon_loss: 0.028765669092535973, dist_loss: 0.35220974683761597
recon_loss: 0.028765277937054634, dist_loss: 0.7326390743255615
recon_loss: 0.02876485511660576, dist_loss: 1.0363430976867676
recon_loss: 0.028764618560671806, dist_loss: 0.4794546067714691
recon_loss: 0.028764592483639717, dist_loss: 0.7391208410263062
recon_loss: 0.028765080496668816, dist_loss: 0.3354750871658325
recon_loss: 0.02876577526330948, dist_loss: 0.6414786577224731
recon_loss: 0.028765693306922913, dist_loss: 0.9054105281829834
recon_loss: 0.028765665367245674, dist_loss: 0.7240723967552185
recon_loss: 0.028764624148607254, dist_loss: 0.7028501033782959
recon_loss: 0.028764508664608, dist_loss: 0.7726972103118896
recon_loss: 0.028765017166733742, dist_loss: 0.4195505380630493
recon_loss: 0.0287648756057024, dist_loss: 0.8884649276733398
recon_loss: 0.028764642775058746, dist_loss: 0.5088675618171692
recon_loss: 0.02876449003815651, dist_loss: 0.7381548881530762
recon_loss: 0.028763463720679283, dist_loss: 0.9912301301956177
recon_loss: 0.02876390516757965, dist_loss: 0.4409865140914917
recon_loss: 0.02876434288918972, dist_loss: 1.0894248485565186
recon_loss: 0.02876472845673561, dist_loss: 0.7128536701202393
recon_loss: 0.028764881193637848, dist_loss: 0.4441697597503662
recon_loss: 0.02876490354537964, dist_loss: 0.5274597406387329
recon_loss: 0.028764763846993446, dist_loss: 0.560226321220398
recon_loss: 0.028764713555574417, dist_loss: 0.8139195442199707
recon_loss: 0.028764456510543823, dist_loss: 0.5137088894844055
recon_loss: 0.028763800859451294, dist_loss: 1.0345218181610107
recon_loss: 0.02876322716474533, dist_loss: 0.5028924942016602
recon_loss: 0.02876281552016735, dist_loss: 0.6423965692520142
recon_loss: 0.02876245230436325, dist_loss: 0.6347736120223999
recon_loss: 0.028762221336364746, dist_loss: 0.4935087561607361
recon_loss: 0.028761951252818108, dist_loss: 0.603399395942688
recon_loss: 0.028761738911271095, dist_loss: 0.9406734108924866
recon_loss: 0.02876160480082035, dist_loss: 1.1180903911590576
recon_loss: 0.028761599212884903, dist_loss: 0.7601364850997925
recon_loss: 0.028761474415659904, dist_loss: 0.4601793885231018
recon_loss: 0.028761573135852814, dist_loss: 0.6036999225616455
recon_loss: 0.02876127138733864, dist_loss: 0.597507655620575
recon_loss: 0.02876119129359722, dist_loss: 0.5531238317489624
recon_loss: 0.028761474415659904, dist_loss: 0.636038064956665
recon_loss: 0.028761407360434532, dist_loss: 0.5381003022193909
recon_loss: 0.028760919347405434, dist_loss: 0.38735347986221313
recon_loss: 0.02876085415482521, dist_loss: 0.6038765907287598
recon_loss: 0.028760554268956184, dist_loss: 0.5912496447563171
recon_loss: 0.02876049280166626, dist_loss: 0.70975661277771
recon_loss: 0.02876061387360096, dist_loss: 0.9311461448669434
recon_loss: 0.02876010723412037, dist_loss: 0.6048450469970703
recon_loss: 0.028760695829987526, dist_loss: 0.4433748126029968
recon_loss: 0.028760282322764397, dist_loss: 1.3391156196594238
recon_loss: 0.02875998429954052, dist_loss: 0.49483513832092285
recon_loss: 0.028760630637407303, dist_loss: 0.6964176893234253
recon_loss: 0.028760602697730064, dist_loss: 0.6136293411254883
recon_loss: 0.028760073706507683, dist_loss: 0.9597270488739014
recon_loss: 0.028759965673089027, dist_loss: 0.9289188385009766
recon_loss: 0.028759455308318138, dist_loss: 0.3145564794540405
recon_loss: 0.028759445995092392, dist_loss: 0.728420078754425
recon_loss: 0.02875996008515358, dist_loss: 0.8493018746376038
recon_loss: 0.028760133311152458, dist_loss: 0.4959535598754883
recon_loss: 0.02875971794128418, dist_loss: 0.5144148468971252
recon_loss: 0.028759878128767014, dist_loss: 0.3928886353969574
recon_loss: 0.028759609907865524, dist_loss: 0.36033639311790466
recon_loss: 0.028759479522705078, dist_loss: 0.46152815222740173
recon_loss: 0.028759727254509926, dist_loss: 0.49204719066619873
recon_loss: 0.0287597868591547, dist_loss: 0.4402724504470825
recon_loss: 0.028760114684700966, dist_loss: 0.8367506265640259
recon_loss: 0.02875993587076664, dist_loss: 0.2545124888420105
recon_loss: 0.028759945183992386, dist_loss: 0.7792654037475586
recon_loss: 0.028759727254509926, dist_loss: 0.7862657904624939
recon_loss: 0.028759030625224113, dist_loss: 0.6012450456619263
recon_loss: 0.028759008273482323, dist_loss: 0.4815073311328888
recon_loss: 0.02875865064561367, dist_loss: 0.9906588792800903
recon_loss: 0.028758255764842033, dist_loss: 0.737755298614502
recon_loss: 0.02875874936580658, dist_loss: 0.7808246612548828
recon_loss: 0.0287593062967062, dist_loss: 1.0086573362350464
recon_loss: 0.028759600594639778, dist_loss: 0.5681923627853394
recon_loss: 0.028760354965925217, dist_loss: 0.5536055564880371
recon_loss: 0.0287609975785017, dist_loss: 1.236029863357544
recon_loss: 0.02876155823469162, dist_loss: 0.7244395017623901
recon_loss: 0.02876248024404049, dist_loss: 0.501427412033081
recon_loss: 0.028763510286808014, dist_loss: 0.633631706237793
recon_loss: 0.02876373566687107, dist_loss: 0.6106364727020264
recon_loss: 0.028763314709067345, dist_loss: 0.798271656036377
recon_loss: 0.028762631118297577, dist_loss: 0.5011230707168579
recon_loss: 0.02876150608062744, dist_loss: 0.8115006685256958
recon_loss: 0.028760576620697975, dist_loss: 1.262256383895874
recon_loss: 0.02875986509025097, dist_loss: 0.5013187527656555
recon_loss: 0.028759008273482323, dist_loss: 0.5449371337890625
recon_loss: 0.02875848114490509, dist_loss: 0.842558741569519
recon_loss: 0.028758510947227478, dist_loss: 0.49725764989852905
recon_loss: 0.02875894494354725, dist_loss: 0.8866503238677979
recon_loss: 0.028759976848959923, dist_loss: 0.8309308290481567
recon_loss: 0.02876162901520729, dist_loss: 0.5491862297058105
recon_loss: 0.028763527050614357, dist_loss: 0.720435619354248
recon_loss: 0.028764871880412102, dist_loss: 0.7218974828720093
recon_loss: 0.028765665367245674, dist_loss: 0.6446139812469482
recon_loss: 0.02876611426472664, dist_loss: 0.34412139654159546
recon_loss: 0.028766140341758728, dist_loss: 1.0705933570861816
recon_loss: 0.02876611426472664, dist_loss: 0.7783981561660767
recon_loss: 0.028765935450792313, dist_loss: 0.40644025802612305
recon_loss: 0.028764955699443817, dist_loss: 0.7927967309951782
Pre-training Epoch 57:  71%|███████   | 260/367 [00:01<00:00, 155.85it/s]Pre-training Epoch 57:  75%|███████▌  | 276/367 [00:01<00:00, 155.38it/s]Pre-training Epoch 57:  80%|███████▉  | 292/367 [00:01<00:00, 154.98it/s]Pre-training Epoch 57:  84%|████████▍ | 310/367 [00:01<00:00, 161.27it/s]Pre-training Epoch 57:  90%|████████▉ | 330/367 [00:02<00:00, 170.36it/s]Pre-training Epoch 57:  95%|█████████▌| 350/367 [00:02<00:00, 176.74it/s]Pre-training Epoch 57: 100%|██████████| 367/367 [00:02<00:00, 165.91it/s]
recon_loss: 0.028763677924871445, dist_loss: 0.5606573820114136
recon_loss: 0.02876259945333004, dist_loss: 0.5632272958755493
recon_loss: 0.028761612251400948, dist_loss: 0.6853001117706299
recon_loss: 0.02876109629869461, dist_loss: 0.7337570190429688
recon_loss: 0.028760602697730064, dist_loss: 0.5434295535087585
recon_loss: 0.028759900480508804, dist_loss: 0.36152464151382446
recon_loss: 0.028758853673934937, dist_loss: 0.5462363958358765
recon_loss: 0.02875763736665249, dist_loss: 0.6931889057159424
recon_loss: 0.02875709906220436, dist_loss: 1.2453699111938477
recon_loss: 0.028756894171237946, dist_loss: 0.8266880512237549
recon_loss: 0.02875630557537079, dist_loss: 0.49310046434402466
recon_loss: 0.02875613607466221, dist_loss: 1.0041359663009644
recon_loss: 0.02875596471130848, dist_loss: 0.44251132011413574
recon_loss: 0.028755828738212585, dist_loss: 0.4497443437576294
recon_loss: 0.028756096959114075, dist_loss: 0.5898959040641785
recon_loss: 0.028756072744727135, dist_loss: 0.44277510046958923
recon_loss: 0.02875577285885811, dist_loss: 1.1637704372406006
recon_loss: 0.02875564433634281, dist_loss: 0.6318175792694092
recon_loss: 0.028755828738212585, dist_loss: 0.716869592666626
recon_loss: 0.028756113722920418, dist_loss: 0.7848204374313354
recon_loss: 0.02875646948814392, dist_loss: 0.7107360363006592
recon_loss: 0.02875666506588459, dist_loss: 0.6902818083763123
recon_loss: 0.02875724993646145, dist_loss: 0.44631338119506836
recon_loss: 0.02875748835504055, dist_loss: 0.43301117420196533
recon_loss: 0.028756793588399887, dist_loss: 0.775093138217926
recon_loss: 0.0287562794983387, dist_loss: 0.4564937949180603
recon_loss: 0.028755974024534225, dist_loss: 0.8936499357223511
recon_loss: 0.0287556704133749, dist_loss: 0.3792378306388855
recon_loss: 0.028755268082022667, dist_loss: 0.4995379149913788
recon_loss: 0.028754953294992447, dist_loss: 0.7605078816413879
recon_loss: 0.028754672035574913, dist_loss: 0.7329768538475037
recon_loss: 0.028753899037837982, dist_loss: 0.9097023606300354
recon_loss: 0.028753288090229034, dist_loss: 0.5015859007835388
recon_loss: 0.028753576800227165, dist_loss: 0.9995687007904053
recon_loss: 0.02875455468893051, dist_loss: 0.9076746702194214
recon_loss: 0.028754491358995438, dist_loss: 0.4825059175491333
recon_loss: 0.02875521406531334, dist_loss: 0.679415225982666
recon_loss: 0.02875506319105625, dist_loss: 0.6998783946037292
recon_loss: 0.028753813356161118, dist_loss: 0.8520418405532837
recon_loss: 0.028753789141774178, dist_loss: 0.9578171372413635
recon_loss: 0.02875281684100628, dist_loss: 0.7085227966308594
recon_loss: 0.028752652928233147, dist_loss: 0.3488977253437042
recon_loss: 0.028752896934747696, dist_loss: 0.7047110199928284
recon_loss: 0.028752503916621208, dist_loss: 0.5469204187393188
recon_loss: 0.028752541169524193, dist_loss: 0.6198293566703796
recon_loss: 0.02875232882797718, dist_loss: 0.9545415639877319
recon_loss: 0.028751850128173828, dist_loss: 0.44204413890838623
recon_loss: 0.028752434998750687, dist_loss: 0.4991530776023865
recon_loss: 0.028752347454428673, dist_loss: 0.5296710133552551
recon_loss: 0.028752664104104042, dist_loss: 0.8151662349700928
recon_loss: 0.028752969577908516, dist_loss: 0.6178802251815796
recon_loss: 0.02875276282429695, dist_loss: 0.44554710388183594
recon_loss: 0.028753308579325676, dist_loss: 0.5156954526901245
recon_loss: 0.028754200786352158, dist_loss: 0.7690376043319702
recon_loss: 0.028753798454999924, dist_loss: 0.3220941722393036
recon_loss: 0.028754688799381256, dist_loss: 0.6591182947158813
recon_loss: 0.028755221515893936, dist_loss: 0.7199512720108032
recon_loss: 0.028754152357578278, dist_loss: 0.5404071807861328
recon_loss: 0.028753342106938362, dist_loss: 0.47467485070228577
recon_loss: 0.02875337190926075, dist_loss: 0.9155676364898682
recon_loss: 0.02875194512307644, dist_loss: 0.8832218647003174
recon_loss: 0.028751656413078308, dist_loss: 0.5957595705986023
recon_loss: 0.02875145524740219, dist_loss: 0.6842642426490784
recon_loss: 0.02875014767050743, dist_loss: 0.5235517621040344
recon_loss: 0.028750332072377205, dist_loss: 0.6953684687614441
recon_loss: 0.028751099482178688, dist_loss: 0.48248714208602905
recon_loss: 0.028751667588949203, dist_loss: 0.6509236097335815
recon_loss: 0.028753360733389854, dist_loss: 0.40693724155426025
recon_loss: 0.02875540219247341, dist_loss: 0.8005795478820801
recon_loss: 0.0287556741386652, dist_loss: 0.7101412415504456
recon_loss: 0.028756696730852127, dist_loss: 0.8973752856254578
recon_loss: 0.02875594235956669, dist_loss: 0.5513437986373901
recon_loss: 0.02875584177672863, dist_loss: 0.39424341917037964
recon_loss: 0.028755735605955124, dist_loss: 0.7487270832061768
recon_loss: 0.028754808008670807, dist_loss: 0.7519725561141968
recon_loss: 0.02875456213951111, dist_loss: 0.5738844275474548
recon_loss: 0.028752928599715233, dist_loss: 0.6936022639274597
recon_loss: 0.028751304373145103, dist_loss: 1.0366477966308594
recon_loss: 0.028750324621796608, dist_loss: 0.3729046583175659
recon_loss: 0.028749709948897362, dist_loss: 0.7364828586578369
recon_loss: 0.028749311342835426, dist_loss: 0.6808609366416931
recon_loss: 0.028749244287610054, dist_loss: 0.4872433841228485
recon_loss: 0.028749382123351097, dist_loss: 0.8317496180534363
recon_loss: 0.02874971367418766, dist_loss: 0.9531798362731934
recon_loss: 0.028749724850058556, dist_loss: 0.6608699560165405
recon_loss: 0.028749573975801468, dist_loss: 0.5548679828643799
recon_loss: 0.02874903194606304, dist_loss: 0.4827914834022522
recon_loss: 0.02874884381890297, dist_loss: 0.6070573329925537
recon_loss: 0.028748497366905212, dist_loss: 0.9226885437965393
recon_loss: 0.02874784544110298, dist_loss: 0.44333547353744507
recon_loss: 0.02874785102903843, dist_loss: 0.9333435297012329
recon_loss: 0.02874797023832798, dist_loss: 0.34496378898620605
recon_loss: 0.028748344630002975, dist_loss: 0.4982176423072815
recon_loss: 0.02874832972884178, dist_loss: 0.6125351190567017
recon_loss: 0.028748266398906708, dist_loss: 0.6068203449249268
recon_loss: 0.028747867792844772, dist_loss: 0.5874531269073486
recon_loss: 0.028747646138072014, dist_loss: 0.887425422668457
recon_loss: 0.028747817501425743, dist_loss: 0.688213050365448
recon_loss: 0.0287478007376194, dist_loss: 0.48405301570892334
recon_loss: 0.02874804101884365, dist_loss: 0.4140835404396057
recon_loss: 0.028747672215104103, dist_loss: 0.758088231086731
recon_loss: 0.028747212141752243, dist_loss: 0.563904881477356
recon_loss: 0.028746971860527992, dist_loss: 0.40703731775283813
recon_loss: 0.028746506199240685, dist_loss: 0.9554681777954102
recon_loss: 0.028746746480464935, dist_loss: 0.4944835901260376
recon_loss: 0.02874673716723919, dist_loss: 0.6154223680496216
recon_loss: 0.02874634973704815, dist_loss: 1.112744688987732
recon_loss: 0.028746912255883217, dist_loss: 0.7747955918312073
recon_loss: 0.028746092692017555, dist_loss: 0.5037674307823181
recon_loss: 0.028745757415890694, dist_loss: 0.5925585627555847
Pre-training Epoch 58:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 58:   5%|▍         | 18/367 [00:00<00:01, 177.05it/s]Pre-training Epoch 58:  10%|▉         | 36/367 [00:00<00:02, 159.74it/s]Pre-training Epoch 58:  14%|█▍        | 53/367 [00:00<00:01, 158.70it/s]Pre-training Epoch 58:  19%|█▉        | 70/367 [00:00<00:01, 160.51it/s]Pre-training Epoch 58:  24%|██▍       | 88/367 [00:00<00:01, 165.43it/s]Pre-training Epoch 58:  29%|██▉       | 106/367 [00:00<00:01, 167.24it/s]Pre-training Epoch 58:  34%|███▎      | 123/367 [00:00<00:01, 167.53it/s]recon_loss: 0.028745749965310097, dist_loss: 0.4920911490917206
recon_loss: 0.0287455003708601, dist_loss: 0.5704827308654785
recon_loss: 0.02874545007944107, dist_loss: 0.7624097466468811
recon_loss: 0.028745807707309723, dist_loss: 1.1344454288482666
recon_loss: 0.028745196759700775, dist_loss: 0.6043945550918579
recon_loss: 0.028745152056217194, dist_loss: 0.508858859539032
recon_loss: 0.028744690120220184, dist_loss: 0.5916171073913574
recon_loss: 0.028744595125317574, dist_loss: 0.8287721872329712
recon_loss: 0.028744827955961227, dist_loss: 0.8323585987091064
recon_loss: 0.02874429151415825, dist_loss: 0.639650821685791
recon_loss: 0.028744321316480637, dist_loss: 0.471729576587677
recon_loss: 0.028744488954544067, dist_loss: 0.46217596530914307
recon_loss: 0.028743993490934372, dist_loss: 0.5879083871841431
recon_loss: 0.02874414436519146, dist_loss: 0.6293955445289612
recon_loss: 0.028744017705321312, dist_loss: 0.7467355728149414
recon_loss: 0.028743786737322807, dist_loss: 0.4736090302467346
recon_loss: 0.028744520619511604, dist_loss: 0.47765401005744934
recon_loss: 0.028743954375386238, dist_loss: 0.4379981756210327
recon_loss: 0.028743375092744827, dist_loss: 0.7767099738121033
recon_loss: 0.028744114562869072, dist_loss: 0.9142196178436279
recon_loss: 0.02874327078461647, dist_loss: 0.5102057456970215
recon_loss: 0.028743207454681396, dist_loss: 0.8800315260887146
recon_loss: 0.028743209317326546, dist_loss: 0.6856904029846191
recon_loss: 0.028742769733071327, dist_loss: 0.508404552936554
recon_loss: 0.028742896392941475, dist_loss: 0.37990230321884155
recon_loss: 0.02874271385371685, dist_loss: 0.6692642569541931
recon_loss: 0.02874278649687767, dist_loss: 0.43270134925842285
recon_loss: 0.02874268777668476, dist_loss: 0.46466249227523804
recon_loss: 0.0287424698472023, dist_loss: 0.3782464563846588
recon_loss: 0.02874249964952469, dist_loss: 0.9279317855834961
recon_loss: 0.028742510825395584, dist_loss: 0.7177974581718445
recon_loss: 0.02874230034649372, dist_loss: 0.5773309469223022
recon_loss: 0.028742387890815735, dist_loss: 0.5880229473114014
recon_loss: 0.028742335736751556, dist_loss: 0.6072646975517273
recon_loss: 0.028742285445332527, dist_loss: 0.6469346284866333
recon_loss: 0.028742628172039986, dist_loss: 0.715829074382782
recon_loss: 0.028741953894495964, dist_loss: 0.5403125286102295
recon_loss: 0.02874237671494484, dist_loss: 0.3826807737350464
recon_loss: 0.028742831200361252, dist_loss: 0.682896614074707
recon_loss: 0.02874239906668663, dist_loss: 1.0988593101501465
recon_loss: 0.028743302449584007, dist_loss: 0.502415657043457
recon_loss: 0.02874305099248886, dist_loss: 0.5269575119018555
recon_loss: 0.028742725029587746, dist_loss: 0.6180999279022217
recon_loss: 0.028742941096425056, dist_loss: 0.9718621373176575
recon_loss: 0.028742456808686256, dist_loss: 0.5809757113456726
recon_loss: 0.028742585331201553, dist_loss: 0.7931004762649536
recon_loss: 0.028742775321006775, dist_loss: 0.3914451599121094
recon_loss: 0.028741972520947456, dist_loss: 0.8030314445495605
recon_loss: 0.028741853311657906, dist_loss: 0.7822890877723694
recon_loss: 0.028741605579853058, dist_loss: 0.7386718988418579
recon_loss: 0.028741618618369102, dist_loss: 0.458335280418396
recon_loss: 0.0287418682128191, dist_loss: 0.3253260850906372
recon_loss: 0.028742190450429916, dist_loss: 0.48926499485969543
recon_loss: 0.028741756454110146, dist_loss: 0.446846067905426
recon_loss: 0.028741121292114258, dist_loss: 0.4362058639526367
recon_loss: 0.028740931302309036, dist_loss: 0.6239860653877258
recon_loss: 0.02874041348695755, dist_loss: 0.5776913166046143
recon_loss: 0.028740311041474342, dist_loss: 0.8245691657066345
recon_loss: 0.028740383684635162, dist_loss: 0.8443254232406616
recon_loss: 0.02874038740992546, dist_loss: 0.8515924215316772
recon_loss: 0.028740666806697845, dist_loss: 0.933376669883728
recon_loss: 0.028740743175148964, dist_loss: 0.6131473779678345
recon_loss: 0.028740758076310158, dist_loss: 0.5165286064147949
recon_loss: 0.02874111570417881, dist_loss: 0.7690377235412598
recon_loss: 0.028740812093019485, dist_loss: 0.5395358204841614
recon_loss: 0.028740689158439636, dist_loss: 1.452153205871582
recon_loss: 0.02874040976166725, dist_loss: 0.6285192966461182
recon_loss: 0.028740141540765762, dist_loss: 0.6490568518638611
recon_loss: 0.02873990498483181, dist_loss: 0.8532686233520508
recon_loss: 0.028739456087350845, dist_loss: 0.7778866291046143
recon_loss: 0.028739044442772865, dist_loss: 0.7598517537117004
recon_loss: 0.028738947585225105, dist_loss: 1.6428143978118896
recon_loss: 0.02873878739774227, dist_loss: 0.5759778618812561
recon_loss: 0.028738634660840034, dist_loss: 0.5944520235061646
recon_loss: 0.028738640248775482, dist_loss: 0.8659230470657349
recon_loss: 0.028738558292388916, dist_loss: 0.6993729472160339
recon_loss: 0.028738798573613167, dist_loss: 0.7594196796417236
recon_loss: 0.028738781809806824, dist_loss: 0.5965440273284912
recon_loss: 0.028738610446453094, dist_loss: 0.6854854822158813
recon_loss: 0.028738316148519516, dist_loss: 0.7100481986999512
recon_loss: 0.028737971559166908, dist_loss: 0.8535274267196655
recon_loss: 0.02873786725103855, dist_loss: 0.6231104731559753
recon_loss: 0.028737647458910942, dist_loss: 0.5060551166534424
recon_loss: 0.028737640008330345, dist_loss: 0.6805009841918945
recon_loss: 0.028737442567944527, dist_loss: 0.6469200849533081
recon_loss: 0.028737422078847885, dist_loss: 0.7479141354560852
recon_loss: 0.02873764932155609, dist_loss: 1.312301516532898
recon_loss: 0.028737377375364304, dist_loss: 0.5316081047058105
recon_loss: 0.028737707063555717, dist_loss: 0.4282987713813782
recon_loss: 0.02873779647052288, dist_loss: 0.4424840807914734
recon_loss: 0.028737572953104973, dist_loss: 0.4376055598258972
recon_loss: 0.028737779706716537, dist_loss: 0.8144145011901855
recon_loss: 0.028738347813487053, dist_loss: 0.5101209878921509
recon_loss: 0.028738148510456085, dist_loss: 0.5099066495895386
recon_loss: 0.028738735243678093, dist_loss: 0.39358341693878174
recon_loss: 0.028738580644130707, dist_loss: 0.6772936582565308
recon_loss: 0.028738223016262054, dist_loss: 1.0111451148986816
recon_loss: 0.028738366439938545, dist_loss: 0.4058547019958496
recon_loss: 0.02873743139207363, dist_loss: 0.5234619975090027
recon_loss: 0.02873779833316803, dist_loss: 0.7210584878921509
recon_loss: 0.02873779833316803, dist_loss: 0.5334213972091675
recon_loss: 0.028736818581819534, dist_loss: 0.5385648012161255
recon_loss: 0.028737541288137436, dist_loss: 0.6761460304260254
recon_loss: 0.028736334294080734, dist_loss: 0.7268245816230774
recon_loss: 0.028736228123307228, dist_loss: 0.44756776094436646
recon_loss: 0.028737084940075874, dist_loss: 0.6098560094833374
recon_loss: 0.028736425563693047, dist_loss: 0.9601678848266602
recon_loss: 0.028736824169754982, dist_loss: 0.6700435280799866
recon_loss: 0.028737643733620644, dist_loss: 1.0423381328582764
recon_loss: 0.0287362989038229, dist_loss: 0.5286195278167725
recon_loss: 0.028736187145113945, dist_loss: 0.39976730942726135
recon_loss: 0.028735574334859848, dist_loss: 0.7205731868743896
recon_loss: 0.02873608097434044, dist_loss: 0.8096113204956055
recon_loss: 0.02873791754245758, dist_loss: 0.40199950337409973
recon_loss: 0.02873903512954712, dist_loss: 0.6388124227523804
recon_loss: 0.02873942442238331, dist_loss: 0.65762859582901
recon_loss: 0.02873910404741764, dist_loss: 0.5495809316635132
recon_loss: 0.02873772569000721, dist_loss: 0.7661617398262024
recon_loss: 0.02873762883245945, dist_loss: 0.513763427734375
recon_loss: 0.028737850487232208, dist_loss: 0.5960643291473389
recon_loss: 0.02873796410858631, dist_loss: 0.6768302321434021
recon_loss: 0.028738001361489296, dist_loss: 0.5279297828674316
recon_loss: 0.028736958280205727, dist_loss: 0.6643030643463135
recon_loss: 0.028735730797052383, dist_loss: 0.8747631311416626
recon_loss: 0.02873493731021881, dist_loss: 0.3615664839744568
recon_loss: 0.028734713792800903, dist_loss: 0.4371376931667328
recon_loss: 0.028734909370541573, dist_loss: 0.5032001733779907
recon_loss: 0.028735239058732986, dist_loss: 0.7336183786392212
Pre-training Epoch 58:  38%|███▊      | 141/367 [00:00<00:01, 168.63it/s]Pre-training Epoch 58:  43%|████▎     | 158/367 [00:00<00:01, 167.35it/s]Pre-training Epoch 58:  48%|████▊     | 176/367 [00:01<00:01, 170.34it/s]Pre-training Epoch 58:  53%|█████▎    | 194/367 [00:01<00:01, 163.26it/s]Pre-training Epoch 58:  57%|█████▋    | 211/367 [00:01<00:00, 159.44it/s]Pre-training Epoch 58:  62%|██████▏   | 228/367 [00:01<00:00, 157.99it/s]Pre-training Epoch 58:  66%|██████▋   | 244/367 [00:01<00:00, 158.41it/s]recon_loss: 0.028735345229506493, dist_loss: 0.7285158038139343
recon_loss: 0.028734784573316574, dist_loss: 0.29885733127593994
recon_loss: 0.028733940795063972, dist_loss: 1.013782262802124
recon_loss: 0.028733553364872932, dist_loss: 0.6899014115333557
recon_loss: 0.028734857216477394, dist_loss: 0.7030119895935059
recon_loss: 0.028737438842654228, dist_loss: 1.0713632106781006
recon_loss: 0.028740564361214638, dist_loss: 0.5141217708587646
recon_loss: 0.028740961104631424, dist_loss: 0.805817723274231
recon_loss: 0.028740568086504936, dist_loss: 0.24525979161262512
recon_loss: 0.028740160167217255, dist_loss: 1.0250000953674316
recon_loss: 0.028740186244249344, dist_loss: 0.6733871102333069
recon_loss: 0.028741905465722084, dist_loss: 0.9423401355743408
recon_loss: 0.02874315343797207, dist_loss: 0.49096304178237915
recon_loss: 0.028743550181388855, dist_loss: 0.7080898284912109
recon_loss: 0.028743037953972816, dist_loss: 0.6111716032028198
recon_loss: 0.028741516172885895, dist_loss: 0.9252512454986572
recon_loss: 0.0287396851927042, dist_loss: 0.8817480802536011
recon_loss: 0.02873801253736019, dist_loss: 0.9342247843742371
recon_loss: 0.028736839070916176, dist_loss: 1.0114426612854004
recon_loss: 0.028736067935824394, dist_loss: 0.34993159770965576
recon_loss: 0.028735676780343056, dist_loss: 0.6936589479446411
recon_loss: 0.028735388070344925, dist_loss: 0.4985972046852112
recon_loss: 0.02873499132692814, dist_loss: 0.3793879747390747
recon_loss: 0.02873518131673336, dist_loss: 0.3927537798881531
recon_loss: 0.02873528189957142, dist_loss: 0.760708749294281
recon_loss: 0.028735214844346046, dist_loss: 0.6962560415267944
recon_loss: 0.028734855353832245, dist_loss: 0.44427192211151123
recon_loss: 0.028734710067510605, dist_loss: 0.5330095291137695
recon_loss: 0.02873469702899456, dist_loss: 0.9741458892822266
recon_loss: 0.02873498573899269, dist_loss: 0.4753022789955139
recon_loss: 0.02873510867357254, dist_loss: 0.6225879192352295
recon_loss: 0.028735514730215073, dist_loss: 0.5577150583267212
recon_loss: 0.028736194595694542, dist_loss: 0.7713240385055542
recon_loss: 0.028736915439367294, dist_loss: 0.5826752185821533
recon_loss: 0.028736844658851624, dist_loss: 0.4667899012565613
recon_loss: 0.028736263513565063, dist_loss: 0.7004599571228027
recon_loss: 0.028736017644405365, dist_loss: 0.4905190169811249
recon_loss: 0.02873706817626953, dist_loss: 0.750719428062439
recon_loss: 0.028736503794789314, dist_loss: 0.7648355960845947
recon_loss: 0.02873714454472065, dist_loss: 0.6316139698028564
recon_loss: 0.028737271204590797, dist_loss: 0.34034350514411926
recon_loss: 0.028735801577568054, dist_loss: 1.2031915187835693
recon_loss: 0.028735728934407234, dist_loss: 0.7500327825546265
recon_loss: 0.028734853491187096, dist_loss: 0.8023721575737
recon_loss: 0.028733545914292336, dist_loss: 0.41263478994369507
recon_loss: 0.028734097257256508, dist_loss: 0.5351232290267944
recon_loss: 0.028733596205711365, dist_loss: 0.8566471338272095
recon_loss: 0.02873246744275093, dist_loss: 0.4580884873867035
recon_loss: 0.02873270958662033, dist_loss: 1.056510329246521
recon_loss: 0.028732944279909134, dist_loss: 0.6197160482406616
recon_loss: 0.028732340782880783, dist_loss: 0.520920991897583
recon_loss: 0.028732838109135628, dist_loss: 0.47304338216781616
recon_loss: 0.02873373031616211, dist_loss: 0.5865445733070374
recon_loss: 0.02873362973332405, dist_loss: 0.6801590919494629
recon_loss: 0.0287348460406065, dist_loss: 0.9360759854316711
recon_loss: 0.028734752908349037, dist_loss: 0.7512937784194946
recon_loss: 0.02873571217060089, dist_loss: 0.6055763959884644
recon_loss: 0.028736520558595657, dist_loss: 0.4617924690246582
recon_loss: 0.028737209737300873, dist_loss: 1.0281790494918823
recon_loss: 0.028738006949424744, dist_loss: 0.40567052364349365
recon_loss: 0.02873811684548855, dist_loss: 0.5276792645454407
recon_loss: 0.028737738728523254, dist_loss: 0.8306875228881836
recon_loss: 0.028738562017679214, dist_loss: 0.4719346761703491
recon_loss: 0.028737949207425117, dist_loss: 0.48760396242141724
recon_loss: 0.02873721532523632, dist_loss: 0.6834927797317505
recon_loss: 0.028736887499690056, dist_loss: 0.7074233293533325
recon_loss: 0.028735782951116562, dist_loss: 1.2496891021728516
recon_loss: 0.02873583696782589, dist_loss: 0.8445026278495789
recon_loss: 0.028735613450407982, dist_loss: 0.971219003200531
recon_loss: 0.02873518504202366, dist_loss: 0.7506966590881348
recon_loss: 0.028735991567373276, dist_loss: 0.7974720001220703
recon_loss: 0.02873559668660164, dist_loss: 0.5532417297363281
recon_loss: 0.02873530611395836, dist_loss: 0.8510534763336182
recon_loss: 0.02873634733259678, dist_loss: 0.6936818957328796
recon_loss: 0.028734780848026276, dist_loss: 0.575726330280304
recon_loss: 0.028734855353832245, dist_loss: 0.6379739046096802
recon_loss: 0.028734911233186722, dist_loss: 0.7028137445449829
recon_loss: 0.028733419254422188, dist_loss: 0.6183117032051086
recon_loss: 0.028732268139719963, dist_loss: 0.40328913927078247
recon_loss: 0.02873210236430168, dist_loss: 0.43414559960365295
recon_loss: 0.02873104438185692, dist_loss: 1.0680210590362549
recon_loss: 0.02873176336288452, dist_loss: 0.5848442316055298
recon_loss: 0.028731822967529297, dist_loss: 0.8435109853744507
recon_loss: 0.02873157523572445, dist_loss: 0.8659031987190247
recon_loss: 0.02873355522751808, dist_loss: 0.5248169898986816
recon_loss: 0.028734911233186722, dist_loss: 0.9291567802429199
recon_loss: 0.02873622439801693, dist_loss: 0.8114156126976013
recon_loss: 0.02873879298567772, dist_loss: 0.6696761846542358
recon_loss: 0.02873937599360943, dist_loss: 0.49263280630111694
recon_loss: 0.028739329427480698, dist_loss: 0.7191328406333923
recon_loss: 0.028740765526890755, dist_loss: 0.439574658870697
recon_loss: 0.028740394860506058, dist_loss: 0.6743912696838379
recon_loss: 0.028739240020513535, dist_loss: 0.6698266863822937
recon_loss: 0.02874041348695755, dist_loss: 0.5163899064064026
recon_loss: 0.028739064931869507, dist_loss: 0.7130458354949951
recon_loss: 0.028738131746649742, dist_loss: 0.7200808525085449
recon_loss: 0.028737226501107216, dist_loss: 0.5632140636444092
recon_loss: 0.028734587132930756, dist_loss: 0.5341637134552002
recon_loss: 0.028734471648931503, dist_loss: 1.1726021766662598
recon_loss: 0.028732234612107277, dist_loss: 0.6207025051116943
recon_loss: 0.02873074822127819, dist_loss: 0.46936559677124023
recon_loss: 0.02873019129037857, dist_loss: 0.4019339978694916
recon_loss: 0.028728248551487923, dist_loss: 0.6084557175636292
recon_loss: 0.02872777171432972, dist_loss: 0.3456449508666992
recon_loss: 0.02872772328555584, dist_loss: 0.5759456157684326
recon_loss: 0.028727596625685692, dist_loss: 0.6666099429130554
recon_loss: 0.028727881610393524, dist_loss: 0.5677012205123901
recon_loss: 0.02872876450419426, dist_loss: 0.8640207052230835
recon_loss: 0.02872975915670395, dist_loss: 0.6464430093765259
recon_loss: 0.0287312101572752, dist_loss: 0.5140150189399719
recon_loss: 0.0287316907197237, dist_loss: 0.5445199012756348
recon_loss: 0.02873179502785206, dist_loss: 0.629479169845581
recon_loss: 0.0287321824580431, dist_loss: 0.5793224573135376
recon_loss: 0.028731368482112885, dist_loss: 0.48505699634552
recon_loss: 0.028730405494570732, dist_loss: 0.7841124534606934
recon_loss: 0.028730133548378944, dist_loss: 0.797085165977478
recon_loss: 0.028729049488902092, dist_loss: 0.5572643876075745
recon_loss: 0.028727715834975243, dist_loss: 0.4642268717288971
recon_loss: 0.028727471828460693, dist_loss: 1.442344307899475
recon_loss: 0.02872675098478794, dist_loss: 0.6212642192840576
recon_loss: 0.028726471588015556, dist_loss: 0.5597774982452393
recon_loss: 0.02872728556394577, dist_loss: 0.5776124000549316
recon_loss: 0.028727829456329346, dist_loss: 0.4218960404396057
recon_loss: 0.02872847206890583, dist_loss: 0.3922009766101837
recon_loss: 0.028729528188705444, dist_loss: 0.562844455242157
recon_loss: 0.028729917481541634, dist_loss: 0.5207012891769409
recon_loss: 0.028729679062962532, dist_loss: 1.5017664432525635
recon_loss: 0.028729679062962532, dist_loss: 0.8192275762557983
Pre-training Epoch 58:  71%|███████   | 261/367 [00:01<00:00, 160.52it/s]Pre-training Epoch 58:  76%|███████▌  | 278/367 [00:01<00:00, 162.05it/s]Pre-training Epoch 58:  80%|████████  | 295/367 [00:01<00:00, 163.06it/s]Pre-training Epoch 58:  85%|████████▌ | 312/367 [00:01<00:00, 163.58it/s]Pre-training Epoch 58:  90%|████████▉ | 329/367 [00:02<00:00, 163.82it/s]Pre-training Epoch 58:  94%|█████████▍| 346/367 [00:02<00:00, 161.26it/s]Pre-training Epoch 58:  99%|█████████▉| 363/367 [00:02<00:00, 158.30it/s]Pre-training Epoch 58: 100%|██████████| 367/367 [00:02<00:00, 162.54it/s]
recon_loss: 0.0287284255027771, dist_loss: 0.7022814154624939
recon_loss: 0.028727620840072632, dist_loss: 0.42116713523864746
recon_loss: 0.028726141899824142, dist_loss: 0.471922904253006
recon_loss: 0.02872479520738125, dist_loss: 0.7031407356262207
recon_loss: 0.028724025934934616, dist_loss: 0.5069031715393066
recon_loss: 0.02872353047132492, dist_loss: 0.7701606750488281
recon_loss: 0.02872316911816597, dist_loss: 0.5652866363525391
recon_loss: 0.02872261218726635, dist_loss: 1.0710139274597168
recon_loss: 0.028721870854496956, dist_loss: 0.7796257138252258
recon_loss: 0.028721731156110764, dist_loss: 0.4708611071109772
recon_loss: 0.028721638023853302, dist_loss: 0.522113025188446
recon_loss: 0.028721511363983154, dist_loss: 0.7427828907966614
recon_loss: 0.028721235692501068, dist_loss: 1.111482858657837
recon_loss: 0.0287210363894701, dist_loss: 0.4891376495361328
recon_loss: 0.028720807284116745, dist_loss: 0.47800979018211365
recon_loss: 0.02872067131102085, dist_loss: 0.3280227482318878
recon_loss: 0.028720375150442123, dist_loss: 0.8005775213241577
recon_loss: 0.028720790520310402, dist_loss: 0.47326821088790894
recon_loss: 0.028720835223793983, dist_loss: 0.6429222822189331
recon_loss: 0.028720296919345856, dist_loss: 0.6285662651062012
recon_loss: 0.028720302507281303, dist_loss: 0.8013781309127808
recon_loss: 0.02872014231979847, dist_loss: 0.7422380447387695
recon_loss: 0.02872021496295929, dist_loss: 0.6979950666427612
recon_loss: 0.028720028698444366, dist_loss: 0.5572761297225952
recon_loss: 0.028719725087285042, dist_loss: 0.9802961945533752
recon_loss: 0.028719967231154442, dist_loss: 0.8173845410346985
recon_loss: 0.028719980269670486, dist_loss: 0.710787296295166
recon_loss: 0.028719551861286163, dist_loss: 0.7862991094589233
recon_loss: 0.02871965430676937, dist_loss: 0.6789734363555908
recon_loss: 0.028719810768961906, dist_loss: 1.0247434377670288
recon_loss: 0.028719862923026085, dist_loss: 0.568286657333374
recon_loss: 0.028720201924443245, dist_loss: 1.0845203399658203
recon_loss: 0.02872036211192608, dist_loss: 0.36976003646850586
recon_loss: 0.02872040681540966, dist_loss: 0.89061439037323
recon_loss: 0.028720635920763016, dist_loss: 0.7028849124908447
recon_loss: 0.028720473870635033, dist_loss: 0.49034327268600464
recon_loss: 0.02872013859450817, dist_loss: 0.6044338941574097
recon_loss: 0.02871978096663952, dist_loss: 0.47208958864212036
recon_loss: 0.02871936373412609, dist_loss: 0.420324444770813
recon_loss: 0.028718912973999977, dist_loss: 0.6031538844108582
recon_loss: 0.02871863543987274, dist_loss: 0.5916330218315125
recon_loss: 0.02871827967464924, dist_loss: 0.9020049571990967
recon_loss: 0.028717877343297005, dist_loss: 0.6305696368217468
recon_loss: 0.028717616572976112, dist_loss: 0.9389822483062744
recon_loss: 0.028717610985040665, dist_loss: 0.4293535351753235
recon_loss: 0.02871706336736679, dist_loss: 0.5010426044464111
recon_loss: 0.028716865926980972, dist_loss: 0.3593439757823944
recon_loss: 0.028716744855046272, dist_loss: 0.9229705333709717
recon_loss: 0.028716593980789185, dist_loss: 0.32046133279800415
recon_loss: 0.02871658094227314, dist_loss: 0.4742407500743866
recon_loss: 0.02871650829911232, dist_loss: 0.44311273097991943
recon_loss: 0.028716405853629112, dist_loss: 0.6330423355102539
recon_loss: 0.028716249391436577, dist_loss: 0.8376956582069397
recon_loss: 0.02871634252369404, dist_loss: 0.6420612931251526
recon_loss: 0.02871636673808098, dist_loss: 0.783042848110199
recon_loss: 0.028716281056404114, dist_loss: 0.58199542760849
recon_loss: 0.02871614322066307, dist_loss: 0.7368284463882446
recon_loss: 0.028715873137116432, dist_loss: 0.9133299589157104
recon_loss: 0.028715673834085464, dist_loss: 1.1462690830230713
recon_loss: 0.0287155918776989, dist_loss: 0.9078561663627625
recon_loss: 0.02871539629995823, dist_loss: 0.6588901281356812
recon_loss: 0.028715314343571663, dist_loss: 0.6990737915039062
recon_loss: 0.02871529757976532, dist_loss: 0.3076673150062561
recon_loss: 0.028715359047055244, dist_loss: 0.9716980457305908
recon_loss: 0.028715336695313454, dist_loss: 0.4711199998855591
recon_loss: 0.028715210035443306, dist_loss: 1.1091864109039307
recon_loss: 0.028714966028928757, dist_loss: 0.4531548321247101
recon_loss: 0.028714817017316818, dist_loss: 0.6883728504180908
recon_loss: 0.028714846819639206, dist_loss: 0.5949901938438416
recon_loss: 0.02871488407254219, dist_loss: 0.9044243693351746
recon_loss: 0.028714772313833237, dist_loss: 0.2001209855079651
recon_loss: 0.028714675456285477, dist_loss: 0.7936437726020813
recon_loss: 0.028714505955576897, dist_loss: 0.40617072582244873
recon_loss: 0.028714418411254883, dist_loss: 0.4934975504875183
recon_loss: 0.02871437557041645, dist_loss: 0.5142364501953125
recon_loss: 0.028714433312416077, dist_loss: 0.4231280982494354
recon_loss: 0.028714746236801147, dist_loss: 0.7819403409957886
recon_loss: 0.0287148617208004, dist_loss: 0.6362906694412231
recon_loss: 0.028714753687381744, dist_loss: 0.7033952474594116
recon_loss: 0.028715144842863083, dist_loss: 0.8823446035385132
recon_loss: 0.02871553972363472, dist_loss: 1.190169334411621
recon_loss: 0.028716016560792923, dist_loss: 0.4733803868293762
recon_loss: 0.028716133907437325, dist_loss: 0.525999903678894
recon_loss: 0.028716307133436203, dist_loss: 0.5895136594772339
recon_loss: 0.02871640957891941, dist_loss: 0.5698223114013672
recon_loss: 0.028716299682855606, dist_loss: 0.3381914496421814
recon_loss: 0.02871648594737053, dist_loss: 0.8003321886062622
recon_loss: 0.028716430068016052, dist_loss: 1.1774063110351562
recon_loss: 0.028715819120407104, dist_loss: 0.8336463570594788
recon_loss: 0.028715476393699646, dist_loss: 1.3083029985427856
recon_loss: 0.028715064749121666, dist_loss: 0.7354927062988281
recon_loss: 0.028714898973703384, dist_loss: 0.7271150350570679
recon_loss: 0.028715163469314575, dist_loss: 0.5142258405685425
recon_loss: 0.028715822845697403, dist_loss: 0.4062875509262085
recon_loss: 0.028715606778860092, dist_loss: 0.7457813024520874
recon_loss: 0.028715290129184723, dist_loss: 0.3398105204105377
recon_loss: 0.028714871034026146, dist_loss: 0.8520260453224182
recon_loss: 0.02871493063867092, dist_loss: 1.1207993030548096
recon_loss: 0.028715163469314575, dist_loss: 0.3955002725124359
recon_loss: 0.028715573251247406, dist_loss: 0.5562573671340942
recon_loss: 0.028715835884213448, dist_loss: 1.035927414894104
recon_loss: 0.02871541865170002, dist_loss: 0.6947788000106812
recon_loss: 0.028715001419186592, dist_loss: 0.6100534200668335
recon_loss: 0.02871432900428772, dist_loss: 0.7326613068580627
recon_loss: 0.02871371991932392, dist_loss: 0.5795494914054871
recon_loss: 0.028713202103972435, dist_loss: 0.7809293270111084
recon_loss: 0.02871309034526348, dist_loss: 1.053294062614441
recon_loss: 0.02871306613087654, dist_loss: 0.8238567113876343
recon_loss: 0.028713924810290337, dist_loss: 0.5748250484466553
recon_loss: 0.028714677318930626, dist_loss: 0.7469892501831055
recon_loss: 0.028716472908854485, dist_loss: 1.4992812871932983
Pre-training Epoch 59:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 59:   4%|▍         | 16/367 [00:00<00:02, 152.92it/s]Pre-training Epoch 59:   9%|▉         | 33/367 [00:00<00:02, 160.26it/s]Pre-training Epoch 59:  14%|█▎        | 50/367 [00:00<00:01, 160.10it/s]Pre-training Epoch 59:  18%|█▊        | 67/367 [00:00<00:01, 162.19it/s]Pre-training Epoch 59:  23%|██▎       | 84/367 [00:00<00:01, 163.59it/s]Pre-training Epoch 59:  28%|██▊       | 101/367 [00:00<00:01, 157.38it/s]Pre-training Epoch 59:  32%|███▏      | 117/367 [00:00<00:01, 156.25it/s]recon_loss: 0.028718482702970505, dist_loss: 0.5168077945709229
recon_loss: 0.02872084081172943, dist_loss: 0.5953426361083984
recon_loss: 0.028722763061523438, dist_loss: 0.7750701308250427
recon_loss: 0.02872423082590103, dist_loss: 0.8989766836166382
recon_loss: 0.02872471883893013, dist_loss: 0.5249325633049011
recon_loss: 0.028723809868097305, dist_loss: 0.7761746644973755
recon_loss: 0.028722967952489853, dist_loss: 0.5341919660568237
recon_loss: 0.028722194954752922, dist_loss: 0.6494948267936707
recon_loss: 0.028719976544380188, dist_loss: 0.5496639609336853
recon_loss: 0.028718624264001846, dist_loss: 0.9365534782409668
recon_loss: 0.028716228902339935, dist_loss: 0.624360203742981
recon_loss: 0.028714250773191452, dist_loss: 0.7969436645507812
recon_loss: 0.02871326543390751, dist_loss: 0.49516594409942627
recon_loss: 0.028712980449199677, dist_loss: 0.5585532188415527
recon_loss: 0.028713133186101913, dist_loss: 1.3020579814910889
recon_loss: 0.028713641688227654, dist_loss: 0.8510562777519226
recon_loss: 0.028714749962091446, dist_loss: 0.864086925983429
recon_loss: 0.02871660701930523, dist_loss: 0.6932684779167175
recon_loss: 0.028718534857034683, dist_loss: 0.8351782560348511
recon_loss: 0.028719333931803703, dist_loss: 0.7909348011016846
recon_loss: 0.028719207271933556, dist_loss: 0.4529073238372803
recon_loss: 0.028719432651996613, dist_loss: 0.5678724646568298
recon_loss: 0.028719084337353706, dist_loss: 0.4255741536617279
recon_loss: 0.028717882931232452, dist_loss: 0.7337914705276489
recon_loss: 0.028717393055558205, dist_loss: 0.40034937858581543
recon_loss: 0.028715873137116432, dist_loss: 0.46808546781539917
recon_loss: 0.028714556246995926, dist_loss: 0.9279967546463013
recon_loss: 0.02871389500796795, dist_loss: 0.6834381818771362
recon_loss: 0.028712039813399315, dist_loss: 0.5016759634017944
recon_loss: 0.028712285682559013, dist_loss: 0.4486616849899292
recon_loss: 0.028711259365081787, dist_loss: 1.2439147233963013
recon_loss: 0.02871164306998253, dist_loss: 0.8167499899864197
recon_loss: 0.028711998835206032, dist_loss: 0.6675974726676941
recon_loss: 0.028710929676890373, dist_loss: 1.0440661907196045
recon_loss: 0.02871219627559185, dist_loss: 0.572809100151062
recon_loss: 0.028710903599858284, dist_loss: 0.7604802846908569
recon_loss: 0.028709856793284416, dist_loss: 0.7773705720901489
recon_loss: 0.028711017221212387, dist_loss: 0.639007031917572
recon_loss: 0.02870882675051689, dist_loss: 0.799017071723938
recon_loss: 0.02871006540954113, dist_loss: 0.49853092432022095
recon_loss: 0.028709862381219864, dist_loss: 0.5676295757293701
recon_loss: 0.028708120808005333, dist_loss: 0.8275970816612244
recon_loss: 0.028709234669804573, dist_loss: 0.7777561545372009
recon_loss: 0.02870810776948929, dist_loss: 0.7113950252532959
recon_loss: 0.028707541525363922, dist_loss: 0.32085496187210083
recon_loss: 0.028708957135677338, dist_loss: 0.7364421486854553
recon_loss: 0.028707971796393394, dist_loss: 0.5449929237365723
recon_loss: 0.028707589954137802, dist_loss: 0.7742799520492554
recon_loss: 0.028708476573228836, dist_loss: 0.5280681252479553
recon_loss: 0.028707558289170265, dist_loss: 0.7548370361328125
recon_loss: 0.028706952929496765, dist_loss: 0.3511175513267517
recon_loss: 0.02870754525065422, dist_loss: 0.8232566118240356
recon_loss: 0.028707554563879967, dist_loss: 0.3287490904331207
recon_loss: 0.028707198798656464, dist_loss: 0.9611827731132507
recon_loss: 0.028707323595881462, dist_loss: 0.6977536082267761
recon_loss: 0.02870715595781803, dist_loss: 0.6514875888824463
recon_loss: 0.02870658040046692, dist_loss: 0.47769126296043396
recon_loss: 0.02870657853782177, dist_loss: 0.8235980272293091
recon_loss: 0.028705991804599762, dist_loss: 0.541416347026825
recon_loss: 0.028705749660730362, dist_loss: 0.6653525829315186
recon_loss: 0.028705859556794167, dist_loss: 0.6626147031784058
recon_loss: 0.028705531731247902, dist_loss: 0.35473453998565674
recon_loss: 0.028705548495054245, dist_loss: 1.1500670909881592
recon_loss: 0.028705406934022903, dist_loss: 0.6639925241470337
recon_loss: 0.02870514988899231, dist_loss: 0.4341639578342438
recon_loss: 0.028704999014735222, dist_loss: 0.684945821762085
recon_loss: 0.02870483696460724, dist_loss: 0.6555310487747192
recon_loss: 0.02870548702776432, dist_loss: 0.6582039594650269
recon_loss: 0.028706250712275505, dist_loss: 0.6065676808357239
recon_loss: 0.02870664931833744, dist_loss: 0.45528465509414673
recon_loss: 0.028707530349493027, dist_loss: 0.5462276935577393
recon_loss: 0.028708072379231453, dist_loss: 0.6091489791870117
recon_loss: 0.02870800532400608, dist_loss: 0.5417168140411377
recon_loss: 0.028708619996905327, dist_loss: 0.7146596908569336
recon_loss: 0.028709033504128456, dist_loss: 0.4134145677089691
recon_loss: 0.02870887890458107, dist_loss: 0.8516942262649536
recon_loss: 0.028709078207612038, dist_loss: 0.5298143029212952
recon_loss: 0.02870863862335682, dist_loss: 0.6506108045578003
recon_loss: 0.02870783396065235, dist_loss: 0.8074856996536255
recon_loss: 0.028707072138786316, dist_loss: 0.4005133807659149
recon_loss: 0.028706436976790428, dist_loss: 0.3936838209629059
recon_loss: 0.028705956414341927, dist_loss: 0.7471218705177307
recon_loss: 0.02870572730898857, dist_loss: 0.8159796595573425
recon_loss: 0.028705280274152756, dist_loss: 0.4419928193092346
recon_loss: 0.028704850003123283, dist_loss: 0.4787745475769043
recon_loss: 0.028704479336738586, dist_loss: 0.4180822968482971
recon_loss: 0.028704412281513214, dist_loss: 0.3506518006324768
recon_loss: 0.028704440221190453, dist_loss: 0.6473504304885864
recon_loss: 0.028704317286610603, dist_loss: 0.5595352649688721
recon_loss: 0.02870418131351471, dist_loss: 0.6087520122528076
recon_loss: 0.028704607859253883, dist_loss: 0.6528457999229431
recon_loss: 0.028704728931188583, dist_loss: 0.6127899885177612
recon_loss: 0.028705187141895294, dist_loss: 0.5615115165710449
recon_loss: 0.028705960139632225, dist_loss: 0.41104087233543396
recon_loss: 0.028706077486276627, dist_loss: 0.8000499606132507
recon_loss: 0.02870602160692215, dist_loss: 0.5901476740837097
recon_loss: 0.02870635874569416, dist_loss: 0.7920119166374207
recon_loss: 0.02870655246078968, dist_loss: 0.7110969424247742
recon_loss: 0.028706414625048637, dist_loss: 0.3299623429775238
recon_loss: 0.02870642952620983, dist_loss: 0.4570380449295044
recon_loss: 0.02870575524866581, dist_loss: 0.3311673402786255
recon_loss: 0.02870558761060238, dist_loss: 0.3874707818031311
recon_loss: 0.028705591335892677, dist_loss: 0.5823701024055481
recon_loss: 0.028704803436994553, dist_loss: 0.6611660718917847
recon_loss: 0.02870434895157814, dist_loss: 0.5827648639678955
recon_loss: 0.02870384231209755, dist_loss: 0.818077027797699
recon_loss: 0.028703179210424423, dist_loss: 0.6752678155899048
recon_loss: 0.028703225776553154, dist_loss: 0.4698832631111145
recon_loss: 0.028703339397907257, dist_loss: 0.5528387427330017
recon_loss: 0.02870330400764942, dist_loss: 0.6912928223609924
recon_loss: 0.028704354539513588, dist_loss: 0.498740553855896
recon_loss: 0.028703967109322548, dist_loss: 0.8277734518051147
recon_loss: 0.028703954070806503, dist_loss: 0.46114838123321533
recon_loss: 0.028704728931188583, dist_loss: 1.3804152011871338
recon_loss: 0.028704455122351646, dist_loss: 0.515923023223877
recon_loss: 0.028704918920993805, dist_loss: 0.2869974970817566
recon_loss: 0.028705647215247154, dist_loss: 1.0752748250961304
recon_loss: 0.028704822063446045, dist_loss: 0.49283042550086975
recon_loss: 0.02870495803654194, dist_loss: 0.3959449231624603
recon_loss: 0.028704475611448288, dist_loss: 0.6511654853820801
recon_loss: 0.02870342694222927, dist_loss: 0.6526638865470886
recon_loss: 0.028702788054943085, dist_loss: 0.5504339933395386
recon_loss: 0.028702231124043465, dist_loss: 0.5966533422470093
recon_loss: 0.02870192378759384, dist_loss: 0.5532780885696411
recon_loss: 0.028701579198241234, dist_loss: 0.4030132293701172
recon_loss: 0.028701283037662506, dist_loss: 0.7440081834793091
recon_loss: 0.02870096080005169, dist_loss: 0.353546142578125
recon_loss: 0.028700778260827065, dist_loss: 0.20472609996795654
Pre-training Epoch 59:  36%|███▌      | 133/367 [00:00<00:01, 153.68it/s]Pre-training Epoch 59:  41%|████      | 149/367 [00:00<00:01, 153.48it/s]Pre-training Epoch 59:  45%|████▍     | 165/367 [00:01<00:01, 153.59it/s]Pre-training Epoch 59:  49%|████▉     | 181/367 [00:01<00:01, 152.90it/s]Pre-training Epoch 59:  54%|█████▎    | 197/367 [00:01<00:01, 152.05it/s]Pre-training Epoch 59:  58%|█████▊    | 213/367 [00:01<00:01, 151.87it/s]Pre-training Epoch 59:  62%|██████▏   | 229/367 [00:01<00:00, 150.89it/s]Pre-training Epoch 59:  67%|██████▋   | 245/367 [00:01<00:00, 147.46it/s]recon_loss: 0.028700459748506546, dist_loss: 0.3742755055427551
recon_loss: 0.02870030142366886, dist_loss: 0.9140708446502686
recon_loss: 0.02870006300508976, dist_loss: 0.5000942349433899
recon_loss: 0.02869988977909088, dist_loss: 0.5555862188339233
recon_loss: 0.02869994379580021, dist_loss: 0.584701657295227
recon_loss: 0.028700003400444984, dist_loss: 0.9878748059272766
recon_loss: 0.028699813410639763, dist_loss: 0.6565306186676025
recon_loss: 0.028699403628706932, dist_loss: 0.5888034105300903
recon_loss: 0.02869894914329052, dist_loss: 0.9792635440826416
recon_loss: 0.02869911678135395, dist_loss: 0.683016836643219
recon_loss: 0.028698841109871864, dist_loss: 1.0772355794906616
recon_loss: 0.028698835521936417, dist_loss: 0.7227866649627686
recon_loss: 0.02869904227554798, dist_loss: 0.5738878846168518
recon_loss: 0.028698692098259926, dist_loss: 0.8550677299499512
recon_loss: 0.02869848906993866, dist_loss: 0.7327778339385986
recon_loss: 0.028698444366455078, dist_loss: 0.7049132585525513
recon_loss: 0.028698405250906944, dist_loss: 0.6645206212997437
recon_loss: 0.028698360547423363, dist_loss: 0.9004131555557251
recon_loss: 0.028698278591036797, dist_loss: 0.5221377611160278
recon_loss: 0.028698064386844635, dist_loss: 0.46907687187194824
recon_loss: 0.028697965666651726, dist_loss: 1.1811082363128662
recon_loss: 0.028697915375232697, dist_loss: 0.6211795806884766
recon_loss: 0.028697965666651726, dist_loss: 0.8105181455612183
recon_loss: 0.028698138892650604, dist_loss: 0.875360369682312
recon_loss: 0.02869938686490059, dist_loss: 0.7278813123703003
recon_loss: 0.02870049886405468, dist_loss: 0.6791688203811646
recon_loss: 0.028700821101665497, dist_loss: 0.5017032623291016
recon_loss: 0.028701052069664, dist_loss: 0.3134028911590576
recon_loss: 0.028701063245534897, dist_loss: 0.7778651714324951
recon_loss: 0.028701405972242355, dist_loss: 1.0867764949798584
recon_loss: 0.028701791539788246, dist_loss: 0.5420860648155212
recon_loss: 0.028701743111014366, dist_loss: 0.3373256325721741
recon_loss: 0.028701182454824448, dist_loss: 0.5268573760986328
recon_loss: 0.02870028279721737, dist_loss: 0.8567546010017395
recon_loss: 0.028699461370706558, dist_loss: 0.4402398467063904
recon_loss: 0.028698917478322983, dist_loss: 0.7619540095329285
recon_loss: 0.028698351234197617, dist_loss: 0.6128745079040527
recon_loss: 0.028698014095425606, dist_loss: 0.6523724794387817
recon_loss: 0.028697820380330086, dist_loss: 0.9431031942367554
recon_loss: 0.02869771048426628, dist_loss: 0.5862814784049988
recon_loss: 0.02869788371026516, dist_loss: 1.1611254215240479
recon_loss: 0.028698140755295753, dist_loss: 1.3844331502914429
recon_loss: 0.028698904439806938, dist_loss: 0.8972024917602539
recon_loss: 0.02869926020503044, dist_loss: 0.6169623732566833
recon_loss: 0.028699055314064026, dist_loss: 0.8667904138565063
recon_loss: 0.028699925169348717, dist_loss: 1.000777006149292
recon_loss: 0.028700290247797966, dist_loss: 0.6483252048492432
recon_loss: 0.028699656948447227, dist_loss: 0.5431656837463379
recon_loss: 0.028699524700641632, dist_loss: 0.9926222562789917
recon_loss: 0.028699595481157303, dist_loss: 0.4868115782737732
recon_loss: 0.028698205947875977, dist_loss: 0.5795162916183472
recon_loss: 0.028698138892650604, dist_loss: 0.6083759665489197
recon_loss: 0.028697825968265533, dist_loss: 0.508922815322876
recon_loss: 0.0286964550614357, dist_loss: 0.4002072811126709
recon_loss: 0.028696779161691666, dist_loss: 1.1246564388275146
recon_loss: 0.02869643270969391, dist_loss: 0.9991098642349243
recon_loss: 0.02869582362473011, dist_loss: 1.2290606498718262
recon_loss: 0.028696278110146523, dist_loss: 0.8615872263908386
recon_loss: 0.02869551256299019, dist_loss: 0.5547266006469727
recon_loss: 0.028695840388536453, dist_loss: 0.9448080062866211
recon_loss: 0.028696099296212196, dist_loss: 0.7662065029144287
recon_loss: 0.028695495799183846, dist_loss: 0.8128631114959717
recon_loss: 0.02869652397930622, dist_loss: 0.7348421812057495
recon_loss: 0.02869628183543682, dist_loss: 0.993362307548523
recon_loss: 0.02869587205350399, dist_loss: 0.7133307456970215
recon_loss: 0.028696143999695778, dist_loss: 0.8700158596038818
recon_loss: 0.028695842251181602, dist_loss: 0.5817416310310364
recon_loss: 0.02869594283401966, dist_loss: 0.5102919340133667
recon_loss: 0.02869626134634018, dist_loss: 1.0254607200622559
recon_loss: 0.02869626134634018, dist_loss: 1.0059946775436401
recon_loss: 0.02869633212685585, dist_loss: 0.452300488948822
recon_loss: 0.028696103021502495, dist_loss: 0.3782590627670288
recon_loss: 0.02869587019085884, dist_loss: 0.5913466811180115
recon_loss: 0.02869550697505474, dist_loss: 0.41185107827186584
recon_loss: 0.02869519218802452, dist_loss: 0.6348851919174194
recon_loss: 0.028694909065961838, dist_loss: 0.5013304948806763
recon_loss: 0.028694767504930496, dist_loss: 0.5855858325958252
recon_loss: 0.02869442105293274, dist_loss: 0.8703585863113403
recon_loss: 0.028694070875644684, dist_loss: 0.6927488446235657
recon_loss: 0.02869398146867752, dist_loss: 0.42092591524124146
recon_loss: 0.028693687170743942, dist_loss: 0.8190163969993591
recon_loss: 0.028693735599517822, dist_loss: 0.798513650894165
recon_loss: 0.028693897649645805, dist_loss: 1.1193739175796509
recon_loss: 0.028694331645965576, dist_loss: 0.43028688430786133
recon_loss: 0.02869568206369877, dist_loss: 0.9936602115631104
recon_loss: 0.028696751222014427, dist_loss: 0.9096279740333557
recon_loss: 0.02869740128517151, dist_loss: 0.34698113799095154
recon_loss: 0.028697771951556206, dist_loss: 0.6317770481109619
recon_loss: 0.02869795262813568, dist_loss: 0.5852388739585876
recon_loss: 0.02869819477200508, dist_loss: 0.6085747480392456
recon_loss: 0.028698312118649483, dist_loss: 0.9542893171310425
recon_loss: 0.028698014095425606, dist_loss: 0.3594963550567627
recon_loss: 0.028697513043880463, dist_loss: 0.794215202331543
recon_loss: 0.028696300461888313, dist_loss: 0.9699445962905884
recon_loss: 0.028695441782474518, dist_loss: 0.6490265130996704
recon_loss: 0.028694430366158485, dist_loss: 0.4783468246459961
recon_loss: 0.0286937914788723, dist_loss: 0.3701268434524536
recon_loss: 0.02869347296655178, dist_loss: 0.45368248224258423
recon_loss: 0.028693201020359993, dist_loss: 0.4242907166481018
recon_loss: 0.028693145141005516, dist_loss: 0.4405750632286072
recon_loss: 0.0286934282630682, dist_loss: 0.4848431348800659
recon_loss: 0.02869272790849209, dist_loss: 0.7251905202865601
recon_loss: 0.028692355379462242, dist_loss: 0.6804153919219971
recon_loss: 0.028692256659269333, dist_loss: 0.9056164026260376
recon_loss: 0.028691790997982025, dist_loss: 0.6545486450195312
recon_loss: 0.02869190089404583, dist_loss: 0.5155622959136963
recon_loss: 0.028691735118627548, dist_loss: 0.7286094427108765
recon_loss: 0.028691366314888, dist_loss: 0.5120729804039001
recon_loss: 0.028691614046692848, dist_loss: 0.6696390509605408
recon_loss: 0.028691355139017105, dist_loss: 0.4893890917301178
recon_loss: 0.02869114838540554, dist_loss: 0.7707237601280212
recon_loss: 0.028691096231341362, dist_loss: 0.8803005218505859
recon_loss: 0.02869071438908577, dist_loss: 0.8834962844848633
recon_loss: 0.028690999373793602, dist_loss: 0.5368438959121704
recon_loss: 0.02869117632508278, dist_loss: 0.5883119702339172
recon_loss: 0.02869066223502159, dist_loss: 1.0120265483856201
recon_loss: 0.028690623119473457, dist_loss: 0.5522024631500244
recon_loss: 0.028690645471215248, dist_loss: 0.4578666090965271
recon_loss: 0.028690027073025703, dist_loss: 0.4869473874568939
recon_loss: 0.028690064325928688, dist_loss: 0.6641206741333008
recon_loss: 0.028689909726381302, dist_loss: 0.5496119856834412
recon_loss: 0.028689902275800705, dist_loss: 0.6030523180961609
recon_loss: 0.02869013324379921, dist_loss: 0.8091079592704773
recon_loss: 0.028690263628959656, dist_loss: 0.3870604634284973
recon_loss: 0.028689803555607796, dist_loss: 0.756762683391571
recon_loss: 0.028689486905932426, dist_loss: 0.740730881690979
recon_loss: 0.02868936024606228, dist_loss: 0.7430728077888489
recon_loss: 0.02868950366973877, dist_loss: 0.5541269183158875
Pre-training Epoch 59:  71%|███████   | 260/367 [00:01<00:00, 147.35it/s]Pre-training Epoch 59:  75%|███████▌  | 276/367 [00:01<00:00, 148.26it/s]Pre-training Epoch 59:  80%|███████▉  | 292/367 [00:01<00:00, 149.16it/s]Pre-training Epoch 59:  84%|████████▍ | 309/367 [00:02<00:00, 153.02it/s]Pre-training Epoch 59:  89%|████████▉ | 326/367 [00:02<00:00, 156.53it/s]Pre-training Epoch 59:  93%|█████████▎| 343/367 [00:02<00:00, 159.12it/s]Pre-training Epoch 59:  98%|█████████▊| 360/367 [00:02<00:00, 161.14it/s]Pre-training Epoch 59: 100%|██████████| 367/367 [00:02<00:00, 155.15it/s]
recon_loss: 0.028689537197351456, dist_loss: 0.6208287477493286
recon_loss: 0.028689708560705185, dist_loss: 0.8189818263053894
recon_loss: 0.028689712285995483, dist_loss: 0.8883154392242432
recon_loss: 0.02868957817554474, dist_loss: 0.8311603665351868
recon_loss: 0.028689458966255188, dist_loss: 0.9323743581771851
recon_loss: 0.028689870610833168, dist_loss: 0.5572860240936279
recon_loss: 0.02869011089205742, dist_loss: 0.9878131151199341
recon_loss: 0.02869008481502533, dist_loss: 0.4554561972618103
recon_loss: 0.028690198436379433, dist_loss: 0.3676992356777191
recon_loss: 0.02869049645960331, dist_loss: 0.8875319957733154
recon_loss: 0.02869039960205555, dist_loss: 1.0503172874450684
recon_loss: 0.028690803796052933, dist_loss: 1.179564118385315
recon_loss: 0.02869124338030815, dist_loss: 0.5709323883056641
recon_loss: 0.02869124338030815, dist_loss: 0.5651668906211853
recon_loss: 0.028690632432699203, dist_loss: 1.0316201448440552
recon_loss: 0.028690267354249954, dist_loss: 0.5367485284805298
recon_loss: 0.028689710423350334, dist_loss: 0.6172389388084412
recon_loss: 0.028689183294773102, dist_loss: 0.5546784996986389
recon_loss: 0.02868911251425743, dist_loss: 0.7822699546813965
recon_loss: 0.028688300400972366, dist_loss: 0.7048966288566589
recon_loss: 0.028687814250588417, dist_loss: 0.5452440977096558
recon_loss: 0.02868720144033432, dist_loss: 0.8424941301345825
recon_loss: 0.028686877340078354, dist_loss: 0.5886281728744507
recon_loss: 0.028687002137303352, dist_loss: 0.9046365022659302
recon_loss: 0.028687579557299614, dist_loss: 0.4598630666732788
recon_loss: 0.02868753857910633, dist_loss: 0.9270557761192322
recon_loss: 0.028687920421361923, dist_loss: 0.3755118250846863
recon_loss: 0.028688393533229828, dist_loss: 0.41072195768356323
recon_loss: 0.028689047321677208, dist_loss: 0.43906843662261963
recon_loss: 0.02868960052728653, dist_loss: 0.931367814540863
recon_loss: 0.028689667582511902, dist_loss: 0.4298518896102905
recon_loss: 0.028689496219158173, dist_loss: 0.7793139815330505
recon_loss: 0.028689183294773102, dist_loss: 0.5573683977127075
recon_loss: 0.02868904173374176, dist_loss: 0.563444197177887
recon_loss: 0.02868974767625332, dist_loss: 0.8388783931732178
recon_loss: 0.028689803555607796, dist_loss: 0.6014662981033325
recon_loss: 0.02868960238993168, dist_loss: 0.8485226035118103
recon_loss: 0.02868819236755371, dist_loss: 0.4265751838684082
recon_loss: 0.028687238693237305, dist_loss: 0.6298331022262573
recon_loss: 0.028686782345175743, dist_loss: 0.6795653104782104
recon_loss: 0.028686875477433205, dist_loss: 0.8814406394958496
recon_loss: 0.028686583042144775, dist_loss: 0.8938560485839844
recon_loss: 0.02868598699569702, dist_loss: 0.8856340646743774
recon_loss: 0.028685644268989563, dist_loss: 0.4679546058177948
recon_loss: 0.028685996308922768, dist_loss: 0.41003602743148804
recon_loss: 0.02868589386343956, dist_loss: 0.41363006830215454
recon_loss: 0.028686443343758583, dist_loss: 0.7277387380599976
recon_loss: 0.028687303885817528, dist_loss: 0.36180379986763
recon_loss: 0.028686268255114555, dist_loss: 0.530827522277832
recon_loss: 0.028685925528407097, dist_loss: 0.3175638020038605
recon_loss: 0.02868627943098545, dist_loss: 0.6976838111877441
recon_loss: 0.028685644268989563, dist_loss: 0.5737675428390503
recon_loss: 0.028685446828603745, dist_loss: 0.6297327280044556
recon_loss: 0.028685303404927254, dist_loss: 0.7390059232711792
recon_loss: 0.02868441492319107, dist_loss: 0.9410493969917297
recon_loss: 0.028684381395578384, dist_loss: 0.7129181623458862
recon_loss: 0.028684740886092186, dist_loss: 0.6293829679489136
recon_loss: 0.02868422493338585, dist_loss: 0.6254957318305969
recon_loss: 0.028684690594673157, dist_loss: 0.5842785835266113
recon_loss: 0.02868516743183136, dist_loss: 0.697432816028595
recon_loss: 0.02868477627635002, dist_loss: 0.7013617753982544
recon_loss: 0.028684822842478752, dist_loss: 0.9252831339836121
recon_loss: 0.02868480049073696, dist_loss: 0.6086304187774658
recon_loss: 0.028684891760349274, dist_loss: 1.1302416324615479
recon_loss: 0.0286848247051239, dist_loss: 0.7165876030921936
recon_loss: 0.028684716671705246, dist_loss: 0.5495166182518005
recon_loss: 0.028684349730610847, dist_loss: 1.0140074491500854
recon_loss: 0.028683653101325035, dist_loss: 0.42765048146247864
recon_loss: 0.028682967647910118, dist_loss: 0.6213440299034119
recon_loss: 0.02868247777223587, dist_loss: 0.6737796068191528
recon_loss: 0.028682464733719826, dist_loss: 0.727066159248352
recon_loss: 0.028681885451078415, dist_loss: 0.7893005609512329
recon_loss: 0.028682298958301544, dist_loss: 0.8476788997650146
recon_loss: 0.028682421892881393, dist_loss: 0.532284677028656
recon_loss: 0.02868243120610714, dist_loss: 1.013695240020752
recon_loss: 0.028683286160230637, dist_loss: 0.6581740379333496
recon_loss: 0.028684251010417938, dist_loss: 0.7416965961456299
recon_loss: 0.028685687109827995, dist_loss: 0.5695815086364746
recon_loss: 0.028687521815299988, dist_loss: 0.38576045632362366
recon_loss: 0.028688903898000717, dist_loss: 1.25453519821167
recon_loss: 0.028688061982393265, dist_loss: 0.8141204714775085
recon_loss: 0.02868776023387909, dist_loss: 0.6892805099487305
recon_loss: 0.028687288984656334, dist_loss: 0.6893864870071411
recon_loss: 0.0286873709410429, dist_loss: 0.5977859497070312
recon_loss: 0.02868662402033806, dist_loss: 0.7299878597259521
recon_loss: 0.02868565358221531, dist_loss: 0.4137248396873474
recon_loss: 0.028684573248028755, dist_loss: 0.44468891620635986
recon_loss: 0.028683386743068695, dist_loss: 0.4338439106941223
recon_loss: 0.028682388365268707, dist_loss: 0.5540875792503357
recon_loss: 0.028681818395853043, dist_loss: 0.3886043429374695
recon_loss: 0.028681321069598198, dist_loss: 0.4746558666229248
recon_loss: 0.028681134805083275, dist_loss: 0.6721107959747314
recon_loss: 0.02868073247373104, dist_loss: 0.3432636857032776
recon_loss: 0.02868056856095791, dist_loss: 0.5886235237121582
recon_loss: 0.028680529445409775, dist_loss: 0.567891001701355
recon_loss: 0.028680693358182907, dist_loss: 0.6685498952865601
recon_loss: 0.02868133783340454, dist_loss: 0.46436792612075806
recon_loss: 0.028682313859462738, dist_loss: 0.7907552123069763
recon_loss: 0.028682086616754532, dist_loss: 0.5450772643089294
recon_loss: 0.02868206985294819, dist_loss: 0.762641429901123
recon_loss: 0.0286826491355896, dist_loss: 0.7855716347694397
recon_loss: 0.02868308685719967, dist_loss: 0.9084801077842712
recon_loss: 0.02868259884417057, dist_loss: 0.7837048172950745
recon_loss: 0.02868245728313923, dist_loss: 0.9425967931747437
recon_loss: 0.02868223935365677, dist_loss: 0.6814237833023071
recon_loss: 0.028681639581918716, dist_loss: 0.4793629050254822
recon_loss: 0.028681015595793724, dist_loss: 0.5520082712173462
recon_loss: 0.028680669143795967, dist_loss: 0.593471884727478
recon_loss: 0.02868024818599224, dist_loss: 0.8817766308784485
recon_loss: 0.028679760172963142, dist_loss: 1.2027872800827026
recon_loss: 0.02867904305458069, dist_loss: 0.38280341029167175
Pre-training Epoch 60:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 60:   5%|▌         | 19/367 [00:00<00:01, 185.44it/s]Pre-training Epoch 60:  11%|█         | 39/367 [00:00<00:01, 189.17it/s]Pre-training Epoch 60:  16%|█▌        | 59/367 [00:00<00:01, 190.55it/s]Pre-training Epoch 60:  22%|██▏       | 79/367 [00:00<00:01, 184.84it/s]Pre-training Epoch 60:  27%|██▋       | 98/367 [00:00<00:01, 185.41it/s]Pre-training Epoch 60:  32%|███▏      | 118/367 [00:00<00:01, 187.30it/s]recon_loss: 0.028678491711616516, dist_loss: 0.8306722640991211
recon_loss: 0.028678206726908684, dist_loss: 0.6562517881393433
recon_loss: 0.028678076341748238, dist_loss: 0.7454215288162231
recon_loss: 0.02867797762155533, dist_loss: 0.5153064727783203
recon_loss: 0.02867775410413742, dist_loss: 0.8742263913154602
recon_loss: 0.028677701950073242, dist_loss: 0.713886022567749
recon_loss: 0.028677750378847122, dist_loss: 1.0649299621582031
recon_loss: 0.02867763862013817, dist_loss: 0.4583433270454407
recon_loss: 0.028677236288785934, dist_loss: 0.5135225057601929
recon_loss: 0.028677238151431084, dist_loss: 0.9435278177261353
recon_loss: 0.02867692895233631, dist_loss: 0.826897919178009
recon_loss: 0.028677206486463547, dist_loss: 0.7363192439079285
recon_loss: 0.028677180409431458, dist_loss: 0.5744879245758057
recon_loss: 0.028677398338913918, dist_loss: 0.46412819623947144
recon_loss: 0.028676310554146767, dist_loss: 0.5068411827087402
recon_loss: 0.028676120564341545, dist_loss: 0.586984395980835
recon_loss: 0.028676681220531464, dist_loss: 0.4939328134059906
recon_loss: 0.028676727786660194, dist_loss: 0.312717080116272
recon_loss: 0.028676683083176613, dist_loss: 0.5364757776260376
recon_loss: 0.02867632545530796, dist_loss: 0.6685914397239685
recon_loss: 0.02867596596479416, dist_loss: 0.5691059827804565
recon_loss: 0.028676073998212814, dist_loss: 0.7980638146400452
recon_loss: 0.028676478192210197, dist_loss: 0.5373799800872803
recon_loss: 0.028676489368081093, dist_loss: 0.5572912693023682
recon_loss: 0.028676489368081093, dist_loss: 0.6175616979598999
recon_loss: 0.02867620810866356, dist_loss: 0.4260716140270233
recon_loss: 0.028676073998212814, dist_loss: 0.7217204570770264
recon_loss: 0.028676072135567665, dist_loss: 0.6622233390808105
recon_loss: 0.02867632545530796, dist_loss: 0.8153654932975769
recon_loss: 0.02867634780704975, dist_loss: 0.4958787262439728
recon_loss: 0.028676120564341545, dist_loss: 0.7846752405166626
recon_loss: 0.02867615967988968, dist_loss: 0.7961883544921875
recon_loss: 0.028676873072981834, dist_loss: 0.5452284216880798
recon_loss: 0.028677666559815407, dist_loss: 0.3772543668746948
recon_loss: 0.028678378090262413, dist_loss: 0.5882383584976196
recon_loss: 0.02867836318910122, dist_loss: 0.6132315993309021
recon_loss: 0.02867824397981167, dist_loss: 0.6358820199966431
recon_loss: 0.02867872081696987, dist_loss: 0.6285923719406128
recon_loss: 0.028678977862000465, dist_loss: 0.49144116044044495
recon_loss: 0.028678886592388153, dist_loss: 0.31007447838783264
recon_loss: 0.02867872267961502, dist_loss: 0.5612440705299377
recon_loss: 0.028678037226200104, dist_loss: 0.7653232216835022
recon_loss: 0.028677083551883698, dist_loss: 0.886756181716919
recon_loss: 0.02867618389427662, dist_loss: 0.5639708638191223
recon_loss: 0.028675397858023643, dist_loss: 0.8781837224960327
recon_loss: 0.02867535501718521, dist_loss: 0.5354529619216919
recon_loss: 0.028675276786088943, dist_loss: 0.8118188381195068
recon_loss: 0.028675192967057228, dist_loss: 0.6395803689956665
recon_loss: 0.028675386682152748, dist_loss: 0.7496603727340698
recon_loss: 0.028674382716417313, dist_loss: 0.9826697111129761
recon_loss: 0.02867458201944828, dist_loss: 0.41584718227386475
recon_loss: 0.028674865141510963, dist_loss: 0.5334634780883789
recon_loss: 0.028673840686678886, dist_loss: 0.6699913740158081
recon_loss: 0.028673788532614708, dist_loss: 0.8718098402023315
recon_loss: 0.028674175962805748, dist_loss: 0.9020746946334839
recon_loss: 0.028673822060227394, dist_loss: 0.539259672164917
recon_loss: 0.028673244640231133, dist_loss: 0.7684635519981384
recon_loss: 0.028674134984612465, dist_loss: 1.2381844520568848
recon_loss: 0.028673319146037102, dist_loss: 0.48899465799331665
recon_loss: 0.0286736860871315, dist_loss: 0.7196699380874634
recon_loss: 0.028675375506281853, dist_loss: 0.5776425004005432
recon_loss: 0.028675055131316185, dist_loss: 0.43778708577156067
recon_loss: 0.028675943613052368, dist_loss: 0.43058496713638306
recon_loss: 0.028676636517047882, dist_loss: 0.8248208165168762
recon_loss: 0.02867582067847252, dist_loss: 0.5121670961380005
recon_loss: 0.028675580397248268, dist_loss: 0.7416081428527832
recon_loss: 0.028675626963377, dist_loss: 0.7789208889007568
recon_loss: 0.028674665838479996, dist_loss: 0.648363471031189
recon_loss: 0.028674300760030746, dist_loss: 0.7319899201393127
recon_loss: 0.028673667460680008, dist_loss: 0.5741616487503052
recon_loss: 0.028672998771071434, dist_loss: 0.5410221219062805
recon_loss: 0.028672751039266586, dist_loss: 0.7051408290863037
recon_loss: 0.028672602027654648, dist_loss: 0.8196983337402344
recon_loss: 0.02867286093533039, dist_loss: 0.4233044981956482
recon_loss: 0.028673531487584114, dist_loss: 0.46931707859039307
recon_loss: 0.028673984110355377, dist_loss: 0.38303887844085693
recon_loss: 0.028674021363258362, dist_loss: 0.7333018779754639
recon_loss: 0.02867436222732067, dist_loss: 0.7137899398803711
recon_loss: 0.02867487445473671, dist_loss: 1.1048917770385742
recon_loss: 0.028675343841314316, dist_loss: 0.5880651473999023
recon_loss: 0.028676269575953484, dist_loss: 0.9681823253631592
recon_loss: 0.02867630124092102, dist_loss: 0.815433144569397
recon_loss: 0.02867598831653595, dist_loss: 0.7574503421783447
recon_loss: 0.028675690293312073, dist_loss: 0.3907121419906616
recon_loss: 0.028674548491835594, dist_loss: 0.6020382642745972
recon_loss: 0.028673749417066574, dist_loss: 0.6963990926742554
recon_loss: 0.02867330238223076, dist_loss: 0.579728364944458
recon_loss: 0.028672723099589348, dist_loss: 0.6965542435646057
recon_loss: 0.028672274202108383, dist_loss: 0.5028382539749146
recon_loss: 0.028671711683273315, dist_loss: 0.40596452355384827
recon_loss: 0.02867109887301922, dist_loss: 0.7694879770278931
recon_loss: 0.028670575469732285, dist_loss: 0.7641451358795166
recon_loss: 0.028671374544501305, dist_loss: 0.5093890428543091
recon_loss: 0.02867179736495018, dist_loss: 0.4715085029602051
recon_loss: 0.028672857210040092, dist_loss: 0.8734169602394104
recon_loss: 0.028673488646745682, dist_loss: 0.7134611010551453
recon_loss: 0.02867336943745613, dist_loss: 0.9017101526260376
recon_loss: 0.028673328459262848, dist_loss: 1.037482500076294
recon_loss: 0.02867395430803299, dist_loss: 0.5660498142242432
recon_loss: 0.028674539178609848, dist_loss: 0.7291597723960876
recon_loss: 0.028674839064478874, dist_loss: 1.1557090282440186
recon_loss: 0.02867468073964119, dist_loss: 0.6771429777145386
recon_loss: 0.028674351051449776, dist_loss: 0.5636477470397949
recon_loss: 0.028674330562353134, dist_loss: 0.7852189540863037
recon_loss: 0.02867501601576805, dist_loss: 0.5360381603240967
recon_loss: 0.028675680980086327, dist_loss: 0.5627701282501221
recon_loss: 0.028676163405179977, dist_loss: 0.6871676445007324
recon_loss: 0.02867618016898632, dist_loss: 0.800584614276886
recon_loss: 0.028676051646471024, dist_loss: 0.44605761766433716
recon_loss: 0.028675522655248642, dist_loss: 0.8951269388198853
recon_loss: 0.02867509424686432, dist_loss: 1.226963996887207
recon_loss: 0.028674138709902763, dist_loss: 0.5814527273178101
recon_loss: 0.02867436408996582, dist_loss: 0.7043617963790894
recon_loss: 0.028673380613327026, dist_loss: 0.9189532995223999
recon_loss: 0.02867257036268711, dist_loss: 1.100827693939209
recon_loss: 0.028671788051724434, dist_loss: 0.9660322666168213
recon_loss: 0.028670651838183403, dist_loss: 1.0827200412750244
recon_loss: 0.028669973835349083, dist_loss: 0.6613675951957703
recon_loss: 0.02867002785205841, dist_loss: 0.8537497520446777
recon_loss: 0.02866963855922222, dist_loss: 0.6983724236488342
recon_loss: 0.02867112122476101, dist_loss: 0.6279985904693604
recon_loss: 0.028671594336628914, dist_loss: 0.5016735792160034
recon_loss: 0.028672805055975914, dist_loss: 0.6839009523391724
recon_loss: 0.028674550354480743, dist_loss: 0.40563663840293884
recon_loss: 0.028674177825450897, dist_loss: 0.47711023688316345
recon_loss: 0.02867371402680874, dist_loss: 0.9664984345436096
recon_loss: 0.028673848137259483, dist_loss: 0.8968661427497864
recon_loss: 0.028672561049461365, dist_loss: 0.9248796701431274
Pre-training Epoch 60:  37%|███▋      | 137/367 [00:00<00:01, 187.82it/s]Pre-training Epoch 60:  43%|████▎     | 156/367 [00:00<00:01, 188.35it/s]Pre-training Epoch 60:  48%|████▊     | 176/367 [00:00<00:01, 189.50it/s]Pre-training Epoch 60:  53%|█████▎    | 196/367 [00:01<00:00, 190.74it/s]Pre-training Epoch 60:  59%|█████▉    | 216/367 [00:01<00:00, 191.33it/s]Pre-training Epoch 60:  64%|██████▍   | 236/367 [00:01<00:00, 191.35it/s]Pre-training Epoch 60:  70%|██████▉   | 256/367 [00:01<00:00, 192.09it/s]recon_loss: 0.028671666979789734, dist_loss: 0.26986581087112427
recon_loss: 0.028670931234955788, dist_loss: 0.9574348330497742
recon_loss: 0.028669806197285652, dist_loss: 0.8257372379302979
recon_loss: 0.028669018298387527, dist_loss: 0.5317636132240295
recon_loss: 0.028667906299233437, dist_loss: 0.5284473896026611
recon_loss: 0.028667479753494263, dist_loss: 0.40920156240463257
recon_loss: 0.028667159378528595, dist_loss: 0.3751692771911621
recon_loss: 0.028667224571108818, dist_loss: 0.42318347096443176
recon_loss: 0.02866753749549389, dist_loss: 1.0364904403686523
recon_loss: 0.028668126091361046, dist_loss: 0.44308191537857056
recon_loss: 0.02866823598742485, dist_loss: 0.5156608819961548
recon_loss: 0.028668230399489403, dist_loss: 0.7801752090454102
recon_loss: 0.02866855077445507, dist_loss: 0.5318595767021179
recon_loss: 0.028668196871876717, dist_loss: 0.7292342185974121
recon_loss: 0.028668228536844254, dist_loss: 0.7560430765151978
recon_loss: 0.028667839244008064, dist_loss: 0.646633505821228
recon_loss: 0.02866721898317337, dist_loss: 0.9653534889221191
recon_loss: 0.02866692654788494, dist_loss: 0.9673687219619751
recon_loss: 0.02866663970053196, dist_loss: 0.5565136671066284
recon_loss: 0.028666146099567413, dist_loss: 0.37544184923171997
recon_loss: 0.028665952384471893, dist_loss: 0.6444002389907837
recon_loss: 0.028665613383054733, dist_loss: 0.3730473220348358
recon_loss: 0.028665022924542427, dist_loss: 0.49750739336013794
recon_loss: 0.028664832934737206, dist_loss: 0.6335766911506653
recon_loss: 0.028664827346801758, dist_loss: 0.6336010694503784
recon_loss: 0.028664398938417435, dist_loss: 0.565187931060791
recon_loss: 0.028664689511060715, dist_loss: 1.0811669826507568
recon_loss: 0.028664855286478996, dist_loss: 0.42764902114868164
recon_loss: 0.028664710000157356, dist_loss: 0.4342503249645233
recon_loss: 0.02866528183221817, dist_loss: 0.6609781384468079
recon_loss: 0.028665658086538315, dist_loss: 0.5875265598297119
recon_loss: 0.028665194287896156, dist_loss: 0.8032108545303345
recon_loss: 0.02866504155099392, dist_loss: 0.6667283773422241
recon_loss: 0.028664665296673775, dist_loss: 0.6146174073219299
recon_loss: 0.02866443060338497, dist_loss: 0.8636132478713989
recon_loss: 0.028664112091064453, dist_loss: 0.5055145621299744
recon_loss: 0.028663309291005135, dist_loss: 0.8205740451812744
recon_loss: 0.028662966564297676, dist_loss: 0.7663665413856506
recon_loss: 0.028663065284490585, dist_loss: 0.3485851287841797
recon_loss: 0.02866300567984581, dist_loss: 0.7343621253967285
recon_loss: 0.028662974014878273, dist_loss: 0.4069802761077881
recon_loss: 0.028663426637649536, dist_loss: 0.9095462560653687
recon_loss: 0.028662215918302536, dist_loss: 0.4739241600036621
recon_loss: 0.02866288647055626, dist_loss: 0.4651758074760437
recon_loss: 0.028662698343396187, dist_loss: 0.8911207914352417
recon_loss: 0.028663013130426407, dist_loss: 0.4856453239917755
recon_loss: 0.028663231059908867, dist_loss: 0.5051350593566895
recon_loss: 0.028662672266364098, dist_loss: 0.7843222618103027
recon_loss: 0.028662949800491333, dist_loss: 0.7596530914306641
recon_loss: 0.028663333505392075, dist_loss: 0.4748747646808624
recon_loss: 0.02866271696984768, dist_loss: 0.6933268904685974
recon_loss: 0.028662467375397682, dist_loss: 0.7444214820861816
recon_loss: 0.028662145137786865, dist_loss: 0.5572376251220703
recon_loss: 0.028661789372563362, dist_loss: 0.3223695158958435
recon_loss: 0.028661519289016724, dist_loss: 0.7550613880157471
recon_loss: 0.02866145223379135, dist_loss: 0.6082342863082886
recon_loss: 0.028661061078310013, dist_loss: 0.42271363735198975
recon_loss: 0.028661096468567848, dist_loss: 0.7683185338973999
recon_loss: 0.028660913929343224, dist_loss: 0.575657844543457
recon_loss: 0.028660651296377182, dist_loss: 0.3461958169937134
recon_loss: 0.02866058051586151, dist_loss: 0.9707526564598083
recon_loss: 0.028660565614700317, dist_loss: 0.6681437492370605
recon_loss: 0.028660254552960396, dist_loss: 0.40354084968566895
recon_loss: 0.028660375624895096, dist_loss: 0.92930006980896
recon_loss: 0.028660083189606667, dist_loss: 0.31066805124282837
recon_loss: 0.028660185635089874, dist_loss: 1.1011232137680054
recon_loss: 0.028660185635089874, dist_loss: 0.8666722774505615
recon_loss: 0.028659749776124954, dist_loss: 0.683068037033081
recon_loss: 0.028659919276833534, dist_loss: 0.9221416711807251
recon_loss: 0.028660302981734276, dist_loss: 0.5417371988296509
recon_loss: 0.028660867363214493, dist_loss: 0.4642387628555298
recon_loss: 0.028661642223596573, dist_loss: 0.6400665044784546
recon_loss: 0.02866191230714321, dist_loss: 0.8929080963134766
recon_loss: 0.028661644086241722, dist_loss: 0.47810375690460205
recon_loss: 0.028661461547017097, dist_loss: 0.5850827097892761
recon_loss: 0.028661604970693588, dist_loss: 0.6170448064804077
recon_loss: 0.028661640360951424, dist_loss: 0.5456768274307251
recon_loss: 0.028661325573921204, dist_loss: 0.40754711627960205
recon_loss: 0.02866036258637905, dist_loss: 0.7900277376174927
recon_loss: 0.028659580275416374, dist_loss: 0.46772500872612
recon_loss: 0.02865920588374138, dist_loss: 0.8022478222846985
recon_loss: 0.028659328818321228, dist_loss: 0.558533787727356
recon_loss: 0.02865949086844921, dist_loss: 0.7068729996681213
recon_loss: 0.028659380972385406, dist_loss: 0.5082239508628845
recon_loss: 0.028659125789999962, dist_loss: 0.6040489673614502
recon_loss: 0.02865898236632347, dist_loss: 0.7145008444786072
recon_loss: 0.028659174218773842, dist_loss: 1.0077921152114868
recon_loss: 0.028659885749220848, dist_loss: 0.5958247780799866
recon_loss: 0.028660401701927185, dist_loss: 0.4676758646965027
recon_loss: 0.028660574927926064, dist_loss: 0.531640887260437
recon_loss: 0.028660757467150688, dist_loss: 0.8532489538192749
recon_loss: 0.028660323470830917, dist_loss: 1.054596185684204
recon_loss: 0.028660548850893974, dist_loss: 0.49367088079452515
recon_loss: 0.028660479933023453, dist_loss: 0.6914397478103638
recon_loss: 0.02866017259657383, dist_loss: 0.7320250272750854
recon_loss: 0.028660094365477562, dist_loss: 0.7063449025154114
recon_loss: 0.028659531846642494, dist_loss: 0.6160202026367188
recon_loss: 0.028658658266067505, dist_loss: 0.886759340763092
recon_loss: 0.028658051043748856, dist_loss: 1.100487470626831
recon_loss: 0.02865765616297722, dist_loss: 0.8267967104911804
recon_loss: 0.028657270595431328, dist_loss: 0.3822869658470154
recon_loss: 0.028657129034399986, dist_loss: 0.9503852725028992
recon_loss: 0.02865714393556118, dist_loss: 0.7440646886825562
recon_loss: 0.028657376766204834, dist_loss: 0.5626184344291687
recon_loss: 0.028657477349042892, dist_loss: 0.6742206811904907
recon_loss: 0.02865784987807274, dist_loss: 0.48434221744537354
recon_loss: 0.028658417984843254, dist_loss: 0.3252660632133484
recon_loss: 0.028659384697675705, dist_loss: 0.7937199473381042
recon_loss: 0.028660090640187263, dist_loss: 0.6000304222106934
recon_loss: 0.02866068296134472, dist_loss: 0.7273509502410889
recon_loss: 0.028661025688052177, dist_loss: 0.6269941926002502
recon_loss: 0.028661200776696205, dist_loss: 0.5748507380485535
recon_loss: 0.02866164967417717, dist_loss: 0.6152815818786621
recon_loss: 0.028661517426371574, dist_loss: 0.4758559465408325
recon_loss: 0.028661483898758888, dist_loss: 0.413271427154541
recon_loss: 0.028661083430051804, dist_loss: 0.5623390674591064
recon_loss: 0.028659895062446594, dist_loss: 0.4409330487251282
recon_loss: 0.028658725321292877, dist_loss: 0.6278883218765259
recon_loss: 0.028657924383878708, dist_loss: 0.5062633752822876
recon_loss: 0.028657225891947746, dist_loss: 0.7539658546447754
recon_loss: 0.028656914830207825, dist_loss: 0.5622527003288269
recon_loss: 0.02865697629749775, dist_loss: 0.5303175449371338
recon_loss: 0.02865760773420334, dist_loss: 0.34582096338272095
recon_loss: 0.028658797964453697, dist_loss: 0.5728065371513367
recon_loss: 0.028659947216510773, dist_loss: 0.6159899830818176
recon_loss: 0.02866148017346859, dist_loss: 0.33739233016967773
recon_loss: 0.028662558645009995, dist_loss: 1.1664639711380005
recon_loss: 0.02866373211145401, dist_loss: 0.6123586893081665
Pre-training Epoch 60:  75%|███████▌  | 276/367 [00:01<00:00, 181.48it/s]Pre-training Epoch 60:  80%|████████  | 295/367 [00:01<00:00, 171.36it/s]Pre-training Epoch 60:  85%|████████▌ | 313/367 [00:01<00:00, 163.92it/s]Pre-training Epoch 60:  90%|████████▉ | 330/367 [00:01<00:00, 160.83it/s]Pre-training Epoch 60:  95%|█████████▍| 347/367 [00:01<00:00, 159.29it/s]Pre-training Epoch 60:  99%|█████████▉| 363/367 [00:02<00:00, 157.33it/s]Pre-training Epoch 60: 100%|██████████| 367/367 [00:02<00:00, 177.00it/s]
recon_loss: 0.02866438962519169, dist_loss: 0.7934163212776184
recon_loss: 0.028663957491517067, dist_loss: 0.6173769235610962
recon_loss: 0.02866336517035961, dist_loss: 0.5228853225708008
recon_loss: 0.028662165626883507, dist_loss: 0.7539499402046204
recon_loss: 0.028660627081990242, dist_loss: 0.5880844593048096
recon_loss: 0.028659561648964882, dist_loss: 0.6300537586212158
recon_loss: 0.028658919036388397, dist_loss: 0.6805980205535889
recon_loss: 0.028657229617238045, dist_loss: 0.6825946569442749
recon_loss: 0.028656993061304092, dist_loss: 0.4772021770477295
recon_loss: 0.02865602634847164, dist_loss: 0.8177263736724854
recon_loss: 0.0286551546305418, dist_loss: 0.8242462873458862
recon_loss: 0.02865678071975708, dist_loss: 0.513719916343689
recon_loss: 0.02865527756512165, dist_loss: 0.8119997978210449
recon_loss: 0.02865634672343731, dist_loss: 0.5629765391349792
recon_loss: 0.028658507391810417, dist_loss: 0.6964356303215027
recon_loss: 0.028658552095294, dist_loss: 0.7306268811225891
recon_loss: 0.028661208227276802, dist_loss: 0.7166662216186523
recon_loss: 0.02866290509700775, dist_loss: 0.8076884150505066
recon_loss: 0.028662340715527534, dist_loss: 0.44538459181785583
recon_loss: 0.028665754944086075, dist_loss: 0.849949061870575
recon_loss: 0.028664646670222282, dist_loss: 0.6604217886924744
recon_loss: 0.02866401895880699, dist_loss: 0.3842005729675293
recon_loss: 0.028665296733379364, dist_loss: 0.6021798849105835
recon_loss: 0.028662962839007378, dist_loss: 0.528388261795044
recon_loss: 0.028661932796239853, dist_loss: 0.6351865530014038
recon_loss: 0.02865990810096264, dist_loss: 1.0102295875549316
recon_loss: 0.02865776978433132, dist_loss: 0.6129114031791687
recon_loss: 0.028656890615820885, dist_loss: 0.6545192003250122
recon_loss: 0.028655659407377243, dist_loss: 0.4537436068058014
recon_loss: 0.02865554206073284, dist_loss: 0.9587279558181763
recon_loss: 0.028655707836151123, dist_loss: 0.7718464136123657
recon_loss: 0.028655031695961952, dist_loss: 0.9234659671783447
recon_loss: 0.028654739260673523, dist_loss: 0.5660228133201599
recon_loss: 0.028653711080551147, dist_loss: 0.8883016109466553
recon_loss: 0.028653288260102272, dist_loss: 0.45006662607192993
recon_loss: 0.028653742745518684, dist_loss: 0.5788145065307617
recon_loss: 0.02865387313067913, dist_loss: 0.9488649368286133
recon_loss: 0.028654752299189568, dist_loss: 0.8194342851638794
recon_loss: 0.028655562549829483, dist_loss: 0.5305137634277344
recon_loss: 0.02865525148808956, dist_loss: 0.9027236700057983
recon_loss: 0.028655758127570152, dist_loss: 0.42250245809555054
recon_loss: 0.02865525148808956, dist_loss: 0.7248663902282715
recon_loss: 0.028654642403125763, dist_loss: 1.1158794164657593
recon_loss: 0.028655435889959335, dist_loss: 0.48864486813545227
recon_loss: 0.028654713183641434, dist_loss: 0.45813193917274475
recon_loss: 0.02865402027964592, dist_loss: 0.595505952835083
recon_loss: 0.028653237968683243, dist_loss: 0.6652426719665527
recon_loss: 0.028651844710111618, dist_loss: 0.5286498069763184
recon_loss: 0.028651263564825058, dist_loss: 1.2656093835830688
recon_loss: 0.028651908040046692, dist_loss: 0.8273787498474121
recon_loss: 0.028651393949985504, dist_loss: 0.7942113876342773
recon_loss: 0.028652170673012733, dist_loss: 0.761981725692749
recon_loss: 0.02865230292081833, dist_loss: 1.0171836614608765
recon_loss: 0.028651118278503418, dist_loss: 0.44749873876571655
recon_loss: 0.028650952503085136, dist_loss: 0.6024770736694336
recon_loss: 0.028649944812059402, dist_loss: 0.6899183988571167
recon_loss: 0.028650274500250816, dist_loss: 0.6545430421829224
recon_loss: 0.02865113690495491, dist_loss: 0.439858078956604
recon_loss: 0.02865017019212246, dist_loss: 0.5372929573059082
recon_loss: 0.028649715706706047, dist_loss: 0.8024251461029053
recon_loss: 0.028648968786001205, dist_loss: 0.7027514576911926
recon_loss: 0.028649209067225456, dist_loss: 0.45906808972358704
recon_loss: 0.028649628162384033, dist_loss: 0.7973625659942627
recon_loss: 0.02864943817257881, dist_loss: 0.6624354720115662
recon_loss: 0.02865012362599373, dist_loss: 0.75150465965271
recon_loss: 0.028649603947997093, dist_loss: 0.5174463987350464
recon_loss: 0.028648773208260536, dist_loss: 0.7376723289489746
recon_loss: 0.02864961512386799, dist_loss: 0.8193731307983398
recon_loss: 0.02864949405193329, dist_loss: 0.41584300994873047
recon_loss: 0.0286494642496109, dist_loss: 0.6078920364379883
recon_loss: 0.02865026518702507, dist_loss: 0.7453312277793884
recon_loss: 0.02864907868206501, dist_loss: 0.7492942810058594
recon_loss: 0.02864862233400345, dist_loss: 0.9165772199630737
recon_loss: 0.028650198131799698, dist_loss: 0.9083366394042969
recon_loss: 0.02864903025329113, dist_loss: 0.8130462169647217
recon_loss: 0.028649630025029182, dist_loss: 0.47122687101364136
recon_loss: 0.028650199994444847, dist_loss: 0.41968968510627747
recon_loss: 0.02864869311451912, dist_loss: 0.8642243146896362
recon_loss: 0.02864883467555046, dist_loss: 0.46341925859451294
recon_loss: 0.028649019077420235, dist_loss: 0.6302590370178223
recon_loss: 0.02864854224026203, dist_loss: 0.7113533616065979
recon_loss: 0.028649089857935905, dist_loss: 0.46004438400268555
recon_loss: 0.028648680076003075, dist_loss: 0.6346390247344971
recon_loss: 0.028648752719163895, dist_loss: 1.0299279689788818
recon_loss: 0.028648588806390762, dist_loss: 0.7160500288009644
recon_loss: 0.02864808589220047, dist_loss: 0.4331732988357544
recon_loss: 0.028648102656006813, dist_loss: 0.6557864546775818
recon_loss: 0.02864828333258629, dist_loss: 0.699967086315155
recon_loss: 0.028647614642977715, dist_loss: 0.9274073243141174
recon_loss: 0.02864757925271988, dist_loss: 0.7718496322631836
recon_loss: 0.028647737577557564, dist_loss: 0.6858798265457153
recon_loss: 0.028647201135754585, dist_loss: 1.2742338180541992
recon_loss: 0.02864699251949787, dist_loss: 0.4374436140060425
recon_loss: 0.028647014871239662, dist_loss: 0.6206350326538086
recon_loss: 0.02864655666053295, dist_loss: 0.6266392469406128
recon_loss: 0.028646839782595634, dist_loss: 0.7603030204772949
recon_loss: 0.02864702045917511, dist_loss: 0.6814020872116089
recon_loss: 0.02864796109497547, dist_loss: 0.6714388132095337
recon_loss: 0.028647638857364655, dist_loss: 0.3798914849758148
recon_loss: 0.028647910803556442, dist_loss: 0.5546166896820068
recon_loss: 0.0286481361836195, dist_loss: 0.6390076875686646
recon_loss: 0.028648201376199722, dist_loss: 0.6786303520202637
recon_loss: 0.0286481324583292, dist_loss: 0.5562339425086975
recon_loss: 0.02864808402955532, dist_loss: 0.6299747228622437
recon_loss: 0.028647493571043015, dist_loss: 1.1078144311904907
recon_loss: 0.028647201135754585, dist_loss: 1.0518722534179688
recon_loss: 0.028646694496273994, dist_loss: 0.7490554451942444
recon_loss: 0.02864600159227848, dist_loss: 0.7511183619499207
recon_loss: 0.028645984828472137, dist_loss: 0.6319870948791504
recon_loss: 0.028645895421504974, dist_loss: 0.5194498300552368
recon_loss: 0.028646256774663925, dist_loss: 1.2731202840805054
Pre-train Epoch: 60
Train - Total Loss: 0.0957, Recon Loss: 0.0287, Dist Loss: 0.6702, l1 regularization: 0.0000
Val - Total Loss: 0.0998, Recon Loss: 0.0286, Dist Loss: 0.7115, l1 regularization: 0.0000
Pre-training Epoch 61:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 61:   4%|▍         | 14/367 [00:00<00:02, 134.31it/s]Pre-training Epoch 61:   8%|▊         | 30/367 [00:00<00:02, 146.40it/s]Pre-training Epoch 61:  12%|█▏        | 45/367 [00:00<00:02, 147.21it/s]Pre-training Epoch 61:  17%|█▋        | 61/367 [00:00<00:02, 150.79it/s]Pre-training Epoch 61:  21%|██        | 77/367 [00:00<00:01, 153.22it/s]Pre-training Epoch 61:  25%|██▌       | 93/367 [00:00<00:01, 152.55it/s]Pre-training Epoch 61:  30%|██▉       | 109/367 [00:00<00:01, 151.08it/s]Pre-training Epoch 61:  34%|███▍      | 125/367 [00:00<00:01, 152.18it/s]recon_loss: 0.02864677459001541, dist_loss: 1.1189028024673462
recon_loss: 0.02864702418446541, dist_loss: 0.4772920310497284
recon_loss: 0.028647836297750473, dist_loss: 0.9185436367988586
recon_loss: 0.02864888496696949, dist_loss: 0.3216031491756439
recon_loss: 0.028649259358644485, dist_loss: 0.6132419109344482
recon_loss: 0.028649169951677322, dist_loss: 0.5430036783218384
recon_loss: 0.02864932455122471, dist_loss: 0.6822330951690674
recon_loss: 0.028648972511291504, dist_loss: 0.39734160900115967
recon_loss: 0.02864852175116539, dist_loss: 0.7276338338851929
recon_loss: 0.02864772081375122, dist_loss: 0.6595566272735596
recon_loss: 0.02864682860672474, dist_loss: 0.41400575637817383
recon_loss: 0.028646254912018776, dist_loss: 0.9076734781265259
recon_loss: 0.02864556759595871, dist_loss: 0.41263046860694885
recon_loss: 0.028645342215895653, dist_loss: 1.0269103050231934
recon_loss: 0.02864576131105423, dist_loss: 0.5637513399124146
recon_loss: 0.028646092861890793, dist_loss: 0.7203202247619629
recon_loss: 0.028646528720855713, dist_loss: 0.6183986663818359
recon_loss: 0.02864738181233406, dist_loss: 0.8564653396606445
recon_loss: 0.02864859253168106, dist_loss: 0.5727834701538086
recon_loss: 0.028648976236581802, dist_loss: 0.6132456660270691
recon_loss: 0.028649669140577316, dist_loss: 0.30018919706344604
recon_loss: 0.028650743886828423, dist_loss: 0.729714035987854
recon_loss: 0.028652483597397804, dist_loss: 1.1029292345046997
recon_loss: 0.028653070330619812, dist_loss: 0.5253012180328369
recon_loss: 0.028652802109718323, dist_loss: 0.8022482395172119
recon_loss: 0.028651267290115356, dist_loss: 0.6928010582923889
recon_loss: 0.0286495853215456, dist_loss: 0.9119065999984741
recon_loss: 0.028648637235164642, dist_loss: 0.8012235164642334
recon_loss: 0.028648028150200844, dist_loss: 0.6668434739112854
recon_loss: 0.0286468043923378, dist_loss: 0.4165811538696289
recon_loss: 0.028645958751440048, dist_loss: 0.6315953731536865
recon_loss: 0.028645731508731842, dist_loss: 0.5051583051681519
recon_loss: 0.028645839542150497, dist_loss: 0.42789945006370544
recon_loss: 0.028646739199757576, dist_loss: 0.3940510153770447
recon_loss: 0.028648458421230316, dist_loss: 0.6097038388252258
recon_loss: 0.028650104999542236, dist_loss: 1.0022075176239014
recon_loss: 0.028651513159275055, dist_loss: 0.43726906180381775
recon_loss: 0.028652120381593704, dist_loss: 1.0083518028259277
recon_loss: 0.028652535751461983, dist_loss: 0.7369879484176636
recon_loss: 0.02865234948694706, dist_loss: 0.6953321695327759
recon_loss: 0.0286514051258564, dist_loss: 0.6343473792076111
recon_loss: 0.028650939464569092, dist_loss: 0.7475854754447937
recon_loss: 0.028651118278503418, dist_loss: 0.8793486952781677
recon_loss: 0.028649061918258667, dist_loss: 0.9142630100250244
recon_loss: 0.028648266568779945, dist_loss: 0.9293609857559204
recon_loss: 0.028647705912590027, dist_loss: 0.7392117977142334
recon_loss: 0.028645401820540428, dist_loss: 0.4550982415676117
recon_loss: 0.028645416721701622, dist_loss: 0.5520031452178955
recon_loss: 0.028645198792219162, dist_loss: 0.4301608204841614
recon_loss: 0.02864387072622776, dist_loss: 0.39124518632888794
recon_loss: 0.02864496037364006, dist_loss: 0.9361599087715149
recon_loss: 0.028643954545259476, dist_loss: 0.731897234916687
recon_loss: 0.028643615543842316, dist_loss: 0.8555547595024109
recon_loss: 0.02864428609609604, dist_loss: 0.5959569215774536
recon_loss: 0.02864319272339344, dist_loss: 0.5169140696525574
recon_loss: 0.028643542900681496, dist_loss: 0.5422142744064331
recon_loss: 0.028644295409321785, dist_loss: 0.5848115682601929
recon_loss: 0.028643645346164703, dist_loss: 0.3240182399749756
recon_loss: 0.028644708916544914, dist_loss: 0.9701633453369141
recon_loss: 0.028644979000091553, dist_loss: 0.5185368061065674
recon_loss: 0.02864323928952217, dist_loss: 0.7380528450012207
recon_loss: 0.02864377200603485, dist_loss: 0.6458455920219421
recon_loss: 0.028643637895584106, dist_loss: 0.7537704706192017
recon_loss: 0.028642769902944565, dist_loss: 0.49111443758010864
recon_loss: 0.028642967343330383, dist_loss: 1.0130701065063477
recon_loss: 0.028642896562814713, dist_loss: 0.5580451488494873
recon_loss: 0.028642013669013977, dist_loss: 0.7845098972320557
recon_loss: 0.028641775250434875, dist_loss: 0.39419955015182495
recon_loss: 0.02864166535437107, dist_loss: 0.6793859004974365
recon_loss: 0.02864132821559906, dist_loss: 0.5523883700370789
recon_loss: 0.028640994802117348, dist_loss: 1.2614378929138184
recon_loss: 0.02864072099328041, dist_loss: 0.5434980392456055
recon_loss: 0.028640471398830414, dist_loss: 0.6812424659729004
recon_loss: 0.02864033170044422, dist_loss: 0.7046471834182739
recon_loss: 0.02864021249115467, dist_loss: 0.4537956714630127
recon_loss: 0.028640486299991608, dist_loss: 0.5144868493080139
recon_loss: 0.02864052914083004, dist_loss: 0.6897779703140259
recon_loss: 0.028641073033213615, dist_loss: 0.7667760252952576
recon_loss: 0.02864127978682518, dist_loss: 0.48584049940109253
recon_loss: 0.028641026467084885, dist_loss: 0.5730343461036682
recon_loss: 0.028641272336244583, dist_loss: 0.568278968334198
recon_loss: 0.028641389682888985, dist_loss: 0.3752725422382355
recon_loss: 0.028640292584896088, dist_loss: 0.7800734043121338
recon_loss: 0.02864069491624832, dist_loss: 0.6316541433334351
recon_loss: 0.028639713302254677, dist_loss: 0.5616850852966309
recon_loss: 0.028639160096645355, dist_loss: 0.7293986082077026
recon_loss: 0.028639234602451324, dist_loss: 0.8507962822914124
recon_loss: 0.028638849034905434, dist_loss: 0.8635661602020264
recon_loss: 0.028639499098062515, dist_loss: 0.8715283870697021
recon_loss: 0.028640007600188255, dist_loss: 0.492154598236084
recon_loss: 0.02863997220993042, dist_loss: 0.5711959004402161
recon_loss: 0.02864021621644497, dist_loss: 0.5410608053207397
recon_loss: 0.0286400243639946, dist_loss: 0.9481527209281921
recon_loss: 0.028639936819672585, dist_loss: 0.7130988836288452
recon_loss: 0.02863995172083378, dist_loss: 0.948698103427887
recon_loss: 0.02863961085677147, dist_loss: 0.781708836555481
recon_loss: 0.02863958664238453, dist_loss: 1.2563104629516602
recon_loss: 0.02863871306180954, dist_loss: 0.42341095209121704
recon_loss: 0.028637778013944626, dist_loss: 0.5079361200332642
recon_loss: 0.02863730862736702, dist_loss: 0.561866044998169
recon_loss: 0.028636954724788666, dist_loss: 0.9535590410232544
recon_loss: 0.028636939823627472, dist_loss: 0.6253962516784668
recon_loss: 0.028636842966079712, dist_loss: 0.8184370994567871
recon_loss: 0.028636643663048744, dist_loss: 0.5742286443710327
recon_loss: 0.028636453673243523, dist_loss: 0.6155393123626709
recon_loss: 0.028636295348405838, dist_loss: 0.5002983808517456
recon_loss: 0.02863617055118084, dist_loss: 0.32530778646469116
recon_loss: 0.028636174276471138, dist_loss: 0.5416573286056519
recon_loss: 0.028635874390602112, dist_loss: 0.5333121418952942
recon_loss: 0.028635531663894653, dist_loss: 0.6456122994422913
recon_loss: 0.0286349318921566, dist_loss: 1.0445549488067627
recon_loss: 0.02863490581512451, dist_loss: 0.8997045755386353
recon_loss: 0.0286346897482872, dist_loss: 0.9905054569244385
recon_loss: 0.028634799644351006, dist_loss: 0.6624688506126404
recon_loss: 0.028634538874030113, dist_loss: 0.699873685836792
recon_loss: 0.028634244576096535, dist_loss: 0.42347657680511475
recon_loss: 0.02863430418074131, dist_loss: 0.9010893106460571
recon_loss: 0.028634395450353622, dist_loss: 1.0721168518066406
recon_loss: 0.028634093701839447, dist_loss: 0.6387404799461365
recon_loss: 0.0286344513297081, dist_loss: 0.4460373520851135
recon_loss: 0.028634464368224144, dist_loss: 0.5475406646728516
recon_loss: 0.028634212911128998, dist_loss: 0.7483190894126892
recon_loss: 0.02863428182899952, dist_loss: 0.9980957508087158
recon_loss: 0.028633803129196167, dist_loss: 0.9979297518730164
recon_loss: 0.028633471578359604, dist_loss: 0.4925076961517334
recon_loss: 0.028633270412683487, dist_loss: 0.5754228830337524
recon_loss: 0.028633002191781998, dist_loss: 1.0316028594970703
recon_loss: 0.02863292396068573, dist_loss: 0.746096134185791
Pre-training Epoch 61:  38%|███▊      | 141/367 [00:00<00:01, 152.71it/s]Pre-training Epoch 61:  43%|████▎     | 158/367 [00:01<00:01, 156.99it/s]Pre-training Epoch 61:  47%|████▋     | 174/367 [00:01<00:01, 151.77it/s]Pre-training Epoch 61:  52%|█████▏    | 190/367 [00:01<00:01, 153.48it/s]Pre-training Epoch 61:  56%|█████▌    | 206/367 [00:01<00:01, 153.21it/s]Pre-training Epoch 61:  60%|██████    | 222/367 [00:01<00:00, 153.92it/s]Pre-training Epoch 61:  65%|██████▍   | 238/367 [00:01<00:00, 152.56it/s]Pre-training Epoch 61:  69%|██████▉   | 254/367 [00:01<00:00, 153.11it/s]recon_loss: 0.02863296866416931, dist_loss: 0.5850076675415039
recon_loss: 0.028633028268814087, dist_loss: 0.7677216529846191
recon_loss: 0.028632724657654762, dist_loss: 0.8889811038970947
recon_loss: 0.02863270789384842, dist_loss: 0.6116578578948975
recon_loss: 0.02863234654068947, dist_loss: 0.6668142080307007
recon_loss: 0.028632275760173798, dist_loss: 0.37594160437583923
recon_loss: 0.028632525354623795, dist_loss: 0.44925564527511597
recon_loss: 0.02863229624927044, dist_loss: 0.7713567614555359
recon_loss: 0.028632039204239845, dist_loss: 0.6900754570960999
recon_loss: 0.02863193489611149, dist_loss: 0.6079678535461426
recon_loss: 0.028632164001464844, dist_loss: 0.794331431388855
recon_loss: 0.02863212674856186, dist_loss: 0.8472257852554321
recon_loss: 0.028632836416363716, dist_loss: 0.6087074279785156
recon_loss: 0.02863297052681446, dist_loss: 0.5961320400238037
recon_loss: 0.02863333560526371, dist_loss: 0.95878005027771
recon_loss: 0.028633398935198784, dist_loss: 0.8448640704154968
recon_loss: 0.028633203357458115, dist_loss: 0.5332834720611572
recon_loss: 0.028633292764425278, dist_loss: 0.9410324692726135
recon_loss: 0.028633596375584602, dist_loss: 0.5338950753211975
recon_loss: 0.028633326292037964, dist_loss: 0.7640781402587891
recon_loss: 0.028633512556552887, dist_loss: 1.2005305290222168
recon_loss: 0.02863294444978237, dist_loss: 0.9903632998466492
recon_loss: 0.028632597997784615, dist_loss: 0.5837130546569824
recon_loss: 0.02863243781030178, dist_loss: 0.5990899205207825
recon_loss: 0.02863193303346634, dist_loss: 0.41774189472198486
recon_loss: 0.02863192744553089, dist_loss: 0.7505514621734619
recon_loss: 0.028631703928112984, dist_loss: 0.4898778200149536
recon_loss: 0.028630858287215233, dist_loss: 0.5488162040710449
recon_loss: 0.028631096705794334, dist_loss: 0.658962607383728
recon_loss: 0.0286312997341156, dist_loss: 0.6512110233306885
recon_loss: 0.028631148859858513, dist_loss: 0.4613814949989319
recon_loss: 0.028632938861846924, dist_loss: 0.5850815773010254
recon_loss: 0.02863563969731331, dist_loss: 0.818473219871521
recon_loss: 0.028636934235692024, dist_loss: 0.576635479927063
recon_loss: 0.02863917127251625, dist_loss: 0.5636559724807739
recon_loss: 0.028639959171414375, dist_loss: 0.6136775016784668
recon_loss: 0.028639718890190125, dist_loss: 0.6726030111312866
recon_loss: 0.02863987162709236, dist_loss: 1.0013837814331055
recon_loss: 0.02863941714167595, dist_loss: 0.8743308782577515
recon_loss: 0.0286383219063282, dist_loss: 0.43794259428977966
recon_loss: 0.028636833652853966, dist_loss: 0.42028433084487915
recon_loss: 0.028635166585445404, dist_loss: 0.39603132009506226
recon_loss: 0.028633320704102516, dist_loss: 0.5119117498397827
recon_loss: 0.028632625937461853, dist_loss: 0.7062349319458008
recon_loss: 0.02863156609237194, dist_loss: 0.8271411061286926
recon_loss: 0.028631344437599182, dist_loss: 0.5060701370239258
recon_loss: 0.028630709275603294, dist_loss: 0.5785304307937622
recon_loss: 0.028630005195736885, dist_loss: 0.609278678894043
recon_loss: 0.028629692271351814, dist_loss: 0.9806020259857178
recon_loss: 0.028629304841160774, dist_loss: 0.5479029417037964
recon_loss: 0.028629085049033165, dist_loss: 0.4035412669181824
recon_loss: 0.02862892486155033, dist_loss: 0.446573942899704
recon_loss: 0.028628746047616005, dist_loss: 0.5148179531097412
recon_loss: 0.028628330677747726, dist_loss: 0.6030125617980957
recon_loss: 0.02862825058400631, dist_loss: 0.777635395526886
recon_loss: 0.02862808108329773, dist_loss: 1.031272292137146
recon_loss: 0.028627948835492134, dist_loss: 1.2775325775146484
recon_loss: 0.028627682477235794, dist_loss: 0.4886624813079834
recon_loss: 0.028627367690205574, dist_loss: 1.0790083408355713
recon_loss: 0.028628015890717506, dist_loss: 0.8936111927032471
recon_loss: 0.02862798236310482, dist_loss: 0.3753783106803894
recon_loss: 0.028627363964915276, dist_loss: 0.5551683902740479
recon_loss: 0.02862776629626751, dist_loss: 0.8446664810180664
recon_loss: 0.02862732857465744, dist_loss: 0.645816445350647
recon_loss: 0.028627023100852966, dist_loss: 0.6493008732795715
recon_loss: 0.028626948595046997, dist_loss: 0.5728796720504761
recon_loss: 0.028627028688788414, dist_loss: 0.8048268556594849
recon_loss: 0.02862754836678505, dist_loss: 0.6269410252571106
recon_loss: 0.028628259897232056, dist_loss: 0.7038236856460571
recon_loss: 0.028628932312130928, dist_loss: 0.6730183362960815
recon_loss: 0.02862945757806301, dist_loss: 0.9627455472946167
recon_loss: 0.028629912063479424, dist_loss: 0.45680373907089233
recon_loss: 0.028630264103412628, dist_loss: 0.6601455211639404
recon_loss: 0.028630265966057777, dist_loss: 0.38365817070007324
recon_loss: 0.028630129992961884, dist_loss: 0.46730563044548035
recon_loss: 0.02863004431128502, dist_loss: 1.0302468538284302
recon_loss: 0.028629349544644356, dist_loss: 0.775905191898346
recon_loss: 0.02862861566245556, dist_loss: 0.3492225706577301
recon_loss: 0.028628136962652206, dist_loss: 0.9221027493476868
recon_loss: 0.02862769365310669, dist_loss: 0.4251330494880676
recon_loss: 0.02862691879272461, dist_loss: 0.7640783786773682
recon_loss: 0.028626224026083946, dist_loss: 0.46516722440719604
recon_loss: 0.028625857084989548, dist_loss: 0.7046971321105957
recon_loss: 0.028625689446926117, dist_loss: 0.742323637008667
recon_loss: 0.02862543612718582, dist_loss: 0.9680216908454895
recon_loss: 0.028626205399632454, dist_loss: 0.47816067934036255
recon_loss: 0.028626443818211555, dist_loss: 0.5890492796897888
recon_loss: 0.028626685962080956, dist_loss: 0.5873682498931885
recon_loss: 0.028627431020140648, dist_loss: 0.4720856547355652
recon_loss: 0.028627298772335052, dist_loss: 0.5355498790740967
recon_loss: 0.028627201914787292, dist_loss: 0.765399694442749
recon_loss: 0.028628328815102577, dist_loss: 0.5108973383903503
recon_loss: 0.028628729283809662, dist_loss: 0.6776152849197388
recon_loss: 0.02862882986664772, dist_loss: 1.005410075187683
recon_loss: 0.02862902730703354, dist_loss: 0.6281169652938843
recon_loss: 0.028627965599298477, dist_loss: 0.535356342792511
recon_loss: 0.028628066182136536, dist_loss: 0.41549819707870483
recon_loss: 0.02862776629626751, dist_loss: 0.5761605501174927
recon_loss: 0.028627390041947365, dist_loss: 0.3981802463531494
recon_loss: 0.02862807735800743, dist_loss: 0.9442310333251953
recon_loss: 0.02862679772078991, dist_loss: 0.7429608702659607
recon_loss: 0.02862544357776642, dist_loss: 0.5442058444023132
recon_loss: 0.028625240549445152, dist_loss: 0.46670466661453247
recon_loss: 0.028625082224607468, dist_loss: 0.5794327259063721
recon_loss: 0.028625434264540672, dist_loss: 0.5136536955833435
recon_loss: 0.02862509712576866, dist_loss: 0.2871618866920471
recon_loss: 0.028625041246414185, dist_loss: 0.29848113656044006
recon_loss: 0.02862549014389515, dist_loss: 0.6110918521881104
recon_loss: 0.028625914826989174, dist_loss: 0.4989539384841919
recon_loss: 0.0286269374191761, dist_loss: 0.5513628721237183
recon_loss: 0.028627688065171242, dist_loss: 0.6163769960403442
recon_loss: 0.02862779051065445, dist_loss: 0.8976299166679382
recon_loss: 0.028628183528780937, dist_loss: 0.6735914945602417
recon_loss: 0.028627658262848854, dist_loss: 0.8401223421096802
recon_loss: 0.02862786501646042, dist_loss: 0.536510169506073
recon_loss: 0.028627827763557434, dist_loss: 0.39560186862945557
recon_loss: 0.02862715534865856, dist_loss: 0.44197967648506165
recon_loss: 0.028626928105950356, dist_loss: 0.4603806436061859
recon_loss: 0.028626225888729095, dist_loss: 0.32243800163269043
recon_loss: 0.028624923899769783, dist_loss: 0.47596070170402527
recon_loss: 0.02862425521016121, dist_loss: 1.01942777633667
recon_loss: 0.028623683378100395, dist_loss: 0.5929666757583618
recon_loss: 0.028623268008232117, dist_loss: 0.5282127857208252
recon_loss: 0.028622953221201897, dist_loss: 0.6875108480453491
recon_loss: 0.02862255461513996, dist_loss: 0.5192052125930786
recon_loss: 0.028622452169656754, dist_loss: 0.4928344488143921
recon_loss: 0.028622424229979515, dist_loss: 0.44870656728744507
recon_loss: 0.02862192504107952, dist_loss: 0.9918392896652222
Pre-training Epoch 61:  74%|███████▎  | 270/367 [00:01<00:00, 153.10it/s]Pre-training Epoch 61:  78%|███████▊  | 286/367 [00:01<00:00, 154.16it/s]Pre-training Epoch 61:  82%|████████▏ | 302/367 [00:01<00:00, 153.85it/s]Pre-training Epoch 61:  87%|████████▋ | 318/367 [00:02<00:00, 152.59it/s]Pre-training Epoch 61:  91%|█████████ | 334/367 [00:02<00:00, 152.13it/s]Pre-training Epoch 61:  95%|█████████▌| 350/367 [00:02<00:00, 151.55it/s]Pre-training Epoch 61: 100%|█████████▉| 366/367 [00:02<00:00, 150.12it/s]Pre-training Epoch 61: 100%|██████████| 367/367 [00:02<00:00, 151.92it/s]
recon_loss: 0.028622111305594444, dist_loss: 0.37035784125328064
recon_loss: 0.028621673583984375, dist_loss: 0.933218777179718
recon_loss: 0.028621500357985497, dist_loss: 0.8446844816207886
recon_loss: 0.028621496632695198, dist_loss: 0.44783568382263184
recon_loss: 0.028621677309274673, dist_loss: 1.0287163257598877
recon_loss: 0.028621718287467957, dist_loss: 1.134616494178772
recon_loss: 0.02862178534269333, dist_loss: 0.46621567010879517
recon_loss: 0.02862190641462803, dist_loss: 0.7333656549453735
recon_loss: 0.028622018173336983, dist_loss: 0.5500683784484863
recon_loss: 0.028622230514883995, dist_loss: 0.537075936794281
recon_loss: 0.028622332960367203, dist_loss: 1.1589909791946411
recon_loss: 0.028622513636946678, dist_loss: 0.7357257604598999
recon_loss: 0.028622515499591827, dist_loss: 0.5551953315734863
recon_loss: 0.028622424229979515, dist_loss: 0.605229914188385
recon_loss: 0.02862214483320713, dist_loss: 1.1235263347625732
recon_loss: 0.028621556237339973, dist_loss: 0.37519127130508423
recon_loss: 0.028621116653084755, dist_loss: 0.5835577249526978
recon_loss: 0.028620745986700058, dist_loss: 0.5975993871688843
recon_loss: 0.028620142489671707, dist_loss: 0.6757973432540894
recon_loss: 0.028619930148124695, dist_loss: 0.6348124146461487
recon_loss: 0.028619740158319473, dist_loss: 0.4559628665447235
recon_loss: 0.028619933873414993, dist_loss: 0.641677975654602
recon_loss: 0.0286200363188982, dist_loss: 0.5847054123878479
recon_loss: 0.028619585558772087, dist_loss: 0.6901459097862244
recon_loss: 0.028619816526770592, dist_loss: 0.7560340166091919
recon_loss: 0.028619635850191116, dist_loss: 0.7876640558242798
recon_loss: 0.02861914597451687, dist_loss: 0.53548264503479
recon_loss: 0.02861945703625679, dist_loss: 0.5833650827407837
recon_loss: 0.028619030490517616, dist_loss: 0.5160719156265259
recon_loss: 0.02861851453781128, dist_loss: 0.49378499388694763
recon_loss: 0.028618285432457924, dist_loss: 0.7766448259353638
recon_loss: 0.02861800231039524, dist_loss: 0.5911228656768799
recon_loss: 0.028618160635232925, dist_loss: 0.697304904460907
recon_loss: 0.028620218858122826, dist_loss: 0.7573472261428833
recon_loss: 0.028620213270187378, dist_loss: 0.8940774202346802
recon_loss: 0.028620228171348572, dist_loss: 0.9687196016311646
recon_loss: 0.02862054854631424, dist_loss: 1.017508625984192
recon_loss: 0.02862001210451126, dist_loss: 0.9526686668395996
recon_loss: 0.02861979976296425, dist_loss: 0.714278519153595
recon_loss: 0.028620829805731773, dist_loss: 1.012001872062683
recon_loss: 0.028621027246117592, dist_loss: 0.5086586475372314
recon_loss: 0.028621051460504532, dist_loss: 0.5574741363525391
recon_loss: 0.0286204032599926, dist_loss: 0.7190964221954346
recon_loss: 0.0286183450371027, dist_loss: 0.8061363697052002
recon_loss: 0.02861826866865158, dist_loss: 0.6540215015411377
recon_loss: 0.028618087992072105, dist_loss: 0.8894215822219849
recon_loss: 0.02861739695072174, dist_loss: 0.6041207313537598
recon_loss: 0.02861894853413105, dist_loss: 0.6208645105361938
recon_loss: 0.0286197941750288, dist_loss: 0.5700226426124573
recon_loss: 0.02861953340470791, dist_loss: 0.377718061208725
recon_loss: 0.02862132340669632, dist_loss: 0.574586033821106
recon_loss: 0.028621703386306763, dist_loss: 0.5711891651153564
recon_loss: 0.028622692450881004, dist_loss: 0.5629702210426331
recon_loss: 0.02862386777997017, dist_loss: 0.7801799774169922
recon_loss: 0.028623457998037338, dist_loss: 0.6572729349136353
recon_loss: 0.02862381562590599, dist_loss: 0.5127304792404175
recon_loss: 0.02862333506345749, dist_loss: 0.6220136880874634
recon_loss: 0.028622448444366455, dist_loss: 0.90339195728302
recon_loss: 0.028621681034564972, dist_loss: 0.6597516536712646
recon_loss: 0.028620636090636253, dist_loss: 0.5784058570861816
recon_loss: 0.02861977182328701, dist_loss: 0.4420109987258911
recon_loss: 0.028619039803743362, dist_loss: 0.4805358946323395
recon_loss: 0.02861843630671501, dist_loss: 0.536388635635376
recon_loss: 0.028617745265364647, dist_loss: 0.9419840574264526
recon_loss: 0.02861708216369152, dist_loss: 0.2616119980812073
recon_loss: 0.028616907075047493, dist_loss: 0.6827019453048706
recon_loss: 0.028616705909371376, dist_loss: 0.5147379040718079
recon_loss: 0.028616635128855705, dist_loss: 0.4283895492553711
recon_loss: 0.02861667610704899, dist_loss: 0.6850961446762085
recon_loss: 0.02861708216369152, dist_loss: 1.2820582389831543
recon_loss: 0.028618279844522476, dist_loss: 0.36287564039230347
recon_loss: 0.028619233518838882, dist_loss: 1.1287224292755127
recon_loss: 0.02862147055566311, dist_loss: 0.5743330717086792
recon_loss: 0.02862207032740116, dist_loss: 0.5594360828399658
recon_loss: 0.02862333506345749, dist_loss: 0.5379456877708435
recon_loss: 0.0286239143460989, dist_loss: 0.4070513844490051
recon_loss: 0.02862381376326084, dist_loss: 0.9152133464813232
recon_loss: 0.028624387457966805, dist_loss: 0.623661994934082
recon_loss: 0.02862377092242241, dist_loss: 0.5000834465026855
recon_loss: 0.028623439371585846, dist_loss: 0.4710354804992676
recon_loss: 0.028622692450881004, dist_loss: 0.4270627498626709
recon_loss: 0.028620904311537743, dist_loss: 0.635871410369873
recon_loss: 0.028620293363928795, dist_loss: 0.7671000361442566
recon_loss: 0.028618844226002693, dist_loss: 0.6073800325393677
recon_loss: 0.02861783467233181, dist_loss: 0.5966978073120117
recon_loss: 0.028617365285754204, dist_loss: 0.7132745981216431
recon_loss: 0.028616877272725105, dist_loss: 0.4091978371143341
recon_loss: 0.028616303578019142, dist_loss: 1.2408579587936401
recon_loss: 0.02861609123647213, dist_loss: 0.3505547046661377
recon_loss: 0.028615783900022507, dist_loss: 1.2607202529907227
recon_loss: 0.02861538529396057, dist_loss: 0.4079304039478302
recon_loss: 0.028615128248929977, dist_loss: 0.7383571267127991
recon_loss: 0.028614884242415428, dist_loss: 1.4403997659683228
recon_loss: 0.028614794835448265, dist_loss: 0.33957603573799133
recon_loss: 0.028614915907382965, dist_loss: 0.6569710969924927
recon_loss: 0.028615109622478485, dist_loss: 0.9534266591072083
recon_loss: 0.0286149512976408, dist_loss: 0.5933884382247925
recon_loss: 0.028615372255444527, dist_loss: 0.4266800284385681
recon_loss: 0.02861553430557251, dist_loss: 0.7653206586837769
recon_loss: 0.02861514873802662, dist_loss: 0.34640610218048096
recon_loss: 0.028614789247512817, dist_loss: 0.5977281332015991
recon_loss: 0.028615305200219154, dist_loss: 0.8202983140945435
recon_loss: 0.028614891692996025, dist_loss: 0.6311423778533936
recon_loss: 0.028614426031708717, dist_loss: 0.8051713109016418
recon_loss: 0.028614813461899757, dist_loss: 0.9997513294219971
recon_loss: 0.028614383190870285, dist_loss: 0.8587482571601868
recon_loss: 0.02861395850777626, dist_loss: 0.42829078435897827
recon_loss: 0.028614090755581856, dist_loss: 0.8469592928886414
recon_loss: 0.028613202273845673, dist_loss: 1.0628381967544556
recon_loss: 0.02861282415688038, dist_loss: 0.76076340675354
recon_loss: 0.028612438589334488, dist_loss: 0.6061626672744751
Pre-training Epoch 62:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 62:   4%|▍         | 16/367 [00:00<00:02, 152.64it/s]Pre-training Epoch 62:   9%|▉         | 34/367 [00:00<00:01, 166.92it/s]Pre-training Epoch 62:  14%|█▍        | 52/367 [00:00<00:01, 169.18it/s]Pre-training Epoch 62:  19%|█▉        | 71/367 [00:00<00:01, 173.83it/s]Pre-training Epoch 62:  25%|██▍       | 90/367 [00:00<00:01, 176.26it/s]Pre-training Epoch 62:  29%|██▉       | 108/367 [00:00<00:01, 176.90it/s]Pre-training Epoch 62:  35%|███▍      | 127/367 [00:00<00:01, 178.04it/s]recon_loss: 0.02861218899488449, dist_loss: 0.9586500525474548
recon_loss: 0.028612365946173668, dist_loss: 0.6936720609664917
recon_loss: 0.02861202508211136, dist_loss: 0.9907535314559937
recon_loss: 0.02861177548766136, dist_loss: 0.829436719417572
recon_loss: 0.028611432760953903, dist_loss: 0.7442788481712341
recon_loss: 0.028611168265342712, dist_loss: 0.7683261036872864
recon_loss: 0.028611453250050545, dist_loss: 0.5792376399040222
recon_loss: 0.02861107513308525, dist_loss: 0.3952244222164154
recon_loss: 0.0286109521985054, dist_loss: 0.5836687684059143
recon_loss: 0.02861083298921585, dist_loss: 1.0657219886779785
recon_loss: 0.02861025556921959, dist_loss: 0.42795097827911377
recon_loss: 0.028610091656446457, dist_loss: 0.5820488929748535
recon_loss: 0.02860974706709385, dist_loss: 0.6876974701881409
recon_loss: 0.028609665110707283, dist_loss: 1.199710488319397
recon_loss: 0.02861025184392929, dist_loss: 0.4202721118927002
recon_loss: 0.02861054614186287, dist_loss: 0.34885576367378235
recon_loss: 0.028610968962311745, dist_loss: 0.6405318975448608
recon_loss: 0.02861117571592331, dist_loss: 0.9280439019203186
recon_loss: 0.02861085906624794, dist_loss: 0.5485114455223083
recon_loss: 0.028610339388251305, dist_loss: 0.9205021262168884
recon_loss: 0.028610723093152046, dist_loss: 1.0074729919433594
recon_loss: 0.02861117571592331, dist_loss: 0.7765551209449768
recon_loss: 0.028610834851861, dist_loss: 0.733296275138855
recon_loss: 0.028610801324248314, dist_loss: 0.35380035638809204
recon_loss: 0.02861033007502556, dist_loss: 0.4018073081970215
recon_loss: 0.028610654175281525, dist_loss: 0.7550317049026489
recon_loss: 0.028611773625016212, dist_loss: 0.8460239171981812
recon_loss: 0.028612125664949417, dist_loss: 0.4679670035839081
recon_loss: 0.02861250378191471, dist_loss: 0.5614851713180542
recon_loss: 0.028612181544303894, dist_loss: 0.6062818169593811
recon_loss: 0.0286103468388319, dist_loss: 1.064814567565918
recon_loss: 0.028610212728381157, dist_loss: 1.0728271007537842
recon_loss: 0.0286086518317461, dist_loss: 0.4503769278526306
recon_loss: 0.028608445078134537, dist_loss: 0.7194281816482544
recon_loss: 0.02860902063548565, dist_loss: 0.5035282373428345
recon_loss: 0.02860873192548752, dist_loss: 0.5293139815330505
recon_loss: 0.02860843949019909, dist_loss: 0.6629317998886108
recon_loss: 0.02860811911523342, dist_loss: 0.5181208848953247
recon_loss: 0.02860742062330246, dist_loss: 0.9629772305488586
recon_loss: 0.02860778011381626, dist_loss: 0.38044553995132446
recon_loss: 0.028607750311493874, dist_loss: 0.38338586688041687
recon_loss: 0.028607485815882683, dist_loss: 0.5516182780265808
recon_loss: 0.02860776148736477, dist_loss: 0.7765334844589233
recon_loss: 0.02860679291188717, dist_loss: 0.4434574544429779
recon_loss: 0.028607221320271492, dist_loss: 0.9243908524513245
recon_loss: 0.028606662526726723, dist_loss: 0.5474124550819397
recon_loss: 0.02860652469098568, dist_loss: 1.292600393295288
recon_loss: 0.028606347739696503, dist_loss: 0.8774226903915405
recon_loss: 0.028606215491890907, dist_loss: 0.8442027568817139
recon_loss: 0.028606172651052475, dist_loss: 0.4372048079967499
recon_loss: 0.02860589325428009, dist_loss: 1.2644627094268799
recon_loss: 0.028605660423636436, dist_loss: 0.7613577842712402
recon_loss: 0.02860582433640957, dist_loss: 1.7233977317810059
recon_loss: 0.028605908155441284, dist_loss: 0.4864220917224884
recon_loss: 0.02860652469098568, dist_loss: 0.5617045164108276
recon_loss: 0.02860703319311142, dist_loss: 0.6102390885353088
recon_loss: 0.02860715612769127, dist_loss: 0.7152530550956726
recon_loss: 0.028607215732336044, dist_loss: 0.7546071410179138
recon_loss: 0.02860707975924015, dist_loss: 0.5759369134902954
recon_loss: 0.028607087209820747, dist_loss: 0.6294780373573303
recon_loss: 0.028607061132788658, dist_loss: 0.6959666013717651
recon_loss: 0.028606366366147995, dist_loss: 0.8042182922363281
recon_loss: 0.028606172651052475, dist_loss: 0.8285559415817261
recon_loss: 0.02860620617866516, dist_loss: 0.5965373516082764
recon_loss: 0.02860553376376629, dist_loss: 0.6065336465835571
recon_loss: 0.028606148436665535, dist_loss: 0.36527442932128906
recon_loss: 0.028606586158275604, dist_loss: 0.6711533069610596
recon_loss: 0.0286070816218853, dist_loss: 0.636847198009491
recon_loss: 0.028609683737158775, dist_loss: 1.0456111431121826
recon_loss: 0.028610697016119957, dist_loss: 0.6015865802764893
recon_loss: 0.02861136943101883, dist_loss: 0.39815226197242737
recon_loss: 0.028613200411200523, dist_loss: 0.8421217799186707
recon_loss: 0.02861325442790985, dist_loss: 0.5879549980163574
recon_loss: 0.028613310307264328, dist_loss: 0.5247994661331177
recon_loss: 0.028614919632673264, dist_loss: 1.4909064769744873
recon_loss: 0.02861243486404419, dist_loss: 0.6245413422584534
recon_loss: 0.028611397370696068, dist_loss: 0.5356427431106567
recon_loss: 0.028610097244381905, dist_loss: 0.851895809173584
recon_loss: 0.02860802784562111, dist_loss: 0.512943685054779
recon_loss: 0.028607523068785667, dist_loss: 0.3598495423793793
recon_loss: 0.028606858104467392, dist_loss: 0.5002997517585754
recon_loss: 0.028606047853827477, dist_loss: 0.3866655230522156
recon_loss: 0.028606627136468887, dist_loss: 0.6717193126678467
recon_loss: 0.02860569953918457, dist_loss: 0.7720571160316467
recon_loss: 0.028604546561837196, dist_loss: 0.9544246196746826
recon_loss: 0.02860421873629093, dist_loss: 0.6660313606262207
recon_loss: 0.028603726997971535, dist_loss: 0.5446004271507263
recon_loss: 0.02860364317893982, dist_loss: 0.9348938465118408
recon_loss: 0.028604023158550262, dist_loss: 0.6363369226455688
recon_loss: 0.028604011982679367, dist_loss: 0.5771110653877258
recon_loss: 0.028603415936231613, dist_loss: 0.5343639850616455
recon_loss: 0.028603194281458855, dist_loss: 0.7967878580093384
recon_loss: 0.028602905571460724, dist_loss: 0.4092995524406433
recon_loss: 0.028603019192814827, dist_loss: 0.5674636363983154
recon_loss: 0.02860315330326557, dist_loss: 0.5940898656845093
recon_loss: 0.028603270649909973, dist_loss: 0.3822973370552063
recon_loss: 0.028603147715330124, dist_loss: 0.2646627426147461
recon_loss: 0.028602594509720802, dist_loss: 0.5986140370368958
recon_loss: 0.028602376580238342, dist_loss: 0.5072815418243408
recon_loss: 0.02860248275101185, dist_loss: 0.6447209119796753
recon_loss: 0.028602303937077522, dist_loss: 0.4518934488296509
recon_loss: 0.028603360056877136, dist_loss: 0.5585196018218994
recon_loss: 0.028602369129657745, dist_loss: 0.5849264860153198
recon_loss: 0.028601843863725662, dist_loss: 0.4873955249786377
recon_loss: 0.028602609410881996, dist_loss: 0.8349164724349976
recon_loss: 0.028601471334695816, dist_loss: 0.9544046521186829
recon_loss: 0.02860172837972641, dist_loss: 1.1025782823562622
recon_loss: 0.028602009639143944, dist_loss: 0.566712498664856
recon_loss: 0.02860165573656559, dist_loss: 0.6780809164047241
recon_loss: 0.028601622208952904, dist_loss: 0.9924207925796509
recon_loss: 0.028601258993148804, dist_loss: 0.5409975051879883
recon_loss: 0.02860115095973015, dist_loss: 0.49407610297203064
recon_loss: 0.028600789606571198, dist_loss: 0.5756988525390625
recon_loss: 0.028600618243217468, dist_loss: 0.549920380115509
recon_loss: 0.028600743040442467, dist_loss: 0.5942038297653198
recon_loss: 0.028600554913282394, dist_loss: 0.6362049579620361
recon_loss: 0.028600407764315605, dist_loss: 0.6968043446540833
recon_loss: 0.028600484132766724, dist_loss: 0.6199359893798828
recon_loss: 0.028600363060832024, dist_loss: 0.6915618777275085
recon_loss: 0.028600255027413368, dist_loss: 0.7474764585494995
recon_loss: 0.028600262477993965, dist_loss: 0.3958371579647064
recon_loss: 0.028600621968507767, dist_loss: 0.5598247051239014
recon_loss: 0.028600573539733887, dist_loss: 0.6702385544776917
recon_loss: 0.028600646182894707, dist_loss: 1.221741795539856
recon_loss: 0.02860012836754322, dist_loss: 0.29143381118774414
recon_loss: 0.028599930927157402, dist_loss: 0.5058524012565613
recon_loss: 0.028599951416254044, dist_loss: 0.6103634834289551
recon_loss: 0.028599504381418228, dist_loss: 0.4957382380962372
Pre-training Epoch 62:  40%|███▉      | 145/367 [00:00<00:01, 172.17it/s]Pre-training Epoch 62:  44%|████▍     | 163/367 [00:00<00:01, 171.14it/s]Pre-training Epoch 62:  49%|████▉     | 181/367 [00:01<00:01, 171.51it/s]Pre-training Epoch 62:  54%|█████▍    | 199/367 [00:01<00:00, 170.41it/s]Pre-training Epoch 62:  60%|█████▉    | 219/367 [00:01<00:00, 176.77it/s]Pre-training Epoch 62:  65%|██████▌   | 239/367 [00:01<00:00, 181.22it/s]recon_loss: 0.028599437326192856, dist_loss: 0.827285885810852
recon_loss: 0.028599362820386887, dist_loss: 0.5679513216018677
recon_loss: 0.028599224984645844, dist_loss: 0.771085798740387
recon_loss: 0.028599312528967857, dist_loss: 1.484894037246704
recon_loss: 0.028600050136446953, dist_loss: 0.7861176133155823
recon_loss: 0.028601879253983498, dist_loss: 0.7120983600616455
recon_loss: 0.028603555634617805, dist_loss: 0.488557904958725
recon_loss: 0.028604567050933838, dist_loss: 0.6518444418907166
recon_loss: 0.028606615960597992, dist_loss: 0.5504927635192871
recon_loss: 0.028607424348592758, dist_loss: 0.789735734462738
recon_loss: 0.028607459738850594, dist_loss: 0.6149555444717407
recon_loss: 0.028607754036784172, dist_loss: 0.5045673251152039
recon_loss: 0.028607208281755447, dist_loss: 0.6573230028152466
recon_loss: 0.028606509789824486, dist_loss: 0.7656823396682739
recon_loss: 0.02860599011182785, dist_loss: 0.5104994773864746
recon_loss: 0.02860376611351967, dist_loss: 0.6797308325767517
recon_loss: 0.02860325761139393, dist_loss: 0.6869850158691406
recon_loss: 0.02860240638256073, dist_loss: 0.7526779174804688
recon_loss: 0.02860189974308014, dist_loss: 0.6180509924888611
recon_loss: 0.028602100908756256, dist_loss: 0.2917338013648987
recon_loss: 0.028600972145795822, dist_loss: 0.83790522813797
recon_loss: 0.028600003570318222, dist_loss: 0.7627161145210266
recon_loss: 0.028599189594388008, dist_loss: 0.5540835857391357
recon_loss: 0.028599189594388008, dist_loss: 1.1923325061798096
recon_loss: 0.028599388897418976, dist_loss: 0.6647874712944031
recon_loss: 0.02859935536980629, dist_loss: 0.7267659902572632
recon_loss: 0.02859962172806263, dist_loss: 0.7146946787834167
recon_loss: 0.028599813580513, dist_loss: 0.38658708333969116
recon_loss: 0.02859991416335106, dist_loss: 0.5681800246238708
recon_loss: 0.028600409626960754, dist_loss: 0.8531748056411743
recon_loss: 0.02860110253095627, dist_loss: 1.0031331777572632
recon_loss: 0.028602266684174538, dist_loss: 0.8265373110771179
recon_loss: 0.02860294282436371, dist_loss: 0.47447237372398376
recon_loss: 0.02860395610332489, dist_loss: 0.9146804213523865
recon_loss: 0.02860395424067974, dist_loss: 0.6905797123908997
recon_loss: 0.02860349416732788, dist_loss: 0.5553672313690186
recon_loss: 0.028602885082364082, dist_loss: 0.43550604581832886
recon_loss: 0.028600657358765602, dist_loss: 0.8341342210769653
recon_loss: 0.02860010415315628, dist_loss: 1.0325473546981812
recon_loss: 0.028598999604582787, dist_loss: 0.5274463891983032
recon_loss: 0.028598293662071228, dist_loss: 0.7462248802185059
recon_loss: 0.02859845943748951, dist_loss: 0.7827668786048889
recon_loss: 0.02859734185039997, dist_loss: 0.8074661493301392
recon_loss: 0.02859760820865631, dist_loss: 0.3755972385406494
recon_loss: 0.02859773486852646, dist_loss: 0.702934980392456
recon_loss: 0.028597472235560417, dist_loss: 0.43204644322395325
recon_loss: 0.02859787829220295, dist_loss: 0.5123555064201355
recon_loss: 0.028597403317689896, dist_loss: 0.9579340815544128
recon_loss: 0.028597362339496613, dist_loss: 0.7233296632766724
recon_loss: 0.028596948832273483, dist_loss: 0.5323828458786011
recon_loss: 0.028596170246601105, dist_loss: 0.5407529473304749
recon_loss: 0.028595831245183945, dist_loss: 0.5559244155883789
recon_loss: 0.028595512732863426, dist_loss: 1.0408456325531006
recon_loss: 0.02859504334628582, dist_loss: 0.48861441016197205
recon_loss: 0.02859487198293209, dist_loss: 0.5243917107582092
recon_loss: 0.028594905510544777, dist_loss: 0.5543067455291748
recon_loss: 0.02859479747712612, dist_loss: 0.8989044427871704
recon_loss: 0.028594639152288437, dist_loss: 0.5953468084335327
recon_loss: 0.02859511971473694, dist_loss: 0.5249001979827881
recon_loss: 0.02859549969434738, dist_loss: 0.8311294913291931
recon_loss: 0.0285952165722847, dist_loss: 0.3793689012527466
recon_loss: 0.02859531342983246, dist_loss: 0.4722146987915039
recon_loss: 0.0285954512655735, dist_loss: 0.4333249628543854
recon_loss: 0.02859525755047798, dist_loss: 0.811426043510437
recon_loss: 0.028595294803380966, dist_loss: 0.7866665124893188
recon_loss: 0.028595443814992905, dist_loss: 0.5702123641967773
recon_loss: 0.028594518080353737, dist_loss: 0.5562204122543335
recon_loss: 0.028594015166163445, dist_loss: 0.6174943447113037
recon_loss: 0.02859387919306755, dist_loss: 0.3218296766281128
recon_loss: 0.02859330363571644, dist_loss: 0.34085410833358765
recon_loss: 0.028593825176358223, dist_loss: 0.5170103311538696
recon_loss: 0.028593759983778, dist_loss: 0.9594526290893555
recon_loss: 0.028592707589268684, dist_loss: 0.40893104672431946
recon_loss: 0.028592390939593315, dist_loss: 0.7926437854766846
recon_loss: 0.028592806309461594, dist_loss: 1.026435375213623
recon_loss: 0.028592588379979134, dist_loss: 1.2828028202056885
recon_loss: 0.02859422005712986, dist_loss: 0.886314868927002
recon_loss: 0.02859453111886978, dist_loss: 0.6114572882652283
recon_loss: 0.02859460562467575, dist_loss: 0.4555791914463043
recon_loss: 0.028595024719834328, dist_loss: 0.4618414640426636
recon_loss: 0.02859489805996418, dist_loss: 0.6765721440315247
recon_loss: 0.028596065938472748, dist_loss: 1.3552658557891846
recon_loss: 0.02859596721827984, dist_loss: 0.6644917726516724
recon_loss: 0.028596244752407074, dist_loss: 0.6411339044570923
recon_loss: 0.02859634719789028, dist_loss: 0.6497041583061218
recon_loss: 0.028595374897122383, dist_loss: 0.8757506012916565
recon_loss: 0.028595417737960815, dist_loss: 0.2526571750640869
recon_loss: 0.02859503962099552, dist_loss: 0.5462462902069092
recon_loss: 0.028594031929969788, dist_loss: 0.827341616153717
recon_loss: 0.028593752533197403, dist_loss: 1.1155378818511963
recon_loss: 0.02859334647655487, dist_loss: 0.5049092173576355
recon_loss: 0.028592269867658615, dist_loss: 0.34897375106811523
recon_loss: 0.0285918191075325, dist_loss: 0.7952026128768921
recon_loss: 0.028591377660632133, dist_loss: 0.4804104268550873
recon_loss: 0.028590841218829155, dist_loss: 0.693235456943512
recon_loss: 0.0285907331854105, dist_loss: 0.8031584024429321
recon_loss: 0.028590679168701172, dist_loss: 0.6355583667755127
recon_loss: 0.028590045869350433, dist_loss: 0.8211010694503784
recon_loss: 0.028590058907866478, dist_loss: 0.7844827175140381
recon_loss: 0.02859000861644745, dist_loss: 0.7807304859161377
recon_loss: 0.028589973226189613, dist_loss: 0.4989827871322632
recon_loss: 0.028590591624379158, dist_loss: 0.6233537197113037
recon_loss: 0.02859051339328289, dist_loss: 0.9691009521484375
recon_loss: 0.028590966016054153, dist_loss: 1.2800425291061401
recon_loss: 0.02859182097017765, dist_loss: 0.35486090183258057
recon_loss: 0.028591930866241455, dist_loss: 0.537686288356781
recon_loss: 0.028592178598046303, dist_loss: 1.0087525844573975
recon_loss: 0.028592539951205254, dist_loss: 0.8956077098846436
recon_loss: 0.028592415153980255, dist_loss: 0.7642405033111572
recon_loss: 0.028592517599463463, dist_loss: 0.3829836845397949
recon_loss: 0.028592491522431374, dist_loss: 0.31329482793807983
recon_loss: 0.02859186753630638, dist_loss: 0.2636551856994629
recon_loss: 0.028591422364115715, dist_loss: 0.8835052251815796
recon_loss: 0.028590813279151917, dist_loss: 0.7314804196357727
recon_loss: 0.02859017625451088, dist_loss: 0.5984693765640259
recon_loss: 0.028589744120836258, dist_loss: 1.0272537469863892
recon_loss: 0.028589023277163506, dist_loss: 0.6402001976966858
recon_loss: 0.02858865074813366, dist_loss: 0.30464887619018555
recon_loss: 0.028588395565748215, dist_loss: 0.5168355107307434
recon_loss: 0.028588157147169113, dist_loss: 0.5042791366577148
recon_loss: 0.028587883338332176, dist_loss: 0.8637868165969849
recon_loss: 0.028587637469172478, dist_loss: 0.7792446613311768
recon_loss: 0.028587616980075836, dist_loss: 0.6029301881790161
recon_loss: 0.028587549924850464, dist_loss: 0.5542249083518982
recon_loss: 0.02858745865523815, dist_loss: 0.7941539287567139
recon_loss: 0.028587231412529945, dist_loss: 0.520288348197937
recon_loss: 0.028586942702531815, dist_loss: 0.4337390065193176
recon_loss: 0.0285867378115654, dist_loss: 0.39754560589790344
Pre-training Epoch 62:  71%|███████   | 259/367 [00:01<00:00, 184.36it/s]Pre-training Epoch 62:  76%|███████▌  | 279/367 [00:01<00:00, 186.63it/s]Pre-training Epoch 62:  81%|████████▏ | 299/367 [00:01<00:00, 188.19it/s]Pre-training Epoch 62:  87%|████████▋ | 319/367 [00:01<00:00, 189.29it/s]Pre-training Epoch 62:  92%|█████████▏| 339/367 [00:01<00:00, 190.11it/s]Pre-training Epoch 62:  98%|█████████▊| 359/367 [00:01<00:00, 190.68it/s]Pre-training Epoch 62: 100%|██████████| 367/367 [00:02<00:00, 180.38it/s]
recon_loss: 0.028586752712726593, dist_loss: 0.5911383628845215
recon_loss: 0.028586911037564278, dist_loss: 0.9592900276184082
recon_loss: 0.02858707122504711, dist_loss: 0.42237555980682373
recon_loss: 0.028586717322468758, dist_loss: 0.7517171502113342
recon_loss: 0.02858654409646988, dist_loss: 0.627440333366394
recon_loss: 0.028586627915501595, dist_loss: 1.0140817165374756
recon_loss: 0.028586681932210922, dist_loss: 0.669643759727478
recon_loss: 0.028587033972144127, dist_loss: 0.7007535099983215
recon_loss: 0.02858687937259674, dist_loss: 0.5729296207427979
recon_loss: 0.028586652129888535, dist_loss: 0.9124063849449158
recon_loss: 0.02858601324260235, dist_loss: 0.31250667572021484
recon_loss: 0.028586046770215034, dist_loss: 0.8467248678207397
recon_loss: 0.02858615852892399, dist_loss: 0.728515625
recon_loss: 0.02858661860227585, dist_loss: 0.48325878381729126
recon_loss: 0.02858663536608219, dist_loss: 0.6523891687393188
recon_loss: 0.02858654223382473, dist_loss: 0.5174334645271301
recon_loss: 0.028586143627762794, dist_loss: 0.3619067668914795
recon_loss: 0.028585774824023247, dist_loss: 0.5536656379699707
recon_loss: 0.02858545072376728, dist_loss: 0.5717791318893433
recon_loss: 0.028585204854607582, dist_loss: 0.633059024810791
recon_loss: 0.02858590893447399, dist_loss: 1.408954381942749
recon_loss: 0.028586165979504585, dist_loss: 0.45957574248313904
recon_loss: 0.028585951775312424, dist_loss: 0.6372594833374023
recon_loss: 0.02858622372150421, dist_loss: 0.5801482200622559
recon_loss: 0.028584742918610573, dist_loss: 0.6098541617393494
recon_loss: 0.028584429994225502, dist_loss: 0.6535735130310059
recon_loss: 0.028584454208612442, dist_loss: 0.5483638048171997
recon_loss: 0.02858429215848446, dist_loss: 0.5191836357116699
recon_loss: 0.028584152460098267, dist_loss: 0.9409249424934387
recon_loss: 0.028584156185388565, dist_loss: 1.312972068786621
recon_loss: 0.02858400158584118, dist_loss: 0.3014889359474182
recon_loss: 0.028584279119968414, dist_loss: 0.7790236473083496
recon_loss: 0.02858407236635685, dist_loss: 0.4003996253013611
recon_loss: 0.028584308922290802, dist_loss: 0.7092001438140869
recon_loss: 0.028584681451320648, dist_loss: 0.4667629897594452
recon_loss: 0.028584539890289307, dist_loss: 0.40048444271087646
recon_loss: 0.02858436480164528, dist_loss: 0.49322718381881714
recon_loss: 0.028584174811840057, dist_loss: 0.3320046067237854
recon_loss: 0.028583690524101257, dist_loss: 0.7354124188423157
recon_loss: 0.028583835810422897, dist_loss: 0.839077889919281
recon_loss: 0.02858385443687439, dist_loss: 0.33399248123168945
recon_loss: 0.02858399972319603, dist_loss: 0.8457086682319641
recon_loss: 0.028584258630871773, dist_loss: 0.3392464518547058
recon_loss: 0.028583992272615433, dist_loss: 0.3589560091495514
recon_loss: 0.028583884239196777, dist_loss: 0.469775527715683
recon_loss: 0.028583653271198273, dist_loss: 0.8440230488777161
recon_loss: 0.02858348935842514, dist_loss: 1.099544882774353
recon_loss: 0.028584027662873268, dist_loss: 0.3032712936401367
recon_loss: 0.028583979234099388, dist_loss: 0.44754481315612793
recon_loss: 0.028583703562617302, dist_loss: 0.7577506899833679
recon_loss: 0.028583286330103874, dist_loss: 0.7911701202392578
recon_loss: 0.028583019971847534, dist_loss: 0.5841917991638184
recon_loss: 0.02858375944197178, dist_loss: 0.6490264534950256
recon_loss: 0.028584256768226624, dist_loss: 0.635625958442688
recon_loss: 0.028585100546479225, dist_loss: 0.9121161699295044
recon_loss: 0.02858497016131878, dist_loss: 0.5839974284172058
recon_loss: 0.028584636747837067, dist_loss: 0.676692545413971
recon_loss: 0.028584307059645653, dist_loss: 0.7955403327941895
recon_loss: 0.02858380414545536, dist_loss: 0.9146220684051514
recon_loss: 0.02858342044055462, dist_loss: 0.8068242073059082
recon_loss: 0.028583159670233727, dist_loss: 0.5595695376396179
recon_loss: 0.02858310006558895, dist_loss: 0.5065454244613647
recon_loss: 0.028582850471138954, dist_loss: 0.5093072056770325
recon_loss: 0.028582386672496796, dist_loss: 1.2180382013320923
recon_loss: 0.02858208492398262, dist_loss: 0.40923407673835754
recon_loss: 0.028581922873854637, dist_loss: 0.8612571954727173
recon_loss: 0.028581885620951653, dist_loss: 0.7585217952728271
recon_loss: 0.028581703081727028, dist_loss: 0.2937946915626526
recon_loss: 0.028581546619534492, dist_loss: 1.130623459815979
recon_loss: 0.028581535443663597, dist_loss: 0.607318639755249
recon_loss: 0.028581364080309868, dist_loss: 0.8080726861953735
recon_loss: 0.0285811685025692, dist_loss: 0.6834100484848022
recon_loss: 0.0285810437053442, dist_loss: 0.8342305421829224
recon_loss: 0.028581269085407257, dist_loss: 0.4699011445045471
recon_loss: 0.028581691905856133, dist_loss: 0.394065797328949
recon_loss: 0.028582144528627396, dist_loss: 0.3935161232948303
recon_loss: 0.028582343831658363, dist_loss: 0.3296130299568176
recon_loss: 0.028582777827978134, dist_loss: 0.5805814266204834
recon_loss: 0.028583362698554993, dist_loss: 0.5402584075927734
recon_loss: 0.02858385257422924, dist_loss: 0.9481520652770996
recon_loss: 0.028583720326423645, dist_loss: 0.7420070171356201
recon_loss: 0.02858375385403633, dist_loss: 0.703853964805603
recon_loss: 0.0285833440721035, dist_loss: 0.509472131729126
recon_loss: 0.028582844883203506, dist_loss: 0.9379955530166626
recon_loss: 0.028582066297531128, dist_loss: 0.44034260511398315
recon_loss: 0.028581207618117332, dist_loss: 0.6094642877578735
recon_loss: 0.028580520302057266, dist_loss: 0.4652266502380371
recon_loss: 0.028580069541931152, dist_loss: 0.7605297565460205
recon_loss: 0.02858002483844757, dist_loss: 0.23296040296554565
recon_loss: 0.028580043464899063, dist_loss: 0.6524980068206787
recon_loss: 0.0285799503326416, dist_loss: 0.5618767738342285
recon_loss: 0.0285794697701931, dist_loss: 0.480662077665329
recon_loss: 0.028579019010066986, dist_loss: 0.4963812232017517
recon_loss: 0.028578853234648705, dist_loss: 0.6928656697273254
recon_loss: 0.02857876569032669, dist_loss: 0.4958052635192871
recon_loss: 0.02857835777103901, dist_loss: 1.1852412223815918
recon_loss: 0.0285782553255558, dist_loss: 0.5898153781890869
recon_loss: 0.02857823669910431, dist_loss: 0.5043140649795532
recon_loss: 0.02857813984155655, dist_loss: 0.7606993317604065
recon_loss: 0.028578100726008415, dist_loss: 0.6081305742263794
recon_loss: 0.02857792004942894, dist_loss: 0.5868580937385559
recon_loss: 0.028577910736203194, dist_loss: 0.5406339168548584
recon_loss: 0.028578083962202072, dist_loss: 0.5900653004646301
recon_loss: 0.028578199446201324, dist_loss: 0.5599256157875061
recon_loss: 0.028577903285622597, dist_loss: 0.49741533398628235
recon_loss: 0.028577998280525208, dist_loss: 0.6048264503479004
recon_loss: 0.02857748232781887, dist_loss: 0.6721413135528564
recon_loss: 0.02857741340994835, dist_loss: 0.75026935338974
recon_loss: 0.02857711911201477, dist_loss: 1.2706300020217896
recon_loss: 0.028576567769050598, dist_loss: 1.00100576877594
recon_loss: 0.028576582670211792, dist_loss: 1.3021427392959595
Pre-training Epoch 63:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 63:   5%|▌         | 19/367 [00:00<00:01, 189.35it/s]Pre-training Epoch 63:  11%|█         | 39/367 [00:00<00:01, 190.80it/s]Pre-training Epoch 63:  16%|█▌        | 59/367 [00:00<00:01, 187.71it/s]Pre-training Epoch 63:  21%|██▏       | 78/367 [00:00<00:01, 184.58it/s]Pre-training Epoch 63:  26%|██▋       | 97/367 [00:00<00:01, 182.32it/s]Pre-training Epoch 63:  32%|███▏      | 116/367 [00:00<00:01, 181.27it/s]recon_loss: 0.028576215729117393, dist_loss: 0.4214475154876709
recon_loss: 0.02857622317969799, dist_loss: 0.7760653495788574
recon_loss: 0.02857622317969799, dist_loss: 0.4354555010795593
recon_loss: 0.02857612632215023, dist_loss: 1.4890260696411133
recon_loss: 0.028576243668794632, dist_loss: 0.5052754878997803
recon_loss: 0.02857666090130806, dist_loss: 0.56146240234375
recon_loss: 0.028577808290719986, dist_loss: 0.42376893758773804
recon_loss: 0.02857884205877781, dist_loss: 0.7431249618530273
recon_loss: 0.028579793870449066, dist_loss: 0.3869865834712982
recon_loss: 0.0285805594176054, dist_loss: 1.0345604419708252
recon_loss: 0.028581472113728523, dist_loss: 0.32560914754867554
recon_loss: 0.02858240343630314, dist_loss: 0.668750524520874
recon_loss: 0.02858252078294754, dist_loss: 0.6436455845832825
recon_loss: 0.028582599014043808, dist_loss: 0.6490482091903687
recon_loss: 0.02858220785856247, dist_loss: 0.4386458694934845
recon_loss: 0.028581932187080383, dist_loss: 0.7251504063606262
recon_loss: 0.028580989688634872, dist_loss: 0.41863757371902466
recon_loss: 0.028580015525221825, dist_loss: 0.43148383498191833
recon_loss: 0.028578711673617363, dist_loss: 0.44453999400138855
recon_loss: 0.028577305376529694, dist_loss: 0.8375856876373291
recon_loss: 0.028576869517564774, dist_loss: 1.2016572952270508
recon_loss: 0.028576163575053215, dist_loss: 0.6753599047660828
recon_loss: 0.028576042503118515, dist_loss: 0.8389565944671631
recon_loss: 0.028576144948601723, dist_loss: 1.286426067352295
recon_loss: 0.028575509786605835, dist_loss: 0.538632333278656
recon_loss: 0.02857626974582672, dist_loss: 0.9985126852989197
recon_loss: 0.028575824573636055, dist_loss: 0.49306023120880127
recon_loss: 0.0285754706710577, dist_loss: 0.8795653581619263
recon_loss: 0.02857576124370098, dist_loss: 0.5765162706375122
recon_loss: 0.028575140982866287, dist_loss: 0.6409002542495728
recon_loss: 0.028574848547577858, dist_loss: 0.6542248725891113
recon_loss: 0.02857469581067562, dist_loss: 0.5024551153182983
recon_loss: 0.028574123978614807, dist_loss: 0.6411172151565552
recon_loss: 0.028574086725711823, dist_loss: 0.522381603717804
recon_loss: 0.02857370115816593, dist_loss: 0.3449883460998535
recon_loss: 0.028573770076036453, dist_loss: 0.8536862730979919
recon_loss: 0.02857363037765026, dist_loss: 0.47554296255111694
recon_loss: 0.02857360802590847, dist_loss: 0.701971173286438
recon_loss: 0.02857382409274578, dist_loss: 0.5702181458473206
recon_loss: 0.028574606403708458, dist_loss: 0.8579254746437073
recon_loss: 0.028574595227837563, dist_loss: 0.3567427098751068
recon_loss: 0.028574440628290176, dist_loss: 0.9008609652519226
recon_loss: 0.028574304655194283, dist_loss: 0.5248465538024902
recon_loss: 0.02857380546629429, dist_loss: 0.80255526304245
recon_loss: 0.02857382595539093, dist_loss: 0.49078071117401123
recon_loss: 0.028573377057909966, dist_loss: 0.43903952836990356
recon_loss: 0.028572743758559227, dist_loss: 0.34068727493286133
recon_loss: 0.028572408482432365, dist_loss: 0.9982250928878784
recon_loss: 0.028572281822562218, dist_loss: 0.4502181112766266
recon_loss: 0.02857293002307415, dist_loss: 0.8157064914703369
recon_loss: 0.028572391718626022, dist_loss: 0.5518836379051208
recon_loss: 0.028572211042046547, dist_loss: 0.48667317628860474
recon_loss: 0.028572412207722664, dist_loss: 0.5556958317756653
recon_loss: 0.02857176400721073, dist_loss: 0.6316331624984741
recon_loss: 0.02857191488146782, dist_loss: 0.5701936483383179
recon_loss: 0.028571942821145058, dist_loss: 0.5330442190170288
recon_loss: 0.028571899980306625, dist_loss: 0.5519355535507202
recon_loss: 0.028571976348757744, dist_loss: 0.6246329545974731
recon_loss: 0.028571564704179764, dist_loss: 0.5126408338546753
recon_loss: 0.028571125119924545, dist_loss: 0.9838303923606873
recon_loss: 0.028570791706442833, dist_loss: 0.608673095703125
recon_loss: 0.028570430353283882, dist_loss: 0.8093938827514648
recon_loss: 0.028570249676704407, dist_loss: 0.8632556200027466
recon_loss: 0.028570309281349182, dist_loss: 0.41945505142211914
recon_loss: 0.028570506721735, dist_loss: 0.5833004117012024
recon_loss: 0.028570881113409996, dist_loss: 0.7386484146118164
recon_loss: 0.028571290895342827, dist_loss: 0.5238326191902161
recon_loss: 0.028571777045726776, dist_loss: 0.899241030216217
recon_loss: 0.028572233393788338, dist_loss: 0.9536902904510498
recon_loss: 0.028571410104632378, dist_loss: 0.5190304517745972
recon_loss: 0.028571223840117455, dist_loss: 0.7549083828926086
recon_loss: 0.028570905327796936, dist_loss: 0.71555095911026
recon_loss: 0.028570637106895447, dist_loss: 0.8554041385650635
recon_loss: 0.028570381924510002, dist_loss: 0.5085152983665466
recon_loss: 0.028570232912898064, dist_loss: 1.2617785930633545
recon_loss: 0.028570249676704407, dist_loss: 0.41332578659057617
recon_loss: 0.02857012301683426, dist_loss: 0.8536076545715332
recon_loss: 0.02856999821960926, dist_loss: 0.44004637002944946
recon_loss: 0.028569603338837624, dist_loss: 0.8399516344070435
recon_loss: 0.028569741174578667, dist_loss: 0.6393266916275024
recon_loss: 0.028569992631673813, dist_loss: 0.30455905199050903
recon_loss: 0.02856983244419098, dist_loss: 0.6926319599151611
recon_loss: 0.028570234775543213, dist_loss: 0.38748735189437866
recon_loss: 0.028570223599672318, dist_loss: 0.3621037006378174
recon_loss: 0.028570162132382393, dist_loss: 0.7175884246826172
recon_loss: 0.028570108115673065, dist_loss: 0.413047730922699
recon_loss: 0.028569728136062622, dist_loss: 0.4080619812011719
recon_loss: 0.028569567948579788, dist_loss: 0.33920055627822876
recon_loss: 0.028569264337420464, dist_loss: 0.6998075842857361
recon_loss: 0.02856886014342308, dist_loss: 0.5146690607070923
recon_loss: 0.028568534180521965, dist_loss: 0.554807722568512
recon_loss: 0.028568387031555176, dist_loss: 0.8000506162643433
recon_loss: 0.02856810763478279, dist_loss: 0.44005513191223145
recon_loss: 0.02856840007007122, dist_loss: 0.4706766903400421
recon_loss: 0.028568239882588387, dist_loss: 0.6753876805305481
recon_loss: 0.028568178415298462, dist_loss: 0.6158656477928162
recon_loss: 0.02856825664639473, dist_loss: 0.9140052199363708
recon_loss: 0.028568126261234283, dist_loss: 0.6954727172851562
recon_loss: 0.02856854535639286, dist_loss: 0.8424139022827148
recon_loss: 0.028568079695105553, dist_loss: 0.42516860365867615
recon_loss: 0.028568286448717117, dist_loss: 0.7107690572738647
recon_loss: 0.02856810763478279, dist_loss: 0.3218921720981598
recon_loss: 0.02856740728020668, dist_loss: 0.5195900201797485
recon_loss: 0.02856704592704773, dist_loss: 0.9101084470748901
recon_loss: 0.02856682613492012, dist_loss: 0.5339893102645874
recon_loss: 0.02856682613492012, dist_loss: 0.7211894989013672
recon_loss: 0.028566965833306313, dist_loss: 0.4746508002281189
recon_loss: 0.028566978871822357, dist_loss: 0.4070099890232086
recon_loss: 0.028566937893629074, dist_loss: 0.501873254776001
recon_loss: 0.02856687642633915, dist_loss: 0.680667519569397
recon_loss: 0.028567014262080193, dist_loss: 0.48589861392974854
recon_loss: 0.02856706641614437, dist_loss: 0.8833728432655334
recon_loss: 0.02856701985001564, dist_loss: 0.8389760255813599
recon_loss: 0.028566502034664154, dist_loss: 0.7702136039733887
recon_loss: 0.028566062450408936, dist_loss: 0.5888149738311768
recon_loss: 0.028565827757120132, dist_loss: 0.4939045310020447
recon_loss: 0.02856624126434326, dist_loss: 0.7684098482131958
recon_loss: 0.028566621243953705, dist_loss: 0.71405029296875
recon_loss: 0.028567006811499596, dist_loss: 0.713638424873352
recon_loss: 0.02856704778969288, dist_loss: 0.5609997510910034
recon_loss: 0.028566893190145493, dist_loss: 0.5113545060157776
recon_loss: 0.028566960245370865, dist_loss: 0.8060246706008911
recon_loss: 0.028567126020789146, dist_loss: 0.4029223620891571
recon_loss: 0.02856752648949623, dist_loss: 0.4244697690010071
recon_loss: 0.028567228466272354, dist_loss: 0.7877309918403625
recon_loss: 0.02856672927737236, dist_loss: 0.7103910446166992
recon_loss: 0.02856649085879326, dist_loss: 0.8880094289779663
recon_loss: 0.02856568433344364, dist_loss: 1.04656183719635
Pre-training Epoch 63:  37%|███▋      | 135/367 [00:00<00:01, 172.48it/s]Pre-training Epoch 63:  42%|████▏     | 153/367 [00:00<00:01, 164.59it/s]Pre-training Epoch 63:  46%|████▋     | 170/367 [00:00<00:01, 164.71it/s]Pre-training Epoch 63:  51%|█████     | 187/367 [00:01<00:01, 159.46it/s]Pre-training Epoch 63:  56%|█████▌    | 204/367 [00:01<00:01, 157.41it/s]Pre-training Epoch 63:  60%|█████▉    | 220/367 [00:01<00:00, 157.18it/s]Pre-training Epoch 63:  64%|██████▍   | 236/367 [00:01<00:00, 157.79it/s]Pre-training Epoch 63:  69%|██████▊   | 252/367 [00:01<00:00, 157.56it/s]recon_loss: 0.028566347435116768, dist_loss: 0.8274543285369873
recon_loss: 0.028566278517246246, dist_loss: 0.8338906168937683
recon_loss: 0.02856522798538208, dist_loss: 0.5004613399505615
recon_loss: 0.028564905747771263, dist_loss: 1.2708996534347534
recon_loss: 0.02856503054499626, dist_loss: 0.724805474281311
recon_loss: 0.028564410284161568, dist_loss: 0.6788301467895508
recon_loss: 0.02856435813009739, dist_loss: 0.8476972579956055
recon_loss: 0.028564222157001495, dist_loss: 0.585963785648346
recon_loss: 0.028564371168613434, dist_loss: 0.8184802532196045
recon_loss: 0.0285648126155138, dist_loss: 0.9012335538864136
recon_loss: 0.028564821928739548, dist_loss: 0.6686667799949646
recon_loss: 0.02856437675654888, dist_loss: 0.5979903936386108
recon_loss: 0.02856391668319702, dist_loss: 1.0387907028198242
recon_loss: 0.028564222157001495, dist_loss: 0.6170965433120728
recon_loss: 0.028564278036355972, dist_loss: 0.6409687399864197
recon_loss: 0.028563886880874634, dist_loss: 0.5853734016418457
recon_loss: 0.02856411784887314, dist_loss: 0.7091301679611206
recon_loss: 0.028564300388097763, dist_loss: 1.1990705728530884
recon_loss: 0.028565265238285065, dist_loss: 0.7473392486572266
recon_loss: 0.028565801680088043, dist_loss: 0.6322506666183472
recon_loss: 0.028565775603055954, dist_loss: 0.48393556475639343
recon_loss: 0.028566749766469002, dist_loss: 0.6325271129608154
recon_loss: 0.028567152097821236, dist_loss: 0.6627019643783569
recon_loss: 0.028566814959049225, dist_loss: 0.31077104806900024
recon_loss: 0.028567109256982803, dist_loss: 0.6511759757995605
recon_loss: 0.028567098081111908, dist_loss: 0.4391862452030182
recon_loss: 0.028566604480147362, dist_loss: 0.6723633408546448
recon_loss: 0.02856619469821453, dist_loss: 0.3317452669143677
recon_loss: 0.02856532856822014, dist_loss: 1.0060118436813354
recon_loss: 0.02856527827680111, dist_loss: 0.893951416015625
recon_loss: 0.028564561158418655, dist_loss: 0.5548766851425171
recon_loss: 0.028564365580677986, dist_loss: 0.592342734336853
recon_loss: 0.028563834726810455, dist_loss: 0.5597568154335022
recon_loss: 0.02856283448636532, dist_loss: 0.6115383505821228
recon_loss: 0.02856266126036644, dist_loss: 0.5077356100082397
recon_loss: 0.02856261469423771, dist_loss: 0.5184735059738159
recon_loss: 0.028562208637595177, dist_loss: 0.27760061621665955
recon_loss: 0.028562122955918312, dist_loss: 0.6959415674209595
recon_loss: 0.028562823310494423, dist_loss: 1.5606095790863037
recon_loss: 0.02856350690126419, dist_loss: 0.4293908178806305
recon_loss: 0.02856442518532276, dist_loss: 0.6777908205986023
recon_loss: 0.02856549620628357, dist_loss: 0.7718659043312073
recon_loss: 0.028565891087055206, dist_loss: 1.3252543210983276
recon_loss: 0.028567425906658173, dist_loss: 0.6837695837020874
recon_loss: 0.02857041172683239, dist_loss: 0.9343292713165283
recon_loss: 0.028574014082551003, dist_loss: 1.1654627323150635
recon_loss: 0.028577493503689766, dist_loss: 0.5562224388122559
recon_loss: 0.02857951447367668, dist_loss: 0.7146559357643127
recon_loss: 0.028580162674188614, dist_loss: 0.8530317544937134
recon_loss: 0.028581734746694565, dist_loss: 0.5538023114204407
recon_loss: 0.028581155464053154, dist_loss: 0.6043410301208496
recon_loss: 0.028580855578184128, dist_loss: 0.41510361433029175
recon_loss: 0.028580302372574806, dist_loss: 0.6518692970275879
recon_loss: 0.028577646240592003, dist_loss: 0.48449209332466125
recon_loss: 0.028575189411640167, dist_loss: 0.7576343417167664
recon_loss: 0.028573235496878624, dist_loss: 0.5320699214935303
recon_loss: 0.028570041060447693, dist_loss: 0.5856340527534485
recon_loss: 0.028567958623170853, dist_loss: 0.5470669269561768
recon_loss: 0.028565550222992897, dist_loss: 0.9286602735519409
recon_loss: 0.028563717380166054, dist_loss: 0.6153680086135864
recon_loss: 0.02856295183300972, dist_loss: 0.4387698471546173
recon_loss: 0.028562886640429497, dist_loss: 0.6728190183639526
recon_loss: 0.0285632461309433, dist_loss: 0.6435651779174805
recon_loss: 0.02856479585170746, dist_loss: 0.891538143157959
recon_loss: 0.028565967455506325, dist_loss: 0.40708857774734497
recon_loss: 0.028567293658852577, dist_loss: 0.47665274143218994
recon_loss: 0.028569001704454422, dist_loss: 0.28485408425331116
recon_loss: 0.028569066897034645, dist_loss: 0.9914866089820862
recon_loss: 0.02857024036347866, dist_loss: 1.0425572395324707
recon_loss: 0.028570465743541718, dist_loss: 0.8756079077720642
recon_loss: 0.028571071103215218, dist_loss: 0.5212646722793579
recon_loss: 0.02857239544391632, dist_loss: 1.0038131475448608
recon_loss: 0.028572939336299896, dist_loss: 0.7544019222259521
recon_loss: 0.028572695329785347, dist_loss: 0.44807857275009155
recon_loss: 0.028573697432875633, dist_loss: 0.8865343332290649
recon_loss: 0.028571125119924545, dist_loss: 0.4364972710609436
recon_loss: 0.028569933027029037, dist_loss: 0.7954816818237305
recon_loss: 0.0285690575838089, dist_loss: 1.1953303813934326
recon_loss: 0.028567081317305565, dist_loss: 0.8042457699775696
recon_loss: 0.02856547199189663, dist_loss: 1.2142417430877686
recon_loss: 0.028564421460032463, dist_loss: 0.539840817451477
recon_loss: 0.0285622701048851, dist_loss: 1.2720222473144531
recon_loss: 0.028561918064951897, dist_loss: 0.7696332931518555
recon_loss: 0.02856134995818138, dist_loss: 0.7350654602050781
recon_loss: 0.02855994924902916, dist_loss: 0.9779531955718994
recon_loss: 0.028561392799019814, dist_loss: 0.7279387712478638
recon_loss: 0.028559952974319458, dist_loss: 0.6857401132583618
recon_loss: 0.02855946682393551, dist_loss: 0.7560172080993652
recon_loss: 0.028560666367411613, dist_loss: 0.7583210468292236
recon_loss: 0.028559599071741104, dist_loss: 0.6662805080413818
recon_loss: 0.028560616075992584, dist_loss: 1.128841519355774
recon_loss: 0.028560154139995575, dist_loss: 0.5965567827224731
recon_loss: 0.028558585792779922, dist_loss: 1.2567377090454102
recon_loss: 0.0285593681037426, dist_loss: 0.3495466113090515
recon_loss: 0.02855837158858776, dist_loss: 0.9413855075836182
recon_loss: 0.02855825237929821, dist_loss: 0.4237808585166931
recon_loss: 0.02855868637561798, dist_loss: 0.6212455630302429
recon_loss: 0.028556816279888153, dist_loss: 0.6827685832977295
recon_loss: 0.028557686135172844, dist_loss: 0.5026940107345581
recon_loss: 0.02855723537504673, dist_loss: 0.6632014513015747
recon_loss: 0.028555938974022865, dist_loss: 0.717705488204956
recon_loss: 0.02855687029659748, dist_loss: 0.5790826082229614
recon_loss: 0.028556019067764282, dist_loss: 0.4742991030216217
recon_loss: 0.02855508401989937, dist_loss: 0.8723810315132141
recon_loss: 0.028555607423186302, dist_loss: 0.44195556640625
recon_loss: 0.028554614633321762, dist_loss: 0.43263059854507446
recon_loss: 0.028554491698741913, dist_loss: 0.38905054330825806
recon_loss: 0.02855502814054489, dist_loss: 0.3875940442085266
recon_loss: 0.028553802520036697, dist_loss: 0.5718196630477905
recon_loss: 0.02855365164577961, dist_loss: 0.49906259775161743
recon_loss: 0.028553476557135582, dist_loss: 0.7396851778030396
recon_loss: 0.02855275198817253, dist_loss: 1.0771058797836304
recon_loss: 0.028552601113915443, dist_loss: 0.9250558614730835
recon_loss: 0.028552701696753502, dist_loss: 0.37259894609451294
recon_loss: 0.028552381321787834, dist_loss: 0.4779067039489746
recon_loss: 0.028552589938044548, dist_loss: 0.44374194741249084
recon_loss: 0.028552928939461708, dist_loss: 0.3677811026573181
recon_loss: 0.028553055599331856, dist_loss: 0.5258148908615112
recon_loss: 0.02855321392416954, dist_loss: 1.1182291507720947
recon_loss: 0.02855319157242775, dist_loss: 0.8045493364334106
recon_loss: 0.028552833944559097, dist_loss: 0.46046924591064453
recon_loss: 0.028553348034620285, dist_loss: 0.6494415998458862
recon_loss: 0.0285524670034647, dist_loss: 1.3325139284133911
recon_loss: 0.02855275198817253, dist_loss: 0.6728177070617676
recon_loss: 0.02855326049029827, dist_loss: 0.4583147168159485
recon_loss: 0.028552843257784843, dist_loss: 0.7877965569496155
recon_loss: 0.028553824871778488, dist_loss: 0.869625449180603
recon_loss: 0.028553174808621407, dist_loss: 0.9565561413764954
Pre-training Epoch 63:  73%|███████▎  | 268/367 [00:01<00:00, 157.62it/s]Pre-training Epoch 63:  77%|███████▋  | 284/367 [00:01<00:00, 157.94it/s]Pre-training Epoch 63:  82%|████████▏ | 300/367 [00:01<00:00, 157.68it/s]Pre-training Epoch 63:  86%|████████▌ | 316/367 [00:01<00:00, 152.29it/s]Pre-training Epoch 63:  90%|█████████ | 332/367 [00:02<00:00, 153.75it/s]Pre-training Epoch 63:  95%|█████████▍| 348/367 [00:02<00:00, 154.42it/s]Pre-training Epoch 63:  99%|█████████▉| 365/367 [00:02<00:00, 156.52it/s]Pre-training Epoch 63: 100%|██████████| 367/367 [00:02<00:00, 163.30it/s]
recon_loss: 0.028552979230880737, dist_loss: 0.7217555046081543
recon_loss: 0.02855309098958969, dist_loss: 0.5442343950271606
recon_loss: 0.02855241671204567, dist_loss: 0.645138144493103
recon_loss: 0.028552427887916565, dist_loss: 0.9547653794288635
recon_loss: 0.028552023693919182, dist_loss: 0.8047573566436768
recon_loss: 0.028551528230309486, dist_loss: 0.7584314346313477
recon_loss: 0.028551332652568817, dist_loss: 0.9281476736068726
recon_loss: 0.028551748022437096, dist_loss: 0.758463442325592
recon_loss: 0.0285523422062397, dist_loss: 0.7744605541229248
recon_loss: 0.02855309471487999, dist_loss: 0.785239577293396
recon_loss: 0.02855341136455536, dist_loss: 0.5181461572647095
recon_loss: 0.028554191812872887, dist_loss: 0.8656461238861084
recon_loss: 0.028555316850543022, dist_loss: 0.787854790687561
recon_loss: 0.028555558994412422, dist_loss: 0.5886306762695312
recon_loss: 0.02855530194938183, dist_loss: 0.5325751900672913
recon_loss: 0.028555821627378464, dist_loss: 0.404269278049469
recon_loss: 0.028555642813444138, dist_loss: 0.5732041001319885
recon_loss: 0.028555763885378838, dist_loss: 0.467385470867157
recon_loss: 0.0285558570176363, dist_loss: 0.7542159557342529
recon_loss: 0.02855398692190647, dist_loss: 0.36491110920906067
recon_loss: 0.028552988544106483, dist_loss: 0.5053846836090088
recon_loss: 0.028552351519465446, dist_loss: 1.161376953125
recon_loss: 0.028551049530506134, dist_loss: 0.494422972202301
recon_loss: 0.028550943359732628, dist_loss: 0.3691202402114868
recon_loss: 0.028550609946250916, dist_loss: 0.5131940841674805
recon_loss: 0.028550151735544205, dist_loss: 0.5037260055541992
recon_loss: 0.028551602736115456, dist_loss: 0.47675392031669617
recon_loss: 0.028552725911140442, dist_loss: 0.5759402513504028
recon_loss: 0.02855270728468895, dist_loss: 0.8924345374107361
recon_loss: 0.028553899377584457, dist_loss: 0.9568563103675842
recon_loss: 0.028554579243063927, dist_loss: 0.48757195472717285
recon_loss: 0.028555557131767273, dist_loss: 0.5996285676956177
recon_loss: 0.028556257486343384, dist_loss: 0.7148374915122986
recon_loss: 0.028555715456604958, dist_loss: 0.6735289096832275
recon_loss: 0.028554808348417282, dist_loss: 0.5074373483657837
recon_loss: 0.02855386771261692, dist_loss: 0.7554440498352051
recon_loss: 0.028552724048495293, dist_loss: 0.8631394505500793
recon_loss: 0.02855253778398037, dist_loss: 0.36799356341362
recon_loss: 0.028550991788506508, dist_loss: 0.722614586353302
recon_loss: 0.028550194576382637, dist_loss: 0.8964511156082153
recon_loss: 0.028549958020448685, dist_loss: 0.32720431685447693
recon_loss: 0.02854989655315876, dist_loss: 0.6557795405387878
recon_loss: 0.02855031192302704, dist_loss: 0.7060891389846802
recon_loss: 0.028550583869218826, dist_loss: 0.5504275560379028
recon_loss: 0.028550919145345688, dist_loss: 0.8582718968391418
recon_loss: 0.028550805523991585, dist_loss: 0.738900899887085
recon_loss: 0.028550397604703903, dist_loss: 0.7413182258605957
recon_loss: 0.02855049818754196, dist_loss: 0.6168516278266907
recon_loss: 0.028549831360578537, dist_loss: 0.8386949300765991
recon_loss: 0.028549598529934883, dist_loss: 0.4950118660926819
recon_loss: 0.028548957780003548, dist_loss: 0.49742788076400757
recon_loss: 0.028548432514071465, dist_loss: 0.5126367211341858
recon_loss: 0.02854843996465206, dist_loss: 0.6755828857421875
recon_loss: 0.02854759432375431, dist_loss: 0.5078796148300171
recon_loss: 0.02854740433394909, dist_loss: 0.4724029302597046
recon_loss: 0.02854766696691513, dist_loss: 0.5943621397018433
recon_loss: 0.02854686602950096, dist_loss: 0.6961719393730164
recon_loss: 0.02854723297059536, dist_loss: 0.8556193709373474
recon_loss: 0.028547709807753563, dist_loss: 0.4640943109989166
recon_loss: 0.02854650281369686, dist_loss: 0.528678297996521
recon_loss: 0.028546852990984917, dist_loss: 0.7271908521652222
recon_loss: 0.028547385707497597, dist_loss: 0.6512784361839294
recon_loss: 0.02854747325181961, dist_loss: 0.7928984761238098
recon_loss: 0.02854803204536438, dist_loss: 0.7953795194625854
recon_loss: 0.028547953814268112, dist_loss: 0.6898305416107178
recon_loss: 0.02854759804904461, dist_loss: 0.8606343865394592
recon_loss: 0.02854830026626587, dist_loss: 0.5009715557098389
recon_loss: 0.028548363596200943, dist_loss: 0.6858639717102051
recon_loss: 0.028548233211040497, dist_loss: 0.7622430920600891
recon_loss: 0.028548147529363632, dist_loss: 0.5689873695373535
recon_loss: 0.02854773961007595, dist_loss: 0.6270775198936462
recon_loss: 0.02854705974459648, dist_loss: 0.6711691617965698
recon_loss: 0.02854655683040619, dist_loss: 0.38757508993148804
recon_loss: 0.028545984998345375, dist_loss: 0.4486986994743347
recon_loss: 0.028545726090669632, dist_loss: 0.8937949538230896
recon_loss: 0.02854560688138008, dist_loss: 0.9458441734313965
recon_loss: 0.028546223416924477, dist_loss: 1.1884641647338867
recon_loss: 0.028547627851366997, dist_loss: 0.3026013970375061
recon_loss: 0.02854887582361698, dist_loss: 0.6671682596206665
recon_loss: 0.02854960411787033, dist_loss: 0.938100278377533
recon_loss: 0.028550131246447563, dist_loss: 0.59941565990448
recon_loss: 0.02855112962424755, dist_loss: 0.7072178721427917
recon_loss: 0.02855176478624344, dist_loss: 0.6467015743255615
recon_loss: 0.028551753610372543, dist_loss: 0.5972564816474915
recon_loss: 0.02855084277689457, dist_loss: 0.2795243263244629
recon_loss: 0.028549788519740105, dist_loss: 0.5721405744552612
recon_loss: 0.028548667207360268, dist_loss: 0.7039231061935425
recon_loss: 0.0285474993288517, dist_loss: 0.36499708890914917
recon_loss: 0.028546659275889397, dist_loss: 0.6681522727012634
recon_loss: 0.028546195477247238, dist_loss: 0.4854734241962433
recon_loss: 0.028545653447508812, dist_loss: 1.0046861171722412
recon_loss: 0.02854512631893158, dist_loss: 0.8800526857376099
recon_loss: 0.028544874861836433, dist_loss: 0.5240199565887451
recon_loss: 0.028543977066874504, dist_loss: 0.5818076133728027
recon_loss: 0.028543679043650627, dist_loss: 0.6356415748596191
recon_loss: 0.028543462976813316, dist_loss: 0.5953885912895203
recon_loss: 0.028543448075652122, dist_loss: 0.8348422050476074
recon_loss: 0.028543734923005104, dist_loss: 0.5563013553619385
recon_loss: 0.028543489053845406, dist_loss: 0.5149737596511841
recon_loss: 0.028543630614876747, dist_loss: 0.5579249858856201
recon_loss: 0.028543641790747643, dist_loss: 0.6466339826583862
recon_loss: 0.028543654829263687, dist_loss: 0.5276273488998413
recon_loss: 0.028544334694743156, dist_loss: 0.5126964449882507
recon_loss: 0.028544679284095764, dist_loss: 0.6246225833892822
recon_loss: 0.028544923290610313, dist_loss: 1.0196468830108643
recon_loss: 0.028545239940285683, dist_loss: 0.6787735223770142
recon_loss: 0.02854544296860695, dist_loss: 0.7789635062217712
recon_loss: 0.028545286506414413, dist_loss: 0.5839561820030212
recon_loss: 0.028545822948217392, dist_loss: 0.623589038848877
recon_loss: 0.028545886278152466, dist_loss: 0.7234266996383667
recon_loss: 0.028545890003442764, dist_loss: 0.7174827456474304
Pre-training Epoch 64:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 64:   4%|▍         | 16/367 [00:00<00:02, 156.63it/s]Pre-training Epoch 64:   9%|▉         | 33/367 [00:00<00:02, 158.87it/s]Pre-training Epoch 64:  13%|█▎        | 49/367 [00:00<00:02, 154.55it/s]Pre-training Epoch 64:  18%|█▊        | 65/367 [00:00<00:01, 154.13it/s]Pre-training Epoch 64:  22%|██▏       | 81/367 [00:00<00:01, 153.36it/s]Pre-training Epoch 64:  26%|██▋       | 97/367 [00:00<00:01, 152.60it/s]Pre-training Epoch 64:  31%|███       | 113/367 [00:00<00:01, 151.57it/s]recon_loss: 0.028545739129185677, dist_loss: 0.7493855953216553
recon_loss: 0.02854447439312935, dist_loss: 0.33139240741729736
recon_loss: 0.028544321656227112, dist_loss: 0.6194784641265869
recon_loss: 0.028543701395392418, dist_loss: 0.7860182523727417
recon_loss: 0.028542770072817802, dist_loss: 0.3609732389450073
recon_loss: 0.028542758896946907, dist_loss: 1.1052641868591309
recon_loss: 0.028542401269078255, dist_loss: 0.3985862135887146
recon_loss: 0.028541559353470802, dist_loss: 0.935792863368988
recon_loss: 0.028541840612888336, dist_loss: 0.6658068895339966
recon_loss: 0.028541773557662964, dist_loss: 0.48284661769866943
recon_loss: 0.02854239195585251, dist_loss: 1.0433228015899658
recon_loss: 0.028542878106236458, dist_loss: 0.4287784695625305
recon_loss: 0.02854304201900959, dist_loss: 0.6606659889221191
recon_loss: 0.02854391373693943, dist_loss: 0.3666599988937378
recon_loss: 0.0285439845174551, dist_loss: 0.6043291091918945
recon_loss: 0.028543677181005478, dist_loss: 0.7973828315734863
recon_loss: 0.028543779626488686, dist_loss: 0.6941490173339844
recon_loss: 0.028542952612042427, dist_loss: 0.8964406251907349
recon_loss: 0.028542304411530495, dist_loss: 0.3496835231781006
recon_loss: 0.02854207530617714, dist_loss: 0.3860045075416565
recon_loss: 0.028541324660182, dist_loss: 0.6103287935256958
recon_loss: 0.02854105457663536, dist_loss: 0.9681904911994934
recon_loss: 0.0285408403724432, dist_loss: 0.8233720064163208
recon_loss: 0.0285403560847044, dist_loss: 0.7148169279098511
recon_loss: 0.02854030579328537, dist_loss: 0.4810003638267517
recon_loss: 0.028540363535284996, dist_loss: 0.8070037364959717
recon_loss: 0.028540998697280884, dist_loss: 0.826054573059082
recon_loss: 0.028541065752506256, dist_loss: 0.44370585680007935
recon_loss: 0.028541037812829018, dist_loss: 0.658597469329834
recon_loss: 0.028541933745145798, dist_loss: 0.4696044921875
recon_loss: 0.028541626408696175, dist_loss: 0.4734884202480316
recon_loss: 0.028541583567857742, dist_loss: 0.615240752696991
recon_loss: 0.028541650623083115, dist_loss: 0.5934029817581177
recon_loss: 0.028541242703795433, dist_loss: 0.7916662693023682
recon_loss: 0.028540579602122307, dist_loss: 0.729413628578186
recon_loss: 0.02853994444012642, dist_loss: 0.7871626615524292
recon_loss: 0.028539516031742096, dist_loss: 0.5096427202224731
recon_loss: 0.028539130464196205, dist_loss: 0.44059664011001587
recon_loss: 0.028538649901747704, dist_loss: 0.6971479654312134
recon_loss: 0.028538312762975693, dist_loss: 0.5687848925590515
recon_loss: 0.028537794947624207, dist_loss: 0.7881292104721069
recon_loss: 0.02853764407336712, dist_loss: 0.6362431645393372
recon_loss: 0.028537562116980553, dist_loss: 0.6248290538787842
recon_loss: 0.028537699952721596, dist_loss: 0.6031234264373779
recon_loss: 0.028537707403302193, dist_loss: 0.7153644561767578
recon_loss: 0.028537239879369736, dist_loss: 0.8752390146255493
recon_loss: 0.0285368449985981, dist_loss: 0.558991551399231
recon_loss: 0.028536701574921608, dist_loss: 0.8688164949417114
recon_loss: 0.028536630794405937, dist_loss: 0.4920312166213989
recon_loss: 0.02853682078421116, dist_loss: 0.7197807431221008
recon_loss: 0.028537079691886902, dist_loss: 0.4195629358291626
recon_loss: 0.028536956757307053, dist_loss: 0.7398204803466797
recon_loss: 0.02853662706911564, dist_loss: 0.7630025148391724
recon_loss: 0.028535695746541023, dist_loss: 0.4878028631210327
recon_loss: 0.028535112738609314, dist_loss: 0.6714938282966614
recon_loss: 0.028535163030028343, dist_loss: 0.7241605520248413
recon_loss: 0.02853517048060894, dist_loss: 0.5794309377670288
recon_loss: 0.028535254299640656, dist_loss: 0.6025195121765137
recon_loss: 0.02853505313396454, dist_loss: 0.6743347644805908
recon_loss: 0.028534892946481705, dist_loss: 0.6382741332054138
recon_loss: 0.02853463590145111, dist_loss: 0.6723166704177856
recon_loss: 0.028534304350614548, dist_loss: 0.4570561647415161
recon_loss: 0.02853435091674328, dist_loss: 0.5315573811531067
recon_loss: 0.028534146025776863, dist_loss: 0.7218214273452759
recon_loss: 0.02853393740952015, dist_loss: 0.5299633145332336
recon_loss: 0.02853369526565075, dist_loss: 0.5096701383590698
recon_loss: 0.02853347361087799, dist_loss: 0.5530625581741333
recon_loss: 0.028533359989523888, dist_loss: 0.5779306888580322
recon_loss: 0.02853311225771904, dist_loss: 0.46552279591560364
recon_loss: 0.028532879427075386, dist_loss: 0.9487349390983582
recon_loss: 0.02853311225771904, dist_loss: 1.0093141794204712
recon_loss: 0.028533637523651123, dist_loss: 0.5064482092857361
recon_loss: 0.028533730655908585, dist_loss: 0.3964458703994751
recon_loss: 0.02853376418352127, dist_loss: 0.5093592405319214
recon_loss: 0.028533754870295525, dist_loss: 0.5039325952529907
recon_loss: 0.028533773496747017, dist_loss: 0.5285258293151855
recon_loss: 0.02853384241461754, dist_loss: 0.6351177096366882
recon_loss: 0.028533726930618286, dist_loss: 0.8117488622665405
recon_loss: 0.028533611446619034, dist_loss: 0.8199520111083984
recon_loss: 0.028533408418297768, dist_loss: 0.43862465023994446
recon_loss: 0.028533102944493294, dist_loss: 0.7990478277206421
recon_loss: 0.028533022850751877, dist_loss: 0.5150097012519836
recon_loss: 0.028533076867461205, dist_loss: 1.2853498458862305
recon_loss: 0.028533706441521645, dist_loss: 0.8612872362136841
recon_loss: 0.028534766286611557, dist_loss: 0.38549524545669556
recon_loss: 0.028535829856991768, dist_loss: 0.730129063129425
recon_loss: 0.028535963967442513, dist_loss: 0.9259650111198425
recon_loss: 0.028535814955830574, dist_loss: 0.9766074419021606
recon_loss: 0.028535975143313408, dist_loss: 0.512631893157959
recon_loss: 0.028536181896924973, dist_loss: 0.5919307470321655
recon_loss: 0.028536183759570122, dist_loss: 0.448019415140152
recon_loss: 0.02853560633957386, dist_loss: 0.8807361721992493
recon_loss: 0.028534527868032455, dist_loss: 0.7176371216773987
recon_loss: 0.028533468022942543, dist_loss: 0.5022791028022766
recon_loss: 0.028532318770885468, dist_loss: 0.7233208417892456
recon_loss: 0.028532177209854126, dist_loss: 0.7465143203735352
recon_loss: 0.028531739488244057, dist_loss: 0.642643928527832
recon_loss: 0.02853197604417801, dist_loss: 0.7522649168968201
recon_loss: 0.028533004224300385, dist_loss: 0.9828741550445557
recon_loss: 0.028534159064292908, dist_loss: 0.8080025911331177
recon_loss: 0.028535716235637665, dist_loss: 0.5757920145988464
recon_loss: 0.028537681326270103, dist_loss: 0.44255340099334717
recon_loss: 0.028538569808006287, dist_loss: 0.732833743095398
recon_loss: 0.028539936989545822, dist_loss: 0.5639533996582031
recon_loss: 0.02854003570973873, dist_loss: 0.7754751443862915
recon_loss: 0.02854018844664097, dist_loss: 0.3208206593990326
recon_loss: 0.028539681807160378, dist_loss: 0.366758793592453
recon_loss: 0.02853899449110031, dist_loss: 0.9762312769889832
recon_loss: 0.028537847101688385, dist_loss: 0.6202132105827332
recon_loss: 0.028536327183246613, dist_loss: 0.7724297642707825
recon_loss: 0.028534872457385063, dist_loss: 0.5371487140655518
recon_loss: 0.028533605858683586, dist_loss: 0.6922712326049805
recon_loss: 0.028532736003398895, dist_loss: 0.7294179201126099
recon_loss: 0.028532234951853752, dist_loss: 0.45748594403266907
recon_loss: 0.028531916439533234, dist_loss: 0.8808073997497559
recon_loss: 0.028531348332762718, dist_loss: 0.5442900657653809
recon_loss: 0.028530467301607132, dist_loss: 0.7062336802482605
recon_loss: 0.028530318289995193, dist_loss: 0.4897453486919403
recon_loss: 0.02852974832057953, dist_loss: 0.4281625747680664
recon_loss: 0.028529619798064232, dist_loss: 0.8794777393341064
recon_loss: 0.02852926217019558, dist_loss: 1.0660793781280518
recon_loss: 0.028528839349746704, dist_loss: 0.5701229572296143
recon_loss: 0.028528600931167603, dist_loss: 0.5761233568191528
recon_loss: 0.0285284835845232, dist_loss: 0.5139062404632568
recon_loss: 0.028528232127428055, dist_loss: 0.47821491956710815
recon_loss: 0.02852829545736313, dist_loss: 0.38304316997528076
recon_loss: 0.02852824702858925, dist_loss: 0.5559045076370239
recon_loss: 0.028528131544589996, dist_loss: 0.7399146556854248
Pre-training Epoch 64:  35%|███▌      | 129/367 [00:00<00:01, 151.27it/s]Pre-training Epoch 64:  40%|███▉      | 145/367 [00:00<00:01, 151.63it/s]Pre-training Epoch 64:  44%|████▍     | 161/367 [00:01<00:01, 151.87it/s]Pre-training Epoch 64:  48%|████▊     | 177/367 [00:01<00:01, 151.98it/s]Pre-training Epoch 64:  53%|█████▎    | 193/367 [00:01<00:01, 151.63it/s]Pre-training Epoch 64:  57%|█████▋    | 209/367 [00:01<00:01, 152.89it/s]Pre-training Epoch 64:  62%|██████▏   | 226/367 [00:01<00:00, 156.06it/s]Pre-training Epoch 64:  66%|██████▌   | 242/367 [00:01<00:00, 155.11it/s]recon_loss: 0.028528226539492607, dist_loss: 0.5779840350151062
recon_loss: 0.028528226539492607, dist_loss: 0.8396202325820923
recon_loss: 0.02852773480117321, dist_loss: 0.8039056062698364
recon_loss: 0.028527870774269104, dist_loss: 0.785678505897522
recon_loss: 0.028527813032269478, dist_loss: 0.870732843875885
recon_loss: 0.028527548536658287, dist_loss: 0.8138141632080078
recon_loss: 0.028528161346912384, dist_loss: 0.5002340078353882
recon_loss: 0.028527693822979927, dist_loss: 0.4629448652267456
recon_loss: 0.02852744236588478, dist_loss: 0.5904761552810669
recon_loss: 0.028527596965432167, dist_loss: 0.6722040176391602
recon_loss: 0.02852749265730381, dist_loss: 0.6355389356613159
recon_loss: 0.02852771058678627, dist_loss: 0.6295746564865112
recon_loss: 0.028527798131108284, dist_loss: 0.5813828706741333
recon_loss: 0.028527649119496346, dist_loss: 1.3060376644134521
recon_loss: 0.02852756157517433, dist_loss: 1.1738004684448242
recon_loss: 0.028527289628982544, dist_loss: 0.6952930688858032
recon_loss: 0.02852696366608143, dist_loss: 0.4304400384426117
recon_loss: 0.028526537120342255, dist_loss: 0.46973007917404175
recon_loss: 0.02852618880569935, dist_loss: 0.8089532852172852
recon_loss: 0.028525978326797485, dist_loss: 0.7866231799125671
recon_loss: 0.0285259410738945, dist_loss: 0.7742985486984253
recon_loss: 0.0285260658711195, dist_loss: 0.8401091694831848
recon_loss: 0.028526058420538902, dist_loss: 0.5327476263046265
recon_loss: 0.028526123613119125, dist_loss: 0.5227848887443542
recon_loss: 0.028526190668344498, dist_loss: 0.6017402410507202
recon_loss: 0.0285264253616333, dist_loss: 0.7433311343193054
recon_loss: 0.028526317328214645, dist_loss: 0.6956348419189453
recon_loss: 0.028526222333312035, dist_loss: 0.8507665395736694
recon_loss: 0.028526024892926216, dist_loss: 0.7988865375518799
recon_loss: 0.028525875881314278, dist_loss: 0.6235279440879822
recon_loss: 0.028525639325380325, dist_loss: 1.1369709968566895
recon_loss: 0.028525421395897865, dist_loss: 0.4061916470527649
recon_loss: 0.028525181114673615, dist_loss: 0.9099476337432861
recon_loss: 0.02852519042789936, dist_loss: 0.7866326570510864
recon_loss: 0.028526097536087036, dist_loss: 0.553820013999939
recon_loss: 0.028526922687888145, dist_loss: 0.3088797330856323
recon_loss: 0.028527725487947464, dist_loss: 0.5443466901779175
recon_loss: 0.028528248891234398, dist_loss: 0.8012440204620361
recon_loss: 0.028529688715934753, dist_loss: 0.4819800555706024
recon_loss: 0.028530318289995193, dist_loss: 0.7916128635406494
recon_loss: 0.028530413284897804, dist_loss: 0.6537529230117798
recon_loss: 0.02853117510676384, dist_loss: 0.7502872347831726
recon_loss: 0.028530173003673553, dist_loss: 0.5533081293106079
recon_loss: 0.028529301285743713, dist_loss: 1.4628534317016602
recon_loss: 0.028529295697808266, dist_loss: 1.065617322921753
recon_loss: 0.02852776274085045, dist_loss: 0.63421231508255
recon_loss: 0.02852770872414112, dist_loss: 0.4121464788913727
recon_loss: 0.028527118265628815, dist_loss: 0.9941356778144836
recon_loss: 0.028525466099381447, dist_loss: 0.6966877579689026
recon_loss: 0.02852601371705532, dist_loss: 0.7458766102790833
recon_loss: 0.028524750843644142, dist_loss: 0.48822808265686035
recon_loss: 0.028525011613965034, dist_loss: 0.6695876717567444
recon_loss: 0.02852478250861168, dist_loss: 0.5818290114402771
recon_loss: 0.02852407470345497, dist_loss: 0.25752806663513184
recon_loss: 0.028524400666356087, dist_loss: 0.7750171422958374
recon_loss: 0.02852393314242363, dist_loss: 0.6437754034996033
recon_loss: 0.02852378971874714, dist_loss: 0.875815212726593
recon_loss: 0.02852429822087288, dist_loss: 0.5440642237663269
recon_loss: 0.02852369099855423, dist_loss: 0.6817291975021362
recon_loss: 0.028523966670036316, dist_loss: 0.9559105634689331
recon_loss: 0.02852429822087288, dist_loss: 0.5510540008544922
recon_loss: 0.028523655608296394, dist_loss: 0.5451983213424683
recon_loss: 0.02852424420416355, dist_loss: 0.5221038460731506
recon_loss: 0.028523720800876617, dist_loss: 0.6881802082061768
recon_loss: 0.028523892164230347, dist_loss: 0.5702288150787354
recon_loss: 0.02852438949048519, dist_loss: 0.803746223449707
recon_loss: 0.028523754328489304, dist_loss: 0.45916348695755005
recon_loss: 0.028523864224553108, dist_loss: 0.7861647605895996
recon_loss: 0.0285235196352005, dist_loss: 0.8893996477127075
recon_loss: 0.028523698449134827, dist_loss: 0.8072969913482666
recon_loss: 0.028523510321974754, dist_loss: 0.5163000822067261
recon_loss: 0.028523165732622147, dist_loss: 0.38693493604660034
recon_loss: 0.02852294221520424, dist_loss: 0.5116601586341858
recon_loss: 0.02852242812514305, dist_loss: 0.7424938678741455
recon_loss: 0.028522063046693802, dist_loss: 0.6071829795837402
recon_loss: 0.02852189540863037, dist_loss: 0.6552277207374573
recon_loss: 0.02852141484618187, dist_loss: 1.215949296951294
recon_loss: 0.028521981090307236, dist_loss: 1.4017462730407715
recon_loss: 0.028522009029984474, dist_loss: 0.8301392793655396
recon_loss: 0.02852201834321022, dist_loss: 0.4662327468395233
recon_loss: 0.028522741049528122, dist_loss: 0.8525430560112
recon_loss: 0.028522934764623642, dist_loss: 0.4408760070800781
recon_loss: 0.02852325327694416, dist_loss: 0.5619683861732483
recon_loss: 0.028523553162813187, dist_loss: 0.56538987159729
recon_loss: 0.028524255380034447, dist_loss: 0.960373044013977
recon_loss: 0.028524495661258698, dist_loss: 0.5582493543624878
recon_loss: 0.028524456545710564, dist_loss: 0.5201722383499146
recon_loss: 0.028524111956357956, dist_loss: 0.7481799125671387
recon_loss: 0.028524020686745644, dist_loss: 0.7003629207611084
recon_loss: 0.028523962944746017, dist_loss: 0.796981930732727
recon_loss: 0.028523987159132957, dist_loss: 0.4973256587982178
recon_loss: 0.028524041175842285, dist_loss: 0.5549556612968445
recon_loss: 0.028523949906229973, dist_loss: 0.5882267951965332
recon_loss: 0.02852354384958744, dist_loss: 0.603472113609314
recon_loss: 0.02852301113307476, dist_loss: 0.5160735249519348
recon_loss: 0.028522439301013947, dist_loss: 0.4867446720600128
recon_loss: 0.028522051870822906, dist_loss: 0.561978816986084
recon_loss: 0.028521548956632614, dist_loss: 0.45813560485839844
recon_loss: 0.028521141037344933, dist_loss: 1.2739590406417847
recon_loss: 0.02852102927863598, dist_loss: 0.7357585430145264
recon_loss: 0.02852032519876957, dist_loss: 0.3076993525028229
recon_loss: 0.028520124033093452, dist_loss: 0.5713866949081421
recon_loss: 0.02852012775838375, dist_loss: 0.45606452226638794
recon_loss: 0.028519602492451668, dist_loss: 0.35988670587539673
recon_loss: 0.02851911261677742, dist_loss: 1.007849931716919
recon_loss: 0.028518812730908394, dist_loss: 0.7537512183189392
recon_loss: 0.028518706560134888, dist_loss: 0.7221851944923401
recon_loss: 0.028518859297037125, dist_loss: 0.40682268142700195
recon_loss: 0.028519058600068092, dist_loss: 0.5451308488845825
recon_loss: 0.02851954847574234, dist_loss: 0.676115870475769
recon_loss: 0.02852010726928711, dist_loss: 0.673880398273468
recon_loss: 0.028520848602056503, dist_loss: 0.5879548788070679
recon_loss: 0.028521502390503883, dist_loss: 0.5738877058029175
recon_loss: 0.028522305190563202, dist_loss: 0.9606002569198608
recon_loss: 0.028523392975330353, dist_loss: 0.6366347074508667
recon_loss: 0.028523948043584824, dist_loss: 0.34477850794792175
recon_loss: 0.028523916378617287, dist_loss: 0.5447419881820679
recon_loss: 0.02852349914610386, dist_loss: 0.6753671765327454
recon_loss: 0.028522826731204987, dist_loss: 0.728671669960022
recon_loss: 0.028522012755274773, dist_loss: 0.7587634921073914
recon_loss: 0.028521087020635605, dist_loss: 0.8715225458145142
recon_loss: 0.028520679101347923, dist_loss: 0.7055603265762329
recon_loss: 0.028520304709672928, dist_loss: 0.4993589520454407
recon_loss: 0.02851995639503002, dist_loss: 0.774080753326416
recon_loss: 0.02851996012032032, dist_loss: 0.7483694553375244
recon_loss: 0.028519369661808014, dist_loss: 0.3915967643260956
recon_loss: 0.0285192783921957, dist_loss: 0.6633869409561157
recon_loss: 0.02851882576942444, dist_loss: 0.6870365142822266
recon_loss: 0.02851906791329384, dist_loss: 0.630934476852417
Pre-training Epoch 64:  71%|███████   | 260/367 [00:01<00:00, 161.72it/s]Pre-training Epoch 64:  76%|███████▌  | 279/367 [00:01<00:00, 169.46it/s]Pre-training Epoch 64:  81%|████████  | 298/367 [00:01<00:00, 175.40it/s]Pre-training Epoch 64:  86%|████████▋ | 317/367 [00:01<00:00, 179.54it/s]Pre-training Epoch 64:  92%|█████████▏| 336/367 [00:02<00:00, 182.50it/s]Pre-training Epoch 64:  97%|█████████▋| 355/367 [00:02<00:00, 184.56it/s]Pre-training Epoch 64: 100%|██████████| 367/367 [00:02<00:00, 163.57it/s]
recon_loss: 0.02851918525993824, dist_loss: 0.6400208473205566
recon_loss: 0.02851874567568302, dist_loss: 0.547513484954834
recon_loss: 0.028518836945295334, dist_loss: 0.8759304881095886
recon_loss: 0.028518207371234894, dist_loss: 0.8017603754997253
recon_loss: 0.028518039733171463, dist_loss: 0.866004467010498
recon_loss: 0.02851872332394123, dist_loss: 0.3114660382270813
recon_loss: 0.02851809374988079, dist_loss: 0.5482944846153259
recon_loss: 0.02851828932762146, dist_loss: 0.4247129559516907
recon_loss: 0.02851797826588154, dist_loss: 0.9814045429229736
recon_loss: 0.028517605736851692, dist_loss: 1.0597302913665771
recon_loss: 0.02851736545562744, dist_loss: 0.7573832273483276
recon_loss: 0.028517412021756172, dist_loss: 0.7939364910125732
recon_loss: 0.02851715311408043, dist_loss: 0.4826595187187195
recon_loss: 0.02851753495633602, dist_loss: 0.5344059467315674
recon_loss: 0.028517326340079308, dist_loss: 0.5322465896606445
recon_loss: 0.02851708233356476, dist_loss: 1.032127022743225
recon_loss: 0.028517400845885277, dist_loss: 0.43979570269584656
recon_loss: 0.028516976162791252, dist_loss: 0.6324561834335327
recon_loss: 0.028517911210656166, dist_loss: 0.7103003263473511
recon_loss: 0.028518348932266235, dist_loss: 1.127396821975708
recon_loss: 0.02851809933781624, dist_loss: 0.4948577880859375
recon_loss: 0.02851876989006996, dist_loss: 0.46004718542099
recon_loss: 0.028517842292785645, dist_loss: 0.3290586769580841
recon_loss: 0.028517957776784897, dist_loss: 0.7000454068183899
recon_loss: 0.028518080711364746, dist_loss: 0.9115688800811768
recon_loss: 0.028517531231045723, dist_loss: 0.8322672247886658
recon_loss: 0.0285185556858778, dist_loss: 0.5272730588912964
recon_loss: 0.02851780690252781, dist_loss: 0.927484393119812
recon_loss: 0.0285168569535017, dist_loss: 0.5811727046966553
recon_loss: 0.028518497943878174, dist_loss: 0.40884125232696533
recon_loss: 0.028516478836536407, dist_loss: 0.5686078071594238
recon_loss: 0.028517676517367363, dist_loss: 1.0479819774627686
recon_loss: 0.02851869910955429, dist_loss: 1.2004115581512451
recon_loss: 0.028516722843050957, dist_loss: 0.4512559175491333
recon_loss: 0.02851860783994198, dist_loss: 0.40074804425239563
recon_loss: 0.0285183172672987, dist_loss: 0.7050513029098511
recon_loss: 0.028517894446849823, dist_loss: 0.6613962650299072
recon_loss: 0.02851969748735428, dist_loss: 0.36817142367362976
recon_loss: 0.028518326580524445, dist_loss: 0.7399763464927673
recon_loss: 0.028518637642264366, dist_loss: 0.803472101688385
recon_loss: 0.028519701212644577, dist_loss: 0.3942369818687439
recon_loss: 0.02851802296936512, dist_loss: 0.4967210590839386
recon_loss: 0.0285181887447834, dist_loss: 0.6978365182876587
recon_loss: 0.028518127277493477, dist_loss: 0.9785250425338745
recon_loss: 0.028516441583633423, dist_loss: 0.4708838164806366
recon_loss: 0.028517330065369606, dist_loss: 0.6276408433914185
recon_loss: 0.028515329584479332, dist_loss: 0.7336745262145996
recon_loss: 0.028514595702290535, dist_loss: 0.6882664561271667
recon_loss: 0.02851524017751217, dist_loss: 0.722619891166687
recon_loss: 0.028514012694358826, dist_loss: 0.6051473021507263
recon_loss: 0.02851543202996254, dist_loss: 0.7658464908599854
recon_loss: 0.028515445068478584, dist_loss: 0.7627562880516052
recon_loss: 0.028514627367258072, dist_loss: 1.339829444885254
recon_loss: 0.028515547513961792, dist_loss: 0.523249626159668
recon_loss: 0.02851429581642151, dist_loss: 0.42536765336990356
recon_loss: 0.028514448553323746, dist_loss: 0.5239137411117554
recon_loss: 0.02851470559835434, dist_loss: 0.43775373697280884
recon_loss: 0.028513874858617783, dist_loss: 0.7663819789886475
recon_loss: 0.028514478355646133, dist_loss: 0.5911279916763306
recon_loss: 0.028515079990029335, dist_loss: 0.6601537466049194
recon_loss: 0.028514103963971138, dist_loss: 0.7313218116760254
recon_loss: 0.028514090925455093, dist_loss: 0.822029709815979
recon_loss: 0.02851301245391369, dist_loss: 0.805623471736908
recon_loss: 0.02851322665810585, dist_loss: 0.6440859436988831
recon_loss: 0.028513900935649872, dist_loss: 0.39578723907470703
recon_loss: 0.02851250395178795, dist_loss: 0.6193857192993164
recon_loss: 0.02851293422281742, dist_loss: 0.8035838007926941
recon_loss: 0.028512518852949142, dist_loss: 0.8980412483215332
recon_loss: 0.02851138822734356, dist_loss: 0.4620785415172577
recon_loss: 0.028513172641396523, dist_loss: 0.9610247611999512
recon_loss: 0.028513271361589432, dist_loss: 0.8570289015769958
recon_loss: 0.02851376123726368, dist_loss: 0.5010208487510681
recon_loss: 0.02851494774222374, dist_loss: 0.8042823076248169
recon_loss: 0.02851318009197712, dist_loss: 0.485324889421463
recon_loss: 0.02851323038339615, dist_loss: 0.623018741607666
recon_loss: 0.028512554243206978, dist_loss: 0.36198174953460693
recon_loss: 0.02851133421063423, dist_loss: 0.7641328573226929
recon_loss: 0.02851160056889057, dist_loss: 0.8418020009994507
recon_loss: 0.028510939329862595, dist_loss: 0.8165926933288574
recon_loss: 0.028510531410574913, dist_loss: 0.7949889898300171
recon_loss: 0.02851126529276371, dist_loss: 0.42483556270599365
recon_loss: 0.028510473668575287, dist_loss: 0.756331205368042
recon_loss: 0.02851015329360962, dist_loss: 0.4893348217010498
recon_loss: 0.028510095551609993, dist_loss: 0.6550711393356323
recon_loss: 0.028509648516774178, dist_loss: 0.5364920496940613
recon_loss: 0.028509488329291344, dist_loss: 0.6455565690994263
recon_loss: 0.028509503230452538, dist_loss: 0.4892355799674988
recon_loss: 0.028509335592389107, dist_loss: 0.5320906639099121
recon_loss: 0.028509175404906273, dist_loss: 0.4930536150932312
recon_loss: 0.028508836403489113, dist_loss: 0.7282612323760986
recon_loss: 0.028508754447102547, dist_loss: 0.7254876494407654
recon_loss: 0.02850900962948799, dist_loss: 0.3915054202079773
recon_loss: 0.028509464114904404, dist_loss: 0.9371673464775085
recon_loss: 0.028509341180324554, dist_loss: 0.6932765245437622
recon_loss: 0.028508925810456276, dist_loss: 0.7090349197387695
recon_loss: 0.02850860357284546, dist_loss: 0.6837278604507446
recon_loss: 0.02850821614265442, dist_loss: 0.5064535140991211
recon_loss: 0.028508620336651802, dist_loss: 0.9672204852104187
recon_loss: 0.028508247807621956, dist_loss: 0.4813607335090637
recon_loss: 0.028508244082331657, dist_loss: 0.6181926131248474
recon_loss: 0.028508014976978302, dist_loss: 0.6795634627342224
recon_loss: 0.028506988659501076, dist_loss: 0.7055594325065613
recon_loss: 0.028507379814982414, dist_loss: 0.8773478269577026
recon_loss: 0.028507335111498833, dist_loss: 0.6161371469497681
recon_loss: 0.028508076444268227, dist_loss: 0.6489758491516113
recon_loss: 0.02850879728794098, dist_loss: 0.4415593445301056
recon_loss: 0.028508106246590614, dist_loss: 0.7786233425140381
recon_loss: 0.028508823364973068, dist_loss: 0.5618342161178589
recon_loss: 0.028508814051747322, dist_loss: 0.7222040295600891
recon_loss: 0.02850748598575592, dist_loss: 1.2573364973068237
Pre-training Epoch 65:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 65:   5%|▌         | 19/367 [00:00<00:01, 185.58it/s]Pre-training Epoch 65:  10%|█         | 38/367 [00:00<00:01, 187.43it/s]Pre-training Epoch 65:  16%|█▌        | 57/367 [00:00<00:01, 188.01it/s]Pre-training Epoch 65:  21%|██        | 76/367 [00:00<00:01, 188.37it/s]Pre-training Epoch 65:  26%|██▌       | 95/367 [00:00<00:01, 188.28it/s]Pre-training Epoch 65:  31%|███       | 114/367 [00:00<00:01, 188.37it/s]recon_loss: 0.028506731614470482, dist_loss: 0.5443894863128662
recon_loss: 0.028506187722086906, dist_loss: 0.6505941152572632
recon_loss: 0.02850586175918579, dist_loss: 0.5372699499130249
recon_loss: 0.02850569598376751, dist_loss: 0.7135626673698425
recon_loss: 0.028505517169833183, dist_loss: 0.3781735301017761
recon_loss: 0.028505699709057808, dist_loss: 0.40501856803894043
recon_loss: 0.02850586548447609, dist_loss: 0.48672547936439514
recon_loss: 0.028505990281701088, dist_loss: 0.39383092522621155
recon_loss: 0.02850627899169922, dist_loss: 0.43641600012779236
recon_loss: 0.028505953028798103, dist_loss: 0.8672631978988647
recon_loss: 0.02850526198744774, dist_loss: 0.8520667552947998
recon_loss: 0.028505584225058556, dist_loss: 0.47526663541793823
recon_loss: 0.0285057220607996, dist_loss: 0.7499876618385315
recon_loss: 0.028505271300673485, dist_loss: 0.9133163690567017
recon_loss: 0.028505675494670868, dist_loss: 0.7973309755325317
recon_loss: 0.028504854068160057, dist_loss: 0.7302923202514648
recon_loss: 0.02850472554564476, dist_loss: 0.4857282042503357
recon_loss: 0.02850535698235035, dist_loss: 0.9222620129585266
recon_loss: 0.028505757451057434, dist_loss: 0.49218273162841797
recon_loss: 0.028506027534604073, dist_loss: 0.6993915438652039
recon_loss: 0.028505707159638405, dist_loss: 0.6413990259170532
recon_loss: 0.02850460633635521, dist_loss: 0.6518744230270386
recon_loss: 0.028503695502877235, dist_loss: 0.7863706946372986
recon_loss: 0.028503572568297386, dist_loss: 0.7087901830673218
recon_loss: 0.028504125773906708, dist_loss: 0.7895938158035278
recon_loss: 0.028504401445388794, dist_loss: 0.7281912565231323
recon_loss: 0.028504490852355957, dist_loss: 1.0089454650878906
recon_loss: 0.02850421890616417, dist_loss: 0.39804506301879883
recon_loss: 0.028503229841589928, dist_loss: 0.7721706032752991
recon_loss: 0.028502652421593666, dist_loss: 0.5042598247528076
recon_loss: 0.02850286103785038, dist_loss: 0.45913803577423096
recon_loss: 0.02850346639752388, dist_loss: 0.5194904804229736
recon_loss: 0.02850380912423134, dist_loss: 0.6990557909011841
recon_loss: 0.028503721579909325, dist_loss: 0.48557227849960327
recon_loss: 0.028503084555268288, dist_loss: 0.6998685598373413
recon_loss: 0.028502780944108963, dist_loss: 0.44361060857772827
recon_loss: 0.02850283496081829, dist_loss: 0.6777069568634033
recon_loss: 0.028503311797976494, dist_loss: 0.7457600831985474
recon_loss: 0.02850372903048992, dist_loss: 0.5775209665298462
recon_loss: 0.028503786772489548, dist_loss: 0.6253945827484131
recon_loss: 0.02850368060171604, dist_loss: 0.3464410901069641
recon_loss: 0.028503619134426117, dist_loss: 0.8799645900726318
recon_loss: 0.028503764420747757, dist_loss: 0.45801037549972534
recon_loss: 0.02850344590842724, dist_loss: 0.44573408365249634
recon_loss: 0.02850307710468769, dist_loss: 0.8117872476577759
recon_loss: 0.02850251831114292, dist_loss: 0.7171883583068848
recon_loss: 0.028502080589532852, dist_loss: 0.39931491017341614
recon_loss: 0.028502032160758972, dist_loss: 0.6158128976821899
recon_loss: 0.028501631692051888, dist_loss: 0.7483508586883545
recon_loss: 0.02850158140063286, dist_loss: 1.1868541240692139
recon_loss: 0.028501272201538086, dist_loss: 0.34634554386138916
recon_loss: 0.028501015156507492, dist_loss: 0.5151835680007935
recon_loss: 0.028500739485025406, dist_loss: 0.6778519153594971
recon_loss: 0.028500735759735107, dist_loss: 0.5993000268936157
recon_loss: 0.02850085124373436, dist_loss: 1.080626368522644
recon_loss: 0.028500638902187347, dist_loss: 0.41445207595825195
recon_loss: 0.02850019559264183, dist_loss: 0.6789730191230774
recon_loss: 0.028499847277998924, dist_loss: 0.7641621828079224
recon_loss: 0.028499895706772804, dist_loss: 0.586097776889801
recon_loss: 0.0284997820854187, dist_loss: 0.43914663791656494
recon_loss: 0.0284995436668396, dist_loss: 0.9213038682937622
recon_loss: 0.028499357402324677, dist_loss: 0.976669192314148
recon_loss: 0.028499281033873558, dist_loss: 0.36009126901626587
recon_loss: 0.028499238193035126, dist_loss: 0.5947892665863037
recon_loss: 0.028499241918325424, dist_loss: 0.32778263092041016
recon_loss: 0.028499387204647064, dist_loss: 0.3966568112373352
recon_loss: 0.028499500826001167, dist_loss: 0.4201385974884033
recon_loss: 0.028499610722064972, dist_loss: 0.44680556654930115
recon_loss: 0.028500068932771683, dist_loss: 0.5064070820808411
recon_loss: 0.028500432148575783, dist_loss: 0.6089310646057129
recon_loss: 0.028499914333224297, dist_loss: 0.34000667929649353
recon_loss: 0.02850024588406086, dist_loss: 0.6710494756698608
recon_loss: 0.02850007265806198, dist_loss: 0.5682883262634277
recon_loss: 0.028500080108642578, dist_loss: 0.4551318883895874
recon_loss: 0.028499973937869072, dist_loss: 1.0339903831481934
recon_loss: 0.02849939465522766, dist_loss: 1.405893087387085
recon_loss: 0.028499526903033257, dist_loss: 0.6194585561752319
recon_loss: 0.028499895706772804, dist_loss: 0.46439769864082336
recon_loss: 0.02850041724741459, dist_loss: 1.0739712715148926
recon_loss: 0.028500206768512726, dist_loss: 0.8005774617195129
recon_loss: 0.028500134125351906, dist_loss: 0.5748443603515625
recon_loss: 0.028500614687800407, dist_loss: 0.7050868272781372
recon_loss: 0.028499560430645943, dist_loss: 0.4767113924026489
recon_loss: 0.028499433770775795, dist_loss: 0.626162052154541
recon_loss: 0.028499169275164604, dist_loss: 0.4510217010974884
recon_loss: 0.028499314561486244, dist_loss: 0.8629579544067383
recon_loss: 0.028499886393547058, dist_loss: 0.6164458990097046
recon_loss: 0.028499964624643326, dist_loss: 0.5370802283287048
recon_loss: 0.02849995531141758, dist_loss: 1.1803181171417236
recon_loss: 0.02849993295967579, dist_loss: 1.1519609689712524
recon_loss: 0.028499661013484, dist_loss: 0.8014308214187622
recon_loss: 0.02849969081580639, dist_loss: 0.7423800230026245
recon_loss: 0.028499577194452286, dist_loss: 1.197715401649475
recon_loss: 0.028499143198132515, dist_loss: 0.4452414810657501
recon_loss: 0.028499003499746323, dist_loss: 1.025688886642456
recon_loss: 0.028498811647295952, dist_loss: 0.5818725824356079
recon_loss: 0.02849843166768551, dist_loss: 0.6607236266136169
recon_loss: 0.028498610481619835, dist_loss: 0.6612813472747803
recon_loss: 0.028498273342847824, dist_loss: 0.8064278364181519
recon_loss: 0.02849799022078514, dist_loss: 0.3593211770057678
recon_loss: 0.028498152270913124, dist_loss: 0.39349788427352905
recon_loss: 0.028497466817498207, dist_loss: 0.6094109416007996
recon_loss: 0.028497545048594475, dist_loss: 1.1606972217559814
recon_loss: 0.02849738672375679, dist_loss: 0.5218510627746582
recon_loss: 0.02849726751446724, dist_loss: 0.6595758199691772
recon_loss: 0.02849734202027321, dist_loss: 0.516135036945343
recon_loss: 0.028497420251369476, dist_loss: 0.5480496883392334
recon_loss: 0.028497476130723953, dist_loss: 0.26286929845809937
recon_loss: 0.028497666120529175, dist_loss: 0.4400360584259033
recon_loss: 0.028498195111751556, dist_loss: 0.7015263438224792
recon_loss: 0.02849864400923252, dist_loss: 0.5874264240264893
recon_loss: 0.02849908545613289, dist_loss: 0.547164797782898
recon_loss: 0.028498975560069084, dist_loss: 0.6224982738494873
recon_loss: 0.028498737141489983, dist_loss: 0.7827385663986206
recon_loss: 0.028498109430074692, dist_loss: 0.7368334531784058
recon_loss: 0.028497768566012383, dist_loss: 0.3967364728450775
recon_loss: 0.028497736901044846, dist_loss: 0.5657123923301697
recon_loss: 0.028497209772467613, dist_loss: 0.5027732253074646
recon_loss: 0.02849702350795269, dist_loss: 0.7398366928100586
recon_loss: 0.02849697694182396, dist_loss: 1.0343425273895264
recon_loss: 0.02849702164530754, dist_loss: 0.8683483600616455
recon_loss: 0.02849714830517769, dist_loss: 0.6538801193237305
recon_loss: 0.028497295454144478, dist_loss: 0.7325851321220398
recon_loss: 0.02849687822163105, dist_loss: 0.9130980968475342
recon_loss: 0.02849634736776352, dist_loss: 0.7501708269119263
recon_loss: 0.028495972976088524, dist_loss: 0.5943318009376526
recon_loss: 0.02849564142525196, dist_loss: 0.4735187292098999
recon_loss: 0.0284959077835083, dist_loss: 0.9224745035171509
Pre-training Epoch 65:  36%|███▌      | 133/367 [00:00<00:01, 188.58it/s]Pre-training Epoch 65:  41%|████▏     | 152/367 [00:00<00:01, 188.79it/s]Pre-training Epoch 65:  47%|████▋     | 171/367 [00:00<00:01, 188.94it/s]Pre-training Epoch 65:  52%|█████▏    | 190/367 [00:01<00:00, 188.52it/s]Pre-training Epoch 65:  57%|█████▋    | 209/367 [00:01<00:00, 188.73it/s]Pre-training Epoch 65:  62%|██████▏   | 228/367 [00:01<00:00, 188.79it/s]Pre-training Epoch 65:  67%|██████▋   | 247/367 [00:01<00:00, 188.95it/s]recon_loss: 0.028496338054537773, dist_loss: 1.048799991607666
recon_loss: 0.028496326878666878, dist_loss: 0.6165534853935242
recon_loss: 0.028495943173766136, dist_loss: 0.7958487272262573
recon_loss: 0.028495265170931816, dist_loss: 0.7898590564727783
recon_loss: 0.028495093807578087, dist_loss: 0.5569977760314941
recon_loss: 0.028495335951447487, dist_loss: 0.42835408449172974
recon_loss: 0.028495879843831062, dist_loss: 0.44301754236221313
recon_loss: 0.02849622629582882, dist_loss: 0.5516573190689087
recon_loss: 0.02849561721086502, dist_loss: 0.6104207634925842
recon_loss: 0.028495492413640022, dist_loss: 0.6037747859954834
recon_loss: 0.02849573642015457, dist_loss: 0.7476310133934021
recon_loss: 0.028495414182543755, dist_loss: 0.3190602660179138
recon_loss: 0.0284963920712471, dist_loss: 0.5313161015510559
recon_loss: 0.02849620394408703, dist_loss: 0.8354573845863342
recon_loss: 0.028495855629444122, dist_loss: 0.5893041491508484
recon_loss: 0.028495177626609802, dist_loss: 0.8147145509719849
recon_loss: 0.028494305908679962, dist_loss: 0.6103653907775879
recon_loss: 0.02849351242184639, dist_loss: 0.789259672164917
recon_loss: 0.028492994606494904, dist_loss: 0.6518245339393616
recon_loss: 0.028492774814367294, dist_loss: 0.9115492105484009
recon_loss: 0.028493059799075127, dist_loss: 0.5981556177139282
recon_loss: 0.02849327214062214, dist_loss: 0.39141616225242615
recon_loss: 0.028493011370301247, dist_loss: 0.3040492534637451
recon_loss: 0.0284927599132061, dist_loss: 0.49051231145858765
recon_loss: 0.028492698445916176, dist_loss: 0.7823683023452759
recon_loss: 0.028493409976363182, dist_loss: 0.8772814869880676
recon_loss: 0.0284944549202919, dist_loss: 0.5636279582977295
recon_loss: 0.028494980186223984, dist_loss: 0.6371976137161255
recon_loss: 0.028495315462350845, dist_loss: 0.8269996047019958
recon_loss: 0.028495434671640396, dist_loss: 0.5230380296707153
recon_loss: 0.02849496342241764, dist_loss: 0.9689740538597107
recon_loss: 0.02849489450454712, dist_loss: 0.6560061573982239
recon_loss: 0.02849511429667473, dist_loss: 0.4829377830028534
recon_loss: 0.028495226055383682, dist_loss: 0.5606558918952942
recon_loss: 0.028494838625192642, dist_loss: 0.5481199026107788
recon_loss: 0.028494466096162796, dist_loss: 0.7799683809280396
recon_loss: 0.02849586308002472, dist_loss: 0.347694993019104
recon_loss: 0.028497913852334023, dist_loss: 0.9223518371582031
recon_loss: 0.02849985659122467, dist_loss: 0.9197566509246826
recon_loss: 0.028500257059931755, dist_loss: 0.5166333317756653
recon_loss: 0.028498558327555656, dist_loss: 1.5360724925994873
recon_loss: 0.02849772572517395, dist_loss: 0.5261861681938171
recon_loss: 0.0284974817186594, dist_loss: 0.8966128826141357
recon_loss: 0.02849733829498291, dist_loss: 0.6043290495872498
recon_loss: 0.02849670499563217, dist_loss: 0.6407027244567871
recon_loss: 0.028495153412222862, dist_loss: 0.9520062208175659
recon_loss: 0.028493152931332588, dist_loss: 0.8847501277923584
recon_loss: 0.028492093086242676, dist_loss: 0.5237970352172852
recon_loss: 0.02849213406443596, dist_loss: 1.2456878423690796
recon_loss: 0.028492780402302742, dist_loss: 0.8484320640563965
recon_loss: 0.028492972254753113, dist_loss: 0.5995343923568726
recon_loss: 0.028493132442235947, dist_loss: 0.27446866035461426
recon_loss: 0.028493603691458702, dist_loss: 1.0211212635040283
recon_loss: 0.028494035825133324, dist_loss: 0.4020869731903076
recon_loss: 0.028494905680418015, dist_loss: 0.393282413482666
recon_loss: 0.028495704755187035, dist_loss: 0.9888697862625122
recon_loss: 0.028496483340859413, dist_loss: 0.8030238151550293
recon_loss: 0.02849785052239895, dist_loss: 0.8270800709724426
recon_loss: 0.02849830873310566, dist_loss: 0.6343066096305847
recon_loss: 0.028498424217104912, dist_loss: 0.41302621364593506
recon_loss: 0.028499102219939232, dist_loss: 0.8174659013748169
recon_loss: 0.028499292209744453, dist_loss: 0.35580548644065857
recon_loss: 0.028499262407422066, dist_loss: 0.5162204504013062
recon_loss: 0.028498338535428047, dist_loss: 0.5911458134651184
recon_loss: 0.02849707379937172, dist_loss: 0.7706389427185059
recon_loss: 0.028495902195572853, dist_loss: 0.43424028158187866
recon_loss: 0.028495486825704575, dist_loss: 0.5110613107681274
recon_loss: 0.028494928032159805, dist_loss: 0.7289553880691528
recon_loss: 0.028495702892541885, dist_loss: 1.162969946861267
recon_loss: 0.028495240956544876, dist_loss: 0.7268160581588745
recon_loss: 0.028493531048297882, dist_loss: 0.5863000154495239
recon_loss: 0.028491901233792305, dist_loss: 0.3835636079311371
recon_loss: 0.028491200879216194, dist_loss: 0.6208494901657104
recon_loss: 0.0284910649061203, dist_loss: 0.6903150677680969
recon_loss: 0.028490837663412094, dist_loss: 0.4935767352581024
recon_loss: 0.028490355238318443, dist_loss: 1.3172435760498047
recon_loss: 0.028489822521805763, dist_loss: 0.5972573757171631
recon_loss: 0.028489576652646065, dist_loss: 0.7196557521820068
recon_loss: 0.02849017269909382, dist_loss: 0.5253745913505554
recon_loss: 0.028490668162703514, dist_loss: 0.6578447818756104
recon_loss: 0.02849145606160164, dist_loss: 0.8572200536727905
recon_loss: 0.028491931036114693, dist_loss: 0.6678866147994995
recon_loss: 0.028491636738181114, dist_loss: 0.5386686325073242
recon_loss: 0.02849172241985798, dist_loss: 0.7629501819610596
recon_loss: 0.028491701930761337, dist_loss: 1.1230087280273438
recon_loss: 0.0284916702657938, dist_loss: 0.4262639880180359
recon_loss: 0.028490982949733734, dist_loss: 0.6314471960067749
recon_loss: 0.02849002741277218, dist_loss: 0.5140955448150635
recon_loss: 0.028489429503679276, dist_loss: 0.7780330181121826
recon_loss: 0.028488658368587494, dist_loss: 0.5882129669189453
recon_loss: 0.02848833054304123, dist_loss: 0.4412456750869751
recon_loss: 0.0284877959638834, dist_loss: 0.5407329797744751
recon_loss: 0.02848757430911064, dist_loss: 0.6294981241226196
recon_loss: 0.02848714403808117, dist_loss: 0.7867012023925781
recon_loss: 0.028486840426921844, dist_loss: 0.3696326017379761
recon_loss: 0.02848673053085804, dist_loss: 0.41209590435028076
recon_loss: 0.028486624360084534, dist_loss: 0.8556187748908997
recon_loss: 0.02848651446402073, dist_loss: 0.4091554284095764
recon_loss: 0.028486425057053566, dist_loss: 0.30457693338394165
recon_loss: 0.028486158698797226, dist_loss: 0.5955464839935303
recon_loss: 0.028485948219895363, dist_loss: 0.4673757553100586
recon_loss: 0.028485804796218872, dist_loss: 0.7921931743621826
recon_loss: 0.028485558927059174, dist_loss: 0.43766671419143677
recon_loss: 0.028485199436545372, dist_loss: 0.5943179726600647
recon_loss: 0.02848534844815731, dist_loss: 0.6629937887191772
recon_loss: 0.028485175222158432, dist_loss: 0.5582695007324219
recon_loss: 0.028485015034675598, dist_loss: 0.9660780429840088
recon_loss: 0.028485309332609177, dist_loss: 0.29776209592819214
recon_loss: 0.028484424576163292, dist_loss: 0.8957326412200928
recon_loss: 0.028484756126999855, dist_loss: 0.8988118171691895
recon_loss: 0.028484966605901718, dist_loss: 0.34214287996292114
recon_loss: 0.028483865782618523, dist_loss: 1.2311110496520996
recon_loss: 0.028484292328357697, dist_loss: 0.4764140248298645
recon_loss: 0.028484195470809937, dist_loss: 0.843897819519043
recon_loss: 0.0284845232963562, dist_loss: 0.675540566444397
recon_loss: 0.02848474495112896, dist_loss: 0.46910932660102844
recon_loss: 0.028484521433711052, dist_loss: 0.887930691242218
recon_loss: 0.028484445065259933, dist_loss: 0.9538382291793823
recon_loss: 0.02848445437848568, dist_loss: 1.0547306537628174
recon_loss: 0.02848431095480919, dist_loss: 0.7624142169952393
recon_loss: 0.028484715148806572, dist_loss: 0.7734547257423401
recon_loss: 0.028484085574746132, dist_loss: 0.6751223206520081
recon_loss: 0.02848285436630249, dist_loss: 0.6919457316398621
recon_loss: 0.02848300151526928, dist_loss: 0.49270427227020264
recon_loss: 0.02848273329436779, dist_loss: 0.7601727247238159
recon_loss: 0.0284829530864954, dist_loss: 1.0799485445022583
recon_loss: 0.028482569381594658, dist_loss: 0.48683321475982666
recon_loss: 0.028482364490628242, dist_loss: 0.28301262855529785
Pre-training Epoch 65:  72%|███████▏  | 266/367 [00:01<00:00, 188.58it/s]Pre-training Epoch 65:  78%|███████▊  | 285/367 [00:01<00:00, 187.94it/s]Pre-training Epoch 65:  83%|████████▎ | 304/367 [00:01<00:00, 188.08it/s]Pre-training Epoch 65:  88%|████████▊ | 323/367 [00:01<00:00, 188.19it/s]Pre-training Epoch 65:  93%|█████████▎| 342/367 [00:01<00:00, 188.34it/s]Pre-training Epoch 65:  98%|█████████▊| 361/367 [00:01<00:00, 188.58it/s]Pre-training Epoch 65: 100%|██████████| 367/367 [00:01<00:00, 187.79it/s]
recon_loss: 0.028482893481850624, dist_loss: 0.5087509155273438
recon_loss: 0.02848348580300808, dist_loss: 0.6409450769424438
recon_loss: 0.028484666720032692, dist_loss: 0.642856240272522
recon_loss: 0.02848520129919052, dist_loss: 0.4135615825653076
recon_loss: 0.02848462201654911, dist_loss: 0.5551012754440308
recon_loss: 0.028484728187322617, dist_loss: 0.4763612747192383
recon_loss: 0.02848450280725956, dist_loss: 0.5727344751358032
recon_loss: 0.028484400361776352, dist_loss: 1.0125114917755127
recon_loss: 0.028484540060162544, dist_loss: 0.7517787218093872
recon_loss: 0.028483614325523376, dist_loss: 0.4364604651927948
recon_loss: 0.02848302200436592, dist_loss: 0.2723042964935303
recon_loss: 0.02848220244050026, dist_loss: 0.4367624521255493
recon_loss: 0.028481798246502876, dist_loss: 0.8730285167694092
recon_loss: 0.028482679277658463, dist_loss: 1.0619726181030273
recon_loss: 0.028483159840106964, dist_loss: 0.6851904392242432
recon_loss: 0.0284848865121603, dist_loss: 0.7458807229995728
recon_loss: 0.028486311435699463, dist_loss: 0.44217270612716675
recon_loss: 0.028486205264925957, dist_loss: 0.8825279474258423
recon_loss: 0.028485482558608055, dist_loss: 0.7452619075775146
recon_loss: 0.028485547751188278, dist_loss: 1.3024933338165283
recon_loss: 0.028485115617513657, dist_loss: 0.5258309841156006
recon_loss: 0.02848447859287262, dist_loss: 0.9505744576454163
recon_loss: 0.028483552858233452, dist_loss: 0.5117397308349609
recon_loss: 0.028482671827077866, dist_loss: 0.8472796082496643
recon_loss: 0.02848225273191929, dist_loss: 0.5927503108978271
recon_loss: 0.028482096269726753, dist_loss: 0.7261219024658203
recon_loss: 0.0284818634390831, dist_loss: 0.9714287519454956
recon_loss: 0.028481917455792427, dist_loss: 0.37549924850463867
recon_loss: 0.028481774032115936, dist_loss: 0.4095321297645569
recon_loss: 0.028481198474764824, dist_loss: 0.6978980302810669
recon_loss: 0.028480645269155502, dist_loss: 0.5008009672164917
recon_loss: 0.028480231761932373, dist_loss: 0.5553848743438721
recon_loss: 0.02848060242831707, dist_loss: 0.8247343301773071
recon_loss: 0.02848212420940399, dist_loss: 0.35450541973114014
recon_loss: 0.028481971472501755, dist_loss: 0.7389534115791321
recon_loss: 0.028482621535658836, dist_loss: 0.297676146030426
recon_loss: 0.028482967987656593, dist_loss: 0.9199956059455872
recon_loss: 0.028485869988799095, dist_loss: 0.4325007498264313
recon_loss: 0.028487667441368103, dist_loss: 0.38235172629356384
recon_loss: 0.02848917618393898, dist_loss: 0.6726425886154175
recon_loss: 0.02849043533205986, dist_loss: 0.8472483158111572
recon_loss: 0.028488706797361374, dist_loss: 0.34658801555633545
recon_loss: 0.028487764298915863, dist_loss: 0.5782486796379089
recon_loss: 0.028485648334026337, dist_loss: 0.4828583598136902
recon_loss: 0.02848300151526928, dist_loss: 0.7834146022796631
recon_loss: 0.028482655063271523, dist_loss: 0.9169872999191284
recon_loss: 0.02848176471889019, dist_loss: 1.0902034044265747
recon_loss: 0.028482014313340187, dist_loss: 0.626885175704956
recon_loss: 0.028482474386692047, dist_loss: 0.5964277982711792
recon_loss: 0.02848118171095848, dist_loss: 0.803036093711853
recon_loss: 0.02848011441528797, dist_loss: 0.5574307441711426
recon_loss: 0.028479712083935738, dist_loss: 0.4022876024246216
recon_loss: 0.02847953885793686, dist_loss: 0.5206671953201294
recon_loss: 0.02848011441528797, dist_loss: 0.6095142960548401
recon_loss: 0.02848024293780327, dist_loss: 0.7113123536109924
recon_loss: 0.02847965620458126, dist_loss: 0.5508942604064941
recon_loss: 0.028479119762778282, dist_loss: 0.38208022713661194
recon_loss: 0.028478678315877914, dist_loss: 0.49193045496940613
recon_loss: 0.02847879007458687, dist_loss: 0.5974531173706055
recon_loss: 0.02847914770245552, dist_loss: 1.2241061925888062
recon_loss: 0.02847871743142605, dist_loss: 1.2177238464355469
recon_loss: 0.02847851999104023, dist_loss: 0.8931874632835388
recon_loss: 0.028478015214204788, dist_loss: 0.7048807144165039
recon_loss: 0.028477691113948822, dist_loss: 0.5504971742630005
recon_loss: 0.02847772277891636, dist_loss: 0.8457863926887512
recon_loss: 0.02847825549542904, dist_loss: 0.537020206451416
recon_loss: 0.028479078784585, dist_loss: 1.4742512702941895
recon_loss: 0.028479479253292084, dist_loss: 0.47422516345977783
recon_loss: 0.02847965992987156, dist_loss: 0.8628281354904175
recon_loss: 0.028479697182774544, dist_loss: 0.4169820547103882
recon_loss: 0.02847967855632305, dist_loss: 0.7506751418113708
recon_loss: 0.028480006381869316, dist_loss: 0.5063781142234802
recon_loss: 0.028480594977736473, dist_loss: 0.5952185988426208
recon_loss: 0.028480319306254387, dist_loss: 0.32906121015548706
recon_loss: 0.028479894623160362, dist_loss: 0.558316171169281
recon_loss: 0.02847902849316597, dist_loss: 0.6032923460006714
recon_loss: 0.028478436172008514, dist_loss: 1.2742716073989868
recon_loss: 0.0284785944968462, dist_loss: 0.9360822439193726
recon_loss: 0.02847830206155777, dist_loss: 0.32670071721076965
recon_loss: 0.028478261083364487, dist_loss: 0.40874552726745605
recon_loss: 0.028477797284722328, dist_loss: 0.5561109781265259
recon_loss: 0.028477486222982407, dist_loss: 0.8081268072128296
recon_loss: 0.02847812883555889, dist_loss: 0.5674526691436768
recon_loss: 0.028478587046265602, dist_loss: 0.7754513025283813
recon_loss: 0.028479812666773796, dist_loss: 0.6894100904464722
recon_loss: 0.02848014608025551, dist_loss: 0.8342247009277344
recon_loss: 0.028479399159550667, dist_loss: 0.5421761870384216
recon_loss: 0.028479604050517082, dist_loss: 0.7097170352935791
recon_loss: 0.02847990393638611, dist_loss: 0.8735499382019043
recon_loss: 0.028480397537350655, dist_loss: 0.7078143358230591
recon_loss: 0.028480419889092445, dist_loss: 0.920579195022583
recon_loss: 0.028479885309934616, dist_loss: 0.7382980585098267
recon_loss: 0.028479624539613724, dist_loss: 0.6781556606292725
recon_loss: 0.028479179367423058, dist_loss: 1.3620026111602783
recon_loss: 0.02847920171916485, dist_loss: 0.9120027422904968
recon_loss: 0.02847774513065815, dist_loss: 0.3915683627128601
recon_loss: 0.028477268293499947, dist_loss: 1.1151221990585327
recon_loss: 0.02847612462937832, dist_loss: 0.5007275342941284
recon_loss: 0.028475560247898102, dist_loss: 0.4190846383571625
recon_loss: 0.02847527153789997, dist_loss: 0.4887116551399231
recon_loss: 0.028474921360611916, dist_loss: 0.8383711576461792
recon_loss: 0.028474856168031693, dist_loss: 0.9348359704017639
recon_loss: 0.028474697843194008, dist_loss: 0.2520255446434021
recon_loss: 0.028474651277065277, dist_loss: 0.7507689595222473
recon_loss: 0.02847481518983841, dist_loss: 0.4788029193878174
recon_loss: 0.028474798426032066, dist_loss: 0.9829703569412231
recon_loss: 0.028475133702158928, dist_loss: 0.5913833379745483
recon_loss: 0.028475536033511162, dist_loss: 0.5344433784484863
recon_loss: 0.028475873172283173, dist_loss: 0.48476946353912354
recon_loss: 0.02847621962428093, dist_loss: 0.6133840084075928
recon_loss: 0.028476156294345856, dist_loss: 1.0536102056503296
Pre-training Epoch 66:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 66:   4%|▍         | 16/367 [00:00<00:02, 156.33it/s]Pre-training Epoch 66:   9%|▊         | 32/367 [00:00<00:02, 156.83it/s]Pre-training Epoch 66:  13%|█▎        | 48/367 [00:00<00:02, 157.59it/s]Pre-training Epoch 66:  18%|█▊        | 65/367 [00:00<00:01, 159.44it/s]Pre-training Epoch 66:  22%|██▏       | 81/367 [00:00<00:01, 158.56it/s]Pre-training Epoch 66:  27%|██▋       | 98/367 [00:00<00:01, 160.55it/s]Pre-training Epoch 66:  31%|███▏      | 115/367 [00:00<00:01, 161.73it/s]recon_loss: 0.028475934639573097, dist_loss: 0.564803421497345
recon_loss: 0.02847650647163391, dist_loss: 0.6121406555175781
recon_loss: 0.028475895524024963, dist_loss: 0.7192566394805908
recon_loss: 0.028476594015955925, dist_loss: 0.5640730261802673
recon_loss: 0.028476199135184288, dist_loss: 0.8249727487564087
recon_loss: 0.02847531996667385, dist_loss: 0.46414005756378174
recon_loss: 0.028474906459450722, dist_loss: 0.8105514049530029
recon_loss: 0.028474057093262672, dist_loss: 1.0338891744613647
recon_loss: 0.02847365103662014, dist_loss: 1.1368731260299683
recon_loss: 0.028473207727074623, dist_loss: 0.8008317947387695
recon_loss: 0.028472742065787315, dist_loss: 0.369345486164093
recon_loss: 0.028472691774368286, dist_loss: 0.7760611176490784
recon_loss: 0.028472421690821648, dist_loss: 0.36107245087623596
recon_loss: 0.028472617268562317, dist_loss: 0.2856561839580536
recon_loss: 0.02847270295023918, dist_loss: 0.7017570734024048
recon_loss: 0.02847256511449814, dist_loss: 0.49037110805511475
recon_loss: 0.02847261168062687, dist_loss: 0.8647159337997437
recon_loss: 0.02847217209637165, dist_loss: 0.7063629627227783
recon_loss: 0.028471769765019417, dist_loss: 0.510601282119751
recon_loss: 0.02847193367779255, dist_loss: 0.43148842453956604
recon_loss: 0.02847161702811718, dist_loss: 1.0063132047653198
recon_loss: 0.0284715723246336, dist_loss: 0.8941054344177246
recon_loss: 0.028471466153860092, dist_loss: 0.5143923759460449
recon_loss: 0.028470974415540695, dist_loss: 0.5649009346961975
recon_loss: 0.028470531105995178, dist_loss: 0.8494468331336975
recon_loss: 0.02847043052315712, dist_loss: 0.5581832528114319
recon_loss: 0.028470346704125404, dist_loss: 0.3997528553009033
recon_loss: 0.02847028523683548, dist_loss: 0.732150137424469
recon_loss: 0.02847026288509369, dist_loss: 0.8632470965385437
recon_loss: 0.02846992202103138, dist_loss: 0.548509418964386
recon_loss: 0.02847052924335003, dist_loss: 1.0632835626602173
recon_loss: 0.02846996672451496, dist_loss: 0.3990328907966614
recon_loss: 0.02847016416490078, dist_loss: 0.519250214099884
recon_loss: 0.028470134362578392, dist_loss: 1.009925127029419
recon_loss: 0.02846999652683735, dist_loss: 0.7918784618377686
recon_loss: 0.028470909222960472, dist_loss: 1.2679128646850586
recon_loss: 0.02846972830593586, dist_loss: 0.6065827012062073
recon_loss: 0.028470078483223915, dist_loss: 0.45749643445014954
recon_loss: 0.028470292687416077, dist_loss: 0.31544768810272217
recon_loss: 0.02846905030310154, dist_loss: 1.1377198696136475
recon_loss: 0.028469296172261238, dist_loss: 1.2795344591140747
recon_loss: 0.02846866101026535, dist_loss: 0.6943049430847168
recon_loss: 0.028468633070588112, dist_loss: 0.8039869070053101
recon_loss: 0.028468506410717964, dist_loss: 0.3993717133998871
recon_loss: 0.02846829779446125, dist_loss: 0.4627387523651123
recon_loss: 0.028468189761042595, dist_loss: 0.36771517992019653
recon_loss: 0.028467977419495583, dist_loss: 0.3727472126483917
recon_loss: 0.02846761792898178, dist_loss: 0.8949504494667053
recon_loss: 0.02846759930253029, dist_loss: 0.8458044528961182
recon_loss: 0.028467688709497452, dist_loss: 0.9230633974075317
recon_loss: 0.02846735715866089, dist_loss: 0.8045459985733032
recon_loss: 0.028467915952205658, dist_loss: 0.5309482216835022
recon_loss: 0.028467684984207153, dist_loss: 0.7575527429580688
recon_loss: 0.02846698649227619, dist_loss: 1.4060413837432861
recon_loss: 0.028467543423175812, dist_loss: 0.6425519585609436
recon_loss: 0.028467262163758278, dist_loss: 0.4827573299407959
recon_loss: 0.028467485681176186, dist_loss: 0.6420903205871582
recon_loss: 0.0284676942974329, dist_loss: 0.9490081071853638
recon_loss: 0.028467616066336632, dist_loss: 0.65241539478302
recon_loss: 0.028467783704400063, dist_loss: 0.5609986782073975
recon_loss: 0.02846779301762581, dist_loss: 0.879304051399231
recon_loss: 0.02846781350672245, dist_loss: 0.6610017418861389
recon_loss: 0.028467712923884392, dist_loss: 0.846116304397583
recon_loss: 0.028467364609241486, dist_loss: 0.44325339794158936
recon_loss: 0.02846716158092022, dist_loss: 0.7981849908828735
recon_loss: 0.028467057272791862, dist_loss: 0.4587858319282532
recon_loss: 0.028466900810599327, dist_loss: 0.4773377478122711
recon_loss: 0.028466690331697464, dist_loss: 0.8474922180175781
recon_loss: 0.028466535732150078, dist_loss: 0.5426379442214966
recon_loss: 0.02846630848944187, dist_loss: 0.6028270721435547
recon_loss: 0.028466494753956795, dist_loss: 0.7137813568115234
recon_loss: 0.028466958552598953, dist_loss: 0.451887845993042
recon_loss: 0.02846684865653515, dist_loss: 0.5053185224533081
recon_loss: 0.028467420488595963, dist_loss: 0.8625690937042236
recon_loss: 0.028466925024986267, dist_loss: 0.7074387073516846
recon_loss: 0.02846718579530716, dist_loss: 0.6687757968902588
recon_loss: 0.0284678116440773, dist_loss: 0.4839228391647339
recon_loss: 0.028467193245887756, dist_loss: 0.4186520576477051
recon_loss: 0.028467796742916107, dist_loss: 0.5956107974052429
recon_loss: 0.028467796742916107, dist_loss: 0.7355022430419922
recon_loss: 0.028466887772083282, dist_loss: 0.6918331384658813
recon_loss: 0.02846650779247284, dist_loss: 0.5394096374511719
recon_loss: 0.02846613898873329, dist_loss: 0.31831425428390503
recon_loss: 0.02846570871770382, dist_loss: 1.2375563383102417
recon_loss: 0.028466230258345604, dist_loss: 0.2782133221626282
recon_loss: 0.028466040268540382, dist_loss: 0.99660325050354
recon_loss: 0.028466317802667618, dist_loss: 0.35894519090652466
recon_loss: 0.02846704237163067, dist_loss: 0.5125723481178284
recon_loss: 0.028467172756791115, dist_loss: 0.6302452683448792
recon_loss: 0.028467237949371338, dist_loss: 0.7222265601158142
recon_loss: 0.02846735715866089, dist_loss: 0.6654515266418457
recon_loss: 0.02846723236143589, dist_loss: 0.964560329914093
recon_loss: 0.028466813266277313, dist_loss: 0.4301914870738983
recon_loss: 0.02846628613770008, dist_loss: 0.6611895561218262
recon_loss: 0.028465401381254196, dist_loss: 0.5627732872962952
recon_loss: 0.028464671224355698, dist_loss: 0.2676997184753418
recon_loss: 0.028464240953326225, dist_loss: 0.6340216994285583
recon_loss: 0.028464101254940033, dist_loss: 0.6864966154098511
recon_loss: 0.02846384048461914, dist_loss: 0.6652984023094177
recon_loss: 0.028463931754231453, dist_loss: 0.8553447723388672
recon_loss: 0.028464486822485924, dist_loss: 0.837260365486145
recon_loss: 0.028464829549193382, dist_loss: 0.7145191431045532
recon_loss: 0.028465241193771362, dist_loss: 0.475037157535553
recon_loss: 0.02846520207822323, dist_loss: 0.562597393989563
recon_loss: 0.02846497856080532, dist_loss: 0.6343911290168762
recon_loss: 0.02846449799835682, dist_loss: 0.847802996635437
recon_loss: 0.02846387028694153, dist_loss: 0.7136420011520386
recon_loss: 0.028463415801525116, dist_loss: 0.7514788508415222
recon_loss: 0.028463013470172882, dist_loss: 0.5737818479537964
recon_loss: 0.028462616726756096, dist_loss: 0.7077102661132812
recon_loss: 0.028462465852499008, dist_loss: 0.8484887480735779
recon_loss: 0.02846221812069416, dist_loss: 0.7485611438751221
recon_loss: 0.028462087735533714, dist_loss: 0.43461358547210693
recon_loss: 0.02846209891140461, dist_loss: 1.2096467018127441
recon_loss: 0.02846173569560051, dist_loss: 0.45098239183425903
recon_loss: 0.028461506590247154, dist_loss: 0.8607474565505981
recon_loss: 0.028461452573537827, dist_loss: 0.5632970333099365
recon_loss: 0.028461437672376633, dist_loss: 0.6915267109870911
recon_loss: 0.028461413457989693, dist_loss: 0.5968009829521179
recon_loss: 0.028461385518312454, dist_loss: 0.45102599263191223
recon_loss: 0.02846134826540947, dist_loss: 0.7124136686325073
recon_loss: 0.028461972251534462, dist_loss: 0.44350188970565796
recon_loss: 0.028461918234825134, dist_loss: 0.971031665802002
recon_loss: 0.028461866080760956, dist_loss: 0.7039006948471069
recon_loss: 0.028462303802371025, dist_loss: 0.4483131468296051
recon_loss: 0.028461817651987076, dist_loss: 0.6115605235099792
recon_loss: 0.028462441638112068, dist_loss: 0.6569011211395264
recon_loss: 0.028461558744311333, dist_loss: 0.36568814516067505
Pre-training Epoch 66:  36%|███▌      | 132/367 [00:00<00:01, 162.60it/s]Pre-training Epoch 66:  41%|████      | 149/367 [00:00<00:01, 163.03it/s]Pre-training Epoch 66:  45%|████▌     | 166/367 [00:01<00:01, 163.46it/s]Pre-training Epoch 66:  50%|████▉     | 183/367 [00:01<00:01, 163.61it/s]Pre-training Epoch 66:  54%|█████▍    | 200/367 [00:01<00:01, 158.96it/s]Pre-training Epoch 66:  59%|█████▉    | 217/367 [00:01<00:00, 160.63it/s]Pre-training Epoch 66:  64%|██████▍   | 234/367 [00:01<00:00, 159.41it/s]Pre-training Epoch 66:  69%|██████▉   | 253/367 [00:01<00:00, 167.95it/s]recon_loss: 0.0284613985568285, dist_loss: 0.6200014352798462
recon_loss: 0.028461115434765816, dist_loss: 0.6122329831123352
recon_loss: 0.028460431843996048, dist_loss: 0.510579526424408
recon_loss: 0.028461173176765442, dist_loss: 0.613964319229126
recon_loss: 0.02846013940870762, dist_loss: 0.6994140148162842
recon_loss: 0.02846001461148262, dist_loss: 0.5814425349235535
recon_loss: 0.028459858149290085, dist_loss: 0.8385617136955261
recon_loss: 0.028459269553422928, dist_loss: 0.4151441156864166
recon_loss: 0.028459180146455765, dist_loss: 0.4088374376296997
recon_loss: 0.028458913788199425, dist_loss: 0.5401749610900879
recon_loss: 0.028458867222070694, dist_loss: 1.4542783498764038
recon_loss: 0.02845853567123413, dist_loss: 0.7887470722198486
recon_loss: 0.02845814637839794, dist_loss: 0.91892409324646
recon_loss: 0.028458138927817345, dist_loss: 0.4921165704727173
recon_loss: 0.028458144515752792, dist_loss: 0.5309280157089233
recon_loss: 0.028457708656787872, dist_loss: 0.7472285032272339
recon_loss: 0.028457624837756157, dist_loss: 0.88020920753479
recon_loss: 0.02845764346420765, dist_loss: 0.7603052258491516
recon_loss: 0.028457514941692352, dist_loss: 0.5242750644683838
recon_loss: 0.028457416221499443, dist_loss: 0.6001982688903809
recon_loss: 0.028457870706915855, dist_loss: 0.6218352317810059
recon_loss: 0.028457140550017357, dist_loss: 0.5024341940879822
recon_loss: 0.02845790795981884, dist_loss: 0.628082275390625
recon_loss: 0.02845795266330242, dist_loss: 0.44825559854507446
recon_loss: 0.02845834195613861, dist_loss: 0.787828803062439
recon_loss: 0.028458645567297935, dist_loss: 0.7516855597496033
recon_loss: 0.02845846861600876, dist_loss: 0.929133415222168
recon_loss: 0.028458109125494957, dist_loss: 1.035259485244751
recon_loss: 0.028458034619688988, dist_loss: 0.6343462467193604
recon_loss: 0.028458071872591972, dist_loss: 0.50993812084198
recon_loss: 0.028458166867494583, dist_loss: 0.5728608965873718
recon_loss: 0.02845810540020466, dist_loss: 0.4360463321208954
recon_loss: 0.02845783345401287, dist_loss: 0.6714389324188232
recon_loss: 0.028457725420594215, dist_loss: 0.5882114171981812
recon_loss: 0.028458092361688614, dist_loss: 0.42355984449386597
recon_loss: 0.028458500280976295, dist_loss: 0.692719578742981
recon_loss: 0.028459498658776283, dist_loss: 0.4640502631664276
recon_loss: 0.028460213914513588, dist_loss: 1.1492745876312256
recon_loss: 0.028460806235671043, dist_loss: 0.7854097485542297
recon_loss: 0.028461048379540443, dist_loss: 0.7846286296844482
recon_loss: 0.0284610316157341, dist_loss: 0.5150644183158875
recon_loss: 0.028460849076509476, dist_loss: 0.7366966009140015
recon_loss: 0.028460100293159485, dist_loss: 0.6084448099136353
recon_loss: 0.028459656983613968, dist_loss: 0.4430187940597534
recon_loss: 0.028459487482905388, dist_loss: 0.5344589948654175
recon_loss: 0.028458507731556892, dist_loss: 0.9631667733192444
recon_loss: 0.02845848724246025, dist_loss: 0.778367280960083
recon_loss: 0.028457963839173317, dist_loss: 0.8279358744621277
recon_loss: 0.02845788560807705, dist_loss: 0.5281035900115967
recon_loss: 0.028457429260015488, dist_loss: 0.9227747917175293
recon_loss: 0.028457103297114372, dist_loss: 0.911083996295929
recon_loss: 0.028456948697566986, dist_loss: 0.8206924200057983
recon_loss: 0.02845671772956848, dist_loss: 0.6928350925445557
recon_loss: 0.02845640853047371, dist_loss: 0.42948684096336365
recon_loss: 0.028456280007958412, dist_loss: 0.6388659477233887
recon_loss: 0.028456121683120728, dist_loss: 0.6784429550170898
recon_loss: 0.028456393629312515, dist_loss: 0.4023924469947815
recon_loss: 0.028455760329961777, dist_loss: 0.36190083622932434
recon_loss: 0.028455914929509163, dist_loss: 0.5391867160797119
recon_loss: 0.028455691412091255, dist_loss: 0.5286171436309814
recon_loss: 0.02845521830022335, dist_loss: 0.7040122747421265
recon_loss: 0.02845524251461029, dist_loss: 0.7792662382125854
recon_loss: 0.0284553412348032, dist_loss: 0.5080130100250244
recon_loss: 0.028455208986997604, dist_loss: 0.7375503182411194
recon_loss: 0.02845495007932186, dist_loss: 0.6281377077102661
recon_loss: 0.02845480665564537, dist_loss: 0.7567710876464844
recon_loss: 0.02845502644777298, dist_loss: 0.7410788536071777
recon_loss: 0.028455525636672974, dist_loss: 0.8695423603057861
recon_loss: 0.028456365689635277, dist_loss: 0.6616912484169006
recon_loss: 0.028458137065172195, dist_loss: 0.7460412979125977
recon_loss: 0.028459511697292328, dist_loss: 0.4605215787887573
recon_loss: 0.028460031375288963, dist_loss: 0.6623906493186951
recon_loss: 0.028461281210184097, dist_loss: 1.3174750804901123
recon_loss: 0.028463350608944893, dist_loss: 0.6342428922653198
recon_loss: 0.028463533148169518, dist_loss: 0.5873900055885315
recon_loss: 0.028463786467909813, dist_loss: 0.6600379943847656
recon_loss: 0.02846330963075161, dist_loss: 0.3857533931732178
recon_loss: 0.028462883085012436, dist_loss: 0.8870952725410461
recon_loss: 0.028461672365665436, dist_loss: 0.8550028800964355
recon_loss: 0.028460104018449783, dist_loss: 0.36551129817962646
recon_loss: 0.028458477929234505, dist_loss: 0.629330039024353
recon_loss: 0.02845720946788788, dist_loss: 0.433841347694397
recon_loss: 0.02845649980008602, dist_loss: 0.5508872270584106
recon_loss: 0.028456229716539383, dist_loss: 0.8729267120361328
recon_loss: 0.028456294909119606, dist_loss: 0.46418240666389465
recon_loss: 0.028456613421440125, dist_loss: 0.9693139791488647
recon_loss: 0.028457272797822952, dist_loss: 1.1420488357543945
recon_loss: 0.028457678854465485, dist_loss: 0.9554758667945862
recon_loss: 0.028457539156079292, dist_loss: 1.1044268608093262
recon_loss: 0.028457490727305412, dist_loss: 0.8655787110328674
recon_loss: 0.0284561924636364, dist_loss: 0.5220697522163391
recon_loss: 0.028455009683966637, dist_loss: 0.47036027908325195
recon_loss: 0.028454314917325974, dist_loss: 0.640613317489624
recon_loss: 0.0284537672996521, dist_loss: 0.9854176044464111
recon_loss: 0.02845356985926628, dist_loss: 0.8530312776565552
recon_loss: 0.028453493490815163, dist_loss: 1.0040135383605957
recon_loss: 0.028453750535845757, dist_loss: 0.6859250664710999
recon_loss: 0.028454037383198738, dist_loss: 0.4757562279701233
recon_loss: 0.02845449186861515, dist_loss: 0.8549351692199707
recon_loss: 0.028454165905714035, dist_loss: 0.5785517692565918
recon_loss: 0.02845376916229725, dist_loss: 1.3915430307388306
recon_loss: 0.02845333144068718, dist_loss: 0.7299104928970337
recon_loss: 0.028452850878238678, dist_loss: 0.6182630062103271
recon_loss: 0.02845235913991928, dist_loss: 0.5857191681861877
recon_loss: 0.028451913967728615, dist_loss: 0.5330431461334229
recon_loss: 0.028451664373278618, dist_loss: 1.054814100265503
recon_loss: 0.028451409190893173, dist_loss: 0.4504813551902771
recon_loss: 0.02845127135515213, dist_loss: 0.5698443055152893
recon_loss: 0.028451211750507355, dist_loss: 1.1062400341033936
recon_loss: 0.028450971469283104, dist_loss: 0.9086395502090454
recon_loss: 0.028450826182961464, dist_loss: 0.9054011702537537
recon_loss: 0.028450660407543182, dist_loss: 1.00477135181427
recon_loss: 0.028450649231672287, dist_loss: 0.4732133150100708
recon_loss: 0.02845052257180214, dist_loss: 0.5524930953979492
recon_loss: 0.028450388461351395, dist_loss: 0.4020978510379791
recon_loss: 0.02845022641122341, dist_loss: 0.7600888013839722
recon_loss: 0.02845013327896595, dist_loss: 0.6694755554199219
recon_loss: 0.028449924662709236, dist_loss: 0.7462000250816345
recon_loss: 0.02844984084367752, dist_loss: 0.6696598529815674
recon_loss: 0.02845023199915886, dist_loss: 0.6048489212989807
recon_loss: 0.028450986370444298, dist_loss: 0.9577305316925049
recon_loss: 0.02845085971057415, dist_loss: 0.43994054198265076
recon_loss: 0.02845033071935177, dist_loss: 0.7787930965423584
recon_loss: 0.02844982035458088, dist_loss: 0.8531528115272522
recon_loss: 0.02845030091702938, dist_loss: 0.751126766204834
recon_loss: 0.02845066972076893, dist_loss: 0.6552860736846924
recon_loss: 0.028451232239603996, dist_loss: 0.6869187355041504
recon_loss: 0.028449906036257744, dist_loss: 0.8505810499191284
recon_loss: 0.028449619188904762, dist_loss: 0.5262807607650757Pre-training Epoch 66:  74%|███████▍  | 273/367 [00:01<00:00, 174.80it/s]Pre-training Epoch 66:  80%|███████▉  | 293/367 [00:01<00:00, 179.76it/s]Pre-training Epoch 66:  85%|████████▌ | 313/367 [00:01<00:00, 182.99it/s]Pre-training Epoch 66:  91%|█████████ | 333/367 [00:01<00:00, 185.25it/s]Pre-training Epoch 66:  96%|█████████▌| 353/367 [00:02<00:00, 187.14it/s]Pre-training Epoch 66: 100%|██████████| 367/367 [00:02<00:00, 170.17it/s]

recon_loss: 0.028449932113289833, dist_loss: 0.8699952363967896
recon_loss: 0.028450094163417816, dist_loss: 0.6242714524269104
recon_loss: 0.028450792655348778, dist_loss: 0.5390430092811584
recon_loss: 0.028449879959225655, dist_loss: 1.0751299858093262
recon_loss: 0.028448959812521935, dist_loss: 0.46527305245399475
recon_loss: 0.028448553755879402, dist_loss: 0.6965052485466003
recon_loss: 0.028448600322008133, dist_loss: 0.5143495798110962
recon_loss: 0.028449131175875664, dist_loss: 0.9758884906768799
recon_loss: 0.028448889032006264, dist_loss: 0.5701738595962524
recon_loss: 0.028448697179555893, dist_loss: 0.41330647468566895
recon_loss: 0.028448250144720078, dist_loss: 0.6557968854904175
recon_loss: 0.02844804711639881, dist_loss: 0.4165339469909668
recon_loss: 0.028448276221752167, dist_loss: 0.3553898334503174
recon_loss: 0.02844817563891411, dist_loss: 0.3896169066429138
recon_loss: 0.028448594734072685, dist_loss: 0.6287213563919067
recon_loss: 0.028448158875107765, dist_loss: 0.42224013805389404
recon_loss: 0.028447860851883888, dist_loss: 0.527677059173584
recon_loss: 0.028447993099689484, dist_loss: 0.4566372334957123
recon_loss: 0.028447644785046577, dist_loss: 0.6068073511123657
recon_loss: 0.028447695076465607, dist_loss: 0.6068065762519836
recon_loss: 0.028447778895497322, dist_loss: 0.5418921709060669
recon_loss: 0.028447479009628296, dist_loss: 0.5843085050582886
recon_loss: 0.028447462245821953, dist_loss: 0.5499440431594849
recon_loss: 0.02844693325459957, dist_loss: 0.9060213565826416
recon_loss: 0.028446471318602562, dist_loss: 0.43601471185684204
recon_loss: 0.028446730226278305, dist_loss: 0.4672797620296478
recon_loss: 0.02844630740582943, dist_loss: 0.47385334968566895
recon_loss: 0.028446270152926445, dist_loss: 0.782259464263916
recon_loss: 0.028446458280086517, dist_loss: 0.43060749769210815
recon_loss: 0.028445802628993988, dist_loss: 1.020110011100769
recon_loss: 0.028445826843380928, dist_loss: 0.5233384966850281
recon_loss: 0.02844560332596302, dist_loss: 0.46329203248023987
recon_loss: 0.028445476666092873, dist_loss: 0.6549578309059143
recon_loss: 0.02844555862247944, dist_loss: 0.6677307486534119
recon_loss: 0.028445279225707054, dist_loss: 0.7592905759811401
recon_loss: 0.028445247560739517, dist_loss: 0.5085383057594299
recon_loss: 0.028445666655898094, dist_loss: 0.6183195114135742
recon_loss: 0.028445331379771233, dist_loss: 0.8198734521865845
recon_loss: 0.028445716947317123, dist_loss: 0.6984025239944458
recon_loss: 0.02844560518860817, dist_loss: 0.6131390929222107
recon_loss: 0.028445761650800705, dist_loss: 0.4325817823410034
recon_loss: 0.028445832431316376, dist_loss: 0.46732720732688904
recon_loss: 0.028446165844798088, dist_loss: 0.4696282148361206
recon_loss: 0.028446238487958908, dist_loss: 0.5474693775177002
recon_loss: 0.028446508571505547, dist_loss: 0.44687768816947937
recon_loss: 0.028446774929761887, dist_loss: 0.944878101348877
recon_loss: 0.02844635210931301, dist_loss: 0.5044059157371521
recon_loss: 0.028446365147829056, dist_loss: 0.8325033783912659
recon_loss: 0.028445949777960777, dist_loss: 0.5311872959136963
recon_loss: 0.028446445241570473, dist_loss: 1.0472311973571777
recon_loss: 0.028446119278669357, dist_loss: 0.55126953125
recon_loss: 0.02844548039138317, dist_loss: 0.43427664041519165
recon_loss: 0.02844543382525444, dist_loss: 0.9229075312614441
recon_loss: 0.028444960713386536, dist_loss: 0.5782134532928467
recon_loss: 0.0284454096108675, dist_loss: 0.6359691619873047
recon_loss: 0.02844545617699623, dist_loss: 0.5158350467681885
recon_loss: 0.028444631025195122, dist_loss: 0.3026546835899353
recon_loss: 0.028444601222872734, dist_loss: 0.8186206817626953
recon_loss: 0.02844446711242199, dist_loss: 0.47713494300842285
recon_loss: 0.028444845229387283, dist_loss: 0.7644299864768982
recon_loss: 0.02844584360718727, dist_loss: 0.6493332386016846
recon_loss: 0.028446659445762634, dist_loss: 0.32081642746925354
recon_loss: 0.028446590527892113, dist_loss: 0.5123484134674072
recon_loss: 0.02844715304672718, dist_loss: 0.7083191275596619
recon_loss: 0.02844640053808689, dist_loss: 0.40953660011291504
recon_loss: 0.028446093201637268, dist_loss: 0.5660807490348816
recon_loss: 0.028446253389120102, dist_loss: 0.4896629750728607
recon_loss: 0.02844521775841713, dist_loss: 0.7521094679832458
recon_loss: 0.028444834053516388, dist_loss: 0.39257869124412537
recon_loss: 0.028443854302167892, dist_loss: 0.7912940382957458
recon_loss: 0.028443142771720886, dist_loss: 0.6083412170410156
recon_loss: 0.028443751856684685, dist_loss: 0.579081118106842
recon_loss: 0.02844296395778656, dist_loss: 0.4611686170101166
recon_loss: 0.028443966060876846, dist_loss: 0.5422066450119019
recon_loss: 0.0284432340413332, dist_loss: 0.5005940198898315
recon_loss: 0.028443729504942894, dist_loss: 0.7383360862731934
recon_loss: 0.02844567783176899, dist_loss: 1.060705304145813
recon_loss: 0.028444385156035423, dist_loss: 0.6038721799850464
recon_loss: 0.028444549068808556, dist_loss: 0.43846485018730164
recon_loss: 0.028444530442357063, dist_loss: 1.1249704360961914
recon_loss: 0.028443757444620132, dist_loss: 0.42302998900413513
recon_loss: 0.02844487689435482, dist_loss: 0.5947198867797852
recon_loss: 0.0284443162381649, dist_loss: 0.7731554508209229
recon_loss: 0.02844306267797947, dist_loss: 0.6452297568321228
recon_loss: 0.028444163501262665, dist_loss: 0.5555380582809448
recon_loss: 0.02844281867146492, dist_loss: 0.9833425879478455
recon_loss: 0.028443479910492897, dist_loss: 0.5055840611457825
recon_loss: 0.028444107621908188, dist_loss: 0.6379474997520447
recon_loss: 0.028442684561014175, dist_loss: 0.362556517124176
recon_loss: 0.028441956266760826, dist_loss: 0.5882107019424438
recon_loss: 0.028441574424505234, dist_loss: 0.5473508834838867
recon_loss: 0.028441118076443672, dist_loss: 0.7665571570396423
recon_loss: 0.028440888971090317, dist_loss: 0.7377634048461914
recon_loss: 0.028440477326512337, dist_loss: 0.5816045999526978
recon_loss: 0.028440017253160477, dist_loss: 0.5274076461791992
recon_loss: 0.02843991480767727, dist_loss: 0.4257175922393799
recon_loss: 0.028439775109291077, dist_loss: 0.5130349397659302
recon_loss: 0.02844024822115898, dist_loss: 0.6771109104156494
recon_loss: 0.028441183269023895, dist_loss: 1.0346322059631348
recon_loss: 0.028442317619919777, dist_loss: 0.5885972380638123
recon_loss: 0.02844427153468132, dist_loss: 0.7424978017807007
recon_loss: 0.028446245938539505, dist_loss: 0.5679628849029541
recon_loss: 0.02844758704304695, dist_loss: 0.597030520439148
recon_loss: 0.028448687866330147, dist_loss: 1.3772153854370117
recon_loss: 0.028449470177292824, dist_loss: 0.7336890697479248
recon_loss: 0.02845013700425625, dist_loss: 0.5306714177131653
recon_loss: 0.028450770303606987, dist_loss: 0.7865423560142517
recon_loss: 0.028451571241021156, dist_loss: 0.6411470174789429
recon_loss: 0.02845143899321556, dist_loss: 0.9047473669052124
recon_loss: 0.028449473902583122, dist_loss: 1.4408315420150757
Pre-training Epoch 67:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 67:   4%|▍         | 15/367 [00:00<00:02, 149.82it/s]Pre-training Epoch 67:   8%|▊         | 31/367 [00:00<00:02, 153.96it/s]Pre-training Epoch 67:  13%|█▎        | 47/367 [00:00<00:02, 154.69it/s]Pre-training Epoch 67:  17%|█▋        | 63/367 [00:00<00:01, 153.48it/s]Pre-training Epoch 67:  22%|██▏       | 79/367 [00:00<00:01, 154.66it/s]Pre-training Epoch 67:  26%|██▌       | 95/367 [00:00<00:01, 154.67it/s]Pre-training Epoch 67:  30%|███       | 111/367 [00:00<00:01, 155.42it/s]Pre-training Epoch 67:  35%|███▍      | 127/367 [00:00<00:01, 151.42it/s]recon_loss: 0.02844741940498352, dist_loss: 0.4588225483894348
recon_loss: 0.028445906937122345, dist_loss: 0.4805278778076172
recon_loss: 0.02844376489520073, dist_loss: 0.6840451955795288
recon_loss: 0.02844258025288582, dist_loss: 0.6688421964645386
recon_loss: 0.028441673144698143, dist_loss: 0.5783438086509705
recon_loss: 0.028440263122320175, dist_loss: 0.9342658519744873
recon_loss: 0.02844037301838398, dist_loss: 0.4735531806945801
recon_loss: 0.028439711779356003, dist_loss: 0.7213159799575806
recon_loss: 0.028439823538064957, dist_loss: 0.5996682047843933
recon_loss: 0.028439991176128387, dist_loss: 0.592625617980957
recon_loss: 0.028440548107028008, dist_loss: 0.7491941452026367
recon_loss: 0.028442468494176865, dist_loss: 0.7151321172714233
recon_loss: 0.02844296023249626, dist_loss: 0.6171120405197144
recon_loss: 0.028442781418561935, dist_loss: 0.789276123046875
recon_loss: 0.028444238007068634, dist_loss: 0.8046604990959167
recon_loss: 0.028444457799196243, dist_loss: 0.7072851061820984
recon_loss: 0.0284434761852026, dist_loss: 0.4496493637561798
recon_loss: 0.028444133698940277, dist_loss: 0.7111490368843079
recon_loss: 0.02844337373971939, dist_loss: 0.7323200702667236
recon_loss: 0.028441712260246277, dist_loss: 0.46225443482398987
recon_loss: 0.02844097837805748, dist_loss: 0.5301873683929443
recon_loss: 0.028439601883292198, dist_loss: 0.6496566534042358
recon_loss: 0.02843845635652542, dist_loss: 0.6624571084976196
recon_loss: 0.028439203277230263, dist_loss: 0.2443808913230896
recon_loss: 0.028438150882720947, dist_loss: 0.19615183770656586
recon_loss: 0.028437582775950432, dist_loss: 0.7920854091644287
recon_loss: 0.028437621891498566, dist_loss: 0.6807672381401062
recon_loss: 0.028435977175831795, dist_loss: 0.5972586274147034
recon_loss: 0.028436224907636642, dist_loss: 0.4905248284339905
recon_loss: 0.028436630964279175, dist_loss: 0.36900368332862854
recon_loss: 0.02843637950718403, dist_loss: 0.563653826713562
recon_loss: 0.02843676507472992, dist_loss: 0.4304355978965759
recon_loss: 0.0284366924315691, dist_loss: 0.6154699325561523
recon_loss: 0.02843646891415119, dist_loss: 0.6531803607940674
recon_loss: 0.02843726985156536, dist_loss: 0.5675618648529053
recon_loss: 0.02843719720840454, dist_loss: 0.39050817489624023
recon_loss: 0.02843812108039856, dist_loss: 0.9000617265701294
recon_loss: 0.028437666594982147, dist_loss: 1.203586220741272
recon_loss: 0.028437240049242973, dist_loss: 0.9002636075019836
recon_loss: 0.028437074273824692, dist_loss: 1.1356525421142578
recon_loss: 0.02843593806028366, dist_loss: 0.43569788336753845
recon_loss: 0.028435582295060158, dist_loss: 0.5237393379211426
recon_loss: 0.02843484841287136, dist_loss: 0.7370364665985107
recon_loss: 0.028434548527002335, dist_loss: 0.33457067608833313
recon_loss: 0.02843484841287136, dist_loss: 0.6811467409133911
recon_loss: 0.028434837237000465, dist_loss: 0.9267041087150574
recon_loss: 0.028435062617063522, dist_loss: 0.4992106556892395
recon_loss: 0.02843492478132248, dist_loss: 0.8813481330871582
recon_loss: 0.02843530662357807, dist_loss: 1.4329482316970825
recon_loss: 0.028435589745640755, dist_loss: 0.5179583430290222
recon_loss: 0.02843582071363926, dist_loss: 0.574176549911499
recon_loss: 0.028436563909053802, dist_loss: 0.8881809115409851
recon_loss: 0.028437528759241104, dist_loss: 0.3537842035293579
recon_loss: 0.028438610956072807, dist_loss: 0.7763094902038574
recon_loss: 0.028439192101359367, dist_loss: 0.9044715166091919
recon_loss: 0.028438493609428406, dist_loss: 0.44452545046806335
recon_loss: 0.028437864035367966, dist_loss: 0.724089503288269
recon_loss: 0.028437042608857155, dist_loss: 0.7824044227600098
recon_loss: 0.028436588123440742, dist_loss: 0.7053543329238892
recon_loss: 0.028435857966542244, dist_loss: 0.9552745819091797
recon_loss: 0.028434675186872482, dist_loss: 0.4667358994483948
recon_loss: 0.02843373455107212, dist_loss: 0.6755478978157043
recon_loss: 0.028433162719011307, dist_loss: 0.3476567566394806
recon_loss: 0.028432942926883698, dist_loss: 0.8686221837997437
recon_loss: 0.028433071449398994, dist_loss: 1.0167385339736938
recon_loss: 0.02843310311436653, dist_loss: 0.59538733959198
recon_loss: 0.028433363884687424, dist_loss: 0.9396271705627441
recon_loss: 0.02843386121094227, dist_loss: 1.0569612979888916
recon_loss: 0.028434062376618385, dist_loss: 0.7724868655204773
recon_loss: 0.028434883803129196, dist_loss: 0.44530779123306274
recon_loss: 0.028435351327061653, dist_loss: 0.5868010520935059
recon_loss: 0.028435155749320984, dist_loss: 0.6389668583869934
recon_loss: 0.028435828164219856, dist_loss: 0.9691594839096069
recon_loss: 0.02843816578388214, dist_loss: 0.5071090459823608
recon_loss: 0.028440091758966446, dist_loss: 0.6493188738822937
recon_loss: 0.028441447764635086, dist_loss: 0.7857272624969482
recon_loss: 0.0284429918974638, dist_loss: 0.5209039449691772
recon_loss: 0.028443455696105957, dist_loss: 0.3815997242927551
recon_loss: 0.028443483635783195, dist_loss: 1.0520057678222656
recon_loss: 0.0284439530223608, dist_loss: 0.4605521261692047
recon_loss: 0.028442688286304474, dist_loss: 0.7657923698425293
recon_loss: 0.02844192087650299, dist_loss: 0.5071589350700378
recon_loss: 0.02844082936644554, dist_loss: 0.6422882676124573
recon_loss: 0.028439830988645554, dist_loss: 0.7600752115249634
recon_loss: 0.028438236564397812, dist_loss: 1.184806227684021
recon_loss: 0.028436487540602684, dist_loss: 0.2441936731338501
recon_loss: 0.02843509241938591, dist_loss: 0.3791074752807617
recon_loss: 0.02843380905687809, dist_loss: 0.5231587290763855
recon_loss: 0.028432834893465042, dist_loss: 0.7667801976203918
recon_loss: 0.0284322090446949, dist_loss: 0.63608717918396
recon_loss: 0.028432434424757957, dist_loss: 0.7679135203361511
recon_loss: 0.028433270752429962, dist_loss: 0.8213673233985901
recon_loss: 0.028434738516807556, dist_loss: 0.6795443892478943
recon_loss: 0.02843593619763851, dist_loss: 0.6141392588615417
recon_loss: 0.028437329456210136, dist_loss: 0.9735846519470215
recon_loss: 0.028438391163945198, dist_loss: 0.8270722031593323
recon_loss: 0.028438588604331017, dist_loss: 0.3782247006893158
recon_loss: 0.028439201414585114, dist_loss: 0.34309566020965576
recon_loss: 0.028439315035939217, dist_loss: 0.6190087795257568
recon_loss: 0.028439078480005264, dist_loss: 0.7602663636207581
recon_loss: 0.028439674526453018, dist_loss: 0.5813000202178955
recon_loss: 0.028440386056900024, dist_loss: 0.8664802312850952
recon_loss: 0.028440387919545174, dist_loss: 0.3745799660682678
recon_loss: 0.028440074995160103, dist_loss: 0.45219534635543823
recon_loss: 0.028439361602067947, dist_loss: 0.9404924511909485
recon_loss: 0.028438428416848183, dist_loss: 0.5396707653999329
recon_loss: 0.028437569737434387, dist_loss: 0.7063448429107666
recon_loss: 0.028436623513698578, dist_loss: 0.5374689698219299
recon_loss: 0.02843545563519001, dist_loss: 0.48983922600746155
recon_loss: 0.028434371575713158, dist_loss: 0.5776317715644836
recon_loss: 0.028432654216885567, dist_loss: 1.0184824466705322
recon_loss: 0.028431318700313568, dist_loss: 0.5645633935928345
recon_loss: 0.028430253267288208, dist_loss: 0.8813400268554688
recon_loss: 0.028429798781871796, dist_loss: 0.750874400138855
recon_loss: 0.02842978946864605, dist_loss: 0.8424754738807678
recon_loss: 0.028429297730326653, dist_loss: 0.3604997396469116
recon_loss: 0.028429154306650162, dist_loss: 0.5117073059082031
recon_loss: 0.028429409489035606, dist_loss: 0.7357851266860962
recon_loss: 0.02842842787504196, dist_loss: 0.6262497305870056
recon_loss: 0.028428684920072556, dist_loss: 0.8590614795684814
recon_loss: 0.02842842973768711, dist_loss: 0.6114734411239624
recon_loss: 0.028428060933947563, dist_loss: 0.6655409932136536
recon_loss: 0.028428511694073677, dist_loss: 0.6804392337799072
recon_loss: 0.02842807024717331, dist_loss: 0.8563790321350098
recon_loss: 0.028427887707948685, dist_loss: 1.228407859802246
recon_loss: 0.028428420424461365, dist_loss: 0.5247613191604614
recon_loss: 0.0284279715269804, dist_loss: 1.0143784284591675
recon_loss: 0.02842801623046398, dist_loss: 0.6847420930862427
Pre-training Epoch 67:  39%|███▉      | 144/367 [00:00<00:01, 155.77it/s]Pre-training Epoch 67:  44%|████▍     | 161/367 [00:01<00:01, 157.93it/s]Pre-training Epoch 67:  48%|████▊     | 177/367 [00:01<00:01, 153.72it/s]Pre-training Epoch 67:  53%|█████▎    | 193/367 [00:01<00:01, 153.27it/s]Pre-training Epoch 67:  57%|█████▋    | 209/367 [00:01<00:01, 153.66it/s]Pre-training Epoch 67:  61%|██████▏   | 225/367 [00:01<00:00, 152.76it/s]Pre-training Epoch 67:  66%|██████▌   | 241/367 [00:01<00:00, 149.89it/s]recon_loss: 0.028427690267562866, dist_loss: 0.8904185891151428
recon_loss: 0.028428135439753532, dist_loss: 0.4377287030220032
recon_loss: 0.028428101912140846, dist_loss: 1.2082995176315308
recon_loss: 0.02842784859240055, dist_loss: 0.839013934135437
recon_loss: 0.02842862531542778, dist_loss: 0.7183878421783447
recon_loss: 0.02842981368303299, dist_loss: 0.6763584017753601
recon_loss: 0.028430981561541557, dist_loss: 0.6164299249649048
recon_loss: 0.028431780636310577, dist_loss: 0.3572053909301758
recon_loss: 0.02843192033469677, dist_loss: 0.6665507555007935
recon_loss: 0.028432302176952362, dist_loss: 0.383553147315979
recon_loss: 0.028431754559278488, dist_loss: 0.6088090538978577
recon_loss: 0.028432074934244156, dist_loss: 0.635061502456665
recon_loss: 0.028432201594114304, dist_loss: 0.41100001335144043
recon_loss: 0.02843117155134678, dist_loss: 0.7290576100349426
recon_loss: 0.02843049168586731, dist_loss: 0.36223268508911133
recon_loss: 0.028429510071873665, dist_loss: 0.3691902160644531
recon_loss: 0.028428250923752785, dist_loss: 0.738552451133728
recon_loss: 0.028427375480532646, dist_loss: 0.5828865766525269
recon_loss: 0.028426863253116608, dist_loss: 0.5465172529220581
recon_loss: 0.028426412492990494, dist_loss: 0.381848007440567
recon_loss: 0.02842630259692669, dist_loss: 0.6025786399841309
recon_loss: 0.028426123782992363, dist_loss: 0.6979113817214966
recon_loss: 0.02842654287815094, dist_loss: 0.4576510787010193
recon_loss: 0.02842755615711212, dist_loss: 1.0359736680984497
recon_loss: 0.02842896431684494, dist_loss: 0.5483424663543701
recon_loss: 0.028429897502064705, dist_loss: 0.5939352512359619
recon_loss: 0.028430411592125893, dist_loss: 0.602149248123169
recon_loss: 0.028430767357349396, dist_loss: 0.7408772706985474
recon_loss: 0.028430938720703125, dist_loss: 0.7973056435585022
recon_loss: 0.02843048982322216, dist_loss: 0.2573468089103699
recon_loss: 0.028429832309484482, dist_loss: 1.087939977645874
recon_loss: 0.02842930145561695, dist_loss: 0.41404104232788086
recon_loss: 0.02842813730239868, dist_loss: 0.5461224913597107
recon_loss: 0.028427423909306526, dist_loss: 0.7860524654388428
recon_loss: 0.028426092118024826, dist_loss: 0.4305702745914459
recon_loss: 0.028425462543964386, dist_loss: 0.7543808221817017
recon_loss: 0.028425350785255432, dist_loss: 0.6635668873786926
recon_loss: 0.028424199670553207, dist_loss: 0.8163174390792847
recon_loss: 0.028423797339200974, dist_loss: 0.6183503270149231
recon_loss: 0.028423557057976723, dist_loss: 0.9025249481201172
recon_loss: 0.028422968462109566, dist_loss: 0.9284128546714783
recon_loss: 0.028422886505723, dist_loss: 0.503278374671936
recon_loss: 0.028422564268112183, dist_loss: 0.4000481367111206
recon_loss: 0.028422165662050247, dist_loss: 0.4210551977157593
recon_loss: 0.02842222899198532, dist_loss: 0.824446439743042
recon_loss: 0.028421927243471146, dist_loss: 0.7140889167785645
recon_loss: 0.028421640396118164, dist_loss: 0.48309385776519775
recon_loss: 0.02842169813811779, dist_loss: 0.5547781586647034
recon_loss: 0.028421716764569283, dist_loss: 0.5543626546859741
recon_loss: 0.028421295806765556, dist_loss: 1.1676748991012573
recon_loss: 0.02842140570282936, dist_loss: 0.878813624382019
recon_loss: 0.02842133119702339, dist_loss: 0.54924076795578
recon_loss: 0.02842111326754093, dist_loss: 0.4858011305332184
recon_loss: 0.02842111513018608, dist_loss: 0.6749534606933594
recon_loss: 0.028420966118574142, dist_loss: 0.8760396838188171
recon_loss: 0.028421157971024513, dist_loss: 0.8704511523246765
recon_loss: 0.028421062976121902, dist_loss: 0.8011387586593628
recon_loss: 0.02842126041650772, dist_loss: 0.6178008913993835
recon_loss: 0.0284209493547678, dist_loss: 0.5807523727416992
recon_loss: 0.02842101640999317, dist_loss: 0.5376803278923035
recon_loss: 0.02842092141509056, dist_loss: 0.9461251497268677
recon_loss: 0.028420861810445786, dist_loss: 0.8726978302001953
recon_loss: 0.02842094749212265, dist_loss: 0.32830381393432617
recon_loss: 0.02842084690928459, dist_loss: 0.43711549043655396
recon_loss: 0.028420476242899895, dist_loss: 0.4569587707519531
recon_loss: 0.02842061221599579, dist_loss: 0.47747570276260376
recon_loss: 0.028420230373740196, dist_loss: 0.4572240710258484
recon_loss: 0.028420398011803627, dist_loss: 0.4753536581993103
recon_loss: 0.02842024900019169, dist_loss: 0.6179710626602173
recon_loss: 0.028419984504580498, dist_loss: 0.5158994197845459
recon_loss: 0.028420282527804375, dist_loss: 0.4332027733325958
recon_loss: 0.02842072769999504, dist_loss: 0.7444618940353394
recon_loss: 0.028421180322766304, dist_loss: 0.3637213110923767
recon_loss: 0.028420915827155113, dist_loss: 0.6331413984298706
recon_loss: 0.028420988470315933, dist_loss: 0.5141180753707886
recon_loss: 0.028421157971024513, dist_loss: 0.3530016541481018
recon_loss: 0.028421295806765556, dist_loss: 0.4995332956314087
recon_loss: 0.028421347960829735, dist_loss: 1.275213360786438
recon_loss: 0.028421370312571526, dist_loss: 0.5653989911079407
recon_loss: 0.028421131893992424, dist_loss: 0.509157657623291
recon_loss: 0.02842116914689541, dist_loss: 0.8760163187980652
recon_loss: 0.02842102013528347, dist_loss: 0.7812944650650024
recon_loss: 0.028421368449926376, dist_loss: 0.38977673649787903
recon_loss: 0.028421517461538315, dist_loss: 0.6218265295028687
recon_loss: 0.0284214336425066, dist_loss: 0.5921319723129272
recon_loss: 0.028422079980373383, dist_loss: 0.9252811074256897
recon_loss: 0.028421543538570404, dist_loss: 1.2398110628128052
recon_loss: 0.028421102091670036, dist_loss: 0.5227431058883667
recon_loss: 0.0284207072108984, dist_loss: 0.47164127230644226
recon_loss: 0.028420014306902885, dist_loss: 0.44694510102272034
recon_loss: 0.028419874608516693, dist_loss: 0.3537146747112274
recon_loss: 0.028419343754649162, dist_loss: 0.5657035112380981
recon_loss: 0.028418976813554764, dist_loss: 0.4964919686317444
recon_loss: 0.02841923199594021, dist_loss: 1.0026726722717285
recon_loss: 0.028418585658073425, dist_loss: 0.6647776365280151
recon_loss: 0.02841903083026409, dist_loss: 1.0028986930847168
recon_loss: 0.028418797999620438, dist_loss: 0.929523229598999
recon_loss: 0.028418367728590965, dist_loss: 0.9436776638031006
recon_loss: 0.028418593108654022, dist_loss: 0.7976236343383789
recon_loss: 0.028418483212590218, dist_loss: 0.48320192098617554
recon_loss: 0.02841835282742977, dist_loss: 0.9836102724075317
recon_loss: 0.028418658301234245, dist_loss: 0.7361146807670593
recon_loss: 0.028418609872460365, dist_loss: 0.44553500413894653
recon_loss: 0.028418611735105515, dist_loss: 0.342848539352417
recon_loss: 0.028418967500329018, dist_loss: 0.4395250082015991
recon_loss: 0.028419267386198044, dist_loss: 0.6737958788871765
recon_loss: 0.02841942012310028, dist_loss: 0.6831159591674805
recon_loss: 0.02841910906136036, dist_loss: 0.5703365802764893
recon_loss: 0.02841871976852417, dist_loss: 0.6124093532562256
recon_loss: 0.028418762609362602, dist_loss: 0.3640860915184021
recon_loss: 0.02841910533607006, dist_loss: 1.0021042823791504
recon_loss: 0.028418829664587975, dist_loss: 0.8816181421279907
recon_loss: 0.028418762609362602, dist_loss: 0.5292189121246338
recon_loss: 0.02841816283762455, dist_loss: 0.4697633385658264
recon_loss: 0.028418121859431267, dist_loss: 0.6136184930801392
recon_loss: 0.028417548164725304, dist_loss: 0.40631386637687683
recon_loss: 0.028417538851499557, dist_loss: 0.5884993076324463
recon_loss: 0.02841760963201523, dist_loss: 0.7509222626686096
recon_loss: 0.028417330235242844, dist_loss: 0.6644949913024902
recon_loss: 0.028417358174920082, dist_loss: 0.45482131838798523
recon_loss: 0.028417758643627167, dist_loss: 0.7818437814712524
recon_loss: 0.02841796539723873, dist_loss: 1.1428501605987549
recon_loss: 0.028418777510523796, dist_loss: 1.0046889781951904
recon_loss: 0.0284203439950943, dist_loss: 0.8283717632293701
recon_loss: 0.02842220664024353, dist_loss: 0.8453185558319092
recon_loss: 0.028422750532627106, dist_loss: 0.5028026700019836
recon_loss: 0.0284231249243021, dist_loss: 0.7775826454162598
recon_loss: 0.028422927483916283, dist_loss: 0.8579354286193848
Pre-training Epoch 67:  70%|███████   | 257/367 [00:01<00:00, 149.37it/s]Pre-training Epoch 67:  74%|███████▍  | 272/367 [00:01<00:00, 149.05it/s]Pre-training Epoch 67:  78%|███████▊  | 287/367 [00:01<00:00, 145.28it/s]Pre-training Epoch 67:  83%|████████▎ | 303/367 [00:01<00:00, 148.92it/s]Pre-training Epoch 67:  87%|████████▋ | 319/367 [00:02<00:00, 149.63it/s]Pre-training Epoch 67:  91%|█████████▏| 335/367 [00:02<00:00, 152.21it/s]Pre-training Epoch 67:  96%|█████████▌| 352/367 [00:02<00:00, 155.86it/s]Pre-training Epoch 67: 100%|██████████| 367/367 [00:02<00:00, 153.23it/s]
recon_loss: 0.028422605246305466, dist_loss: 0.8301222324371338
recon_loss: 0.028421862050890923, dist_loss: 0.7368056774139404
recon_loss: 0.02842083014547825, dist_loss: 0.277529239654541
recon_loss: 0.028419766575098038, dist_loss: 0.4921759366989136
recon_loss: 0.028418434783816338, dist_loss: 0.7249529957771301
recon_loss: 0.02841750718653202, dist_loss: 0.42468494176864624
recon_loss: 0.028416745364665985, dist_loss: 0.694586992263794
recon_loss: 0.028416378423571587, dist_loss: 0.709843099117279
recon_loss: 0.028416331857442856, dist_loss: 0.44229960441589355
recon_loss: 0.02841605804860592, dist_loss: 0.8332201838493347
recon_loss: 0.028416093438863754, dist_loss: 0.5526794195175171
recon_loss: 0.028416339308023453, dist_loss: 0.6580771207809448
recon_loss: 0.02841658517718315, dist_loss: 0.8891782164573669
recon_loss: 0.028416719287633896, dist_loss: 0.9620456695556641
recon_loss: 0.028416533023118973, dist_loss: 0.3989104926586151
recon_loss: 0.028416264802217484, dist_loss: 0.4623588025569916
recon_loss: 0.02841610461473465, dist_loss: 0.7740483283996582
recon_loss: 0.028415732085704803, dist_loss: 0.4501821994781494
recon_loss: 0.028415532782673836, dist_loss: 0.6251584887504578
recon_loss: 0.028414970263838768, dist_loss: 0.5235411524772644
recon_loss: 0.028414476662874222, dist_loss: 0.5756556987762451
recon_loss: 0.028414079919457436, dist_loss: 0.6397523283958435
recon_loss: 0.028413789346814156, dist_loss: 0.6948540210723877
recon_loss: 0.028413744643330574, dist_loss: 1.001440167427063
recon_loss: 0.028413787484169006, dist_loss: 0.6387468576431274
recon_loss: 0.028412891551852226, dist_loss: 0.94292151927948
recon_loss: 0.02841307409107685, dist_loss: 0.8293557167053223
recon_loss: 0.028413934633135796, dist_loss: 0.754006028175354
recon_loss: 0.028414983302354813, dist_loss: 1.1430450677871704
recon_loss: 0.02841569483280182, dist_loss: 0.8982721567153931
recon_loss: 0.028416307643055916, dist_loss: 0.5346183776855469
recon_loss: 0.028416631743311882, dist_loss: 0.7264829874038696
recon_loss: 0.028415950015187263, dist_loss: 1.029797911643982
recon_loss: 0.028416210785508156, dist_loss: 1.0622888803482056
recon_loss: 0.02841552160680294, dist_loss: 1.288708209991455
recon_loss: 0.028414804488420486, dist_loss: 0.5632804036140442
recon_loss: 0.028413843363523483, dist_loss: 0.6510781049728394
recon_loss: 0.02841276489198208, dist_loss: 0.4413583278656006
recon_loss: 0.028412435203790665, dist_loss: 0.6280130743980408
recon_loss: 0.028411688283085823, dist_loss: 0.6731301546096802
recon_loss: 0.028411976993083954, dist_loss: 0.43257904052734375
recon_loss: 0.02841193415224552, dist_loss: 0.767512321472168
recon_loss: 0.028412658721208572, dist_loss: 0.4574609398841858
recon_loss: 0.028413748368620872, dist_loss: 0.7592816352844238
recon_loss: 0.028415247797966003, dist_loss: 0.6078121662139893
recon_loss: 0.02841704897582531, dist_loss: 0.8202527165412903
recon_loss: 0.028419610112905502, dist_loss: 0.4450480341911316
recon_loss: 0.028421754017472267, dist_loss: 0.4505387544631958
recon_loss: 0.028423061594367027, dist_loss: 0.9559513330459595
recon_loss: 0.028423547744750977, dist_loss: 0.470856249332428
recon_loss: 0.028423525393009186, dist_loss: 1.0310548543930054
recon_loss: 0.02842315286397934, dist_loss: 0.787895917892456
recon_loss: 0.028422385454177856, dist_loss: 0.4715360403060913
recon_loss: 0.028420012444257736, dist_loss: 0.49474430084228516
recon_loss: 0.028417497873306274, dist_loss: 0.6690516471862793
recon_loss: 0.028415417298674583, dist_loss: 0.5594215989112854
recon_loss: 0.028413303196430206, dist_loss: 0.45694682002067566
recon_loss: 0.028412558138370514, dist_loss: 0.37525492906570435
recon_loss: 0.02841256745159626, dist_loss: 0.803240954875946
recon_loss: 0.02841278351843357, dist_loss: 0.7562476992607117
recon_loss: 0.028412900865077972, dist_loss: 0.56102454662323
recon_loss: 0.02841245010495186, dist_loss: 0.5825214385986328
recon_loss: 0.02841224893927574, dist_loss: 0.8514267206192017
recon_loss: 0.02841169759631157, dist_loss: 0.7368871569633484
recon_loss: 0.02841184288263321, dist_loss: 0.589207112789154
recon_loss: 0.02841171808540821, dist_loss: 1.0171842575073242
recon_loss: 0.028411494567990303, dist_loss: 0.766549289226532
recon_loss: 0.02841239981353283, dist_loss: 0.33906054496765137
recon_loss: 0.02841130457818508, dist_loss: 0.9558569192886353
recon_loss: 0.028411341831088066, dist_loss: 1.002676248550415
recon_loss: 0.0284116268157959, dist_loss: 0.6697310209274292
recon_loss: 0.028412528336048126, dist_loss: 0.6052038669586182
recon_loss: 0.0284137986600399, dist_loss: 0.8165651559829712
recon_loss: 0.028414903208613396, dist_loss: 0.8066619634628296
recon_loss: 0.02841665968298912, dist_loss: 0.8002486824989319
recon_loss: 0.028417471796274185, dist_loss: 0.6469371914863586
recon_loss: 0.028416858986020088, dist_loss: 1.2012596130371094
recon_loss: 0.028416939079761505, dist_loss: 1.130000114440918
recon_loss: 0.028417229652404785, dist_loss: 0.4001154899597168
recon_loss: 0.028417512774467468, dist_loss: 0.3876568675041199
recon_loss: 0.028417466208338737, dist_loss: 0.6397814154624939
recon_loss: 0.02841687574982643, dist_loss: 0.43837687373161316
recon_loss: 0.028416046872735023, dist_loss: 1.088418960571289
recon_loss: 0.0284148957580328, dist_loss: 0.6726666688919067
recon_loss: 0.028413791209459305, dist_loss: 0.5993978977203369
recon_loss: 0.028412848711013794, dist_loss: 0.6144958734512329
recon_loss: 0.02841160260140896, dist_loss: 0.5282273888587952
recon_loss: 0.02841073088347912, dist_loss: 0.6314560770988464
recon_loss: 0.02841000445187092, dist_loss: 0.5022389888763428
recon_loss: 0.028409287333488464, dist_loss: 0.3637094795703888
recon_loss: 0.028409073129296303, dist_loss: 0.85481858253479
recon_loss: 0.02840876393020153, dist_loss: 0.5402801036834717
recon_loss: 0.028408631682395935, dist_loss: 0.5740346908569336
recon_loss: 0.02840961329638958, dist_loss: 0.8820818066596985
recon_loss: 0.028411168605089188, dist_loss: 0.8234361410140991
recon_loss: 0.02841373160481453, dist_loss: 0.5441498160362244
recon_loss: 0.028416110202670097, dist_loss: 1.1952807903289795
recon_loss: 0.02841847762465477, dist_loss: 0.6416569948196411
recon_loss: 0.028421958908438683, dist_loss: 0.4794202148914337
recon_loss: 0.028423910960555077, dist_loss: 0.29723694920539856
recon_loss: 0.028426527976989746, dist_loss: 0.5808964371681213
recon_loss: 0.028428122401237488, dist_loss: 0.7596727609634399
recon_loss: 0.02842916175723076, dist_loss: 0.7286418676376343
recon_loss: 0.028430571779608727, dist_loss: 0.5296803712844849
recon_loss: 0.02842993289232254, dist_loss: 0.4379923343658447
recon_loss: 0.028428662568330765, dist_loss: 0.4558311402797699
recon_loss: 0.02842731401324272, dist_loss: 0.9325737953186035
recon_loss: 0.02842569537460804, dist_loss: 0.41219672560691833
recon_loss: 0.028423426672816277, dist_loss: 0.5446171760559082
recon_loss: 0.02842024527490139, dist_loss: 0.5762907266616821
recon_loss: 0.028417272493243217, dist_loss: 1.0181255340576172
Pre-training Epoch 68:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 68:   4%|▍         | 15/367 [00:00<00:02, 145.51it/s]Pre-training Epoch 68:   8%|▊         | 31/367 [00:00<00:02, 149.52it/s]Pre-training Epoch 68:  13%|█▎        | 47/367 [00:00<00:02, 151.50it/s]Pre-training Epoch 68:  17%|█▋        | 63/367 [00:00<00:02, 150.63it/s]Pre-training Epoch 68:  22%|██▏       | 79/367 [00:00<00:01, 152.74it/s]Pre-training Epoch 68:  26%|██▌       | 95/367 [00:00<00:01, 153.74it/s]Pre-training Epoch 68:  30%|███       | 111/367 [00:00<00:01, 154.56it/s]Pre-training Epoch 68:  35%|███▍      | 127/367 [00:00<00:01, 154.01it/s]recon_loss: 0.02841450460255146, dist_loss: 0.4798416495323181
recon_loss: 0.028412532061338425, dist_loss: 0.5518155097961426
recon_loss: 0.028410654515028, dist_loss: 0.38542497158050537
recon_loss: 0.028409356251358986, dist_loss: 0.5159372091293335
recon_loss: 0.028408657759428024, dist_loss: 0.42108508944511414
recon_loss: 0.02840839885175228, dist_loss: 0.5272022485733032
recon_loss: 0.028408370912075043, dist_loss: 0.7866114377975464
recon_loss: 0.028408551588654518, dist_loss: 0.4448777735233307
recon_loss: 0.028409041464328766, dist_loss: 0.5953328609466553
recon_loss: 0.028409341350197792, dist_loss: 0.9065934419631958
recon_loss: 0.028408804908394814, dist_loss: 0.4326218068599701
recon_loss: 0.028408320620656013, dist_loss: 0.8945749998092651
recon_loss: 0.028408093377947807, dist_loss: 0.8843162655830383
recon_loss: 0.02840743213891983, dist_loss: 0.4784485101699829
recon_loss: 0.028406914323568344, dist_loss: 0.6041867136955261
recon_loss: 0.02840655855834484, dist_loss: 0.8864668011665344
recon_loss: 0.02840575948357582, dist_loss: 0.8659464716911316
recon_loss: 0.02840551733970642, dist_loss: 0.6963441371917725
recon_loss: 0.028405049815773964, dist_loss: 0.6152344942092896
recon_loss: 0.028405316174030304, dist_loss: 0.5069790482521057
recon_loss: 0.02840561978518963, dist_loss: 0.7393158674240112
recon_loss: 0.028405383229255676, dist_loss: 0.9036492705345154
recon_loss: 0.028405044227838516, dist_loss: 0.9838229417800903
recon_loss: 0.02840471640229225, dist_loss: 0.505988597869873
recon_loss: 0.02840462140738964, dist_loss: 0.6699047684669495
recon_loss: 0.028404688462615013, dist_loss: 0.9052107334136963
recon_loss: 0.02840447425842285, dist_loss: 0.4184976816177368
recon_loss: 0.02840392291545868, dist_loss: 0.7002228498458862
recon_loss: 0.028403449803590775, dist_loss: 0.43097740411758423
recon_loss: 0.028403155505657196, dist_loss: 0.5109802484512329
recon_loss: 0.02840309590101242, dist_loss: 0.4503624439239502
recon_loss: 0.028403375297784805, dist_loss: 0.6885160207748413
recon_loss: 0.028403587639331818, dist_loss: 0.3837418556213379
recon_loss: 0.02840380184352398, dist_loss: 0.39816373586654663
recon_loss: 0.028403647243976593, dist_loss: 0.4609523415565491
recon_loss: 0.02840309590101242, dist_loss: 0.7152333855628967
recon_loss: 0.028403105214238167, dist_loss: 0.35332927107810974
recon_loss: 0.028402581810951233, dist_loss: 1.428539514541626
recon_loss: 0.02840244024991989, dist_loss: 0.4858854413032532
recon_loss: 0.028402741998434067, dist_loss: 0.8048864006996155
recon_loss: 0.028402727097272873, dist_loss: 1.3493818044662476
recon_loss: 0.028402604162693024, dist_loss: 0.39701583981513977
recon_loss: 0.02840241603553295, dist_loss: 0.6404206156730652
recon_loss: 0.028402116149663925, dist_loss: 0.9323264956474304
recon_loss: 0.02840145118534565, dist_loss: 0.5903342962265015
recon_loss: 0.028400901705026627, dist_loss: 0.5173007249832153
recon_loss: 0.028400808572769165, dist_loss: 0.752777636051178
recon_loss: 0.02840026654303074, dist_loss: 0.6066522002220154
recon_loss: 0.028400598093867302, dist_loss: 0.6190760135650635
recon_loss: 0.02840029075741768, dist_loss: 0.7031530141830444
recon_loss: 0.028400685638189316, dist_loss: 0.765151858329773
recon_loss: 0.028401145711541176, dist_loss: 0.38550662994384766
recon_loss: 0.028400911018252373, dist_loss: 0.6291394233703613
recon_loss: 0.0284013319760561, dist_loss: 0.672130823135376
recon_loss: 0.02840154990553856, dist_loss: 0.5309964418411255
recon_loss: 0.02840147726237774, dist_loss: 0.6233658790588379
recon_loss: 0.02840231917798519, dist_loss: 1.0330677032470703
recon_loss: 0.028401624411344528, dist_loss: 0.8028252720832825
recon_loss: 0.02840161696076393, dist_loss: 0.5962697267532349
recon_loss: 0.028401082381606102, dist_loss: 0.3969147205352783
recon_loss: 0.02840118296444416, dist_loss: 0.6863071322441101
recon_loss: 0.028400590643286705, dist_loss: 0.3573577404022217
recon_loss: 0.02840033732354641, dist_loss: 1.0606446266174316
recon_loss: 0.02840029075741768, dist_loss: 0.5290230512619019
recon_loss: 0.02839967980980873, dist_loss: 1.242763876914978
recon_loss: 0.028399327769875526, dist_loss: 1.1682469844818115
recon_loss: 0.028399189934134483, dist_loss: 0.8456047177314758
recon_loss: 0.028399042785167694, dist_loss: 0.5923734903335571
recon_loss: 0.02839892916381359, dist_loss: 0.6265777349472046
recon_loss: 0.028398677706718445, dist_loss: 0.8885332345962524
recon_loss: 0.028398511931300163, dist_loss: 0.6299268007278442
recon_loss: 0.028398727998137474, dist_loss: 0.7548894286155701
recon_loss: 0.028399212285876274, dist_loss: 0.960951566696167
recon_loss: 0.02839934453368187, dist_loss: 0.8156371116638184
recon_loss: 0.028400573879480362, dist_loss: 1.0456465482711792
recon_loss: 0.02840072102844715, dist_loss: 0.7219301462173462
recon_loss: 0.028400685638189316, dist_loss: 0.7271095514297485
recon_loss: 0.02840091660618782, dist_loss: 1.0383151769638062
recon_loss: 0.028401395305991173, dist_loss: 0.910538911819458
recon_loss: 0.028401674702763557, dist_loss: 1.1671409606933594
recon_loss: 0.028400937095284462, dist_loss: 0.5406248569488525
recon_loss: 0.028399793431162834, dist_loss: 0.46641063690185547
recon_loss: 0.028399355709552765, dist_loss: 0.4000445008277893
recon_loss: 0.028398452326655388, dist_loss: 0.5494731068611145
recon_loss: 0.028398416936397552, dist_loss: 0.944278359413147
recon_loss: 0.028399039059877396, dist_loss: 0.6343563795089722
recon_loss: 0.028400057926774025, dist_loss: 0.6724444627761841
recon_loss: 0.028400491923093796, dist_loss: 0.5901163220405579
recon_loss: 0.028399953618645668, dist_loss: 0.41121619939804077
recon_loss: 0.028399482369422913, dist_loss: 0.5307953953742981
recon_loss: 0.028399217873811722, dist_loss: 0.8037710189819336
recon_loss: 0.02839924395084381, dist_loss: 0.8379561901092529
recon_loss: 0.0283993910998106, dist_loss: 0.4301871657371521
recon_loss: 0.028398456051945686, dist_loss: 1.2866320610046387
recon_loss: 0.02839805744588375, dist_loss: 1.0108312368392944
recon_loss: 0.028397494927048683, dist_loss: 0.42093753814697266
recon_loss: 0.028397442772984505, dist_loss: 0.7493090033531189
recon_loss: 0.02839956060051918, dist_loss: 0.6132190823554993
recon_loss: 0.028400639072060585, dist_loss: 0.6526703834533691
recon_loss: 0.028402453288435936, dist_loss: 1.1093320846557617
recon_loss: 0.02840435318648815, dist_loss: 0.4739406406879425
recon_loss: 0.028404822573065758, dist_loss: 0.43356698751449585
recon_loss: 0.028407439589500427, dist_loss: 0.8246150016784668
recon_loss: 0.028408929705619812, dist_loss: 0.6682319641113281
recon_loss: 0.028410596773028374, dist_loss: 0.5673197507858276
recon_loss: 0.028411976993083954, dist_loss: 0.4574574828147888
recon_loss: 0.028411075472831726, dist_loss: 0.4613632261753082
recon_loss: 0.02841164357960224, dist_loss: 0.7799349427223206
recon_loss: 0.028410324826836586, dist_loss: 0.5464898347854614
recon_loss: 0.02840816229581833, dist_loss: 0.7580094337463379
recon_loss: 0.028407560661435127, dist_loss: 0.8437384963035583
recon_loss: 0.028404567390680313, dist_loss: 0.4948200583457947
recon_loss: 0.028402570635080338, dist_loss: 0.6369680166244507
recon_loss: 0.0284018125385046, dist_loss: 0.638299822807312
recon_loss: 0.02840074710547924, dist_loss: 0.4264209568500519
recon_loss: 0.02840055525302887, dist_loss: 0.6441389918327332
recon_loss: 0.02839919552206993, dist_loss: 0.7548184394836426
recon_loss: 0.0283979419618845, dist_loss: 0.7629992961883545
recon_loss: 0.028397155925631523, dist_loss: 0.48334455490112305
recon_loss: 0.028396841138601303, dist_loss: 0.3288925886154175
recon_loss: 0.02839788794517517, dist_loss: 0.5018892288208008
recon_loss: 0.028398387134075165, dist_loss: 0.5798183083534241
recon_loss: 0.02839960902929306, dist_loss: 0.5611381530761719
recon_loss: 0.028400547802448273, dist_loss: 0.6146426200866699
recon_loss: 0.028401518240571022, dist_loss: 0.8242548108100891
recon_loss: 0.028403611853718758, dist_loss: 0.8908597230911255
recon_loss: 0.028405362740159035, dist_loss: 0.4968121647834778
recon_loss: 0.02840612269937992, dist_loss: 0.7276304960250854
Pre-training Epoch 68:  39%|███▉      | 143/367 [00:00<00:01, 154.86it/s]Pre-training Epoch 68:  43%|████▎     | 159/367 [00:01<00:01, 154.20it/s]Pre-training Epoch 68:  48%|████▊     | 175/367 [00:01<00:01, 149.74it/s]Pre-training Epoch 68:  52%|█████▏    | 191/367 [00:01<00:01, 149.75it/s]Pre-training Epoch 68:  56%|█████▋    | 207/367 [00:01<00:01, 149.08it/s]Pre-training Epoch 68:  61%|██████    | 223/367 [00:01<00:00, 149.83it/s]Pre-training Epoch 68:  65%|██████▌   | 239/367 [00:01<00:00, 150.81it/s]Pre-training Epoch 68:  69%|██████▉   | 255/367 [00:01<00:00, 151.37it/s]recon_loss: 0.02840658649802208, dist_loss: 0.7577569484710693
recon_loss: 0.02840728685259819, dist_loss: 0.7309081554412842
recon_loss: 0.028407584875822067, dist_loss: 0.7207121253013611
recon_loss: 0.028408264741301537, dist_loss: 0.6327894330024719
recon_loss: 0.028409071266651154, dist_loss: 0.4861831068992615
recon_loss: 0.028408974409103394, dist_loss: 0.48248380422592163
recon_loss: 0.028407573699951172, dist_loss: 0.648598313331604
recon_loss: 0.028405403718352318, dist_loss: 0.731493353843689
recon_loss: 0.02840382605791092, dist_loss: 0.6326513290405273
recon_loss: 0.028401359915733337, dist_loss: 0.40210115909576416
recon_loss: 0.02840079739689827, dist_loss: 0.7828754186630249
recon_loss: 0.02840013988316059, dist_loss: 0.7420857548713684
recon_loss: 0.02839716523885727, dist_loss: 0.49662497639656067
recon_loss: 0.028398044407367706, dist_loss: 0.6671866178512573
recon_loss: 0.028397535905241966, dist_loss: 0.5975121855735779
recon_loss: 0.028398476541042328, dist_loss: 0.3754410445690155
recon_loss: 0.028400782495737076, dist_loss: 0.88893723487854
recon_loss: 0.02839997038245201, dist_loss: 0.46687525510787964
recon_loss: 0.028399821370840073, dist_loss: 0.7463028430938721
recon_loss: 0.028399109840393066, dist_loss: 0.4807618260383606
recon_loss: 0.02839813567698002, dist_loss: 0.5366775989532471
recon_loss: 0.028398478403687477, dist_loss: 0.8580440282821655
recon_loss: 0.028397439047694206, dist_loss: 0.6706348657608032
recon_loss: 0.02839791588485241, dist_loss: 0.47867053747177124
recon_loss: 0.028397155925631523, dist_loss: 0.9731573462486267
recon_loss: 0.028395263478159904, dist_loss: 0.8004093766212463
recon_loss: 0.028395941480994225, dist_loss: 0.6130616664886475
recon_loss: 0.02839505486190319, dist_loss: 0.762825608253479
recon_loss: 0.02839411236345768, dist_loss: 0.8088592290878296
recon_loss: 0.028395172208547592, dist_loss: 0.5949104428291321
recon_loss: 0.028393270447850227, dist_loss: 0.6460354328155518
recon_loss: 0.028393205255270004, dist_loss: 0.5535503029823303
recon_loss: 0.02839447185397148, dist_loss: 0.7352601289749146
recon_loss: 0.02839220128953457, dist_loss: 0.7159086465835571
recon_loss: 0.028394317254424095, dist_loss: 0.6964705586433411
recon_loss: 0.028393389657139778, dist_loss: 0.4164990782737732
recon_loss: 0.02839192934334278, dist_loss: 0.9108642339706421
recon_loss: 0.02839258871972561, dist_loss: 0.38513487577438354
recon_loss: 0.028390904888510704, dist_loss: 0.9503408074378967
recon_loss: 0.028392814099788666, dist_loss: 0.7112871408462524
recon_loss: 0.028393199667334557, dist_loss: 0.6068735122680664
recon_loss: 0.028391124680638313, dist_loss: 0.6143895983695984
recon_loss: 0.02839469164609909, dist_loss: 0.8380005359649658
recon_loss: 0.02839125320315361, dist_loss: 0.5016653537750244
recon_loss: 0.028391508385539055, dist_loss: 1.2241028547286987
recon_loss: 0.028393611311912537, dist_loss: 1.1541624069213867
recon_loss: 0.028389550745487213, dist_loss: 0.6298532485961914
recon_loss: 0.028392115607857704, dist_loss: 1.1912506818771362
recon_loss: 0.028393464162945747, dist_loss: 0.3339883089065552
recon_loss: 0.02839195355772972, dist_loss: 0.5387794375419617
recon_loss: 0.028394466266036034, dist_loss: 0.7679073810577393
recon_loss: 0.028393477201461792, dist_loss: 0.8702201247215271
recon_loss: 0.02839445322751999, dist_loss: 1.5167045593261719
recon_loss: 0.028396431356668472, dist_loss: 0.8832113146781921
recon_loss: 0.028395939618349075, dist_loss: 0.8635267019271851
recon_loss: 0.02839650586247444, dist_loss: 0.9067070484161377
recon_loss: 0.028396090492606163, dist_loss: 0.7081056237220764
recon_loss: 0.028393594548106194, dist_loss: 0.5501178503036499
recon_loss: 0.028392909094691277, dist_loss: 1.2467271089553833
recon_loss: 0.028391167521476746, dist_loss: 0.48130038380622864
recon_loss: 0.028390411287546158, dist_loss: 0.4979623556137085
recon_loss: 0.028391094878315926, dist_loss: 0.5544414520263672
recon_loss: 0.028390895575284958, dist_loss: 0.6775095462799072
recon_loss: 0.028391798958182335, dist_loss: 0.553413450717926
recon_loss: 0.02839294821023941, dist_loss: 0.3660668730735779
recon_loss: 0.028392011299729347, dist_loss: 0.8067004680633545
recon_loss: 0.028393583372235298, dist_loss: 1.051447868347168
recon_loss: 0.0283928494900465, dist_loss: 0.729378342628479
recon_loss: 0.028392178937792778, dist_loss: 1.092504858970642
recon_loss: 0.0283928532153368, dist_loss: 0.7869307994842529
recon_loss: 0.028391532599925995, dist_loss: 0.6347260475158691
recon_loss: 0.02839050628244877, dist_loss: 0.5235466957092285
recon_loss: 0.028391700237989426, dist_loss: 1.0110228061676025
recon_loss: 0.028389645740389824, dist_loss: 0.6248100996017456
recon_loss: 0.028388837352395058, dist_loss: 0.5549076795578003
recon_loss: 0.028389781713485718, dist_loss: 0.5864588618278503
recon_loss: 0.028388265520334244, dist_loss: 0.6871188879013062
recon_loss: 0.02838880382478237, dist_loss: 0.37078413367271423
recon_loss: 0.02838985249400139, dist_loss: 0.7230872511863708
recon_loss: 0.028388220816850662, dist_loss: 0.48501092195510864
recon_loss: 0.02838965319097042, dist_loss: 0.5196325182914734
recon_loss: 0.028389841318130493, dist_loss: 0.8095766305923462
recon_loss: 0.028388328850269318, dist_loss: 0.6127209067344666
recon_loss: 0.02838902920484543, dist_loss: 0.6093044877052307
recon_loss: 0.028388438746333122, dist_loss: 0.5326610207557678
recon_loss: 0.02838725969195366, dist_loss: 0.8150293231010437
recon_loss: 0.028387898579239845, dist_loss: 0.5783584713935852
recon_loss: 0.028386767953634262, dist_loss: 0.5436427593231201
recon_loss: 0.028386501595377922, dist_loss: 0.4775908291339874
recon_loss: 0.028386840596795082, dist_loss: 0.4787622392177582
recon_loss: 0.02838612161576748, dist_loss: 0.8725882172584534
recon_loss: 0.028386292979121208, dist_loss: 0.4829173684120178
recon_loss: 0.028386173769831657, dist_loss: 0.6219962239265442
recon_loss: 0.028385773301124573, dist_loss: 0.9846744537353516
recon_loss: 0.028386088088154793, dist_loss: 0.780032753944397
recon_loss: 0.028385667130351067, dist_loss: 0.5783274173736572
recon_loss: 0.02838602475821972, dist_loss: 0.4383428692817688
recon_loss: 0.028385968878865242, dist_loss: 0.7009440660476685
recon_loss: 0.028385506942868233, dist_loss: 0.3337911367416382
recon_loss: 0.028385888785123825, dist_loss: 0.2508721947669983
recon_loss: 0.028385546058416367, dist_loss: 1.0862376689910889
recon_loss: 0.028385605663061142, dist_loss: 0.44327056407928467
recon_loss: 0.0283857062458992, dist_loss: 1.0250571966171265
recon_loss: 0.028385380282998085, dist_loss: 0.6525102853775024
recon_loss: 0.028385277837514877, dist_loss: 0.9889011979103088
recon_loss: 0.028384918347001076, dist_loss: 0.5392980575561523
recon_loss: 0.028384825214743614, dist_loss: 0.9103044271469116
recon_loss: 0.02838493511080742, dist_loss: 0.9374507069587708
recon_loss: 0.02838418260216713, dist_loss: 0.6288822293281555
recon_loss: 0.02838413044810295, dist_loss: 0.9788731336593628
recon_loss: 0.02838388830423355, dist_loss: 0.5754615068435669
recon_loss: 0.02838403545320034, dist_loss: 0.8288037776947021
recon_loss: 0.028383739292621613, dist_loss: 0.5859382152557373
recon_loss: 0.028383353725075722, dist_loss: 0.658831000328064
recon_loss: 0.02838342823088169, dist_loss: 0.3797798752784729
recon_loss: 0.028383200988173485, dist_loss: 0.67003333568573
recon_loss: 0.0283831637352705, dist_loss: 0.6459361910820007
recon_loss: 0.02838342823088169, dist_loss: 0.5205026865005493
recon_loss: 0.028383543714880943, dist_loss: 0.6528918743133545
recon_loss: 0.02838435210287571, dist_loss: 0.7951236963272095
recon_loss: 0.02838527411222458, dist_loss: 0.5253862142562866
recon_loss: 0.028385447338223457, dist_loss: 0.4305267632007599
recon_loss: 0.028385290876030922, dist_loss: 0.6545801162719727
recon_loss: 0.028385555371642113, dist_loss: 0.5688523650169373
recon_loss: 0.02838560938835144, dist_loss: 0.836116373538971
recon_loss: 0.028386259451508522, dist_loss: 0.528579831123352
recon_loss: 0.028386440128087997, dist_loss: 0.4169970154762268
recon_loss: 0.02838616631925106, dist_loss: 0.4785148799419403
Pre-training Epoch 68:  74%|███████▍  | 271/367 [00:01<00:00, 151.63it/s]Pre-training Epoch 68:  78%|███████▊  | 287/367 [00:01<00:00, 152.76it/s]Pre-training Epoch 68:  83%|████████▎ | 303/367 [00:01<00:00, 152.87it/s]Pre-training Epoch 68:  87%|████████▋ | 319/367 [00:02<00:00, 152.49it/s]Pre-training Epoch 68:  91%|█████████▏| 335/367 [00:02<00:00, 145.57it/s]Pre-training Epoch 68:  96%|█████████▌| 351/367 [00:02<00:00, 148.24it/s]Pre-training Epoch 68: 100%|██████████| 367/367 [00:02<00:00, 149.73it/s]Pre-training Epoch 68: 100%|██████████| 367/367 [00:02<00:00, 151.06it/s]
recon_loss: 0.028385963290929794, dist_loss: 0.7323793172836304
recon_loss: 0.028385858982801437, dist_loss: 0.5219476819038391
recon_loss: 0.028385445475578308, dist_loss: 0.44710543751716614
recon_loss: 0.028385231271386147, dist_loss: 0.44714057445526123
recon_loss: 0.02838517539203167, dist_loss: 0.2795703411102295
recon_loss: 0.028385432437062263, dist_loss: 0.8231205344200134
recon_loss: 0.028385702520608902, dist_loss: 0.41188207268714905
recon_loss: 0.028385065495967865, dist_loss: 0.49028271436691284
recon_loss: 0.028384219855070114, dist_loss: 0.41092729568481445
recon_loss: 0.028383826836943626, dist_loss: 0.47095730900764465
recon_loss: 0.02838370017707348, dist_loss: 0.5621311664581299
recon_loss: 0.02838335558772087, dist_loss: 0.6657263040542603
recon_loss: 0.02838294580578804, dist_loss: 0.8223279118537903
recon_loss: 0.02838270738720894, dist_loss: 1.2985060214996338
recon_loss: 0.028381934389472008, dist_loss: 0.4906008243560791
recon_loss: 0.028381280601024628, dist_loss: 0.8481454849243164
recon_loss: 0.028381770476698875, dist_loss: 0.743229866027832
recon_loss: 0.028380995616316795, dist_loss: 0.4945286512374878
recon_loss: 0.02838154509663582, dist_loss: 0.647060215473175
recon_loss: 0.028381453827023506, dist_loss: 0.6529519557952881
recon_loss: 0.028380300849676132, dist_loss: 0.5538253784179688
recon_loss: 0.028380639851093292, dist_loss: 0.8150871396064758
recon_loss: 0.028380149975419044, dist_loss: 0.46794605255126953
recon_loss: 0.028380652889609337, dist_loss: 0.5513660907745361
recon_loss: 0.028381146490573883, dist_loss: 0.7591685056686401
recon_loss: 0.028381040319800377, dist_loss: 0.4319753050804138
recon_loss: 0.028381308540701866, dist_loss: 0.603283703327179
recon_loss: 0.02838161773979664, dist_loss: 0.572451114654541
recon_loss: 0.02838265895843506, dist_loss: 0.9614368677139282
recon_loss: 0.028383400291204453, dist_loss: 0.4501868188381195
recon_loss: 0.028383804485201836, dist_loss: 0.4352421164512634
recon_loss: 0.028384307399392128, dist_loss: 0.3620811104774475
recon_loss: 0.028384406119585037, dist_loss: 0.7820307016372681
recon_loss: 0.028383728116750717, dist_loss: 0.5036965608596802
recon_loss: 0.028382766991853714, dist_loss: 0.5336412787437439
recon_loss: 0.02838188223540783, dist_loss: 1.1056718826293945
recon_loss: 0.02838125079870224, dist_loss: 0.5767345428466797
recon_loss: 0.028380686417222023, dist_loss: 0.4996384382247925
recon_loss: 0.028380323201417923, dist_loss: 0.5863072276115417
recon_loss: 0.028379851952195168, dist_loss: 0.34935376048088074
recon_loss: 0.02837930992245674, dist_loss: 0.6637263298034668
recon_loss: 0.028378741815686226, dist_loss: 0.6290580034255981
recon_loss: 0.028378412127494812, dist_loss: 0.5079234838485718
recon_loss: 0.028378071263432503, dist_loss: 0.5970133543014526
recon_loss: 0.028377849608659744, dist_loss: 0.6364613771438599
recon_loss: 0.028377609327435493, dist_loss: 0.8932764530181885
recon_loss: 0.028377419337630272, dist_loss: 0.49284517765045166
recon_loss: 0.028377477079629898, dist_loss: 1.049813985824585
recon_loss: 0.028377600014209747, dist_loss: 0.4597400426864624
recon_loss: 0.028377357870340347, dist_loss: 0.46586281061172485
recon_loss: 0.028377264738082886, dist_loss: 0.7468328475952148
recon_loss: 0.028377363458275795, dist_loss: 0.614625871181488
recon_loss: 0.028377212584018707, dist_loss: 0.6018972396850586
recon_loss: 0.028376955538988113, dist_loss: 0.6217238903045654
recon_loss: 0.028376763686537743, dist_loss: 0.8804849982261658
recon_loss: 0.028376681730151176, dist_loss: 0.6269756555557251
recon_loss: 0.02837669663131237, dist_loss: 0.5544490814208984
recon_loss: 0.028376732021570206, dist_loss: 0.5024774670600891
recon_loss: 0.028376838192343712, dist_loss: 0.5403257608413696
recon_loss: 0.028377799317240715, dist_loss: 0.8967762589454651
recon_loss: 0.028378043323755264, dist_loss: 0.3979420065879822
recon_loss: 0.02837860956788063, dist_loss: 0.5496867895126343
recon_loss: 0.028379596769809723, dist_loss: 0.8369313478469849
recon_loss: 0.028379477560520172, dist_loss: 0.993065595626831
recon_loss: 0.028379134833812714, dist_loss: 0.6343774795532227
recon_loss: 0.028379732742905617, dist_loss: 0.3637947738170624
recon_loss: 0.02837863750755787, dist_loss: 0.4893656373023987
recon_loss: 0.0283790435642004, dist_loss: 1.231336236000061
recon_loss: 0.02837899699807167, dist_loss: 0.3759987950325012
recon_loss: 0.028377598151564598, dist_loss: 0.5013502836227417
recon_loss: 0.028376828879117966, dist_loss: 0.7404365539550781
recon_loss: 0.028377199545502663, dist_loss: 0.5872328877449036
recon_loss: 0.028376199305057526, dist_loss: 0.6755412817001343
recon_loss: 0.02837633341550827, dist_loss: 0.7282415628433228
recon_loss: 0.028377210721373558, dist_loss: 0.8172827363014221
recon_loss: 0.028375880792737007, dist_loss: 0.6087839007377625
recon_loss: 0.02837684191763401, dist_loss: 0.6621882915496826
recon_loss: 0.0283773522824049, dist_loss: 0.455081582069397
recon_loss: 0.028378291055560112, dist_loss: 0.5576024651527405
recon_loss: 0.0283797699958086, dist_loss: 0.42767417430877686
recon_loss: 0.028379786759614944, dist_loss: 0.9316698312759399
recon_loss: 0.02838125452399254, dist_loss: 0.3130252957344055
recon_loss: 0.0283817145973444, dist_loss: 0.7458192110061646
recon_loss: 0.02838132157921791, dist_loss: 0.7314082384109497
recon_loss: 0.028380760923027992, dist_loss: 0.685687780380249
recon_loss: 0.02837982587516308, dist_loss: 1.3327100276947021
recon_loss: 0.028379427269101143, dist_loss: 0.658366322517395
recon_loss: 0.028379030525684357, dist_loss: 0.6051353216171265
recon_loss: 0.028376879170536995, dist_loss: 0.5920132398605347
recon_loss: 0.02837640605866909, dist_loss: 0.5928488969802856
recon_loss: 0.02837591990828514, dist_loss: 0.3672851324081421
recon_loss: 0.028375394642353058, dist_loss: 0.6652479767799377
recon_loss: 0.02837606705725193, dist_loss: 0.8870798945426941
recon_loss: 0.028376178815960884, dist_loss: 0.4118279814720154
recon_loss: 0.028377288952469826, dist_loss: 0.5211869478225708
recon_loss: 0.02837817743420601, dist_loss: 0.4083608388900757
recon_loss: 0.02837887406349182, dist_loss: 0.5222536325454712
recon_loss: 0.02837982214987278, dist_loss: 0.5905768871307373
recon_loss: 0.028380637988448143, dist_loss: 0.6399601697921753
recon_loss: 0.02838071435689926, dist_loss: 0.45160120725631714
recon_loss: 0.02838035486638546, dist_loss: 0.48714450001716614
recon_loss: 0.028379244729876518, dist_loss: 0.7769031524658203
recon_loss: 0.02837785705924034, dist_loss: 1.0345407724380493
recon_loss: 0.028377048671245575, dist_loss: 0.5606276988983154
recon_loss: 0.028375957161188126, dist_loss: 0.6724105477333069
recon_loss: 0.028374873101711273, dist_loss: 0.7383599281311035
recon_loss: 0.02837449498474598, dist_loss: 1.4333328008651733
recon_loss: 0.02837376669049263, dist_loss: 0.8723821640014648
recon_loss: 0.028373342007398605, dist_loss: 0.46115535497665405
recon_loss: 0.02837298810482025, dist_loss: 0.5774276852607727
recon_loss: 0.02837277203798294, dist_loss: 0.604213535785675
Pre-training Epoch 69:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 69:   5%|▍         | 18/367 [00:00<00:01, 179.68it/s]Pre-training Epoch 69:  10%|▉         | 36/367 [00:00<00:02, 165.48it/s]Pre-training Epoch 69:  15%|█▍        | 54/367 [00:00<00:01, 171.13it/s]Pre-training Epoch 69:  20%|█▉        | 72/367 [00:00<00:01, 170.47it/s]Pre-training Epoch 69:  25%|██▍       | 90/367 [00:00<00:01, 172.71it/s]Pre-training Epoch 69:  29%|██▉       | 108/367 [00:00<00:01, 173.77it/s]Pre-training Epoch 69:  34%|███▍      | 126/367 [00:00<00:01, 174.24it/s]recon_loss: 0.028373681008815765, dist_loss: 0.841901957988739
recon_loss: 0.028375903144478798, dist_loss: 0.3575757145881653
recon_loss: 0.02837761677801609, dist_loss: 0.7165944576263428
recon_loss: 0.02837856486439705, dist_loss: 0.6357678771018982
recon_loss: 0.02837875671684742, dist_loss: 0.4273887276649475
recon_loss: 0.028378969058394432, dist_loss: 0.6146594882011414
recon_loss: 0.028378549963235855, dist_loss: 0.7892156839370728
recon_loss: 0.028378577902913094, dist_loss: 0.45512422919273376
recon_loss: 0.02837786264717579, dist_loss: 0.7544088363647461
recon_loss: 0.028376614674925804, dist_loss: 0.9591021537780762
recon_loss: 0.028375189751386642, dist_loss: 0.44907835125923157
recon_loss: 0.02837393246591091, dist_loss: 0.594517707824707
recon_loss: 0.028373178094625473, dist_loss: 0.8015519380569458
recon_loss: 0.02837311290204525, dist_loss: 0.3695296049118042
recon_loss: 0.028373098000884056, dist_loss: 0.5475014448165894
recon_loss: 0.02837299555540085, dist_loss: 0.903718113899231
recon_loss: 0.028372669592499733, dist_loss: 0.7147985100746155
recon_loss: 0.028372550383210182, dist_loss: 0.692865788936615
recon_loss: 0.02837255410850048, dist_loss: 0.8475172519683838
recon_loss: 0.028372080996632576, dist_loss: 0.3506530523300171
recon_loss: 0.028371771797537804, dist_loss: 0.6622811555862427
recon_loss: 0.028371552005410194, dist_loss: 0.4358988404273987
recon_loss: 0.028371259570121765, dist_loss: 0.8491355180740356
recon_loss: 0.028371188789606094, dist_loss: 0.36294546723365784
recon_loss: 0.02837125025689602, dist_loss: 0.7765310406684875
recon_loss: 0.02837112732231617, dist_loss: 0.6771005392074585
recon_loss: 0.028370898216962814, dist_loss: 0.7770489454269409
recon_loss: 0.02837076224386692, dist_loss: 1.1905630826950073
recon_loss: 0.028370510786771774, dist_loss: 0.7145078778266907
recon_loss: 0.028370017185807228, dist_loss: 0.866192102432251
recon_loss: 0.02836952917277813, dist_loss: 0.36388590931892395
recon_loss: 0.02836921624839306, dist_loss: 0.5997741222381592
recon_loss: 0.028368772938847542, dist_loss: 0.4724629521369934
recon_loss: 0.028368744999170303, dist_loss: 0.9730550050735474
recon_loss: 0.028369547799229622, dist_loss: 0.40850311517715454
recon_loss: 0.028369050472974777, dist_loss: 0.5665946006774902
recon_loss: 0.0283694788813591, dist_loss: 0.5448383688926697
recon_loss: 0.02836925908923149, dist_loss: 0.6689655780792236
recon_loss: 0.028368862345814705, dist_loss: 0.5716954469680786
recon_loss: 0.028368916362524033, dist_loss: 0.4566614031791687
recon_loss: 0.028368547558784485, dist_loss: 0.4699036478996277
recon_loss: 0.028368530794978142, dist_loss: 0.5454298257827759
recon_loss: 0.02836829237639904, dist_loss: 0.9798597097396851
recon_loss: 0.028367871418595314, dist_loss: 0.5257270336151123
recon_loss: 0.028367452323436737, dist_loss: 0.4522243142127991
recon_loss: 0.028367184102535248, dist_loss: 0.8400973081588745
recon_loss: 0.028366953134536743, dist_loss: 0.8317664861679077
recon_loss: 0.02836683578789234, dist_loss: 0.4490845799446106
recon_loss: 0.02836681343615055, dist_loss: 0.7811115384101868
recon_loss: 0.028366858139634132, dist_loss: 1.0717458724975586
recon_loss: 0.028366753831505775, dist_loss: 0.7769345045089722
recon_loss: 0.028367215767502785, dist_loss: 0.5947174429893494
recon_loss: 0.028367532417178154, dist_loss: 0.7814064025878906
recon_loss: 0.028368376195430756, dist_loss: 0.9536203742027283
recon_loss: 0.028368808329105377, dist_loss: 0.9346680641174316
recon_loss: 0.02836901880800724, dist_loss: 0.4691581130027771
recon_loss: 0.028369195759296417, dist_loss: 0.4600366950035095
recon_loss: 0.028369460254907608, dist_loss: 0.8086669445037842
recon_loss: 0.028370097279548645, dist_loss: 0.8444629907608032
recon_loss: 0.028370581567287445, dist_loss: 0.5900853872299194
recon_loss: 0.0283714160323143, dist_loss: 0.743061900138855
recon_loss: 0.028372224420309067, dist_loss: 0.9867315888404846
recon_loss: 0.02837224304676056, dist_loss: 0.667670726776123
recon_loss: 0.028371570631861687, dist_loss: 0.5924713611602783
recon_loss: 0.028370574116706848, dist_loss: 0.6569404006004333
recon_loss: 0.02836957573890686, dist_loss: 0.6255478262901306
recon_loss: 0.028368782252073288, dist_loss: 0.9363131523132324
recon_loss: 0.02836822159588337, dist_loss: 0.5469459295272827
recon_loss: 0.028366848826408386, dist_loss: 0.6500318050384521
recon_loss: 0.028366319835186005, dist_loss: 0.5345585942268372
recon_loss: 0.028366265818476677, dist_loss: 0.6231971979141235
recon_loss: 0.028366388753056526, dist_loss: 1.3291103839874268
recon_loss: 0.028367606922984123, dist_loss: 0.5903877019882202
recon_loss: 0.028367793187499046, dist_loss: 1.0642292499542236
recon_loss: 0.028368864208459854, dist_loss: 0.3250001072883606
recon_loss: 0.028370842337608337, dist_loss: 0.3671487867832184
recon_loss: 0.028372444212436676, dist_loss: 0.5127201676368713
recon_loss: 0.028374770656228065, dist_loss: 0.4510810077190399
recon_loss: 0.028373820707201958, dist_loss: 0.5790762901306152
recon_loss: 0.028373876586556435, dist_loss: 0.8756992220878601
recon_loss: 0.028373567387461662, dist_loss: 0.36543601751327515
recon_loss: 0.028370728716254234, dist_loss: 0.5824859142303467
recon_loss: 0.028370754793286324, dist_loss: 0.6909134387969971
recon_loss: 0.028369510546326637, dist_loss: 0.5275051593780518
recon_loss: 0.02836710959672928, dist_loss: 0.4553195834159851
recon_loss: 0.02836759388446808, dist_loss: 1.252934217453003
recon_loss: 0.02836601622402668, dist_loss: 0.712130606174469
recon_loss: 0.028365423902869225, dist_loss: 0.6124989986419678
recon_loss: 0.028366336598992348, dist_loss: 0.9346964955329895
recon_loss: 0.02836546115577221, dist_loss: 0.3676932454109192
recon_loss: 0.028364624828100204, dist_loss: 0.5114103555679321
recon_loss: 0.028364745900034904, dist_loss: 0.9192977547645569
recon_loss: 0.028363915160298347, dist_loss: 0.6290685534477234
recon_loss: 0.028364190831780434, dist_loss: 0.3515567183494568
recon_loss: 0.028364691883325577, dist_loss: 0.5595322251319885
recon_loss: 0.02836439572274685, dist_loss: 0.49857228994369507
recon_loss: 0.028363866731524467, dist_loss: 0.5082127451896667
recon_loss: 0.028363429009914398, dist_loss: 0.327237069606781
recon_loss: 0.028363266959786415, dist_loss: 1.229636311531067
recon_loss: 0.028363849967718124, dist_loss: 0.5173634886741638
recon_loss: 0.02836395613849163, dist_loss: 0.45967090129852295
recon_loss: 0.028363700956106186, dist_loss: 1.306304931640625
recon_loss: 0.02836381271481514, dist_loss: 1.0676665306091309
recon_loss: 0.02836245857179165, dist_loss: 1.0973243713378906
recon_loss: 0.02836335264146328, dist_loss: 0.7451701760292053
recon_loss: 0.028363443911075592, dist_loss: 0.664048433303833
recon_loss: 0.02836279571056366, dist_loss: 0.587598443031311
recon_loss: 0.028362775221467018, dist_loss: 0.36171916127204895
recon_loss: 0.02836179919540882, dist_loss: 0.5686137080192566
recon_loss: 0.028362099081277847, dist_loss: 0.44643634557724
recon_loss: 0.028362078592181206, dist_loss: 0.6807056069374084
recon_loss: 0.028362151235342026, dist_loss: 0.678455650806427
recon_loss: 0.02836228348314762, dist_loss: 0.5124754905700684
recon_loss: 0.028361337259411812, dist_loss: 0.5340456366539001
recon_loss: 0.028361227363348007, dist_loss: 0.5384652614593506
recon_loss: 0.028361009433865547, dist_loss: 0.9560744762420654
recon_loss: 0.028360916301608086, dist_loss: 0.6599479913711548
recon_loss: 0.028361396864056587, dist_loss: 0.4350506067276001
recon_loss: 0.028360798954963684, dist_loss: 0.7823481559753418
recon_loss: 0.028360839933156967, dist_loss: 1.00634765625
recon_loss: 0.028360962867736816, dist_loss: 1.166325330734253
recon_loss: 0.02836030349135399, dist_loss: 0.8346548676490784
recon_loss: 0.0283608827739954, dist_loss: 0.7041376233100891
recon_loss: 0.02836127020418644, dist_loss: 0.5196415185928345
recon_loss: 0.028361033648252487, dist_loss: 0.6824679970741272
recon_loss: 0.028361007571220398, dist_loss: 1.0006439685821533
recon_loss: 0.028360381722450256, dist_loss: 0.7109931111335754
recon_loss: 0.028360281139612198, dist_loss: 0.8558205962181091
Pre-training Epoch 69:  39%|███▉      | 144/367 [00:00<00:01, 174.14it/s]Pre-training Epoch 69:  44%|████▍     | 162/367 [00:00<00:01, 172.78it/s]Pre-training Epoch 69:  49%|████▉     | 180/367 [00:01<00:01, 174.64it/s]Pre-training Epoch 69:  54%|█████▍    | 198/367 [00:01<00:00, 175.61it/s]Pre-training Epoch 69:  59%|█████▉    | 216/367 [00:01<00:00, 163.02it/s]Pre-training Epoch 69:  63%|██████▎   | 233/367 [00:01<00:00, 158.44it/s]Pre-training Epoch 69:  68%|██████▊   | 251/367 [00:01<00:00, 163.53it/s]recon_loss: 0.028360748663544655, dist_loss: 0.3906151056289673
recon_loss: 0.028360916301608086, dist_loss: 0.7897917032241821
recon_loss: 0.028360983356833458, dist_loss: 0.44748032093048096
recon_loss: 0.028360938653349876, dist_loss: 0.6628473997116089
recon_loss: 0.02836022712290287, dist_loss: 0.5231055021286011
recon_loss: 0.02836015075445175, dist_loss: 1.3365775346755981
recon_loss: 0.0283601526170969, dist_loss: 0.5593531727790833
recon_loss: 0.028360405936837196, dist_loss: 0.46325981616973877
recon_loss: 0.028360815718770027, dist_loss: 0.8347004055976868
recon_loss: 0.028360359370708466, dist_loss: 0.590788722038269
recon_loss: 0.028360212221741676, dist_loss: 0.5585048198699951
recon_loss: 0.028359435498714447, dist_loss: 0.6930765509605408
recon_loss: 0.02835955284535885, dist_loss: 0.727681577205658
recon_loss: 0.028359944000840187, dist_loss: 0.8112751245498657
recon_loss: 0.028359340503811836, dist_loss: 0.42597705125808716
recon_loss: 0.028360091149806976, dist_loss: 0.4984644055366516
recon_loss: 0.028359562158584595, dist_loss: 0.5533077716827393
recon_loss: 0.028358761221170425, dist_loss: 0.8454839587211609
recon_loss: 0.02835940010845661, dist_loss: 0.5954312086105347
recon_loss: 0.02835930325090885, dist_loss: 0.44833260774612427
recon_loss: 0.028359342366456985, dist_loss: 0.44148898124694824
recon_loss: 0.028359653428196907, dist_loss: 0.6262438893318176
recon_loss: 0.028358107432723045, dist_loss: 0.903972864151001
recon_loss: 0.02835904248058796, dist_loss: 0.44170689582824707
recon_loss: 0.02835911698639393, dist_loss: 1.1246421337127686
recon_loss: 0.028358226642012596, dist_loss: 1.0649784803390503
recon_loss: 0.028359422460198402, dist_loss: 0.7798388600349426
recon_loss: 0.02835940383374691, dist_loss: 0.7320422530174255
recon_loss: 0.028358744457364082, dist_loss: 0.6897639036178589
recon_loss: 0.028359560295939445, dist_loss: 0.5645251870155334
recon_loss: 0.02835860662162304, dist_loss: 0.6451430916786194
recon_loss: 0.028358958661556244, dist_loss: 0.5977639555931091
recon_loss: 0.028358926996588707, dist_loss: 0.5103254914283752
recon_loss: 0.028358055278658867, dist_loss: 0.3797915279865265
recon_loss: 0.028358347713947296, dist_loss: 0.5083999037742615
recon_loss: 0.02835754305124283, dist_loss: 0.9708307385444641
recon_loss: 0.0283573716878891, dist_loss: 0.26470863819122314
recon_loss: 0.028358012437820435, dist_loss: 1.1076304912567139
recon_loss: 0.028356702998280525, dist_loss: 0.5841686725616455
recon_loss: 0.02835625223815441, dist_loss: 0.8566613793373108
recon_loss: 0.028356723487377167, dist_loss: 0.5561230182647705
recon_loss: 0.028356244787573814, dist_loss: 0.6246087551116943
recon_loss: 0.02835663966834545, dist_loss: 0.9012489318847656
recon_loss: 0.028357479721307755, dist_loss: 0.6964843273162842
recon_loss: 0.028356119990348816, dist_loss: 0.6977096796035767
recon_loss: 0.028356311842799187, dist_loss: 0.7850542068481445
recon_loss: 0.028356965631246567, dist_loss: 0.4892975687980652
recon_loss: 0.028355639427900314, dist_loss: 0.6484545469284058
recon_loss: 0.028356142342090607, dist_loss: 0.7350248098373413
recon_loss: 0.028355790302157402, dist_loss: 0.48817387223243713
recon_loss: 0.0283553097397089, dist_loss: 0.5177409648895264
recon_loss: 0.028355857357382774, dist_loss: 0.5580888390541077
recon_loss: 0.028355611488223076, dist_loss: 0.48583924770355225
recon_loss: 0.028355387970805168, dist_loss: 0.5591162443161011
recon_loss: 0.028355415910482407, dist_loss: 0.3881776034832001
recon_loss: 0.028354784473776817, dist_loss: 0.7625689506530762
recon_loss: 0.028354985639452934, dist_loss: 0.7567328214645386
recon_loss: 0.028354745358228683, dist_loss: 0.7993689775466919
recon_loss: 0.028354763984680176, dist_loss: 0.8572793006896973
recon_loss: 0.028354771435260773, dist_loss: 0.740415096282959
recon_loss: 0.028354518115520477, dist_loss: 0.582175612449646
recon_loss: 0.028354743495583534, dist_loss: 0.6741535663604736
recon_loss: 0.028354886919260025, dist_loss: 0.9734035134315491
recon_loss: 0.028354797512292862, dist_loss: 0.6700500845909119
recon_loss: 0.028354745358228683, dist_loss: 0.5327774286270142
recon_loss: 0.028354370966553688, dist_loss: 0.9534138441085815
recon_loss: 0.02835480310022831, dist_loss: 0.5580325722694397
recon_loss: 0.028355073183774948, dist_loss: 0.6272506713867188
recon_loss: 0.028354350477457047, dist_loss: 0.9024824500083923
recon_loss: 0.02835497446358204, dist_loss: 0.9631558656692505
recon_loss: 0.028355032205581665, dist_loss: 0.3825760781764984
recon_loss: 0.02835569903254509, dist_loss: 0.5961570143699646
recon_loss: 0.028356261551380157, dist_loss: 0.9181299805641174
recon_loss: 0.028356334194540977, dist_loss: 0.6882428526878357
recon_loss: 0.028357045724987984, dist_loss: 0.5717946290969849
recon_loss: 0.02835792861878872, dist_loss: 0.7611550688743591
recon_loss: 0.02835872955620289, dist_loss: 0.4725230932235718
recon_loss: 0.02835911512374878, dist_loss: 0.44033077359199524
recon_loss: 0.02835911326110363, dist_loss: 0.34715959429740906
recon_loss: 0.028359228745102882, dist_loss: 0.3277745246887207
recon_loss: 0.028359148651361465, dist_loss: 0.6929463148117065
recon_loss: 0.028358496725559235, dist_loss: 1.0265607833862305
recon_loss: 0.02835771068930626, dist_loss: 0.5906398892402649
recon_loss: 0.028357381001114845, dist_loss: 0.7915083169937134
recon_loss: 0.028356507420539856, dist_loss: 0.5261982679367065
recon_loss: 0.028356408700346947, dist_loss: 0.516670823097229
recon_loss: 0.028356216847896576, dist_loss: 0.9552778005599976
recon_loss: 0.028356807306408882, dist_loss: 0.5296977758407593
recon_loss: 0.028357381001114845, dist_loss: 0.29875099658966064
recon_loss: 0.02835754118859768, dist_loss: 0.5055423974990845
recon_loss: 0.028358954936265945, dist_loss: 0.4074554443359375
recon_loss: 0.02836042456328869, dist_loss: 0.7870086431503296
recon_loss: 0.028360938653349876, dist_loss: 0.33658817410469055
recon_loss: 0.02836223691701889, dist_loss: 0.6116973757743835
recon_loss: 0.028362248092889786, dist_loss: 0.5541565418243408
recon_loss: 0.02836254984140396, dist_loss: 0.7226017713546753
recon_loss: 0.02836342342197895, dist_loss: 0.7711791396141052
recon_loss: 0.028364013880491257, dist_loss: 0.41356003284454346
recon_loss: 0.02836453728377819, dist_loss: 0.8561393618583679
recon_loss: 0.028364893049001694, dist_loss: 0.6127761602401733
recon_loss: 0.0283639095723629, dist_loss: 0.6324371099472046
recon_loss: 0.0283629409968853, dist_loss: 1.0325682163238525
recon_loss: 0.028361851349473, dist_loss: 0.53857421875
recon_loss: 0.028360595926642418, dist_loss: 0.6145345568656921
recon_loss: 0.028359614312648773, dist_loss: 0.3671543598175049
recon_loss: 0.028358185663819313, dist_loss: 0.5652240514755249
recon_loss: 0.028357088565826416, dist_loss: 0.4548678398132324
recon_loss: 0.028356052935123444, dist_loss: 0.4907238781452179
recon_loss: 0.028355557471513748, dist_loss: 0.4850500524044037
recon_loss: 0.028355436399579048, dist_loss: 0.41477805376052856
recon_loss: 0.028355486690998077, dist_loss: 0.605463445186615
recon_loss: 0.028356105089187622, dist_loss: 0.7779504060745239
recon_loss: 0.02835741639137268, dist_loss: 0.7257925868034363
recon_loss: 0.02835823968052864, dist_loss: 0.3691290616989136
recon_loss: 0.02835957519710064, dist_loss: 0.6166676878929138
recon_loss: 0.028360681608319283, dist_loss: 0.9922051429748535
recon_loss: 0.028360813856124878, dist_loss: 0.5749112963676453
recon_loss: 0.02836090885102749, dist_loss: 0.684632420539856
recon_loss: 0.02836032584309578, dist_loss: 0.7331683039665222
recon_loss: 0.02836035192012787, dist_loss: 0.8706142902374268
recon_loss: 0.028361042961478233, dist_loss: 0.3814127743244171
recon_loss: 0.028360579162836075, dist_loss: 0.8573566675186157
recon_loss: 0.028360454365611076, dist_loss: 0.43504053354263306
recon_loss: 0.02835870161652565, dist_loss: 1.014799952507019
recon_loss: 0.028357038274407387, dist_loss: 0.49764490127563477
recon_loss: 0.028355935588479042, dist_loss: 0.9917380809783936
recon_loss: 0.028354516252875328, dist_loss: 0.8694770336151123
recon_loss: 0.028353584930300713, dist_loss: 0.43369898200035095
Pre-training Epoch 69:  73%|███████▎  | 269/367 [00:01<00:00, 166.92it/s]Pre-training Epoch 69:  78%|███████▊  | 287/367 [00:01<00:00, 169.52it/s]Pre-training Epoch 69:  83%|████████▎ | 305/367 [00:01<00:00, 171.58it/s]Pre-training Epoch 69:  88%|████████▊ | 323/367 [00:01<00:00, 172.55it/s]Pre-training Epoch 69:  93%|█████████▎| 341/367 [00:01<00:00, 174.22it/s]Pre-training Epoch 69:  98%|█████████▊| 359/367 [00:02<00:00, 174.63it/s]Pre-training Epoch 69: 100%|██████████| 367/367 [00:02<00:00, 171.14it/s]
recon_loss: 0.028352532535791397, dist_loss: 0.8792173266410828
recon_loss: 0.02835177630186081, dist_loss: 0.4210531711578369
recon_loss: 0.02835189923644066, dist_loss: 0.3374611437320709
recon_loss: 0.028352661058306694, dist_loss: 0.810523271560669
recon_loss: 0.028353413566946983, dist_loss: 0.8045817613601685
recon_loss: 0.028354084119200706, dist_loss: 0.3584580421447754
recon_loss: 0.028354503214359283, dist_loss: 1.046152949333191
recon_loss: 0.02835449017584324, dist_loss: 0.3765242099761963
recon_loss: 0.028354234993457794, dist_loss: 0.8888806104660034
recon_loss: 0.028353679925203323, dist_loss: 0.5264793634414673
recon_loss: 0.028352893888950348, dist_loss: 0.5586701035499573
recon_loss: 0.028351901099085808, dist_loss: 0.6871525645256042
recon_loss: 0.0283510759472847, dist_loss: 0.3821300268173218
recon_loss: 0.028350550681352615, dist_loss: 0.47704029083251953
recon_loss: 0.02835013158619404, dist_loss: 0.3190844655036926
recon_loss: 0.02835005335509777, dist_loss: 0.8394286632537842
recon_loss: 0.028349904343485832, dist_loss: 1.067488670349121
recon_loss: 0.02834978885948658, dist_loss: 0.7065167427062988
recon_loss: 0.0283497404307127, dist_loss: 0.9708942174911499
recon_loss: 0.028349604457616806, dist_loss: 1.1012382507324219
recon_loss: 0.028349407017230988, dist_loss: 0.44791698455810547
recon_loss: 0.028349513188004494, dist_loss: 0.46651798486709595
recon_loss: 0.028349047526717186, dist_loss: 0.38555577397346497
recon_loss: 0.028348585590720177, dist_loss: 0.7160391807556152
recon_loss: 0.028348250314593315, dist_loss: 1.0529038906097412
recon_loss: 0.028347795829176903, dist_loss: 0.7592530250549316
recon_loss: 0.02834763564169407, dist_loss: 0.3578190207481384
recon_loss: 0.02834712155163288, dist_loss: 0.8075721859931946
recon_loss: 0.028346829116344452, dist_loss: 0.48008400201797485
recon_loss: 0.028346538543701172, dist_loss: 0.745307981967926
recon_loss: 0.028346294537186623, dist_loss: 0.7212517857551575
recon_loss: 0.028346193954348564, dist_loss: 0.6319776177406311
recon_loss: 0.028346143662929535, dist_loss: 0.3817371129989624
recon_loss: 0.028346186503767967, dist_loss: 0.5971028804779053
recon_loss: 0.028346383944153786, dist_loss: 0.843611478805542
recon_loss: 0.02834652177989483, dist_loss: 0.4270365834236145
recon_loss: 0.028346620500087738, dist_loss: 0.4245458245277405
recon_loss: 0.028346966952085495, dist_loss: 0.6185871362686157
recon_loss: 0.028346704319119453, dist_loss: 0.5719707012176514
recon_loss: 0.028346452862024307, dist_loss: 0.6408676505088806
recon_loss: 0.028346676379442215, dist_loss: 0.6345775723457336
recon_loss: 0.02834630012512207, dist_loss: 0.47084280848503113
recon_loss: 0.02834543213248253, dist_loss: 0.4351801872253418
recon_loss: 0.028345393016934395, dist_loss: 0.6155539751052856
recon_loss: 0.028345327824354172, dist_loss: 0.6353904604911804
recon_loss: 0.028345201164484024, dist_loss: 0.7082103490829468
recon_loss: 0.028345342725515366, dist_loss: 0.482294499874115
recon_loss: 0.028345022350549698, dist_loss: 0.6267877817153931
recon_loss: 0.028345279395580292, dist_loss: 0.836027979850769
recon_loss: 0.02834489569067955, dist_loss: 0.3662978410720825
recon_loss: 0.028344370424747467, dist_loss: 0.727906346321106
recon_loss: 0.028344329446554184, dist_loss: 0.5286397933959961
recon_loss: 0.028344199061393738, dist_loss: 1.1673650741577148
recon_loss: 0.02834450826048851, dist_loss: 0.7913186550140381
recon_loss: 0.028344834223389626, dist_loss: 0.9336820840835571
recon_loss: 0.028345240280032158, dist_loss: 0.4959986209869385
recon_loss: 0.028345851227641106, dist_loss: 0.935962975025177
recon_loss: 0.028346316888928413, dist_loss: 0.6031800508499146
recon_loss: 0.028346894308924675, dist_loss: 1.3480652570724487
recon_loss: 0.02834724821150303, dist_loss: 0.7262227535247803
recon_loss: 0.02834683656692505, dist_loss: 0.4919489920139313
recon_loss: 0.028346294537186623, dist_loss: 0.5020508170127869
recon_loss: 0.028346072882413864, dist_loss: 0.9776520729064941
recon_loss: 0.028345845639705658, dist_loss: 0.47255802154541016
recon_loss: 0.028345603495836258, dist_loss: 1.3412725925445557
recon_loss: 0.02834559790790081, dist_loss: 1.0061336755752563
recon_loss: 0.028345145285129547, dist_loss: 0.7476089596748352
recon_loss: 0.028345409780740738, dist_loss: 0.7461047768592834
recon_loss: 0.028345473110675812, dist_loss: 1.3097281455993652
recon_loss: 0.028345055878162384, dist_loss: 0.5719401836395264
recon_loss: 0.028344538062810898, dist_loss: 0.6966363191604614
recon_loss: 0.02834414131939411, dist_loss: 0.3328036069869995
recon_loss: 0.028344418853521347, dist_loss: 0.7654282450675964
recon_loss: 0.028343722224235535, dist_loss: 0.6585985422134399
recon_loss: 0.028343698009848595, dist_loss: 0.618803858757019
recon_loss: 0.02834322676062584, dist_loss: 0.6507754325866699
recon_loss: 0.028342897072434425, dist_loss: 1.1427648067474365
recon_loss: 0.02834342233836651, dist_loss: 0.37815678119659424
recon_loss: 0.028343547135591507, dist_loss: 0.7428872585296631
recon_loss: 0.028344321995973587, dist_loss: 0.8897855877876282
recon_loss: 0.028344295918941498, dist_loss: 0.41299062967300415
recon_loss: 0.02834385074675083, dist_loss: 0.7510677576065063
recon_loss: 0.02834395132958889, dist_loss: 0.6653993725776672
recon_loss: 0.02834389917552471, dist_loss: 0.32350045442581177
recon_loss: 0.028343861922621727, dist_loss: 0.5703270435333252
recon_loss: 0.02834372967481613, dist_loss: 1.0706967115402222
recon_loss: 0.02834339067339897, dist_loss: 0.25506970286369324
recon_loss: 0.02834305539727211, dist_loss: 0.7981457710266113
recon_loss: 0.028342625126242638, dist_loss: 0.5050296783447266
recon_loss: 0.028342438861727715, dist_loss: 0.4080994725227356
recon_loss: 0.02834242954850197, dist_loss: 0.6035130023956299
recon_loss: 0.028342466801404953, dist_loss: 1.0349395275115967
recon_loss: 0.02834293618798256, dist_loss: 0.6725266575813293
recon_loss: 0.028343595564365387, dist_loss: 0.674559473991394
recon_loss: 0.0283441711217165, dist_loss: 1.085726022720337
recon_loss: 0.02834448404610157, dist_loss: 0.5899044871330261
recon_loss: 0.028344834223389626, dist_loss: 0.5932443141937256
recon_loss: 0.028344914317131042, dist_loss: 0.8107419610023499
recon_loss: 0.0283450186252594, dist_loss: 0.5008453726768494
recon_loss: 0.028345046564936638, dist_loss: 0.5677015781402588
recon_loss: 0.028344836086034775, dist_loss: 0.8252488374710083
recon_loss: 0.028345251455903053, dist_loss: 0.3911798298358917
recon_loss: 0.028344932943582535, dist_loss: 0.7072499990463257
recon_loss: 0.028344713151454926, dist_loss: 0.5625166893005371
recon_loss: 0.02834470383822918, dist_loss: 0.646247386932373
recon_loss: 0.028344083577394485, dist_loss: 0.8375670909881592
recon_loss: 0.028344271704554558, dist_loss: 0.5806640386581421
recon_loss: 0.028343740850687027, dist_loss: 0.5125329494476318
recon_loss: 0.028344009071588516, dist_loss: 0.41948196291923523
recon_loss: 0.028343569487333298, dist_loss: 0.8075739145278931
recon_loss: 0.02834324724972248, dist_loss: 1.2813374996185303
Pre-training Epoch 70:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 70:   5%|▍         | 17/367 [00:00<00:02, 169.55it/s]Pre-training Epoch 70:  10%|▉         | 35/367 [00:00<00:01, 173.33it/s]Pre-training Epoch 70:  14%|█▍        | 53/367 [00:00<00:01, 173.86it/s]Pre-training Epoch 70:  19%|█▉        | 71/367 [00:00<00:01, 174.60it/s]Pre-training Epoch 70:  24%|██▍       | 89/367 [00:00<00:01, 175.28it/s]Pre-training Epoch 70:  29%|██▉       | 107/367 [00:00<00:01, 174.75it/s]Pre-training Epoch 70:  34%|███▍      | 125/367 [00:00<00:01, 174.64it/s]recon_loss: 0.02834431268274784, dist_loss: 0.4967557191848755
recon_loss: 0.028343243524432182, dist_loss: 0.43222758173942566
recon_loss: 0.028342507779598236, dist_loss: 0.5368096828460693
recon_loss: 0.028342794626951218, dist_loss: 0.6680856347084045
recon_loss: 0.0283418670296669, dist_loss: 0.4754486382007599
recon_loss: 0.028342025354504585, dist_loss: 0.9606136083602905
recon_loss: 0.02834191918373108, dist_loss: 0.7255744934082031
recon_loss: 0.028342120349407196, dist_loss: 0.614453911781311
recon_loss: 0.028342103585600853, dist_loss: 0.6560530662536621
recon_loss: 0.028341567143797874, dist_loss: 0.5717322826385498
recon_loss: 0.028341690078377724, dist_loss: 0.9718751311302185
recon_loss: 0.028341373428702354, dist_loss: 0.5275079607963562
recon_loss: 0.02834131009876728, dist_loss: 0.8191379308700562
recon_loss: 0.02834126725792885, dist_loss: 0.5523056983947754
recon_loss: 0.028341220691800117, dist_loss: 0.9222652912139893
recon_loss: 0.02834084816277027, dist_loss: 0.7774014472961426
recon_loss: 0.028340807184576988, dist_loss: 0.34693843126296997
recon_loss: 0.028340457007288933, dist_loss: 0.5449286699295044
recon_loss: 0.02834085002541542, dist_loss: 0.8962628841400146
recon_loss: 0.028340691700577736, dist_loss: 0.6987273097038269
recon_loss: 0.02834014594554901, dist_loss: 0.35464078187942505
recon_loss: 0.02834032103419304, dist_loss: 0.6910183429718018
recon_loss: 0.028340090066194534, dist_loss: 0.6586094498634338
recon_loss: 0.028340356424450874, dist_loss: 0.6924058198928833
recon_loss: 0.028340991586446762, dist_loss: 0.6010850071907043
recon_loss: 0.028340572491288185, dist_loss: 0.7142105102539062
recon_loss: 0.02834080345928669, dist_loss: 0.6095621585845947
recon_loss: 0.028340043500065804, dist_loss: 0.5647628307342529
recon_loss: 0.028339743614196777, dist_loss: 0.30022814869880676
recon_loss: 0.02833978459239006, dist_loss: 0.7468957901000977
recon_loss: 0.028339073061943054, dist_loss: 0.5676556825637817
recon_loss: 0.02833893895149231, dist_loss: 0.5049463510513306
recon_loss: 0.028338389471173286, dist_loss: 0.625977635383606
recon_loss: 0.028338031843304634, dist_loss: 0.5983065962791443
recon_loss: 0.028337983414530754, dist_loss: 0.6661851406097412
recon_loss: 0.02833814173936844, dist_loss: 0.46663931012153625
recon_loss: 0.02833855338394642, dist_loss: 0.5917477607727051
recon_loss: 0.028338821604847908, dist_loss: 0.24318616092205048
recon_loss: 0.028338991105556488, dist_loss: 0.7529661059379578
recon_loss: 0.028339212760329247, dist_loss: 0.4129664897918701
recon_loss: 0.02833951637148857, dist_loss: 0.9043082594871521
recon_loss: 0.028339775279164314, dist_loss: 0.49756669998168945
recon_loss: 0.028339652344584465, dist_loss: 0.5129300951957703
recon_loss: 0.028339512646198273, dist_loss: 0.668639063835144
recon_loss: 0.028339294716715813, dist_loss: 0.9283220767974854
recon_loss: 0.028338823467493057, dist_loss: 0.40004676580429077
recon_loss: 0.028338231146335602, dist_loss: 0.6107490062713623
recon_loss: 0.028337787836790085, dist_loss: 0.4665924310684204
recon_loss: 0.02833758294582367, dist_loss: 1.0244704484939575
recon_loss: 0.028337683528661728, dist_loss: 0.7359548211097717
recon_loss: 0.028338493779301643, dist_loss: 0.6736541986465454
recon_loss: 0.028339724987745285, dist_loss: 0.45826178789138794
recon_loss: 0.028340406715869904, dist_loss: 0.5513678193092346
recon_loss: 0.028341468423604965, dist_loss: 0.6552907228469849
recon_loss: 0.028342369943857193, dist_loss: 0.4901737868785858
recon_loss: 0.02834298647940159, dist_loss: 0.6019396185874939
recon_loss: 0.02834370918571949, dist_loss: 0.8161283731460571
recon_loss: 0.028343910351395607, dist_loss: 0.7856057286262512
recon_loss: 0.028343627229332924, dist_loss: 0.7134518027305603
recon_loss: 0.028344159945845604, dist_loss: 0.5250017046928406
recon_loss: 0.02834421768784523, dist_loss: 0.6177480220794678
recon_loss: 0.028343353420495987, dist_loss: 0.9714609384536743
recon_loss: 0.028343552723526955, dist_loss: 0.5117478370666504
recon_loss: 0.028342442587018013, dist_loss: 0.6678273677825928
recon_loss: 0.02834123559296131, dist_loss: 0.4538869559764862
recon_loss: 0.02834067866206169, dist_loss: 0.6741776466369629
recon_loss: 0.028339775279164314, dist_loss: 0.48086315393447876
recon_loss: 0.028338782489299774, dist_loss: 0.7283623218536377
recon_loss: 0.02833833172917366, dist_loss: 0.6683650016784668
recon_loss: 0.028337910771369934, dist_loss: 0.5359185934066772
recon_loss: 0.02833808772265911, dist_loss: 0.9702249765396118
recon_loss: 0.028337901458144188, dist_loss: 0.4191321134567261
recon_loss: 0.028337618336081505, dist_loss: 0.5219697952270508
recon_loss: 0.028337817639112473, dist_loss: 0.7586837410926819
recon_loss: 0.028336914256215096, dist_loss: 0.9508668780326843
recon_loss: 0.02833598479628563, dist_loss: 0.9277282357215881
recon_loss: 0.02833600714802742, dist_loss: 0.9648078680038452
recon_loss: 0.028335008770227432, dist_loss: 0.49174439907073975
recon_loss: 0.02833482064306736, dist_loss: 0.5656920075416565
recon_loss: 0.028334343805909157, dist_loss: 0.6624476909637451
recon_loss: 0.02833378314971924, dist_loss: 0.8132346868515015
recon_loss: 0.028333798050880432, dist_loss: 0.6518529653549194
recon_loss: 0.028333235532045364, dist_loss: 0.4267289638519287
recon_loss: 0.02833368442952633, dist_loss: 0.4940536618232727
recon_loss: 0.028333522379398346, dist_loss: 0.8348509073257446
recon_loss: 0.028333310037851334, dist_loss: 0.8529463410377502
recon_loss: 0.028333600610494614, dist_loss: 0.8158597946166992
recon_loss: 0.028333567082881927, dist_loss: 0.6196370124816895
recon_loss: 0.02833336405456066, dist_loss: 0.4117733836174011
recon_loss: 0.028333419933915138, dist_loss: 0.4030584692955017
recon_loss: 0.028333403170108795, dist_loss: 0.6083618998527527
recon_loss: 0.028333213180303574, dist_loss: 0.8328642249107361
recon_loss: 0.028333274647593498, dist_loss: 0.9160503149032593
recon_loss: 0.028332697227597237, dist_loss: 0.748024046421051
recon_loss: 0.028332985937595367, dist_loss: 0.6160374283790588
recon_loss: 0.028332510963082314, dist_loss: 0.42798739671707153
recon_loss: 0.028332054615020752, dist_loss: 0.824774980545044
recon_loss: 0.02833179011940956, dist_loss: 0.7835804224014282
recon_loss: 0.028331782668828964, dist_loss: 0.6657286882400513
recon_loss: 0.028331812471151352, dist_loss: 0.7282770872116089
recon_loss: 0.02833172120153904, dist_loss: 0.3966086506843567
recon_loss: 0.028331873938441277, dist_loss: 0.4278944730758667
recon_loss: 0.028331270441412926, dist_loss: 0.6747866272926331
recon_loss: 0.028331371024250984, dist_loss: 0.513088583946228
recon_loss: 0.02833160012960434, dist_loss: 0.649215579032898
recon_loss: 0.028331758454442024, dist_loss: 0.6322157382965088
recon_loss: 0.028332462534308434, dist_loss: 0.6143553256988525
recon_loss: 0.02833293005824089, dist_loss: 0.9318503141403198
recon_loss: 0.028332935646176338, dist_loss: 0.5571143627166748
recon_loss: 0.028333021327853203, dist_loss: 0.9009966850280762
recon_loss: 0.028332335874438286, dist_loss: 0.44445765018463135
recon_loss: 0.028332410380244255, dist_loss: 0.4323572814464569
recon_loss: 0.028331659734249115, dist_loss: 0.7770956754684448
recon_loss: 0.028330981731414795, dist_loss: 1.127495527267456
recon_loss: 0.028330376371741295, dist_loss: 0.7142679691314697
recon_loss: 0.028329825028777122, dist_loss: 0.5684422254562378
recon_loss: 0.028329996392130852, dist_loss: 0.7033467888832092
recon_loss: 0.028329767286777496, dist_loss: 0.829007625579834
recon_loss: 0.028329888358712196, dist_loss: 0.8263990879058838
recon_loss: 0.02832997962832451, dist_loss: 0.5318619012832642
recon_loss: 0.028329797089099884, dist_loss: 0.6619032621383667
recon_loss: 0.028329797089099884, dist_loss: 0.4345119595527649
recon_loss: 0.02832956425845623, dist_loss: 0.5181375741958618
recon_loss: 0.028329329565167427, dist_loss: 0.5472469329833984
recon_loss: 0.028328871354460716, dist_loss: 0.8096330165863037
recon_loss: 0.028328929096460342, dist_loss: 0.6378210186958313
recon_loss: 0.028328590095043182, dist_loss: 0.7168078422546387
recon_loss: 0.028328444808721542, dist_loss: 0.5298840999603271
Pre-training Epoch 70:  39%|███▉      | 143/367 [00:00<00:01, 170.97it/s]Pre-training Epoch 70:  44%|████▍     | 161/367 [00:00<00:01, 172.33it/s]Pre-training Epoch 70:  49%|████▉     | 179/367 [00:01<00:01, 171.03it/s]Pre-training Epoch 70:  54%|█████▎    | 197/367 [00:01<00:00, 172.74it/s]Pre-training Epoch 70:  59%|█████▊    | 215/367 [00:01<00:00, 173.26it/s]Pre-training Epoch 70:  63%|██████▎   | 233/367 [00:01<00:00, 174.11it/s]Pre-training Epoch 70:  68%|██████▊   | 251/367 [00:01<00:00, 175.10it/s]recon_loss: 0.02832879312336445, dist_loss: 0.6865355372428894
recon_loss: 0.028328077867627144, dist_loss: 0.4376116394996643
recon_loss: 0.028328189626336098, dist_loss: 0.7392017841339111
recon_loss: 0.028328485786914825, dist_loss: 0.5744266510009766
recon_loss: 0.028328092768788338, dist_loss: 0.5646618604660034
recon_loss: 0.02832883968949318, dist_loss: 0.4629310369491577
recon_loss: 0.02832835726439953, dist_loss: 0.5100868344306946
recon_loss: 0.028328150510787964, dist_loss: 0.6527599096298218
recon_loss: 0.028328746557235718, dist_loss: 0.34147119522094727
recon_loss: 0.02832827903330326, dist_loss: 0.5665656328201294
recon_loss: 0.02832851931452751, dist_loss: 0.46307307481765747
recon_loss: 0.028328241780400276, dist_loss: 0.6596860885620117
recon_loss: 0.028327947482466698, dist_loss: 0.5679531097412109
recon_loss: 0.028327951207756996, dist_loss: 0.6759105920791626
recon_loss: 0.028327805921435356, dist_loss: 0.9761465787887573
recon_loss: 0.028327960520982742, dist_loss: 0.8876549601554871
recon_loss: 0.028328001499176025, dist_loss: 0.5273624062538147
recon_loss: 0.02832784131169319, dist_loss: 0.976138174533844
recon_loss: 0.028327587991952896, dist_loss: 1.0324146747589111
recon_loss: 0.02832743525505066, dist_loss: 0.50333571434021
recon_loss: 0.02832755818963051, dist_loss: 1.0165778398513794
recon_loss: 0.028327591717243195, dist_loss: 0.7672243118286133
recon_loss: 0.02832736447453499, dist_loss: 0.6376667022705078
recon_loss: 0.02832704596221447, dist_loss: 0.538138747215271
recon_loss: 0.028326911851763725, dist_loss: 0.4562020003795624
recon_loss: 0.028326459228992462, dist_loss: 0.6282052397727966
recon_loss: 0.02832641638815403, dist_loss: 0.9903969168663025
recon_loss: 0.02832649089396, dist_loss: 0.5339596271514893
recon_loss: 0.028325742110610008, dist_loss: 0.8197758197784424
recon_loss: 0.028325706720352173, dist_loss: 0.4763196110725403
recon_loss: 0.02832530066370964, dist_loss: 1.0109257698059082
recon_loss: 0.028325142338871956, dist_loss: 0.5666474103927612
recon_loss: 0.02832585759460926, dist_loss: 0.5815762281417847
recon_loss: 0.028325075283646584, dist_loss: 0.6401259899139404
recon_loss: 0.02832525223493576, dist_loss: 0.5605289936065674
recon_loss: 0.028325354680418968, dist_loss: 0.6016982197761536
recon_loss: 0.028324678540229797, dist_loss: 0.5170279741287231
recon_loss: 0.028325043618679047, dist_loss: 0.7221940159797668
recon_loss: 0.028324821963906288, dist_loss: 1.1099607944488525
recon_loss: 0.028324710205197334, dist_loss: 0.5437353849411011
recon_loss: 0.02832457423210144, dist_loss: 0.389154314994812
recon_loss: 0.0283244289457798, dist_loss: 0.9970659017562866
recon_loss: 0.02832435443997383, dist_loss: 1.0109634399414062
recon_loss: 0.028324168175458908, dist_loss: 0.8720093965530396
recon_loss: 0.02832402102649212, dist_loss: 0.9117802977561951
recon_loss: 0.02832365594804287, dist_loss: 0.5875710844993591
recon_loss: 0.02832375280559063, dist_loss: 0.785919725894928
recon_loss: 0.028323648497462273, dist_loss: 0.5687046647071838
recon_loss: 0.028323449194431305, dist_loss: 0.46219468116760254
recon_loss: 0.028323406353592873, dist_loss: 0.7398332953453064
recon_loss: 0.028323430567979813, dist_loss: 0.3898002803325653
recon_loss: 0.028323231264948845, dist_loss: 0.6568058133125305
recon_loss: 0.028323374688625336, dist_loss: 0.5399571657180786
recon_loss: 0.028323762118816376, dist_loss: 0.9170779585838318
recon_loss: 0.028323253616690636, dist_loss: 0.5063245892524719
recon_loss: 0.028322936967015266, dist_loss: 0.6350394487380981
recon_loss: 0.028323335573077202, dist_loss: 0.7183822393417358
recon_loss: 0.02832377329468727, dist_loss: 0.3801911175251007
recon_loss: 0.028324030339717865, dist_loss: 0.6691790223121643
recon_loss: 0.028324156999588013, dist_loss: 0.5220453143119812
recon_loss: 0.02832428179681301, dist_loss: 0.35344576835632324
recon_loss: 0.028324611485004425, dist_loss: 1.071545958518982
recon_loss: 0.028325090184807777, dist_loss: 0.6994783878326416
recon_loss: 0.028325501829385757, dist_loss: 0.35737255215644836
recon_loss: 0.028325902298092842, dist_loss: 0.8468751907348633
recon_loss: 0.028327083215117455, dist_loss: 0.4783744812011719
recon_loss: 0.028327982872724533, dist_loss: 0.4367738962173462
recon_loss: 0.028328487649559975, dist_loss: 0.5789183378219604
recon_loss: 0.02832813374698162, dist_loss: 0.48060694336891174
recon_loss: 0.02832731418311596, dist_loss: 0.9125759601593018
recon_loss: 0.02832702547311783, dist_loss: 0.5955716371536255
recon_loss: 0.02832665666937828, dist_loss: 0.6267768144607544
recon_loss: 0.028325989842414856, dist_loss: 0.6769279837608337
recon_loss: 0.028325073421001434, dist_loss: 0.3892790377140045
recon_loss: 0.028324242681264877, dist_loss: 0.8821714520454407
recon_loss: 0.028323469683527946, dist_loss: 0.7773923873901367
recon_loss: 0.02832292951643467, dist_loss: 0.9484405517578125
recon_loss: 0.02832275815308094, dist_loss: 0.7607871890068054
recon_loss: 0.028322700411081314, dist_loss: 1.028965711593628
recon_loss: 0.028322888538241386, dist_loss: 0.8918786644935608
recon_loss: 0.028322484344244003, dist_loss: 0.808445155620575
recon_loss: 0.028322242200374603, dist_loss: 0.9498313069343567
recon_loss: 0.028322136029601097, dist_loss: 0.7230522036552429
recon_loss: 0.028322001919150352, dist_loss: 0.8657529354095459
recon_loss: 0.02832205779850483, dist_loss: 0.6638398170471191
recon_loss: 0.028321800753474236, dist_loss: 0.8751469254493713
recon_loss: 0.028321560472249985, dist_loss: 1.1254162788391113
recon_loss: 0.028321458026766777, dist_loss: 1.0790464878082275
recon_loss: 0.028321141377091408, dist_loss: 0.4193303883075714
recon_loss: 0.028321607038378716, dist_loss: 0.6624269485473633
recon_loss: 0.02832126058638096, dist_loss: 0.9390076398849487
recon_loss: 0.028320837765932083, dist_loss: 0.8197788000106812
recon_loss: 0.028321117162704468, dist_loss: 0.8752132654190063
recon_loss: 0.02832043170928955, dist_loss: 0.5240747928619385
recon_loss: 0.028320742771029472, dist_loss: 0.6310730576515198
recon_loss: 0.028320543467998505, dist_loss: 0.7538076639175415
recon_loss: 0.028320541605353355, dist_loss: 0.5286417007446289
recon_loss: 0.028321055695414543, dist_loss: 0.4033809304237366
recon_loss: 0.028320668265223503, dist_loss: 0.43263164162635803
recon_loss: 0.028321238234639168, dist_loss: 1.2341389656066895
recon_loss: 0.02832132764160633, dist_loss: 1.0566195249557495
recon_loss: 0.02832004614174366, dist_loss: 0.29595234990119934
recon_loss: 0.028319889679551125, dist_loss: 0.5507541298866272
recon_loss: 0.028319772332906723, dist_loss: 0.6387051343917847
recon_loss: 0.02831936627626419, dist_loss: 0.4328967332839966
recon_loss: 0.02831963449716568, dist_loss: 0.35634949803352356
recon_loss: 0.02831912599503994, dist_loss: 0.7554327249526978
recon_loss: 0.0283193401992321, dist_loss: 0.6237572431564331
recon_loss: 0.028319211676716805, dist_loss: 0.9356551766395569
recon_loss: 0.028319310396909714, dist_loss: 0.5497982501983643
recon_loss: 0.028319358825683594, dist_loss: 0.852109432220459
recon_loss: 0.02831936813890934, dist_loss: 0.6955281496047974
recon_loss: 0.028319425880908966, dist_loss: 0.7754358053207397
recon_loss: 0.02831973321735859, dist_loss: 0.6790658235549927
recon_loss: 0.028319906443357468, dist_loss: 0.47206926345825195
recon_loss: 0.02832016348838806, dist_loss: 0.5637162327766418
recon_loss: 0.0283205509185791, dist_loss: 0.5950839519500732
recon_loss: 0.028321310877799988, dist_loss: 0.6202725768089294
recon_loss: 0.028320977464318275, dist_loss: 1.0225902795791626
recon_loss: 0.028320925310254097, dist_loss: 0.5866883993148804
recon_loss: 0.028320614248514175, dist_loss: 0.5630541443824768
recon_loss: 0.028319967910647392, dist_loss: 0.5950291156768799
recon_loss: 0.028319772332906723, dist_loss: 0.5650976896286011
recon_loss: 0.02831900306046009, dist_loss: 0.7229755520820618
recon_loss: 0.028318945318460464, dist_loss: 0.4534786641597748
recon_loss: 0.02831866405904293, dist_loss: 0.4438891112804413
recon_loss: 0.028318706899881363, dist_loss: 0.6848629713058472
recon_loss: 0.028319373726844788, dist_loss: 0.5485181212425232
Pre-training Epoch 70:  73%|███████▎  | 269/367 [00:01<00:00, 175.51it/s]Pre-training Epoch 70:  78%|███████▊  | 287/367 [00:01<00:00, 176.27it/s]Pre-training Epoch 70:  83%|████████▎ | 305/367 [00:01<00:00, 175.38it/s]Pre-training Epoch 70:  88%|████████▊ | 323/367 [00:01<00:00, 167.40it/s]Pre-training Epoch 70:  93%|█████████▎| 340/367 [00:01<00:00, 162.05it/s]Pre-training Epoch 70:  97%|█████████▋| 357/367 [00:02<00:00, 157.75it/s]Pre-training Epoch 70: 100%|██████████| 367/367 [00:02<00:00, 169.59it/s]
recon_loss: 0.028318822383880615, dist_loss: 0.590889573097229
recon_loss: 0.02831972762942314, dist_loss: 1.033665418624878
recon_loss: 0.02831951342523098, dist_loss: 0.828589141368866
recon_loss: 0.028320230543613434, dist_loss: 0.6860849857330322
recon_loss: 0.028320733457803726, dist_loss: 0.507013738155365
recon_loss: 0.028320884332060814, dist_loss: 0.521987795829773
recon_loss: 0.028321603313088417, dist_loss: 1.3486915826797485
recon_loss: 0.02832156792283058, dist_loss: 0.5941163301467896
recon_loss: 0.028321124613285065, dist_loss: 0.49021607637405396
recon_loss: 0.02832130901515484, dist_loss: 0.4824560284614563
recon_loss: 0.0283206757158041, dist_loss: 0.9495425224304199
recon_loss: 0.02832052856683731, dist_loss: 0.4266080856323242
recon_loss: 0.028319532051682472, dist_loss: 0.5334212779998779
recon_loss: 0.02831895835697651, dist_loss: 0.9407070875167847
recon_loss: 0.028318924829363823, dist_loss: 0.3870065212249756
recon_loss: 0.028318827971816063, dist_loss: 0.6584749817848206
recon_loss: 0.028318241238594055, dist_loss: 0.32405006885528564
recon_loss: 0.028317898511886597, dist_loss: 0.33677685260772705
recon_loss: 0.0283174030482769, dist_loss: 0.9643137454986572
recon_loss: 0.028317252174019814, dist_loss: 0.6957902908325195
recon_loss: 0.028317220509052277, dist_loss: 0.4247123599052429
recon_loss: 0.02831716276705265, dist_loss: 0.5929780006408691
recon_loss: 0.028317047283053398, dist_loss: 0.3730400800704956
recon_loss: 0.028317157179117203, dist_loss: 0.9014708995819092
recon_loss: 0.02831784449517727, dist_loss: 0.6515979766845703
recon_loss: 0.02831825241446495, dist_loss: 0.6365610361099243
recon_loss: 0.028318343684077263, dist_loss: 0.6303056478500366
recon_loss: 0.028318354859948158, dist_loss: 0.5401941537857056
recon_loss: 0.028318043798208237, dist_loss: 0.8760663270950317
recon_loss: 0.028318151831626892, dist_loss: 0.4913622736930847
recon_loss: 0.028318051248788834, dist_loss: 0.8343927264213562
recon_loss: 0.028318004682660103, dist_loss: 0.33128973841667175
recon_loss: 0.02831767313182354, dist_loss: 0.6212233304977417
recon_loss: 0.028316928073763847, dist_loss: 0.7748405337333679
recon_loss: 0.028317248448729515, dist_loss: 0.9566888213157654
recon_loss: 0.028318103402853012, dist_loss: 0.5014094114303589
recon_loss: 0.028320005163550377, dist_loss: 0.7107298970222473
recon_loss: 0.0283214058727026, dist_loss: 0.4355185329914093
recon_loss: 0.02832328900694847, dist_loss: 0.4842449724674225
recon_loss: 0.028324680402874947, dist_loss: 0.39518553018569946
recon_loss: 0.028324337676167488, dist_loss: 1.1532748937606812
recon_loss: 0.02832561358809471, dist_loss: 0.7209811210632324
recon_loss: 0.028324952349066734, dist_loss: 0.7147289514541626
recon_loss: 0.028324376791715622, dist_loss: 0.9477900266647339
recon_loss: 0.0283245537430048, dist_loss: 0.45366430282592773
recon_loss: 0.02832356095314026, dist_loss: 0.459884375333786
recon_loss: 0.02832356095314026, dist_loss: 0.8353738784790039
recon_loss: 0.028324000537395477, dist_loss: 0.5258562564849854
recon_loss: 0.02832464873790741, dist_loss: 0.9156200289726257
recon_loss: 0.02832498401403427, dist_loss: 0.5471246242523193
recon_loss: 0.028322819620370865, dist_loss: 0.6397048234939575
recon_loss: 0.028320834040641785, dist_loss: 0.5253832340240479
recon_loss: 0.028319906443357468, dist_loss: 0.4903060495853424
recon_loss: 0.028318438678979874, dist_loss: 0.6372702121734619
recon_loss: 0.028317056596279144, dist_loss: 0.7267630100250244
recon_loss: 0.028316348791122437, dist_loss: 0.8960631489753723
recon_loss: 0.02831469103693962, dist_loss: 0.8940582275390625
recon_loss: 0.028314098715782166, dist_loss: 0.8024596571922302
recon_loss: 0.028314147144556046, dist_loss: 0.8748108148574829
recon_loss: 0.028314288705587387, dist_loss: 0.6044449210166931
recon_loss: 0.028315069153904915, dist_loss: 0.3917519152164459
recon_loss: 0.028315749019384384, dist_loss: 0.7901867032051086
recon_loss: 0.028316272422671318, dist_loss: 0.41745561361312866
recon_loss: 0.028316857293248177, dist_loss: 0.3641176223754883
recon_loss: 0.028316766023635864, dist_loss: 0.4784163236618042
recon_loss: 0.028316829353570938, dist_loss: 0.952803373336792
recon_loss: 0.028316257521510124, dist_loss: 0.8404868841171265
recon_loss: 0.02831556648015976, dist_loss: 0.5935941934585571
recon_loss: 0.028314972296357155, dist_loss: 1.0692323446273804
recon_loss: 0.028314340859651566, dist_loss: 0.5345184206962585
recon_loss: 0.028313448652625084, dist_loss: 0.7535377144813538
recon_loss: 0.028312882408499718, dist_loss: 0.5788047313690186
recon_loss: 0.028312304988503456, dist_loss: 0.5802268385887146
recon_loss: 0.028311975300312042, dist_loss: 0.6813624501228333
recon_loss: 0.02831173874437809, dist_loss: 0.6736912727355957
recon_loss: 0.028311436995863914, dist_loss: 0.7055321335792542
recon_loss: 0.028311066329479218, dist_loss: 0.39833030104637146
recon_loss: 0.028310993686318398, dist_loss: 0.4985147714614868
recon_loss: 0.02831059694290161, dist_loss: 0.9817714691162109
recon_loss: 0.02831077203154564, dist_loss: 0.6007071733474731
recon_loss: 0.028310736641287804, dist_loss: 0.9310027360916138
recon_loss: 0.02831040695309639, dist_loss: 0.7608152031898499
recon_loss: 0.028310224413871765, dist_loss: 1.036708116531372
recon_loss: 0.028309933841228485, dist_loss: 0.6335196495056152
recon_loss: 0.028309723362326622, dist_loss: 0.6616843938827515
recon_loss: 0.02830939181149006, dist_loss: 0.767243504524231
recon_loss: 0.028309427201747894, dist_loss: 0.8125354647636414
recon_loss: 0.028309550136327744, dist_loss: 0.592930793762207
recon_loss: 0.028309457004070282, dist_loss: 0.5590463876724243
recon_loss: 0.028309104964137077, dist_loss: 1.0090253353118896
recon_loss: 0.02830897457897663, dist_loss: 0.5355014801025391
recon_loss: 0.028308911249041557, dist_loss: 0.8239418864250183
recon_loss: 0.028309307992458344, dist_loss: 0.4180290102958679
recon_loss: 0.028310131281614304, dist_loss: 1.0932399034500122
recon_loss: 0.028310077264904976, dist_loss: 0.7977967858314514
recon_loss: 0.028309760615229607, dist_loss: 0.6657081246376038
recon_loss: 0.028309553861618042, dist_loss: 0.741173267364502
recon_loss: 0.02830975502729416, dist_loss: 0.8850969076156616
recon_loss: 0.02830970287322998, dist_loss: 0.4230549931526184
recon_loss: 0.028309598565101624, dist_loss: 0.34655553102493286
recon_loss: 0.028309160843491554, dist_loss: 0.9267760515213013
recon_loss: 0.028308594599366188, dist_loss: 0.7619802355766296
recon_loss: 0.02830931544303894, dist_loss: 0.2711724042892456
recon_loss: 0.028308771550655365, dist_loss: 0.5496588945388794
recon_loss: 0.028309017419815063, dist_loss: 0.6655998826026917
recon_loss: 0.02830902487039566, dist_loss: 0.9046521186828613
recon_loss: 0.028308682143688202, dist_loss: 0.7895169854164124
recon_loss: 0.028308948501944542, dist_loss: 0.7384648323059082
recon_loss: 0.0283088106662035, dist_loss: 0.6489062309265137
recon_loss: 0.028308939188718796, dist_loss: 0.8919628858566284
recon_loss: 0.02830912172794342, dist_loss: 0.6923783421516418
Pre-train Epoch: 70
Train - Total Loss: 0.0949, Recon Loss: 0.0283, Dist Loss: 0.6656, l1 regularization: 0.0000
Val - Total Loss: 0.0991, Recon Loss: 0.0283, Dist Loss: 0.7084, l1 regularization: 0.0000
Pre-training Epoch 71:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 71:   4%|▍         | 15/367 [00:00<00:02, 143.86it/s]Pre-training Epoch 71:   8%|▊         | 31/367 [00:00<00:02, 149.33it/s]Pre-training Epoch 71:  13%|█▎        | 47/367 [00:00<00:02, 152.39it/s]Pre-training Epoch 71:  17%|█▋        | 63/367 [00:00<00:01, 152.37it/s]Pre-training Epoch 71:  22%|██▏       | 79/367 [00:00<00:01, 153.08it/s]Pre-training Epoch 71:  26%|██▌       | 95/367 [00:00<00:01, 153.63it/s]Pre-training Epoch 71:  30%|███       | 111/367 [00:00<00:01, 154.54it/s]Pre-training Epoch 71:  35%|███▍      | 127/367 [00:00<00:01, 155.41it/s]recon_loss: 0.028308989480137825, dist_loss: 0.6947227716445923
recon_loss: 0.028309190645813942, dist_loss: 0.2964372932910919
recon_loss: 0.02830846793949604, dist_loss: 0.5975021719932556
recon_loss: 0.028308255597949028, dist_loss: 0.44834092259407043
recon_loss: 0.028308387845754623, dist_loss: 1.0100408792495728
recon_loss: 0.028308071196079254, dist_loss: 0.726309597492218
recon_loss: 0.028308583423495293, dist_loss: 0.8404793739318848
recon_loss: 0.028308095410466194, dist_loss: 0.5486708283424377
recon_loss: 0.028307311236858368, dist_loss: 0.686530590057373
recon_loss: 0.028307074680924416, dist_loss: 0.8547776341438293
recon_loss: 0.02830706536769867, dist_loss: 0.7749487161636353
recon_loss: 0.02830684743821621, dist_loss: 0.5420106053352356
recon_loss: 0.0283067524433136, dist_loss: 0.5657515525817871
recon_loss: 0.02830633521080017, dist_loss: 0.8278393745422363
recon_loss: 0.028306756168603897, dist_loss: 0.6889026165008545
recon_loss: 0.02830648422241211, dist_loss: 0.5525669455528259
recon_loss: 0.028307005763053894, dist_loss: 0.7368089556694031
recon_loss: 0.028307465836405754, dist_loss: 0.5166652798652649
recon_loss: 0.028307253494858742, dist_loss: 0.3717206120491028
recon_loss: 0.028306839987635612, dist_loss: 0.4373035132884979
recon_loss: 0.028307002037763596, dist_loss: 0.5972871780395508
recon_loss: 0.0283071156591177, dist_loss: 0.6826618909835815
recon_loss: 0.028307124972343445, dist_loss: 0.7300422191619873
recon_loss: 0.028306853026151657, dist_loss: 0.7234342694282532
recon_loss: 0.02830655872821808, dist_loss: 0.877866804599762
recon_loss: 0.028306102380156517, dist_loss: 0.315681129693985
recon_loss: 0.028305957093834877, dist_loss: 0.6523292660713196
recon_loss: 0.02830585651099682, dist_loss: 0.7825731635093689
recon_loss: 0.02830575592815876, dist_loss: 0.7456200122833252
recon_loss: 0.028305456042289734, dist_loss: 0.7807009220123291
recon_loss: 0.02830524742603302, dist_loss: 0.43339499831199646
recon_loss: 0.028304988518357277, dist_loss: 0.7906922698020935
recon_loss: 0.02830522693693638, dist_loss: 0.43639636039733887
recon_loss: 0.0283054206520319, dist_loss: 0.3141968250274658
recon_loss: 0.02830560877919197, dist_loss: 0.8937361240386963
recon_loss: 0.028305834159255028, dist_loss: 1.1429085731506348
recon_loss: 0.028305556625127792, dist_loss: 0.8599065542221069
recon_loss: 0.02830558456480503, dist_loss: 0.2836582660675049
recon_loss: 0.02830561436712742, dist_loss: 0.8744860887527466
recon_loss: 0.028305305168032646, dist_loss: 0.8654038906097412
recon_loss: 0.02830514684319496, dist_loss: 0.612320601940155
recon_loss: 0.028304796665906906, dist_loss: 0.926800012588501
recon_loss: 0.02830449678003788, dist_loss: 0.467989444732666
recon_loss: 0.028304578736424446, dist_loss: 0.5101513862609863
recon_loss: 0.028304124251008034, dist_loss: 0.6203465461730957
recon_loss: 0.028303982689976692, dist_loss: 0.6748114228248596
recon_loss: 0.02830399014055729, dist_loss: 1.3527470827102661
recon_loss: 0.028303897008299828, dist_loss: 0.49572497606277466
recon_loss: 0.02830432914197445, dist_loss: 0.721378743648529
recon_loss: 0.02830398641526699, dist_loss: 0.7128501534461975
recon_loss: 0.028304141014814377, dist_loss: 0.64117431640625
recon_loss: 0.028304066509008408, dist_loss: 0.5698835849761963
recon_loss: 0.028304390609264374, dist_loss: 0.8056515455245972
recon_loss: 0.028304381296038628, dist_loss: 0.8192243576049805
recon_loss: 0.028304172679781914, dist_loss: 0.8512758612632751
recon_loss: 0.028304480016231537, dist_loss: 0.4009845554828644
recon_loss: 0.028303414583206177, dist_loss: 0.36198869347572327
recon_loss: 0.028303328901529312, dist_loss: 0.778059720993042
recon_loss: 0.02830306999385357, dist_loss: 0.5880608558654785
recon_loss: 0.028303032740950584, dist_loss: 0.5660117864608765
recon_loss: 0.028303256258368492, dist_loss: 1.1999146938323975
recon_loss: 0.028303364291787148, dist_loss: 0.8631017804145813
recon_loss: 0.028303204104304314, dist_loss: 0.6724996566772461
recon_loss: 0.02830258570611477, dist_loss: 0.8343141078948975
recon_loss: 0.028303010389208794, dist_loss: 0.33417844772338867
recon_loss: 0.028303103521466255, dist_loss: 0.4520804286003113
recon_loss: 0.028303053230047226, dist_loss: 1.0448994636535645
recon_loss: 0.028303487226366997, dist_loss: 1.1040229797363281
recon_loss: 0.028302833437919617, dist_loss: 0.7031941413879395
recon_loss: 0.02830248512327671, dist_loss: 0.29382216930389404
recon_loss: 0.028302602469921112, dist_loss: 0.6184260845184326
recon_loss: 0.02830282226204872, dist_loss: 0.4210025668144226
recon_loss: 0.02830301970243454, dist_loss: 0.4511154294013977
recon_loss: 0.02830325812101364, dist_loss: 0.3518613576889038
recon_loss: 0.028303509578108788, dist_loss: 1.3557698726654053
recon_loss: 0.02830345742404461, dist_loss: 0.8088976144790649
recon_loss: 0.028303414583206177, dist_loss: 0.8294268846511841
recon_loss: 0.028302844613790512, dist_loss: 0.6950595378875732
recon_loss: 0.028302665799856186, dist_loss: 0.9459326267242432
recon_loss: 0.02830258198082447, dist_loss: 0.5988482236862183
recon_loss: 0.028302446007728577, dist_loss: 0.5426157712936401
recon_loss: 0.02830246277153492, dist_loss: 0.7616384029388428
recon_loss: 0.0283017810434103, dist_loss: 1.0438511371612549
recon_loss: 0.0283019058406353, dist_loss: 0.622234582901001
recon_loss: 0.028301864862442017, dist_loss: 1.071051836013794
recon_loss: 0.028301900252699852, dist_loss: 0.6389772295951843
recon_loss: 0.028302475810050964, dist_loss: 0.47241002321243286
recon_loss: 0.028300680220127106, dist_loss: 0.5582324862480164
recon_loss: 0.028303062543272972, dist_loss: 0.5578991174697876
recon_loss: 0.02830071561038494, dist_loss: 0.6203481554985046
recon_loss: 0.02830222062766552, dist_loss: 0.5706590414047241
recon_loss: 0.028303027153015137, dist_loss: 0.7050355672836304
recon_loss: 0.02829982154071331, dist_loss: 0.8438568115234375
recon_loss: 0.02830333448946476, dist_loss: 0.3608095645904541
recon_loss: 0.02830079384148121, dist_loss: 0.2890714406967163
recon_loss: 0.028301160782575607, dist_loss: 0.49615734815597534
recon_loss: 0.0283021479845047, dist_loss: 0.5058547258377075
recon_loss: 0.028300192207098007, dist_loss: 0.5512063503265381
recon_loss: 0.028301939368247986, dist_loss: 0.571255087852478
recon_loss: 0.02830076962709427, dist_loss: 0.5820655822753906
recon_loss: 0.02829979546368122, dist_loss: 0.7965829372406006
recon_loss: 0.02830086275935173, dist_loss: 0.3607180118560791
recon_loss: 0.028299150988459587, dist_loss: 0.8608678579330444
recon_loss: 0.028299419209361076, dist_loss: 0.9613393545150757
recon_loss: 0.028299342840909958, dist_loss: 0.7228721380233765
recon_loss: 0.028298478573560715, dist_loss: 0.6278748512268066
recon_loss: 0.02829945832490921, dist_loss: 0.5248094201087952
recon_loss: 0.028298502787947655, dist_loss: 1.0497691631317139
recon_loss: 0.0282988790422678, dist_loss: 0.6655718088150024
recon_loss: 0.028299326077103615, dist_loss: 0.41999465227127075
recon_loss: 0.028298554942011833, dist_loss: 0.6676599979400635
recon_loss: 0.02829924412071705, dist_loss: 0.5836442708969116
recon_loss: 0.02829844504594803, dist_loss: 0.5450344085693359
recon_loss: 0.028299517929553986, dist_loss: 0.5094618797302246
recon_loss: 0.028299374505877495, dist_loss: 0.427024245262146
recon_loss: 0.02829897403717041, dist_loss: 0.7598481178283691
recon_loss: 0.028300855308771133, dist_loss: 0.3874334692955017
recon_loss: 0.028298527002334595, dist_loss: 0.5316141843795776
recon_loss: 0.028298594057559967, dist_loss: 0.5168414115905762
recon_loss: 0.028299666941165924, dist_loss: 0.5698822736740112
recon_loss: 0.028298716992139816, dist_loss: 0.41347891092300415
recon_loss: 0.028300322592258453, dist_loss: 0.6460435390472412
recon_loss: 0.028300076723098755, dist_loss: 0.4600359797477722
recon_loss: 0.028300125151872635, dist_loss: 0.7368708252906799
recon_loss: 0.028300946578383446, dist_loss: 0.6870622038841248
recon_loss: 0.028300784528255463, dist_loss: 0.8337739706039429
recon_loss: 0.028302563354372978, dist_loss: 0.7086458802223206
recon_loss: 0.0283017847687006, dist_loss: 0.3075137138366699
Pre-training Epoch 71:  39%|███▉      | 143/367 [00:00<00:01, 155.43it/s]Pre-training Epoch 71:  43%|████▎     | 159/367 [00:01<00:01, 155.34it/s]Pre-training Epoch 71:  48%|████▊     | 175/367 [00:01<00:01, 153.03it/s]Pre-training Epoch 71:  52%|█████▏    | 191/367 [00:01<00:01, 152.75it/s]Pre-training Epoch 71:  56%|█████▋    | 207/367 [00:01<00:01, 152.92it/s]Pre-training Epoch 71:  61%|██████    | 223/367 [00:01<00:00, 154.46it/s]Pre-training Epoch 71:  65%|██████▌   | 239/367 [00:01<00:00, 155.22it/s]Pre-training Epoch 71:  69%|██████▉   | 255/367 [00:01<00:00, 155.22it/s]recon_loss: 0.028300805017352104, dist_loss: 0.7000668048858643
recon_loss: 0.028301561251282692, dist_loss: 0.4630170464515686
recon_loss: 0.02830066904425621, dist_loss: 0.712963342666626
recon_loss: 0.028301073238253593, dist_loss: 0.4868084192276001
recon_loss: 0.028300976380705833, dist_loss: 0.6420694589614868
recon_loss: 0.02829980105161667, dist_loss: 0.9091209769248962
recon_loss: 0.028300566598773003, dist_loss: 0.37068086862564087
recon_loss: 0.028298866003751755, dist_loss: 0.49713796377182007
recon_loss: 0.02829821966588497, dist_loss: 0.6602553725242615
recon_loss: 0.028298314660787582, dist_loss: 0.6283454298973083
recon_loss: 0.028297608718276024, dist_loss: 0.39651089906692505
recon_loss: 0.02829771861433983, dist_loss: 0.5398449301719666
recon_loss: 0.02829786390066147, dist_loss: 0.6809581518173218
recon_loss: 0.02829749695956707, dist_loss: 0.5768399238586426
recon_loss: 0.02829834260046482, dist_loss: 0.6652549505233765
recon_loss: 0.02829856425523758, dist_loss: 0.4149399697780609
recon_loss: 0.02829878404736519, dist_loss: 0.8140336275100708
recon_loss: 0.028298748657107353, dist_loss: 0.589871346950531
recon_loss: 0.0282981526106596, dist_loss: 0.6202751994132996
recon_loss: 0.028298119083046913, dist_loss: 0.5672085285186768
recon_loss: 0.02829819545149803, dist_loss: 0.44392919540405273
recon_loss: 0.02829844318330288, dist_loss: 0.21123598515987396
recon_loss: 0.02829861454665661, dist_loss: 0.26602938771247864
recon_loss: 0.02829797938466072, dist_loss: 0.9065601825714111
recon_loss: 0.02829769067466259, dist_loss: 0.9914118051528931
recon_loss: 0.028297442942857742, dist_loss: 1.3149797916412354
recon_loss: 0.028297560289502144, dist_loss: 0.7947337627410889
recon_loss: 0.02829805016517639, dist_loss: 0.5745053291320801
recon_loss: 0.028297752141952515, dist_loss: 0.42121654748916626
recon_loss: 0.02829800546169281, dist_loss: 0.8095472455024719
recon_loss: 0.028297074139118195, dist_loss: 0.4743306338787079
recon_loss: 0.02829611301422119, dist_loss: 0.48343425989151
recon_loss: 0.02829558402299881, dist_loss: 0.384128212928772
recon_loss: 0.028295356780290604, dist_loss: 0.5697341561317444
recon_loss: 0.028294876217842102, dist_loss: 0.8860570192337036
recon_loss: 0.02829502336680889, dist_loss: 0.7352434396743774
recon_loss: 0.028294755145907402, dist_loss: 0.4283750057220459
recon_loss: 0.028293732553720474, dist_loss: 0.8831597566604614
recon_loss: 0.02829386480152607, dist_loss: 0.6545507311820984
recon_loss: 0.028294000774621964, dist_loss: 1.0752408504486084
recon_loss: 0.02829357050359249, dist_loss: 0.7090765237808228
recon_loss: 0.028293313458561897, dist_loss: 0.8707112073898315
recon_loss: 0.028293082490563393, dist_loss: 0.7805240154266357
recon_loss: 0.028293047100305557, dist_loss: 1.0553109645843506
recon_loss: 0.02829298935830593, dist_loss: 0.375706285238266
recon_loss: 0.028293024748563766, dist_loss: 0.7911466360092163
recon_loss: 0.028293121606111526, dist_loss: 0.6137988567352295
recon_loss: 0.028292778879404068, dist_loss: 0.6711708307266235
recon_loss: 0.028292659670114517, dist_loss: 0.677859902381897
recon_loss: 0.028292501345276833, dist_loss: 0.8973597884178162
recon_loss: 0.028292471542954445, dist_loss: 0.3998022973537445
recon_loss: 0.028292356058955193, dist_loss: 0.6552135348320007
recon_loss: 0.02829235978424549, dist_loss: 0.46585512161254883
recon_loss: 0.028292564675211906, dist_loss: 0.322582483291626
recon_loss: 0.028292886912822723, dist_loss: 0.6748692989349365
recon_loss: 0.028292465955018997, dist_loss: 0.8176032900810242
recon_loss: 0.02829251065850258, dist_loss: 1.1977500915527344
recon_loss: 0.028292201459407806, dist_loss: 0.3751411437988281
recon_loss: 0.028292110189795494, dist_loss: 0.8144910335540771
recon_loss: 0.028291800990700722, dist_loss: 0.4124611020088196
recon_loss: 0.028291335329413414, dist_loss: 0.6472939252853394
recon_loss: 0.028291452676057816, dist_loss: 0.49790045619010925
recon_loss: 0.02829138934612274, dist_loss: 0.6771142482757568
recon_loss: 0.02829158306121826, dist_loss: 0.7172638773918152
recon_loss: 0.028292059898376465, dist_loss: 0.9183647036552429
recon_loss: 0.02829173393547535, dist_loss: 0.5701637268066406
recon_loss: 0.02829216793179512, dist_loss: 0.4475538432598114
recon_loss: 0.028291814029216766, dist_loss: 0.7992908954620361
recon_loss: 0.028291650116443634, dist_loss: 0.4414852261543274
recon_loss: 0.028291938826441765, dist_loss: 0.9169371724128723
recon_loss: 0.02829109877347946, dist_loss: 0.6018043756484985
recon_loss: 0.028291212394833565, dist_loss: 0.6014369130134583
recon_loss: 0.028291229158639908, dist_loss: 0.8494501113891602
recon_loss: 0.028291160240769386, dist_loss: 0.680107831954956
recon_loss: 0.028291162103414536, dist_loss: 0.43682533502578735
recon_loss: 0.028290970250964165, dist_loss: 1.0952879190444946
recon_loss: 0.028290964663028717, dist_loss: 0.48221176862716675
recon_loss: 0.028291087597608566, dist_loss: 0.4094850420951843
recon_loss: 0.028290942311286926, dist_loss: 1.602107048034668
recon_loss: 0.028290845453739166, dist_loss: 0.7619267106056213
recon_loss: 0.028290776535868645, dist_loss: 0.6712639331817627
recon_loss: 0.02829066291451454, dist_loss: 0.6604017019271851
recon_loss: 0.028290720656514168, dist_loss: 0.5779014229774475
recon_loss: 0.028290530666708946, dist_loss: 0.40792277455329895
recon_loss: 0.0282901618629694, dist_loss: 0.5274337530136108
recon_loss: 0.02829005755484104, dist_loss: 0.7368772029876709
recon_loss: 0.028289875015616417, dist_loss: 1.214495062828064
recon_loss: 0.028289560228586197, dist_loss: 0.7519347667694092
recon_loss: 0.02828958071768284, dist_loss: 0.9463841319084167
recon_loss: 0.028289223089814186, dist_loss: 0.5721426606178284
recon_loss: 0.028289122506976128, dist_loss: 0.9694478511810303
recon_loss: 0.028289051726460457, dist_loss: 1.3300584554672241
recon_loss: 0.028289148584008217, dist_loss: 0.4809728264808655
recon_loss: 0.028289007022976875, dist_loss: 1.044127345085144
recon_loss: 0.028288928791880608, dist_loss: 0.5114932656288147
recon_loss: 0.02828879840672016, dist_loss: 0.9106049537658691
recon_loss: 0.028288424015045166, dist_loss: 0.5646177530288696
recon_loss: 0.0282882247120142, dist_loss: 0.8252814412117004
recon_loss: 0.028287893161177635, dist_loss: 0.9114564657211304
recon_loss: 0.028287818655371666, dist_loss: 0.43288880586624146
recon_loss: 0.028287842869758606, dist_loss: 0.4685448408126831
recon_loss: 0.02828763611614704, dist_loss: 0.7361702919006348
recon_loss: 0.028287377208471298, dist_loss: 0.32452231645584106
recon_loss: 0.02828732505440712, dist_loss: 0.7618865966796875
recon_loss: 0.028287392109632492, dist_loss: 0.39673954248428345
recon_loss: 0.028287390246987343, dist_loss: 0.5511701107025146
recon_loss: 0.028286883607506752, dist_loss: 0.571698009967804
recon_loss: 0.02828705869615078, dist_loss: 0.7097532749176025
recon_loss: 0.028287366032600403, dist_loss: 0.3435317277908325
recon_loss: 0.028287943452596664, dist_loss: 0.4526607394218445
recon_loss: 0.028287695720791817, dist_loss: 0.3740074336528778
recon_loss: 0.028287772089242935, dist_loss: 0.7388453483581543
recon_loss: 0.028288161382079124, dist_loss: 0.538101851940155
recon_loss: 0.028288086876273155, dist_loss: 0.8377441763877869
recon_loss: 0.02828775718808174, dist_loss: 0.852452278137207
recon_loss: 0.028287088498473167, dist_loss: 0.4217628240585327
recon_loss: 0.02828630432486534, dist_loss: 0.4704429507255554
recon_loss: 0.02828589454293251, dist_loss: 0.3596007227897644
recon_loss: 0.028285983949899673, dist_loss: 0.6002837419509888
recon_loss: 0.02828620932996273, dist_loss: 0.9375059604644775
recon_loss: 0.028286773711442947, dist_loss: 0.33827584981918335
recon_loss: 0.028286892920732498, dist_loss: 1.1191256046295166
recon_loss: 0.028287123888731003, dist_loss: 0.8156755566596985
recon_loss: 0.02828708477318287, dist_loss: 1.0086365938186646
recon_loss: 0.02828722633421421, dist_loss: 1.2773512601852417
recon_loss: 0.0282874908298254, dist_loss: 0.31651151180267334
recon_loss: 0.028288016095757484, dist_loss: 0.6411880254745483
recon_loss: 0.028287697583436966, dist_loss: 0.9782819151878357
Pre-training Epoch 71:  74%|███████▍  | 271/367 [00:01<00:00, 155.46it/s]Pre-training Epoch 71:  78%|███████▊  | 287/367 [00:01<00:00, 154.40it/s]Pre-training Epoch 71:  83%|████████▎ | 304/367 [00:01<00:00, 157.51it/s]Pre-training Epoch 71:  88%|████████▊ | 322/367 [00:02<00:00, 162.64it/s]Pre-training Epoch 71:  93%|█████████▎| 340/367 [00:02<00:00, 165.41it/s]Pre-training Epoch 71:  98%|█████████▊| 358/367 [00:02<00:00, 168.04it/s]Pre-training Epoch 71: 100%|██████████| 367/367 [00:02<00:00, 157.40it/s]
recon_loss: 0.028287850320339203, dist_loss: 0.6034322381019592
recon_loss: 0.028287595137953758, dist_loss: 0.5184198617935181
recon_loss: 0.028287367895245552, dist_loss: 0.686402440071106
recon_loss: 0.028287377208471298, dist_loss: 0.560415506362915
recon_loss: 0.028287220746278763, dist_loss: 0.5129401683807373
recon_loss: 0.028286824002861977, dist_loss: 0.6869874596595764
recon_loss: 0.02828630432486534, dist_loss: 0.47291454672813416
recon_loss: 0.02828589454293251, dist_loss: 0.4498811364173889
recon_loss: 0.028285803273320198, dist_loss: 0.5533530116081238
recon_loss: 0.028285672888159752, dist_loss: 0.5982527732849121
recon_loss: 0.028285494074225426, dist_loss: 0.3663269877433777
recon_loss: 0.028284994885325432, dist_loss: 0.859764575958252
recon_loss: 0.028284721076488495, dist_loss: 0.8976436853408813
recon_loss: 0.028284311294555664, dist_loss: 0.4233543574810028
recon_loss: 0.028284303843975067, dist_loss: 1.3531770706176758
recon_loss: 0.028284208849072456, dist_loss: 0.6407026052474976
recon_loss: 0.028284020721912384, dist_loss: 0.6839909553527832
recon_loss: 0.02828378789126873, dist_loss: 0.7929626107215881
recon_loss: 0.028283756226301193, dist_loss: 0.35250550508499146
recon_loss: 0.02828396111726761, dist_loss: 0.9845052361488342
recon_loss: 0.02828383445739746, dist_loss: 0.8840522766113281
recon_loss: 0.028285497799515724, dist_loss: 0.5369457006454468
recon_loss: 0.02828400395810604, dist_loss: 0.5340028405189514
recon_loss: 0.028283780440688133, dist_loss: 1.3710272312164307
recon_loss: 0.028284629806876183, dist_loss: 0.6272491216659546
recon_loss: 0.02828301303088665, dist_loss: 0.5363070964813232
recon_loss: 0.0282844640314579, dist_loss: 0.812063455581665
recon_loss: 0.028284111991524696, dist_loss: 0.33183854818344116
recon_loss: 0.028283651918172836, dist_loss: 0.5136270523071289
recon_loss: 0.02828478068113327, dist_loss: 0.7351470589637756
recon_loss: 0.02828328125178814, dist_loss: 0.3740769028663635
recon_loss: 0.02828335389494896, dist_loss: 0.44198304414749146
recon_loss: 0.02828344702720642, dist_loss: 0.9503872394561768
recon_loss: 0.02828298695385456, dist_loss: 0.4643392562866211
recon_loss: 0.02828519232571125, dist_loss: 0.6669588088989258
recon_loss: 0.028284387663006783, dist_loss: 0.6474999785423279
recon_loss: 0.028285890817642212, dist_loss: 1.0657902956008911
recon_loss: 0.028286706656217575, dist_loss: 0.3987506628036499
recon_loss: 0.028285712003707886, dist_loss: 0.49251818656921387
recon_loss: 0.02828761748969555, dist_loss: 0.7959600687026978
recon_loss: 0.028286630287766457, dist_loss: 0.7461788058280945
recon_loss: 0.02828579768538475, dist_loss: 0.6063535809516907
recon_loss: 0.028285697102546692, dist_loss: 0.6525716185569763
recon_loss: 0.028284089639782906, dist_loss: 0.9746881723403931
recon_loss: 0.028285307809710503, dist_loss: 0.4755899906158447
recon_loss: 0.02828514762222767, dist_loss: 0.5305807590484619
recon_loss: 0.028284167870879173, dist_loss: 0.33631643652915955
recon_loss: 0.02828461118042469, dist_loss: 1.1002295017242432
recon_loss: 0.02828340046107769, dist_loss: 0.8836058378219604
recon_loss: 0.028282681480050087, dist_loss: 0.6733195781707764
recon_loss: 0.028282608836889267, dist_loss: 0.6965537071228027
recon_loss: 0.028282172977924347, dist_loss: 0.6593672037124634
recon_loss: 0.028282081708312035, dist_loss: 0.5870157480239868
recon_loss: 0.028281578794121742, dist_loss: 0.4603877067565918
recon_loss: 0.028281183913350105, dist_loss: 0.30895596742630005
recon_loss: 0.02828099951148033, dist_loss: 1.3582501411437988
recon_loss: 0.02828061394393444, dist_loss: 0.5662319660186768
recon_loss: 0.028280481696128845, dist_loss: 0.6494554281234741
recon_loss: 0.02828068658709526, dist_loss: 0.7590745687484741
recon_loss: 0.028280654922127724, dist_loss: 0.6341561079025269
recon_loss: 0.028280654922127724, dist_loss: 1.1665258407592773
recon_loss: 0.028280680999159813, dist_loss: 1.1200108528137207
recon_loss: 0.02828075923025608, dist_loss: 0.365665078163147
recon_loss: 0.02828085981309414, dist_loss: 0.37936827540397644
recon_loss: 0.02828088216483593, dist_loss: 0.5582618713378906
recon_loss: 0.028280610218644142, dist_loss: 0.6820774674415588
recon_loss: 0.028280362486839294, dist_loss: 0.43849045038223267
recon_loss: 0.028280407190322876, dist_loss: 0.46257567405700684
recon_loss: 0.028280097991228104, dist_loss: 0.7343807816505432
recon_loss: 0.02828027494251728, dist_loss: 0.7211865186691284
recon_loss: 0.028280004858970642, dist_loss: 0.733590304851532
recon_loss: 0.028280097991228104, dist_loss: 0.5046027898788452
recon_loss: 0.028280271217226982, dist_loss: 0.42262163758277893
recon_loss: 0.02828034572303295, dist_loss: 0.6631882190704346
recon_loss: 0.02828058786690235, dist_loss: 0.4092792272567749
recon_loss: 0.028280654922127724, dist_loss: 0.7246997356414795
recon_loss: 0.028280485421419144, dist_loss: 0.5403831005096436
recon_loss: 0.02828027680516243, dist_loss: 0.5336118936538696
recon_loss: 0.028280122205615044, dist_loss: 1.056053876876831
recon_loss: 0.028279967606067657, dist_loss: 1.105248212814331
recon_loss: 0.028279755264520645, dist_loss: 0.6019498109817505
recon_loss: 0.02827976830303669, dist_loss: 0.45790404081344604
recon_loss: 0.028279505670070648, dist_loss: 0.5660146474838257
recon_loss: 0.028279513120651245, dist_loss: 0.6999608278274536
recon_loss: 0.028279947116971016, dist_loss: 0.4060158133506775
recon_loss: 0.028279677033424377, dist_loss: 0.8210626840591431
recon_loss: 0.02828022465109825, dist_loss: 0.6379948854446411
recon_loss: 0.02828112803399563, dist_loss: 1.0809698104858398
recon_loss: 0.02828177623450756, dist_loss: 0.7639024257659912
recon_loss: 0.02828264608979225, dist_loss: 0.6585984230041504
recon_loss: 0.02828250825405121, dist_loss: 0.5021570920944214
recon_loss: 0.028282959014177322, dist_loss: 0.5186432600021362
recon_loss: 0.02828289568424225, dist_loss: 1.350407600402832
recon_loss: 0.02828322723507881, dist_loss: 0.6813162565231323
recon_loss: 0.02828335575759411, dist_loss: 0.5526492595672607
recon_loss: 0.02828291803598404, dist_loss: 0.633140504360199
recon_loss: 0.02828211709856987, dist_loss: 0.3908366560935974
recon_loss: 0.02828032523393631, dist_loss: 0.6340376138687134
recon_loss: 0.028279680758714676, dist_loss: 0.4504602551460266
recon_loss: 0.028278855606913567, dist_loss: 0.5396860241889954
recon_loss: 0.028277840465307236, dist_loss: 0.5114292502403259
recon_loss: 0.028278211131691933, dist_loss: 0.3372747004032135
recon_loss: 0.028277723118662834, dist_loss: 0.7143077850341797
recon_loss: 0.028278261423110962, dist_loss: 0.7189115285873413
recon_loss: 0.02827792800962925, dist_loss: 0.6186046600341797
recon_loss: 0.02827821858227253, dist_loss: 0.9384871125221252
recon_loss: 0.02827872894704342, dist_loss: 0.45287466049194336
recon_loss: 0.028278186917304993, dist_loss: 0.8922632932662964
recon_loss: 0.028279045596718788, dist_loss: 0.9384469985961914
recon_loss: 0.028278954327106476, dist_loss: 0.5908032059669495
recon_loss: 0.02827688865363598, dist_loss: 1.1341091394424438
Pre-training Epoch 72:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 72:   4%|▍         | 15/367 [00:00<00:02, 143.52it/s]Pre-training Epoch 72:   8%|▊         | 31/367 [00:00<00:02, 147.03it/s]Pre-training Epoch 72:  13%|█▎        | 47/367 [00:00<00:02, 150.55it/s]Pre-training Epoch 72:  17%|█▋        | 63/367 [00:00<00:01, 153.15it/s]Pre-training Epoch 72:  22%|██▏       | 79/367 [00:00<00:01, 154.28it/s]Pre-training Epoch 72:  26%|██▋       | 97/367 [00:00<00:01, 160.95it/s]Pre-training Epoch 72:  31%|███▏      | 115/367 [00:00<00:01, 166.02it/s]recon_loss: 0.02827829122543335, dist_loss: 0.47532910108566284
recon_loss: 0.028276342898607254, dist_loss: 0.3542238175868988
recon_loss: 0.028276847675442696, dist_loss: 0.7193573117256165
recon_loss: 0.028276626020669937, dist_loss: 0.8274921774864197
recon_loss: 0.028275609016418457, dist_loss: 0.7096390724182129
recon_loss: 0.02827620320022106, dist_loss: 0.6572375893592834
recon_loss: 0.028275849297642708, dist_loss: 0.48052626848220825
recon_loss: 0.02827528677880764, dist_loss: 0.8921375870704651
recon_loss: 0.028275154531002045, dist_loss: 0.8506779074668884
recon_loss: 0.02827482670545578, dist_loss: 0.5694154500961304
recon_loss: 0.02827480621635914, dist_loss: 0.3487187623977661
recon_loss: 0.028274772688746452, dist_loss: 0.6419223546981812
recon_loss: 0.028274336829781532, dist_loss: 0.6279278993606567
recon_loss: 0.028274156153202057, dist_loss: 1.0781431198120117
recon_loss: 0.028274092823266983, dist_loss: 0.6083582639694214
recon_loss: 0.028274044394493103, dist_loss: 0.37675681710243225
recon_loss: 0.028274180367588997, dist_loss: 0.5258127450942993
recon_loss: 0.028273936361074448, dist_loss: 0.7998162508010864
recon_loss: 0.02827378921210766, dist_loss: 0.7348599433898926
recon_loss: 0.028273485600948334, dist_loss: 0.7402766942977905
recon_loss: 0.028273213654756546, dist_loss: 0.5603375434875488
recon_loss: 0.028273101896047592, dist_loss: 0.9817066192626953
recon_loss: 0.028272952884435654, dist_loss: 0.8589569926261902
recon_loss: 0.028272652998566628, dist_loss: 0.712630569934845
recon_loss: 0.02827254682779312, dist_loss: 0.3575665056705475
recon_loss: 0.028272604569792747, dist_loss: 0.8019976615905762
recon_loss: 0.028273072093725204, dist_loss: 0.7684116363525391
recon_loss: 0.0282734502106905, dist_loss: 0.37889450788497925
recon_loss: 0.028273697942495346, dist_loss: 1.0733786821365356
recon_loss: 0.028273919597268105, dist_loss: 0.6563894748687744
recon_loss: 0.028273683041334152, dist_loss: 0.6554346084594727
recon_loss: 0.028273344039916992, dist_loss: 0.5161052942276001
recon_loss: 0.028273288160562515, dist_loss: 0.4400196373462677
recon_loss: 0.028273360803723335, dist_loss: 0.8590397238731384
recon_loss: 0.028273148462176323, dist_loss: 0.4529164433479309
recon_loss: 0.028273236006498337, dist_loss: 0.5000052452087402
recon_loss: 0.028273042291402817, dist_loss: 0.48862677812576294
recon_loss: 0.028272395953536034, dist_loss: 0.6958134174346924
recon_loss: 0.028271907940506935, dist_loss: 0.662765383720398
recon_loss: 0.028271857649087906, dist_loss: 0.7213077545166016
recon_loss: 0.028271641582250595, dist_loss: 0.30247312784194946
recon_loss: 0.028271695598959923, dist_loss: 0.5596355199813843
recon_loss: 0.028271635994315147, dist_loss: 0.5326414108276367
recon_loss: 0.028271421790122986, dist_loss: 0.9953177571296692
recon_loss: 0.028271429240703583, dist_loss: 0.5323656797409058
recon_loss: 0.028271054849028587, dist_loss: 0.9848341941833496
recon_loss: 0.028271272778511047, dist_loss: 0.7946281433105469
recon_loss: 0.02827085740864277, dist_loss: 0.4949369430541992
recon_loss: 0.028270695358514786, dist_loss: 0.5961661338806152
recon_loss: 0.028271013870835304, dist_loss: 0.9802570343017578
recon_loss: 0.028270913287997246, dist_loss: 0.5443741679191589
recon_loss: 0.02827104553580284, dist_loss: 0.5539005994796753
recon_loss: 0.02827097661793232, dist_loss: 0.8028061389923096
recon_loss: 0.028270810842514038, dist_loss: 0.6578493118286133
recon_loss: 0.028270864859223366, dist_loss: 0.4234083890914917
recon_loss: 0.028269989416003227, dist_loss: 0.4314553737640381
recon_loss: 0.02827015332877636, dist_loss: 0.7742046117782593
recon_loss: 0.02826964296400547, dist_loss: 0.6925598382949829
recon_loss: 0.028269438073039055, dist_loss: 0.6248623132705688
recon_loss: 0.028269179165363312, dist_loss: 0.6253247261047363
recon_loss: 0.028269022703170776, dist_loss: 0.6994718909263611
recon_loss: 0.028269121423363686, dist_loss: 0.5925918817520142
recon_loss: 0.028269095346331596, dist_loss: 0.5647255182266235
recon_loss: 0.028268961235880852, dist_loss: 0.8519672155380249
recon_loss: 0.02826889231801033, dist_loss: 0.7130112648010254
recon_loss: 0.028269391506910324, dist_loss: 0.4591476619243622
recon_loss: 0.028269607573747635, dist_loss: 1.0088492631912231
recon_loss: 0.028269851580262184, dist_loss: 0.48509758710861206
recon_loss: 0.02827010303735733, dist_loss: 0.5673760175704956
recon_loss: 0.028269797563552856, dist_loss: 0.7498884201049805
recon_loss: 0.028269587084650993, dist_loss: 0.5627368092536926
recon_loss: 0.028269661590456963, dist_loss: 0.890362024307251
recon_loss: 0.02826969511806965, dist_loss: 1.0114972591400146
recon_loss: 0.02826928161084652, dist_loss: 0.6330608129501343
recon_loss: 0.02826884761452675, dist_loss: 0.7305234670639038
recon_loss: 0.028268659487366676, dist_loss: 0.6000829339027405
recon_loss: 0.028268661350011826, dist_loss: 0.6068305373191833
recon_loss: 0.028269058093428612, dist_loss: 1.1954777240753174
recon_loss: 0.02826879359781742, dist_loss: 0.5924155712127686
recon_loss: 0.02826881594955921, dist_loss: 0.6219801306724548
recon_loss: 0.028269324451684952, dist_loss: 0.47297799587249756
recon_loss: 0.028269169852137566, dist_loss: 0.9004428386688232
recon_loss: 0.028268305584788322, dist_loss: 0.5830544233322144
recon_loss: 0.02826802246272564, dist_loss: 0.6815063953399658
recon_loss: 0.028268104419112206, dist_loss: 0.5248862504959106
recon_loss: 0.028267689049243927, dist_loss: 0.6712931394577026
recon_loss: 0.02826792560517788, dist_loss: 1.441976547241211
recon_loss: 0.02826867438852787, dist_loss: 0.7719323635101318
recon_loss: 0.028268782421946526, dist_loss: 0.4646505117416382
recon_loss: 0.028269309550523758, dist_loss: 0.4613885283470154
recon_loss: 0.02826993726193905, dist_loss: 0.627544105052948
recon_loss: 0.02827041782438755, dist_loss: 0.8339884281158447
recon_loss: 0.028271304443478584, dist_loss: 0.39384639263153076
recon_loss: 0.028271974995732307, dist_loss: 0.6568644046783447
recon_loss: 0.028272230178117752, dist_loss: 1.0627754926681519
recon_loss: 0.028272505849599838, dist_loss: 0.6523274779319763
recon_loss: 0.02827213704586029, dist_loss: 0.6074705719947815
recon_loss: 0.0282718688249588, dist_loss: 0.6757901906967163
recon_loss: 0.028271682560443878, dist_loss: 0.9106888771057129
recon_loss: 0.028271591290831566, dist_loss: 0.7240692377090454
recon_loss: 0.028272010385990143, dist_loss: 0.28458279371261597
recon_loss: 0.028272205963730812, dist_loss: 0.870401918888092
recon_loss: 0.028271513059735298, dist_loss: 1.0928159952163696
recon_loss: 0.028270700946450233, dist_loss: 0.5616110563278198
recon_loss: 0.028269872069358826, dist_loss: 0.8101226091384888
recon_loss: 0.028269462287425995, dist_loss: 0.4359360933303833
recon_loss: 0.02826889604330063, dist_loss: 0.6227671504020691
recon_loss: 0.02826802246272564, dist_loss: 1.070901870727539
recon_loss: 0.028267528861761093, dist_loss: 0.596504807472229
recon_loss: 0.02826714888215065, dist_loss: 0.5910106897354126
recon_loss: 0.028266962617635727, dist_loss: 0.4483182728290558
recon_loss: 0.02826683782041073, dist_loss: 0.32334643602371216
recon_loss: 0.028266973793506622, dist_loss: 0.3991001844406128
recon_loss: 0.02826695144176483, dist_loss: 0.5689490437507629
recon_loss: 0.02826659381389618, dist_loss: 0.7536754608154297
recon_loss: 0.028266441076993942, dist_loss: 0.9876845479011536
recon_loss: 0.028266124427318573, dist_loss: 0.39133119583129883
recon_loss: 0.028265953063964844, dist_loss: 0.3467963933944702
recon_loss: 0.028265831992030144, dist_loss: 1.0533990859985352
recon_loss: 0.02826586179435253, dist_loss: 0.3915421962738037
recon_loss: 0.02826623059809208, dist_loss: 0.33524778485298157
recon_loss: 0.028266506269574165, dist_loss: 0.6330214738845825
recon_loss: 0.028266528621315956, dist_loss: 0.8100423216819763
recon_loss: 0.028266666457057, dist_loss: 1.028177261352539
recon_loss: 0.02826654724776745, dist_loss: 1.1705937385559082
recon_loss: 0.028266888111829758, dist_loss: 0.6572518348693848
recon_loss: 0.028266597539186478, dist_loss: 0.6986968517303467
recon_loss: 0.028266606852412224, dist_loss: 0.7833114266395569
Pre-training Epoch 72:  36%|███▌      | 133/367 [00:00<00:01, 169.85it/s]Pre-training Epoch 72:  41%|████      | 151/367 [00:00<00:01, 172.05it/s]Pre-training Epoch 72:  46%|████▌     | 169/367 [00:01<00:01, 171.50it/s]Pre-training Epoch 72:  51%|█████     | 187/367 [00:01<00:01, 164.06it/s]Pre-training Epoch 72:  56%|█████▌    | 204/367 [00:01<00:01, 160.32it/s]Pre-training Epoch 72:  60%|██████    | 221/367 [00:01<00:00, 158.19it/s]Pre-training Epoch 72:  65%|██████▍   | 237/367 [00:01<00:00, 156.40it/s]Pre-training Epoch 72:  69%|██████▉   | 253/367 [00:01<00:00, 155.65it/s]recon_loss: 0.028266295790672302, dist_loss: 0.3405343294143677
recon_loss: 0.028265593573451042, dist_loss: 0.9368381500244141
recon_loss: 0.028265222907066345, dist_loss: 0.4796183705329895
recon_loss: 0.028264636173844337, dist_loss: 0.4775606393814087
recon_loss: 0.028264621272683144, dist_loss: 0.4921301007270813
recon_loss: 0.02826502174139023, dist_loss: 0.6947866082191467
recon_loss: 0.02826595865190029, dist_loss: 0.6688300371170044
recon_loss: 0.028267472982406616, dist_loss: 0.7890611886978149
recon_loss: 0.028269484639167786, dist_loss: 0.3735467195510864
recon_loss: 0.02827133983373642, dist_loss: 0.9140347242355347
recon_loss: 0.02827381156384945, dist_loss: 0.41561251878738403
recon_loss: 0.02827579714357853, dist_loss: 0.6415369510650635
recon_loss: 0.028278183192014694, dist_loss: 0.7049297094345093
recon_loss: 0.02828158251941204, dist_loss: 0.5350884199142456
recon_loss: 0.028282832354307175, dist_loss: 0.6594083309173584
recon_loss: 0.02828199230134487, dist_loss: 0.42932742834091187
recon_loss: 0.02827991358935833, dist_loss: 0.4073300361633301
recon_loss: 0.02827819250524044, dist_loss: 1.0686020851135254
recon_loss: 0.028275979682803154, dist_loss: 0.4704984426498413
recon_loss: 0.028273915871977806, dist_loss: 0.4886699914932251
recon_loss: 0.028271852061152458, dist_loss: 1.0288188457489014
recon_loss: 0.02827027440071106, dist_loss: 0.42097216844558716
recon_loss: 0.02826913818717003, dist_loss: 1.0732221603393555
recon_loss: 0.028268462046980858, dist_loss: 0.4325253963470459
recon_loss: 0.028267228975892067, dist_loss: 0.4733666479587555
recon_loss: 0.028266170993447304, dist_loss: 0.3305361270904541
recon_loss: 0.028265519067645073, dist_loss: 0.5807552337646484
recon_loss: 0.028264937922358513, dist_loss: 0.7247674465179443
recon_loss: 0.028264591470360756, dist_loss: 0.7397856712341309
recon_loss: 0.02826453000307083, dist_loss: 1.2780841588974
recon_loss: 0.028264421969652176, dist_loss: 0.7388961315155029
recon_loss: 0.02826482243835926, dist_loss: 0.6830679178237915
recon_loss: 0.02826492302119732, dist_loss: 0.7331567406654358
recon_loss: 0.0282660573720932, dist_loss: 0.9614874124526978
recon_loss: 0.028266428038477898, dist_loss: 0.527957022190094
recon_loss: 0.028266796842217445, dist_loss: 0.43229517340660095
recon_loss: 0.02826792560517788, dist_loss: 0.5537536144256592
recon_loss: 0.028268013149499893, dist_loss: 0.4914979338645935
recon_loss: 0.028268221765756607, dist_loss: 0.5420085191726685
recon_loss: 0.028268136084079742, dist_loss: 0.63446044921875
recon_loss: 0.028267493471503258, dist_loss: 0.6250443458557129
recon_loss: 0.028267452493309975, dist_loss: 0.964912474155426
recon_loss: 0.02826666459441185, dist_loss: 0.5515474081039429
recon_loss: 0.028265701606869698, dist_loss: 0.5780181288719177
recon_loss: 0.028265222907066345, dist_loss: 0.758409857749939
recon_loss: 0.028264453634619713, dist_loss: 0.5033630132675171
recon_loss: 0.02826407179236412, dist_loss: 0.6849133968353271
recon_loss: 0.028263797983527184, dist_loss: 0.6353543400764465
recon_loss: 0.02826293557882309, dist_loss: 0.7703901529312134
recon_loss: 0.02826290763914585, dist_loss: 1.0446925163269043
recon_loss: 0.02826261892914772, dist_loss: 0.5197124481201172
recon_loss: 0.0282630305737257, dist_loss: 0.5886144638061523
recon_loss: 0.02826278656721115, dist_loss: 0.7620086669921875
recon_loss: 0.028263073414564133, dist_loss: 0.7301466464996338
recon_loss: 0.028263580054044724, dist_loss: 0.38057833909988403
recon_loss: 0.02826397679746151, dist_loss: 0.6778699159622192
recon_loss: 0.028263866901397705, dist_loss: 0.5511587858200073
recon_loss: 0.028264056891202927, dist_loss: 0.9172722101211548
recon_loss: 0.028263917192816734, dist_loss: 0.36763328313827515
recon_loss: 0.02826358750462532, dist_loss: 0.47084835171699524
recon_loss: 0.028262827545404434, dist_loss: 0.5793520212173462
recon_loss: 0.02826237678527832, dist_loss: 0.7106572389602661
recon_loss: 0.028261903673410416, dist_loss: 1.0070852041244507
recon_loss: 0.028261473402380943, dist_loss: 0.6129119992256165
recon_loss: 0.028261985629796982, dist_loss: 0.7373925447463989
recon_loss: 0.02826150506734848, dist_loss: 0.5298080444335938
recon_loss: 0.028261715546250343, dist_loss: 0.40201127529144287
recon_loss: 0.028262265026569366, dist_loss: 1.0653795003890991
recon_loss: 0.028262438252568245, dist_loss: 0.5533347725868225
recon_loss: 0.02826281264424324, dist_loss: 0.5981862545013428
recon_loss: 0.02826293744146824, dist_loss: 0.6353904008865356
recon_loss: 0.02826303243637085, dist_loss: 0.5763047933578491
recon_loss: 0.02826348878443241, dist_loss: 0.5995804071426392
recon_loss: 0.02826380729675293, dist_loss: 0.5398271083831787
recon_loss: 0.02826329879462719, dist_loss: 0.7073438763618469
recon_loss: 0.028262486681342125, dist_loss: 0.9674774408340454
recon_loss: 0.028261495754122734, dist_loss: 0.5588120222091675
recon_loss: 0.028260909020900726, dist_loss: 0.3262367844581604
recon_loss: 0.028260767459869385, dist_loss: 0.7106291055679321
recon_loss: 0.02826208807528019, dist_loss: 0.5257575511932373
recon_loss: 0.028261838480830193, dist_loss: 0.5501055121421814
recon_loss: 0.028262952342629433, dist_loss: 0.39961326122283936
recon_loss: 0.028264010325074196, dist_loss: 0.49890467524528503
recon_loss: 0.028264353051781654, dist_loss: 0.4244215786457062
recon_loss: 0.028265835717320442, dist_loss: 0.6389620304107666
recon_loss: 0.028265930712223053, dist_loss: 0.4385216236114502
recon_loss: 0.028265105560421944, dist_loss: 0.5490281581878662
recon_loss: 0.028264619410037994, dist_loss: 0.5727969408035278
recon_loss: 0.028264323249459267, dist_loss: 0.6530719995498657
recon_loss: 0.02826392836868763, dist_loss: 0.7032152414321899
recon_loss: 0.02826392464339733, dist_loss: 0.48649853467941284
recon_loss: 0.02826378308236599, dist_loss: 0.5394809246063232
recon_loss: 0.028263412415981293, dist_loss: 0.34329602122306824
recon_loss: 0.028262779116630554, dist_loss: 0.621019721031189
recon_loss: 0.028262386098504066, dist_loss: 1.2878620624542236
recon_loss: 0.02826184593141079, dist_loss: 0.8664356470108032
recon_loss: 0.028261227533221245, dist_loss: 0.43981438875198364
recon_loss: 0.028260741382837296, dist_loss: 0.433328777551651
recon_loss: 0.028259538114070892, dist_loss: 0.5077351927757263
recon_loss: 0.028258563950657845, dist_loss: 0.6503918766975403
recon_loss: 0.028258008882403374, dist_loss: 1.7613962888717651
recon_loss: 0.028257790952920914, dist_loss: 0.48558884859085083
recon_loss: 0.02825751155614853, dist_loss: 0.894930362701416
recon_loss: 0.028257107362151146, dist_loss: 0.9237086772918701
recon_loss: 0.028256908059120178, dist_loss: 0.44791287183761597
recon_loss: 0.028256701305508614, dist_loss: 1.3071274757385254
recon_loss: 0.02825688011944294, dist_loss: 0.5177289247512817
recon_loss: 0.028256867080926895, dist_loss: 1.1201039552688599
recon_loss: 0.028256576508283615, dist_loss: 0.7059565782546997
recon_loss: 0.028256895020604134, dist_loss: 0.3167485296726227
recon_loss: 0.028256256133317947, dist_loss: 1.032855749130249
recon_loss: 0.028256477788090706, dist_loss: 0.6977753043174744
recon_loss: 0.028256405144929886, dist_loss: 1.0655708312988281
recon_loss: 0.028256094083189964, dist_loss: 0.4769858121871948
recon_loss: 0.028256306424736977, dist_loss: 0.38944947719573975
recon_loss: 0.028255825862288475, dist_loss: 0.6298900842666626
recon_loss: 0.028256302699446678, dist_loss: 0.9995715618133545
recon_loss: 0.028256485238671303, dist_loss: 0.6204599738121033
recon_loss: 0.02825693041086197, dist_loss: 0.5906535983085632
recon_loss: 0.02825690433382988, dist_loss: 0.42763975262641907
recon_loss: 0.028256962075829506, dist_loss: 0.4791960120201111
recon_loss: 0.028256554156541824, dist_loss: 0.9700785875320435
recon_loss: 0.028256574645638466, dist_loss: 0.6903866529464722
recon_loss: 0.0282562468200922, dist_loss: 0.6949567794799805
recon_loss: 0.028255706652998924, dist_loss: 0.5488084554672241
recon_loss: 0.028255514800548553, dist_loss: 0.6716648936271667
recon_loss: 0.02825484238564968, dist_loss: 0.48796898126602173
recon_loss: 0.028254248201847076, dist_loss: 0.47890016436576843
Pre-training Epoch 72:  73%|███████▎  | 269/367 [00:01<00:00, 156.19it/s]Pre-training Epoch 72:  78%|███████▊  | 285/367 [00:01<00:00, 156.86it/s]Pre-training Epoch 72:  82%|████████▏ | 301/367 [00:01<00:00, 157.06it/s]Pre-training Epoch 72:  86%|████████▋ | 317/367 [00:01<00:00, 155.79it/s]Pre-training Epoch 72:  91%|█████████ | 333/367 [00:02<00:00, 151.20it/s]Pre-training Epoch 72:  95%|█████████▌| 349/367 [00:02<00:00, 152.77it/s]Pre-training Epoch 72:  99%|█████████▉| 365/367 [00:02<00:00, 151.39it/s]Pre-training Epoch 72: 100%|██████████| 367/367 [00:02<00:00, 157.46it/s]
recon_loss: 0.02825446054339409, dist_loss: 0.4034461975097656
recon_loss: 0.02825375646352768, dist_loss: 0.6225457191467285
recon_loss: 0.02825387939810753, dist_loss: 0.9685169458389282
recon_loss: 0.02825394831597805, dist_loss: 0.6253889799118042
recon_loss: 0.028254015371203423, dist_loss: 0.5614517331123352
recon_loss: 0.028254520148038864, dist_loss: 0.7918987274169922
recon_loss: 0.02825462631881237, dist_loss: 0.8994594216346741
recon_loss: 0.02825465053319931, dist_loss: 0.8694236278533936
recon_loss: 0.02825464867055416, dist_loss: 0.79606693983078
recon_loss: 0.02825445495545864, dist_loss: 0.7408161759376526
recon_loss: 0.028254322707653046, dist_loss: 1.0574181079864502
recon_loss: 0.028253955766558647, dist_loss: 1.2720381021499634
recon_loss: 0.028253711760044098, dist_loss: 0.5893822908401489
recon_loss: 0.02825343981385231, dist_loss: 0.5897213220596313
recon_loss: 0.028253547847270966, dist_loss: 0.43914994597435
recon_loss: 0.02825343795120716, dist_loss: 0.4116511642932892
recon_loss: 0.02825315110385418, dist_loss: 0.40666282176971436
recon_loss: 0.02825324982404709, dist_loss: 0.7182043194770813
recon_loss: 0.028252970427274704, dist_loss: 0.9262884259223938
recon_loss: 0.028252720832824707, dist_loss: 0.31487396359443665
recon_loss: 0.02825242094695568, dist_loss: 0.5661402344703674
recon_loss: 0.028252633288502693, dist_loss: 0.6263504028320312
recon_loss: 0.028253257274627686, dist_loss: 0.6645476818084717
recon_loss: 0.028253836557269096, dist_loss: 0.5415297746658325
recon_loss: 0.02825446054339409, dist_loss: 0.7776862382888794
recon_loss: 0.028253868222236633, dist_loss: 0.9172762036323547
recon_loss: 0.028254033997654915, dist_loss: 0.49060162901878357
recon_loss: 0.028254639357328415, dist_loss: 0.684032142162323
recon_loss: 0.028254002332687378, dist_loss: 0.7157799005508423
recon_loss: 0.028253749012947083, dist_loss: 0.5286688804626465
recon_loss: 0.028253117576241493, dist_loss: 0.28144198656082153
recon_loss: 0.028252122923731804, dist_loss: 0.6324251890182495
recon_loss: 0.028252067044377327, dist_loss: 0.8789342641830444
recon_loss: 0.0282507985830307, dist_loss: 0.7958831787109375
recon_loss: 0.028250746428966522, dist_loss: 0.5508315563201904
recon_loss: 0.02825063094496727, dist_loss: 0.5154749751091003
recon_loss: 0.02825029566884041, dist_loss: 0.6881450414657593
recon_loss: 0.028250565752387047, dist_loss: 0.41542893648147583
recon_loss: 0.028250331059098244, dist_loss: 0.5269356966018677
recon_loss: 0.028250787407159805, dist_loss: 0.3972587287425995
recon_loss: 0.02825108729302883, dist_loss: 0.6971535682678223
recon_loss: 0.028250712901353836, dist_loss: 0.9708733558654785
recon_loss: 0.02825099788606167, dist_loss: 0.6114637851715088
recon_loss: 0.028250262141227722, dist_loss: 0.5203537940979004
recon_loss: 0.028250515460968018, dist_loss: 0.3721633553504944
recon_loss: 0.0282500758767128, dist_loss: 0.5607313513755798
recon_loss: 0.02824961580336094, dist_loss: 0.7537958025932312
recon_loss: 0.02824929729104042, dist_loss: 0.5924426317214966
recon_loss: 0.028248976916074753, dist_loss: 0.6470937728881836
recon_loss: 0.02824927493929863, dist_loss: 0.5036327838897705
recon_loss: 0.028248794376850128, dist_loss: 0.5323504209518433
recon_loss: 0.028249096125364304, dist_loss: 0.8172245621681213
recon_loss: 0.028248921036720276, dist_loss: 0.5671490430831909
recon_loss: 0.028248660266399384, dist_loss: 0.6172935962677002
recon_loss: 0.028249045833945274, dist_loss: 0.5317882299423218
recon_loss: 0.028248565271496773, dist_loss: 1.0003046989440918
recon_loss: 0.028248531743884087, dist_loss: 0.5739680528640747
recon_loss: 0.028248289600014687, dist_loss: 0.6164091229438782
recon_loss: 0.028247999027371407, dist_loss: 0.6926401257514954
recon_loss: 0.02824789471924305, dist_loss: 0.6886594295501709
recon_loss: 0.02824781835079193, dist_loss: 0.8524659276008606
recon_loss: 0.0282480176538229, dist_loss: 0.575314998626709
recon_loss: 0.028247704729437828, dist_loss: 0.5921560525894165
recon_loss: 0.028247788548469543, dist_loss: 1.0815110206604004
recon_loss: 0.028248194605112076, dist_loss: 0.9381699562072754
recon_loss: 0.028248608112335205, dist_loss: 0.4255693256855011
recon_loss: 0.02824917435646057, dist_loss: 0.6254891753196716
recon_loss: 0.028249362483620644, dist_loss: 0.6652756929397583
recon_loss: 0.028249051421880722, dist_loss: 0.43094363808631897
recon_loss: 0.028248878195881844, dist_loss: 0.8696663975715637
recon_loss: 0.028248528018593788, dist_loss: 0.5282558798789978
recon_loss: 0.028248319402337074, dist_loss: 0.8472058176994324
recon_loss: 0.02824833057820797, dist_loss: 0.4997807741165161
recon_loss: 0.02824813313782215, dist_loss: 0.7525730729103088
recon_loss: 0.02824806608259678, dist_loss: 0.27066510915756226
recon_loss: 0.028248339891433716, dist_loss: 0.7428638935089111
recon_loss: 0.02824879251420498, dist_loss: 0.606456995010376
recon_loss: 0.028249206021428108, dist_loss: 0.9795064926147461
recon_loss: 0.028249671682715416, dist_loss: 0.4399157464504242
recon_loss: 0.0282489825040102, dist_loss: 0.8196319341659546
recon_loss: 0.028249382972717285, dist_loss: 0.9945347309112549
recon_loss: 0.028248878195881844, dist_loss: 0.5455211997032166
recon_loss: 0.028248345479369164, dist_loss: 0.681368350982666
recon_loss: 0.028248069807887077, dist_loss: 0.5835907459259033
recon_loss: 0.02824736386537552, dist_loss: 0.7702051401138306
recon_loss: 0.0282476507127285, dist_loss: 0.9519141912460327
recon_loss: 0.028246989473700523, dist_loss: 0.7291750907897949
recon_loss: 0.02824750542640686, dist_loss: 0.47831135988235474
recon_loss: 0.028247229754924774, dist_loss: 0.643101692199707
recon_loss: 0.028247321024537086, dist_loss: 0.870476484298706
recon_loss: 0.028247660025954247, dist_loss: 0.45917797088623047
recon_loss: 0.028247321024537086, dist_loss: 0.6484136581420898
recon_loss: 0.02824721299111843, dist_loss: 0.8342859745025635
recon_loss: 0.0282470490783453, dist_loss: 1.0785510540008545
recon_loss: 0.028247004374861717, dist_loss: 0.7524105906486511
recon_loss: 0.028246857225894928, dist_loss: 0.8573938608169556
recon_loss: 0.028246527537703514, dist_loss: 0.9517230987548828
recon_loss: 0.02824622392654419, dist_loss: 0.4409068822860718
recon_loss: 0.02824595756828785, dist_loss: 0.6404557228088379
recon_loss: 0.028245853260159492, dist_loss: 0.704422652721405
recon_loss: 0.028246108442544937, dist_loss: 0.8796737790107727
recon_loss: 0.02824556827545166, dist_loss: 0.42831185460090637
recon_loss: 0.02824580855667591, dist_loss: 1.4368022680282593
recon_loss: 0.0282455962151289, dist_loss: 0.2702285051345825
recon_loss: 0.028245599940419197, dist_loss: 0.7169264554977417
recon_loss: 0.02824585884809494, dist_loss: 0.38758382201194763
recon_loss: 0.028245853260159492, dist_loss: 0.6226218342781067
recon_loss: 0.02824617736041546, dist_loss: 0.398275226354599
recon_loss: 0.028246425092220306, dist_loss: 1.0312565565109253
recon_loss: 0.028247224166989326, dist_loss: 0.4682101607322693
recon_loss: 0.028248289600014687, dist_loss: 0.49874645471572876
Pre-training Epoch 73:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 73:   4%|▍         | 16/367 [00:00<00:02, 150.96it/s]Pre-training Epoch 73:   9%|▊         | 32/367 [00:00<00:02, 153.35it/s]Pre-training Epoch 73:  13%|█▎        | 48/367 [00:00<00:02, 152.85it/s]Pre-training Epoch 73:  17%|█▋        | 64/367 [00:00<00:01, 155.42it/s]Pre-training Epoch 73:  22%|██▏       | 80/367 [00:00<00:01, 155.15it/s]Pre-training Epoch 73:  26%|██▌       | 96/367 [00:00<00:01, 153.61it/s]Pre-training Epoch 73:  31%|███       | 112/367 [00:00<00:01, 152.95it/s]Pre-training Epoch 73:  35%|███▍      | 128/367 [00:00<00:01, 153.26it/s]recon_loss: 0.028249405324459076, dist_loss: 0.972205638885498
recon_loss: 0.02825174108147621, dist_loss: 0.5382434129714966
recon_loss: 0.028250835835933685, dist_loss: 0.7691485285758972
recon_loss: 0.028252149000763893, dist_loss: 0.8300213813781738
recon_loss: 0.028253743425011635, dist_loss: 0.5218362808227539
recon_loss: 0.028251316398382187, dist_loss: 0.8064927458763123
recon_loss: 0.028253935277462006, dist_loss: 1.0446056127548218
recon_loss: 0.02825036458671093, dist_loss: 0.6023092269897461
recon_loss: 0.02824985608458519, dist_loss: 0.4846278429031372
recon_loss: 0.028248704969882965, dist_loss: 0.7075120210647583
recon_loss: 0.028246648609638214, dist_loss: 0.7561395168304443
recon_loss: 0.02824733592569828, dist_loss: 0.7348188161849976
recon_loss: 0.028246033936738968, dist_loss: 0.7441774010658264
recon_loss: 0.0282472912222147, dist_loss: 0.6014158725738525
recon_loss: 0.028248561546206474, dist_loss: 0.5800074338912964
recon_loss: 0.028248388320207596, dist_loss: 0.3147711157798767
recon_loss: 0.028249889612197876, dist_loss: 0.5071935653686523
recon_loss: 0.028250621631741524, dist_loss: 0.5304429531097412
recon_loss: 0.02825040929019451, dist_loss: 0.5142593383789062
recon_loss: 0.028251707553863525, dist_loss: 0.6834415197372437
recon_loss: 0.02824934385716915, dist_loss: 0.38880443572998047
recon_loss: 0.028249206021428108, dist_loss: 0.45621004700660706
recon_loss: 0.028249463066458702, dist_loss: 0.6081881523132324
recon_loss: 0.028247462585568428, dist_loss: 0.5132148861885071
recon_loss: 0.02824905887246132, dist_loss: 0.3423875570297241
recon_loss: 0.028247438371181488, dist_loss: 0.693038821220398
recon_loss: 0.02824546955525875, dist_loss: 0.3748819828033447
recon_loss: 0.02824576571583748, dist_loss: 0.7074568271636963
recon_loss: 0.02824409492313862, dist_loss: 0.7149336338043213
recon_loss: 0.02824433334171772, dist_loss: 0.34753039479255676
recon_loss: 0.028244255110621452, dist_loss: 0.5914748311042786
recon_loss: 0.028243713080883026, dist_loss: 0.5552106499671936
recon_loss: 0.02824464440345764, dist_loss: 0.79502272605896
recon_loss: 0.0282443817704916, dist_loss: 0.8937084674835205
recon_loss: 0.028245670720934868, dist_loss: 0.4429267644882202
recon_loss: 0.028246058151125908, dist_loss: 1.0819870233535767
recon_loss: 0.028245670720934868, dist_loss: 0.674759030342102
recon_loss: 0.028246013447642326, dist_loss: 0.7663763761520386
recon_loss: 0.028244683519005775, dist_loss: 0.3617045283317566
recon_loss: 0.028243981301784515, dist_loss: 0.8909180164337158
recon_loss: 0.028243884444236755, dist_loss: 0.6108584403991699
recon_loss: 0.02824285812675953, dist_loss: 0.6044370532035828
recon_loss: 0.02824315056204796, dist_loss: 1.176080346107483
recon_loss: 0.028242450207471848, dist_loss: 0.7525607943534851
recon_loss: 0.028241751715540886, dist_loss: 0.6962353587150574
recon_loss: 0.028242329135537148, dist_loss: 1.6287786960601807
recon_loss: 0.02824125997722149, dist_loss: 0.5641615390777588
recon_loss: 0.028241334483027458, dist_loss: 0.4910184442996979
recon_loss: 0.028241217136383057, dist_loss: 0.6047104001045227
recon_loss: 0.028240201994776726, dist_loss: 0.6958281397819519
recon_loss: 0.02824028953909874, dist_loss: 0.5863373875617981
recon_loss: 0.028240052983164787, dist_loss: 0.5202571153640747
recon_loss: 0.028239767998456955, dist_loss: 0.8303426504135132
recon_loss: 0.02823997102677822, dist_loss: 0.6742891073226929
recon_loss: 0.028239969164133072, dist_loss: 1.0965956449508667
recon_loss: 0.028239650651812553, dist_loss: 0.4095516502857208
recon_loss: 0.028239494189620018, dist_loss: 0.8324746489524841
recon_loss: 0.028239432722330093, dist_loss: 0.4601573050022125
recon_loss: 0.02823949232697487, dist_loss: 0.7793174982070923
recon_loss: 0.028239358216524124, dist_loss: 0.7756821513175964
recon_loss: 0.028239339590072632, dist_loss: 0.5887651443481445
recon_loss: 0.02823866717517376, dist_loss: 0.9405441880226135
recon_loss: 0.028238603845238686, dist_loss: 0.8383729457855225
recon_loss: 0.02823837473988533, dist_loss: 0.3850999176502228
recon_loss: 0.028238296508789062, dist_loss: 0.7140087485313416
recon_loss: 0.02823822945356369, dist_loss: 0.47462397813796997
recon_loss: 0.028238067403435707, dist_loss: 0.6326531171798706
recon_loss: 0.02823789045214653, dist_loss: 1.0313284397125244
recon_loss: 0.02823772095143795, dist_loss: 0.6123430728912354
recon_loss: 0.028237931430339813, dist_loss: 0.3437173068523407
recon_loss: 0.028238380327820778, dist_loss: 0.4027063250541687
recon_loss: 0.02823883295059204, dist_loss: 0.357556015253067
recon_loss: 0.0282394178211689, dist_loss: 0.7748119235038757
recon_loss: 0.02823910489678383, dist_loss: 0.8661932349205017
recon_loss: 0.028239162638783455, dist_loss: 0.49550604820251465
recon_loss: 0.02823876217007637, dist_loss: 0.6707454919815063
recon_loss: 0.028238659724593163, dist_loss: 0.5983490347862244
recon_loss: 0.028238769620656967, dist_loss: 0.9015831351280212
recon_loss: 0.028238939121365547, dist_loss: 0.36143314838409424
recon_loss: 0.028238948434591293, dist_loss: 0.47181105613708496
recon_loss: 0.02823876403272152, dist_loss: 0.5822325944900513
recon_loss: 0.028238151222467422, dist_loss: 0.7655772566795349
recon_loss: 0.028237372636795044, dist_loss: 0.4523390233516693
recon_loss: 0.028236769139766693, dist_loss: 0.7129682898521423
recon_loss: 0.02823673188686371, dist_loss: 0.7390942573547363
recon_loss: 0.02823713608086109, dist_loss: 0.9381543397903442
recon_loss: 0.028237909078598022, dist_loss: 0.7109188437461853
recon_loss: 0.028239456936717033, dist_loss: 0.706793487071991
recon_loss: 0.02824075147509575, dist_loss: 0.3102476894855499
recon_loss: 0.028242072090506554, dist_loss: 0.5652191638946533
recon_loss: 0.028242843225598335, dist_loss: 0.5231139659881592
recon_loss: 0.028243230655789375, dist_loss: 1.05593740940094
recon_loss: 0.028243189677596092, dist_loss: 0.601140022277832
recon_loss: 0.028242703527212143, dist_loss: 0.4599570631980896
recon_loss: 0.028241891413927078, dist_loss: 0.5495656728744507
recon_loss: 0.028240879997611046, dist_loss: 0.42599034309387207
recon_loss: 0.028240079060196877, dist_loss: 0.7044258117675781
recon_loss: 0.02823939360678196, dist_loss: 0.8938946723937988
recon_loss: 0.028238719329237938, dist_loss: 1.158724308013916
recon_loss: 0.028237972408533096, dist_loss: 0.5990124940872192
recon_loss: 0.028237495571374893, dist_loss: 0.7799190282821655
recon_loss: 0.028237279504537582, dist_loss: 0.3915957510471344
recon_loss: 0.028236767277121544, dist_loss: 0.4319011867046356
recon_loss: 0.028236832469701767, dist_loss: 0.815529465675354
recon_loss: 0.028236743062734604, dist_loss: 0.4901663661003113
recon_loss: 0.028236446902155876, dist_loss: 0.6878278255462646
recon_loss: 0.028236161917448044, dist_loss: 0.9748471975326538
recon_loss: 0.028235821053385735, dist_loss: 0.7196634411811829
recon_loss: 0.028235265985131264, dist_loss: 0.6846158504486084
recon_loss: 0.02823490835726261, dist_loss: 0.4208567142486572
recon_loss: 0.02823476307094097, dist_loss: 0.5961488485336304
recon_loss: 0.028234487399458885, dist_loss: 0.8759334087371826
recon_loss: 0.028234396129846573, dist_loss: 0.7568800449371338
recon_loss: 0.028234314173460007, dist_loss: 0.5482169389724731
recon_loss: 0.02823452465236187, dist_loss: 0.4033227860927582
recon_loss: 0.028234675526618958, dist_loss: 0.6749331951141357
recon_loss: 0.028234630823135376, dist_loss: 0.7055032253265381
recon_loss: 0.028234371915459633, dist_loss: 0.5310691595077515
recon_loss: 0.02823401428759098, dist_loss: 0.47367990016937256
recon_loss: 0.02823399193584919, dist_loss: 0.5392286777496338
recon_loss: 0.028234081342816353, dist_loss: 1.2192081212997437
recon_loss: 0.028233954682946205, dist_loss: 0.3046931028366089
recon_loss: 0.028233591467142105, dist_loss: 0.848484992980957
recon_loss: 0.028232697397470474, dist_loss: 0.48917120695114136
recon_loss: 0.02823271043598652, dist_loss: 0.5633051991462708
recon_loss: 0.028233155608177185, dist_loss: 0.5496436357498169
recon_loss: 0.028233258053660393, dist_loss: 0.6452040672302246
recon_loss: 0.028233088552951813, dist_loss: 0.8303840160369873
Pre-training Epoch 73:  39%|███▉      | 144/367 [00:00<00:01, 153.90it/s]Pre-training Epoch 73:  44%|████▎     | 160/367 [00:01<00:01, 154.22it/s]Pre-training Epoch 73:  48%|████▊     | 176/367 [00:01<00:01, 154.39it/s]Pre-training Epoch 73:  52%|█████▏    | 192/367 [00:01<00:01, 155.59it/s]Pre-training Epoch 73:  57%|█████▋    | 208/367 [00:01<00:01, 155.53it/s]Pre-training Epoch 73:  62%|██████▏   | 226/367 [00:01<00:00, 160.56it/s]Pre-training Epoch 73:  66%|██████▋   | 244/367 [00:01<00:00, 165.38it/s]recon_loss: 0.028232615441083908, dist_loss: 0.9154167771339417
recon_loss: 0.02823260799050331, dist_loss: 0.7900039553642273
recon_loss: 0.028232941403985023, dist_loss: 0.36885127425193787
recon_loss: 0.02823282778263092, dist_loss: 0.4888477921485901
recon_loss: 0.028232516720891, dist_loss: 0.5039442777633667
recon_loss: 0.02823207527399063, dist_loss: 0.27500641345977783
recon_loss: 0.028231719508767128, dist_loss: 0.9683620929718018
recon_loss: 0.028231602162122726, dist_loss: 0.6307671070098877
recon_loss: 0.028231656178832054, dist_loss: 0.33518075942993164
recon_loss: 0.02823149412870407, dist_loss: 0.9657124280929565
recon_loss: 0.028231199830770493, dist_loss: 0.9388177394866943
recon_loss: 0.028231073170900345, dist_loss: 1.2137877941131592
recon_loss: 0.02823111042380333, dist_loss: 0.7132735848426819
recon_loss: 0.028231212869286537, dist_loss: 0.6679593920707703
recon_loss: 0.028231361880898476, dist_loss: 0.7678990364074707
recon_loss: 0.02823152393102646, dist_loss: 0.44561684131622314
recon_loss: 0.028231557458639145, dist_loss: 0.3641631603240967
recon_loss: 0.028231453150510788, dist_loss: 0.8053421378135681
recon_loss: 0.02823100984096527, dist_loss: 0.6732897758483887
recon_loss: 0.02823096141219139, dist_loss: 0.7775794267654419
recon_loss: 0.028231030330061913, dist_loss: 1.1257460117340088
recon_loss: 0.02823103778064251, dist_loss: 0.5440943241119385
recon_loss: 0.028231140226125717, dist_loss: 0.9067420363426208
recon_loss: 0.028230903670191765, dist_loss: 0.33176881074905396
recon_loss: 0.028231393545866013, dist_loss: 0.7361082434654236
recon_loss: 0.028231369331479073, dist_loss: 0.4930345416069031
recon_loss: 0.028230365365743637, dist_loss: 0.9169663190841675
recon_loss: 0.028231261298060417, dist_loss: 0.3792019486427307
recon_loss: 0.028230156749486923, dist_loss: 0.6180434823036194
recon_loss: 0.02823036164045334, dist_loss: 1.0677779912948608
recon_loss: 0.028231220319867134, dist_loss: 0.4676052927970886
recon_loss: 0.02822997234761715, dist_loss: 0.5537436604499817
recon_loss: 0.028230465948581696, dist_loss: 1.1668094396591187
recon_loss: 0.028229787945747375, dist_loss: 1.078843355178833
recon_loss: 0.02822992205619812, dist_loss: 0.5332870483398438
recon_loss: 0.028230544179677963, dist_loss: 0.39687442779541016
recon_loss: 0.028230266645550728, dist_loss: 0.5021470189094543
recon_loss: 0.028231577947735786, dist_loss: 0.7448592782020569
recon_loss: 0.0282317902892828, dist_loss: 0.3330581784248352
recon_loss: 0.028232689946889877, dist_loss: 0.5721626281738281
recon_loss: 0.028234776109457016, dist_loss: 1.007115364074707
recon_loss: 0.028235208243131638, dist_loss: 0.4921244978904724
recon_loss: 0.028236107900738716, dist_loss: 0.4264398515224457
recon_loss: 0.028237029910087585, dist_loss: 0.44493043422698975
recon_loss: 0.028236757963895798, dist_loss: 0.4518386721611023
recon_loss: 0.028237029910087585, dist_loss: 0.646379828453064
recon_loss: 0.028236443176865578, dist_loss: 0.34722787141799927
recon_loss: 0.02823561802506447, dist_loss: 0.6823819875717163
recon_loss: 0.0282346922904253, dist_loss: 0.9602575302124023
recon_loss: 0.028233269229531288, dist_loss: 1.1358613967895508
recon_loss: 0.028232406824827194, dist_loss: 1.0039277076721191
recon_loss: 0.028232311829924583, dist_loss: 0.4734015464782715
recon_loss: 0.02823316864669323, dist_loss: 0.5351715087890625
recon_loss: 0.028234316036105156, dist_loss: 0.5651614665985107
recon_loss: 0.028236789628863335, dist_loss: 0.5148540735244751
recon_loss: 0.02823932282626629, dist_loss: 0.598258376121521
recon_loss: 0.028240954503417015, dist_loss: 0.4261821508407593
recon_loss: 0.028241604566574097, dist_loss: 0.4047127962112427
recon_loss: 0.02824152261018753, dist_loss: 0.410434365272522
recon_loss: 0.028240391984581947, dist_loss: 0.8806725740432739
recon_loss: 0.028239229694008827, dist_loss: 1.1765739917755127
recon_loss: 0.02823844738304615, dist_loss: 0.5337218046188354
recon_loss: 0.02823750674724579, dist_loss: 0.8640180826187134
recon_loss: 0.028236962854862213, dist_loss: 0.6203173398971558
recon_loss: 0.028235603123903275, dist_loss: 0.7126952409744263
recon_loss: 0.02823389694094658, dist_loss: 0.6064298152923584
recon_loss: 0.02823302149772644, dist_loss: 1.095930576324463
recon_loss: 0.028232382610440254, dist_loss: 1.1581264734268188
recon_loss: 0.028232045471668243, dist_loss: 0.7722444534301758
recon_loss: 0.02823145128786564, dist_loss: 0.5152778625488281
recon_loss: 0.028230899944901466, dist_loss: 0.6467817425727844
recon_loss: 0.02823031134903431, dist_loss: 0.4326636493206024
recon_loss: 0.028229717165231705, dist_loss: 0.7237416505813599
recon_loss: 0.02822934277355671, dist_loss: 0.438010573387146
recon_loss: 0.028228554874658585, dist_loss: 0.3345720171928406
recon_loss: 0.028228428214788437, dist_loss: 0.9296941161155701
recon_loss: 0.02822805382311344, dist_loss: 0.3162706792354584
recon_loss: 0.028228063136339188, dist_loss: 0.6986796855926514
recon_loss: 0.02822820097208023, dist_loss: 0.8906707167625427
recon_loss: 0.028229152783751488, dist_loss: 1.0979712009429932
recon_loss: 0.028229916468262672, dist_loss: 1.293169617652893
recon_loss: 0.02823035791516304, dist_loss: 1.1021885871887207
recon_loss: 0.0282305758446455, dist_loss: 0.6618271470069885
recon_loss: 0.02823043428361416, dist_loss: 0.5554238557815552
recon_loss: 0.028230685740709305, dist_loss: 0.556110143661499
recon_loss: 0.028231415897607803, dist_loss: 0.6247347593307495
recon_loss: 0.02823130413889885, dist_loss: 0.8402073979377747
recon_loss: 0.028231045231223106, dist_loss: 0.7253259420394897
recon_loss: 0.028230685740709305, dist_loss: 0.7581115365028381
recon_loss: 0.028229396790266037, dist_loss: 0.9023195505142212
recon_loss: 0.028228428214788437, dist_loss: 1.1246156692504883
recon_loss: 0.02822856791317463, dist_loss: 0.7170248627662659
recon_loss: 0.02822778932750225, dist_loss: 0.6157441735267639
recon_loss: 0.028227055445313454, dist_loss: 0.4736281633377075
recon_loss: 0.02822709269821644, dist_loss: 0.430993914604187
recon_loss: 0.028227083384990692, dist_loss: 0.5112643241882324
recon_loss: 0.028226979076862335, dist_loss: 0.7274846434593201
recon_loss: 0.028226599097251892, dist_loss: 0.7154908776283264
recon_loss: 0.02822619490325451, dist_loss: 0.34086471796035767
recon_loss: 0.028225839138031006, dist_loss: 0.5416004657745361
recon_loss: 0.028225596994161606, dist_loss: 0.395984411239624
recon_loss: 0.028225308284163475, dist_loss: 0.2936822175979614
recon_loss: 0.028224963694810867, dist_loss: 0.370893657207489
recon_loss: 0.028224682435393333, dist_loss: 0.5808244943618774
recon_loss: 0.028224535286426544, dist_loss: 0.4503242075443268
recon_loss: 0.028224362060427666, dist_loss: 0.3732205033302307
recon_loss: 0.028224119916558266, dist_loss: 0.542548418045044
recon_loss: 0.028224021196365356, dist_loss: 0.6813156604766846
recon_loss: 0.028223808854818344, dist_loss: 0.8450703620910645
recon_loss: 0.028224436566233635, dist_loss: 0.5206340551376343
recon_loss: 0.028224820271134377, dist_loss: 0.28639018535614014
recon_loss: 0.028224173933267593, dist_loss: 1.109923005104065
recon_loss: 0.028225446119904518, dist_loss: 0.7208319902420044
recon_loss: 0.028224697336554527, dist_loss: 0.7461816668510437
recon_loss: 0.028225122019648552, dist_loss: 0.3119375705718994
recon_loss: 0.028225446119904518, dist_loss: 0.8559821844100952
recon_loss: 0.02822588011622429, dist_loss: 1.3345506191253662
recon_loss: 0.028225639835000038, dist_loss: 0.8076023459434509
recon_loss: 0.02822629176080227, dist_loss: 0.6570844650268555
recon_loss: 0.028225667774677277, dist_loss: 0.5682527422904968
recon_loss: 0.028226224705576897, dist_loss: 0.5291857719421387
recon_loss: 0.028224540874361992, dist_loss: 0.7108477354049683
recon_loss: 0.02822406217455864, dist_loss: 0.43200045824050903
recon_loss: 0.028223928064107895, dist_loss: 0.6294705867767334
recon_loss: 0.02822326496243477, dist_loss: 1.5757420063018799
recon_loss: 0.02822284959256649, dist_loss: 0.4652141332626343
recon_loss: 0.02822248823940754, dist_loss: 0.2814389765262604
recon_loss: 0.0282223392277956, dist_loss: 0.9677231311798096
Pre-training Epoch 73:  71%|███████   | 261/367 [00:01<00:00, 164.82it/s]Pre-training Epoch 73:  76%|███████▌  | 278/367 [00:01<00:00, 161.62it/s]Pre-training Epoch 73:  80%|████████  | 295/367 [00:01<00:00, 160.02it/s]Pre-training Epoch 73:  85%|████████▌ | 312/367 [00:01<00:00, 158.65it/s]Pre-training Epoch 73:  89%|████████▉ | 328/367 [00:02<00:00, 158.18it/s]Pre-training Epoch 73:  94%|█████████▎| 344/367 [00:02<00:00, 155.62it/s]Pre-training Epoch 73:  98%|█████████▊| 360/367 [00:02<00:00, 156.04it/s]Pre-training Epoch 73: 100%|██████████| 367/367 [00:02<00:00, 156.76it/s]
recon_loss: 0.02822236903011799, dist_loss: 0.86643385887146
recon_loss: 0.028222139924764633, dist_loss: 0.5952324867248535
recon_loss: 0.028222760185599327, dist_loss: 1.1194323301315308
recon_loss: 0.028222303837537766, dist_loss: 0.5482086539268494
recon_loss: 0.02822194993495941, dist_loss: 0.4611888527870178
recon_loss: 0.028221968561410904, dist_loss: 0.7012729644775391
recon_loss: 0.028221946209669113, dist_loss: 0.6963568329811096
recon_loss: 0.02822214551270008, dist_loss: 0.638959527015686
recon_loss: 0.028222080320119858, dist_loss: 0.684528648853302
recon_loss: 0.02822181023657322, dist_loss: 0.732835590839386
recon_loss: 0.028221430256962776, dist_loss: 0.36351537704467773
recon_loss: 0.02822113409638405, dist_loss: 0.5382959842681885
recon_loss: 0.02822144888341427, dist_loss: 0.6146107912063599
recon_loss: 0.028221696615219116, dist_loss: 0.5771664977073669
recon_loss: 0.028221825137734413, dist_loss: 0.5722655653953552
recon_loss: 0.028221631422638893, dist_loss: 0.3407703936100006
recon_loss: 0.02822139486670494, dist_loss: 0.5852084159851074
recon_loss: 0.02822146937251091, dist_loss: 0.5943905115127563
recon_loss: 0.028221584856510162, dist_loss: 0.4815903306007385
recon_loss: 0.028221704065799713, dist_loss: 0.7113214731216431
recon_loss: 0.02822146564722061, dist_loss: 0.966768741607666
recon_loss: 0.028221426531672478, dist_loss: 1.0298391580581665
recon_loss: 0.028221677988767624, dist_loss: 0.395591676235199
recon_loss: 0.028221920132637024, dist_loss: 0.5572086572647095
recon_loss: 0.028222503140568733, dist_loss: 0.7758451700210571
recon_loss: 0.028223078697919846, dist_loss: 0.8523759841918945
recon_loss: 0.028223713859915733, dist_loss: 0.6593940854072571
recon_loss: 0.02822386845946312, dist_loss: 0.4271959662437439
recon_loss: 0.028224194422364235, dist_loss: 0.9556028842926025
recon_loss: 0.0282240379601717, dist_loss: 0.532082200050354
recon_loss: 0.028223801404237747, dist_loss: 0.51838219165802
recon_loss: 0.028223464265465736, dist_loss: 0.545396089553833
recon_loss: 0.02822306752204895, dist_loss: 0.7969703674316406
recon_loss: 0.02822282165288925, dist_loss: 0.5749655961990356
recon_loss: 0.028222136199474335, dist_loss: 0.4059596359729767
recon_loss: 0.028221219778060913, dist_loss: 0.4556809067726135
recon_loss: 0.028221985325217247, dist_loss: 0.8296971321105957
recon_loss: 0.028220420703291893, dist_loss: 0.4279721975326538
recon_loss: 0.02822091430425644, dist_loss: 0.8491740822792053
recon_loss: 0.028220025822520256, dist_loss: 0.6246383190155029
recon_loss: 0.02822004072368145, dist_loss: 0.4826202094554901
recon_loss: 0.028219860047101974, dist_loss: 1.0243756771087646
recon_loss: 0.02821911871433258, dist_loss: 0.43128594756126404
recon_loss: 0.028219150379300117, dist_loss: 0.497562050819397
recon_loss: 0.02821890451014042, dist_loss: 0.5480936169624329
recon_loss: 0.02821890451014042, dist_loss: 1.618394374847412
recon_loss: 0.0282188318669796, dist_loss: 0.3278421461582184
recon_loss: 0.028218960389494896, dist_loss: 0.8189214468002319
recon_loss: 0.028218712657690048, dist_loss: 0.9996559023857117
recon_loss: 0.02821880578994751, dist_loss: 0.9777899980545044
recon_loss: 0.028219155967235565, dist_loss: 0.3910874128341675
recon_loss: 0.028219623491168022, dist_loss: 0.5202221274375916
recon_loss: 0.028219517320394516, dist_loss: 0.5483971834182739
recon_loss: 0.028219647705554962, dist_loss: 0.46852368116378784
recon_loss: 0.02821868471801281, dist_loss: 0.9209362268447876
recon_loss: 0.028218168765306473, dist_loss: 0.6004239320755005
recon_loss: 0.028217457234859467, dist_loss: 0.6626848578453064
recon_loss: 0.028217250481247902, dist_loss: 0.37679001688957214
recon_loss: 0.028217114508152008, dist_loss: 0.6208891868591309
recon_loss: 0.028217071667313576, dist_loss: 0.4971500337123871
recon_loss: 0.028217073529958725, dist_loss: 0.5414669513702393
recon_loss: 0.028216565027832985, dist_loss: 0.8223814368247986
recon_loss: 0.028216488659381866, dist_loss: 0.35768213868141174
recon_loss: 0.02821580320596695, dist_loss: 0.6456347703933716
recon_loss: 0.028215942904353142, dist_loss: 0.865144670009613
recon_loss: 0.028216127306222916, dist_loss: 0.5547921657562256
recon_loss: 0.02821570634841919, dist_loss: 0.43507444858551025
recon_loss: 0.028215555474162102, dist_loss: 0.6929359436035156
recon_loss: 0.028215164318680763, dist_loss: 0.6425937414169312
recon_loss: 0.02821521647274494, dist_loss: 0.8704159259796143
recon_loss: 0.028215190395712852, dist_loss: 0.48879384994506836
recon_loss: 0.028215277940034866, dist_loss: 0.7947913408279419
recon_loss: 0.0282149575650692, dist_loss: 1.150400161743164
recon_loss: 0.02821509726345539, dist_loss: 0.707416296005249
recon_loss: 0.028214719146490097, dist_loss: 0.5622846484184265
recon_loss: 0.02821514569222927, dist_loss: 1.0111942291259766
recon_loss: 0.02821486070752144, dist_loss: 0.7291713953018188
recon_loss: 0.02821526490151882, dist_loss: 0.5613232851028442
recon_loss: 0.028215164318680763, dist_loss: 0.8141512870788574
recon_loss: 0.02821504883468151, dist_loss: 0.6046498417854309
recon_loss: 0.028214892372488976, dist_loss: 0.39064785838127136
recon_loss: 0.028215082362294197, dist_loss: 0.5976701974868774
recon_loss: 0.02821500599384308, dist_loss: 0.41194912791252136
recon_loss: 0.028214793652296066, dist_loss: 0.6434483528137207
recon_loss: 0.028214775025844574, dist_loss: 0.37637025117874146
recon_loss: 0.02821476198732853, dist_loss: 1.1859290599822998
recon_loss: 0.028214680030941963, dist_loss: 0.8659454584121704
recon_loss: 0.028214680030941963, dist_loss: 0.5147601366043091
recon_loss: 0.028214644640684128, dist_loss: 0.8400837182998657
recon_loss: 0.028214775025844574, dist_loss: 0.634772002696991
recon_loss: 0.028214862570166588, dist_loss: 0.5315187573432922
recon_loss: 0.02821509726345539, dist_loss: 0.3398701250553131
recon_loss: 0.028215453028678894, dist_loss: 1.1807618141174316
recon_loss: 0.02821528911590576, dist_loss: 0.4864320755004883
recon_loss: 0.028215497732162476, dist_loss: 0.5521258115768433
recon_loss: 0.028216511011123657, dist_loss: 0.7280749082565308
recon_loss: 0.028215879574418068, dist_loss: 0.8114746809005737
recon_loss: 0.028216339647769928, dist_loss: 0.49907806515693665
recon_loss: 0.02821534126996994, dist_loss: 0.5186582803726196
recon_loss: 0.0282150786370039, dist_loss: 0.53533935546875
recon_loss: 0.02821478247642517, dist_loss: 0.6973508596420288
recon_loss: 0.02821386232972145, dist_loss: 0.7003278136253357
recon_loss: 0.02821437269449234, dist_loss: 1.030322790145874
recon_loss: 0.028214363381266594, dist_loss: 0.8982915878295898
recon_loss: 0.02821430005133152, dist_loss: 0.33316582441329956
recon_loss: 0.02821487747132778, dist_loss: 0.6193501949310303
recon_loss: 0.02821492962539196, dist_loss: 0.5527722835540771
recon_loss: 0.028215760365128517, dist_loss: 0.6068515777587891
recon_loss: 0.02821643464267254, dist_loss: 0.9034332036972046
recon_loss: 0.02821713499724865, dist_loss: 0.6866980791091919
recon_loss: 0.028217855840921402, dist_loss: 0.7820097804069519
Pre-training Epoch 74:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 74:   5%|▍         | 18/367 [00:00<00:02, 171.63it/s]Pre-training Epoch 74:  10%|▉         | 36/367 [00:00<00:01, 174.96it/s]Pre-training Epoch 74:  15%|█▍        | 54/367 [00:00<00:01, 175.45it/s]Pre-training Epoch 74:  20%|█▉        | 73/367 [00:00<00:01, 177.39it/s]Pre-training Epoch 74:  25%|██▍       | 91/367 [00:00<00:01, 177.99it/s]Pre-training Epoch 74:  30%|██▉       | 109/367 [00:00<00:01, 177.27it/s]Pre-training Epoch 74:  35%|███▍      | 127/367 [00:00<00:01, 176.22it/s]recon_loss: 0.028217477723956108, dist_loss: 0.5670691728591919
recon_loss: 0.028215890750288963, dist_loss: 0.4269743263721466
recon_loss: 0.028216013684868813, dist_loss: 0.716346263885498
recon_loss: 0.02821609191596508, dist_loss: 0.6887092590332031
recon_loss: 0.02821515128016472, dist_loss: 0.4414743185043335
recon_loss: 0.028216226026415825, dist_loss: 0.8455147743225098
recon_loss: 0.02821613848209381, dist_loss: 0.6223368644714355
recon_loss: 0.028217123821377754, dist_loss: 0.4463310241699219
recon_loss: 0.028218459337949753, dist_loss: 0.5690653920173645
recon_loss: 0.028217097744345665, dist_loss: 0.556126058101654
recon_loss: 0.028217943385243416, dist_loss: 1.0352716445922852
recon_loss: 0.02821686863899231, dist_loss: 0.7400123476982117
recon_loss: 0.028216779232025146, dist_loss: 0.8101229071617126
recon_loss: 0.02821783535182476, dist_loss: 1.015929937362671
recon_loss: 0.02821490727365017, dist_loss: 0.43350139260292053
recon_loss: 0.02821650728583336, dist_loss: 0.8894493579864502
recon_loss: 0.02821604534983635, dist_loss: 0.41062650084495544
recon_loss: 0.02821463905274868, dist_loss: 0.519041121006012
recon_loss: 0.028216715902090073, dist_loss: 0.4806995391845703
recon_loss: 0.028213242068886757, dist_loss: 0.6757948398590088
recon_loss: 0.028213798999786377, dist_loss: 0.7125505208969116
recon_loss: 0.028214234858751297, dist_loss: 0.5954672694206238
recon_loss: 0.028213826939463615, dist_loss: 0.7335004806518555
recon_loss: 0.028214870020747185, dist_loss: 0.822148323059082
recon_loss: 0.028214316815137863, dist_loss: 0.6547806262969971
recon_loss: 0.028214918449521065, dist_loss: 0.6206459999084473
recon_loss: 0.028215911239385605, dist_loss: 0.42903468012809753
recon_loss: 0.02821495570242405, dist_loss: 0.677189826965332
recon_loss: 0.028215957805514336, dist_loss: 0.5322506427764893
recon_loss: 0.02821524813771248, dist_loss: 0.4674946665763855
recon_loss: 0.02821599692106247, dist_loss: 0.3862178325653076
recon_loss: 0.028215616941452026, dist_loss: 0.5129300355911255
recon_loss: 0.028214316815137863, dist_loss: 0.3819202780723572
recon_loss: 0.02821475826203823, dist_loss: 0.4317331910133362
recon_loss: 0.02821316011250019, dist_loss: 0.8111738562583923
recon_loss: 0.028212793171405792, dist_loss: 0.4825453758239746
recon_loss: 0.028212517499923706, dist_loss: 0.9401129484176636
recon_loss: 0.02821151725947857, dist_loss: 0.6526721715927124
recon_loss: 0.0282122939825058, dist_loss: 0.6881327629089355
recon_loss: 0.028211789205670357, dist_loss: 0.3907433748245239
recon_loss: 0.0282113216817379, dist_loss: 0.44212937355041504
recon_loss: 0.028212133795022964, dist_loss: 0.46557867527008057
recon_loss: 0.02821061946451664, dist_loss: 0.2841346859931946
recon_loss: 0.028210680931806564, dist_loss: 0.7541660070419312
recon_loss: 0.028211144730448723, dist_loss: 0.6427319049835205
recon_loss: 0.028210390359163284, dist_loss: 1.442314863204956
recon_loss: 0.02821258269250393, dist_loss: 0.5325156450271606
recon_loss: 0.028210824355483055, dist_loss: 0.536660373210907
recon_loss: 0.028212768957018852, dist_loss: 0.6468760967254639
recon_loss: 0.028212320059537888, dist_loss: 0.9540860056877136
recon_loss: 0.02821212261915207, dist_loss: 0.4600154757499695
recon_loss: 0.028213148936629295, dist_loss: 0.7154029011726379
recon_loss: 0.028211388736963272, dist_loss: 0.8591886758804321
recon_loss: 0.02821172960102558, dist_loss: 0.635543167591095
recon_loss: 0.02821110561490059, dist_loss: 0.828460693359375
recon_loss: 0.028210395947098732, dist_loss: 0.6991098523139954
recon_loss: 0.028210477903485298, dist_loss: 0.8071509599685669
recon_loss: 0.02820943109691143, dist_loss: 0.40611112117767334
recon_loss: 0.028209060430526733, dist_loss: 0.2598878741264343
recon_loss: 0.028208626434206963, dist_loss: 0.7064929604530334
recon_loss: 0.02820822410285473, dist_loss: 0.8646574020385742
recon_loss: 0.02820793353021145, dist_loss: 0.6250189542770386
recon_loss: 0.028207678347826004, dist_loss: 0.501211404800415
recon_loss: 0.028207704424858093, dist_loss: 0.93567955493927
recon_loss: 0.028207574039697647, dist_loss: 0.9257031083106995
recon_loss: 0.028207484632730484, dist_loss: 0.6593649387359619
recon_loss: 0.028207432478666306, dist_loss: 1.2281568050384521
recon_loss: 0.028208456933498383, dist_loss: 0.4685356616973877
recon_loss: 0.028207525610923767, dist_loss: 0.5581912994384766
recon_loss: 0.028207853436470032, dist_loss: 0.5358803272247314
recon_loss: 0.028207726776599884, dist_loss: 0.906264066696167
recon_loss: 0.028207926079630852, dist_loss: 0.3790954649448395
recon_loss: 0.02820892073214054, dist_loss: 0.49340468645095825
recon_loss: 0.02820884808897972, dist_loss: 0.5747594833374023
recon_loss: 0.02820982225239277, dist_loss: 0.7932484745979309
recon_loss: 0.02820931002497673, dist_loss: 0.508094072341919
recon_loss: 0.02820822410285473, dist_loss: 0.82076495885849
recon_loss: 0.028208551928400993, dist_loss: 0.6705045104026794
recon_loss: 0.0282078105956316, dist_loss: 0.9327828884124756
recon_loss: 0.028208594769239426, dist_loss: 0.43153995275497437
recon_loss: 0.028207693248987198, dist_loss: 0.47088536620140076
recon_loss: 0.028206514194607735, dist_loss: 0.7745852470397949
recon_loss: 0.028206603601574898, dist_loss: 0.39765316247940063
recon_loss: 0.02820664644241333, dist_loss: 0.5948790311813354
recon_loss: 0.028207192197442055, dist_loss: 0.5331970453262329
recon_loss: 0.028207316994667053, dist_loss: 0.6883669495582581
recon_loss: 0.028207451105117798, dist_loss: 0.5575171709060669
recon_loss: 0.028207704424858093, dist_loss: 1.4495139122009277
recon_loss: 0.02820798009634018, dist_loss: 0.5666277408599854
recon_loss: 0.02820766530930996, dist_loss: 0.8470892906188965
recon_loss: 0.028206903487443924, dist_loss: 0.5179876089096069
recon_loss: 0.028207052499055862, dist_loss: 0.5987371802330017
recon_loss: 0.02820643037557602, dist_loss: 0.49371346831321716
recon_loss: 0.028206290677189827, dist_loss: 0.5697145462036133
recon_loss: 0.028205910697579384, dist_loss: 0.8988412618637085
recon_loss: 0.02820533514022827, dist_loss: 0.8726963996887207
recon_loss: 0.02820567600429058, dist_loss: 0.35286885499954224
recon_loss: 0.02820497192442417, dist_loss: 0.4958128035068512
recon_loss: 0.028205061331391335, dist_loss: 0.6859790086746216
recon_loss: 0.028204817324876785, dist_loss: 0.8373755812644958
recon_loss: 0.028204821050167084, dist_loss: 0.5467681288719177
recon_loss: 0.028204670175909996, dist_loss: 1.1216241121292114
recon_loss: 0.028204219415783882, dist_loss: 0.588356614112854
recon_loss: 0.028204699978232384, dist_loss: 0.7943507432937622
recon_loss: 0.028204020112752914, dist_loss: 0.494831919670105
recon_loss: 0.028204113245010376, dist_loss: 1.079035758972168
recon_loss: 0.02820420078933239, dist_loss: 0.6137150526046753
recon_loss: 0.028203120455145836, dist_loss: 0.5933349132537842
recon_loss: 0.02820330113172531, dist_loss: 0.554140031337738
recon_loss: 0.028203191235661507, dist_loss: 0.8679437637329102
recon_loss: 0.028203114867210388, dist_loss: 0.5115569233894348
recon_loss: 0.02820291370153427, dist_loss: 0.5869753360748291
recon_loss: 0.028202978894114494, dist_loss: 0.5511112809181213
recon_loss: 0.028203319758176804, dist_loss: 0.6960131525993347
recon_loss: 0.028203396126627922, dist_loss: 0.8466756343841553
recon_loss: 0.028203055262565613, dist_loss: 0.8382701873779297
recon_loss: 0.02820274420082569, dist_loss: 0.7222763299942017
recon_loss: 0.028202444314956665, dist_loss: 0.44422510266304016
recon_loss: 0.028202196583151817, dist_loss: 0.9589044451713562
recon_loss: 0.028202274814248085, dist_loss: 0.4574076533317566
recon_loss: 0.028202535584568977, dist_loss: 0.524735689163208
recon_loss: 0.028202565386891365, dist_loss: 0.5740492343902588
recon_loss: 0.028202885761857033, dist_loss: 0.582738995552063
recon_loss: 0.028203262016177177, dist_loss: 0.5099044442176819
recon_loss: 0.02820282056927681, dist_loss: 0.3393505811691284
recon_loss: 0.02820262685418129, dist_loss: 1.2402725219726562
recon_loss: 0.028202513232827187, dist_loss: 0.6685545444488525
recon_loss: 0.02820233814418316, dist_loss: 0.6735245585441589
Pre-training Epoch 74:  40%|███▉      | 145/367 [00:00<00:01, 175.57it/s]Pre-training Epoch 74:  44%|████▍     | 163/367 [00:00<00:01, 176.37it/s]Pre-training Epoch 74:  49%|████▉     | 181/367 [00:01<00:01, 174.57it/s]Pre-training Epoch 74:  54%|█████▍    | 199/367 [00:01<00:00, 175.93it/s]Pre-training Epoch 74:  59%|█████▉    | 217/367 [00:01<00:00, 176.71it/s]Pre-training Epoch 74:  64%|██████▍   | 236/367 [00:01<00:00, 177.73it/s]Pre-training Epoch 74:  69%|██████▉   | 254/367 [00:01<00:00, 177.72it/s]recon_loss: 0.028202366083860397, dist_loss: 0.5119071006774902
recon_loss: 0.028201637789607048, dist_loss: 0.9074365496635437
recon_loss: 0.02820209041237831, dist_loss: 0.6504554748535156
recon_loss: 0.028201518580317497, dist_loss: 0.7363258600234985
recon_loss: 0.028201574459671974, dist_loss: 0.6566723585128784
recon_loss: 0.028201602399349213, dist_loss: 0.6235960721969604
recon_loss: 0.02820172719657421, dist_loss: 0.7501528263092041
recon_loss: 0.02820274420082569, dist_loss: 0.4230932593345642
recon_loss: 0.028203854337334633, dist_loss: 0.47348880767822266
recon_loss: 0.028205547481775284, dist_loss: 1.0613166093826294
recon_loss: 0.02820822410285473, dist_loss: 1.2017121315002441
recon_loss: 0.028209511190652847, dist_loss: 1.0369731187820435
recon_loss: 0.028210358694195747, dist_loss: 0.5619577765464783
recon_loss: 0.028211314231157303, dist_loss: 0.7469472289085388
recon_loss: 0.028212130069732666, dist_loss: 0.4546493887901306
recon_loss: 0.02821200154721737, dist_loss: 0.6118277907371521
recon_loss: 0.028211070224642754, dist_loss: 1.237906813621521
recon_loss: 0.028209339827299118, dist_loss: 0.6071246862411499
recon_loss: 0.028207510709762573, dist_loss: 0.5215886831283569
recon_loss: 0.0282059945166111, dist_loss: 0.4717729091644287
recon_loss: 0.028204305097460747, dist_loss: 0.7864437103271484
recon_loss: 0.02820311114192009, dist_loss: 0.5693248510360718
recon_loss: 0.028202228248119354, dist_loss: 0.622871994972229
recon_loss: 0.02820165455341339, dist_loss: 0.6240676045417786
recon_loss: 0.028201378881931305, dist_loss: 0.6985878348350525
recon_loss: 0.02820153534412384, dist_loss: 0.5526328086853027
recon_loss: 0.028201965615153313, dist_loss: 0.48255014419555664
recon_loss: 0.028202319517731667, dist_loss: 0.6835523843765259
recon_loss: 0.028203153982758522, dist_loss: 0.6080698370933533
recon_loss: 0.028203319758176804, dist_loss: 0.7331297397613525
recon_loss: 0.028203602880239487, dist_loss: 0.5768805146217346
recon_loss: 0.028204888105392456, dist_loss: 1.1197569370269775
recon_loss: 0.028204722329974174, dist_loss: 1.0591847896575928
recon_loss: 0.028204871341586113, dist_loss: 0.4705391526222229
recon_loss: 0.02820434607565403, dist_loss: 0.5710995197296143
recon_loss: 0.028203502297401428, dist_loss: 0.895089864730835
recon_loss: 0.028203871101140976, dist_loss: 0.5076599717140198
recon_loss: 0.028202610090374947, dist_loss: 0.9674708843231201
recon_loss: 0.0282024834305048, dist_loss: 0.6620118021965027
recon_loss: 0.028201745823025703, dist_loss: 0.595872700214386
recon_loss: 0.02820083498954773, dist_loss: 0.7556226849555969
recon_loss: 0.028201822191476822, dist_loss: 0.44270938634872437
recon_loss: 0.028200190514326096, dist_loss: 0.6191886067390442
recon_loss: 0.028200453147292137, dist_loss: 0.8397661447525024
recon_loss: 0.028199708089232445, dist_loss: 1.1155798435211182
recon_loss: 0.028199579566717148, dist_loss: 0.6330313682556152
recon_loss: 0.028199609369039536, dist_loss: 1.0066076517105103
recon_loss: 0.028199223801493645, dist_loss: 0.28484559059143066
recon_loss: 0.028199173510074615, dist_loss: 0.7323578596115112
recon_loss: 0.02819906361401081, dist_loss: 0.2977237105369568
recon_loss: 0.028198957443237305, dist_loss: 0.6615647077560425
recon_loss: 0.028199059888720512, dist_loss: 0.8314028978347778
recon_loss: 0.02819894440472126, dist_loss: 0.5199213624000549
recon_loss: 0.028199048712849617, dist_loss: 0.5771816372871399
recon_loss: 0.02819906175136566, dist_loss: 0.5354578495025635
recon_loss: 0.028198841959238052, dist_loss: 0.8908424377441406
recon_loss: 0.0281988512724638, dist_loss: 1.2457773685455322
recon_loss: 0.028198858723044395, dist_loss: 0.870258629322052
recon_loss: 0.028199154883623123, dist_loss: 0.5165326595306396
recon_loss: 0.028198355808854103, dist_loss: 1.1701823472976685
recon_loss: 0.028198471292853355, dist_loss: 0.9342995882034302
recon_loss: 0.02819814532995224, dist_loss: 0.731094241142273
recon_loss: 0.028198527172207832, dist_loss: 0.6560326814651489
recon_loss: 0.028199946507811546, dist_loss: 0.8340815305709839
recon_loss: 0.02819906361401081, dist_loss: 0.6859134435653687
recon_loss: 0.028199709951877594, dist_loss: 0.8903160691261292
recon_loss: 0.028199808672070503, dist_loss: 0.47721031308174133
recon_loss: 0.028199074789881706, dist_loss: 0.7908830046653748
recon_loss: 0.028199052438139915, dist_loss: 0.5111654996871948
recon_loss: 0.02819853462278843, dist_loss: 0.529247522354126
recon_loss: 0.028198380023241043, dist_loss: 0.7384944558143616
recon_loss: 0.028197869658470154, dist_loss: 0.4968511462211609
recon_loss: 0.02819756418466568, dist_loss: 0.6957620978355408
recon_loss: 0.02819766104221344, dist_loss: 0.6177170276641846
recon_loss: 0.028197960928082466, dist_loss: 0.5757638216018677
recon_loss: 0.02819831296801567, dist_loss: 0.5398926734924316
recon_loss: 0.028198296204209328, dist_loss: 0.7010651230812073
recon_loss: 0.02819841355085373, dist_loss: 0.5411933660507202
recon_loss: 0.028198620304465294, dist_loss: 0.46644818782806396
recon_loss: 0.028198977932333946, dist_loss: 1.1551779508590698
recon_loss: 0.02819998934864998, dist_loss: 0.3951648473739624
recon_loss: 0.02820068970322609, dist_loss: 0.9161690473556519
recon_loss: 0.028200648725032806, dist_loss: 0.7929571866989136
recon_loss: 0.028199996799230576, dist_loss: 0.5845931768417358
recon_loss: 0.028199533000588417, dist_loss: 0.4009268283843994
recon_loss: 0.028198987245559692, dist_loss: 0.654205322265625
recon_loss: 0.028198936954140663, dist_loss: 0.9025743007659912
recon_loss: 0.028198082000017166, dist_loss: 0.6176817417144775
recon_loss: 0.02819802053272724, dist_loss: 0.6405373811721802
recon_loss: 0.028198061510920525, dist_loss: 0.44947731494903564
recon_loss: 0.028198525309562683, dist_loss: 0.5057046413421631
recon_loss: 0.028198985382914543, dist_loss: 0.7593355774879456
recon_loss: 0.02819911576807499, dist_loss: 0.8934543132781982
recon_loss: 0.028198890388011932, dist_loss: 0.4622970223426819
recon_loss: 0.02819821611046791, dist_loss: 0.44870525598526
recon_loss: 0.028197459876537323, dist_loss: 0.6480658054351807
recon_loss: 0.028196994215250015, dist_loss: 0.755722165107727
recon_loss: 0.02819671295583248, dist_loss: 0.47921866178512573
recon_loss: 0.02819729782640934, dist_loss: 0.7085638046264648
recon_loss: 0.02819700911641121, dist_loss: 0.5672876238822937
recon_loss: 0.028196988627314568, dist_loss: 0.8436654806137085
recon_loss: 0.028197146952152252, dist_loss: 0.2631741762161255
recon_loss: 0.028196431696414948, dist_loss: 0.7684910297393799
recon_loss: 0.028196612372994423, dist_loss: 0.5467104911804199
recon_loss: 0.028197012841701508, dist_loss: 0.7765543460845947
recon_loss: 0.028196996077895164, dist_loss: 0.5836907625198364
recon_loss: 0.02819746360182762, dist_loss: 0.4063916504383087
recon_loss: 0.028197316452860832, dist_loss: 0.8284206390380859
recon_loss: 0.028196947649121284, dist_loss: 0.4418770670890808
recon_loss: 0.028196778148412704, dist_loss: 1.100134015083313
recon_loss: 0.028195686638355255, dist_loss: 0.46443456411361694
recon_loss: 0.028194932267069817, dist_loss: 0.5657800436019897
recon_loss: 0.028194336220622063, dist_loss: 0.8539106249809265
recon_loss: 0.028194116428494453, dist_loss: 0.49488747119903564
recon_loss: 0.028194166719913483, dist_loss: 0.5008814334869385
recon_loss: 0.028194768354296684, dist_loss: 0.43096113204956055
recon_loss: 0.02819567359983921, dist_loss: 0.5936143398284912
recon_loss: 0.02819717489182949, dist_loss: 0.6732579469680786
recon_loss: 0.028198760002851486, dist_loss: 0.47450125217437744
recon_loss: 0.028200412169098854, dist_loss: 0.6269810199737549
recon_loss: 0.028202438727021217, dist_loss: 0.8358434438705444
recon_loss: 0.02820359356701374, dist_loss: 0.25858354568481445
recon_loss: 0.028204698115587234, dist_loss: 0.6268798112869263
recon_loss: 0.028205368667840958, dist_loss: 0.8635700345039368
recon_loss: 0.028205174952745438, dist_loss: 0.882736325263977
recon_loss: 0.028203720226883888, dist_loss: 0.5535115003585815
recon_loss: 0.028202425688505173, dist_loss: 1.1279230117797852
recon_loss: 0.028200870379805565, dist_loss: 0.6977883577346802
Pre-training Epoch 74:  74%|███████▍  | 273/367 [00:01<00:00, 178.34it/s]Pre-training Epoch 74:  79%|███████▉  | 291/367 [00:01<00:00, 178.75it/s]Pre-training Epoch 74:  84%|████████▍ | 309/367 [00:01<00:00, 177.50it/s]Pre-training Epoch 74:  89%|████████▉ | 327/367 [00:01<00:00, 177.28it/s]Pre-training Epoch 74:  94%|█████████▍| 346/367 [00:01<00:00, 178.60it/s]Pre-training Epoch 74:  99%|█████████▉| 364/367 [00:02<00:00, 177.73it/s]Pre-training Epoch 74: 100%|██████████| 367/367 [00:02<00:00, 177.10it/s]
recon_loss: 0.028199147433042526, dist_loss: 1.0801514387130737
recon_loss: 0.028197618201375008, dist_loss: 0.48846644163131714
recon_loss: 0.02819632552564144, dist_loss: 0.9693068265914917
recon_loss: 0.02819555066525936, dist_loss: 0.5998239517211914
recon_loss: 0.028194893151521683, dist_loss: 0.868627667427063
recon_loss: 0.02819470502436161, dist_loss: 0.554275393486023
recon_loss: 0.02819477953016758, dist_loss: 0.611737847328186
recon_loss: 0.02819439023733139, dist_loss: 0.7357932329177856
recon_loss: 0.02819466032087803, dist_loss: 0.5431959629058838
recon_loss: 0.028194904327392578, dist_loss: 0.9443870782852173
recon_loss: 0.02819550223648548, dist_loss: 0.590194582939148
recon_loss: 0.028196416795253754, dist_loss: 0.46579408645629883
recon_loss: 0.028196699917316437, dist_loss: 0.4853860139846802
recon_loss: 0.028197595849633217, dist_loss: 0.5994895100593567
recon_loss: 0.028197087347507477, dist_loss: 1.4525834321975708
recon_loss: 0.028197387233376503, dist_loss: 0.6856098771095276
recon_loss: 0.028197472915053368, dist_loss: 0.49327921867370605
recon_loss: 0.02819715067744255, dist_loss: 0.6695221662521362
recon_loss: 0.02819717302918434, dist_loss: 0.4968528747558594
recon_loss: 0.02819705940783024, dist_loss: 0.7903476357460022
recon_loss: 0.02819680981338024, dist_loss: 0.33303719758987427
recon_loss: 0.028196198865771294, dist_loss: 0.7026107907295227
recon_loss: 0.028195327147841454, dist_loss: 0.7909482717514038
recon_loss: 0.02819444052875042, dist_loss: 0.5865156054496765
recon_loss: 0.02819397859275341, dist_loss: 0.5708832740783691
recon_loss: 0.028193887323141098, dist_loss: 0.7843581438064575
recon_loss: 0.028193147853016853, dist_loss: 0.5353345274925232
recon_loss: 0.028193023055791855, dist_loss: 0.5545244216918945
recon_loss: 0.028192849829792976, dist_loss: 0.5364251136779785
recon_loss: 0.028191732242703438, dist_loss: 0.3733736276626587
recon_loss: 0.028191188350319862, dist_loss: 0.7631096243858337
recon_loss: 0.028191180899739265, dist_loss: 0.859014630317688
recon_loss: 0.0281907357275486, dist_loss: 0.445180207490921
recon_loss: 0.02819068171083927, dist_loss: 1.045372486114502
recon_loss: 0.02819077856838703, dist_loss: 0.7421972751617432
recon_loss: 0.028190219774842262, dist_loss: 0.6198605298995972
recon_loss: 0.028190359473228455, dist_loss: 0.8725292682647705
recon_loss: 0.028190063312649727, dist_loss: 0.2857445478439331
recon_loss: 0.028189459815621376, dist_loss: 0.6650034189224243
recon_loss: 0.028189966455101967, dist_loss: 0.5857956409454346
recon_loss: 0.02819005772471428, dist_loss: 0.4203137457370758
recon_loss: 0.028189290314912796, dist_loss: 0.735164999961853
recon_loss: 0.028190109878778458, dist_loss: 0.5749154686927795
recon_loss: 0.02818976528942585, dist_loss: 0.5963441133499146
recon_loss: 0.02819013223052025, dist_loss: 0.8249542713165283
recon_loss: 0.028191402554512024, dist_loss: 1.0893933773040771
recon_loss: 0.028191212564706802, dist_loss: 0.5563976764678955
recon_loss: 0.02819211781024933, dist_loss: 0.7627855539321899
recon_loss: 0.028191760182380676, dist_loss: 0.4790646731853485
recon_loss: 0.0281917043030262, dist_loss: 0.5142114758491516
recon_loss: 0.02819162979722023, dist_loss: 0.8988786935806274
recon_loss: 0.02819153107702732, dist_loss: 0.8412811160087585
recon_loss: 0.028192544355988503, dist_loss: 0.7790573835372925
recon_loss: 0.028193959966301918, dist_loss: 0.5467122793197632
recon_loss: 0.028195425868034363, dist_loss: 0.9527626633644104
recon_loss: 0.028195185586810112, dist_loss: 0.3505220413208008
recon_loss: 0.02819567173719406, dist_loss: 0.46609342098236084
recon_loss: 0.028196614235639572, dist_loss: 0.6114631295204163
recon_loss: 0.02819681540131569, dist_loss: 0.6452281475067139
recon_loss: 0.028196338564157486, dist_loss: 0.9602822065353394
recon_loss: 0.02819526195526123, dist_loss: 0.581743597984314
recon_loss: 0.02819357067346573, dist_loss: 0.7972182631492615
recon_loss: 0.028192052617669106, dist_loss: 0.843407392501831
recon_loss: 0.028190841898322105, dist_loss: 0.6521682739257812
recon_loss: 0.028189372271299362, dist_loss: 0.6321403980255127
recon_loss: 0.02818887121975422, dist_loss: 0.5834155082702637
recon_loss: 0.028188789263367653, dist_loss: 0.5913469791412354
recon_loss: 0.028189998120069504, dist_loss: 0.23185357451438904
recon_loss: 0.028191830962896347, dist_loss: 0.803886890411377
recon_loss: 0.02819201722741127, dist_loss: 0.3746216893196106
recon_loss: 0.02819252759218216, dist_loss: 0.817344605922699
recon_loss: 0.028190815821290016, dist_loss: 0.5228428244590759
recon_loss: 0.028191005811095238, dist_loss: 0.4368688762187958
recon_loss: 0.028190404176712036, dist_loss: 0.8182644844055176
recon_loss: 0.02819041535258293, dist_loss: 1.0139245986938477
recon_loss: 0.028190085664391518, dist_loss: 0.8982328176498413
recon_loss: 0.028188595548272133, dist_loss: 0.5342656970024109
recon_loss: 0.028188403695821762, dist_loss: 0.5519216656684875
recon_loss: 0.02818804793059826, dist_loss: 0.3788817524909973
recon_loss: 0.028187472373247147, dist_loss: 0.4056396484375
recon_loss: 0.028187213465571404, dist_loss: 0.49084460735321045
recon_loss: 0.028187014162540436, dist_loss: 1.1276253461837769
recon_loss: 0.028186632320284843, dist_loss: 0.3890024721622467
recon_loss: 0.02818651683628559, dist_loss: 0.6821366548538208
recon_loss: 0.028185948729515076, dist_loss: 0.4927818477153778
recon_loss: 0.028186077252030373, dist_loss: 0.6029258370399475
recon_loss: 0.02818567119538784, dist_loss: 0.5783335566520691
recon_loss: 0.028185930103063583, dist_loss: 0.4730537533760071
recon_loss: 0.028185823932290077, dist_loss: 0.646529495716095
recon_loss: 0.0281857680529356, dist_loss: 0.6558202505111694
recon_loss: 0.028186362236738205, dist_loss: 0.959136426448822
recon_loss: 0.02818622998893261, dist_loss: 0.8888083696365356
recon_loss: 0.02818630076944828, dist_loss: 0.6106197237968445
recon_loss: 0.028186459094285965, dist_loss: 0.7374314069747925
recon_loss: 0.02818612940609455, dist_loss: 0.5618892908096313
recon_loss: 0.028186123818159103, dist_loss: 1.098069667816162
recon_loss: 0.028186557814478874, dist_loss: 0.4093402624130249
recon_loss: 0.028185365721583366, dist_loss: 0.7602565288543701
recon_loss: 0.02818530984222889, dist_loss: 0.6206523180007935
recon_loss: 0.02818496711552143, dist_loss: 0.42981910705566406
recon_loss: 0.02818467654287815, dist_loss: 0.586024820804596
recon_loss: 0.028184710070490837, dist_loss: 0.8751381635665894
recon_loss: 0.02818436548113823, dist_loss: 0.4116397798061371
recon_loss: 0.02818477153778076, dist_loss: 0.8628464937210083
recon_loss: 0.02818453684449196, dist_loss: 0.8111822605133057
recon_loss: 0.02818477340042591, dist_loss: 0.5567560195922852
recon_loss: 0.028184564784169197, dist_loss: 0.9144028425216675
recon_loss: 0.028184179216623306, dist_loss: 0.5526821613311768
recon_loss: 0.028184659779071808, dist_loss: 0.305634468793869
recon_loss: 0.028184307739138603, dist_loss: 0.3416244685649872
recon_loss: 0.028185343369841576, dist_loss: 0.622321605682373
Pre-training Epoch 75:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 75:   5%|▌         | 19/367 [00:00<00:01, 186.40it/s]Pre-training Epoch 75:  11%|█         | 39/367 [00:00<00:01, 191.22it/s]Pre-training Epoch 75:  16%|█▌        | 59/367 [00:00<00:01, 192.39it/s]Pre-training Epoch 75:  22%|██▏       | 79/367 [00:00<00:01, 187.81it/s]Pre-training Epoch 75:  27%|██▋       | 98/367 [00:00<00:01, 183.95it/s]Pre-training Epoch 75:  32%|███▏      | 118/367 [00:00<00:01, 187.02it/s]recon_loss: 0.02818598970770836, dist_loss: 0.43364205956459045
recon_loss: 0.028187165036797523, dist_loss: 0.43014025688171387
recon_loss: 0.028186392039060593, dist_loss: 0.9754160642623901
recon_loss: 0.028185810893774033, dist_loss: 0.6363300085067749
recon_loss: 0.028185855597257614, dist_loss: 0.709540605545044
recon_loss: 0.02818586677312851, dist_loss: 0.6280320882797241
recon_loss: 0.02818579226732254, dist_loss: 0.6317582130432129
recon_loss: 0.028185656294226646, dist_loss: 0.3667462468147278
recon_loss: 0.02818480134010315, dist_loss: 1.0838245153427124
recon_loss: 0.028184829279780388, dist_loss: 0.5085675716400146
recon_loss: 0.02818428911268711, dist_loss: 0.7906460762023926
recon_loss: 0.028185008093714714, dist_loss: 0.8294601440429688
recon_loss: 0.028186189010739326, dist_loss: 0.43116065859794617
recon_loss: 0.028186846524477005, dist_loss: 0.8128131628036499
recon_loss: 0.02818775177001953, dist_loss: 0.8896244764328003
recon_loss: 0.02818765863776207, dist_loss: 0.7540881633758545
recon_loss: 0.028188111260533333, dist_loss: 0.6256755590438843
recon_loss: 0.02818746492266655, dist_loss: 0.8930447101593018
recon_loss: 0.028186477720737457, dist_loss: 0.4530988931655884
recon_loss: 0.02818606048822403, dist_loss: 0.8993091583251953
recon_loss: 0.02818481996655464, dist_loss: 0.559240996837616
recon_loss: 0.028184253722429276, dist_loss: 0.7191271781921387
recon_loss: 0.02818327210843563, dist_loss: 0.9289868474006653
recon_loss: 0.028182730078697205, dist_loss: 0.43640539050102234
recon_loss: 0.028182296082377434, dist_loss: 0.9432599544525146
recon_loss: 0.028181523084640503, dist_loss: 0.5799282789230347
recon_loss: 0.028181249275803566, dist_loss: 0.555956244468689
recon_loss: 0.028181031346321106, dist_loss: 0.9289191961288452
recon_loss: 0.028181103989481926, dist_loss: 0.395854651927948
recon_loss: 0.02818113937973976, dist_loss: 0.40202009677886963
recon_loss: 0.02818196639418602, dist_loss: 0.5943412780761719
recon_loss: 0.028183823451399803, dist_loss: 0.6142479181289673
recon_loss: 0.02818543277680874, dist_loss: 0.7984951138496399
recon_loss: 0.02818744070827961, dist_loss: 0.6359935998916626
recon_loss: 0.02818954363465309, dist_loss: 0.6536681652069092
recon_loss: 0.028191639110445976, dist_loss: 0.6150914430618286
recon_loss: 0.02819276601076126, dist_loss: 0.590803861618042
recon_loss: 0.028192374855279922, dist_loss: 0.7395334243774414
recon_loss: 0.028190866112709045, dist_loss: 0.4721905589103699
recon_loss: 0.028189459815621376, dist_loss: 0.8407076001167297
recon_loss: 0.028187405318021774, dist_loss: 1.1592042446136475
recon_loss: 0.028185592964291573, dist_loss: 0.5833344459533691
recon_loss: 0.028184426948428154, dist_loss: 1.0057458877563477
recon_loss: 0.028183234855532646, dist_loss: 0.9595652222633362
recon_loss: 0.02818295732140541, dist_loss: 1.0371544361114502
recon_loss: 0.028184177353978157, dist_loss: 0.5420992374420166
recon_loss: 0.02818615362048149, dist_loss: 0.372671902179718
recon_loss: 0.02818809449672699, dist_loss: 0.6769213080406189
recon_loss: 0.02818998508155346, dist_loss: 0.5397429466247559
recon_loss: 0.02819061279296875, dist_loss: 0.47015154361724854
recon_loss: 0.02819097973406315, dist_loss: 0.9444370269775391
recon_loss: 0.028190918266773224, dist_loss: 0.6289318203926086
recon_loss: 0.028189755976200104, dist_loss: 0.3227085769176483
recon_loss: 0.028188083320856094, dist_loss: 0.4548989236354828
recon_loss: 0.028186585754156113, dist_loss: 0.5895976424217224
recon_loss: 0.028185589239001274, dist_loss: 0.6314471960067749
recon_loss: 0.02818499691784382, dist_loss: 0.5913410782814026
recon_loss: 0.02818445861339569, dist_loss: 0.7208117842674255
recon_loss: 0.028183916583657265, dist_loss: 0.44834405183792114
recon_loss: 0.028182614594697952, dist_loss: 0.5458133220672607
recon_loss: 0.0281822606921196, dist_loss: 0.9759877324104309
recon_loss: 0.028181584551930428, dist_loss: 0.6176369786262512
recon_loss: 0.028180649504065514, dist_loss: 0.5849129557609558
recon_loss: 0.0281808003783226, dist_loss: 0.7645816802978516
recon_loss: 0.028180649504065514, dist_loss: 0.5674118995666504
recon_loss: 0.02818041481077671, dist_loss: 0.481040358543396
recon_loss: 0.028180409222841263, dist_loss: 0.47027885913848877
recon_loss: 0.02817966416478157, dist_loss: 0.9224691987037659
recon_loss: 0.028179625049233437, dist_loss: 0.37339431047439575
recon_loss: 0.02817910723388195, dist_loss: 0.696044921875
recon_loss: 0.02817835472524166, dist_loss: 0.4520809054374695
recon_loss: 0.028178220614790916, dist_loss: 0.9765024781227112
recon_loss: 0.02817787230014801, dist_loss: 0.7009934186935425
recon_loss: 0.028177231550216675, dist_loss: 0.8484389185905457
recon_loss: 0.028177019208669662, dist_loss: 0.44582507014274597
recon_loss: 0.02817690186202526, dist_loss: 0.7223523855209351
recon_loss: 0.028176523745059967, dist_loss: 0.9395449161529541
recon_loss: 0.028176696971058846, dist_loss: 0.6844671964645386
recon_loss: 0.028176266700029373, dist_loss: 0.4701880216598511
recon_loss: 0.028176287189126015, dist_loss: 0.5619291067123413
recon_loss: 0.028176255524158478, dist_loss: 0.5997508764266968
recon_loss: 0.0281757190823555, dist_loss: 0.3777753710746765
recon_loss: 0.02817572094500065, dist_loss: 0.5541929006576538
recon_loss: 0.02817569486796856, dist_loss: 0.4524880051612854
recon_loss: 0.02817537635564804, dist_loss: 0.5457385182380676
recon_loss: 0.02817574329674244, dist_loss: 0.7570450305938721
recon_loss: 0.028176037594676018, dist_loss: 0.8093107342720032
recon_loss: 0.02817557193338871, dist_loss: 0.5216702222824097
recon_loss: 0.02817600779235363, dist_loss: 0.5390591621398926
recon_loss: 0.02817632630467415, dist_loss: 0.4922337830066681
recon_loss: 0.028175439685583115, dist_loss: 1.0751832723617554
recon_loss: 0.028177078813314438, dist_loss: 0.7711095809936523
recon_loss: 0.02817639149725437, dist_loss: 0.5197592973709106
recon_loss: 0.028176212683320045, dist_loss: 0.8273824453353882
recon_loss: 0.028177376836538315, dist_loss: 0.677587628364563
recon_loss: 0.02817590720951557, dist_loss: 0.7048146724700928
recon_loss: 0.028176341205835342, dist_loss: 0.7171792984008789
recon_loss: 0.028176208958029747, dist_loss: 0.5924387574195862
recon_loss: 0.028175638988614082, dist_loss: 0.3925546407699585
recon_loss: 0.02817663736641407, dist_loss: 0.4820466935634613
recon_loss: 0.02817475236952305, dist_loss: 0.45986512303352356
recon_loss: 0.028175581246614456, dist_loss: 0.34086793661117554
recon_loss: 0.02817486971616745, dist_loss: 0.929397702217102
recon_loss: 0.02817504107952118, dist_loss: 0.7407095432281494
recon_loss: 0.028176257386803627, dist_loss: 1.0285147428512573
recon_loss: 0.028174055740237236, dist_loss: 0.7508816719055176
recon_loss: 0.028175268322229385, dist_loss: 1.5842431783676147
recon_loss: 0.02817620523273945, dist_loss: 0.7714170217514038
recon_loss: 0.028174912557005882, dist_loss: 0.7839405536651611
recon_loss: 0.028176452964544296, dist_loss: 0.658349871635437
recon_loss: 0.028175408020615578, dist_loss: 0.9171427488327026
recon_loss: 0.028175408020615578, dist_loss: 0.7773744463920593
recon_loss: 0.02817644365131855, dist_loss: 0.9168921709060669
recon_loss: 0.02817467413842678, dist_loss: 1.0720553398132324
recon_loss: 0.02817530930042267, dist_loss: 0.7545709609985352
recon_loss: 0.028174586594104767, dist_loss: 0.4557627737522125
recon_loss: 0.028174515813589096, dist_loss: 0.5148791670799255
recon_loss: 0.028175555169582367, dist_loss: 0.8136515617370605
recon_loss: 0.02817418798804283, dist_loss: 0.8071853518486023
recon_loss: 0.02817518636584282, dist_loss: 0.7495983242988586
recon_loss: 0.028173919767141342, dist_loss: 0.549027681350708
recon_loss: 0.02817291021347046, dist_loss: 0.6298154592514038
recon_loss: 0.028173768892884254, dist_loss: 0.5820080041885376
recon_loss: 0.02817259542644024, dist_loss: 0.6797547936439514
recon_loss: 0.02817295677959919, dist_loss: 0.9595880508422852
recon_loss: 0.028173111379146576, dist_loss: 0.7614617347717285
recon_loss: 0.02817271277308464, dist_loss: 0.3696031868457794
recon_loss: 0.028173884376883507, dist_loss: 0.46326392889022827
Pre-training Epoch 75:  37%|███▋      | 137/367 [00:00<00:01, 183.94it/s]Pre-training Epoch 75:  43%|████▎     | 156/367 [00:00<00:01, 182.70it/s]Pre-training Epoch 75:  48%|████▊     | 175/367 [00:00<00:01, 183.01it/s]Pre-training Epoch 75:  53%|█████▎    | 195/367 [00:01<00:00, 186.50it/s]Pre-training Epoch 75:  59%|█████▊    | 215/367 [00:01<00:00, 188.85it/s]Pre-training Epoch 75:  64%|██████▍   | 235/367 [00:01<00:00, 190.32it/s]Pre-training Epoch 75:  69%|██████▉   | 255/367 [00:01<00:00, 191.50it/s]recon_loss: 0.028171898797154427, dist_loss: 0.5195745229721069
recon_loss: 0.028172636404633522, dist_loss: 0.9881858229637146
recon_loss: 0.028172900900244713, dist_loss: 0.3719332218170166
recon_loss: 0.02817150391638279, dist_loss: 0.3945480287075043
recon_loss: 0.028173690661787987, dist_loss: 0.9995919466018677
recon_loss: 0.028171515092253685, dist_loss: 0.4704069197177887
recon_loss: 0.02817244827747345, dist_loss: 0.6588290929794312
recon_loss: 0.028172096237540245, dist_loss: 0.6095641851425171
recon_loss: 0.02817154861986637, dist_loss: 0.6220678091049194
recon_loss: 0.028173130005598068, dist_loss: 0.5735468864440918
recon_loss: 0.028172168880701065, dist_loss: 0.7871150374412537
recon_loss: 0.02817206270992756, dist_loss: 0.5274237990379333
recon_loss: 0.028173021972179413, dist_loss: 0.8491243124008179
recon_loss: 0.028172647580504417, dist_loss: 0.7441158890724182
recon_loss: 0.028174137696623802, dist_loss: 0.6358665227890015
recon_loss: 0.02817474491894245, dist_loss: 0.3371827006340027
recon_loss: 0.028174543753266335, dist_loss: 0.5278476476669312
recon_loss: 0.02817474491894245, dist_loss: 0.5889648199081421
recon_loss: 0.028173895552754402, dist_loss: 1.2513338327407837
recon_loss: 0.028174253180623055, dist_loss: 0.7257030010223389
recon_loss: 0.0281741414219141, dist_loss: 0.8769785761833191
recon_loss: 0.028173334896564484, dist_loss: 0.6189043521881104
recon_loss: 0.028173748403787613, dist_loss: 0.840883731842041
recon_loss: 0.028172222897410393, dist_loss: 0.396289587020874
recon_loss: 0.02817203477025032, dist_loss: 0.3682917654514313
recon_loss: 0.02817145548760891, dist_loss: 0.44675391912460327
recon_loss: 0.028170714154839516, dist_loss: 0.6983978152275085
recon_loss: 0.028171004727482796, dist_loss: 1.0445396900177002
recon_loss: 0.028170490637421608, dist_loss: 0.4217575192451477
recon_loss: 0.028170481324195862, dist_loss: 0.5857111811637878
recon_loss: 0.028170494362711906, dist_loss: 0.6340473294258118
recon_loss: 0.028170684352517128, dist_loss: 0.8618847131729126
recon_loss: 0.02817111648619175, dist_loss: 0.8351227045059204
recon_loss: 0.028170477598905563, dist_loss: 1.0173850059509277
recon_loss: 0.02817079983651638, dist_loss: 0.7526682615280151
recon_loss: 0.028170175850391388, dist_loss: 0.6001614332199097
recon_loss: 0.02817014418542385, dist_loss: 0.4125318229198456
recon_loss: 0.028170110657811165, dist_loss: 1.0879631042480469
recon_loss: 0.028169456869363785, dist_loss: 0.6368761658668518
recon_loss: 0.028168998658657074, dist_loss: 0.5494490265846252
recon_loss: 0.02816859446465969, dist_loss: 1.110966444015503
recon_loss: 0.02816862054169178, dist_loss: 0.39971208572387695
recon_loss: 0.0281684510409832, dist_loss: 0.4576146602630615
recon_loss: 0.02816842868924141, dist_loss: 0.4866894483566284
recon_loss: 0.028168121352791786, dist_loss: 1.0096060037612915
recon_loss: 0.028168004006147385, dist_loss: 0.5075142979621887
recon_loss: 0.028167814016342163, dist_loss: 0.5367447137832642
recon_loss: 0.02816758304834366, dist_loss: 1.047461748123169
recon_loss: 0.02816765382885933, dist_loss: 0.3804783523082733
recon_loss: 0.0281678456813097, dist_loss: 0.6443451642990112
recon_loss: 0.028168560937047005, dist_loss: 0.39262083172798157
recon_loss: 0.02816878631711006, dist_loss: 0.5536137223243713
recon_loss: 0.028168443590402603, dist_loss: 0.9190126657485962
recon_loss: 0.028168221935629845, dist_loss: 0.7302693128585815
recon_loss: 0.028168126940727234, dist_loss: 0.8595173358917236
recon_loss: 0.028168262913823128, dist_loss: 0.6611125469207764
recon_loss: 0.028168080374598503, dist_loss: 0.9474276304244995
recon_loss: 0.02816767618060112, dist_loss: 0.9091231226921082
recon_loss: 0.028167912736535072, dist_loss: 0.5032944083213806
recon_loss: 0.02816789411008358, dist_loss: 0.9666973948478699
recon_loss: 0.028168383985757828, dist_loss: 0.3930537700653076
recon_loss: 0.02816852554678917, dist_loss: 0.312115877866745
recon_loss: 0.028168048709630966, dist_loss: 0.3772543668746948
recon_loss: 0.028167732059955597, dist_loss: 0.43454936146736145
recon_loss: 0.028167877346277237, dist_loss: 0.399804949760437
recon_loss: 0.028168002143502235, dist_loss: 1.150860071182251
recon_loss: 0.028168007731437683, dist_loss: 0.48604249954223633
recon_loss: 0.028167642652988434, dist_loss: 0.6547555327415466
recon_loss: 0.028167063370347023, dist_loss: 0.6538609266281128
recon_loss: 0.028166886419057846, dist_loss: 1.216618537902832
recon_loss: 0.028166471049189568, dist_loss: 0.9071602821350098
recon_loss: 0.028166143223643303, dist_loss: 0.6231763362884521
recon_loss: 0.028165927156805992, dist_loss: 0.667479395866394
recon_loss: 0.028165854513645172, dist_loss: 0.6665529608726501
recon_loss: 0.028165897354483604, dist_loss: 0.7604468464851379
recon_loss: 0.028165539726614952, dist_loss: 0.5685648918151855
recon_loss: 0.02816523239016533, dist_loss: 0.73725825548172
recon_loss: 0.028165070340037346, dist_loss: 0.6952450275421143
recon_loss: 0.028164921328425407, dist_loss: 0.6252594590187073
recon_loss: 0.028164822608232498, dist_loss: 0.5913877487182617
recon_loss: 0.028164690360426903, dist_loss: 0.8252335786819458
recon_loss: 0.028164654970169067, dist_loss: 0.5250850319862366
recon_loss: 0.028164975345134735, dist_loss: 0.8979760408401489
recon_loss: 0.028164925053715706, dist_loss: 0.4326133728027344
recon_loss: 0.02816532365977764, dist_loss: 0.8299643993377686
recon_loss: 0.028165724128484726, dist_loss: 0.4051440954208374
recon_loss: 0.028166513890028, dist_loss: 0.5760499835014343
recon_loss: 0.028167085722088814, dist_loss: 0.724341630935669
recon_loss: 0.028168223798274994, dist_loss: 0.5083107948303223
recon_loss: 0.028168892487883568, dist_loss: 0.6037057638168335
recon_loss: 0.028168655931949615, dist_loss: 1.0955322980880737
recon_loss: 0.028168324381113052, dist_loss: 0.6901610493659973
recon_loss: 0.028168020769953728, dist_loss: 0.8840697407722473
recon_loss: 0.028167396783828735, dist_loss: 1.0594955682754517
recon_loss: 0.028166865929961205, dist_loss: 0.5219498872756958
recon_loss: 0.028166064992547035, dist_loss: 0.32737547159194946
recon_loss: 0.02816561423242092, dist_loss: 0.548741340637207
recon_loss: 0.028165176510810852, dist_loss: 0.48258188366889954
recon_loss: 0.028165576979517937, dist_loss: 0.6087130904197693
recon_loss: 0.02816513553261757, dist_loss: 1.5386121273040771
recon_loss: 0.028165370225906372, dist_loss: 1.1229267120361328
recon_loss: 0.028165718540549278, dist_loss: 0.8201553821563721
recon_loss: 0.028164716437458992, dist_loss: 0.38247397541999817
recon_loss: 0.028164617717266083, dist_loss: 1.0846552848815918
recon_loss: 0.0281649362295866, dist_loss: 0.4530084431171417
recon_loss: 0.028163831681013107, dist_loss: 0.38940611481666565
recon_loss: 0.028163885697722435, dist_loss: 0.8770914673805237
recon_loss: 0.028163539245724678, dist_loss: 0.5538314580917358
recon_loss: 0.02816326543688774, dist_loss: 0.48535338044166565
recon_loss: 0.028163760900497437, dist_loss: 0.9619227051734924
recon_loss: 0.028162995353341103, dist_loss: 0.3227168321609497
recon_loss: 0.02816341444849968, dist_loss: 0.5431835651397705
recon_loss: 0.028163280338048935, dist_loss: 1.0077346563339233
recon_loss: 0.028162414208054543, dist_loss: 0.5523234605789185
recon_loss: 0.028162676841020584, dist_loss: 0.4520365595817566
recon_loss: 0.02816256880760193, dist_loss: 1.1064947843551636
recon_loss: 0.02816198393702507, dist_loss: 0.44498971104621887
recon_loss: 0.028162050992250443, dist_loss: 0.9276667833328247
recon_loss: 0.02816206030547619, dist_loss: 0.6885002851486206
recon_loss: 0.028161916881799698, dist_loss: 0.8410961627960205
recon_loss: 0.02816202864050865, dist_loss: 0.5893667936325073
recon_loss: 0.02816130965948105, dist_loss: 0.7033440470695496
recon_loss: 0.028161318972706795, dist_loss: 0.5125946402549744
recon_loss: 0.028161345049738884, dist_loss: 0.5904972553253174
recon_loss: 0.028161287307739258, dist_loss: 0.361559122800827
recon_loss: 0.02816196158528328, dist_loss: 0.4121517837047577
recon_loss: 0.028161711990833282, dist_loss: 0.44037482142448425
recon_loss: 0.0281609408557415, dist_loss: 1.1937251091003418
Pre-training Epoch 75:  75%|███████▍  | 275/367 [00:01<00:00, 185.93it/s]Pre-training Epoch 75:  80%|████████  | 294/367 [00:01<00:00, 181.61it/s]Pre-training Epoch 75:  85%|████████▌ | 313/367 [00:01<00:00, 180.65it/s]Pre-training Epoch 75:  90%|█████████ | 332/367 [00:01<00:00, 178.35it/s]Pre-training Epoch 75:  96%|█████████▌| 351/367 [00:01<00:00, 179.37it/s]Pre-training Epoch 75: 100%|██████████| 367/367 [00:01<00:00, 184.08it/s]
recon_loss: 0.02816067636013031, dist_loss: 0.776682436466217
recon_loss: 0.028160812333226204, dist_loss: 0.4024656116962433
recon_loss: 0.02816084958612919, dist_loss: 0.6070451736450195
recon_loss: 0.02816133014857769, dist_loss: 0.799966037273407
recon_loss: 0.028160493820905685, dist_loss: 0.5900871157646179
recon_loss: 0.02815994620323181, dist_loss: 0.4249953627586365
recon_loss: 0.02816048637032509, dist_loss: 0.5956444144248962
recon_loss: 0.02816004678606987, dist_loss: 0.7362192869186401
recon_loss: 0.028160754591226578, dist_loss: 0.5929811596870422
recon_loss: 0.028159746900200844, dist_loss: 0.7525796890258789
recon_loss: 0.0281593669205904, dist_loss: 0.8825132846832275
recon_loss: 0.02815927006304264, dist_loss: 0.8217950463294983
recon_loss: 0.028159143403172493, dist_loss: 0.7400238513946533
recon_loss: 0.02816079929471016, dist_loss: 0.7254220843315125
recon_loss: 0.028161313384771347, dist_loss: 0.6868299245834351
recon_loss: 0.028160830959677696, dist_loss: 0.9200838804244995
recon_loss: 0.02816181816160679, dist_loss: 0.3835318088531494
recon_loss: 0.028161879628896713, dist_loss: 0.683516263961792
recon_loss: 0.028162389993667603, dist_loss: 1.1732991933822632
recon_loss: 0.02816230058670044, dist_loss: 0.7171448469161987
recon_loss: 0.028161663562059402, dist_loss: 0.5425673127174377
recon_loss: 0.028160374611616135, dist_loss: 0.5257405042648315
recon_loss: 0.02815898507833481, dist_loss: 0.41283947229385376
recon_loss: 0.028158528730273247, dist_loss: 0.48403340578079224
recon_loss: 0.028159163892269135, dist_loss: 0.5680545568466187
recon_loss: 0.028159799054265022, dist_loss: 0.9887751340866089
recon_loss: 0.02815939672291279, dist_loss: 0.5551782846450806
recon_loss: 0.0281587652862072, dist_loss: 0.36283251643180847
recon_loss: 0.02815742790699005, dist_loss: 0.4280943274497986
recon_loss: 0.02815869264304638, dist_loss: 0.7072688937187195
recon_loss: 0.028158091008663177, dist_loss: 0.5622209310531616
recon_loss: 0.02815878950059414, dist_loss: 0.4117276072502136
recon_loss: 0.028158361092209816, dist_loss: 0.8315322995185852
recon_loss: 0.028157146647572517, dist_loss: 0.44333186745643616
recon_loss: 0.028157440945506096, dist_loss: 0.784838080406189
recon_loss: 0.028156934306025505, dist_loss: 0.7801238894462585
recon_loss: 0.028157562017440796, dist_loss: 0.38493382930755615
recon_loss: 0.02815757319331169, dist_loss: 0.7942144870758057
recon_loss: 0.028156889602541924, dist_loss: 0.5627700686454773
recon_loss: 0.028157006949186325, dist_loss: 0.4194208085536957
recon_loss: 0.028156625106930733, dist_loss: 0.6419380903244019
recon_loss: 0.028156302869319916, dist_loss: 0.8329687118530273
recon_loss: 0.02815742790699005, dist_loss: 0.8345158100128174
recon_loss: 0.028157038614153862, dist_loss: 0.7273125648498535
recon_loss: 0.028156807646155357, dist_loss: 0.7034659385681152
recon_loss: 0.02815757505595684, dist_loss: 0.5272442102432251
recon_loss: 0.02815627120435238, dist_loss: 0.9703338742256165
recon_loss: 0.02815788984298706, dist_loss: 0.7428733110427856
recon_loss: 0.02815728262066841, dist_loss: 0.7299169301986694
recon_loss: 0.028157180175185204, dist_loss: 0.6665264368057251
recon_loss: 0.02815823443233967, dist_loss: 0.5030065178871155
recon_loss: 0.028157364577054977, dist_loss: 0.6606442928314209
recon_loss: 0.02815769985318184, dist_loss: 0.44438692927360535
recon_loss: 0.02815796621143818, dist_loss: 0.42405369877815247
recon_loss: 0.028157297521829605, dist_loss: 0.5894002318382263
recon_loss: 0.028158333152532578, dist_loss: 0.5415093898773193
recon_loss: 0.028157202526926994, dist_loss: 0.5901392698287964
recon_loss: 0.028157776221632957, dist_loss: 0.6282330751419067
recon_loss: 0.028157636523246765, dist_loss: 0.6872591972351074
recon_loss: 0.02815687656402588, dist_loss: 1.320712685585022
recon_loss: 0.028158076107501984, dist_loss: 0.7507152557373047
recon_loss: 0.028156772255897522, dist_loss: 0.29475969076156616
recon_loss: 0.028158634901046753, dist_loss: 0.705108642578125
recon_loss: 0.028157347813248634, dist_loss: 0.43791866302490234
recon_loss: 0.028157632797956467, dist_loss: 0.5674895644187927
recon_loss: 0.028158776462078094, dist_loss: 0.639850378036499
recon_loss: 0.02815823256969452, dist_loss: 0.5192112326622009
recon_loss: 0.02815927565097809, dist_loss: 0.49414652585983276
recon_loss: 0.028158893808722496, dist_loss: 1.1638942956924438
recon_loss: 0.028159089386463165, dist_loss: 0.6757750511169434
recon_loss: 0.0281596127897501, dist_loss: 0.6005879640579224
recon_loss: 0.028159135952591896, dist_loss: 0.4254660904407501
recon_loss: 0.028158631175756454, dist_loss: 0.554107666015625
recon_loss: 0.02815891243517399, dist_loss: 0.5058338642120361
recon_loss: 0.02815811149775982, dist_loss: 0.5332006216049194
recon_loss: 0.028157439082860947, dist_loss: 0.7962935566902161
recon_loss: 0.028156721964478493, dist_loss: 0.5235586762428284
recon_loss: 0.028155818581581116, dist_loss: 0.7324689626693726
recon_loss: 0.028155526146292686, dist_loss: 0.6739022731781006
recon_loss: 0.028155192732810974, dist_loss: 0.6252422332763672
recon_loss: 0.028155140578746796, dist_loss: 0.45045235753059387
recon_loss: 0.028155244886875153, dist_loss: 0.5432133674621582
recon_loss: 0.028155196458101273, dist_loss: 0.5568933486938477
recon_loss: 0.02815520577132702, dist_loss: 0.7766347527503967
recon_loss: 0.028154758736491203, dist_loss: 0.623407244682312
recon_loss: 0.02815455198287964, dist_loss: 0.9819715023040771
recon_loss: 0.02815438248217106, dist_loss: 0.66543048620224
recon_loss: 0.028154630213975906, dist_loss: 0.38343098759651184
recon_loss: 0.028154650703072548, dist_loss: 0.5603570938110352
recon_loss: 0.028154488652944565, dist_loss: 0.5872070789337158
recon_loss: 0.028154252097010612, dist_loss: 0.9052053689956665
recon_loss: 0.028153885155916214, dist_loss: 0.608477771282196
recon_loss: 0.02815391682088375, dist_loss: 0.43764951825141907
recon_loss: 0.028153542429208755, dist_loss: 0.7480024099349976
recon_loss: 0.028153475373983383, dist_loss: 0.8351035118103027
recon_loss: 0.02815266326069832, dist_loss: 0.3959580659866333
recon_loss: 0.028152527287602425, dist_loss: 0.5455436706542969
recon_loss: 0.028152571991086006, dist_loss: 0.5353403687477112
recon_loss: 0.02815246768295765, dist_loss: 0.6121606826782227
recon_loss: 0.028152402490377426, dist_loss: 0.5089092254638672
recon_loss: 0.028152015060186386, dist_loss: 0.3969881534576416
recon_loss: 0.02815183810889721, dist_loss: 0.5713935494422913
recon_loss: 0.028151461854577065, dist_loss: 0.8747912645339966
recon_loss: 0.028151383623480797, dist_loss: 0.41345423460006714
recon_loss: 0.028151698410511017, dist_loss: 0.6950736045837402
recon_loss: 0.028152432292699814, dist_loss: 0.5411433577537537
recon_loss: 0.028152575716376305, dist_loss: 0.6334527730941772
recon_loss: 0.028153162449598312, dist_loss: 0.5376482009887695
recon_loss: 0.028153179213404655, dist_loss: 0.29729369282722473
recon_loss: 0.028153451159596443, dist_loss: 0.8472815752029419
recon_loss: 0.028153108432888985, dist_loss: 0.2821621000766754
Pre-training Epoch 76:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 76:   5%|▍         | 18/367 [00:00<00:02, 173.54it/s]Pre-training Epoch 76:  10%|▉         | 36/367 [00:00<00:01, 172.14it/s]Pre-training Epoch 76:  15%|█▍        | 54/367 [00:00<00:01, 172.95it/s]Pre-training Epoch 76:  20%|█▉        | 73/367 [00:00<00:01, 176.02it/s]Pre-training Epoch 76:  25%|██▍       | 91/367 [00:00<00:01, 174.59it/s]Pre-training Epoch 76:  30%|██▉       | 109/367 [00:00<00:01, 175.78it/s]Pre-training Epoch 76:  35%|███▍      | 127/367 [00:00<00:01, 176.72it/s]recon_loss: 0.028152739629149437, dist_loss: 0.5458207130432129
recon_loss: 0.028152702376246452, dist_loss: 0.3264310956001282
recon_loss: 0.02815190888941288, dist_loss: 0.827440083026886
recon_loss: 0.028152309358119965, dist_loss: 0.5748846530914307
recon_loss: 0.028152242302894592, dist_loss: 0.7662603855133057
recon_loss: 0.02815236896276474, dist_loss: 0.4042707085609436
recon_loss: 0.028154058381915092, dist_loss: 0.4970208406448364
recon_loss: 0.028153812512755394, dist_loss: 0.8240641951560974
recon_loss: 0.028155140578746796, dist_loss: 0.4834882616996765
recon_loss: 0.028155794367194176, dist_loss: 0.5676792860031128
recon_loss: 0.028155943378806114, dist_loss: 0.7586365938186646
recon_loss: 0.028156647458672523, dist_loss: 0.38774988055229187
recon_loss: 0.02815551497042179, dist_loss: 0.742922306060791
recon_loss: 0.028156200423836708, dist_loss: 0.4375833570957184
recon_loss: 0.02815580740571022, dist_loss: 0.5190949440002441
recon_loss: 0.02815585769712925, dist_loss: 0.5815125703811646
recon_loss: 0.028155740350484848, dist_loss: 0.9968916177749634
recon_loss: 0.028155673295259476, dist_loss: 0.7227474451065063
recon_loss: 0.028155285865068436, dist_loss: 0.4447815716266632
recon_loss: 0.02815430238842964, dist_loss: 0.42907071113586426
recon_loss: 0.028153225779533386, dist_loss: 0.8312680721282959
recon_loss: 0.028153087943792343, dist_loss: 0.4679071307182312
recon_loss: 0.02815244533121586, dist_loss: 0.4576556384563446
recon_loss: 0.02815181016921997, dist_loss: 0.45680731534957886
recon_loss: 0.028151528909802437, dist_loss: 0.6259151101112366
recon_loss: 0.028151072561740875, dist_loss: 0.8787394762039185
recon_loss: 0.02815048210322857, dist_loss: 0.4800450801849365
recon_loss: 0.028150083497166634, dist_loss: 0.47932004928588867
recon_loss: 0.02814972773194313, dist_loss: 0.7726669907569885
recon_loss: 0.028149425983428955, dist_loss: 0.46779924631118774
recon_loss: 0.02814927138388157, dist_loss: 1.1294569969177246
recon_loss: 0.028148949146270752, dist_loss: 0.9165830612182617
recon_loss: 0.028148937970399857, dist_loss: 0.607178270816803
recon_loss: 0.028148779645562172, dist_loss: 0.6430687308311462
recon_loss: 0.028148742392659187, dist_loss: 0.6518711447715759
recon_loss: 0.028148561716079712, dist_loss: 0.7976523041725159
recon_loss: 0.028148528188467026, dist_loss: 0.4286623001098633
recon_loss: 0.028148505836725235, dist_loss: 1.281899333000183
recon_loss: 0.028148261830210686, dist_loss: 0.5947978496551514
recon_loss: 0.028148194774985313, dist_loss: 0.835626482963562
recon_loss: 0.02814800664782524, dist_loss: 1.188275694847107
recon_loss: 0.028148312121629715, dist_loss: 0.958558201789856
recon_loss: 0.02814839780330658, dist_loss: 0.4404013752937317
recon_loss: 0.028148306533694267, dist_loss: 0.4638708829879761
recon_loss: 0.028147919103503227, dist_loss: 0.5204979181289673
recon_loss: 0.028148116543889046, dist_loss: 1.1375564336776733
recon_loss: 0.028148135170340538, dist_loss: 0.7228485345840454
recon_loss: 0.028148148208856583, dist_loss: 0.29874175786972046
recon_loss: 0.028148243203759193, dist_loss: 0.5898786187171936
recon_loss: 0.02814827673137188, dist_loss: 0.5721527338027954
recon_loss: 0.028148287907242775, dist_loss: 0.5732077360153198
recon_loss: 0.028148159384727478, dist_loss: 0.5825393795967102
recon_loss: 0.028147907927632332, dist_loss: 0.7185205221176147
recon_loss: 0.02814778871834278, dist_loss: 0.4296855926513672
recon_loss: 0.02814767137169838, dist_loss: 0.5591617822647095
recon_loss: 0.028147540986537933, dist_loss: 0.7663719654083252
recon_loss: 0.028147488832473755, dist_loss: 0.5862731337547302
recon_loss: 0.028147563338279724, dist_loss: 0.5537468791007996
recon_loss: 0.02814711444079876, dist_loss: 0.6159682273864746
recon_loss: 0.028147650882601738, dist_loss: 0.6335228681564331
recon_loss: 0.02814718708395958, dist_loss: 0.4369974136352539
recon_loss: 0.028146782889962196, dist_loss: 0.37911078333854675
recon_loss: 0.028147006407380104, dist_loss: 0.547910213470459
recon_loss: 0.0281465332955122, dist_loss: 0.6237753629684448
recon_loss: 0.028146851807832718, dist_loss: 0.6644286513328552
recon_loss: 0.028146447613835335, dist_loss: 0.9219090342521667
recon_loss: 0.028146222233772278, dist_loss: 0.5534999370574951
recon_loss: 0.028146345168352127, dist_loss: 0.9859689474105835
recon_loss: 0.02814592234790325, dist_loss: 0.5382643938064575
recon_loss: 0.028146227821707726, dist_loss: 1.1301411390304565
recon_loss: 0.028146298602223396, dist_loss: 0.36591047048568726
recon_loss: 0.02814643271267414, dist_loss: 0.505596935749054
recon_loss: 0.028146786615252495, dist_loss: 0.31989431381225586
recon_loss: 0.02814692072570324, dist_loss: 0.6975884437561035
recon_loss: 0.028147296980023384, dist_loss: 0.3610997200012207
recon_loss: 0.02814696915447712, dist_loss: 0.5808408260345459
recon_loss: 0.02814691700041294, dist_loss: 0.4834367036819458
recon_loss: 0.028147058561444283, dist_loss: 0.5543553829193115
recon_loss: 0.028146913275122643, dist_loss: 0.8558990955352783
recon_loss: 0.0281471349298954, dist_loss: 0.6359022855758667
recon_loss: 0.028147125616669655, dist_loss: 1.0711854696273804
recon_loss: 0.028146706521511078, dist_loss: 0.5622933506965637
recon_loss: 0.028146926313638687, dist_loss: 0.6405102014541626
recon_loss: 0.02814655750989914, dist_loss: 0.5687456130981445
recon_loss: 0.02814617194235325, dist_loss: 0.4007318615913391
recon_loss: 0.028146032243967056, dist_loss: 0.7651100158691406
recon_loss: 0.028145812451839447, dist_loss: 1.3782646656036377
recon_loss: 0.02814568392932415, dist_loss: 0.4195873737335205
recon_loss: 0.028145208954811096, dist_loss: 0.45632946491241455
recon_loss: 0.028145242482423782, dist_loss: 0.551908016204834
recon_loss: 0.02814471907913685, dist_loss: 0.7215806841850281
recon_loss: 0.02814440242946148, dist_loss: 0.749915599822998
recon_loss: 0.02814428322017193, dist_loss: 0.731482982635498
recon_loss: 0.028144104406237602, dist_loss: 0.8335238695144653
recon_loss: 0.02814425155520439, dist_loss: 0.5576555132865906
recon_loss: 0.028144102543592453, dist_loss: 0.6871445775032043
recon_loss: 0.028144309297204018, dist_loss: 0.5392249822616577
recon_loss: 0.02814403735101223, dist_loss: 0.5497949719429016
recon_loss: 0.028143906965851784, dist_loss: 0.7781747579574585
recon_loss: 0.02814416028559208, dist_loss: 0.5861901640892029
recon_loss: 0.028143754228949547, dist_loss: 0.5632480382919312
recon_loss: 0.02814352512359619, dist_loss: 0.7383546233177185
recon_loss: 0.02814377099275589, dist_loss: 0.8607021570205688
recon_loss: 0.028143681585788727, dist_loss: 0.4284469187259674
recon_loss: 0.02814379706978798, dist_loss: 0.645451545715332
recon_loss: 0.028143655508756638, dist_loss: 0.910443902015686
recon_loss: 0.028143197298049927, dist_loss: 0.6759974360466003
recon_loss: 0.02814394235610962, dist_loss: 0.6635618209838867
recon_loss: 0.028143376111984253, dist_loss: 0.79393070936203
recon_loss: 0.028143586590886116, dist_loss: 0.6723238229751587
recon_loss: 0.02814445272088051, dist_loss: 0.3523256480693817
recon_loss: 0.028144247829914093, dist_loss: 0.3288872539997101
recon_loss: 0.02814440429210663, dist_loss: 0.7242748141288757
recon_loss: 0.028144320473074913, dist_loss: 0.6662453413009644
recon_loss: 0.02814418077468872, dist_loss: 0.8172088861465454
recon_loss: 0.028144320473074913, dist_loss: 0.49616798758506775
recon_loss: 0.028143635019659996, dist_loss: 0.7500369548797607
recon_loss: 0.028142929077148438, dist_loss: 0.5707988739013672
recon_loss: 0.028142517432570457, dist_loss: 0.7495549321174622
recon_loss: 0.028142616152763367, dist_loss: 0.5633397102355957
recon_loss: 0.02814280241727829, dist_loss: 0.5426372289657593
recon_loss: 0.028143087401986122, dist_loss: 0.4456106126308441
recon_loss: 0.028143959119915962, dist_loss: 0.6237119436264038
recon_loss: 0.02814444899559021, dist_loss: 0.5642997026443481
recon_loss: 0.028144272044301033, dist_loss: 0.7318679094314575
recon_loss: 0.028144586831331253, dist_loss: 0.9266065359115601
recon_loss: 0.02814428135752678, dist_loss: 0.3288842439651489
recon_loss: 0.028144290670752525, dist_loss: 0.6777694225311279
Pre-training Epoch 76:  40%|███▉      | 146/367 [00:00<00:01, 178.27it/s]Pre-training Epoch 76:  45%|████▍     | 164/367 [00:00<00:01, 178.53it/s]Pre-training Epoch 76:  50%|████▉     | 183/367 [00:01<00:01, 179.57it/s]Pre-training Epoch 76:  55%|█████▍    | 201/367 [00:01<00:00, 179.38it/s]Pre-training Epoch 76:  60%|█████▉    | 219/367 [00:01<00:00, 178.38it/s]Pre-training Epoch 76:  65%|██████▍   | 238/367 [00:01<00:00, 179.95it/s]recon_loss: 0.028144702315330505, dist_loss: 0.42988884449005127
recon_loss: 0.028144894167780876, dist_loss: 0.7358022928237915
recon_loss: 0.028144916519522667, dist_loss: 0.9091600179672241
recon_loss: 0.028144514188170433, dist_loss: 0.4758489429950714
recon_loss: 0.02814391441643238, dist_loss: 1.2471177577972412
recon_loss: 0.028143085539340973, dist_loss: 0.5150881409645081
recon_loss: 0.028142543509602547, dist_loss: 0.637639045715332
recon_loss: 0.028141722083091736, dist_loss: 0.8176736831665039
recon_loss: 0.028141528367996216, dist_loss: 0.8548387289047241
recon_loss: 0.028140757232904434, dist_loss: 0.2796061038970947
recon_loss: 0.028140617534518242, dist_loss: 0.9797952175140381
recon_loss: 0.028140470385551453, dist_loss: 0.5976360440254211
recon_loss: 0.028140436857938766, dist_loss: 0.5655286908149719
recon_loss: 0.028140434995293617, dist_loss: 0.6677641868591309
recon_loss: 0.028140515089035034, dist_loss: 0.6352616548538208
recon_loss: 0.028140699490904808, dist_loss: 0.543915331363678
recon_loss: 0.028140537440776825, dist_loss: 0.5439929962158203
recon_loss: 0.028140468522906303, dist_loss: 0.9429391026496887
recon_loss: 0.028140123933553696, dist_loss: 0.5652695298194885
recon_loss: 0.02814001403748989, dist_loss: 0.574959397315979
recon_loss: 0.02813977561891079, dist_loss: 0.7795027494430542
recon_loss: 0.028139546513557434, dist_loss: 0.5755834579467773
recon_loss: 0.028139615431427956, dist_loss: 0.7361326217651367
recon_loss: 0.028139609843492508, dist_loss: 0.49186599254608154
recon_loss: 0.028139736503362656, dist_loss: 0.8737750053405762
recon_loss: 0.028139449656009674, dist_loss: 0.5382069945335388
recon_loss: 0.028139587491750717, dist_loss: 0.693479597568512
recon_loss: 0.028139714151620865, dist_loss: 0.9762082695960999
recon_loss: 0.028139812871813774, dist_loss: 1.0119233131408691
recon_loss: 0.02813989855349064, dist_loss: 0.38809460401535034
recon_loss: 0.028140025213360786, dist_loss: 0.8144800662994385
recon_loss: 0.028140028938651085, dist_loss: 0.8962038159370422
recon_loss: 0.028140181675553322, dist_loss: 0.3532555103302002
recon_loss: 0.028140099719166756, dist_loss: 0.4860075116157532
recon_loss: 0.02814045175909996, dist_loss: 0.6940833330154419
recon_loss: 0.02814025804400444, dist_loss: 0.5439934730529785
recon_loss: 0.028140217065811157, dist_loss: 0.5123026967048645
recon_loss: 0.02813967689871788, dist_loss: 0.7968407869338989
recon_loss: 0.028139999136328697, dist_loss: 0.7560544610023499
recon_loss: 0.028139622882008553, dist_loss: 0.7060282230377197
recon_loss: 0.028139278292655945, dist_loss: 0.6547925472259521
recon_loss: 0.028140434995293617, dist_loss: 0.6699621677398682
recon_loss: 0.028139200061559677, dist_loss: 0.35449284315109253
recon_loss: 0.028140829876065254, dist_loss: 0.4302214980125427
recon_loss: 0.028141969814896584, dist_loss: 0.6340748071670532
recon_loss: 0.028141919523477554, dist_loss: 0.7339246869087219
recon_loss: 0.028143256902694702, dist_loss: 0.46033209562301636
recon_loss: 0.028144340962171555, dist_loss: 0.6077203750610352
recon_loss: 0.02814403362572193, dist_loss: 0.958923876285553
recon_loss: 0.028145793825387955, dist_loss: 1.0213403701782227
recon_loss: 0.028144914656877518, dist_loss: 0.928144633769989
recon_loss: 0.028145134449005127, dist_loss: 0.8715829849243164
recon_loss: 0.02814418263733387, dist_loss: 0.3525427281856537
recon_loss: 0.028142664581537247, dist_loss: 0.3021269142627716
recon_loss: 0.0281427800655365, dist_loss: 0.8557557463645935
recon_loss: 0.028140349313616753, dist_loss: 0.7347397804260254
recon_loss: 0.028139902278780937, dist_loss: 0.7188448309898376
recon_loss: 0.028139567002654076, dist_loss: 0.4985485076904297
recon_loss: 0.028138045221567154, dist_loss: 0.36515480279922485
recon_loss: 0.028139159083366394, dist_loss: 0.6869370937347412
recon_loss: 0.028138944879174232, dist_loss: 0.49962881207466125
recon_loss: 0.02813870459794998, dist_loss: 0.6056317090988159
recon_loss: 0.028139464557170868, dist_loss: 0.7445727586746216
recon_loss: 0.028137654066085815, dist_loss: 1.0773577690124512
recon_loss: 0.028138358145952225, dist_loss: 0.5991684794425964
recon_loss: 0.028137652203440666, dist_loss: 0.5912861824035645
recon_loss: 0.02813735045492649, dist_loss: 0.8324522972106934
recon_loss: 0.028138352558016777, dist_loss: 0.7887052297592163
recon_loss: 0.028136681765317917, dist_loss: 0.44310349225997925
recon_loss: 0.028137601912021637, dist_loss: 0.5963824391365051
recon_loss: 0.028137188404798508, dist_loss: 0.7243287563323975
recon_loss: 0.028135886415839195, dist_loss: 0.8633242845535278
recon_loss: 0.028136571869254112, dist_loss: 0.7713303565979004
recon_loss: 0.028135282918810844, dist_loss: 0.716521143913269
recon_loss: 0.028135258704423904, dist_loss: 0.6143398284912109
recon_loss: 0.028134871274232864, dist_loss: 0.998541533946991
recon_loss: 0.028134314343333244, dist_loss: 0.7043941020965576
recon_loss: 0.028134705498814583, dist_loss: 0.5326182842254639
recon_loss: 0.028134003281593323, dist_loss: 0.5616309642791748
recon_loss: 0.02813449129462242, dist_loss: 0.914441704750061
recon_loss: 0.02813420258462429, dist_loss: 0.6224316954612732
recon_loss: 0.0281338170170784, dist_loss: 0.7321324944496155
recon_loss: 0.028133969753980637, dist_loss: 0.5753289461135864
recon_loss: 0.028133541345596313, dist_loss: 0.47803324460983276
recon_loss: 0.028133803978562355, dist_loss: 1.04099440574646
recon_loss: 0.028133593499660492, dist_loss: 0.552397608757019
recon_loss: 0.028133448213338852, dist_loss: 0.3687734603881836
recon_loss: 0.02813367359340191, dist_loss: 0.756801962852478
recon_loss: 0.028133520856499672, dist_loss: 0.8861808776855469
recon_loss: 0.028133107349276543, dist_loss: 0.7072271108627319
recon_loss: 0.028133077546954155, dist_loss: 0.4904521405696869
recon_loss: 0.028132786974310875, dist_loss: 0.693398118019104
recon_loss: 0.02813270315527916, dist_loss: 0.6256866455078125
recon_loss: 0.02813255786895752, dist_loss: 0.6774774789810181
recon_loss: 0.028132425621151924, dist_loss: 0.6300955414772034
recon_loss: 0.02813240885734558, dist_loss: 0.4482317268848419
recon_loss: 0.028132569044828415, dist_loss: 0.616857647895813
recon_loss: 0.028132259845733643, dist_loss: 0.7498564720153809
recon_loss: 0.028132528066635132, dist_loss: 1.1512353420257568
recon_loss: 0.028132261708378792, dist_loss: 0.7757079601287842
recon_loss: 0.028132300823926926, dist_loss: 0.7003668546676636
recon_loss: 0.028132537379860878, dist_loss: 0.6219308376312256
recon_loss: 0.028132809326052666, dist_loss: 0.35546761751174927
recon_loss: 0.02813350036740303, dist_loss: 0.3453032970428467
recon_loss: 0.028134189546108246, dist_loss: 1.0254521369934082
recon_loss: 0.028134219348430634, dist_loss: 0.9289866089820862
recon_loss: 0.02813432738184929, dist_loss: 0.5410774946212769
recon_loss: 0.028133833780884743, dist_loss: 0.3513275980949402
recon_loss: 0.028134264051914215, dist_loss: 0.8183510899543762
recon_loss: 0.028134047985076904, dist_loss: 0.44464531540870667
recon_loss: 0.028133826330304146, dist_loss: 0.5070280432701111
recon_loss: 0.02813432365655899, dist_loss: 0.6418545246124268
recon_loss: 0.0281326062977314, dist_loss: 0.8255250453948975
recon_loss: 0.028132570907473564, dist_loss: 0.6972531080245972
recon_loss: 0.02813250571489334, dist_loss: 0.570264458656311
recon_loss: 0.02813148871064186, dist_loss: 0.7143456339836121
recon_loss: 0.028131922706961632, dist_loss: 1.0803592205047607
recon_loss: 0.0281316377222538, dist_loss: 0.7736106514930725
recon_loss: 0.02813067100942135, dist_loss: 0.5312449336051941
recon_loss: 0.028131157159805298, dist_loss: 0.9694092273712158
recon_loss: 0.028130650520324707, dist_loss: 0.7120487093925476
recon_loss: 0.02813163585960865, dist_loss: 0.4694950580596924
recon_loss: 0.028132770210504532, dist_loss: 0.4879281520843506
recon_loss: 0.028131959959864616, dist_loss: 0.5598945617675781
recon_loss: 0.028133423998951912, dist_loss: 0.6248851418495178
recon_loss: 0.02813275344669819, dist_loss: 0.6991426944732666
recon_loss: 0.028132477775216103, dist_loss: 0.8972756862640381
recon_loss: 0.028132863342761993, dist_loss: 0.7127851843833923
Pre-training Epoch 76:  70%|███████   | 258/367 [00:01<00:00, 184.28it/s]Pre-training Epoch 76:  75%|███████▌  | 277/367 [00:01<00:00, 181.91it/s]Pre-training Epoch 76:  81%|████████  | 296/367 [00:01<00:00, 181.43it/s]Pre-training Epoch 76:  86%|████████▌ | 315/367 [00:01<00:00, 179.39it/s]Pre-training Epoch 76:  91%|█████████ | 333/367 [00:01<00:00, 179.41it/s]Pre-training Epoch 76:  96%|█████████▌| 351/367 [00:01<00:00, 178.55it/s]Pre-training Epoch 76: 100%|██████████| 367/367 [00:02<00:00, 178.47it/s]
recon_loss: 0.02813243493437767, dist_loss: 1.2556945085525513
recon_loss: 0.028132854029536247, dist_loss: 0.33316463232040405
recon_loss: 0.02813345193862915, dist_loss: 0.8922549486160278
recon_loss: 0.028133083134889603, dist_loss: 0.6897099614143372
recon_loss: 0.028133191168308258, dist_loss: 0.5672537088394165
recon_loss: 0.02813308872282505, dist_loss: 0.6212159395217896
recon_loss: 0.028133010491728783, dist_loss: 0.8638356328010559
recon_loss: 0.028133772313594818, dist_loss: 0.3933933675289154
recon_loss: 0.028132034465670586, dist_loss: 0.5061604380607605
recon_loss: 0.02813182771205902, dist_loss: 0.4830474257469177
recon_loss: 0.02813129685819149, dist_loss: 0.4086379408836365
recon_loss: 0.02813037857413292, dist_loss: 1.018524408340454
recon_loss: 0.028131723403930664, dist_loss: 0.7834203243255615
recon_loss: 0.028130382299423218, dist_loss: 0.33680903911590576
recon_loss: 0.02813074178993702, dist_loss: 0.3719772696495056
recon_loss: 0.028131533414125443, dist_loss: 0.8056895732879639
recon_loss: 0.028132477775216103, dist_loss: 0.45467400550842285
recon_loss: 0.028133364394307137, dist_loss: 0.7355744242668152
recon_loss: 0.028133388608694077, dist_loss: 0.6004445552825928
recon_loss: 0.028133727610111237, dist_loss: 0.9514251351356506
recon_loss: 0.028133945539593697, dist_loss: 0.5379359722137451
recon_loss: 0.028134411200881004, dist_loss: 0.511940598487854
recon_loss: 0.028133980929851532, dist_loss: 0.7526399493217468
recon_loss: 0.028134334832429886, dist_loss: 0.6059702634811401
recon_loss: 0.028133708983659744, dist_loss: 0.5454553365707397
recon_loss: 0.02813253179192543, dist_loss: 1.0659669637680054
recon_loss: 0.028132304549217224, dist_loss: 0.5555082559585571
recon_loss: 0.02813100256025791, dist_loss: 0.664628267288208
recon_loss: 0.028131384402513504, dist_loss: 0.452318012714386
recon_loss: 0.028130430728197098, dist_loss: 0.9120430946350098
recon_loss: 0.028129296377301216, dist_loss: 0.7703857421875
recon_loss: 0.02812936156988144, dist_loss: 0.8043829202651978
recon_loss: 0.028129268437623978, dist_loss: 0.6738482713699341
recon_loss: 0.0281292162835598, dist_loss: 0.5776038765907288
recon_loss: 0.0281297005712986, dist_loss: 0.7256399989128113
recon_loss: 0.02813020907342434, dist_loss: 0.6744997501373291
recon_loss: 0.02813047356903553, dist_loss: 0.6727717518806458
recon_loss: 0.028130531311035156, dist_loss: 0.8359416127204895
recon_loss: 0.028130384162068367, dist_loss: 0.5459827184677124
recon_loss: 0.02813001163303852, dist_loss: 0.8090003728866577
recon_loss: 0.028129415586590767, dist_loss: 0.9002573490142822
recon_loss: 0.02812904492020607, dist_loss: 0.33207499980926514
recon_loss: 0.028129246085882187, dist_loss: 0.5761877298355103
recon_loss: 0.02812921069562435, dist_loss: 0.7320186495780945
recon_loss: 0.028129395097494125, dist_loss: 0.4346475899219513
recon_loss: 0.028129473328590393, dist_loss: 1.074070692062378
recon_loss: 0.02812892757356167, dist_loss: 0.49950578808784485
recon_loss: 0.028129104524850845, dist_loss: 0.6602699756622314
recon_loss: 0.02812887355685234, dist_loss: 0.6693528890609741
recon_loss: 0.02812889590859413, dist_loss: 0.405351847410202
recon_loss: 0.02812866121530533, dist_loss: 0.7609355449676514
recon_loss: 0.028127627447247505, dist_loss: 0.44979092478752136
recon_loss: 0.028127776458859444, dist_loss: 0.7439882159233093
recon_loss: 0.028127651661634445, dist_loss: 0.6764896512031555
recon_loss: 0.02812693454325199, dist_loss: 0.48609310388565063
recon_loss: 0.02812710404396057, dist_loss: 0.7539669275283813
recon_loss: 0.02812645584344864, dist_loss: 0.4470386207103729
recon_loss: 0.028126185759902, dist_loss: 0.7507044076919556
recon_loss: 0.028125813230872154, dist_loss: 0.593697190284729
recon_loss: 0.02812572568655014, dist_loss: 1.135340690612793
recon_loss: 0.028125593438744545, dist_loss: 0.3988751769065857
recon_loss: 0.02812531217932701, dist_loss: 0.3470323085784912
recon_loss: 0.028125343844294548, dist_loss: 0.8364841938018799
recon_loss: 0.02812548168003559, dist_loss: 0.5081909894943237
recon_loss: 0.028125127777457237, dist_loss: 0.6347848773002625
recon_loss: 0.02812492661178112, dist_loss: 0.3719470500946045
recon_loss: 0.02812497317790985, dist_loss: 0.463462769985199
recon_loss: 0.02812488190829754, dist_loss: 0.5602483749389648
recon_loss: 0.028124814853072166, dist_loss: 0.7633277177810669
recon_loss: 0.028124885633587837, dist_loss: 0.6373382806777954
recon_loss: 0.028124850243330002, dist_loss: 1.47951340675354
recon_loss: 0.02812529355287552, dist_loss: 0.722412109375
recon_loss: 0.028125673532485962, dist_loss: 0.6416044235229492
recon_loss: 0.028126437216997147, dist_loss: 0.9309647083282471
recon_loss: 0.02812696248292923, dist_loss: 0.7471300363540649
recon_loss: 0.028127068653702736, dist_loss: 0.6383424997329712
recon_loss: 0.028127312660217285, dist_loss: 0.660413384437561
recon_loss: 0.02812691032886505, dist_loss: 0.46896764636039734
recon_loss: 0.028126701712608337, dist_loss: 0.8684582710266113
recon_loss: 0.028126828372478485, dist_loss: 0.6135972142219543
recon_loss: 0.028126509860157967, dist_loss: 0.5408352613449097
recon_loss: 0.028126053512096405, dist_loss: 0.5837898254394531
recon_loss: 0.028125811368227005, dist_loss: 0.49789413809776306
recon_loss: 0.028125638142228127, dist_loss: 0.5439015626907349
recon_loss: 0.028125399723649025, dist_loss: 0.463971883058548
recon_loss: 0.02812499925494194, dist_loss: 0.7110122442245483
recon_loss: 0.028124116361141205, dist_loss: 0.8370432257652283
recon_loss: 0.02812422439455986, dist_loss: 0.8703336715698242
recon_loss: 0.028123635798692703, dist_loss: 0.5716235637664795
recon_loss: 0.028123967349529266, dist_loss: 0.6935861706733704
recon_loss: 0.028124762699007988, dist_loss: 0.566577672958374
recon_loss: 0.028124235570430756, dist_loss: 0.9359828233718872
recon_loss: 0.028124654665589333, dist_loss: 0.6485806107521057
recon_loss: 0.028124388307332993, dist_loss: 0.7292540073394775
recon_loss: 0.028123924508690834, dist_loss: 0.851677417755127
recon_loss: 0.028123335912823677, dist_loss: 0.765320897102356
recon_loss: 0.028123119845986366, dist_loss: 0.4737420082092285
recon_loss: 0.028123265132308006, dist_loss: 0.4322749674320221
recon_loss: 0.028123576194047928, dist_loss: 0.6142191290855408
recon_loss: 0.02812354825437069, dist_loss: 0.8605583906173706
recon_loss: 0.028123466297984123, dist_loss: 0.5417518615722656
recon_loss: 0.028123358264565468, dist_loss: 0.5602915287017822
recon_loss: 0.028123343363404274, dist_loss: 0.8840897679328918
recon_loss: 0.02812342718243599, dist_loss: 1.024141550064087
recon_loss: 0.02812383323907852, dist_loss: 0.718104898929596
recon_loss: 0.028123656287789345, dist_loss: 1.3041532039642334
recon_loss: 0.028123008087277412, dist_loss: 0.9261895418167114
recon_loss: 0.02812228351831436, dist_loss: 0.4044140875339508
recon_loss: 0.028121402487158775, dist_loss: 0.7746394872665405
recon_loss: 0.028121592476963997, dist_loss: 0.7955171465873718
recon_loss: 0.02812124416232109, dist_loss: 0.23957131803035736
Pre-training Epoch 77:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 77:   5%|▍         | 18/367 [00:00<00:02, 173.07it/s]Pre-training Epoch 77:  10%|█         | 37/367 [00:00<00:01, 177.97it/s]Pre-training Epoch 77:  15%|█▌        | 56/367 [00:00<00:01, 179.02it/s]Pre-training Epoch 77:  20%|██        | 75/367 [00:00<00:01, 179.94it/s]Pre-training Epoch 77:  25%|██▌       | 93/367 [00:00<00:01, 178.84it/s]Pre-training Epoch 77:  30%|███       | 111/367 [00:00<00:01, 177.44it/s]recon_loss: 0.02812199853360653, dist_loss: 0.3596852719783783
recon_loss: 0.028123196214437485, dist_loss: 1.0083894729614258
recon_loss: 0.028124572709202766, dist_loss: 0.5129724740982056
recon_loss: 0.02812611684203148, dist_loss: 0.69241863489151
recon_loss: 0.028127271682024002, dist_loss: 0.3175610303878784
recon_loss: 0.028127960860729218, dist_loss: 0.9194941520690918
recon_loss: 0.02812829427421093, dist_loss: 0.9943814277648926
recon_loss: 0.028127679601311684, dist_loss: 0.47456690669059753
recon_loss: 0.02812686376273632, dist_loss: 0.8713932633399963
recon_loss: 0.02812565490603447, dist_loss: 0.8969115614891052
recon_loss: 0.02812499739229679, dist_loss: 0.5813941955566406
recon_loss: 0.028123248368501663, dist_loss: 0.9230475425720215
recon_loss: 0.02812224254012108, dist_loss: 0.31500381231307983
recon_loss: 0.02812139131128788, dist_loss: 0.7740733623504639
recon_loss: 0.028120823204517365, dist_loss: 0.6572626829147339
recon_loss: 0.028120432049036026, dist_loss: 0.9168463945388794
recon_loss: 0.028120534494519234, dist_loss: 0.5448253750801086
recon_loss: 0.02812018431723118, dist_loss: 0.7091130018234253
recon_loss: 0.028120433911681175, dist_loss: 0.6619263887405396
recon_loss: 0.028120070695877075, dist_loss: 0.8498311042785645
recon_loss: 0.028119955211877823, dist_loss: 0.34189409017562866
recon_loss: 0.02811962179839611, dist_loss: 0.5032016038894653
recon_loss: 0.028119627386331558, dist_loss: 0.44867897033691406
recon_loss: 0.028119387105107307, dist_loss: 0.5345243215560913
recon_loss: 0.028119157999753952, dist_loss: 0.9986895322799683
recon_loss: 0.02811909280717373, dist_loss: 0.4732224941253662
recon_loss: 0.02811899222433567, dist_loss: 0.24811208248138428
recon_loss: 0.0281191598623991, dist_loss: 0.6078715324401855
recon_loss: 0.028120363131165504, dist_loss: 0.7360114455223083
recon_loss: 0.02812047488987446, dist_loss: 0.4287458658218384
recon_loss: 0.02812115103006363, dist_loss: 0.45544275641441345
recon_loss: 0.02812068536877632, dist_loss: 0.6306379437446594
recon_loss: 0.028120506554841995, dist_loss: 1.1736146211624146
recon_loss: 0.028119847178459167, dist_loss: 0.3704862594604492
recon_loss: 0.028119012713432312, dist_loss: 0.665615439414978
recon_loss: 0.028118811547756195, dist_loss: 0.6058021783828735
recon_loss: 0.02811824157834053, dist_loss: 0.8137231469154358
recon_loss: 0.028118232265114784, dist_loss: 0.7150214910507202
recon_loss: 0.028118569403886795, dist_loss: 0.46492820978164673
recon_loss: 0.028117865324020386, dist_loss: 0.4260174036026001
recon_loss: 0.028117746114730835, dist_loss: 0.5396171808242798
recon_loss: 0.028118159621953964, dist_loss: 0.4391191601753235
recon_loss: 0.02811778150498867, dist_loss: 0.6253244280815125
recon_loss: 0.028117842972278595, dist_loss: 0.5441678166389465
recon_loss: 0.028117388486862183, dist_loss: 0.3720974028110504
recon_loss: 0.02811744250357151, dist_loss: 0.8741669058799744
recon_loss: 0.0281175896525383, dist_loss: 0.5101091265678406
recon_loss: 0.028117435052990913, dist_loss: 0.40179091691970825
recon_loss: 0.02811763994395733, dist_loss: 0.3984217643737793
recon_loss: 0.028117895126342773, dist_loss: 0.3452398180961609
recon_loss: 0.028118183836340904, dist_loss: 0.7664084434509277
recon_loss: 0.02811826951801777, dist_loss: 1.0155441761016846
recon_loss: 0.028118502348661423, dist_loss: 0.7196322083473206
recon_loss: 0.028118448331952095, dist_loss: 0.531344473361969
recon_loss: 0.02811812423169613, dist_loss: 0.5840247869491577
recon_loss: 0.02811770886182785, dist_loss: 0.6773519515991211
recon_loss: 0.028117233887314796, dist_loss: 1.185925006866455
recon_loss: 0.028116712346673012, dist_loss: 0.6620322465896606
recon_loss: 0.02811698615550995, dist_loss: 0.49257761240005493
recon_loss: 0.02811623364686966, dist_loss: 0.5997553467750549
recon_loss: 0.02811605855822563, dist_loss: 0.7415323853492737
recon_loss: 0.02811562456190586, dist_loss: 0.38687020540237427
recon_loss: 0.02811523526906967, dist_loss: 0.526046872138977
recon_loss: 0.028115427121520042, dist_loss: 0.7783002853393555
recon_loss: 0.02811531350016594, dist_loss: 1.5444340705871582
recon_loss: 0.028116410598158836, dist_loss: 0.54884272813797
recon_loss: 0.02811761572957039, dist_loss: 0.9169207811355591
recon_loss: 0.028118453919887543, dist_loss: 0.8793690204620361
recon_loss: 0.028119277209043503, dist_loss: 0.5101770758628845
recon_loss: 0.0281204916536808, dist_loss: 0.4626407027244568
recon_loss: 0.02812122367322445, dist_loss: 0.7098259925842285
recon_loss: 0.028121504932641983, dist_loss: 0.8931779861450195
recon_loss: 0.028120538219809532, dist_loss: 1.0203969478607178
recon_loss: 0.028120286762714386, dist_loss: 0.4069957137107849
recon_loss: 0.028119811788201332, dist_loss: 0.5710623264312744
recon_loss: 0.028117792680859566, dist_loss: 0.4856087565422058
recon_loss: 0.028118077665567398, dist_loss: 0.9412732720375061
recon_loss: 0.028116948902606964, dist_loss: 0.8795784115791321
recon_loss: 0.028116581961512566, dist_loss: 0.5297524333000183
recon_loss: 0.028116313740611076, dist_loss: 0.5320166945457458
recon_loss: 0.02811509370803833, dist_loss: 0.6400680541992188
recon_loss: 0.02811547741293907, dist_loss: 0.3754829168319702
recon_loss: 0.02811492048203945, dist_loss: 0.9795495271682739
recon_loss: 0.02811415120959282, dist_loss: 0.5052410364151001
recon_loss: 0.028114639222621918, dist_loss: 1.0222952365875244
recon_loss: 0.028113456442952156, dist_loss: 0.37701648473739624
recon_loss: 0.0281139574944973, dist_loss: 0.8053298592567444
recon_loss: 0.028113871812820435, dist_loss: 0.6276102066040039
recon_loss: 0.028112901374697685, dist_loss: 0.4760228395462036
recon_loss: 0.028113802894949913, dist_loss: 0.5543062686920166
recon_loss: 0.02811363898217678, dist_loss: 0.5708642601966858
recon_loss: 0.028113525360822678, dist_loss: 0.5625932812690735
recon_loss: 0.02811492048203945, dist_loss: 0.7423564195632935
recon_loss: 0.028115112334489822, dist_loss: 0.8436842560768127
recon_loss: 0.02811639942228794, dist_loss: 0.7316334247589111
recon_loss: 0.028118478134274483, dist_loss: 1.109919548034668
recon_loss: 0.02812102623283863, dist_loss: 0.571938693523407
recon_loss: 0.028122419491410255, dist_loss: 0.9765872955322266
recon_loss: 0.028123747557401657, dist_loss: 0.5370100140571594
recon_loss: 0.02812448889017105, dist_loss: 0.5275588631629944
recon_loss: 0.028124278411269188, dist_loss: 0.6316933631896973
recon_loss: 0.028122970834374428, dist_loss: 0.5798953175544739
recon_loss: 0.02812168374657631, dist_loss: 0.7432982921600342
recon_loss: 0.028120050206780434, dist_loss: 0.6035785675048828
recon_loss: 0.028118403628468513, dist_loss: 0.5163383483886719
recon_loss: 0.028116924688220024, dist_loss: 0.6765093803405762
recon_loss: 0.028115786612033844, dist_loss: 0.7335790991783142
recon_loss: 0.028114674612879753, dist_loss: 0.9795659780502319
recon_loss: 0.028114644810557365, dist_loss: 0.736225426197052
recon_loss: 0.028115855529904366, dist_loss: 0.3940531015396118
recon_loss: 0.028117192909121513, dist_loss: 0.37645626068115234
recon_loss: 0.028118550777435303, dist_loss: 0.5931445360183716
recon_loss: 0.02811959572136402, dist_loss: 0.6288245916366577
recon_loss: 0.02812030538916588, dist_loss: 0.6674559712409973
recon_loss: 0.028120996430516243, dist_loss: 0.7470331192016602
recon_loss: 0.028121571987867355, dist_loss: 0.7114151120185852
recon_loss: 0.028121722862124443, dist_loss: 1.363713264465332
recon_loss: 0.028121739625930786, dist_loss: 1.2459619045257568
recon_loss: 0.028122227638959885, dist_loss: 0.6861543655395508
recon_loss: 0.028121596202254295, dist_loss: 1.3862645626068115
recon_loss: 0.02812057174742222, dist_loss: 0.6075605750083923
recon_loss: 0.028119919821619987, dist_loss: 0.5437604188919067
recon_loss: 0.028117936104536057, dist_loss: 0.4263109862804413
recon_loss: 0.028116878122091293, dist_loss: 1.0028729438781738
recon_loss: 0.028115659952163696, dist_loss: 0.9032529592514038
recon_loss: 0.028114138171076775, dist_loss: 0.7707961201667786
recon_loss: 0.028113603591918945, dist_loss: 0.39545178413391113
recon_loss: 0.028112713247537613, dist_loss: 0.3269617557525635
Pre-training Epoch 77:  35%|███▌      | 129/367 [00:00<00:01, 174.51it/s]Pre-training Epoch 77:  40%|████      | 148/367 [00:00<00:01, 176.36it/s]Pre-training Epoch 77:  45%|████▌     | 166/367 [00:00<00:01, 177.01it/s]Pre-training Epoch 77:  50%|█████     | 184/367 [00:01<00:01, 177.83it/s]Pre-training Epoch 77:  55%|█████▌    | 203/367 [00:01<00:00, 178.74it/s]Pre-training Epoch 77:  60%|██████    | 221/367 [00:01<00:00, 178.71it/s]Pre-training Epoch 77:  65%|██████▌   | 239/367 [00:01<00:00, 178.93it/s]recon_loss: 0.02811332792043686, dist_loss: 0.40010160207748413
recon_loss: 0.028113212436437607, dist_loss: 0.8078696727752686
recon_loss: 0.02811359241604805, dist_loss: 1.0711363554000854
recon_loss: 0.028113650158047676, dist_loss: 0.7274041175842285
recon_loss: 0.02811318077147007, dist_loss: 1.1360598802566528
recon_loss: 0.028113670647144318, dist_loss: 0.5791918039321899
recon_loss: 0.02811318449676037, dist_loss: 0.50495445728302
recon_loss: 0.028113313019275665, dist_loss: 0.614609956741333
recon_loss: 0.028112679719924927, dist_loss: 0.5258623957633972
recon_loss: 0.028112152591347694, dist_loss: 0.8275660872459412
recon_loss: 0.028111977502703667, dist_loss: 0.8334621787071228
recon_loss: 0.028111113235354424, dist_loss: 0.6012293696403503
recon_loss: 0.028111014515161514, dist_loss: 0.5239405632019043
recon_loss: 0.028110353276133537, dist_loss: 0.5993481874465942
recon_loss: 0.028110262006521225, dist_loss: 0.8748436570167542
recon_loss: 0.028110118582844734, dist_loss: 0.6495811343193054
recon_loss: 0.028109649196267128, dist_loss: 0.37658771872520447
recon_loss: 0.02810983918607235, dist_loss: 0.6625466346740723
recon_loss: 0.028109166771173477, dist_loss: 0.33587348461151123
recon_loss: 0.028109440580010414, dist_loss: 0.33409297466278076
recon_loss: 0.028109295293688774, dist_loss: 0.9247802495956421
recon_loss: 0.028109120205044746, dist_loss: 0.42533206939697266
recon_loss: 0.028109123930335045, dist_loss: 0.5846144556999207
recon_loss: 0.028108928352594376, dist_loss: 0.5937293767929077
recon_loss: 0.02810918353497982, dist_loss: 0.9393616318702698
recon_loss: 0.02810877375304699, dist_loss: 0.8432925939559937
recon_loss: 0.028108524158596992, dist_loss: 0.8378188610076904
recon_loss: 0.028108572587370872, dist_loss: 0.5724673271179199
recon_loss: 0.028108268976211548, dist_loss: 0.6972711086273193
recon_loss: 0.028108084574341774, dist_loss: 0.7487777471542358
recon_loss: 0.028110403567552567, dist_loss: 0.6405823230743408
recon_loss: 0.028109770268201828, dist_loss: 0.47975045442581177
recon_loss: 0.02811039239168167, dist_loss: 0.6260460019111633
recon_loss: 0.028110817074775696, dist_loss: 0.6909450888633728
recon_loss: 0.028109142556786537, dist_loss: 0.8483983278274536
recon_loss: 0.028110191226005554, dist_loss: 0.594785213470459
recon_loss: 0.028108278289437294, dist_loss: 0.6646941304206848
recon_loss: 0.02810845710337162, dist_loss: 1.1178805828094482
recon_loss: 0.028108300641179085, dist_loss: 0.6772487163543701
recon_loss: 0.028107281774282455, dist_loss: 0.5810815691947937
recon_loss: 0.028107399120926857, dist_loss: 0.39405524730682373
recon_loss: 0.028108084574341774, dist_loss: 0.59809410572052
recon_loss: 0.02810879424214363, dist_loss: 0.34183138608932495
recon_loss: 0.028109543025493622, dist_loss: 0.41014114022254944
recon_loss: 0.02810974046587944, dist_loss: 0.6922664642333984
recon_loss: 0.02811053954064846, dist_loss: 1.004036545753479
recon_loss: 0.028111431747674942, dist_loss: 0.791363537311554
recon_loss: 0.028111472725868225, dist_loss: 0.4871116280555725
recon_loss: 0.028111152350902557, dist_loss: 0.41378289461135864
recon_loss: 0.02811083197593689, dist_loss: 0.5571050643920898
recon_loss: 0.028110770508646965, dist_loss: 0.7622044086456299
recon_loss: 0.02811061218380928, dist_loss: 0.935858964920044
recon_loss: 0.028109952807426453, dist_loss: 0.8924533128738403
recon_loss: 0.02810961753129959, dist_loss: 0.5088744759559631
recon_loss: 0.02810848131775856, dist_loss: 0.5112264156341553
recon_loss: 0.028107689693570137, dist_loss: 0.8824566602706909
recon_loss: 0.028106650337576866, dist_loss: 0.42738863825798035
recon_loss: 0.028105784207582474, dist_loss: 0.7563404440879822
recon_loss: 0.028105324134230614, dist_loss: 0.9590469598770142
recon_loss: 0.028105206787586212, dist_loss: 0.6172138452529907
recon_loss: 0.028104646131396294, dist_loss: 0.7344390153884888
recon_loss: 0.0281046275049448, dist_loss: 0.6744842529296875
recon_loss: 0.02810445800423622, dist_loss: 0.7117384076118469
recon_loss: 0.028104480355978012, dist_loss: 0.636541485786438
recon_loss: 0.028105266392230988, dist_loss: 0.3664325773715973
recon_loss: 0.028105000033974648, dist_loss: 0.493906170129776
recon_loss: 0.02810467779636383, dist_loss: 0.5473035573959351
recon_loss: 0.028105566278100014, dist_loss: 0.7772438526153564
recon_loss: 0.028105659410357475, dist_loss: 0.7923759818077087
recon_loss: 0.02810593694448471, dist_loss: 0.4985056519508362
recon_loss: 0.02810613065958023, dist_loss: 0.5411343574523926
recon_loss: 0.028105372563004494, dist_loss: 0.6608731746673584
recon_loss: 0.028104610741138458, dist_loss: 0.8995628952980042
recon_loss: 0.028104448691010475, dist_loss: 0.8523690700531006
recon_loss: 0.028103603050112724, dist_loss: 0.41234710812568665
recon_loss: 0.028103550896048546, dist_loss: 0.4684741795063019
recon_loss: 0.028103670105338097, dist_loss: 0.1873406320810318
recon_loss: 0.028103621676564217, dist_loss: 0.44672250747680664
recon_loss: 0.028104066848754883, dist_loss: 1.0379838943481445
recon_loss: 0.028104107826948166, dist_loss: 0.7221294641494751
recon_loss: 0.028103604912757874, dist_loss: 0.45259857177734375
recon_loss: 0.028103269636631012, dist_loss: 0.668723464012146
recon_loss: 0.028103001415729523, dist_loss: 0.349563866853714
recon_loss: 0.028102688491344452, dist_loss: 0.907822847366333
recon_loss: 0.028102539479732513, dist_loss: 0.5808447599411011
recon_loss: 0.028102748095989227, dist_loss: 0.4048979878425598
recon_loss: 0.028102677315473557, dist_loss: 0.7497690916061401
recon_loss: 0.02810334414243698, dist_loss: 0.6416807174682617
recon_loss: 0.02810485102236271, dist_loss: 0.5833593606948853
recon_loss: 0.02810545638203621, dist_loss: 0.8229674696922302
recon_loss: 0.028107156977057457, dist_loss: 1.0165603160858154
recon_loss: 0.02810882404446602, dist_loss: 0.4727858603000641
recon_loss: 0.028108980506658554, dist_loss: 0.8431490063667297
recon_loss: 0.028109172359108925, dist_loss: 0.5375611186027527
recon_loss: 0.02810872159898281, dist_loss: 0.6943007707595825
recon_loss: 0.028107427060604095, dist_loss: 0.3456604480743408
recon_loss: 0.028106888756155968, dist_loss: 0.6388665437698364
recon_loss: 0.028105754405260086, dist_loss: 0.449817419052124
recon_loss: 0.028105763718485832, dist_loss: 0.6036677360534668
recon_loss: 0.028104649856686592, dist_loss: 0.37067344784736633
recon_loss: 0.02810387685894966, dist_loss: 0.8643836975097656
recon_loss: 0.028103934600949287, dist_loss: 0.6389269828796387
recon_loss: 0.02810271456837654, dist_loss: 0.5096820592880249
recon_loss: 0.028103146702051163, dist_loss: 0.5588908791542053
recon_loss: 0.028102895244956017, dist_loss: 0.6577880382537842
recon_loss: 0.02810271643102169, dist_loss: 0.9875794649124146
recon_loss: 0.028102761134505272, dist_loss: 0.8801267147064209
recon_loss: 0.028102325275540352, dist_loss: 0.6515355706214905
recon_loss: 0.028103943914175034, dist_loss: 0.60257488489151
recon_loss: 0.028103474527597427, dist_loss: 0.4104585349559784
recon_loss: 0.028103582561016083, dist_loss: 0.6401153802871704
recon_loss: 0.028104299679398537, dist_loss: 0.6982972621917725
recon_loss: 0.028103619813919067, dist_loss: 0.6415996551513672
recon_loss: 0.028105979785323143, dist_loss: 1.0663871765136719
recon_loss: 0.028104759752750397, dist_loss: 0.38203608989715576
recon_loss: 0.028105491772294044, dist_loss: 0.4811384379863739
recon_loss: 0.028104469180107117, dist_loss: 0.6807584166526794
recon_loss: 0.028103340417146683, dist_loss: 0.5553394556045532
recon_loss: 0.028103025630116463, dist_loss: 0.8428057432174683
recon_loss: 0.02810189686715603, dist_loss: 0.5640305876731873
recon_loss: 0.028101446107029915, dist_loss: 0.719312310218811
recon_loss: 0.028100794181227684, dist_loss: 0.7204984426498413
recon_loss: 0.028100397437810898, dist_loss: 0.9962301254272461
recon_loss: 0.02810012921690941, dist_loss: 0.7608679533004761
recon_loss: 0.028099600225687027, dist_loss: 0.32761746644973755
recon_loss: 0.02809942699968815, dist_loss: 0.5595207214355469
recon_loss: 0.02809893526136875, dist_loss: 0.43332335352897644
recon_loss: 0.028098607435822487, dist_loss: 0.5294001698493958
Pre-training Epoch 77:  70%|███████   | 257/367 [00:01<00:00, 178.33it/s]Pre-training Epoch 77:  75%|███████▍  | 275/367 [00:01<00:00, 178.45it/s]Pre-training Epoch 77:  80%|███████▉  | 293/367 [00:01<00:00, 174.42it/s]Pre-training Epoch 77:  85%|████████▍ | 311/367 [00:01<00:00, 173.92it/s]Pre-training Epoch 77:  90%|████████▉ | 329/367 [00:01<00:00, 175.51it/s]Pre-training Epoch 77:  95%|█████████▍| 347/367 [00:01<00:00, 174.26it/s]Pre-training Epoch 77:  99%|█████████▉| 365/367 [00:02<00:00, 175.55it/s]Pre-training Epoch 77: 100%|██████████| 367/367 [00:02<00:00, 176.73it/s]
recon_loss: 0.028098763898015022, dist_loss: 0.7268829941749573
recon_loss: 0.028099048882722855, dist_loss: 0.35106179118156433
recon_loss: 0.02810002863407135, dist_loss: 0.6672415733337402
recon_loss: 0.02810036577284336, dist_loss: 0.56453937292099
recon_loss: 0.028101053088903427, dist_loss: 0.7013622522354126
recon_loss: 0.028101952746510506, dist_loss: 0.39569389820098877
recon_loss: 0.028102288022637367, dist_loss: 0.3865617513656616
recon_loss: 0.02810247614979744, dist_loss: 0.6637498736381531
recon_loss: 0.02810223586857319, dist_loss: 0.356228232383728
recon_loss: 0.028101474046707153, dist_loss: 0.579169511795044
recon_loss: 0.028101054951548576, dist_loss: 0.7433494329452515
recon_loss: 0.028101544827222824, dist_loss: 0.5712092518806458
recon_loss: 0.028101924806833267, dist_loss: 1.36454176902771
recon_loss: 0.02810121886432171, dist_loss: 0.9773067831993103
recon_loss: 0.028100503608584404, dist_loss: 0.6339118480682373
recon_loss: 0.028099188581109047, dist_loss: 0.7524899244308472
recon_loss: 0.028100093826651573, dist_loss: 0.483634889125824
recon_loss: 0.02809979021549225, dist_loss: 0.5077273845672607
recon_loss: 0.02809941954910755, dist_loss: 0.8107135891914368
recon_loss: 0.028100421652197838, dist_loss: 0.7904752492904663
recon_loss: 0.028098968788981438, dist_loss: 0.5629085302352905
recon_loss: 0.02810070663690567, dist_loss: 0.9148954749107361
recon_loss: 0.02810084819793701, dist_loss: 0.6735312938690186
recon_loss: 0.02810094878077507, dist_loss: 0.9925469160079956
recon_loss: 0.02810235135257244, dist_loss: 0.6506699919700623
recon_loss: 0.028101203963160515, dist_loss: 0.6209391355514526
recon_loss: 0.028101634234189987, dist_loss: 0.8433571457862854
recon_loss: 0.028101081028580666, dist_loss: 0.3247329890727997
recon_loss: 0.028099462389945984, dist_loss: 0.9200236797332764
recon_loss: 0.028098799288272858, dist_loss: 0.8449984192848206
recon_loss: 0.028099218383431435, dist_loss: 0.5066918730735779
recon_loss: 0.02809828333556652, dist_loss: 0.6533157825469971
recon_loss: 0.028098490089178085, dist_loss: 0.613176703453064
recon_loss: 0.028098290786147118, dist_loss: 0.6077901124954224
recon_loss: 0.028098594397306442, dist_loss: 0.36681973934173584
recon_loss: 0.0280991792678833, dist_loss: 0.6977121233940125
recon_loss: 0.028099725022912025, dist_loss: 0.6477552652359009
recon_loss: 0.028100065886974335, dist_loss: 0.534250795841217
recon_loss: 0.028099868446588516, dist_loss: 0.7447096109390259
recon_loss: 0.028099894523620605, dist_loss: 0.6948513984680176
recon_loss: 0.028099901974201202, dist_loss: 0.557863712310791
recon_loss: 0.02809946797788143, dist_loss: 1.0739632844924927
recon_loss: 0.02809925191104412, dist_loss: 0.8801558613777161
recon_loss: 0.02809889428317547, dist_loss: 0.6462373733520508
recon_loss: 0.0280983317643404, dist_loss: 1.101298213005066
recon_loss: 0.028097936883568764, dist_loss: 0.6845699548721313
recon_loss: 0.02809758111834526, dist_loss: 0.4423380196094513
recon_loss: 0.02809717506170273, dist_loss: 0.6691677570343018
recon_loss: 0.02809697948396206, dist_loss: 0.5725599527359009
recon_loss: 0.02809714712202549, dist_loss: 0.4816950559616089
recon_loss: 0.02809738740324974, dist_loss: 0.30384063720703125
recon_loss: 0.02809731289744377, dist_loss: 0.6537119746208191
recon_loss: 0.028097372502088547, dist_loss: 0.8676645159721375
recon_loss: 0.02809743396937847, dist_loss: 0.40041184425354004
recon_loss: 0.028097543865442276, dist_loss: 0.5887923240661621
recon_loss: 0.02809741534292698, dist_loss: 0.3865452706813812
recon_loss: 0.028097180649638176, dist_loss: 0.7105963826179504
recon_loss: 0.028097031638026237, dist_loss: 0.7606170177459717
recon_loss: 0.028096867725253105, dist_loss: 0.8632751703262329
recon_loss: 0.028097307309508324, dist_loss: 0.5117759704589844
recon_loss: 0.028097357600927353, dist_loss: 0.6492292881011963
recon_loss: 0.028097599744796753, dist_loss: 0.6425878405570984
recon_loss: 0.028097661212086678, dist_loss: 0.35391905903816223
recon_loss: 0.028097141534090042, dist_loss: 0.6248480081558228
recon_loss: 0.02809709496796131, dist_loss: 0.5853129625320435
recon_loss: 0.02809661440551281, dist_loss: 1.000227689743042
recon_loss: 0.02809642255306244, dist_loss: 0.5320227742195129
recon_loss: 0.02809627540409565, dist_loss: 0.2822941839694977
recon_loss: 0.028096307069063187, dist_loss: 1.1763886213302612
recon_loss: 0.028096145018935204, dist_loss: 0.6929758787155151
recon_loss: 0.028096187859773636, dist_loss: 0.6908349990844727
recon_loss: 0.028095733374357224, dist_loss: 0.5356431007385254
recon_loss: 0.02809550054371357, dist_loss: 0.5638325214385986
recon_loss: 0.028095224872231483, dist_loss: 0.45101895928382874
recon_loss: 0.028094839304685593, dist_loss: 0.6853005290031433
recon_loss: 0.028094427660107613, dist_loss: 0.8558743000030518
recon_loss: 0.02809436433017254, dist_loss: 0.6347659230232239
recon_loss: 0.028094271197915077, dist_loss: 0.5555099248886108
recon_loss: 0.02809431403875351, dist_loss: 0.4957870841026306
recon_loss: 0.028094623237848282, dist_loss: 0.5978769063949585
recon_loss: 0.028094664216041565, dist_loss: 0.9622858166694641
recon_loss: 0.028094980865716934, dist_loss: 0.416099488735199
recon_loss: 0.02809484861791134, dist_loss: 0.7515481114387512
recon_loss: 0.02809515781700611, dist_loss: 0.6919569969177246
recon_loss: 0.028095168992877007, dist_loss: 0.3259357511997223
recon_loss: 0.02809489332139492, dist_loss: 0.7469353675842285
recon_loss: 0.02809450775384903, dist_loss: 0.5596314668655396
recon_loss: 0.02809460088610649, dist_loss: 1.0355947017669678
recon_loss: 0.0280942190438509, dist_loss: 0.6865943670272827
recon_loss: 0.02809404768049717, dist_loss: 0.9643051028251648
recon_loss: 0.028093421831727028, dist_loss: 0.4012550115585327
recon_loss: 0.028093259781599045, dist_loss: 0.7902740240097046
recon_loss: 0.028093110769987106, dist_loss: 0.6118934154510498
recon_loss: 0.028093203902244568, dist_loss: 0.4266401529312134
recon_loss: 0.02809324488043785, dist_loss: 0.6703454852104187
recon_loss: 0.028093161061406136, dist_loss: 0.6336468458175659
recon_loss: 0.028093276545405388, dist_loss: 0.9211003184318542
recon_loss: 0.028093140572309494, dist_loss: 0.4859287738800049
recon_loss: 0.028092801570892334, dist_loss: 0.6713801622390747
recon_loss: 0.02809247188270092, dist_loss: 0.6888847947120667
recon_loss: 0.028092235326766968, dist_loss: 0.7524847388267517
recon_loss: 0.028091970831155777, dist_loss: 1.025317907333374
recon_loss: 0.028091806918382645, dist_loss: 0.8337273597717285
recon_loss: 0.028091879561543465, dist_loss: 1.1406763792037964
recon_loss: 0.028092307969927788, dist_loss: 0.908525824546814
recon_loss: 0.028093567118048668, dist_loss: 0.678675651550293
recon_loss: 0.028094807639718056, dist_loss: 0.7398815751075745
recon_loss: 0.02809523418545723, dist_loss: 0.5244208574295044
recon_loss: 0.028095757588744164, dist_loss: 0.4571624994277954
recon_loss: 0.02809567004442215, dist_loss: 0.772972822189331
recon_loss: 0.02809523232281208, dist_loss: 0.7337501645088196
Pre-training Epoch 78:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 78:   5%|▍         | 18/367 [00:00<00:02, 173.71it/s]Pre-training Epoch 78:  10%|▉         | 36/367 [00:00<00:01, 177.17it/s]Pre-training Epoch 78:  15%|█▍        | 54/367 [00:00<00:01, 172.19it/s]Pre-training Epoch 78:  20%|█▉        | 72/367 [00:00<00:01, 164.87it/s]Pre-training Epoch 78:  24%|██▍       | 89/367 [00:00<00:01, 161.34it/s]Pre-training Epoch 78:  29%|██▉       | 106/367 [00:00<00:01, 160.83it/s]Pre-training Epoch 78:  34%|███▎      | 123/367 [00:00<00:01, 161.78it/s]recon_loss: 0.02809462882578373, dist_loss: 0.6500141620635986
recon_loss: 0.028094058856368065, dist_loss: 0.3812141418457031
recon_loss: 0.028093449771404266, dist_loss: 0.5569844245910645
recon_loss: 0.028092678636312485, dist_loss: 0.36257755756378174
recon_loss: 0.028092073276638985, dist_loss: 0.3978330194950104
recon_loss: 0.028091488406062126, dist_loss: 0.751884937286377
recon_loss: 0.028090888634324074, dist_loss: 0.9442828893661499
recon_loss: 0.028090467676520348, dist_loss: 0.8779107332229614
recon_loss: 0.028089921921491623, dist_loss: 0.6097245812416077
recon_loss: 0.028089774772524834, dist_loss: 0.4205020070075989
recon_loss: 0.028089433908462524, dist_loss: 0.8181573152542114
recon_loss: 0.028089329600334167, dist_loss: 0.4942803978919983
recon_loss: 0.028089167550206184, dist_loss: 1.0170193910598755
recon_loss: 0.028089232742786407, dist_loss: 0.8808519840240479
recon_loss: 0.02808896265923977, dist_loss: 0.4731093645095825
recon_loss: 0.028089316561818123, dist_loss: 0.6651839017868042
recon_loss: 0.028089402243494987, dist_loss: 0.4890492558479309
recon_loss: 0.028089025989174843, dist_loss: 0.6539332866668701
recon_loss: 0.028089862316846848, dist_loss: 0.4415152966976166
recon_loss: 0.028088990598917007, dist_loss: 1.02461576461792
recon_loss: 0.028090165928006172, dist_loss: 0.9651930332183838
recon_loss: 0.028088921681046486, dist_loss: 0.5439008474349976
recon_loss: 0.028088543564081192, dist_loss: 0.2832988202571869
recon_loss: 0.02808859571814537, dist_loss: 0.3635064363479614
recon_loss: 0.028087656944990158, dist_loss: 0.6715197563171387
recon_loss: 0.028087792918086052, dist_loss: 0.5519058704376221
recon_loss: 0.028087938204407692, dist_loss: 0.3465591073036194
recon_loss: 0.028087077662348747, dist_loss: 0.6952944993972778
recon_loss: 0.028088044375181198, dist_loss: 0.5735259652137756
recon_loss: 0.028087342157959938, dist_loss: 0.4551692008972168
recon_loss: 0.02808721922338009, dist_loss: 0.39053237438201904
recon_loss: 0.0280881579965353, dist_loss: 0.8235588073730469
recon_loss: 0.028089486062526703, dist_loss: 0.38673150539398193
recon_loss: 0.02809053100645542, dist_loss: 0.5523804426193237
recon_loss: 0.028091106563806534, dist_loss: 1.1764150857925415
recon_loss: 0.028091566637158394, dist_loss: 0.5702154636383057
recon_loss: 0.028091253712773323, dist_loss: 0.547661304473877
recon_loss: 0.02809043601155281, dist_loss: 0.9833157062530518
recon_loss: 0.028089819476008415, dist_loss: 0.5360171794891357
recon_loss: 0.028088372200727463, dist_loss: 0.8171559572219849
recon_loss: 0.028087642043828964, dist_loss: 0.45909929275512695
recon_loss: 0.028087476268410683, dist_loss: 0.719529926776886
recon_loss: 0.028087783604860306, dist_loss: 0.4221653342247009
recon_loss: 0.028088821098208427, dist_loss: 0.5577204823493958
recon_loss: 0.028089331462979317, dist_loss: 0.5078689455986023
recon_loss: 0.028090301901102066, dist_loss: 1.020963191986084
recon_loss: 0.028089864179491997, dist_loss: 1.003488302230835
recon_loss: 0.028088722378015518, dist_loss: 0.8421448469161987
recon_loss: 0.028088005259633064, dist_loss: 0.5569312572479248
recon_loss: 0.028087282553315163, dist_loss: 0.40796416997909546
recon_loss: 0.02808685041964054, dist_loss: 0.5360750555992126
recon_loss: 0.02808648720383644, dist_loss: 0.7235012054443359
recon_loss: 0.02808619849383831, dist_loss: 1.105602741241455
recon_loss: 0.028086064383387566, dist_loss: 0.8201073408126831
recon_loss: 0.028085876256227493, dist_loss: 0.4488297700881958
recon_loss: 0.028085697442293167, dist_loss: 0.7777702808380127
recon_loss: 0.028085393831133842, dist_loss: 0.8335249423980713
recon_loss: 0.02808518335223198, dist_loss: 0.8759328722953796
recon_loss: 0.028085168451070786, dist_loss: 0.5425325036048889
recon_loss: 0.02808513678610325, dist_loss: 0.8047500848770142
recon_loss: 0.02808493934571743, dist_loss: 0.5642479658126831
recon_loss: 0.028085319325327873, dist_loss: 0.5779958367347717
recon_loss: 0.028084423393011093, dist_loss: 1.146822214126587
recon_loss: 0.02808431163430214, dist_loss: 0.8126554489135742
recon_loss: 0.028084268793463707, dist_loss: 0.6857150197029114
recon_loss: 0.02808418497443199, dist_loss: 0.2836821973323822
recon_loss: 0.028084145858883858, dist_loss: 0.579688310623169
recon_loss: 0.02808416821062565, dist_loss: 0.7783709168434143
recon_loss: 0.028084268793463707, dist_loss: 0.41106346249580383
recon_loss: 0.028084389865398407, dist_loss: 0.526896059513092
recon_loss: 0.028084630146622658, dist_loss: 0.6554375886917114
recon_loss: 0.02808459661900997, dist_loss: 0.9843767285346985
recon_loss: 0.02808440662920475, dist_loss: 0.7289155721664429
recon_loss: 0.02808414027094841, dist_loss: 0.5454117059707642
recon_loss: 0.028083765879273415, dist_loss: 1.033170223236084
recon_loss: 0.02808338589966297, dist_loss: 0.45343947410583496
recon_loss: 0.028083089739084244, dist_loss: 0.37329962849617004
recon_loss: 0.028082946315407753, dist_loss: 0.7769591808319092
recon_loss: 0.028082702308893204, dist_loss: 0.40884971618652344
recon_loss: 0.028082406148314476, dist_loss: 0.5821347832679749
recon_loss: 0.028082385659217834, dist_loss: 0.5715945959091187
recon_loss: 0.028082406148314476, dist_loss: 0.3662968575954437
recon_loss: 0.02808229811489582, dist_loss: 0.757926881313324
recon_loss: 0.028082387521862984, dist_loss: 0.6737662553787231
recon_loss: 0.028082339093089104, dist_loss: 0.7460790872573853
recon_loss: 0.02808239869773388, dist_loss: 0.5963186025619507
recon_loss: 0.028082437813282013, dist_loss: 0.6351194977760315
recon_loss: 0.028082363307476044, dist_loss: 0.7135488986968994
recon_loss: 0.028082331642508507, dist_loss: 0.7544199228286743
recon_loss: 0.02808234468102455, dist_loss: 0.621343195438385
recon_loss: 0.028082353994250298, dist_loss: 0.5943506956100464
recon_loss: 0.02808254025876522, dist_loss: 0.34477072954177856
recon_loss: 0.028082536533474922, dist_loss: 0.7211579084396362
recon_loss: 0.028082165867090225, dist_loss: 0.38869595527648926
recon_loss: 0.028081947937607765, dist_loss: 0.43500256538391113
recon_loss: 0.028081772848963737, dist_loss: 1.3568696975708008
recon_loss: 0.028081586584448814, dist_loss: 0.8166851997375488
recon_loss: 0.02808116003870964, dist_loss: 0.4657289385795593
recon_loss: 0.028081104159355164, dist_loss: 0.5079964995384216
recon_loss: 0.028080573305487633, dist_loss: 0.9560220241546631
recon_loss: 0.02808046154677868, dist_loss: 0.5979111194610596
recon_loss: 0.028080299496650696, dist_loss: 0.643206000328064
recon_loss: 0.028080211952328682, dist_loss: 0.46337082982063293
recon_loss: 0.028080547228455544, dist_loss: 0.6680665612220764
recon_loss: 0.028080295771360397, dist_loss: 0.860826849937439
recon_loss: 0.028080260381102562, dist_loss: 0.4930141866207123
recon_loss: 0.0280806552618742, dist_loss: 0.49860379099845886
recon_loss: 0.028080519288778305, dist_loss: 0.8539729714393616
recon_loss: 0.028080623596906662, dist_loss: 0.594414234161377
recon_loss: 0.028082026168704033, dist_loss: 0.6449660062789917
recon_loss: 0.028081443160772324, dist_loss: 0.8888373374938965
recon_loss: 0.028082020580768585, dist_loss: 0.6720749139785767
recon_loss: 0.028082817792892456, dist_loss: 0.48649609088897705
recon_loss: 0.02808210253715515, dist_loss: 0.5487505197525024
recon_loss: 0.028082091361284256, dist_loss: 0.582245409488678
recon_loss: 0.02808132953941822, dist_loss: 0.5122648477554321
recon_loss: 0.028080949559807777, dist_loss: 0.5216231346130371
recon_loss: 0.028080638498067856, dist_loss: 0.5667697191238403
recon_loss: 0.028080055490136147, dist_loss: 0.4378296434879303
recon_loss: 0.028080414980649948, dist_loss: 0.49276021122932434
recon_loss: 0.02808014489710331, dist_loss: 0.64471036195755
recon_loss: 0.028079913929104805, dist_loss: 0.698935329914093
recon_loss: 0.028079956769943237, dist_loss: 0.7716531753540039
recon_loss: 0.028079558163881302, dist_loss: 0.7295971512794495
recon_loss: 0.028079383075237274, dist_loss: 0.7895036935806274
recon_loss: 0.028080055490136147, dist_loss: 0.42759501934051514
recon_loss: 0.028080549091100693, dist_loss: 0.9498217701911926
recon_loss: 0.028080658987164497, dist_loss: 0.9054677486419678
Pre-training Epoch 78:  38%|███▊      | 140/367 [00:00<00:01, 162.32it/s]Pre-training Epoch 78:  43%|████▎     | 157/367 [00:00<00:01, 163.21it/s]Pre-training Epoch 78:  47%|████▋     | 174/367 [00:01<00:01, 163.90it/s]Pre-training Epoch 78:  52%|█████▏    | 191/367 [00:01<00:01, 164.33it/s]Pre-training Epoch 78:  57%|█████▋    | 208/367 [00:01<00:00, 163.02it/s]Pre-training Epoch 78:  61%|██████▏   | 225/367 [00:01<00:00, 158.97it/s]Pre-training Epoch 78:  66%|██████▌   | 241/367 [00:01<00:00, 158.00it/s]recon_loss: 0.028080331161618233, dist_loss: 0.8806109428405762
recon_loss: 0.028080033138394356, dist_loss: 0.4692213833332062
recon_loss: 0.028079785406589508, dist_loss: 0.9554394483566284
recon_loss: 0.028079528361558914, dist_loss: 0.5307750105857849
recon_loss: 0.028079114854335785, dist_loss: 0.3840699791908264
recon_loss: 0.028078682720661163, dist_loss: 0.744076669216156
recon_loss: 0.02807878702878952, dist_loss: 0.8402488827705383
recon_loss: 0.02807949110865593, dist_loss: 0.7191036343574524
recon_loss: 0.028080539777874947, dist_loss: 0.4212416410446167
recon_loss: 0.02808070369064808, dist_loss: 0.5810378789901733
recon_loss: 0.02808094210922718, dist_loss: 0.8346424102783203
recon_loss: 0.028081076219677925, dist_loss: 0.5069831013679504
recon_loss: 0.028081396594643593, dist_loss: 0.651330828666687
recon_loss: 0.02808118239045143, dist_loss: 0.8613423109054565
recon_loss: 0.028081318363547325, dist_loss: 0.9753627777099609
recon_loss: 0.028080560266971588, dist_loss: 0.8190300464630127
recon_loss: 0.028079932555556297, dist_loss: 0.7824211120605469
recon_loss: 0.02807939238846302, dist_loss: 0.5970624685287476
recon_loss: 0.028079191222786903, dist_loss: 0.6919595003128052
recon_loss: 0.028079167008399963, dist_loss: 0.5157480239868164
recon_loss: 0.028079023584723473, dist_loss: 0.8712355494499207
recon_loss: 0.028079524636268616, dist_loss: 0.38576775789260864
recon_loss: 0.028079932555556297, dist_loss: 0.4241611659526825
recon_loss: 0.028080685064196587, dist_loss: 1.4762636423110962
recon_loss: 0.028081649914383888, dist_loss: 0.5229853391647339
recon_loss: 0.028082121163606644, dist_loss: 0.5558559894561768
recon_loss: 0.028082603588700294, dist_loss: 0.593891978263855
recon_loss: 0.028082791715860367, dist_loss: 0.47821953892707825
recon_loss: 0.028082387521862984, dist_loss: 0.923656702041626
recon_loss: 0.028082311153411865, dist_loss: 0.8763725757598877
recon_loss: 0.02808193303644657, dist_loss: 0.5512233376502991
recon_loss: 0.028081759810447693, dist_loss: 1.0089173316955566
recon_loss: 0.028080621734261513, dist_loss: 0.36316895484924316
recon_loss: 0.028079936280846596, dist_loss: 0.6057578325271606
recon_loss: 0.028079191222786903, dist_loss: 0.8821108341217041
recon_loss: 0.028078272938728333, dist_loss: 0.72575443983078
recon_loss: 0.028078168630599976, dist_loss: 0.8020091652870178
recon_loss: 0.02807772159576416, dist_loss: 0.723421573638916
recon_loss: 0.02807697281241417, dist_loss: 0.2581791281700134
recon_loss: 0.028077781200408936, dist_loss: 0.7969979047775269
recon_loss: 0.028077220544219017, dist_loss: 0.3979482650756836
recon_loss: 0.02807696908712387, dist_loss: 0.6158663630485535
recon_loss: 0.02807754836976528, dist_loss: 0.4117811918258667
recon_loss: 0.028078824281692505, dist_loss: 0.9155876636505127
recon_loss: 0.02807997167110443, dist_loss: 0.8811545372009277
recon_loss: 0.02808116003870964, dist_loss: 0.8257272243499756
recon_loss: 0.028082985430955887, dist_loss: 0.6033660769462585
recon_loss: 0.028084777295589447, dist_loss: 0.4076652228832245
recon_loss: 0.028086291626095772, dist_loss: 0.44094136357307434
recon_loss: 0.028086774051189423, dist_loss: 0.4376487731933594
recon_loss: 0.028086788952350616, dist_loss: 0.9128499031066895
recon_loss: 0.02808692306280136, dist_loss: 0.6380558013916016
recon_loss: 0.028086669743061066, dist_loss: 0.8724320530891418
recon_loss: 0.028086023405194283, dist_loss: 1.016388177871704
recon_loss: 0.02808479778468609, dist_loss: 0.5899323225021362
recon_loss: 0.02808350697159767, dist_loss: 0.6205283403396606
recon_loss: 0.02808184176683426, dist_loss: 1.3963820934295654
recon_loss: 0.02808031439781189, dist_loss: 0.7080115079879761
recon_loss: 0.028079884126782417, dist_loss: 0.923310399055481
recon_loss: 0.028078153729438782, dist_loss: 0.6815454959869385
recon_loss: 0.028078295290470123, dist_loss: 0.8596166372299194
recon_loss: 0.02807750552892685, dist_loss: 0.5000209808349609
recon_loss: 0.02807757444679737, dist_loss: 0.5402784943580627
recon_loss: 0.028078023344278336, dist_loss: 0.7524243593215942
recon_loss: 0.02807774394750595, dist_loss: 0.5578130483627319
recon_loss: 0.028079451993107796, dist_loss: 0.34698590636253357
recon_loss: 0.028078744187951088, dist_loss: 0.7767118215560913
recon_loss: 0.028080549091100693, dist_loss: 0.3354092240333557
recon_loss: 0.028079746291041374, dist_loss: 0.4107264280319214
recon_loss: 0.028080370277166367, dist_loss: 0.7419731020927429
recon_loss: 0.028079871088266373, dist_loss: 0.7595688104629517
recon_loss: 0.02807912603020668, dist_loss: 0.4762793779373169
recon_loss: 0.028079763054847717, dist_loss: 0.7619890570640564
recon_loss: 0.028079628944396973, dist_loss: 0.6411004066467285
recon_loss: 0.028079399839043617, dist_loss: 0.6238980293273926
recon_loss: 0.028079744428396225, dist_loss: 1.153062105178833
recon_loss: 0.028079794719815254, dist_loss: 0.6722286939620972
recon_loss: 0.028079716488718987, dist_loss: 0.8208903670310974
recon_loss: 0.028079334646463394, dist_loss: 0.5492184162139893
recon_loss: 0.028077809140086174, dist_loss: 0.48113906383514404
recon_loss: 0.02807767689228058, dist_loss: 0.7840985059738159
recon_loss: 0.02807644009590149, dist_loss: 0.5314723253250122
recon_loss: 0.028076015412807465, dist_loss: 0.7931442856788635
recon_loss: 0.028075382113456726, dist_loss: 0.5674142837524414
recon_loss: 0.028074301779270172, dist_loss: 1.0694141387939453
recon_loss: 0.028073757886886597, dist_loss: 0.5133090615272522
recon_loss: 0.02807352878153324, dist_loss: 0.6011587977409363
recon_loss: 0.028073225170373917, dist_loss: 0.9538180232048035
recon_loss: 0.028073402121663094, dist_loss: 0.4229561984539032
recon_loss: 0.028074031695723534, dist_loss: 0.6410508751869202
recon_loss: 0.028074437752366066, dist_loss: 0.6290242075920105
recon_loss: 0.028075411915779114, dist_loss: 0.30021238327026367
recon_loss: 0.028076540678739548, dist_loss: 0.6568725109100342
recon_loss: 0.028077345341444016, dist_loss: 0.45605993270874023
recon_loss: 0.0280771441757679, dist_loss: 0.42654886841773987
recon_loss: 0.02807692252099514, dist_loss: 0.7916476726531982
recon_loss: 0.028076456859707832, dist_loss: 0.7459207773208618
recon_loss: 0.028076203539967537, dist_loss: 0.46283113956451416
recon_loss: 0.028075437992811203, dist_loss: 0.47776296734809875
recon_loss: 0.02807520143687725, dist_loss: 0.967993974685669
recon_loss: 0.028075112029910088, dist_loss: 1.0042744874954224
recon_loss: 0.02807498909533024, dist_loss: 0.6457984447479248
recon_loss: 0.02807442843914032, dist_loss: 0.4480415880680084
recon_loss: 0.028073972091078758, dist_loss: 0.8112831711769104
recon_loss: 0.02807343378663063, dist_loss: 0.8547155857086182
recon_loss: 0.028073150664567947, dist_loss: 0.741452693939209
recon_loss: 0.028072688728570938, dist_loss: 0.7700040340423584
recon_loss: 0.028072407469153404, dist_loss: 0.42054903507232666
recon_loss: 0.028072083368897438, dist_loss: 0.7025867700576782
recon_loss: 0.028071824461221695, dist_loss: 0.9257938861846924
recon_loss: 0.028071774169802666, dist_loss: 0.5399630069732666
recon_loss: 0.028071586042642593, dist_loss: 0.9145925045013428
recon_loss: 0.028071563690900803, dist_loss: 0.7368350625038147
recon_loss: 0.028071869164705276, dist_loss: 0.6247449517250061
recon_loss: 0.02807326801121235, dist_loss: 0.45395535230636597
recon_loss: 0.028074029833078384, dist_loss: 0.41084688901901245
recon_loss: 0.028075193986296654, dist_loss: 0.9952354431152344
recon_loss: 0.028075484558939934, dist_loss: 0.5764094591140747
recon_loss: 0.028075339272618294, dist_loss: 1.0041489601135254
recon_loss: 0.028076352551579475, dist_loss: 1.0071008205413818
recon_loss: 0.028077151626348495, dist_loss: 1.1596988439559937
recon_loss: 0.028077613562345505, dist_loss: 0.551835298538208
recon_loss: 0.02807808667421341, dist_loss: 0.9042072296142578
recon_loss: 0.028077028691768646, dist_loss: 0.39968395233154297
recon_loss: 0.02807711623609066, dist_loss: 0.6557152271270752
recon_loss: 0.028076497837901115, dist_loss: 0.9030112028121948
recon_loss: 0.028075899928808212, dist_loss: 0.9411880970001221
recon_loss: 0.02807537280023098, dist_loss: 0.6362402439117432
Pre-training Epoch 78:  70%|███████   | 257/367 [00:01<00:00, 157.15it/s]Pre-training Epoch 78:  74%|███████▍  | 273/367 [00:01<00:00, 156.74it/s]Pre-training Epoch 78:  79%|███████▊  | 289/367 [00:01<00:00, 156.37it/s]Pre-training Epoch 78:  83%|████████▎ | 305/367 [00:01<00:00, 156.14it/s]Pre-training Epoch 78:  87%|████████▋ | 321/367 [00:01<00:00, 156.04it/s]Pre-training Epoch 78:  92%|█████████▏| 337/367 [00:02<00:00, 155.78it/s]Pre-training Epoch 78:  96%|█████████▌| 353/367 [00:02<00:00, 155.80it/s]Pre-training Epoch 78: 100%|██████████| 367/367 [00:02<00:00, 160.40it/s]
recon_loss: 0.0280745979398489, dist_loss: 0.49093788862228394
recon_loss: 0.0280744731426239, dist_loss: 0.49072927236557007
recon_loss: 0.028073672205209732, dist_loss: 0.5341033935546875
recon_loss: 0.028073200955986977, dist_loss: 0.6671638488769531
recon_loss: 0.028072770684957504, dist_loss: 0.6592230200767517
recon_loss: 0.028072042390704155, dist_loss: 0.5569604635238647
recon_loss: 0.028071697801351547, dist_loss: 0.6375324130058289
recon_loss: 0.02806996926665306, dist_loss: 0.5291193723678589
recon_loss: 0.028070606291294098, dist_loss: 0.7708302140235901
recon_loss: 0.02806972526013851, dist_loss: 0.7530458569526672
recon_loss: 0.02806929498910904, dist_loss: 0.7096735239028931
recon_loss: 0.028070634230971336, dist_loss: 0.5127735137939453
recon_loss: 0.028070097789168358, dist_loss: 0.2924143373966217
recon_loss: 0.028071552515029907, dist_loss: 0.6113459467887878
recon_loss: 0.028071587905287743, dist_loss: 1.0400316715240479
recon_loss: 0.028071774169802666, dist_loss: 0.7941457033157349
recon_loss: 0.028071880340576172, dist_loss: 0.8223253488540649
recon_loss: 0.028070291504263878, dist_loss: 0.5786336660385132
recon_loss: 0.028070835396647453, dist_loss: 0.39297983050346375
recon_loss: 0.02807009592652321, dist_loss: 0.5597968101501465
recon_loss: 0.02806980349123478, dist_loss: 0.4693567156791687
recon_loss: 0.028070297092199326, dist_loss: 0.7314633727073669
recon_loss: 0.02806907892227173, dist_loss: 0.42170286178588867
recon_loss: 0.02806931361556053, dist_loss: 0.4361148476600647
recon_loss: 0.02806880697607994, dist_loss: 0.43656665086746216
recon_loss: 0.028068548068404198, dist_loss: 0.3817887306213379
recon_loss: 0.028068970888853073, dist_loss: 1.0885850191116333
recon_loss: 0.028068512678146362, dist_loss: 0.6565614938735962
recon_loss: 0.02806776948273182, dist_loss: 0.40553659200668335
recon_loss: 0.02806869149208069, dist_loss: 0.386867493391037
recon_loss: 0.02806752361357212, dist_loss: 0.905515730381012
recon_loss: 0.02806803397834301, dist_loss: 0.7916284799575806
recon_loss: 0.028067875653505325, dist_loss: 0.38051992654800415
recon_loss: 0.0280668493360281, dist_loss: 0.588851273059845
recon_loss: 0.0280673298984766, dist_loss: 0.2513187527656555
recon_loss: 0.028066541999578476, dist_loss: 0.9963138699531555
recon_loss: 0.02806651033461094, dist_loss: 0.8978309631347656
recon_loss: 0.028066648170351982, dist_loss: 0.5196344256401062
recon_loss: 0.028066065162420273, dist_loss: 0.5014246702194214
recon_loss: 0.028066391125321388, dist_loss: 0.46828410029411316
recon_loss: 0.02806585468351841, dist_loss: 0.5805068016052246
recon_loss: 0.028065793216228485, dist_loss: 1.0765703916549683
recon_loss: 0.02806592918932438, dist_loss: 0.1833285093307495
recon_loss: 0.02806590311229229, dist_loss: 0.6350273489952087
recon_loss: 0.02806629054248333, dist_loss: 0.48162686824798584
recon_loss: 0.028066398575901985, dist_loss: 0.4135782718658447
recon_loss: 0.028065720573067665, dist_loss: 0.822709321975708
recon_loss: 0.028065094724297523, dist_loss: 1.063917636871338
recon_loss: 0.028064880520105362, dist_loss: 1.1534202098846436
recon_loss: 0.028064992278814316, dist_loss: 0.4913692772388458
recon_loss: 0.02806512825191021, dist_loss: 0.7928564548492432
recon_loss: 0.028065292164683342, dist_loss: 0.7695783376693726
recon_loss: 0.0280647911131382, dist_loss: 0.7909263372421265
recon_loss: 0.028064731508493423, dist_loss: 1.3463811874389648
recon_loss: 0.028065016493201256, dist_loss: 0.4986805319786072
recon_loss: 0.02806449867784977, dist_loss: 0.4251408576965332
recon_loss: 0.02806445024907589, dist_loss: 0.39884552359580994
recon_loss: 0.028063880279660225, dist_loss: 0.7013853192329407
recon_loss: 0.028063567355275154, dist_loss: 0.2672898769378662
recon_loss: 0.028063733130693436, dist_loss: 0.8585689067840576
recon_loss: 0.02806304208934307, dist_loss: 0.8015537261962891
recon_loss: 0.028063291683793068, dist_loss: 0.482383668422699
recon_loss: 0.028063183650374413, dist_loss: 0.40420275926589966
recon_loss: 0.028063243255019188, dist_loss: 0.5153211951255798
recon_loss: 0.028063440695405006, dist_loss: 0.5876638889312744
recon_loss: 0.02806340903043747, dist_loss: 0.5148934721946716
recon_loss: 0.02806444652378559, dist_loss: 0.6412010788917542
recon_loss: 0.028063613921403885, dist_loss: 0.5964027643203735
recon_loss: 0.028064431622624397, dist_loss: 0.6707791090011597
recon_loss: 0.028063824400305748, dist_loss: 0.899795413017273
recon_loss: 0.028063669800758362, dist_loss: 0.39137622714042664
recon_loss: 0.028064509853720665, dist_loss: 0.4853140115737915
recon_loss: 0.02806372009217739, dist_loss: 0.8600456714630127
recon_loss: 0.028064608573913574, dist_loss: 0.9681033492088318
recon_loss: 0.028063764795660973, dist_loss: 0.4828009605407715
recon_loss: 0.028064414858818054, dist_loss: 0.8297409415245056
recon_loss: 0.02806398645043373, dist_loss: 0.43244117498397827
recon_loss: 0.02806376852095127, dist_loss: 0.5918928384780884
recon_loss: 0.028063476085662842, dist_loss: 1.1677570343017578
recon_loss: 0.028063369914889336, dist_loss: 0.20127063989639282
recon_loss: 0.028064318001270294, dist_loss: 0.7593827247619629
recon_loss: 0.02806415781378746, dist_loss: 0.43457746505737305
recon_loss: 0.028063567355275154, dist_loss: 0.786250114440918
recon_loss: 0.02806290052831173, dist_loss: 0.4776526391506195
recon_loss: 0.02806251496076584, dist_loss: 0.9027686715126038
recon_loss: 0.028062336146831512, dist_loss: 0.6582715511322021
recon_loss: 0.028062190860509872, dist_loss: 0.31021010875701904
recon_loss: 0.028061697259545326, dist_loss: 0.6361895799636841
recon_loss: 0.02806149236857891, dist_loss: 1.1229685544967651
recon_loss: 0.02806118130683899, dist_loss: 0.7522054314613342
recon_loss: 0.02806096151471138, dist_loss: 0.37526392936706543
recon_loss: 0.028061209246516228, dist_loss: 0.677747368812561
recon_loss: 0.02806098759174347, dist_loss: 0.5714091658592224
recon_loss: 0.028061429038643837, dist_loss: 0.4344353675842285
recon_loss: 0.02806183136999607, dist_loss: 0.36322692036628723
recon_loss: 0.028061455115675926, dist_loss: 0.634253978729248
recon_loss: 0.02806156314909458, dist_loss: 0.5978577136993408
recon_loss: 0.028062043711543083, dist_loss: 0.9155886769294739
recon_loss: 0.028062209486961365, dist_loss: 0.968796968460083
recon_loss: 0.02806316874921322, dist_loss: 0.9592804908752441
recon_loss: 0.028063710778951645, dist_loss: 0.5162612199783325
recon_loss: 0.02806498482823372, dist_loss: 0.46554574370384216
recon_loss: 0.028066253289580345, dist_loss: 0.5124494433403015
recon_loss: 0.02806583046913147, dist_loss: 1.1668773889541626
recon_loss: 0.02806732803583145, dist_loss: 0.5706641674041748
recon_loss: 0.02806740254163742, dist_loss: 0.5200616121292114
recon_loss: 0.02806743048131466, dist_loss: 0.6187256574630737
recon_loss: 0.02806697227060795, dist_loss: 0.8459376096725464
recon_loss: 0.02806575782597065, dist_loss: 0.6201838850975037
recon_loss: 0.028064755722880363, dist_loss: 1.142045259475708
recon_loss: 0.028063440695405006, dist_loss: 0.23482751846313477
Pre-training Epoch 79:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 79:   5%|▌         | 20/367 [00:00<00:01, 190.57it/s]Pre-training Epoch 79:  11%|█         | 40/367 [00:00<00:01, 191.47it/s]Pre-training Epoch 79:  16%|█▋        | 60/367 [00:00<00:01, 191.93it/s]Pre-training Epoch 79:  22%|██▏       | 80/367 [00:00<00:01, 192.19it/s]Pre-training Epoch 79:  27%|██▋       | 100/367 [00:00<00:01, 190.52it/s]Pre-training Epoch 79:  33%|███▎      | 120/367 [00:00<00:01, 192.00it/s]recon_loss: 0.028063669800758362, dist_loss: 0.7370790839195251
recon_loss: 0.02806202508509159, dist_loss: 0.523584246635437
recon_loss: 0.028062758967280388, dist_loss: 0.9227356910705566
recon_loss: 0.028062786906957626, dist_loss: 0.9017000198364258
recon_loss: 0.02806299366056919, dist_loss: 0.48857006430625916
recon_loss: 0.02806445024907589, dist_loss: 0.6409671902656555
recon_loss: 0.028063207864761353, dist_loss: 0.6960830688476562
recon_loss: 0.028064224869012833, dist_loss: 0.37671905755996704
recon_loss: 0.028063412755727768, dist_loss: 0.3898935616016388
recon_loss: 0.0280633345246315, dist_loss: 0.6598608493804932
recon_loss: 0.028063418343663216, dist_loss: 0.528235912322998
recon_loss: 0.02806272730231285, dist_loss: 0.4409840703010559
recon_loss: 0.028063397854566574, dist_loss: 0.5149431824684143
recon_loss: 0.028063014149665833, dist_loss: 0.6253576874732971
recon_loss: 0.028063146397471428, dist_loss: 0.5749974846839905
recon_loss: 0.028062008321285248, dist_loss: 0.6816819310188293
recon_loss: 0.02806120365858078, dist_loss: 0.38037025928497314
recon_loss: 0.028061646968126297, dist_loss: 0.4851521849632263
recon_loss: 0.028060173615813255, dist_loss: 0.5008153915405273
recon_loss: 0.02806086465716362, dist_loss: 0.4058951437473297
recon_loss: 0.02805933728814125, dist_loss: 0.4321390688419342
recon_loss: 0.028058402240276337, dist_loss: 0.7417992353439331
recon_loss: 0.02805887535214424, dist_loss: 0.8592936992645264
recon_loss: 0.028058156371116638, dist_loss: 0.5305702686309814
recon_loss: 0.028058338910341263, dist_loss: 0.44892364740371704
recon_loss: 0.028058486059308052, dist_loss: 1.1793574094772339
recon_loss: 0.02805802784860134, dist_loss: 0.48911571502685547
recon_loss: 0.02805824764072895, dist_loss: 0.3911318778991699
recon_loss: 0.028057992458343506, dist_loss: 0.35253065824508667
recon_loss: 0.02805723436176777, dist_loss: 0.649791955947876
recon_loss: 0.028058499097824097, dist_loss: 0.4039570093154907
recon_loss: 0.028058072552084923, dist_loss: 0.5516653060913086
recon_loss: 0.028058642521500587, dist_loss: 0.7393772602081299
recon_loss: 0.028059396892786026, dist_loss: 0.47790420055389404
recon_loss: 0.028058240190148354, dist_loss: 0.5239508152008057
recon_loss: 0.02805934101343155, dist_loss: 0.5861281156539917
recon_loss: 0.02805902808904648, dist_loss: 0.524573564529419
recon_loss: 0.028059309348464012, dist_loss: 0.768516480922699
recon_loss: 0.028059495612978935, dist_loss: 0.38614219427108765
recon_loss: 0.028057826682925224, dist_loss: 0.8713066577911377
recon_loss: 0.028058312833309174, dist_loss: 0.8988138437271118
recon_loss: 0.028056524693965912, dist_loss: 0.8210794925689697
recon_loss: 0.028056496754288673, dist_loss: 0.4885176420211792
recon_loss: 0.028056684881448746, dist_loss: 0.9581217169761658
recon_loss: 0.028056658804416656, dist_loss: 0.5525087118148804
recon_loss: 0.028056474402546883, dist_loss: 0.6546696424484253
recon_loss: 0.02805596962571144, dist_loss: 0.377766489982605
recon_loss: 0.028056133538484573, dist_loss: 0.7391763925552368
recon_loss: 0.028056178241968155, dist_loss: 1.3561899662017822
recon_loss: 0.028055794537067413, dist_loss: 0.8192232847213745
recon_loss: 0.02805561013519764, dist_loss: 0.6495206952095032
recon_loss: 0.028055837377905846, dist_loss: 0.8200118541717529
recon_loss: 0.02805604413151741, dist_loss: 0.6816453337669373
recon_loss: 0.028056550770998, dist_loss: 0.5310743451118469
recon_loss: 0.028057720512151718, dist_loss: 1.339372992515564
recon_loss: 0.028058812022209167, dist_loss: 0.8060022592544556
recon_loss: 0.028059205040335655, dist_loss: 0.6527243256568909
recon_loss: 0.02805919758975506, dist_loss: 0.5919459462165833
recon_loss: 0.02805957943201065, dist_loss: 0.906593918800354
recon_loss: 0.028058789670467377, dist_loss: 0.8691213130950928
recon_loss: 0.028058532625436783, dist_loss: 0.46863889694213867
recon_loss: 0.028058074414730072, dist_loss: 0.5750016570091248
recon_loss: 0.02805776335299015, dist_loss: 1.2391314506530762
recon_loss: 0.02805694192647934, dist_loss: 0.4455830454826355
recon_loss: 0.02805672213435173, dist_loss: 0.6163480281829834
recon_loss: 0.02805587276816368, dist_loss: 0.63118577003479
recon_loss: 0.028055554255843163, dist_loss: 1.2567975521087646
recon_loss: 0.028055282309651375, dist_loss: 0.4749786853790283
recon_loss: 0.028054552152752876, dist_loss: 0.5947183966636658
recon_loss: 0.028054390102624893, dist_loss: 0.5505938529968262
recon_loss: 0.028054330497980118, dist_loss: 1.0217314958572388
recon_loss: 0.02805420011281967, dist_loss: 0.7060506343841553
recon_loss: 0.028054185211658478, dist_loss: 0.5226309895515442
recon_loss: 0.028053687885403633, dist_loss: 0.5229443907737732
recon_loss: 0.028053462505340576, dist_loss: 0.9120111465454102
recon_loss: 0.028053365647792816, dist_loss: 0.6389362812042236
recon_loss: 0.028053322806954384, dist_loss: 0.5858640074729919
recon_loss: 0.028053399175405502, dist_loss: 0.4128718674182892
recon_loss: 0.028053652495145798, dist_loss: 0.7990862131118774
recon_loss: 0.02805366925895214, dist_loss: 0.38442233204841614
recon_loss: 0.028054216876626015, dist_loss: 0.4697534441947937
recon_loss: 0.028055259957909584, dist_loss: 0.7777764797210693
recon_loss: 0.02805665321648121, dist_loss: 0.577123761177063
recon_loss: 0.02805798500776291, dist_loss: 0.3987351655960083
recon_loss: 0.028059815987944603, dist_loss: 0.695367693901062
recon_loss: 0.028060197830200195, dist_loss: 0.412309467792511
recon_loss: 0.028060749173164368, dist_loss: 0.8287911415100098
recon_loss: 0.028060145676136017, dist_loss: 0.6718025207519531
recon_loss: 0.02805960737168789, dist_loss: 0.6920886039733887
recon_loss: 0.028059478849172592, dist_loss: 0.7005784511566162
recon_loss: 0.02805858850479126, dist_loss: 0.24562767148017883
recon_loss: 0.02805776335299015, dist_loss: 0.6976320743560791
recon_loss: 0.028056245297193527, dist_loss: 0.5861508250236511
recon_loss: 0.028055371716618538, dist_loss: 0.4800803065299988
recon_loss: 0.028055010363459587, dist_loss: 0.6091710329055786
recon_loss: 0.028054993599653244, dist_loss: 0.7437946796417236
recon_loss: 0.028055109083652496, dist_loss: 0.5265284180641174
recon_loss: 0.028055299073457718, dist_loss: 0.9033682346343994
recon_loss: 0.02805441804230213, dist_loss: 0.7734654545783997
recon_loss: 0.02805423177778721, dist_loss: 0.4335952699184418
recon_loss: 0.02805420383810997, dist_loss: 0.6157971620559692
recon_loss: 0.028053663671016693, dist_loss: 0.5023559331893921
recon_loss: 0.028053682297468185, dist_loss: 0.506104052066803
recon_loss: 0.028054174035787582, dist_loss: 0.8231383562088013
recon_loss: 0.028055336326360703, dist_loss: 0.38561123609542847
recon_loss: 0.02805515006184578, dist_loss: 0.4578530788421631
recon_loss: 0.028054894879460335, dist_loss: 0.5540825128555298
recon_loss: 0.02805444970726967, dist_loss: 0.5476371049880981
recon_loss: 0.028053931891918182, dist_loss: 0.3041635751724243
recon_loss: 0.028054099529981613, dist_loss: 0.38657769560813904
recon_loss: 0.028052791953086853, dist_loss: 0.8992688059806824
recon_loss: 0.02805180847644806, dist_loss: 0.612417995929718
recon_loss: 0.02805161289870739, dist_loss: 0.7496599555015564
recon_loss: 0.0280515905469656, dist_loss: 0.5121277570724487
recon_loss: 0.0280519500374794, dist_loss: 0.9354838132858276
recon_loss: 0.028051486238837242, dist_loss: 0.6456514596939087
recon_loss: 0.0280511062592268, dist_loss: 0.4960310757160187
recon_loss: 0.028051095083355904, dist_loss: 0.8199963569641113
recon_loss: 0.028051691129803658, dist_loss: 1.1239984035491943
recon_loss: 0.02805183082818985, dist_loss: 0.6247997283935547
recon_loss: 0.028052086010575294, dist_loss: 1.0949004888534546
recon_loss: 0.028052469715476036, dist_loss: 0.7015975117683411
recon_loss: 0.02805306576192379, dist_loss: 0.8502689599990845
recon_loss: 0.028053274378180504, dist_loss: 0.7374701499938965
recon_loss: 0.02805277518928051, dist_loss: 0.29923492670059204
recon_loss: 0.028052834793925285, dist_loss: 0.5774675607681274
recon_loss: 0.028052736073732376, dist_loss: 0.5770658850669861
recon_loss: 0.028052223846316338, dist_loss: 0.7019316554069519
Pre-training Epoch 79:  38%|███▊      | 140/367 [00:00<00:01, 192.80it/s]Pre-training Epoch 79:  44%|████▎     | 160/367 [00:00<00:01, 178.73it/s]Pre-training Epoch 79:  49%|████▉     | 179/367 [00:00<00:01, 171.13it/s]Pre-training Epoch 79:  54%|█████▎    | 197/367 [00:01<00:01, 165.48it/s]Pre-training Epoch 79:  58%|█████▊    | 214/367 [00:01<00:00, 163.62it/s]Pre-training Epoch 79:  63%|██████▎   | 231/367 [00:01<00:00, 161.28it/s]Pre-training Epoch 79:  68%|██████▊   | 248/367 [00:01<00:00, 159.34it/s]recon_loss: 0.02805263362824917, dist_loss: 0.7392967939376831
recon_loss: 0.028051849454641342, dist_loss: 0.7552973628044128
recon_loss: 0.028051966801285744, dist_loss: 0.8166167736053467
recon_loss: 0.028052378445863724, dist_loss: 0.6999946236610413
recon_loss: 0.028052709996700287, dist_loss: 0.4142877161502838
recon_loss: 0.028053075075149536, dist_loss: 0.5115054249763489
recon_loss: 0.028053538873791695, dist_loss: 0.943040668964386
recon_loss: 0.02805439569056034, dist_loss: 0.864647388458252
recon_loss: 0.028055233880877495, dist_loss: 0.4762815535068512
recon_loss: 0.028056101873517036, dist_loss: 0.3461030125617981
recon_loss: 0.02805705927312374, dist_loss: 0.4047723114490509
recon_loss: 0.028057832270860672, dist_loss: 0.8178592324256897
recon_loss: 0.028057696297764778, dist_loss: 0.8447310924530029
recon_loss: 0.028057759627699852, dist_loss: 1.205806016921997
recon_loss: 0.028058094903826714, dist_loss: 0.9390848875045776
recon_loss: 0.028058646246790886, dist_loss: 0.6228529810905457
recon_loss: 0.028058551251888275, dist_loss: 0.3503188490867615
recon_loss: 0.028057795017957687, dist_loss: 0.4425126314163208
recon_loss: 0.028056291863322258, dist_loss: 1.2109817266464233
recon_loss: 0.028055964037775993, dist_loss: 0.7214605808258057
recon_loss: 0.02805517055094242, dist_loss: 0.3740155100822449
recon_loss: 0.02805330976843834, dist_loss: 0.6223971247673035
recon_loss: 0.0280532855540514, dist_loss: 0.7996246218681335
recon_loss: 0.028051232919096947, dist_loss: 0.6692801713943481
recon_loss: 0.028049858286976814, dist_loss: 0.7323150634765625
recon_loss: 0.028049470856785774, dist_loss: 1.001558542251587
recon_loss: 0.028049372136592865, dist_loss: 0.6828999519348145
recon_loss: 0.028049591928720474, dist_loss: 0.7246387600898743
recon_loss: 0.028050128370523453, dist_loss: 0.8054555654525757
recon_loss: 0.0280515905469656, dist_loss: 0.7466080188751221
recon_loss: 0.028052804991602898, dist_loss: 0.7126696705818176
recon_loss: 0.028053302317857742, dist_loss: 0.6843472719192505
recon_loss: 0.02805403620004654, dist_loss: 0.6572961807250977
recon_loss: 0.028054969385266304, dist_loss: 0.6668012738227844
recon_loss: 0.028055058792233467, dist_loss: 0.6786313056945801
recon_loss: 0.02805587835609913, dist_loss: 0.6684890985488892
recon_loss: 0.028057487681508064, dist_loss: 0.5039932727813721
recon_loss: 0.028058309108018875, dist_loss: 0.6599071025848389
recon_loss: 0.028058599680662155, dist_loss: 0.987486720085144
recon_loss: 0.028057685121893883, dist_loss: 0.45277538895606995
recon_loss: 0.02805730141699314, dist_loss: 0.38365060091018677
recon_loss: 0.028056086972355843, dist_loss: 0.5476507544517517
recon_loss: 0.028055060654878616, dist_loss: 0.933566689491272
recon_loss: 0.028053300455212593, dist_loss: 0.6035745143890381
recon_loss: 0.02805139869451523, dist_loss: 0.7387006282806396
recon_loss: 0.028049679473042488, dist_loss: 0.6044228076934814
recon_loss: 0.028048740699887276, dist_loss: 0.48825541138648987
recon_loss: 0.028048422187566757, dist_loss: 0.6561034321784973
recon_loss: 0.02804860658943653, dist_loss: 0.6989992260932922
recon_loss: 0.02804896980524063, dist_loss: 0.6237576007843018
recon_loss: 0.028049446642398834, dist_loss: 0.7358563542366028
recon_loss: 0.02804948389530182, dist_loss: 0.7528969645500183
recon_loss: 0.028049428015947342, dist_loss: 0.752234697341919
recon_loss: 0.02805018424987793, dist_loss: 0.41984957456588745
recon_loss: 0.02804986946284771, dist_loss: 0.6062884330749512
recon_loss: 0.02805047295987606, dist_loss: 0.903102695941925
recon_loss: 0.0280495285987854, dist_loss: 0.7925279140472412
recon_loss: 0.0280483178794384, dist_loss: 0.8781147003173828
recon_loss: 0.028047790750861168, dist_loss: 0.441442608833313
recon_loss: 0.028046678751707077, dist_loss: 0.7431173324584961
recon_loss: 0.028046254068613052, dist_loss: 1.0489110946655273
recon_loss: 0.028045661747455597, dist_loss: 0.5148088932037354
recon_loss: 0.02804470807313919, dist_loss: 0.8077143430709839
recon_loss: 0.028045164421200752, dist_loss: 0.3833613991737366
recon_loss: 0.02804498001933098, dist_loss: 0.9030187129974365
recon_loss: 0.02804548107087612, dist_loss: 0.6680099964141846
recon_loss: 0.028045855462551117, dist_loss: 0.5220335721969604
recon_loss: 0.02804577350616455, dist_loss: 0.9250357151031494
recon_loss: 0.028046434745192528, dist_loss: 0.6675071716308594
recon_loss: 0.02804586850106716, dist_loss: 0.5878060460090637
recon_loss: 0.02804551087319851, dist_loss: 0.72532057762146
recon_loss: 0.028046030551195145, dist_loss: 0.45354369282722473
recon_loss: 0.028044912964105606, dist_loss: 0.5245247483253479
recon_loss: 0.028045184910297394, dist_loss: 0.711658775806427
recon_loss: 0.028044838458299637, dist_loss: 0.7357953786849976
recon_loss: 0.02804413251578808, dist_loss: 0.7698401212692261
recon_loss: 0.028044693171977997, dist_loss: 0.47618168592453003
recon_loss: 0.028044097125530243, dist_loss: 0.7487829923629761
recon_loss: 0.02804400958120823, dist_loss: 0.7822453379631042
recon_loss: 0.028044527396559715, dist_loss: 0.7386109828948975
recon_loss: 0.028043949976563454, dist_loss: 0.8033341765403748
recon_loss: 0.028043976053595543, dist_loss: 0.6929131746292114
recon_loss: 0.028044378384947777, dist_loss: 1.0047423839569092
recon_loss: 0.028044501319527626, dist_loss: 0.6390860676765442
recon_loss: 0.028044067323207855, dist_loss: 0.6035060882568359
recon_loss: 0.028043758124113083, dist_loss: 1.1038312911987305
recon_loss: 0.02804398164153099, dist_loss: 1.1201413869857788
recon_loss: 0.028044022619724274, dist_loss: 1.0966064929962158
recon_loss: 0.028044475242495537, dist_loss: 0.7155181169509888
recon_loss: 0.028044793754816055, dist_loss: 0.4412629306316376
recon_loss: 0.028045007959008217, dist_loss: 0.695959746837616
recon_loss: 0.028044860810041428, dist_loss: 0.5244492888450623
recon_loss: 0.028044629842042923, dist_loss: 0.5361912250518799
recon_loss: 0.02804412879049778, dist_loss: 0.8809128403663635
recon_loss: 0.028043825179338455, dist_loss: 0.6160063743591309
recon_loss: 0.028042951598763466, dist_loss: 0.43958228826522827
recon_loss: 0.02804255299270153, dist_loss: 0.39731261134147644
recon_loss: 0.02804180048406124, dist_loss: 0.5558366179466248
recon_loss: 0.028041649609804153, dist_loss: 0.5613366365432739
recon_loss: 0.028041454032063484, dist_loss: 0.76674485206604
recon_loss: 0.028041375800967216, dist_loss: 0.70476895570755
recon_loss: 0.0280411746352911, dist_loss: 0.4021897315979004
recon_loss: 0.028040727600455284, dist_loss: 0.7247610688209534
recon_loss: 0.028040576726198196, dist_loss: 0.4383171796798706
recon_loss: 0.028040610253810883, dist_loss: 0.774206280708313
recon_loss: 0.028040407225489616, dist_loss: 0.5923699140548706
recon_loss: 0.02804032899439335, dist_loss: 0.8267104029655457
recon_loss: 0.028039850294589996, dist_loss: 1.0270681381225586
recon_loss: 0.028039654716849327, dist_loss: 0.8236932158470154
recon_loss: 0.02803954668343067, dist_loss: 0.4225301444530487
recon_loss: 0.02803942933678627, dist_loss: 0.3083435595035553
recon_loss: 0.028039485216140747, dist_loss: 0.6341081857681274
recon_loss: 0.02803925797343254, dist_loss: 0.5313092470169067
recon_loss: 0.028039012104272842, dist_loss: 0.839194655418396
recon_loss: 0.028038859367370605, dist_loss: 0.6536045074462891
recon_loss: 0.02803877182304859, dist_loss: 0.27211034297943115
recon_loss: 0.02803911082446575, dist_loss: 1.2306928634643555
recon_loss: 0.028038805350661278, dist_loss: 0.8897808790206909
recon_loss: 0.02803891897201538, dist_loss: 0.5265853404998779
recon_loss: 0.02803933434188366, dist_loss: 0.5146255493164062
recon_loss: 0.02803948149085045, dist_loss: 0.391482412815094
recon_loss: 0.028039153665304184, dist_loss: 1.0331021547317505
recon_loss: 0.0280391164124012, dist_loss: 0.66193687915802
recon_loss: 0.02803916111588478, dist_loss: 0.9653419256210327
recon_loss: 0.028039319440722466, dist_loss: 0.6539636850357056
recon_loss: 0.028039077296853065, dist_loss: 0.8327913880348206
recon_loss: 0.028038766235113144, dist_loss: 0.9330912232398987
recon_loss: 0.028038688004016876, dist_loss: 0.513344407081604
recon_loss: 0.028038473799824715, dist_loss: 1.0351488590240479Pre-training Epoch 79:  72%|███████▏  | 264/367 [00:01<00:00, 159.03it/s]Pre-training Epoch 79:  76%|███████▋  | 280/367 [00:01<00:00, 158.17it/s]Pre-training Epoch 79:  81%|████████  | 297/367 [00:01<00:00, 160.61it/s]Pre-training Epoch 79:  86%|████████▌ | 315/367 [00:01<00:00, 164.74it/s]Pre-training Epoch 79:  90%|█████████ | 332/367 [00:01<00:00, 164.43it/s]Pre-training Epoch 79:  95%|█████████▌| 349/367 [00:02<00:00, 164.95it/s]Pre-training Epoch 79: 100%|█████████▉| 366/367 [00:02<00:00, 163.22it/s]Pre-training Epoch 79: 100%|██████████| 367/367 [00:02<00:00, 170.54it/s]

recon_loss: 0.028038304299116135, dist_loss: 0.5930019617080688
recon_loss: 0.02803807705640793, dist_loss: 0.6520970463752747
recon_loss: 0.028038103133440018, dist_loss: 0.8642616868019104
recon_loss: 0.028037866577506065, dist_loss: 0.5976915955543518
recon_loss: 0.02803811803460121, dist_loss: 0.885838508605957
recon_loss: 0.028038403019309044, dist_loss: 0.7349233627319336
recon_loss: 0.02803901582956314, dist_loss: 0.5993852615356445
recon_loss: 0.02804100140929222, dist_loss: 0.6100064516067505
recon_loss: 0.028041761368513107, dist_loss: 0.7911218404769897
recon_loss: 0.028043169528245926, dist_loss: 1.0247465372085571
recon_loss: 0.028041992336511612, dist_loss: 0.7158118486404419
recon_loss: 0.028042953461408615, dist_loss: 0.31701529026031494
recon_loss: 0.02804214134812355, dist_loss: 0.877812922000885
recon_loss: 0.02804102562367916, dist_loss: 0.864912211894989
recon_loss: 0.02804028056561947, dist_loss: 0.2574160099029541
recon_loss: 0.028038281947374344, dist_loss: 1.2367947101593018
recon_loss: 0.02803954854607582, dist_loss: 0.6546496152877808
recon_loss: 0.0280373003333807, dist_loss: 0.534198522567749
recon_loss: 0.02803819067776203, dist_loss: 0.6658620834350586
recon_loss: 0.028037702664732933, dist_loss: 0.9577184915542603
recon_loss: 0.02803656831383705, dist_loss: 0.4983389973640442
recon_loss: 0.028036782518029213, dist_loss: 0.418469101190567
recon_loss: 0.028036056086421013, dist_loss: 0.6461011171340942
recon_loss: 0.028036758303642273, dist_loss: 1.0936400890350342
recon_loss: 0.028037291020154953, dist_loss: 0.43659693002700806
recon_loss: 0.02803684212267399, dist_loss: 1.1433930397033691
recon_loss: 0.028036484494805336, dist_loss: 0.5922457575798035
recon_loss: 0.028036165982484818, dist_loss: 0.6925773620605469
recon_loss: 0.02803649753332138, dist_loss: 0.49850594997406006
recon_loss: 0.028036415576934814, dist_loss: 0.570206880569458
recon_loss: 0.028037041425704956, dist_loss: 0.7811182737350464
recon_loss: 0.028036674484610558, dist_loss: 0.5164623260498047
recon_loss: 0.02803664840757847, dist_loss: 0.6388348937034607
recon_loss: 0.02803669683635235, dist_loss: 0.888355016708374
recon_loss: 0.02803649753332138, dist_loss: 0.6550293564796448
recon_loss: 0.028036603704094887, dist_loss: 0.5222711563110352
recon_loss: 0.02803608402609825, dist_loss: 0.4795418083667755
recon_loss: 0.02803637646138668, dist_loss: 0.6631860136985779
recon_loss: 0.028035074472427368, dist_loss: 0.3959444463253021
recon_loss: 0.028035171329975128, dist_loss: 0.6796051859855652
recon_loss: 0.02803490124642849, dist_loss: 0.820624589920044
recon_loss: 0.028035076335072517, dist_loss: 0.9336246252059937
recon_loss: 0.028035547584295273, dist_loss: 0.7914009094238281
recon_loss: 0.02803473360836506, dist_loss: 0.40406426787376404
recon_loss: 0.028034958988428116, dist_loss: 0.47933101654052734
recon_loss: 0.028034716844558716, dist_loss: 0.6074920296669006
recon_loss: 0.028035251423716545, dist_loss: 0.7674487829208374
recon_loss: 0.028035448864102364, dist_loss: 0.8157273530960083
recon_loss: 0.028035305440425873, dist_loss: 0.530227541923523
recon_loss: 0.0280354842543602, dist_loss: 0.4809589087963104
recon_loss: 0.028034962713718414, dist_loss: 0.5176125168800354
recon_loss: 0.02803533896803856, dist_loss: 0.5895251631736755
recon_loss: 0.028035512194037437, dist_loss: 0.4301294684410095
recon_loss: 0.028035366907715797, dist_loss: 1.2950050830841064
recon_loss: 0.028035243973135948, dist_loss: 0.45567190647125244
recon_loss: 0.02803521603345871, dist_loss: 0.476806104183197
recon_loss: 0.028035476803779602, dist_loss: 0.3804505169391632
recon_loss: 0.028036653995513916, dist_loss: 0.3412472903728485
recon_loss: 0.0280366949737072, dist_loss: 0.6055887937545776
recon_loss: 0.028036274015903473, dist_loss: 0.4142184257507324
recon_loss: 0.02803599275648594, dist_loss: 0.4939805865287781
recon_loss: 0.028035113587975502, dist_loss: 0.6207337379455566
recon_loss: 0.02803478203713894, dist_loss: 0.47586026787757874
recon_loss: 0.028034860268235207, dist_loss: 0.6693163514137268
recon_loss: 0.02803356945514679, dist_loss: 0.6238043308258057
recon_loss: 0.02803375944495201, dist_loss: 0.5181215405464172
recon_loss: 0.028033340349793434, dist_loss: 0.7550036907196045
recon_loss: 0.028033098205924034, dist_loss: 0.7079805731773376
recon_loss: 0.028033211827278137, dist_loss: 0.5888944864273071
recon_loss: 0.028031906113028526, dist_loss: 0.5017924308776855
recon_loss: 0.028031589463353157, dist_loss: 1.276230812072754
recon_loss: 0.028031611815094948, dist_loss: 0.38299164175987244
recon_loss: 0.02803158573806286, dist_loss: 0.6377874612808228
recon_loss: 0.028031427413225174, dist_loss: 0.5609731674194336
recon_loss: 0.02803121879696846, dist_loss: 0.36342939734458923
recon_loss: 0.028031155467033386, dist_loss: 0.7230330109596252
recon_loss: 0.02803121507167816, dist_loss: 0.5061221122741699
recon_loss: 0.028031425550580025, dist_loss: 0.7173738479614258
recon_loss: 0.02803175151348114, dist_loss: 0.35287272930145264
recon_loss: 0.028031494468450546, dist_loss: 0.5235821604728699
recon_loss: 0.02803121879696846, dist_loss: 0.7231642007827759
recon_loss: 0.028031203895807266, dist_loss: 0.6623387336730957
recon_loss: 0.028031297028064728, dist_loss: 0.6792316436767578
recon_loss: 0.028031885623931885, dist_loss: 0.7239211201667786
recon_loss: 0.028032204136252403, dist_loss: 0.4503081440925598
recon_loss: 0.028032464906573296, dist_loss: 0.6244344115257263
recon_loss: 0.028032580390572548, dist_loss: 0.8015587329864502
recon_loss: 0.028031976893544197, dist_loss: 0.556577205657959
recon_loss: 0.02803259901702404, dist_loss: 0.7719717025756836
recon_loss: 0.028033195063471794, dist_loss: 1.0422559976577759
recon_loss: 0.028033673763275146, dist_loss: 0.7109320759773254
recon_loss: 0.02803461253643036, dist_loss: 0.4965575039386749
recon_loss: 0.028034478425979614, dist_loss: 0.8157457113265991
recon_loss: 0.028033925220370293, dist_loss: 0.5097000598907471
recon_loss: 0.028033874928951263, dist_loss: 0.5410187840461731
recon_loss: 0.028033003211021423, dist_loss: 0.539059579372406
recon_loss: 0.02803259901702404, dist_loss: 0.33092033863067627
recon_loss: 0.028031866997480392, dist_loss: 0.9025671482086182
recon_loss: 0.02803081087768078, dist_loss: 0.7748771905899048
recon_loss: 0.028030822053551674, dist_loss: 1.2588093280792236
recon_loss: 0.028031056746840477, dist_loss: 0.48637938499450684
recon_loss: 0.028031866997480392, dist_loss: 0.3108459711074829
recon_loss: 0.028032781556248665, dist_loss: 0.7855514883995056
recon_loss: 0.028035001829266548, dist_loss: 0.8279428482055664
recon_loss: 0.02803628146648407, dist_loss: 0.42585164308547974
recon_loss: 0.028037086129188538, dist_loss: 0.6620309352874756
recon_loss: 0.0280377808958292, dist_loss: 0.4248737692832947
recon_loss: 0.028038037940859795, dist_loss: 0.3532213866710663
recon_loss: 0.028038503602147102, dist_loss: 0.7519886493682861
recon_loss: 0.02803807333111763, dist_loss: 0.42732125520706177
Pre-training Epoch 80:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 80:   5%|▍         | 17/367 [00:00<00:02, 161.70it/s]Pre-training Epoch 80:   9%|▉         | 34/367 [00:00<00:02, 164.20it/s]Pre-training Epoch 80:  14%|█▍        | 51/367 [00:00<00:01, 161.64it/s]Pre-training Epoch 80:  19%|█▊        | 68/367 [00:00<00:01, 158.65it/s]Pre-training Epoch 80:  23%|██▎       | 85/367 [00:00<00:01, 161.35it/s]Pre-training Epoch 80:  28%|██▊       | 102/367 [00:00<00:01, 159.79it/s]Pre-training Epoch 80:  32%|███▏      | 119/367 [00:00<00:01, 161.18it/s]recon_loss: 0.02803764119744301, dist_loss: 0.7303735017776489
recon_loss: 0.02803647890686989, dist_loss: 1.062658429145813
recon_loss: 0.02803432010114193, dist_loss: 0.9134892821311951
recon_loss: 0.028034154325723648, dist_loss: 0.7668470144271851
recon_loss: 0.028033094480633736, dist_loss: 0.5450725555419922
recon_loss: 0.02803226001560688, dist_loss: 0.3645833134651184
recon_loss: 0.028033088892698288, dist_loss: 0.41330912709236145
recon_loss: 0.0280308797955513, dist_loss: 0.8046485185623169
recon_loss: 0.028031762689352036, dist_loss: 0.6312543153762817
recon_loss: 0.02803066372871399, dist_loss: 0.4814518988132477
recon_loss: 0.028030771762132645, dist_loss: 0.3904731273651123
recon_loss: 0.028031112626194954, dist_loss: 0.5951253175735474
recon_loss: 0.028030453249812126, dist_loss: 0.4849961996078491
recon_loss: 0.028031250461935997, dist_loss: 0.6711047887802124
recon_loss: 0.02803121879696846, dist_loss: 0.5671712756156921
recon_loss: 0.028030283749103546, dist_loss: 0.9135745763778687
recon_loss: 0.028031129390001297, dist_loss: 0.35803845524787903
recon_loss: 0.028030158951878548, dist_loss: 0.37995296716690063
recon_loss: 0.028029577806591988, dist_loss: 0.7498103380203247
recon_loss: 0.02802945487201214, dist_loss: 0.7152101993560791
recon_loss: 0.028027663007378578, dist_loss: 1.0985920429229736
recon_loss: 0.028028594329953194, dist_loss: 0.720099925994873
recon_loss: 0.028028292581439018, dist_loss: 0.5040292739868164
recon_loss: 0.028027566149830818, dist_loss: 0.865330696105957
recon_loss: 0.028027893975377083, dist_loss: 0.46271640062332153
recon_loss: 0.028026781976222992, dist_loss: 0.6090606451034546
recon_loss: 0.028027109801769257, dist_loss: 0.3348291218280792
recon_loss: 0.028027012944221497, dist_loss: 0.8814715147018433
recon_loss: 0.028026819229125977, dist_loss: 0.7067646980285645
recon_loss: 0.028027083724737167, dist_loss: 0.5071837306022644
recon_loss: 0.028026871383190155, dist_loss: 0.6078343391418457
recon_loss: 0.0280274897813797, dist_loss: 0.5195204019546509
recon_loss: 0.028026962652802467, dist_loss: 0.9491009712219238
recon_loss: 0.02802719548344612, dist_loss: 0.6500908732414246
recon_loss: 0.028027601540088654, dist_loss: 0.8546290993690491
recon_loss: 0.028027093037962914, dist_loss: 0.9175121784210205
recon_loss: 0.02802707813680172, dist_loss: 0.5055428147315979
recon_loss: 0.02802734076976776, dist_loss: 0.6630521416664124
recon_loss: 0.028026796877384186, dist_loss: 0.9234192967414856
recon_loss: 0.028026921674609184, dist_loss: 0.48351773619651794
recon_loss: 0.02802647277712822, dist_loss: 0.9589823484420776
recon_loss: 0.028026258572936058, dist_loss: 0.4186564087867737
recon_loss: 0.02802651934325695, dist_loss: 1.075925588607788
recon_loss: 0.028025686740875244, dist_loss: 0.8868796825408936
recon_loss: 0.02802608162164688, dist_loss: 1.2090256214141846
recon_loss: 0.028025399893522263, dist_loss: 0.8357385396957397
recon_loss: 0.02802504040300846, dist_loss: 0.6101119518280029
recon_loss: 0.02802485227584839, dist_loss: 0.48816803097724915
recon_loss: 0.028024770319461823, dist_loss: 0.3403434753417969
recon_loss: 0.028025373816490173, dist_loss: 0.643635094165802
recon_loss: 0.02802477963268757, dist_loss: 0.6045132875442505
recon_loss: 0.028025928884744644, dist_loss: 1.0015788078308105
recon_loss: 0.028025805950164795, dist_loss: 0.46320289373397827
recon_loss: 0.028027290478348732, dist_loss: 0.6606380939483643
recon_loss: 0.028027856722474098, dist_loss: 1.1141011714935303
recon_loss: 0.028028475120663643, dist_loss: 0.9117769002914429
recon_loss: 0.028030026704072952, dist_loss: 0.40819281339645386
recon_loss: 0.028030099347233772, dist_loss: 1.3187578916549683
recon_loss: 0.028030700981616974, dist_loss: 0.598419189453125
recon_loss: 0.028030868619680405, dist_loss: 0.5693394541740417
recon_loss: 0.028030138462781906, dist_loss: 0.7063078284263611
recon_loss: 0.028030047193169594, dist_loss: 0.866302490234375
recon_loss: 0.028028957545757294, dist_loss: 1.2613224983215332
recon_loss: 0.028027551248669624, dist_loss: 0.9086402654647827
recon_loss: 0.028026964515447617, dist_loss: 0.2992894649505615
recon_loss: 0.02802608162164688, dist_loss: 0.8645495176315308
recon_loss: 0.028025517240166664, dist_loss: 0.6287258863449097
recon_loss: 0.028025193139910698, dist_loss: 0.7779449224472046
recon_loss: 0.028024310246109962, dist_loss: 0.8198301792144775
recon_loss: 0.028024272993206978, dist_loss: 0.540458083152771
recon_loss: 0.028023993596434593, dist_loss: 0.7713139057159424
recon_loss: 0.02802364155650139, dist_loss: 0.7286313772201538
recon_loss: 0.02802363410592079, dist_loss: 0.3456806540489197
recon_loss: 0.028023380786180496, dist_loss: 0.5369095802307129
recon_loss: 0.028023652732372284, dist_loss: 0.21463212370872498
recon_loss: 0.02802358940243721, dist_loss: 0.8035707473754883
recon_loss: 0.0280232485383749, dist_loss: 0.6678844690322876
recon_loss: 0.02802320197224617, dist_loss: 1.0931401252746582
recon_loss: 0.028022723272442818, dist_loss: 0.7107681035995483
recon_loss: 0.02802266925573349, dist_loss: 0.6242136359214783
recon_loss: 0.028022201731801033, dist_loss: 0.6792773008346558
recon_loss: 0.02802153304219246, dist_loss: 1.3057284355163574
recon_loss: 0.028021395206451416, dist_loss: 0.6181666851043701
recon_loss: 0.02802112326025963, dist_loss: 0.3661211431026459
recon_loss: 0.02802116982638836, dist_loss: 0.543846845626831
recon_loss: 0.028020944446325302, dist_loss: 0.7845458388328552
recon_loss: 0.028021190315485, dist_loss: 0.5998926758766174
recon_loss: 0.028021732345223427, dist_loss: 0.6857055425643921
recon_loss: 0.02802249975502491, dist_loss: 0.7146015167236328
recon_loss: 0.028022464364767075, dist_loss: 1.2944252490997314
recon_loss: 0.028022345155477524, dist_loss: 0.3484318256378174
recon_loss: 0.02802201919257641, dist_loss: 0.5523160696029663
recon_loss: 0.02802165038883686, dist_loss: 0.5494849681854248
recon_loss: 0.02802138775587082, dist_loss: 0.4180762767791748
recon_loss: 0.02802087552845478, dist_loss: 0.4209783673286438
recon_loss: 0.028021296486258507, dist_loss: 0.4014601707458496
recon_loss: 0.028021875768899918, dist_loss: 0.37855616211891174
recon_loss: 0.02802242711186409, dist_loss: 0.8244223594665527
recon_loss: 0.028023572638630867, dist_loss: 0.389479398727417
recon_loss: 0.02802402339875698, dist_loss: 0.5617101192474365
recon_loss: 0.028024056926369667, dist_loss: 0.5270774364471436
recon_loss: 0.02802383340895176, dist_loss: 0.5948463678359985
recon_loss: 0.028023215010762215, dist_loss: 0.36237192153930664
recon_loss: 0.02802252024412155, dist_loss: 0.860140323638916
recon_loss: 0.02802267298102379, dist_loss: 0.7818264365196228
recon_loss: 0.028022952377796173, dist_loss: 0.5918663740158081
recon_loss: 0.028022684156894684, dist_loss: 0.5201755166053772
recon_loss: 0.028021737933158875, dist_loss: 0.5906463265419006
recon_loss: 0.028021149337291718, dist_loss: 0.488561749458313
recon_loss: 0.028020834550261497, dist_loss: 0.6069695949554443
recon_loss: 0.02802075259387493, dist_loss: 0.6372296810150146
recon_loss: 0.02802053466439247, dist_loss: 0.4666008949279785
recon_loss: 0.02802063338458538, dist_loss: 1.2972570657730103
recon_loss: 0.02802073024213314, dist_loss: 0.6963750720024109
recon_loss: 0.02802100032567978, dist_loss: 0.8045982122421265
recon_loss: 0.02802235074341297, dist_loss: 0.6921048164367676
recon_loss: 0.028022825717926025, dist_loss: 0.5149887800216675
recon_loss: 0.028023753315210342, dist_loss: 0.7971285581588745
recon_loss: 0.028024019673466682, dist_loss: 0.6694716215133667
recon_loss: 0.02802439033985138, dist_loss: 0.4971383810043335
recon_loss: 0.028025200590491295, dist_loss: 0.5079488754272461
recon_loss: 0.028024518862366676, dist_loss: 1.1940503120422363
recon_loss: 0.02802465483546257, dist_loss: 0.7854806780815125
recon_loss: 0.02802477963268757, dist_loss: 0.7504892945289612
recon_loss: 0.02802497334778309, dist_loss: 0.46183493733406067
recon_loss: 0.028024248778820038, dist_loss: 0.6292499303817749
recon_loss: 0.028023486956954002, dist_loss: 0.8390802145004272
recon_loss: 0.028022874146699905, dist_loss: 0.5625702142715454
Pre-training Epoch 80:  37%|███▋      | 136/367 [00:00<00:01, 157.78it/s]Pre-training Epoch 80:  41%|████▏     | 152/367 [00:00<00:01, 157.87it/s]Pre-training Epoch 80:  46%|████▌     | 169/367 [00:01<00:01, 159.60it/s]Pre-training Epoch 80:  51%|█████     | 187/367 [00:01<00:01, 165.56it/s]Pre-training Epoch 80:  56%|█████▌    | 205/367 [00:01<00:00, 169.29it/s]Pre-training Epoch 80:  61%|██████    | 224/367 [00:01<00:00, 174.36it/s]Pre-training Epoch 80:  66%|██████▋   | 244/367 [00:01<00:00, 179.26it/s]recon_loss: 0.02802197076380253, dist_loss: 0.3766902685165405
recon_loss: 0.02802097052335739, dist_loss: 0.6438888311386108
recon_loss: 0.02801993116736412, dist_loss: 0.6304373145103455
recon_loss: 0.028019143268465996, dist_loss: 0.821951150894165
recon_loss: 0.02801928110420704, dist_loss: 0.836588978767395
recon_loss: 0.028018806129693985, dist_loss: 0.8353621363639832
recon_loss: 0.02801864966750145, dist_loss: 0.8210641741752625
recon_loss: 0.028019243851304054, dist_loss: 0.4540022611618042
recon_loss: 0.028019651770591736, dist_loss: 0.6378363370895386
recon_loss: 0.028020760044455528, dist_loss: 0.5561214089393616
recon_loss: 0.028021741658449173, dist_loss: 0.6059612035751343
recon_loss: 0.02802126295864582, dist_loss: 0.7920317649841309
recon_loss: 0.02802196517586708, dist_loss: 0.512923002243042
recon_loss: 0.02802165411412716, dist_loss: 0.656204342842102
recon_loss: 0.028021493926644325, dist_loss: 0.5655509233474731
recon_loss: 0.02802160382270813, dist_loss: 0.3085254430770874
recon_loss: 0.028020774945616722, dist_loss: 0.41295716166496277
recon_loss: 0.028020597994327545, dist_loss: 0.8663237690925598
recon_loss: 0.028019733726978302, dist_loss: 0.9065688848495483
recon_loss: 0.02801956608891487, dist_loss: 0.4206676781177521
recon_loss: 0.028019247576594353, dist_loss: 1.0421161651611328
recon_loss: 0.028018252924084663, dist_loss: 0.7738378643989563
recon_loss: 0.028018459677696228, dist_loss: 0.6024838089942932
recon_loss: 0.02801869623363018, dist_loss: 0.7082371711730957
recon_loss: 0.028018467128276825, dist_loss: 0.9038174748420715
recon_loss: 0.028018390759825706, dist_loss: 0.4262276887893677
recon_loss: 0.028018616139888763, dist_loss: 0.5267086625099182
recon_loss: 0.02801823616027832, dist_loss: 0.43558642268180847
recon_loss: 0.028017977252602577, dist_loss: 1.0271215438842773
recon_loss: 0.028017373755574226, dist_loss: 0.3718315362930298
recon_loss: 0.028016824275255203, dist_loss: 1.2946476936340332
recon_loss: 0.028016231954097748, dist_loss: 0.639091968536377
recon_loss: 0.028016073629260063, dist_loss: 0.6120591163635254
recon_loss: 0.028015639632940292, dist_loss: 0.8022128939628601
recon_loss: 0.02801567316055298, dist_loss: 0.6375552415847778
recon_loss: 0.02801632136106491, dist_loss: 0.6405147314071655
recon_loss: 0.02801624871790409, dist_loss: 0.7516125440597534
recon_loss: 0.028016868978738785, dist_loss: 0.6557037234306335
recon_loss: 0.028017327189445496, dist_loss: 0.5518680214881897
recon_loss: 0.028017878532409668, dist_loss: 0.7799128890037537
recon_loss: 0.028019659221172333, dist_loss: 0.9078532457351685
recon_loss: 0.02801997773349285, dist_loss: 0.8759258985519409
recon_loss: 0.0280222836881876, dist_loss: 0.3739834427833557
recon_loss: 0.028022456914186478, dist_loss: 0.45688170194625854
recon_loss: 0.02802295982837677, dist_loss: 0.7141139507293701
recon_loss: 0.028024066239595413, dist_loss: 0.871073842048645
recon_loss: 0.028022106736898422, dist_loss: 0.5506885647773743
recon_loss: 0.028022386133670807, dist_loss: 0.7827578783035278
recon_loss: 0.028019996359944344, dist_loss: 0.43130427598953247
recon_loss: 0.028019677847623825, dist_loss: 0.48108208179473877
recon_loss: 0.02801782824099064, dist_loss: 0.33960747718811035
recon_loss: 0.028016269207000732, dist_loss: 0.7514536380767822
recon_loss: 0.02801627479493618, dist_loss: 0.8776641488075256
recon_loss: 0.028014888986945152, dist_loss: 0.7011839747428894
recon_loss: 0.02801571600139141, dist_loss: 0.8047329187393188
recon_loss: 0.028014585375785828, dist_loss: 0.46010822057724
recon_loss: 0.02801460772752762, dist_loss: 0.7143826484680176
recon_loss: 0.02801433578133583, dist_loss: 0.6709792017936707
recon_loss: 0.028013424947857857, dist_loss: 1.1122090816497803
recon_loss: 0.028014222159981728, dist_loss: 0.45732581615448
recon_loss: 0.028013339266180992, dist_loss: 0.8409011363983154
recon_loss: 0.028013672679662704, dist_loss: 0.4038802683353424
recon_loss: 0.028012892231345177, dist_loss: 0.771265983581543
recon_loss: 0.02801230363547802, dist_loss: 0.5126854181289673
recon_loss: 0.028012683615088463, dist_loss: 0.8641050457954407
recon_loss: 0.028012273833155632, dist_loss: 0.6806210875511169
recon_loss: 0.028012704104185104, dist_loss: 0.7912155985832214
recon_loss: 0.02801349200308323, dist_loss: 0.61485356092453
recon_loss: 0.02801312878727913, dist_loss: 0.559149980545044
recon_loss: 0.02801387570798397, dist_loss: 0.45753782987594604
recon_loss: 0.028013968840241432, dist_loss: 0.47301799058914185
recon_loss: 0.02801492065191269, dist_loss: 0.7288429737091064
recon_loss: 0.028015244752168655, dist_loss: 0.473164439201355
recon_loss: 0.02801470272243023, dist_loss: 0.7084684371948242
recon_loss: 0.02801395393908024, dist_loss: 0.5132197737693787
recon_loss: 0.0280138049274683, dist_loss: 0.6803110837936401
recon_loss: 0.028013277798891068, dist_loss: 0.7483881711959839
recon_loss: 0.02801300212740898, dist_loss: 0.5052960515022278
recon_loss: 0.02801262028515339, dist_loss: 0.5111373662948608
recon_loss: 0.028012637048959732, dist_loss: 0.732025146484375
recon_loss: 0.02801169641315937, dist_loss: 0.7107154726982117
recon_loss: 0.02801184169948101, dist_loss: 0.34350118041038513
recon_loss: 0.02801085263490677, dist_loss: 0.6308093070983887
recon_loss: 0.028010739013552666, dist_loss: 0.5991905331611633
recon_loss: 0.028011243790388107, dist_loss: 0.7360148429870605
recon_loss: 0.028011351823806763, dist_loss: 0.6631373167037964
recon_loss: 0.028012240305542946, dist_loss: 0.7004410028457642
recon_loss: 0.028011353686451912, dist_loss: 0.38822951912879944
recon_loss: 0.028010806068778038, dist_loss: 0.7503302097320557
recon_loss: 0.028011653572320938, dist_loss: 0.7554804086685181
recon_loss: 0.02801060490310192, dist_loss: 0.33271554112434387
recon_loss: 0.028010524809360504, dist_loss: 0.5404624938964844
recon_loss: 0.028010351583361626, dist_loss: 0.719144344329834
recon_loss: 0.02800973318517208, dist_loss: 0.7285782098770142
recon_loss: 0.02801048755645752, dist_loss: 1.1686556339263916
recon_loss: 0.028010228648781776, dist_loss: 0.7069633603096008
recon_loss: 0.02800971269607544, dist_loss: 0.8976598978042603
recon_loss: 0.0280096884816885, dist_loss: 0.4188241958618164
recon_loss: 0.028009697794914246, dist_loss: 0.5005554556846619
recon_loss: 0.028009561821818352, dist_loss: 0.4164559841156006
recon_loss: 0.028009669855237007, dist_loss: 0.8509939908981323
recon_loss: 0.02800951525568962, dist_loss: 0.7719401717185974
recon_loss: 0.02800913155078888, dist_loss: 0.561137318611145
recon_loss: 0.028008976951241493, dist_loss: 0.5617128610610962
recon_loss: 0.02800961397588253, dist_loss: 0.4824919104576111
recon_loss: 0.028009500354528427, dist_loss: 0.6769917011260986
recon_loss: 0.02800937369465828, dist_loss: 0.5488576889038086
recon_loss: 0.028008561581373215, dist_loss: 0.39374613761901855
recon_loss: 0.028008585795760155, dist_loss: 0.7204170227050781
recon_loss: 0.02800860069692135, dist_loss: 0.5917540788650513
recon_loss: 0.02800861932337284, dist_loss: 0.582676112651825
recon_loss: 0.02800830453634262, dist_loss: 0.3977544903755188
recon_loss: 0.02800852246582508, dist_loss: 0.8071500062942505
recon_loss: 0.028008460998535156, dist_loss: 0.8339030742645264
recon_loss: 0.028008723631501198, dist_loss: 0.849267840385437
recon_loss: 0.02801010012626648, dist_loss: 1.309372901916504
recon_loss: 0.028010664507746696, dist_loss: 0.7336477041244507
recon_loss: 0.028010766953229904, dist_loss: 0.7895396947860718
recon_loss: 0.028011878952383995, dist_loss: 0.45286816358566284
recon_loss: 0.02801229991018772, dist_loss: 0.8721292018890381
recon_loss: 0.02801229991018772, dist_loss: 0.7605913281440735
recon_loss: 0.028012162074446678, dist_loss: 0.6964948177337646
recon_loss: 0.028010467067360878, dist_loss: 0.8190913796424866
recon_loss: 0.028010616078972816, dist_loss: 0.47086232900619507
recon_loss: 0.028009843081235886, dist_loss: 0.6239569187164307
recon_loss: 0.028010297566652298, dist_loss: 0.5716820359230042
recon_loss: 0.028010185807943344, dist_loss: 0.9061119556427002
recon_loss: 0.02800995297729969, dist_loss: 0.536409854888916
recon_loss: 0.02801019512116909, dist_loss: 0.7814429998397827
Pre-training Epoch 80:  72%|███████▏  | 264/367 [00:01<00:00, 183.17it/s]Pre-training Epoch 80:  77%|███████▋  | 283/367 [00:01<00:00, 179.61it/s]Pre-training Epoch 80:  82%|████████▏ | 301/367 [00:01<00:00, 178.49it/s]Pre-training Epoch 80:  87%|████████▋ | 319/367 [00:01<00:00, 177.17it/s]Pre-training Epoch 80:  92%|█████████▏| 337/367 [00:01<00:00, 176.01it/s]Pre-training Epoch 80:  97%|█████████▋| 355/367 [00:02<00:00, 175.69it/s]Pre-training Epoch 80: 100%|██████████| 367/367 [00:02<00:00, 169.86it/s]
recon_loss: 0.028009338304400444, dist_loss: 0.7764643430709839
recon_loss: 0.028008664026856422, dist_loss: 0.4552901089191437
recon_loss: 0.028008971363306046, dist_loss: 0.6009359955787659
recon_loss: 0.028008228167891502, dist_loss: 0.7412003874778748
recon_loss: 0.028008656576275826, dist_loss: 0.6324816346168518
recon_loss: 0.028008153662085533, dist_loss: 0.46163609623908997
recon_loss: 0.02800782583653927, dist_loss: 1.034856915473938
recon_loss: 0.028007492423057556, dist_loss: 0.4951116442680359
recon_loss: 0.02800711989402771, dist_loss: 0.5979416370391846
recon_loss: 0.02800682559609413, dist_loss: 0.6555244326591492
recon_loss: 0.028006847947835922, dist_loss: 0.45542317628860474
recon_loss: 0.02800632268190384, dist_loss: 0.7875317335128784
recon_loss: 0.028006691485643387, dist_loss: 0.9634711742401123
recon_loss: 0.028006957843899727, dist_loss: 0.5993224382400513
recon_loss: 0.02800697460770607, dist_loss: 1.0479326248168945
recon_loss: 0.02800808846950531, dist_loss: 0.8226231932640076
recon_loss: 0.02800785005092621, dist_loss: 0.4179072082042694
recon_loss: 0.028008082881569862, dist_loss: 0.41148409247398376
recon_loss: 0.0280098095536232, dist_loss: 0.703829288482666
recon_loss: 0.02800833247601986, dist_loss: 0.7599201202392578
recon_loss: 0.02801067940890789, dist_loss: 0.5593265295028687
recon_loss: 0.028008393943309784, dist_loss: 0.6951313614845276
recon_loss: 0.028008323162794113, dist_loss: 0.4942890703678131
recon_loss: 0.028008252382278442, dist_loss: 0.7846632599830627
recon_loss: 0.02800643816590309, dist_loss: 0.4465605914592743
recon_loss: 0.02800901234149933, dist_loss: 0.5625890493392944
recon_loss: 0.028007356449961662, dist_loss: 0.5853286981582642
recon_loss: 0.028008082881569862, dist_loss: 0.5869007110595703
recon_loss: 0.02800877019762993, dist_loss: 0.34964436292648315
recon_loss: 0.02800711803138256, dist_loss: 0.9076088666915894
recon_loss: 0.02800886332988739, dist_loss: 0.5983419418334961
recon_loss: 0.02800811640918255, dist_loss: 0.55759197473526
recon_loss: 0.02800828590989113, dist_loss: 0.8858933448791504
recon_loss: 0.02800837904214859, dist_loss: 0.820585310459137
recon_loss: 0.028007257729768753, dist_loss: 0.5437961220741272
recon_loss: 0.028008006513118744, dist_loss: 0.5218545198440552
recon_loss: 0.028007563203573227, dist_loss: 0.561623752117157
recon_loss: 0.028007110580801964, dist_loss: 0.5675634145736694
recon_loss: 0.028006823733448982, dist_loss: 0.4335377514362335
recon_loss: 0.028006283566355705, dist_loss: 0.42358994483947754
recon_loss: 0.028006142005324364, dist_loss: 0.583440899848938
recon_loss: 0.02800593338906765, dist_loss: 0.5890289545059204
recon_loss: 0.02800547145307064, dist_loss: 0.8090968728065491
recon_loss: 0.028004923835396767, dist_loss: 0.4992455840110779
recon_loss: 0.028004663065075874, dist_loss: 0.4807727038860321
recon_loss: 0.028004605323076248, dist_loss: 0.6346753835678101
recon_loss: 0.028004946187138557, dist_loss: 0.6678587198257446
recon_loss: 0.028005845844745636, dist_loss: 0.47362250089645386
recon_loss: 0.028007157146930695, dist_loss: 0.3764347732067108
recon_loss: 0.02800835110247135, dist_loss: 0.4005033075809479
recon_loss: 0.028009304776787758, dist_loss: 0.5788528919219971
recon_loss: 0.02800905331969261, dist_loss: 1.0183781385421753
recon_loss: 0.02800852805376053, dist_loss: 0.40602245926856995
recon_loss: 0.028008293360471725, dist_loss: 0.980000376701355
recon_loss: 0.028007764369249344, dist_loss: 1.0823432207107544
recon_loss: 0.02800709195435047, dist_loss: 0.5402184724807739
recon_loss: 0.028006305918097496, dist_loss: 0.48836174607276917
recon_loss: 0.02800559066236019, dist_loss: 0.7110724449157715
recon_loss: 0.028005044907331467, dist_loss: 0.5976095199584961
recon_loss: 0.028004784137010574, dist_loss: 0.8960983753204346
recon_loss: 0.02800486423075199, dist_loss: 0.719447135925293
recon_loss: 0.0280049666762352, dist_loss: 0.640467643737793
recon_loss: 0.02800547517836094, dist_loss: 0.27901506423950195
recon_loss: 0.028006378561258316, dist_loss: 0.6754390001296997
recon_loss: 0.028006868436932564, dist_loss: 0.721014142036438
recon_loss: 0.028007663786411285, dist_loss: 0.475355327129364
recon_loss: 0.028007889166474342, dist_loss: 0.8037370443344116
recon_loss: 0.02800840325653553, dist_loss: 0.5060793161392212
recon_loss: 0.028008490800857544, dist_loss: 0.3693612515926361
recon_loss: 0.028008434921503067, dist_loss: 0.7157833576202393
recon_loss: 0.02800830639898777, dist_loss: 0.701857328414917
recon_loss: 0.028008561581373215, dist_loss: 0.690983772277832
recon_loss: 0.028008481487631798, dist_loss: 0.5853407979011536
recon_loss: 0.02800764888525009, dist_loss: 0.6965435743331909
recon_loss: 0.028006311506032944, dist_loss: 0.8075882196426392
recon_loss: 0.028005195781588554, dist_loss: 0.6212789416313171
recon_loss: 0.02800426073372364, dist_loss: 0.75465327501297
recon_loss: 0.028003482148051262, dist_loss: 0.512741208076477
recon_loss: 0.028002968057990074, dist_loss: 0.8324548602104187
recon_loss: 0.028002385050058365, dist_loss: 0.6936783790588379
recon_loss: 0.028001781553030014, dist_loss: 0.8573704361915588
recon_loss: 0.028001446276903152, dist_loss: 0.8815721273422241
recon_loss: 0.028001384809613228, dist_loss: 0.6824405193328857
recon_loss: 0.028001541271805763, dist_loss: 0.6653002500534058
recon_loss: 0.028001686558127403, dist_loss: 0.6436949968338013
recon_loss: 0.028002366423606873, dist_loss: 0.3363017439842224
recon_loss: 0.02800213359296322, dist_loss: 0.3824719488620758
recon_loss: 0.028002038598060608, dist_loss: 0.42672479152679443
recon_loss: 0.028002090752124786, dist_loss: 0.43953728675842285
recon_loss: 0.0280020572245121, dist_loss: 0.42743849754333496
recon_loss: 0.028001947328448296, dist_loss: 0.9270750284194946
recon_loss: 0.028002019971609116, dist_loss: 1.1306135654449463
recon_loss: 0.028001712635159492, dist_loss: 0.4496152698993683
recon_loss: 0.028001300990581512, dist_loss: 0.7839238047599792
recon_loss: 0.02800086885690689, dist_loss: 0.7283685803413391
recon_loss: 0.028000622987747192, dist_loss: 0.544277012348175
recon_loss: 0.028001682832837105, dist_loss: 0.46610158681869507
recon_loss: 0.028001075610518456, dist_loss: 0.6146761178970337
recon_loss: 0.028001438826322556, dist_loss: 0.974880576133728
recon_loss: 0.02800184302031994, dist_loss: 0.34604811668395996
recon_loss: 0.028002670034766197, dist_loss: 0.34956324100494385
recon_loss: 0.028003517538309097, dist_loss: 0.5975935459136963
recon_loss: 0.02800343558192253, dist_loss: 0.5319453477859497
recon_loss: 0.028003767132759094, dist_loss: 0.47900065779685974
recon_loss: 0.02800370380282402, dist_loss: 0.6773594617843628
recon_loss: 0.028002414852380753, dist_loss: 1.1601935625076294
recon_loss: 0.028001312166452408, dist_loss: 1.0495251417160034
recon_loss: 0.028000477701425552, dist_loss: 0.6316925287246704
recon_loss: 0.02800004370510578, dist_loss: 0.3514854907989502
recon_loss: 0.02799977920949459, dist_loss: 1.295132040977478
Pre-train Epoch: 80
Train - Total Loss: 0.0942, Recon Loss: 0.0280, Dist Loss: 0.6619, l1 regularization: 0.0000
Val - Total Loss: 0.0987, Recon Loss: 0.0280, Dist Loss: 0.7067, l1 regularization: 0.0000
Pre-training Epoch 81:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 81:   5%|▍         | 18/367 [00:00<00:02, 172.69it/s]Pre-training Epoch 81:  10%|▉         | 36/367 [00:00<00:01, 173.75it/s]Pre-training Epoch 81:  15%|█▍        | 55/367 [00:00<00:01, 176.93it/s]Pre-training Epoch 81:  20%|█▉        | 73/367 [00:00<00:01, 178.01it/s]Pre-training Epoch 81:  25%|██▍       | 91/367 [00:00<00:01, 177.89it/s]Pre-training Epoch 81:  30%|██▉       | 109/367 [00:00<00:01, 171.27it/s]recon_loss: 0.02799953706562519, dist_loss: 0.9380545616149902
recon_loss: 0.02799932472407818, dist_loss: 0.3737223148345947
recon_loss: 0.027999265119433403, dist_loss: 0.49097418785095215
recon_loss: 0.027998974546790123, dist_loss: 0.3944101333618164
recon_loss: 0.0279987845569849, dist_loss: 0.4823375940322876
recon_loss: 0.02799849398434162, dist_loss: 0.6412951946258545
recon_loss: 0.027998145669698715, dist_loss: 0.7102496027946472
recon_loss: 0.02799815684556961, dist_loss: 0.8108208775520325
recon_loss: 0.027998125180602074, dist_loss: 0.42800605297088623
recon_loss: 0.02799833007156849, dist_loss: 1.026787519454956
recon_loss: 0.02799816057085991, dist_loss: 0.6773819327354431
recon_loss: 0.02799813449382782, dist_loss: 0.5307741761207581
recon_loss: 0.027997875586152077, dist_loss: 0.3186206817626953
recon_loss: 0.027997633442282677, dist_loss: 0.8336162567138672
recon_loss: 0.027997175231575966, dist_loss: 0.6148068308830261
recon_loss: 0.027997221797704697, dist_loss: 0.6441507935523987
recon_loss: 0.02799799107015133, dist_loss: 0.7423510551452637
recon_loss: 0.02799771912395954, dist_loss: 0.44776371121406555
recon_loss: 0.027998879551887512, dist_loss: 0.5629169940948486
recon_loss: 0.02799852006137371, dist_loss: 0.43876010179519653
recon_loss: 0.027997860684990883, dist_loss: 0.40980881452560425
recon_loss: 0.027998052537441254, dist_loss: 0.5714797973632812
recon_loss: 0.027996940538287163, dist_loss: 0.8043870329856873
recon_loss: 0.027996601536870003, dist_loss: 0.33971452713012695
recon_loss: 0.027996713295578957, dist_loss: 0.9585226774215698
recon_loss: 0.027995901182293892, dist_loss: 0.5754526853561401
recon_loss: 0.027996668592095375, dist_loss: 0.6079245805740356
recon_loss: 0.02799621969461441, dist_loss: 0.5841019153594971
recon_loss: 0.02799646370112896, dist_loss: 0.5435649156570435
recon_loss: 0.027996590360999107, dist_loss: 0.3621214032173157
recon_loss: 0.027996599674224854, dist_loss: 1.100766897201538
recon_loss: 0.027996227145195007, dist_loss: 1.044193983078003
recon_loss: 0.027995629236102104, dist_loss: 0.434479683637619
recon_loss: 0.027995280921459198, dist_loss: 0.5027117729187012
recon_loss: 0.02799537591636181, dist_loss: 0.7716547250747681
recon_loss: 0.027995632961392403, dist_loss: 0.9815809726715088
recon_loss: 0.027996594086289406, dist_loss: 0.7595521211624146
recon_loss: 0.02799750491976738, dist_loss: 0.5274203419685364
recon_loss: 0.02799834869801998, dist_loss: 0.534630298614502
recon_loss: 0.027998749166727066, dist_loss: 0.577560544013977
recon_loss: 0.02799849957227707, dist_loss: 0.7588895559310913
recon_loss: 0.027998318895697594, dist_loss: 0.8333771228790283
recon_loss: 0.027997754514217377, dist_loss: 1.0443795919418335
recon_loss: 0.027997605502605438, dist_loss: 0.8422083854675293
recon_loss: 0.027997350320219994, dist_loss: 0.7808706760406494
recon_loss: 0.027997441589832306, dist_loss: 0.5366021394729614
recon_loss: 0.027997344732284546, dist_loss: 0.664272665977478
recon_loss: 0.027996735647320747, dist_loss: 0.6340612173080444
recon_loss: 0.027996433898806572, dist_loss: 0.8719292879104614
recon_loss: 0.02799561619758606, dist_loss: 0.43760859966278076
recon_loss: 0.02799593284726143, dist_loss: 0.6181477904319763
recon_loss: 0.027995117008686066, dist_loss: 0.686682403087616
recon_loss: 0.027994927018880844, dist_loss: 0.5847806930541992
recon_loss: 0.02799469605088234, dist_loss: 0.5919995307922363
recon_loss: 0.027994850650429726, dist_loss: 0.6553647518157959
recon_loss: 0.027995632961392403, dist_loss: 0.6095905303955078
recon_loss: 0.027995780110359192, dist_loss: 0.4214775562286377
recon_loss: 0.027995673939585686, dist_loss: 0.8497002124786377
recon_loss: 0.02799556776881218, dist_loss: 0.3311834931373596
recon_loss: 0.02799571119248867, dist_loss: 0.8442628979682922
recon_loss: 0.02799558825790882, dist_loss: 0.4574882984161377
recon_loss: 0.027995195239782333, dist_loss: 0.7457613348960876
recon_loss: 0.027994606643915176, dist_loss: 0.5253082513809204
recon_loss: 0.027994075790047646, dist_loss: 0.7031734585762024
recon_loss: 0.02799396589398384, dist_loss: 0.6079402565956116
recon_loss: 0.027993831783533096, dist_loss: 0.705247163772583
recon_loss: 0.02799362689256668, dist_loss: 0.45745140314102173
recon_loss: 0.027993520721793175, dist_loss: 0.5717569589614868
recon_loss: 0.027993256226181984, dist_loss: 1.1286953687667847
recon_loss: 0.027993524447083473, dist_loss: 0.9283668994903564
recon_loss: 0.027994424104690552, dist_loss: 0.5979611873626709
recon_loss: 0.02799462527036667, dist_loss: 0.6736292839050293
recon_loss: 0.027996579185128212, dist_loss: 0.5529590249061584
recon_loss: 0.027996845543384552, dist_loss: 0.4561200737953186
recon_loss: 0.02799830213189125, dist_loss: 1.0591946840286255
recon_loss: 0.028000548481941223, dist_loss: 0.5078797340393066
recon_loss: 0.028000954538583755, dist_loss: 0.4529278874397278
recon_loss: 0.02800196036696434, dist_loss: 0.5526895523071289
recon_loss: 0.028002116829156876, dist_loss: 0.5790795087814331
recon_loss: 0.02800210565328598, dist_loss: 0.855605959892273
recon_loss: 0.028001688420772552, dist_loss: 0.9795233011245728
recon_loss: 0.02800132893025875, dist_loss: 1.1400104761123657
recon_loss: 0.028000760823488235, dist_loss: 1.0086551904678345
recon_loss: 0.02799946255981922, dist_loss: 0.6468948721885681
recon_loss: 0.02799863927066326, dist_loss: 0.5468016862869263
recon_loss: 0.027997490018606186, dist_loss: 0.7956199645996094
recon_loss: 0.027996623888611794, dist_loss: 0.9267538785934448
recon_loss: 0.027995707467198372, dist_loss: 0.7973512411117554
recon_loss: 0.027995271608233452, dist_loss: 0.6812914609909058
recon_loss: 0.027995092794299126, dist_loss: 0.8959068059921265
recon_loss: 0.027995679527521133, dist_loss: 0.7256609201431274
recon_loss: 0.027996627613902092, dist_loss: 0.5168647766113281
recon_loss: 0.02799750491976738, dist_loss: 0.8227318525314331
recon_loss: 0.027997663244605064, dist_loss: 0.4934704303741455
recon_loss: 0.02799784578382969, dist_loss: 0.5654042959213257
recon_loss: 0.027997655794024467, dist_loss: 0.7144112586975098
recon_loss: 0.02799740992486477, dist_loss: 0.9861545562744141
recon_loss: 0.027996893972158432, dist_loss: 0.4751439094543457
recon_loss: 0.02799646370112896, dist_loss: 0.7578384876251221
recon_loss: 0.027996238321065903, dist_loss: 0.543394923210144
recon_loss: 0.027995126321911812, dist_loss: 0.49268442392349243
recon_loss: 0.02799392305314541, dist_loss: 0.9873024225234985
recon_loss: 0.027993256226181984, dist_loss: 0.5047906637191772
recon_loss: 0.02799275331199169, dist_loss: 0.47227489948272705
recon_loss: 0.02799256145954132, dist_loss: 0.9601698517799377
recon_loss: 0.027992522343993187, dist_loss: 0.6064983606338501
recon_loss: 0.02799251303076744, dist_loss: 0.46801504492759705
recon_loss: 0.027992460876703262, dist_loss: 0.5349770784378052
recon_loss: 0.027992412447929382, dist_loss: 0.4615058898925781
recon_loss: 0.02799205109477043, dist_loss: 0.6967485547065735
recon_loss: 0.02799213118851185, dist_loss: 0.466124564409256
recon_loss: 0.027991769835352898, dist_loss: 1.2622065544128418
recon_loss: 0.027991613373160362, dist_loss: 0.8980082273483276
recon_loss: 0.027991365641355515, dist_loss: 0.41237860918045044
recon_loss: 0.027991048991680145, dist_loss: 0.7232869863510132
recon_loss: 0.02799144573509693, dist_loss: 0.8008520007133484
recon_loss: 0.0279910359531641, dist_loss: 0.2688523232936859
recon_loss: 0.02799133211374283, dist_loss: 0.72113037109375
recon_loss: 0.027990689501166344, dist_loss: 1.0664398670196533
recon_loss: 0.027989892289042473, dist_loss: 0.75295490026474
recon_loss: 0.027989886701107025, dist_loss: 0.4427608847618103
recon_loss: 0.027990194037556648, dist_loss: 0.5742491483688354
recon_loss: 0.027990130707621574, dist_loss: 0.8374645709991455
recon_loss: 0.02799065038561821, dist_loss: 0.7342830300331116
recon_loss: 0.027990786358714104, dist_loss: 0.40783822536468506
recon_loss: 0.02799100987613201, dist_loss: 0.5344058275222778
recon_loss: 0.02799092046916485, dist_loss: 0.6309564113616943
recon_loss: 0.027990570291876793, dist_loss: 0.7310201525688171
Pre-training Epoch 81:  35%|███▌      | 129/367 [00:00<00:01, 177.41it/s]Pre-training Epoch 81:  41%|████      | 149/367 [00:00<00:01, 182.01it/s]Pre-training Epoch 81:  46%|████▌     | 169/367 [00:00<00:01, 184.63it/s]Pre-training Epoch 81:  51%|█████▏    | 189/367 [00:01<00:00, 186.56it/s]Pre-training Epoch 81:  57%|█████▋    | 209/367 [00:01<00:00, 188.20it/s]Pre-training Epoch 81:  62%|██████▏   | 229/367 [00:01<00:00, 189.47it/s]Pre-training Epoch 81:  68%|██████▊   | 249/367 [00:01<00:00, 190.24it/s]recon_loss: 0.02799040451645851, dist_loss: 0.6471009850502014
recon_loss: 0.027990348637104034, dist_loss: 0.42473334074020386
recon_loss: 0.027990002185106277, dist_loss: 0.4595218896865845
recon_loss: 0.02798963524401188, dist_loss: 0.7889713048934937
recon_loss: 0.027989324182271957, dist_loss: 0.549720823764801
recon_loss: 0.027989111840724945, dist_loss: 0.3022545278072357
recon_loss: 0.027988804504275322, dist_loss: 0.5060673952102661
recon_loss: 0.027988411486148834, dist_loss: 0.7104965448379517
recon_loss: 0.027988197281956673, dist_loss: 0.5272543430328369
recon_loss: 0.027987826615571976, dist_loss: 0.8566392660140991
recon_loss: 0.027987686917185783, dist_loss: 0.6354352831840515
recon_loss: 0.027987487614154816, dist_loss: 0.47863972187042236
recon_loss: 0.027987301349639893, dist_loss: 0.7453869581222534
recon_loss: 0.027987413108348846, dist_loss: 1.1579108238220215
recon_loss: 0.027987366542220116, dist_loss: 0.9228600263595581
recon_loss: 0.027987228706479073, dist_loss: 1.0890319347381592
recon_loss: 0.02798740565776825, dist_loss: 0.4725918769836426
recon_loss: 0.027987303212285042, dist_loss: 0.3865569829940796
recon_loss: 0.027988044545054436, dist_loss: 0.46547871828079224
recon_loss: 0.027988368645310402, dist_loss: 0.6640642881393433
recon_loss: 0.027988798916339874, dist_loss: 0.43317657709121704
recon_loss: 0.027989545837044716, dist_loss: 1.1607719659805298
recon_loss: 0.027988431975245476, dist_loss: 0.319599986076355
recon_loss: 0.02798832394182682, dist_loss: 0.8141357898712158
recon_loss: 0.027987921610474586, dist_loss: 0.9708574414253235
recon_loss: 0.027987122535705566, dist_loss: 0.48987746238708496
recon_loss: 0.027987083420157433, dist_loss: 0.7980377674102783
recon_loss: 0.027986686676740646, dist_loss: 0.6304319500923157
recon_loss: 0.027987316250801086, dist_loss: 0.39317604899406433
recon_loss: 0.027986757457256317, dist_loss: 0.715052604675293
recon_loss: 0.02798713743686676, dist_loss: 0.7360696792602539
recon_loss: 0.02798718959093094, dist_loss: 0.7229848504066467
recon_loss: 0.027987178415060043, dist_loss: 0.6603001356124878
recon_loss: 0.02798740565776825, dist_loss: 0.6802557706832886
recon_loss: 0.02798733487725258, dist_loss: 0.3926883339881897
recon_loss: 0.027987560257315636, dist_loss: 0.7711526155471802
recon_loss: 0.027987224981188774, dist_loss: 0.23281095921993256
recon_loss: 0.02798721194267273, dist_loss: 0.6480128169059753
recon_loss: 0.027986746281385422, dist_loss: 0.7354973554611206
recon_loss: 0.027986887842416763, dist_loss: 0.6606749892234802
recon_loss: 0.02798638306558132, dist_loss: 0.6211308240890503
recon_loss: 0.027985962107777596, dist_loss: 0.5405819416046143
recon_loss: 0.027985574677586555, dist_loss: 0.7354260683059692
recon_loss: 0.02798525243997574, dist_loss: 0.5738406181335449
recon_loss: 0.0279849786311388, dist_loss: 0.48728370666503906
recon_loss: 0.02798464708030224, dist_loss: 1.067035436630249
recon_loss: 0.02798430807888508, dist_loss: 1.190061330795288
recon_loss: 0.027983998879790306, dist_loss: 0.8096630573272705
recon_loss: 0.027983859181404114, dist_loss: 0.4643891453742981
recon_loss: 0.027983862906694412, dist_loss: 0.4470762610435486
recon_loss: 0.027983836829662323, dist_loss: 0.7093977928161621
recon_loss: 0.027984127402305603, dist_loss: 0.3880707025527954
recon_loss: 0.027984220534563065, dist_loss: 0.8333213925361633
recon_loss: 0.027984146028757095, dist_loss: 0.6804337501525879
recon_loss: 0.027983805164694786, dist_loss: 0.6065317392349243
recon_loss: 0.02798360213637352, dist_loss: 0.5775445699691772
recon_loss: 0.027983475476503372, dist_loss: 1.1279104948043823
recon_loss: 0.0279832873493433, dist_loss: 0.4534643888473511
recon_loss: 0.027983084321022034, dist_loss: 0.7269229292869568
recon_loss: 0.027983061969280243, dist_loss: 0.3903864026069641
recon_loss: 0.027982866391539574, dist_loss: 0.28687942028045654
recon_loss: 0.027983039617538452, dist_loss: 1.1430110931396484
recon_loss: 0.027982866391539574, dist_loss: 0.9889217019081116
recon_loss: 0.02798301726579666, dist_loss: 0.4680485129356384
recon_loss: 0.02798336185514927, dist_loss: 0.417399525642395
recon_loss: 0.02798377349972725, dist_loss: 0.48654383420944214
recon_loss: 0.027983902022242546, dist_loss: 0.6226462125778198
recon_loss: 0.027983762323856354, dist_loss: 0.7876290678977966
recon_loss: 0.02798346057534218, dist_loss: 0.5503249168395996
recon_loss: 0.027983101084828377, dist_loss: 1.0775166749954224
recon_loss: 0.027982888743281364, dist_loss: 0.9192239046096802
recon_loss: 0.02798280119895935, dist_loss: 0.7059147953987122
recon_loss: 0.027982883155345917, dist_loss: 0.8092095255851746
recon_loss: 0.027983037754893303, dist_loss: 0.5927698612213135
recon_loss: 0.027983136475086212, dist_loss: 0.7840016484260559
recon_loss: 0.027983054518699646, dist_loss: 0.5227953195571899
recon_loss: 0.027983112260699272, dist_loss: 0.9252758622169495
recon_loss: 0.027982568368315697, dist_loss: 0.8037329912185669
recon_loss: 0.027982383966445923, dist_loss: 1.155623435974121
recon_loss: 0.027982197701931, dist_loss: 0.7824218273162842
recon_loss: 0.027982359752058983, dist_loss: 0.5382908582687378
recon_loss: 0.027981918305158615, dist_loss: 0.5327622890472412
recon_loss: 0.027981849387288094, dist_loss: 0.4213399291038513
recon_loss: 0.027981549501419067, dist_loss: 0.5911390781402588
recon_loss: 0.027981465682387352, dist_loss: 1.0732073783874512
recon_loss: 0.02798214554786682, dist_loss: 0.6287800073623657
recon_loss: 0.027982065454125404, dist_loss: 0.6235061883926392
recon_loss: 0.02798238955438137, dist_loss: 0.6059309840202332
recon_loss: 0.02798202633857727, dist_loss: 0.5876674652099609
recon_loss: 0.027982577681541443, dist_loss: 0.6934620141983032
recon_loss: 0.02798212692141533, dist_loss: 0.7456667423248291
recon_loss: 0.02798178419470787, dist_loss: 0.5782133340835571
recon_loss: 0.027981365099549294, dist_loss: 0.6346909403800964
recon_loss: 0.02798079140484333, dist_loss: 0.8942030072212219
recon_loss: 0.0279811043292284, dist_loss: 0.44975751638412476
recon_loss: 0.027980681508779526, dist_loss: 0.48515552282333374
recon_loss: 0.027981052175164223, dist_loss: 0.4568726420402527
recon_loss: 0.027981216087937355, dist_loss: 0.6388859748840332
recon_loss: 0.027981679886579514, dist_loss: 0.5698261260986328
recon_loss: 0.027982095256447792, dist_loss: 0.8560259938240051
recon_loss: 0.027981765568256378, dist_loss: 0.6967051029205322
recon_loss: 0.02798233926296234, dist_loss: 0.45631441473960876
recon_loss: 0.027980701997876167, dist_loss: 1.040613055229187
recon_loss: 0.027981383726000786, dist_loss: 0.5702887773513794
recon_loss: 0.02798067405819893, dist_loss: 0.453171968460083
recon_loss: 0.027981750667095184, dist_loss: 0.8636852502822876
recon_loss: 0.027981111779808998, dist_loss: 0.6297096014022827
recon_loss: 0.027981426566839218, dist_loss: 0.6194571852684021
recon_loss: 0.027982106432318687, dist_loss: 0.5392482280731201
recon_loss: 0.02798081561923027, dist_loss: 0.8998093008995056
recon_loss: 0.02798006869852543, dist_loss: 0.7984886169433594
recon_loss: 0.02797989919781685, dist_loss: 0.6750067472457886
recon_loss: 0.027979612350463867, dist_loss: 0.8447444438934326
recon_loss: 0.02798059955239296, dist_loss: 0.9812870025634766
recon_loss: 0.027980223298072815, dist_loss: 0.7437163591384888
recon_loss: 0.027980715036392212, dist_loss: 0.8300216794013977
recon_loss: 0.02798008732497692, dist_loss: 0.6924201250076294
recon_loss: 0.027979547157883644, dist_loss: 0.6482642292976379
recon_loss: 0.027979925274848938, dist_loss: 0.5667673945426941
recon_loss: 0.027979232370853424, dist_loss: 0.4664510488510132
recon_loss: 0.02797960862517357, dist_loss: 0.7976081371307373
recon_loss: 0.027979353442788124, dist_loss: 1.3767144680023193
recon_loss: 0.027978673577308655, dist_loss: 0.5602031946182251
recon_loss: 0.027978722006082535, dist_loss: 0.8294627666473389
recon_loss: 0.02797900140285492, dist_loss: 0.6491701602935791
recon_loss: 0.027979198843240738, dist_loss: 0.42315760254859924
recon_loss: 0.027979182079434395, dist_loss: 0.4887162744998932
recon_loss: 0.027979163452982903, dist_loss: 0.7045555710792542
Pre-training Epoch 81:  73%|███████▎  | 269/367 [00:01<00:00, 190.83it/s]Pre-training Epoch 81:  79%|███████▊  | 289/367 [00:01<00:00, 191.25it/s]Pre-training Epoch 81:  84%|████████▍ | 309/367 [00:01<00:00, 191.10it/s]Pre-training Epoch 81:  90%|████████▉ | 329/367 [00:01<00:00, 191.52it/s]Pre-training Epoch 81:  95%|█████████▌| 349/367 [00:01<00:00, 191.95it/s]Pre-training Epoch 81: 100%|██████████| 367/367 [00:01<00:00, 186.01it/s]
recon_loss: 0.027978962287306786, dist_loss: 0.6449263095855713
recon_loss: 0.02797895483672619, dist_loss: 0.9772985577583313
recon_loss: 0.027979012578725815, dist_loss: 0.5224055051803589
recon_loss: 0.027979113161563873, dist_loss: 0.28912097215652466
recon_loss: 0.02797945961356163, dist_loss: 1.276712417602539
recon_loss: 0.027979519218206406, dist_loss: 0.9615776538848877
recon_loss: 0.027979636564850807, dist_loss: 0.7622765302658081
recon_loss: 0.027979597449302673, dist_loss: 0.6003643870353699
recon_loss: 0.027979254722595215, dist_loss: 0.7626152038574219
recon_loss: 0.027979226782917976, dist_loss: 0.761307954788208
recon_loss: 0.02797914855182171, dist_loss: 0.6553844809532166
recon_loss: 0.027978984639048576, dist_loss: 1.5332906246185303
recon_loss: 0.027979344129562378, dist_loss: 0.5413929224014282
recon_loss: 0.027979249134659767, dist_loss: 0.3455759584903717
recon_loss: 0.027979740872979164, dist_loss: 0.5111933946609497
recon_loss: 0.02797926776111126, dist_loss: 0.6035507917404175
recon_loss: 0.02797894924879074, dist_loss: 0.6179007887840271
recon_loss: 0.027978792786598206, dist_loss: 0.46480563282966614
recon_loss: 0.027978377416729927, dist_loss: 0.561555027961731
recon_loss: 0.02797863818705082, dist_loss: 1.1120500564575195
recon_loss: 0.027978437021374702, dist_loss: 0.46591275930404663
recon_loss: 0.027978427708148956, dist_loss: 0.5631839036941528
recon_loss: 0.02797846868634224, dist_loss: 0.5957046747207642
recon_loss: 0.0279784444719553, dist_loss: 0.6397688984870911
recon_loss: 0.027978191152215004, dist_loss: 0.7015438079833984
recon_loss: 0.02797761932015419, dist_loss: 0.813730001449585
recon_loss: 0.02797735668718815, dist_loss: 1.2944045066833496
recon_loss: 0.027977315708994865, dist_loss: 0.6443544626235962
recon_loss: 0.027977444231510162, dist_loss: 0.43306833505630493
recon_loss: 0.027977392077445984, dist_loss: 0.7396497130393982
recon_loss: 0.027977462857961655, dist_loss: 0.8779689073562622
recon_loss: 0.027976788580417633, dist_loss: 0.4580978751182556
recon_loss: 0.027976607903838158, dist_loss: 0.43876051902770996
recon_loss: 0.027976850047707558, dist_loss: 0.5059880018234253
recon_loss: 0.02797684445977211, dist_loss: 0.34327155351638794
recon_loss: 0.027976684272289276, dist_loss: 0.5815081596374512
recon_loss: 0.02797684445977211, dist_loss: 0.44209402799606323
recon_loss: 0.027977371588349342, dist_loss: 0.7163910865783691
recon_loss: 0.027978073805570602, dist_loss: 0.8598523736000061
recon_loss: 0.027978451922535896, dist_loss: 0.46179595589637756
recon_loss: 0.027978915721178055, dist_loss: 0.5108246803283691
recon_loss: 0.027978960424661636, dist_loss: 0.6491008996963501
recon_loss: 0.02797899767756462, dist_loss: 0.6446399688720703
recon_loss: 0.02797921746969223, dist_loss: 0.46790164709091187
recon_loss: 0.027979334816336632, dist_loss: 0.9620344042778015
recon_loss: 0.027978867292404175, dist_loss: 0.5295145511627197
recon_loss: 0.027978403493762016, dist_loss: 0.4882507622241974
recon_loss: 0.027977805584669113, dist_loss: 0.4309230148792267
recon_loss: 0.02797711081802845, dist_loss: 0.7865114212036133
recon_loss: 0.02797674760222435, dist_loss: 0.9280093908309937
recon_loss: 0.02797582559287548, dist_loss: 0.5188329219818115
recon_loss: 0.02797570824623108, dist_loss: 0.6340965032577515
recon_loss: 0.02797580137848854, dist_loss: 0.36573004722595215
recon_loss: 0.027975603938102722, dist_loss: 0.23171189427375793
recon_loss: 0.02797604165971279, dist_loss: 1.0119924545288086
recon_loss: 0.0279755387455225, dist_loss: 0.7694596648216248
recon_loss: 0.02797546237707138, dist_loss: 0.5146076679229736
recon_loss: 0.027975648641586304, dist_loss: 0.4702526032924652
recon_loss: 0.027975881472229958, dist_loss: 0.6540349721908569
recon_loss: 0.02797631546854973, dist_loss: 0.6836397647857666
recon_loss: 0.027976183220744133, dist_loss: 0.6706336736679077
recon_loss: 0.027976645156741142, dist_loss: 0.548121452331543
recon_loss: 0.027976881712675095, dist_loss: 0.4780251383781433
recon_loss: 0.02797684632241726, dist_loss: 0.5592100620269775
recon_loss: 0.027976851910352707, dist_loss: 0.9124782085418701
recon_loss: 0.027975739911198616, dist_loss: 0.5956542491912842
recon_loss: 0.027975481003522873, dist_loss: 0.41471579670906067
recon_loss: 0.02797386422753334, dist_loss: 0.4228537082672119
recon_loss: 0.02797412872314453, dist_loss: 0.50907301902771
recon_loss: 0.027973327785730362, dist_loss: 0.34385526180267334
recon_loss: 0.027973903343081474, dist_loss: 0.5941665768623352
recon_loss: 0.027973437681794167, dist_loss: 0.5412006378173828
recon_loss: 0.027973005548119545, dist_loss: 0.8165295124053955
recon_loss: 0.027972634881734848, dist_loss: 0.6753644943237305
recon_loss: 0.027972331270575523, dist_loss: 1.022361397743225
recon_loss: 0.027972547337412834, dist_loss: 0.3726762533187866
recon_loss: 0.027972128242254257, dist_loss: 0.7138356566429138
recon_loss: 0.027972351759672165, dist_loss: 0.9365655183792114
recon_loss: 0.027972329407930374, dist_loss: 0.36945033073425293
recon_loss: 0.027972832322120667, dist_loss: 0.6521825790405273
recon_loss: 0.027972865849733353, dist_loss: 0.5148797035217285
recon_loss: 0.027972901239991188, dist_loss: 0.5412898063659668
recon_loss: 0.027973471209406853, dist_loss: 0.3709850311279297
recon_loss: 0.027974070981144905, dist_loss: 0.5367869138717651
recon_loss: 0.02797451801598072, dist_loss: 0.5016310811042786
recon_loss: 0.027974463999271393, dist_loss: 0.6580662727355957
recon_loss: 0.02797459065914154, dist_loss: 0.7343762516975403
recon_loss: 0.02797449566423893, dist_loss: 0.34878477454185486
recon_loss: 0.027974138036370277, dist_loss: 0.6954333782196045
recon_loss: 0.027973707765340805, dist_loss: 0.6749589443206787
recon_loss: 0.027973247691988945, dist_loss: 0.3744947016239166
recon_loss: 0.027972843497991562, dist_loss: 0.6741363406181335
recon_loss: 0.027972515672445297, dist_loss: 0.6454961895942688
recon_loss: 0.027972282841801643, dist_loss: 0.732747495174408
recon_loss: 0.027972396463155746, dist_loss: 0.5157768130302429
recon_loss: 0.027971593663096428, dist_loss: 0.7720162272453308
recon_loss: 0.02797159180045128, dist_loss: 0.2924371659755707
recon_loss: 0.02797164022922516, dist_loss: 0.678734302520752
recon_loss: 0.027972295880317688, dist_loss: 0.40005847811698914
recon_loss: 0.027972551062703133, dist_loss: 0.32101330161094666
recon_loss: 0.027973148971796036, dist_loss: 0.5222277045249939
recon_loss: 0.02797343209385872, dist_loss: 0.40902233123779297
recon_loss: 0.027973471209406853, dist_loss: 0.2983716130256653
recon_loss: 0.027974091470241547, dist_loss: 0.6920644044876099
recon_loss: 0.02797381579875946, dist_loss: 1.0354671478271484
recon_loss: 0.02797326073050499, dist_loss: 0.6678452491760254
recon_loss: 0.02797238528728485, dist_loss: 0.7604550123214722
recon_loss: 0.027972659096121788, dist_loss: 0.7698567509651184
recon_loss: 0.02797173149883747, dist_loss: 1.1102834939956665
recon_loss: 0.02797199971973896, dist_loss: 0.8066240549087524
recon_loss: 0.02797243371605873, dist_loss: 0.2079211324453354
Pre-training Epoch 82:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 82:   5%|▌         | 19/367 [00:00<00:01, 188.99it/s]Pre-training Epoch 82:  11%|█         | 39/367 [00:00<00:01, 190.99it/s]Pre-training Epoch 82:  16%|█▌        | 59/367 [00:00<00:01, 191.75it/s]Pre-training Epoch 82:  22%|██▏       | 79/367 [00:00<00:01, 191.93it/s]Pre-training Epoch 82:  27%|██▋       | 99/367 [00:00<00:01, 188.35it/s]Pre-training Epoch 82:  32%|███▏      | 118/367 [00:00<00:01, 179.75it/s]recon_loss: 0.02797219529747963, dist_loss: 0.4867875576019287
recon_loss: 0.027972467243671417, dist_loss: 0.4153292775154114
recon_loss: 0.027971627190709114, dist_loss: 0.891381561756134
recon_loss: 0.027971815317869186, dist_loss: 0.8181143403053284
recon_loss: 0.027971450239419937, dist_loss: 0.5016623735427856
recon_loss: 0.02797039784491062, dist_loss: 0.7493541240692139
recon_loss: 0.02796981669962406, dist_loss: 0.2809222340583801
recon_loss: 0.027969587594270706, dist_loss: 0.7134807109832764
recon_loss: 0.027969563379883766, dist_loss: 0.5316871404647827
recon_loss: 0.027969488874077797, dist_loss: 0.8105058670043945
recon_loss: 0.02796941064298153, dist_loss: 0.46855154633522034
recon_loss: 0.0279692392796278, dist_loss: 0.9198428392410278
recon_loss: 0.027969202026724815, dist_loss: 0.9585788249969482
recon_loss: 0.027968764305114746, dist_loss: 0.8232725858688354
recon_loss: 0.027968842536211014, dist_loss: 0.590448796749115
recon_loss: 0.02796839363873005, dist_loss: 0.8937180638313293
recon_loss: 0.02796829678118229, dist_loss: 0.5253958702087402
recon_loss: 0.027968289330601692, dist_loss: 0.5265102386474609
recon_loss: 0.027968058362603188, dist_loss: 0.5740729570388794
recon_loss: 0.02796836569905281, dist_loss: 0.7730416655540466
recon_loss: 0.02796802669763565, dist_loss: 0.5719064474105835
recon_loss: 0.027968211099505424, dist_loss: 0.6307151317596436
recon_loss: 0.027967730537056923, dist_loss: 0.8433078527450562
recon_loss: 0.027968155220150948, dist_loss: 0.6845892667770386
recon_loss: 0.02796950936317444, dist_loss: 0.8658536672592163
recon_loss: 0.027969779446721077, dist_loss: 0.8859381079673767
recon_loss: 0.027971211820840836, dist_loss: 0.6555227637290955
recon_loss: 0.027971377596259117, dist_loss: 0.6708846092224121
recon_loss: 0.027970613911747932, dist_loss: 0.31590187549591064
recon_loss: 0.027971690520644188, dist_loss: 0.4283410906791687
recon_loss: 0.027970105409622192, dist_loss: 0.7746198177337646
recon_loss: 0.027970392256975174, dist_loss: 0.41425448656082153
recon_loss: 0.0279697235673666, dist_loss: 0.4730494022369385
recon_loss: 0.027969462797045708, dist_loss: 0.5960403084754944
recon_loss: 0.027969812974333763, dist_loss: 0.9157793521881104
recon_loss: 0.027969831600785255, dist_loss: 0.6098694801330566
recon_loss: 0.027971820905804634, dist_loss: 0.4365314841270447
recon_loss: 0.027972202748060226, dist_loss: 0.9763404130935669
recon_loss: 0.02797485888004303, dist_loss: 0.5481222867965698
recon_loss: 0.027976244688034058, dist_loss: 0.5551857948303223
recon_loss: 0.02797631546854973, dist_loss: 0.7959283590316772
recon_loss: 0.02797624096274376, dist_loss: 0.4295073449611664
recon_loss: 0.027975913137197495, dist_loss: 0.6410468816757202
recon_loss: 0.02797563001513481, dist_loss: 0.42779332399368286
recon_loss: 0.02797476015985012, dist_loss: 0.9427576661109924
recon_loss: 0.027973327785730362, dist_loss: 1.035906195640564
recon_loss: 0.027972271665930748, dist_loss: 0.4074947237968445
recon_loss: 0.02797147072851658, dist_loss: 0.7738374471664429
recon_loss: 0.02797071263194084, dist_loss: 1.0705167055130005
recon_loss: 0.027969900518655777, dist_loss: 0.6465638875961304
recon_loss: 0.027968822047114372, dist_loss: 0.6484636664390564
recon_loss: 0.027967993170022964, dist_loss: 0.5479048490524292
recon_loss: 0.027967197820544243, dist_loss: 0.3815804123878479
recon_loss: 0.027966775000095367, dist_loss: 0.641783595085144
recon_loss: 0.0279662124812603, dist_loss: 0.9355858564376831
recon_loss: 0.027965908870100975, dist_loss: 0.7451909780502319
recon_loss: 0.027965664863586426, dist_loss: 0.41297972202301025
recon_loss: 0.027965277433395386, dist_loss: 0.5670639276504517
recon_loss: 0.02796563133597374, dist_loss: 0.784008264541626
recon_loss: 0.027965230867266655, dist_loss: 0.6657268404960632
recon_loss: 0.027964847162365913, dist_loss: 0.4467582702636719
recon_loss: 0.027965055778622627, dist_loss: 0.609943151473999
recon_loss: 0.027965078130364418, dist_loss: 0.9811288714408875
recon_loss: 0.02796531468629837, dist_loss: 1.2919204235076904
recon_loss: 0.0279652439057827, dist_loss: 0.9378600120544434
recon_loss: 0.02796579711139202, dist_loss: 0.8604955077171326
recon_loss: 0.02796541340649128, dist_loss: 0.5486437082290649
recon_loss: 0.027965988963842392, dist_loss: 0.7308545112609863
recon_loss: 0.027966288849711418, dist_loss: 0.7026286125183105
recon_loss: 0.027966856956481934, dist_loss: 0.3715074956417084
recon_loss: 0.02796679176390171, dist_loss: 0.6856987476348877
recon_loss: 0.02796667255461216, dist_loss: 1.0387194156646729
recon_loss: 0.027966594323515892, dist_loss: 0.41917869448661804
recon_loss: 0.027965761721134186, dist_loss: 0.5443267822265625
recon_loss: 0.027966033667325974, dist_loss: 0.8138489723205566
recon_loss: 0.027965005487203598, dist_loss: 1.1629486083984375
recon_loss: 0.027964787557721138, dist_loss: 0.903931736946106
recon_loss: 0.027964482083916664, dist_loss: 0.5029336810112
recon_loss: 0.027963818982243538, dist_loss: 0.6374678611755371
recon_loss: 0.027963776141405106, dist_loss: 0.46467095613479614
recon_loss: 0.027962956577539444, dist_loss: 1.1102375984191895
recon_loss: 0.02796267904341221, dist_loss: 0.6317936182022095
recon_loss: 0.02796262875199318, dist_loss: 0.8773785829544067
recon_loss: 0.02796209789812565, dist_loss: 0.37682798504829407
recon_loss: 0.027962317690253258, dist_loss: 0.9186006784439087
recon_loss: 0.027962632477283478, dist_loss: 0.9660022258758545
recon_loss: 0.02796262316405773, dist_loss: 0.5734248757362366
recon_loss: 0.027962643653154373, dist_loss: 0.5687422752380371
recon_loss: 0.02796243503689766, dist_loss: 0.7565805912017822
recon_loss: 0.027962373569607735, dist_loss: 0.6845362782478333
recon_loss: 0.02796202152967453, dist_loss: 0.4391299784183502
recon_loss: 0.0279618501663208, dist_loss: 0.41559162735939026
recon_loss: 0.027961600571870804, dist_loss: 0.4769902229309082
recon_loss: 0.027961518615484238, dist_loss: 0.5030467510223389
recon_loss: 0.027961337938904762, dist_loss: 0.9341902136802673
recon_loss: 0.027962079271674156, dist_loss: 0.40934452414512634
recon_loss: 0.027962226420640945, dist_loss: 0.8890814781188965
recon_loss: 0.027962766587734222, dist_loss: 0.6934662461280823
recon_loss: 0.027962809428572655, dist_loss: 0.7334069013595581
recon_loss: 0.02796277031302452, dist_loss: 0.42341193556785583
recon_loss: 0.02796264737844467, dist_loss: 0.45188072323799133
recon_loss: 0.027962282299995422, dist_loss: 0.5251322984695435
recon_loss: 0.02796189859509468, dist_loss: 0.4067990183830261
recon_loss: 0.027961324900388718, dist_loss: 0.6160002946853638
recon_loss: 0.027961252257227898, dist_loss: 0.5568653345108032
recon_loss: 0.027961311861872673, dist_loss: 0.7490513920783997
recon_loss: 0.02796149253845215, dist_loss: 0.481645405292511
recon_loss: 0.02796175330877304, dist_loss: 0.6481411457061768
recon_loss: 0.02796148508787155, dist_loss: 1.0890626907348633
recon_loss: 0.02796158753335476, dist_loss: 0.6225232481956482
recon_loss: 0.02796170301735401, dist_loss: 0.6866235733032227
recon_loss: 0.02796165458858013, dist_loss: 0.659523606300354
recon_loss: 0.027961667627096176, dist_loss: 0.42504531145095825
recon_loss: 0.0279608853161335, dist_loss: 0.25712451338768005
recon_loss: 0.02796098217368126, dist_loss: 0.7503682374954224
recon_loss: 0.02796121872961521, dist_loss: 0.38023191690444946
recon_loss: 0.02796042338013649, dist_loss: 0.4526452124118805
recon_loss: 0.027960292994976044, dist_loss: 0.717273473739624
recon_loss: 0.027959922328591347, dist_loss: 1.2210958003997803
recon_loss: 0.027959803119301796, dist_loss: 0.627042829990387
recon_loss: 0.02796025760471821, dist_loss: 0.5242695808410645
recon_loss: 0.027960142120718956, dist_loss: 0.4126788079738617
recon_loss: 0.027960574254393578, dist_loss: 0.5458288192749023
recon_loss: 0.027960920706391335, dist_loss: 0.4258747398853302
recon_loss: 0.027960702776908875, dist_loss: 1.0900640487670898
recon_loss: 0.027960168197751045, dist_loss: 0.6653865575790405
recon_loss: 0.027960198000073433, dist_loss: 0.4123304784297943
recon_loss: 0.02795974351465702, dist_loss: 0.4726119637489319
Pre-training Epoch 82:  37%|███▋      | 137/367 [00:00<00:01, 174.18it/s]Pre-training Epoch 82:  42%|████▏     | 155/367 [00:00<00:01, 170.95it/s]Pre-training Epoch 82:  47%|████▋     | 173/367 [00:00<00:01, 167.71it/s]Pre-training Epoch 82:  53%|█████▎    | 193/367 [00:01<00:00, 175.60it/s]Pre-training Epoch 82:  57%|█████▋    | 211/367 [00:01<00:00, 173.09it/s]Pre-training Epoch 82:  62%|██████▏   | 229/367 [00:01<00:00, 174.53it/s]Pre-training Epoch 82:  67%|██████▋   | 247/367 [00:01<00:00, 173.24it/s]recon_loss: 0.027959538623690605, dist_loss: 0.5820420980453491
recon_loss: 0.027959724888205528, dist_loss: 0.7237650156021118
recon_loss: 0.027959298342466354, dist_loss: 0.5451148748397827
recon_loss: 0.02795989066362381, dist_loss: 1.0085244178771973
recon_loss: 0.027959227561950684, dist_loss: 0.800966203212738
recon_loss: 0.02795901894569397, dist_loss: 0.8702832460403442
recon_loss: 0.027958638966083527, dist_loss: 0.8126000165939331
recon_loss: 0.027959167957305908, dist_loss: 1.1192783117294312
recon_loss: 0.027960339561104774, dist_loss: 0.5537213683128357
recon_loss: 0.027960380539298058, dist_loss: 0.431899756193161
recon_loss: 0.027960155159235, dist_loss: 0.707242488861084
recon_loss: 0.027959425002336502, dist_loss: 0.6792765855789185
recon_loss: 0.02796000801026821, dist_loss: 0.7369513511657715
recon_loss: 0.027959594503045082, dist_loss: 0.40657949447631836
recon_loss: 0.02795877493917942, dist_loss: 0.647004246711731
recon_loss: 0.027958344668149948, dist_loss: 0.6286190748214722
recon_loss: 0.027958134189248085, dist_loss: 0.6821529865264893
recon_loss: 0.027957968413829803, dist_loss: 0.6218587160110474
recon_loss: 0.02795758657157421, dist_loss: 0.6553407907485962
recon_loss: 0.02795742079615593, dist_loss: 0.8198375701904297
recon_loss: 0.027958031743764877, dist_loss: 0.6136539578437805
recon_loss: 0.027959583327174187, dist_loss: 0.4028601050376892
recon_loss: 0.02796105481684208, dist_loss: 0.791083037853241
recon_loss: 0.027962656691670418, dist_loss: 0.30084890127182007
recon_loss: 0.027964428067207336, dist_loss: 0.9355285167694092
recon_loss: 0.027967184782028198, dist_loss: 0.7003941535949707
recon_loss: 0.027969615533947945, dist_loss: 0.46368852257728577
recon_loss: 0.027972787618637085, dist_loss: 0.634689450263977
recon_loss: 0.027974309399724007, dist_loss: 0.5568419098854065
recon_loss: 0.027974605560302734, dist_loss: 1.0982121229171753
recon_loss: 0.027976954355835915, dist_loss: 0.5145400762557983
recon_loss: 0.027978088706731796, dist_loss: 0.5102634429931641
recon_loss: 0.027979621663689613, dist_loss: 1.0065410137176514
recon_loss: 0.027979552745819092, dist_loss: 0.4922577142715454
recon_loss: 0.02797801047563553, dist_loss: 0.4158003032207489
recon_loss: 0.027976686134934425, dist_loss: 0.6966577172279358
recon_loss: 0.027973836287856102, dist_loss: 0.668885350227356
recon_loss: 0.027972565963864326, dist_loss: 0.7069281339645386
recon_loss: 0.02796885557472706, dist_loss: 0.7144287824630737
recon_loss: 0.027966972440481186, dist_loss: 0.6240115761756897
recon_loss: 0.027965731918811798, dist_loss: 0.8358502388000488
recon_loss: 0.027965031564235687, dist_loss: 0.674938440322876
recon_loss: 0.027966320514678955, dist_loss: 0.47161543369293213
recon_loss: 0.027966341003775597, dist_loss: 0.46697425842285156
recon_loss: 0.02796855755150318, dist_loss: 0.9950320720672607
recon_loss: 0.027970081195235252, dist_loss: 0.8648714423179626
recon_loss: 0.02797173149883747, dist_loss: 0.42204898595809937
recon_loss: 0.027971966192126274, dist_loss: 0.9832427501678467
recon_loss: 0.027971193194389343, dist_loss: 0.7836198806762695
recon_loss: 0.027970606461167336, dist_loss: 1.0931174755096436
recon_loss: 0.02796933241188526, dist_loss: 0.35519397258758545
recon_loss: 0.027967872098088264, dist_loss: 0.4576241075992584
recon_loss: 0.027966124936938286, dist_loss: 0.8750647306442261
recon_loss: 0.02796458825469017, dist_loss: 0.7042892575263977
recon_loss: 0.027963126078248024, dist_loss: 0.4251554012298584
recon_loss: 0.027961937710642815, dist_loss: 0.6157801151275635
recon_loss: 0.027961086481809616, dist_loss: 1.2742714881896973
recon_loss: 0.027959773316979408, dist_loss: 0.43812549114227295
recon_loss: 0.027959154918789864, dist_loss: 0.4491390585899353
recon_loss: 0.027958564460277557, dist_loss: 0.9597811698913574
recon_loss: 0.027958080172538757, dist_loss: 0.5619902014732361
recon_loss: 0.0279578547924757, dist_loss: 0.39359956979751587
recon_loss: 0.02795725129544735, dist_loss: 0.5663679838180542
recon_loss: 0.027956891804933548, dist_loss: 0.792182207107544
recon_loss: 0.027956321835517883, dist_loss: 0.9181913137435913
recon_loss: 0.02795567363500595, dist_loss: 0.39916568994522095
recon_loss: 0.02795541100203991, dist_loss: 0.6553310751914978
recon_loss: 0.027955632656812668, dist_loss: 0.4977880120277405
recon_loss: 0.027955999597907066, dist_loss: 0.8138154149055481
recon_loss: 0.027956511825323105, dist_loss: 0.5553537607192993
recon_loss: 0.027957377955317497, dist_loss: 0.43252265453338623
recon_loss: 0.027957625687122345, dist_loss: 0.5766953825950623
recon_loss: 0.027958350256085396, dist_loss: 0.46442711353302
recon_loss: 0.027958521619439125, dist_loss: 0.5001047849655151
recon_loss: 0.027958130463957787, dist_loss: 0.4254297614097595
recon_loss: 0.027957608923316002, dist_loss: 0.5953705310821533
recon_loss: 0.027956662699580193, dist_loss: 0.35765713453292847
recon_loss: 0.027956081554293633, dist_loss: 0.7525616884231567
recon_loss: 0.027955668047070503, dist_loss: 0.3621516823768616
recon_loss: 0.02795586735010147, dist_loss: 0.7024859189987183
recon_loss: 0.027955807745456696, dist_loss: 0.6019149422645569
recon_loss: 0.027956442907452583, dist_loss: 0.6195007562637329
recon_loss: 0.027957195416092873, dist_loss: 0.7939934730529785
recon_loss: 0.027957649901509285, dist_loss: 0.4712796211242676
recon_loss: 0.027958454564213753, dist_loss: 0.46189063787460327
recon_loss: 0.027958158403635025, dist_loss: 0.6449384093284607
recon_loss: 0.027959724888205528, dist_loss: 0.43530625104904175
recon_loss: 0.027959555387496948, dist_loss: 1.1847376823425293
recon_loss: 0.027960972860455513, dist_loss: 0.6410247087478638
recon_loss: 0.027960719540715218, dist_loss: 0.6158020496368408
recon_loss: 0.027960628271102905, dist_loss: 0.6520581841468811
recon_loss: 0.027961337938904762, dist_loss: 0.6820106506347656
recon_loss: 0.02796022966504097, dist_loss: 0.5206823945045471
recon_loss: 0.027960853651165962, dist_loss: 0.750545859336853
recon_loss: 0.02796083316206932, dist_loss: 0.9644273519515991
recon_loss: 0.02796141617000103, dist_loss: 0.4996700584888458
recon_loss: 0.027961062267422676, dist_loss: 1.4028615951538086
recon_loss: 0.027960525825619698, dist_loss: 0.4014076292514801
recon_loss: 0.027959827333688736, dist_loss: 0.6750943660736084
recon_loss: 0.02795928716659546, dist_loss: 1.2543585300445557
recon_loss: 0.0279588233679533, dist_loss: 1.1177242994308472
recon_loss: 0.02795679308474064, dist_loss: 0.6393409967422485
recon_loss: 0.027956461533904076, dist_loss: 1.1934807300567627
recon_loss: 0.0279547069221735, dist_loss: 0.8774706125259399
recon_loss: 0.027955131605267525, dist_loss: 0.7284857034683228
recon_loss: 0.027954015880823135, dist_loss: 1.0411431789398193
recon_loss: 0.02795388549566269, dist_loss: 0.7441295385360718
recon_loss: 0.0279545895755291, dist_loss: 0.8015245199203491
recon_loss: 0.027954138815402985, dist_loss: 0.9449235796928406
recon_loss: 0.027953123673796654, dist_loss: 0.8467217683792114
recon_loss: 0.02795320376753807, dist_loss: 0.48942849040031433
recon_loss: 0.027952713891863823, dist_loss: 0.679512083530426
recon_loss: 0.027952663600444794, dist_loss: 0.6527363061904907
recon_loss: 0.02795250527560711, dist_loss: 0.49536532163619995
recon_loss: 0.027952449396252632, dist_loss: 0.638330340385437
recon_loss: 0.02795354649424553, dist_loss: 0.4733334183692932
recon_loss: 0.02795405127108097, dist_loss: 0.6446553468704224
recon_loss: 0.027955543249845505, dist_loss: 0.23084045946598053
recon_loss: 0.027957230806350708, dist_loss: 0.5750327110290527
recon_loss: 0.027958599850535393, dist_loss: 0.630886971950531
recon_loss: 0.0279600340873003, dist_loss: 0.5432906746864319
recon_loss: 0.027960292994976044, dist_loss: 0.8699887990951538
recon_loss: 0.0279611274600029, dist_loss: 0.5359682440757751
recon_loss: 0.027961092069745064, dist_loss: 0.5831376910209656
recon_loss: 0.02796061523258686, dist_loss: 0.6243257522583008
recon_loss: 0.027959300205111504, dist_loss: 0.6700571775436401
recon_loss: 0.027957618236541748, dist_loss: 0.5510687828063965
recon_loss: 0.027955980971455574, dist_loss: 0.7647683620452881
Pre-training Epoch 82:  72%|███████▏  | 265/367 [00:01<00:00, 174.68it/s]Pre-training Epoch 82:  77%|███████▋  | 284/367 [00:01<00:00, 176.59it/s]Pre-training Epoch 82:  82%|████████▏ | 302/367 [00:01<00:00, 177.18it/s]Pre-training Epoch 82:  87%|████████▋ | 320/367 [00:01<00:00, 177.79it/s]Pre-training Epoch 82:  92%|█████████▏| 338/367 [00:01<00:00, 178.17it/s]Pre-training Epoch 82:  97%|█████████▋| 356/367 [00:02<00:00, 178.06it/s]Pre-training Epoch 82: 100%|██████████| 367/367 [00:02<00:00, 177.91it/s]
recon_loss: 0.027954716235399246, dist_loss: 0.4721137285232544
recon_loss: 0.027953704819083214, dist_loss: 0.6782703995704651
recon_loss: 0.02795303612947464, dist_loss: 0.7040929794311523
recon_loss: 0.02795265056192875, dist_loss: 0.6180610656738281
recon_loss: 0.027952441945672035, dist_loss: 1.0029631853103638
recon_loss: 0.027952421456575394, dist_loss: 0.7052811980247498
recon_loss: 0.0279525276273489, dist_loss: 0.8047938346862793
recon_loss: 0.02795323356986046, dist_loss: 0.7080533504486084
recon_loss: 0.027953671291470528, dist_loss: 0.903035044670105
recon_loss: 0.027953829616308212, dist_loss: 0.7394678592681885
recon_loss: 0.027953870594501495, dist_loss: 1.1893484592437744
recon_loss: 0.02795448899269104, dist_loss: 0.5151177644729614
recon_loss: 0.02795490249991417, dist_loss: 0.4206172525882721
recon_loss: 0.027954405173659325, dist_loss: 0.8327623605728149
recon_loss: 0.02795407734811306, dist_loss: 0.44635528326034546
recon_loss: 0.027953477576375008, dist_loss: 0.37557193636894226
recon_loss: 0.027952969074249268, dist_loss: 0.6800346374511719
recon_loss: 0.02795240841805935, dist_loss: 0.50380539894104
recon_loss: 0.02795172668993473, dist_loss: 1.0203065872192383
recon_loss: 0.027950843796133995, dist_loss: 0.46042197942733765
recon_loss: 0.027949774637818336, dist_loss: 0.506418764591217
recon_loss: 0.027949009090662003, dist_loss: 0.6862354278564453
recon_loss: 0.02794913947582245, dist_loss: 0.6846059560775757
recon_loss: 0.02794940583407879, dist_loss: 0.5863873958587646
recon_loss: 0.02795015648007393, dist_loss: 0.35241860151290894
recon_loss: 0.02795049548149109, dist_loss: 0.5437644720077515
recon_loss: 0.02795068733394146, dist_loss: 0.4999145269393921
recon_loss: 0.027950946241617203, dist_loss: 0.6989864110946655
recon_loss: 0.027950717136263847, dist_loss: 0.6363776922225952
recon_loss: 0.02795007824897766, dist_loss: 0.6002712249755859
recon_loss: 0.027949312701821327, dist_loss: 0.6179798245429993
recon_loss: 0.027948660776019096, dist_loss: 0.7713640332221985
recon_loss: 0.027948306873440742, dist_loss: 1.0356196165084839
recon_loss: 0.027948299422860146, dist_loss: 0.7491225004196167
recon_loss: 0.027948452159762383, dist_loss: 0.4767515957355499
recon_loss: 0.027948234230279922, dist_loss: 0.6859305500984192
recon_loss: 0.027948034927248955, dist_loss: 0.6539704203605652
recon_loss: 0.027947958558797836, dist_loss: 0.5900660753250122
recon_loss: 0.027948062866926193, dist_loss: 0.809431791305542
recon_loss: 0.027948010712862015, dist_loss: 0.5329413414001465
recon_loss: 0.02794787660241127, dist_loss: 0.8053030371665955
recon_loss: 0.027947792783379555, dist_loss: 0.80588698387146
recon_loss: 0.02794734016060829, dist_loss: 0.43295973539352417
recon_loss: 0.02794712223112583, dist_loss: 1.001675009727478
recon_loss: 0.02794686332345009, dist_loss: 1.1097279787063599
recon_loss: 0.027946725487709045, dist_loss: 0.7077355980873108
recon_loss: 0.027946999296545982, dist_loss: 0.2488667070865631
recon_loss: 0.02794726938009262, dist_loss: 0.5565476417541504
recon_loss: 0.02794749289751053, dist_loss: 0.485853910446167
recon_loss: 0.027948204427957535, dist_loss: 0.6580188274383545
recon_loss: 0.027949102222919464, dist_loss: 0.40233004093170166
recon_loss: 0.027949919924139977, dist_loss: 0.6109397411346436
recon_loss: 0.02795080468058586, dist_loss: 0.6353715062141418
recon_loss: 0.027951834723353386, dist_loss: 0.7442712187767029
recon_loss: 0.02795225940644741, dist_loss: 0.37293562293052673
recon_loss: 0.02795274928212166, dist_loss: 0.7396112680435181
recon_loss: 0.02795206755399704, dist_loss: 0.46546196937561035
recon_loss: 0.027950959280133247, dist_loss: 0.5560121536254883
recon_loss: 0.02794918604195118, dist_loss: 0.6753073930740356
recon_loss: 0.027948295697569847, dist_loss: 0.37016206979751587
recon_loss: 0.027947744354605675, dist_loss: 0.4178122878074646
recon_loss: 0.027948174625635147, dist_loss: 0.5427197813987732
recon_loss: 0.02794935181736946, dist_loss: 0.5086856484413147
recon_loss: 0.02795119769871235, dist_loss: 0.7119255661964417
recon_loss: 0.027952201664447784, dist_loss: 0.5289050340652466
recon_loss: 0.02795160748064518, dist_loss: 0.8258066177368164
recon_loss: 0.02795177511870861, dist_loss: 0.6732301712036133
recon_loss: 0.02795271947979927, dist_loss: 0.3989974558353424
recon_loss: 0.027953695505857468, dist_loss: 0.7539411783218384
recon_loss: 0.02795526199042797, dist_loss: 0.5311412215232849
recon_loss: 0.027953360229730606, dist_loss: 0.5878496170043945
recon_loss: 0.02795177325606346, dist_loss: 0.5600448846817017
recon_loss: 0.02795102261006832, dist_loss: 1.338180661201477
recon_loss: 0.027949264273047447, dist_loss: 0.400023490190506
recon_loss: 0.02794942632317543, dist_loss: 0.541130542755127
recon_loss: 0.02794756554067135, dist_loss: 1.166393756866455
recon_loss: 0.027947725728154182, dist_loss: 0.693252444267273
recon_loss: 0.02794618345797062, dist_loss: 0.45743805170059204
recon_loss: 0.027945656329393387, dist_loss: 0.29182755947113037
recon_loss: 0.02794562466442585, dist_loss: 0.4682723879814148
recon_loss: 0.027944767847657204, dist_loss: 0.9136760234832764
recon_loss: 0.027945689857006073, dist_loss: 0.4841856360435486
recon_loss: 0.027944685891270638, dist_loss: 0.3050980567932129
recon_loss: 0.027944747358560562, dist_loss: 0.913429319858551
recon_loss: 0.027945393696427345, dist_loss: 0.43769747018814087
recon_loss: 0.027944102883338928, dist_loss: 0.4525619149208069
recon_loss: 0.027945706620812416, dist_loss: 1.0308263301849365
recon_loss: 0.027944084256887436, dist_loss: 1.5602788925170898
recon_loss: 0.027943477034568787, dist_loss: 0.6598602533340454
recon_loss: 0.027943812310695648, dist_loss: 0.7534867525100708
recon_loss: 0.027942681685090065, dist_loss: 0.5441622734069824
recon_loss: 0.027943937107920647, dist_loss: 0.5423574447631836
recon_loss: 0.027943087741732597, dist_loss: 0.42422688007354736
recon_loss: 0.02794376201927662, dist_loss: 0.6501611471176147
recon_loss: 0.027945110574364662, dist_loss: 0.5057684183120728
recon_loss: 0.02794501557946205, dist_loss: 0.768904983997345
recon_loss: 0.027946574613451958, dist_loss: 0.518179178237915
recon_loss: 0.027945561334490776, dist_loss: 0.5030686855316162
recon_loss: 0.027945825830101967, dist_loss: 0.7711379528045654
recon_loss: 0.027945568785071373, dist_loss: 0.4962692856788635
recon_loss: 0.02794395200908184, dist_loss: 0.6607365012168884
recon_loss: 0.02794461138546467, dist_loss: 0.742918074131012
recon_loss: 0.027943015098571777, dist_loss: 0.9109647274017334
recon_loss: 0.027942853048443794, dist_loss: 0.4864460229873657
recon_loss: 0.027942633256316185, dist_loss: 0.5750219225883484
recon_loss: 0.027942383661866188, dist_loss: 0.837324321269989
recon_loss: 0.027943259105086327, dist_loss: 0.5874848365783691
recon_loss: 0.02794269286096096, dist_loss: 0.6720244288444519
recon_loss: 0.02794317714869976, dist_loss: 0.7065690755844116
recon_loss: 0.027942342683672905, dist_loss: 0.5210596323013306
recon_loss: 0.027942413464188576, dist_loss: 1.0274146795272827
Pre-training Epoch 83:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 83:   4%|▍         | 16/367 [00:00<00:02, 152.29it/s]Pre-training Epoch 83:   9%|▊         | 32/367 [00:00<00:02, 150.55it/s]Pre-training Epoch 83:  13%|█▎        | 48/367 [00:00<00:02, 152.53it/s]Pre-training Epoch 83:  17%|█▋        | 64/367 [00:00<00:01, 154.23it/s]Pre-training Epoch 83:  22%|██▏       | 80/367 [00:00<00:01, 154.73it/s]Pre-training Epoch 83:  26%|██▌       | 96/367 [00:00<00:01, 152.53it/s]Pre-training Epoch 83:  31%|███       | 112/367 [00:00<00:01, 153.70it/s]Pre-training Epoch 83:  35%|███▍      | 128/367 [00:00<00:01, 148.13it/s]recon_loss: 0.02794218808412552, dist_loss: 0.4643593430519104
recon_loss: 0.027941955253481865, dist_loss: 0.8166433572769165
recon_loss: 0.027942350134253502, dist_loss: 0.5193506479263306
recon_loss: 0.027941621840000153, dist_loss: 0.6333434581756592
recon_loss: 0.02794167771935463, dist_loss: 0.9075978994369507
recon_loss: 0.027942687273025513, dist_loss: 0.5160372257232666
recon_loss: 0.02794298529624939, dist_loss: 0.6014792919158936
recon_loss: 0.027943497523665428, dist_loss: 0.8198137283325195
recon_loss: 0.02794293314218521, dist_loss: 0.7074539661407471
recon_loss: 0.027943260967731476, dist_loss: 0.2926453649997711
recon_loss: 0.02794255129992962, dist_loss: 0.8667935132980347
recon_loss: 0.027942845597863197, dist_loss: 0.5378174185752869
recon_loss: 0.027943190187215805, dist_loss: 0.5911647081375122
recon_loss: 0.02794131077826023, dist_loss: 0.5406183004379272
recon_loss: 0.027943236753344536, dist_loss: 0.4597494900226593
recon_loss: 0.027940714731812477, dist_loss: 0.5629006028175354
recon_loss: 0.027941953390836716, dist_loss: 0.8602026700973511
recon_loss: 0.027942437678575516, dist_loss: 0.6829338073730469
recon_loss: 0.02793997712433338, dist_loss: 0.5670318603515625
recon_loss: 0.027942435815930367, dist_loss: 0.43481165170669556
recon_loss: 0.027941400185227394, dist_loss: 0.5968708992004395
recon_loss: 0.02794051542878151, dist_loss: 0.5776607990264893
recon_loss: 0.027941200882196426, dist_loss: 1.0248064994812012
recon_loss: 0.027939843013882637, dist_loss: 0.669587254524231
recon_loss: 0.027942227199673653, dist_loss: 0.909548819065094
recon_loss: 0.02794050984084606, dist_loss: 0.7168004512786865
recon_loss: 0.027942625805735588, dist_loss: 0.6975622177124023
recon_loss: 0.02794228494167328, dist_loss: 0.3926604390144348
recon_loss: 0.027940643951296806, dist_loss: 0.47120600938796997
recon_loss: 0.027941592037677765, dist_loss: 1.1713647842407227
recon_loss: 0.027939923107624054, dist_loss: 0.5370308756828308
recon_loss: 0.02794131077826023, dist_loss: 0.4987289011478424
recon_loss: 0.027940496802330017, dist_loss: 0.8680159449577332
recon_loss: 0.027940941974520683, dist_loss: 1.321570873260498
recon_loss: 0.027942387387156487, dist_loss: 0.5800742506980896
recon_loss: 0.02794080227613449, dist_loss: 0.9320847988128662
recon_loss: 0.02794419601559639, dist_loss: 0.5742020010948181
recon_loss: 0.027942325919866562, dist_loss: 0.8803576827049255
recon_loss: 0.027941560372710228, dist_loss: 0.6120010614395142
recon_loss: 0.027942616492509842, dist_loss: 0.4899643063545227
recon_loss: 0.02794046513736248, dist_loss: 0.7791597843170166
recon_loss: 0.02794250100851059, dist_loss: 0.5772369503974915
recon_loss: 0.02793979085981846, dist_loss: 1.0085409879684448
recon_loss: 0.02794002555310726, dist_loss: 0.5569350719451904
recon_loss: 0.027940567582845688, dist_loss: 0.7283589839935303
recon_loss: 0.02793918550014496, dist_loss: 0.4019816219806671
recon_loss: 0.027939721941947937, dist_loss: 0.853489339351654
recon_loss: 0.027938833460211754, dist_loss: 0.5279616117477417
recon_loss: 0.02793877013027668, dist_loss: 0.8835591077804565
recon_loss: 0.02793862856924534, dist_loss: 0.8036336302757263
recon_loss: 0.0279382336884737, dist_loss: 0.6782823204994202
recon_loss: 0.0279384832829237, dist_loss: 0.805837094783783
recon_loss: 0.027939055114984512, dist_loss: 0.39863941073417664
recon_loss: 0.0279386043548584, dist_loss: 0.36093324422836304
recon_loss: 0.027939721941947937, dist_loss: 0.5653198957443237
recon_loss: 0.027938738465309143, dist_loss: 0.7564014196395874
recon_loss: 0.027938565239310265, dist_loss: 0.5010875463485718
recon_loss: 0.02793891169130802, dist_loss: 0.6961588859558105
recon_loss: 0.027937665581703186, dist_loss: 0.5471793413162231
recon_loss: 0.027938848361372948, dist_loss: 0.8924342393875122
recon_loss: 0.0279378741979599, dist_loss: 0.4426928162574768
recon_loss: 0.027938565239310265, dist_loss: 0.9140763878822327
recon_loss: 0.02793852612376213, dist_loss: 0.67447829246521
recon_loss: 0.027938811108469963, dist_loss: 0.5514687895774841
recon_loss: 0.027939898893237114, dist_loss: 0.6858075261116028
recon_loss: 0.027939066290855408, dist_loss: 0.5405304431915283
recon_loss: 0.02794027328491211, dist_loss: 0.7958787679672241
recon_loss: 0.02793872356414795, dist_loss: 0.7049510478973389
recon_loss: 0.027939312160015106, dist_loss: 1.1502530574798584
recon_loss: 0.027938205748796463, dist_loss: 0.2188250571489334
recon_loss: 0.02793767675757408, dist_loss: 0.9042908549308777
recon_loss: 0.027937108650803566, dist_loss: 0.5379431247711182
recon_loss: 0.027936812490224838, dist_loss: 1.561044454574585
recon_loss: 0.027936983853578568, dist_loss: 0.7469489574432373
recon_loss: 0.027936948463320732, dist_loss: 0.8985251188278198
recon_loss: 0.02793714962899685, dist_loss: 0.7860080003738403
recon_loss: 0.0279373861849308, dist_loss: 1.0752513408660889
recon_loss: 0.02793734148144722, dist_loss: 1.1294056177139282
recon_loss: 0.027938755229115486, dist_loss: 0.23680561780929565
recon_loss: 0.02793983556330204, dist_loss: 0.47369447350502014
recon_loss: 0.027940258383750916, dist_loss: 0.819934606552124
recon_loss: 0.02794051356613636, dist_loss: 0.6183120608329773
recon_loss: 0.02794019877910614, dist_loss: 0.686323881149292
recon_loss: 0.027939990162849426, dist_loss: 0.7358757853507996
recon_loss: 0.02793899178504944, dist_loss: 0.6074299812316895
recon_loss: 0.02793843485414982, dist_loss: 0.509873628616333
recon_loss: 0.02793680876493454, dist_loss: 0.6484478116035461
recon_loss: 0.027936356142163277, dist_loss: 0.22965699434280396
recon_loss: 0.027936333790421486, dist_loss: 0.7294216156005859
recon_loss: 0.02793627232313156, dist_loss: 0.6567437648773193
recon_loss: 0.027936644852161407, dist_loss: 0.9554292559623718
recon_loss: 0.027936555445194244, dist_loss: 0.5058044791221619
recon_loss: 0.027936676517128944, dist_loss: 0.4281807839870453
recon_loss: 0.027936823666095734, dist_loss: 0.7111188173294067
recon_loss: 0.027936585247516632, dist_loss: 0.5343430042266846
recon_loss: 0.027937298640608788, dist_loss: 0.49805229902267456
recon_loss: 0.02793663553893566, dist_loss: 0.5321109294891357
recon_loss: 0.027936754748225212, dist_loss: 0.6352749466896057
recon_loss: 0.02793644182384014, dist_loss: 0.593061625957489
recon_loss: 0.027935251593589783, dist_loss: 0.8882379531860352
recon_loss: 0.02793474681675434, dist_loss: 0.7940636873245239
recon_loss: 0.02793433889746666, dist_loss: 0.8947381973266602
recon_loss: 0.027934443205595016, dist_loss: 1.11992609500885
recon_loss: 0.027934418991208076, dist_loss: 0.6304455995559692
recon_loss: 0.02793494053184986, dist_loss: 0.7804325819015503
recon_loss: 0.027935495600104332, dist_loss: 1.1834404468536377
recon_loss: 0.02793615125119686, dist_loss: 0.5128464698791504
recon_loss: 0.027936341241002083, dist_loss: 0.6037673950195312
recon_loss: 0.02793547324836254, dist_loss: 0.5729948282241821
recon_loss: 0.02793549932539463, dist_loss: 0.5762816071510315
recon_loss: 0.027935536578297615, dist_loss: 1.0105314254760742
recon_loss: 0.0279358122497797, dist_loss: 0.41473639011383057
recon_loss: 0.02793589048087597, dist_loss: 0.6354994177818298
recon_loss: 0.027934877201914787, dist_loss: 0.8449188470840454
recon_loss: 0.027934474870562553, dist_loss: 0.6467832922935486
recon_loss: 0.027934860438108444, dist_loss: 0.9114297032356262
recon_loss: 0.027934394776821136, dist_loss: 0.8506758213043213
recon_loss: 0.027934102341532707, dist_loss: 0.5188101530075073
recon_loss: 0.02793378010392189, dist_loss: 0.34118330478668213
recon_loss: 0.027933698147535324, dist_loss: 0.8745392560958862
recon_loss: 0.027934150770306587, dist_loss: 0.774744987487793
recon_loss: 0.027933547273278236, dist_loss: 0.6941864490509033
recon_loss: 0.02793373540043831, dist_loss: 0.5154755711555481
recon_loss: 0.02793280966579914, dist_loss: 0.6153231859207153
recon_loss: 0.027933169156312943, dist_loss: 0.3985193371772766
recon_loss: 0.02793320268392563, dist_loss: 0.4796285629272461
recon_loss: 0.027932804077863693, dist_loss: 1.3463501930236816
recon_loss: 0.027933211997151375, dist_loss: 0.8232811689376831
recon_loss: 0.02793274261057377, dist_loss: 0.38295838236808777
Pre-training Epoch 83:  39%|███▉      | 144/367 [00:00<00:01, 149.36it/s]Pre-training Epoch 83:  44%|████▎     | 160/367 [00:01<00:01, 151.41it/s]Pre-training Epoch 83:  48%|████▊     | 177/367 [00:01<00:01, 156.07it/s]Pre-training Epoch 83:  53%|█████▎    | 195/367 [00:01<00:01, 161.86it/s]Pre-training Epoch 83:  58%|█████▊    | 213/367 [00:01<00:00, 166.22it/s]Pre-training Epoch 83:  63%|██████▎   | 231/367 [00:01<00:00, 170.17it/s]Pre-training Epoch 83:  68%|██████▊   | 249/367 [00:01<00:00, 172.09it/s]recon_loss: 0.027933407574892044, dist_loss: 0.7967721819877625
recon_loss: 0.02793397195637226, dist_loss: 0.517454981803894
recon_loss: 0.027933869510889053, dist_loss: 0.8102294206619263
recon_loss: 0.027934251353144646, dist_loss: 0.5781130790710449
recon_loss: 0.027932794764637947, dist_loss: 0.5496001243591309
recon_loss: 0.027932308614253998, dist_loss: 0.3893129229545593
recon_loss: 0.02793227508664131, dist_loss: 0.9363370537757874
recon_loss: 0.02793264389038086, dist_loss: 0.29737475514411926
recon_loss: 0.027933064848184586, dist_loss: 0.4364117383956909
recon_loss: 0.027933524921536446, dist_loss: 0.4772137403488159
recon_loss: 0.02793392539024353, dist_loss: 0.5138143301010132
recon_loss: 0.027933672070503235, dist_loss: 0.6841921806335449
recon_loss: 0.02793373167514801, dist_loss: 0.5808460712432861
recon_loss: 0.027932988479733467, dist_loss: 0.9364862442016602
recon_loss: 0.027932465076446533, dist_loss: 0.7326174974441528
recon_loss: 0.027932336553931236, dist_loss: 0.48914623260498047
recon_loss: 0.0279319416731596, dist_loss: 1.0965771675109863
recon_loss: 0.02793177217245102, dist_loss: 0.7438062429428101
recon_loss: 0.027932070195674896, dist_loss: 0.392997682094574
recon_loss: 0.02793269231915474, dist_loss: 0.4062063694000244
recon_loss: 0.027932846918702126, dist_loss: 0.9457502365112305
recon_loss: 0.02793237194418907, dist_loss: 0.5666715502738953
recon_loss: 0.02793208695948124, dist_loss: 0.6437154412269592
recon_loss: 0.027932051569223404, dist_loss: 0.33647677302360535
recon_loss: 0.02793203480541706, dist_loss: 0.6037604808807373
recon_loss: 0.02793143130838871, dist_loss: 0.43751055002212524
recon_loss: 0.027931049466133118, dist_loss: 0.44080448150634766
recon_loss: 0.027931073680520058, dist_loss: 0.7449365258216858
recon_loss: 0.02793162688612938, dist_loss: 0.5403786897659302
recon_loss: 0.02793211303651333, dist_loss: 0.3805379271507263
recon_loss: 0.027932684868574142, dist_loss: 0.7521430253982544
recon_loss: 0.027933096513152122, dist_loss: 0.4884476363658905
recon_loss: 0.02793358638882637, dist_loss: 0.7707326412200928
recon_loss: 0.02793373167514801, dist_loss: 0.7705408334732056
recon_loss: 0.02793397754430771, dist_loss: 0.4150186777114868
recon_loss: 0.02793470211327076, dist_loss: 0.5284118056297302
recon_loss: 0.027935385704040527, dist_loss: 1.0505280494689941
recon_loss: 0.02793527953326702, dist_loss: 0.906969428062439
recon_loss: 0.027935709804296494, dist_loss: 0.6631539463996887
recon_loss: 0.027933962643146515, dist_loss: 0.5606667995452881
recon_loss: 0.02793339639902115, dist_loss: 0.3789762854576111
recon_loss: 0.027933236211538315, dist_loss: 0.614884078502655
recon_loss: 0.027931857854127884, dist_loss: 0.4164363145828247
recon_loss: 0.027932262048125267, dist_loss: 0.5016011595726013
recon_loss: 0.02793213725090027, dist_loss: 0.7458393573760986
recon_loss: 0.027932465076446533, dist_loss: 0.6977255344390869
recon_loss: 0.027933461591601372, dist_loss: 0.9133937358856201
recon_loss: 0.02793397754430771, dist_loss: 0.5776855945587158
recon_loss: 0.02793649397790432, dist_loss: 0.5948461294174194
recon_loss: 0.02793707512319088, dist_loss: 0.5057296752929688
recon_loss: 0.027939843013882637, dist_loss: 0.7414782643318176
recon_loss: 0.027939986437559128, dist_loss: 0.9405936002731323
recon_loss: 0.027938883751630783, dist_loss: 0.5939775705337524
recon_loss: 0.027938684448599815, dist_loss: 0.27397215366363525
recon_loss: 0.027936743572354317, dist_loss: 0.5138993263244629
recon_loss: 0.027936184778809547, dist_loss: 0.6012673377990723
recon_loss: 0.0279349684715271, dist_loss: 0.6673727035522461
recon_loss: 0.027933984994888306, dist_loss: 0.9420974850654602
recon_loss: 0.027933195233345032, dist_loss: 1.1478227376937866
recon_loss: 0.027931585907936096, dist_loss: 0.5328096747398376
recon_loss: 0.02793196588754654, dist_loss: 0.49794095754623413
recon_loss: 0.02793162502348423, dist_loss: 0.5554810166358948
recon_loss: 0.027932757511734962, dist_loss: 0.44263756275177
recon_loss: 0.027934104204177856, dist_loss: 0.5599853992462158
recon_loss: 0.02793414331972599, dist_loss: 0.7321063876152039
recon_loss: 0.027935665100812912, dist_loss: 0.6874681115150452
recon_loss: 0.02793513797223568, dist_loss: 0.633026659488678
recon_loss: 0.027935974299907684, dist_loss: 0.7398097515106201
recon_loss: 0.027934975922107697, dist_loss: 0.4401898980140686
recon_loss: 0.027933456003665924, dist_loss: 1.075338363647461
recon_loss: 0.02793317846953869, dist_loss: 0.7585498094558716
recon_loss: 0.027931522578001022, dist_loss: 0.513707160949707
recon_loss: 0.02793166972696781, dist_loss: 0.575568675994873
recon_loss: 0.027930499985814095, dist_loss: 0.5524163246154785
recon_loss: 0.02793045900762081, dist_loss: 0.6154704093933105
recon_loss: 0.02793068252503872, dist_loss: 0.3825967013835907
recon_loss: 0.02792934514582157, dist_loss: 0.4512072205543518
recon_loss: 0.027930108830332756, dist_loss: 0.5555610656738281
recon_loss: 0.02793005108833313, dist_loss: 0.5768914222717285
recon_loss: 0.027930106967687607, dist_loss: 1.127054214477539
recon_loss: 0.027930565178394318, dist_loss: 0.5054064393043518
recon_loss: 0.027929645031690598, dist_loss: 0.5253607630729675
recon_loss: 0.027929577976465225, dist_loss: 0.8898792862892151
recon_loss: 0.027928462252020836, dist_loss: 0.8463531732559204
recon_loss: 0.02792835421860218, dist_loss: 0.6343820691108704
recon_loss: 0.027927299961447716, dist_loss: 0.6012578010559082
recon_loss: 0.027927033603191376, dist_loss: 0.8289950489997864
recon_loss: 0.027927210554480553, dist_loss: 0.4055598974227905
recon_loss: 0.027927495539188385, dist_loss: 0.6793278455734253
recon_loss: 0.027928426861763, dist_loss: 0.582062840461731
recon_loss: 0.027928484603762627, dist_loss: 0.40276455879211426
recon_loss: 0.02792903408408165, dist_loss: 1.3988018035888672
recon_loss: 0.027929231524467468, dist_loss: 0.863173246383667
recon_loss: 0.02792953886091709, dist_loss: 0.6717240810394287
recon_loss: 0.027929486706852913, dist_loss: 0.534258246421814
recon_loss: 0.02792862243950367, dist_loss: 0.6379285454750061
recon_loss: 0.027928583323955536, dist_loss: 0.7931900024414062
recon_loss: 0.02792832814157009, dist_loss: 0.8489207029342651
recon_loss: 0.02792827971279621, dist_loss: 0.9232304096221924
recon_loss: 0.027929211035370827, dist_loss: 0.934002161026001
recon_loss: 0.02792878821492195, dist_loss: 0.6809194087982178
recon_loss: 0.027928370982408524, dist_loss: 0.4878848195075989
recon_loss: 0.027928177267313004, dist_loss: 0.7045703530311584
recon_loss: 0.02792765572667122, dist_loss: 0.7453585863113403
recon_loss: 0.02792765013873577, dist_loss: 0.5682626962661743
recon_loss: 0.027927661314606667, dist_loss: 0.5921438932418823
recon_loss: 0.02792629599571228, dist_loss: 0.6508922576904297
recon_loss: 0.027926083654165268, dist_loss: 0.6419569849967957
recon_loss: 0.027926098555326462, dist_loss: 0.4270884394645691
recon_loss: 0.0279264934360981, dist_loss: 0.8021457195281982
recon_loss: 0.027927739545702934, dist_loss: 0.8996872305870056
recon_loss: 0.027928205206990242, dist_loss: 0.6485078930854797
recon_loss: 0.02792987786233425, dist_loss: 0.5699990391731262
recon_loss: 0.027930347248911858, dist_loss: 0.41903454065322876
recon_loss: 0.027929967269301414, dist_loss: 0.9736813902854919
recon_loss: 0.027930274605751038, dist_loss: 0.4889218509197235
recon_loss: 0.027929158881306648, dist_loss: 1.3894116878509521
recon_loss: 0.027929645031690598, dist_loss: 1.0077123641967773
recon_loss: 0.027928277850151062, dist_loss: 0.5503753423690796
recon_loss: 0.02792803943157196, dist_loss: 0.6772157549858093
recon_loss: 0.027927814051508904, dist_loss: 1.0389082431793213
recon_loss: 0.027926791459321976, dist_loss: 0.4052712917327881
recon_loss: 0.027926690876483917, dist_loss: 1.1116201877593994
recon_loss: 0.027925780043005943, dist_loss: 0.5714093446731567
recon_loss: 0.02792557328939438, dist_loss: 0.43393775820732117
recon_loss: 0.027925416827201843, dist_loss: 0.4607355296611786
recon_loss: 0.02792487107217312, dist_loss: 1.1030230522155762
recon_loss: 0.0279254037886858, dist_loss: 0.5857758522033691
recon_loss: 0.02792513370513916, dist_loss: 0.5638322234153748
Pre-training Epoch 83:  73%|███████▎  | 267/367 [00:01<00:00, 173.92it/s]Pre-training Epoch 83:  78%|███████▊  | 285/367 [00:01<00:00, 174.30it/s]Pre-training Epoch 83:  83%|████████▎ | 303/367 [00:01<00:00, 163.73it/s]Pre-training Epoch 83:  87%|████████▋ | 320/367 [00:02<00:00, 160.20it/s]Pre-training Epoch 83:  92%|█████████▏| 337/367 [00:02<00:00, 157.02it/s]Pre-training Epoch 83:  96%|█████████▋| 354/367 [00:02<00:00, 158.40it/s]Pre-training Epoch 83: 100%|██████████| 367/367 [00:02<00:00, 159.48it/s]
recon_loss: 0.027925651520490646, dist_loss: 0.3704097867012024
recon_loss: 0.027925530448555946, dist_loss: 0.5211694240570068
recon_loss: 0.02792537957429886, dist_loss: 0.338486909866333
recon_loss: 0.02792523428797722, dist_loss: 0.43179619312286377
recon_loss: 0.027924856171011925, dist_loss: 0.6242767572402954
recon_loss: 0.027924655005335808, dist_loss: 0.5533997416496277
recon_loss: 0.027924342080950737, dist_loss: 0.5449553728103638
recon_loss: 0.027924176305532455, dist_loss: 0.37745845317840576
recon_loss: 0.02792407013475895, dist_loss: 0.8329494595527649
recon_loss: 0.027923662215471268, dist_loss: 0.8616710305213928
recon_loss: 0.027923332527279854, dist_loss: 0.4394800364971161
recon_loss: 0.02792339213192463, dist_loss: 0.8995878100395203
recon_loss: 0.02792363055050373, dist_loss: 0.6965548992156982
recon_loss: 0.027923686429858208, dist_loss: 0.7784464955329895
recon_loss: 0.0279241856187582, dist_loss: 0.5370854139328003
recon_loss: 0.02792438678443432, dist_loss: 0.48179423809051514
recon_loss: 0.027925221249461174, dist_loss: 0.21567371487617493
recon_loss: 0.027925163507461548, dist_loss: 0.2731610834598541
recon_loss: 0.027925727888941765, dist_loss: 0.6022061109542847
recon_loss: 0.027925383299589157, dist_loss: 0.7201095819473267
recon_loss: 0.027924973517656326, dist_loss: 0.9061951637268066
recon_loss: 0.02792523242533207, dist_loss: 0.5044553279876709
recon_loss: 0.027924420312047005, dist_loss: 0.6500614881515503
recon_loss: 0.027923932299017906, dist_loss: 0.7159525156021118
recon_loss: 0.027924394235014915, dist_loss: 0.6281890273094177
recon_loss: 0.027922550216317177, dist_loss: 0.94643634557724
recon_loss: 0.027923032641410828, dist_loss: 0.6355708837509155
recon_loss: 0.027922840788960457, dist_loss: 0.7449581027030945
recon_loss: 0.027922499924898148, dist_loss: 0.7180250883102417
recon_loss: 0.02792493812739849, dist_loss: 0.5296985507011414
recon_loss: 0.02792435884475708, dist_loss: 0.6934510469436646
recon_loss: 0.027925996109843254, dist_loss: 0.3837687373161316
recon_loss: 0.02792678028345108, dist_loss: 0.4337404668331146
recon_loss: 0.027926243841648102, dist_loss: 0.28638961911201477
recon_loss: 0.027927692979574203, dist_loss: 0.7438252568244934
recon_loss: 0.027925822883844376, dist_loss: 0.8864831924438477
recon_loss: 0.02792431227862835, dist_loss: 1.0122190713882446
recon_loss: 0.02792305126786232, dist_loss: 0.919748067855835
recon_loss: 0.027922535315155983, dist_loss: 0.55829918384552
recon_loss: 0.027922675013542175, dist_loss: 0.3775056302547455
recon_loss: 0.027923062443733215, dist_loss: 0.7225900888442993
recon_loss: 0.027923353016376495, dist_loss: 0.5359589457511902
recon_loss: 0.027923645451664925, dist_loss: 0.5551587343215942
recon_loss: 0.027923328801989555, dist_loss: 0.7440866231918335
recon_loss: 0.027923552319407463, dist_loss: 0.47069263458251953
recon_loss: 0.02792365476489067, dist_loss: 0.4540275037288666
recon_loss: 0.02792387641966343, dist_loss: 0.6255556344985962
recon_loss: 0.027923759073019028, dist_loss: 0.49921831488609314
recon_loss: 0.027923043817281723, dist_loss: 0.41131308674812317
recon_loss: 0.02792288549244404, dist_loss: 0.4442194700241089
recon_loss: 0.027922334149479866, dist_loss: 0.6006206274032593
recon_loss: 0.027921617031097412, dist_loss: 0.6831841468811035
recon_loss: 0.02792120911180973, dist_loss: 0.3294859528541565
recon_loss: 0.027920491993427277, dist_loss: 0.5721486806869507
recon_loss: 0.027920184656977654, dist_loss: 0.4854203164577484
recon_loss: 0.02792014740407467, dist_loss: 0.6477019786834717
recon_loss: 0.027919907122850418, dist_loss: 0.4271332025527954
recon_loss: 0.027920013293623924, dist_loss: 1.0605080127716064
recon_loss: 0.027921399101614952, dist_loss: 0.8676832914352417
recon_loss: 0.027921872213482857, dist_loss: 0.8466190099716187
recon_loss: 0.02792353928089142, dist_loss: 0.8156297206878662
recon_loss: 0.027924053370952606, dist_loss: 0.6951131224632263
recon_loss: 0.027923118323087692, dist_loss: 0.7503282427787781
recon_loss: 0.027922309935092926, dist_loss: 0.3512294888496399
recon_loss: 0.02792154997587204, dist_loss: 0.49319082498550415
recon_loss: 0.027920614928007126, dist_loss: 0.5534114241600037
recon_loss: 0.02791975438594818, dist_loss: 0.8466047048568726
recon_loss: 0.027919283136725426, dist_loss: 0.4348668158054352
recon_loss: 0.02791910618543625, dist_loss: 0.5655747056007385
recon_loss: 0.027919849380850792, dist_loss: 0.7296994924545288
recon_loss: 0.02792038954794407, dist_loss: 0.5705997943878174
recon_loss: 0.027920516207814217, dist_loss: 0.9973812103271484
recon_loss: 0.02792067639529705, dist_loss: 1.1425433158874512
recon_loss: 0.027920402586460114, dist_loss: 0.6283104419708252
recon_loss: 0.027920499444007874, dist_loss: 0.6252355575561523
recon_loss: 0.02792084403336048, dist_loss: 0.649189829826355
recon_loss: 0.02792111411690712, dist_loss: 0.7800289392471313
recon_loss: 0.027920864522457123, dist_loss: 0.4442853629589081
recon_loss: 0.027920449152588844, dist_loss: 0.8123819828033447
recon_loss: 0.027919836342334747, dist_loss: 0.5151951313018799
recon_loss: 0.027919141575694084, dist_loss: 0.6284928321838379
recon_loss: 0.02791854925453663, dist_loss: 0.42865628004074097
recon_loss: 0.027918050065636635, dist_loss: 0.6376067399978638
recon_loss: 0.02791738696396351, dist_loss: 0.4920671582221985
recon_loss: 0.02791685052216053, dist_loss: 0.4891616702079773
recon_loss: 0.027916451916098595, dist_loss: 0.6721194386482239
recon_loss: 0.027916157618165016, dist_loss: 0.6587784886360168
recon_loss: 0.027916042134165764, dist_loss: 1.0615131855010986
recon_loss: 0.02791614830493927, dist_loss: 0.9087094068527222
recon_loss: 0.02791597880423069, dist_loss: 0.8586124777793884
recon_loss: 0.02791609615087509, dist_loss: 0.7532927989959717
recon_loss: 0.027916399762034416, dist_loss: 0.594485878944397
recon_loss: 0.027916952967643738, dist_loss: 0.6165108680725098
recon_loss: 0.02791723981499672, dist_loss: 0.7120165228843689
recon_loss: 0.027917295694351196, dist_loss: 0.3928297162055969
recon_loss: 0.02791743166744709, dist_loss: 0.6347882747650146
recon_loss: 0.027917632833123207, dist_loss: 0.6536793112754822
recon_loss: 0.027917824685573578, dist_loss: 0.39337462186813354
recon_loss: 0.02791774272918701, dist_loss: 0.9614561796188354
recon_loss: 0.027917327359318733, dist_loss: 0.7453300952911377
recon_loss: 0.027916880324482918, dist_loss: 1.1670199632644653
recon_loss: 0.02791660465300083, dist_loss: 0.42543572187423706
recon_loss: 0.02791638858616352, dist_loss: 0.6479649543762207
recon_loss: 0.02791612595319748, dist_loss: 0.5068680047988892
recon_loss: 0.027915963903069496, dist_loss: 0.6845771074295044
recon_loss: 0.027915408834815025, dist_loss: 0.7533462047576904
recon_loss: 0.02791503816843033, dist_loss: 0.47514569759368896
recon_loss: 0.027914833277463913, dist_loss: 0.4893384277820587
recon_loss: 0.027914708480238914, dist_loss: 0.19052362442016602
Pre-training Epoch 84:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 84:   5%|▌         | 19/367 [00:00<00:01, 181.98it/s]Pre-training Epoch 84:  11%|█         | 39/367 [00:00<00:01, 188.27it/s]Pre-training Epoch 84:  16%|█▌        | 59/367 [00:00<00:01, 190.28it/s]Pre-training Epoch 84:  22%|██▏       | 79/367 [00:00<00:01, 191.24it/s]Pre-training Epoch 84:  27%|██▋       | 99/367 [00:00<00:01, 191.20it/s]Pre-training Epoch 84:  32%|███▏      | 119/367 [00:00<00:01, 191.52it/s]recon_loss: 0.027914542704820633, dist_loss: 0.7319918274879456
recon_loss: 0.027914423495531082, dist_loss: 0.5180113315582275
recon_loss: 0.027914175763726234, dist_loss: 0.635966420173645
recon_loss: 0.0279141366481781, dist_loss: 0.43577685952186584
recon_loss: 0.027914049103856087, dist_loss: 0.2656053304672241
recon_loss: 0.027913933619856834, dist_loss: 0.6531257629394531
recon_loss: 0.02791387215256691, dist_loss: 1.386629581451416
recon_loss: 0.0279136523604393, dist_loss: 0.4435321092605591
recon_loss: 0.02791355922818184, dist_loss: 0.6926715970039368
recon_loss: 0.02791336551308632, dist_loss: 0.6632339954376221
recon_loss: 0.027913540601730347, dist_loss: 0.46594372391700745
recon_loss: 0.027913745492696762, dist_loss: 0.8233065605163574
recon_loss: 0.02791387028992176, dist_loss: 0.806209921836853
recon_loss: 0.027914337813854218, dist_loss: 0.6526002287864685
recon_loss: 0.02791553921997547, dist_loss: 0.5758763551712036
recon_loss: 0.027916572988033295, dist_loss: 0.7705724239349365
recon_loss: 0.027917848899960518, dist_loss: 0.5870473980903625
recon_loss: 0.02791750431060791, dist_loss: 0.5552241802215576
recon_loss: 0.027915943413972855, dist_loss: 0.48963963985443115
recon_loss: 0.027916796505451202, dist_loss: 0.3031838536262512
recon_loss: 0.02791507914662361, dist_loss: 0.7409024834632874
recon_loss: 0.027915792539715767, dist_loss: 0.6795470714569092
recon_loss: 0.027914874255657196, dist_loss: 0.46847003698349
recon_loss: 0.027914121747016907, dist_loss: 0.3539988398551941
recon_loss: 0.02791445516049862, dist_loss: 0.31306585669517517
recon_loss: 0.027913318946957588, dist_loss: 0.553227961063385
recon_loss: 0.027913492172956467, dist_loss: 0.6141046285629272
recon_loss: 0.027913017198443413, dist_loss: 0.4307895302772522
recon_loss: 0.027912797406315804, dist_loss: 0.43162617087364197
recon_loss: 0.027912842109799385, dist_loss: 0.7387510538101196
recon_loss: 0.027912858873605728, dist_loss: 0.5504916906356812
recon_loss: 0.02791285514831543, dist_loss: 0.7489612698554993
recon_loss: 0.027913041412830353, dist_loss: 0.774193286895752
recon_loss: 0.027913333848118782, dist_loss: 0.6793933510780334
recon_loss: 0.027913281694054604, dist_loss: 0.5951102375984192
recon_loss: 0.02791324071586132, dist_loss: 0.6472629308700562
recon_loss: 0.027912979945540428, dist_loss: 0.6061921119689941
recon_loss: 0.027912700548768044, dist_loss: 0.48192745447158813
recon_loss: 0.02791220135986805, dist_loss: 1.1992390155792236
recon_loss: 0.027911897748708725, dist_loss: 0.9663909673690796
recon_loss: 0.027911681681871414, dist_loss: 0.5771449208259583
recon_loss: 0.02791147492825985, dist_loss: 0.9428917169570923
recon_loss: 0.02791123278439045, dist_loss: 0.3664969801902771
recon_loss: 0.02791101671755314, dist_loss: 0.4738561511039734
recon_loss: 0.027910813689231873, dist_loss: 0.5872183442115784
recon_loss: 0.027910931035876274, dist_loss: 1.000471591949463
recon_loss: 0.02791098691523075, dist_loss: 0.37088197469711304
recon_loss: 0.0279112309217453, dist_loss: 0.6942146420478821
recon_loss: 0.02791135385632515, dist_loss: 0.6583503484725952
recon_loss: 0.02791089005768299, dist_loss: 0.6270134449005127
recon_loss: 0.027910785749554634, dist_loss: 0.8629471659660339
recon_loss: 0.027910426259040833, dist_loss: 0.5403546094894409
recon_loss: 0.027910521253943443, dist_loss: 0.958249032497406
recon_loss: 0.02791021019220352, dist_loss: 0.8131145238876343
recon_loss: 0.02791035920381546, dist_loss: 0.5658169984817505
recon_loss: 0.027910524979233742, dist_loss: 0.553190290927887
recon_loss: 0.02791055291891098, dist_loss: 0.5328301191329956
recon_loss: 0.027910664677619934, dist_loss: 0.5610948204994202
recon_loss: 0.027910567820072174, dist_loss: 0.7693002820014954
recon_loss: 0.027910584583878517, dist_loss: 0.6233030557632446
recon_loss: 0.02791060321033001, dist_loss: 0.36433619260787964
recon_loss: 0.02791043370962143, dist_loss: 0.40919002890586853
recon_loss: 0.02791043184697628, dist_loss: 0.5715823173522949
recon_loss: 0.027909886091947556, dist_loss: 0.5300039052963257
recon_loss: 0.02790960855782032, dist_loss: 0.6534377932548523
recon_loss: 0.02790948934853077, dist_loss: 0.37868860363960266
recon_loss: 0.027909496799111366, dist_loss: 0.7397420406341553
recon_loss: 0.027909744530916214, dist_loss: 0.6499783396720886
recon_loss: 0.027909666299819946, dist_loss: 0.5600675344467163
recon_loss: 0.027910331264138222, dist_loss: 0.6001871228218079
recon_loss: 0.027910323813557625, dist_loss: 0.47909876704216003
recon_loss: 0.027909893542528152, dist_loss: 0.41265302896499634
recon_loss: 0.027910487726330757, dist_loss: 0.6596684455871582
recon_loss: 0.027909092605113983, dist_loss: 0.6411011219024658
recon_loss: 0.027909396216273308, dist_loss: 0.6341265439987183
recon_loss: 0.027910269796848297, dist_loss: 0.5474161505699158
recon_loss: 0.027910586446523666, dist_loss: 0.9629359245300293
recon_loss: 0.02791033312678337, dist_loss: 0.6024641990661621
recon_loss: 0.02791016548871994, dist_loss: 0.6472418308258057
recon_loss: 0.027910200878977776, dist_loss: 0.46006184816360474
recon_loss: 0.02790962904691696, dist_loss: 0.8199999928474426
recon_loss: 0.027909573167562485, dist_loss: 0.5072751045227051
recon_loss: 0.027909180149435997, dist_loss: 0.6202185153961182
recon_loss: 0.027909690514206886, dist_loss: 0.33545660972595215
recon_loss: 0.02791045419871807, dist_loss: 1.1011383533477783
recon_loss: 0.027910931035876274, dist_loss: 1.0069711208343506
recon_loss: 0.027911216020584106, dist_loss: 0.8719373345375061
recon_loss: 0.027911005541682243, dist_loss: 0.6468300819396973
recon_loss: 0.027911534532904625, dist_loss: 0.972176194190979
recon_loss: 0.027912000194191933, dist_loss: 0.5951385498046875
recon_loss: 0.027911951765418053, dist_loss: 1.018592119216919
recon_loss: 0.027912510558962822, dist_loss: 0.6106239557266235
recon_loss: 0.027912331745028496, dist_loss: 0.4089004695415497
recon_loss: 0.027912558987736702, dist_loss: 0.7602924108505249
recon_loss: 0.027912762016057968, dist_loss: 0.5572503805160522
recon_loss: 0.027912640944123268, dist_loss: 0.5228475332260132
recon_loss: 0.02791210450232029, dist_loss: 0.6021904945373535
recon_loss: 0.02791111171245575, dist_loss: 0.5112988948822021
recon_loss: 0.02791018597781658, dist_loss: 0.6425179839134216
recon_loss: 0.027909250929951668, dist_loss: 0.8464206457138062
recon_loss: 0.027908645570278168, dist_loss: 0.6320798397064209
recon_loss: 0.02790842391550541, dist_loss: 0.4353835880756378
recon_loss: 0.027908626943826675, dist_loss: 0.41582924127578735
recon_loss: 0.027909429743885994, dist_loss: 0.9606337547302246
recon_loss: 0.027910076081752777, dist_loss: 1.3188996315002441
recon_loss: 0.027910500764846802, dist_loss: 0.47167378664016724
recon_loss: 0.02791028842329979, dist_loss: 0.9989268183708191
recon_loss: 0.027910389006137848, dist_loss: 0.9642072916030884
recon_loss: 0.02791023999452591, dist_loss: 0.6222676634788513
recon_loss: 0.027910500764846802, dist_loss: 0.6910735964775085
recon_loss: 0.02791089005768299, dist_loss: 0.873298168182373
recon_loss: 0.027910569682717323, dist_loss: 0.7165095806121826
recon_loss: 0.02791045792400837, dist_loss: 0.9543363451957703
recon_loss: 0.027910100296139717, dist_loss: 0.7630984783172607
recon_loss: 0.027909789234399796, dist_loss: 0.6767895221710205
recon_loss: 0.027909638360142708, dist_loss: 0.4965454339981079
recon_loss: 0.02790811099112034, dist_loss: 0.4606790244579315
recon_loss: 0.027907881885766983, dist_loss: 0.6889075040817261
recon_loss: 0.027907365933060646, dist_loss: 0.6546285152435303
recon_loss: 0.027906509116292, dist_loss: 0.9275972247123718
recon_loss: 0.0279073566198349, dist_loss: 1.3106145858764648
recon_loss: 0.027906466275453568, dist_loss: 0.7736095190048218
recon_loss: 0.027906866744160652, dist_loss: 0.7758313417434692
recon_loss: 0.027907634153962135, dist_loss: 0.8180640935897827
recon_loss: 0.02790861576795578, dist_loss: 0.7601302862167358
recon_loss: 0.027909208089113235, dist_loss: 0.578896164894104
recon_loss: 0.027909988537430763, dist_loss: 0.5287853479385376
recon_loss: 0.027910519391298294, dist_loss: 0.6233677268028259
Pre-training Epoch 84:  38%|███▊      | 139/367 [00:00<00:01, 184.98it/s]Pre-training Epoch 84:  43%|████▎     | 158/367 [00:00<00:01, 177.10it/s]Pre-training Epoch 84:  48%|████▊     | 176/367 [00:00<00:01, 173.83it/s]Pre-training Epoch 84:  53%|█████▎    | 194/367 [00:01<00:01, 167.89it/s]Pre-training Epoch 84:  57%|█████▋    | 211/367 [00:01<00:00, 166.90it/s]Pre-training Epoch 84:  62%|██████▏   | 228/367 [00:01<00:00, 166.39it/s]Pre-training Epoch 84:  67%|██████▋   | 245/367 [00:01<00:00, 165.28it/s]recon_loss: 0.027910521253943443, dist_loss: 0.5499247908592224
recon_loss: 0.02791069634258747, dist_loss: 0.9196335673332214
recon_loss: 0.027910294011235237, dist_loss: 0.6867122650146484
recon_loss: 0.0279096607118845, dist_loss: 0.7213916778564453
recon_loss: 0.027909228578209877, dist_loss: 0.9305617213249207
recon_loss: 0.02790842019021511, dist_loss: 0.6339486837387085
recon_loss: 0.02790813520550728, dist_loss: 0.8346945643424988
recon_loss: 0.027908027172088623, dist_loss: 0.6832057237625122
recon_loss: 0.02790834754705429, dist_loss: 0.5361655354499817
recon_loss: 0.027907775714993477, dist_loss: 0.8963800668716431
recon_loss: 0.027907056733965874, dist_loss: 0.7034668326377869
recon_loss: 0.02790718339383602, dist_loss: 0.4035269021987915
recon_loss: 0.02790669910609722, dist_loss: 0.7531580924987793
recon_loss: 0.02790726162493229, dist_loss: 0.6117439270019531
recon_loss: 0.027907388284802437, dist_loss: 0.5330128073692322
recon_loss: 0.027907714247703552, dist_loss: 0.7502191066741943
recon_loss: 0.02790828049182892, dist_loss: 0.7553237676620483
recon_loss: 0.027908125892281532, dist_loss: 0.5625885128974915
recon_loss: 0.027908995747566223, dist_loss: 0.6352756023406982
recon_loss: 0.02790837548673153, dist_loss: 0.9553998112678528
recon_loss: 0.027908463031053543, dist_loss: 0.6545841693878174
recon_loss: 0.027907321229577065, dist_loss: 0.37090644240379333
recon_loss: 0.027906276285648346, dist_loss: 0.7013052701950073
recon_loss: 0.02790687419474125, dist_loss: 0.6137850284576416
recon_loss: 0.02790607511997223, dist_loss: 0.7552691698074341
recon_loss: 0.02790592983365059, dist_loss: 1.2973902225494385
recon_loss: 0.027906402945518494, dist_loss: 0.4233102798461914
recon_loss: 0.027905263006687164, dist_loss: 0.7193953990936279
recon_loss: 0.027905624359846115, dist_loss: 0.816230058670044
recon_loss: 0.02790590189397335, dist_loss: 0.5765307545661926
recon_loss: 0.02790561318397522, dist_loss: 0.8310680389404297
recon_loss: 0.02790643833577633, dist_loss: 0.43029484152793884
recon_loss: 0.027906659990549088, dist_loss: 0.648878812789917
recon_loss: 0.02790692076086998, dist_loss: 0.4581845700740814
recon_loss: 0.02790740504860878, dist_loss: 0.37799644470214844
recon_loss: 0.027906600385904312, dist_loss: 0.6524001359939575
recon_loss: 0.02790701761841774, dist_loss: 0.739710807800293
recon_loss: 0.027906058356165886, dist_loss: 0.4289278984069824
recon_loss: 0.027906054630875587, dist_loss: 0.560063898563385
recon_loss: 0.02790573239326477, dist_loss: 0.9262773394584656
recon_loss: 0.02790536917746067, dist_loss: 0.9391597509384155
recon_loss: 0.027905546128749847, dist_loss: 0.8043771386146545
recon_loss: 0.02790522202849388, dist_loss: 0.6323695182800293
recon_loss: 0.027904924005270004, dist_loss: 0.5020333528518677
recon_loss: 0.027904123067855835, dist_loss: 0.8470261693000793
recon_loss: 0.02790449745953083, dist_loss: 0.500792384147644
recon_loss: 0.027903715148568153, dist_loss: 0.5103597640991211
recon_loss: 0.027903296053409576, dist_loss: 0.4730933904647827
recon_loss: 0.02790370211005211, dist_loss: 0.7110366821289062
recon_loss: 0.027902543544769287, dist_loss: 0.45498961210250854
recon_loss: 0.027903566136956215, dist_loss: 0.5836451053619385
recon_loss: 0.027902793139219284, dist_loss: 0.7755278944969177
recon_loss: 0.027902914211153984, dist_loss: 1.0901285409927368
recon_loss: 0.02790340967476368, dist_loss: 0.4996640086174011
recon_loss: 0.027901187539100647, dist_loss: 0.7645764350891113
recon_loss: 0.027902262285351753, dist_loss: 0.49526268243789673
recon_loss: 0.027902284637093544, dist_loss: 0.8351887464523315
recon_loss: 0.027901826426386833, dist_loss: 0.7430547475814819
recon_loss: 0.02790292724967003, dist_loss: 0.6358473300933838
recon_loss: 0.027900727465748787, dist_loss: 0.5369884967803955
recon_loss: 0.027901653200387955, dist_loss: 0.615192174911499
recon_loss: 0.027900448068976402, dist_loss: 0.35390138626098633
recon_loss: 0.02790125459432602, dist_loss: 0.8560651540756226
recon_loss: 0.027900448068976402, dist_loss: 0.5649009943008423
recon_loss: 0.027899695560336113, dist_loss: 0.6062958240509033
recon_loss: 0.027900686487555504, dist_loss: 0.585883617401123
recon_loss: 0.027900025248527527, dist_loss: 0.7989722490310669
recon_loss: 0.02790153957903385, dist_loss: 0.9657595753669739
recon_loss: 0.027900371700525284, dist_loss: 0.6022176742553711
recon_loss: 0.02790028043091297, dist_loss: 0.7104321718215942
recon_loss: 0.027900800108909607, dist_loss: 0.5227927565574646
recon_loss: 0.02790023945271969, dist_loss: 0.4235759973526001
recon_loss: 0.027900347486138344, dist_loss: 0.4253723621368408
recon_loss: 0.0278994832187891, dist_loss: 0.507756769657135
recon_loss: 0.02789946459233761, dist_loss: 0.47814178466796875
recon_loss: 0.02789934352040291, dist_loss: 0.6193723678588867
recon_loss: 0.027899451553821564, dist_loss: 0.8323677182197571
recon_loss: 0.02790038287639618, dist_loss: 0.5017439126968384
recon_loss: 0.027900133281946182, dist_loss: 0.9881003499031067
recon_loss: 0.0279008150100708, dist_loss: 0.4431731700897217
recon_loss: 0.02790110372006893, dist_loss: 0.7527632713317871
recon_loss: 0.02790180966258049, dist_loss: 0.36841726303100586
recon_loss: 0.027902334928512573, dist_loss: 0.5365458130836487
recon_loss: 0.027902014553546906, dist_loss: 0.7914537787437439
recon_loss: 0.027901506051421165, dist_loss: 0.29953065514564514
recon_loss: 0.027900874614715576, dist_loss: 0.6749083995819092
recon_loss: 0.027900302782654762, dist_loss: 1.0116524696350098
recon_loss: 0.027899667620658875, dist_loss: 0.7143360376358032
recon_loss: 0.027899209409952164, dist_loss: 0.3948642909526825
recon_loss: 0.02789897844195366, dist_loss: 0.8332957029342651
recon_loss: 0.0278988778591156, dist_loss: 0.48987576365470886
recon_loss: 0.027898788452148438, dist_loss: 0.5326220989227295
recon_loss: 0.027898797765374184, dist_loss: 0.4777868390083313
recon_loss: 0.027898825705051422, dist_loss: 0.7389475703239441
recon_loss: 0.027898777276277542, dist_loss: 0.6403148174285889
recon_loss: 0.027898510918021202, dist_loss: 0.8193475008010864
recon_loss: 0.027898382395505905, dist_loss: 0.8846984505653381
recon_loss: 0.027898278087377548, dist_loss: 0.42237740755081177
recon_loss: 0.027898263186216354, dist_loss: 0.9409493803977966
recon_loss: 0.027897944673895836, dist_loss: 0.24250578880310059
recon_loss: 0.027898477390408516, dist_loss: 0.6967501640319824
recon_loss: 0.027898132801055908, dist_loss: 0.47525638341903687
recon_loss: 0.027899274602532387, dist_loss: 0.8667277097702026
recon_loss: 0.027901049703359604, dist_loss: 0.6783380508422852
recon_loss: 0.027902457863092422, dist_loss: 0.5246028900146484
recon_loss: 0.027903728187084198, dist_loss: 0.5555867552757263
recon_loss: 0.027904368937015533, dist_loss: 1.3141770362854004
recon_loss: 0.027904482558369637, dist_loss: 0.5888906121253967
recon_loss: 0.027903752401471138, dist_loss: 0.3561967611312866
recon_loss: 0.02790285274386406, dist_loss: 0.7209515571594238
recon_loss: 0.027902213856577873, dist_loss: 0.8488723635673523
recon_loss: 0.027902061119675636, dist_loss: 0.5771167278289795
recon_loss: 0.027901621535420418, dist_loss: 0.5109232068061829
recon_loss: 0.02790127694606781, dist_loss: 0.5437698364257812
recon_loss: 0.027900557965040207, dist_loss: 0.7291259169578552
recon_loss: 0.02789953723549843, dist_loss: 0.5791592597961426
recon_loss: 0.02789894863963127, dist_loss: 0.4350197911262512
recon_loss: 0.02789871208369732, dist_loss: 0.5266687870025635
recon_loss: 0.027898592874407768, dist_loss: 0.811454713344574
recon_loss: 0.02789817564189434, dist_loss: 0.47473978996276855
recon_loss: 0.027898414060473442, dist_loss: 0.8887473344802856
recon_loss: 0.027898520231246948, dist_loss: 0.4846586585044861
recon_loss: 0.027898767963051796, dist_loss: 0.47112491726875305
recon_loss: 0.027899710461497307, dist_loss: 0.7098492383956909
recon_loss: 0.02790062129497528, dist_loss: 0.7670114636421204
recon_loss: 0.027902137488126755, dist_loss: 0.6370560526847839
recon_loss: 0.027903249487280846, dist_loss: 0.6853891611099243
recon_loss: 0.027904050424695015, dist_loss: 0.5962845683097839
Pre-training Epoch 84:  71%|███████▏  | 262/367 [00:01<00:00, 165.45it/s]Pre-training Epoch 84:  76%|███████▌  | 279/367 [00:01<00:00, 164.59it/s]Pre-training Epoch 84:  81%|████████  | 296/367 [00:01<00:00, 165.08it/s]Pre-training Epoch 84:  85%|████████▌ | 313/367 [00:01<00:00, 157.98it/s]Pre-training Epoch 84:  90%|████████▉ | 330/367 [00:01<00:00, 159.88it/s]Pre-training Epoch 84:  95%|█████████▍| 347/367 [00:02<00:00, 159.25it/s]Pre-training Epoch 84:  99%|█████████▉| 364/367 [00:02<00:00, 159.90it/s]Pre-training Epoch 84: 100%|██████████| 367/367 [00:02<00:00, 170.23it/s]
recon_loss: 0.0279049314558506, dist_loss: 0.569909930229187
recon_loss: 0.027905628085136414, dist_loss: 0.5633394718170166
recon_loss: 0.02790628932416439, dist_loss: 0.7376944422721863
recon_loss: 0.027906671166419983, dist_loss: 0.8091013431549072
recon_loss: 0.027907375246286392, dist_loss: 0.9135364294052124
recon_loss: 0.02790842205286026, dist_loss: 0.43287888169288635
recon_loss: 0.027908015996217728, dist_loss: 0.5797083377838135
recon_loss: 0.027909018099308014, dist_loss: 0.6577150821685791
recon_loss: 0.02790820226073265, dist_loss: 0.5294893980026245
recon_loss: 0.027907783165574074, dist_loss: 1.0592553615570068
recon_loss: 0.02790755406022072, dist_loss: 0.5219945907592773
recon_loss: 0.027905456721782684, dist_loss: 1.0144152641296387
recon_loss: 0.027903424575924873, dist_loss: 0.39756718277931213
recon_loss: 0.027901683002710342, dist_loss: 0.3906838893890381
recon_loss: 0.027899716049432755, dist_loss: 0.6898088455200195
recon_loss: 0.027899036183953285, dist_loss: 0.8929668664932251
recon_loss: 0.02789807878434658, dist_loss: 0.4412634074687958
recon_loss: 0.02789820171892643, dist_loss: 0.6562537550926208
recon_loss: 0.02789897285401821, dist_loss: 0.46406370401382446
recon_loss: 0.027899811044335365, dist_loss: 0.505753219127655
recon_loss: 0.027900947257876396, dist_loss: 0.7501552700996399
recon_loss: 0.0279020294547081, dist_loss: 0.8613885045051575
recon_loss: 0.027901921421289444, dist_loss: 0.9676820039749146
recon_loss: 0.0279006939381361, dist_loss: 0.6041887998580933
recon_loss: 0.027899285778403282, dist_loss: 0.3807888627052307
recon_loss: 0.02789815329015255, dist_loss: 0.44330546259880066
recon_loss: 0.027897076681256294, dist_loss: 0.5999876260757446
recon_loss: 0.027896305546164513, dist_loss: 0.43838390707969666
recon_loss: 0.027895739302039146, dist_loss: 0.9316426515579224
recon_loss: 0.02789546549320221, dist_loss: 0.48121118545532227
recon_loss: 0.027894845232367516, dist_loss: 1.257775068283081
recon_loss: 0.027894556522369385, dist_loss: 1.0071303844451904
recon_loss: 0.027894364669919014, dist_loss: 1.0047340393066406
recon_loss: 0.02789432555437088, dist_loss: 0.3622671961784363
recon_loss: 0.027894429862499237, dist_loss: 0.686043918132782
recon_loss: 0.02789405919611454, dist_loss: 0.6050704717636108
recon_loss: 0.027893487364053726, dist_loss: 0.48277491331100464
recon_loss: 0.027893031015992165, dist_loss: 0.6560688614845276
recon_loss: 0.027892611920833588, dist_loss: 0.3621644377708435
recon_loss: 0.02789292298257351, dist_loss: 0.8075152039527893
recon_loss: 0.02789263240993023, dist_loss: 0.4853752553462982
recon_loss: 0.0278925858438015, dist_loss: 0.6020520329475403
recon_loss: 0.0278920941054821, dist_loss: 0.6546135544776917
recon_loss: 0.027891667559742928, dist_loss: 0.7820762991905212
recon_loss: 0.027891729027032852, dist_loss: 0.4746153652667999
recon_loss: 0.027891773730516434, dist_loss: 0.5305373668670654
recon_loss: 0.02789204940199852, dist_loss: 0.5389885902404785
recon_loss: 0.027892140671610832, dist_loss: 0.5618312358856201
recon_loss: 0.02789251133799553, dist_loss: 0.5422911643981934
recon_loss: 0.027892500162124634, dist_loss: 0.5553864240646362
recon_loss: 0.027892088517546654, dist_loss: 1.1035194396972656
recon_loss: 0.02789166010916233, dist_loss: 0.9989949464797974
recon_loss: 0.02789159119129181, dist_loss: 0.7443904876708984
recon_loss: 0.027891185134649277, dist_loss: 0.6863501071929932
recon_loss: 0.027890941128134727, dist_loss: 1.2888574600219727
recon_loss: 0.02789120562374592, dist_loss: 0.5184399485588074
recon_loss: 0.027891365811228752, dist_loss: 0.30664801597595215
recon_loss: 0.02789137326180935, dist_loss: 0.8410106301307678
recon_loss: 0.027891898527741432, dist_loss: 0.6047592163085938
recon_loss: 0.027892202138900757, dist_loss: 0.7606474161148071
recon_loss: 0.02789204567670822, dist_loss: 0.4280525743961334
recon_loss: 0.02789209969341755, dist_loss: 0.830886721611023
recon_loss: 0.0278918519616127, dist_loss: 0.39092910289764404
recon_loss: 0.027891406789422035, dist_loss: 0.9642859697341919
recon_loss: 0.027891354635357857, dist_loss: 0.3854876160621643
recon_loss: 0.027891438454389572, dist_loss: 0.5870916843414307
recon_loss: 0.02789129689335823, dist_loss: 0.4980908930301666
recon_loss: 0.027890928089618683, dist_loss: 0.6835553646087646
recon_loss: 0.027890613302588463, dist_loss: 0.7937576770782471
recon_loss: 0.027890289202332497, dist_loss: 0.6940774917602539
recon_loss: 0.027890045195817947, dist_loss: 1.4274941682815552
recon_loss: 0.0278900358825922, dist_loss: 0.5348178744316101
recon_loss: 0.027889855206012726, dist_loss: 0.594840407371521
recon_loss: 0.027890123426914215, dist_loss: 1.2080988883972168
recon_loss: 0.027889925986528397, dist_loss: 0.4893651008605957
recon_loss: 0.0278897974640131, dist_loss: 0.46325263381004333
recon_loss: 0.027890216559171677, dist_loss: 0.7489555478096008
recon_loss: 0.02789015881717205, dist_loss: 0.6094286441802979
recon_loss: 0.02789015881717205, dist_loss: 0.4997575581073761
recon_loss: 0.02788994275033474, dist_loss: 0.7441825270652771
recon_loss: 0.027890024706721306, dist_loss: 1.1351369619369507
recon_loss: 0.02789030782878399, dist_loss: 0.9301298260688782
recon_loss: 0.0278911255300045, dist_loss: 0.7275408506393433
recon_loss: 0.027891632169485092, dist_loss: 0.466562420129776
recon_loss: 0.027892429381608963, dist_loss: 0.632296085357666
recon_loss: 0.027893152087926865, dist_loss: 0.5612668991088867
recon_loss: 0.02789350226521492, dist_loss: 0.6508163809776306
recon_loss: 0.02789364755153656, dist_loss: 0.9736384749412537
recon_loss: 0.027894148603081703, dist_loss: 0.5553527474403381
recon_loss: 0.02789440006017685, dist_loss: 0.6292321681976318
recon_loss: 0.027894292026758194, dist_loss: 1.0535306930541992
recon_loss: 0.02789403311908245, dist_loss: 0.34739935398101807
recon_loss: 0.02789352461695671, dist_loss: 0.9152534604072571
recon_loss: 0.02789272926747799, dist_loss: 0.9622840881347656
recon_loss: 0.027892136946320534, dist_loss: 0.7252638339996338
recon_loss: 0.027891485020518303, dist_loss: 0.4575473666191101
recon_loss: 0.027890939265489578, dist_loss: 0.45625799894332886
recon_loss: 0.02789127640426159, dist_loss: 0.8798650503158569
recon_loss: 0.027891872450709343, dist_loss: 0.5609190464019775
recon_loss: 0.02789306640625, dist_loss: 0.4450608789920807
recon_loss: 0.027894604951143265, dist_loss: 0.7802332639694214
recon_loss: 0.027894819155335426, dist_loss: 0.6411660313606262
recon_loss: 0.027894677594304085, dist_loss: 0.3841142952442169
recon_loss: 0.027893703430891037, dist_loss: 0.5382858514785767
recon_loss: 0.027892539277672768, dist_loss: 0.5137168169021606
recon_loss: 0.027891438454389572, dist_loss: 0.5838527679443359
recon_loss: 0.02789086475968361, dist_loss: 0.5191947817802429
recon_loss: 0.02789054624736309, dist_loss: 0.5230657458305359
recon_loss: 0.02788979932665825, dist_loss: 0.5880919694900513
recon_loss: 0.027889562770724297, dist_loss: 0.7695881128311157
recon_loss: 0.027889477089047432, dist_loss: 0.6364862322807312
Pre-training Epoch 85:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 85:   4%|▍         | 16/367 [00:00<00:02, 159.41it/s]Pre-training Epoch 85:   9%|▉         | 33/367 [00:00<00:02, 162.74it/s]Pre-training Epoch 85:  14%|█▎        | 50/367 [00:00<00:02, 154.34it/s]Pre-training Epoch 85:  18%|█▊        | 67/367 [00:00<00:01, 158.43it/s]Pre-training Epoch 85:  23%|██▎       | 84/367 [00:00<00:01, 159.34it/s]Pre-training Epoch 85:  28%|██▊       | 101/367 [00:00<00:01, 160.83it/s]Pre-training Epoch 85:  32%|███▏      | 118/367 [00:00<00:01, 162.47it/s]recon_loss: 0.027889223769307137, dist_loss: 0.4281262159347534
recon_loss: 0.027888819575309753, dist_loss: 0.9282988905906677
recon_loss: 0.02788836881518364, dist_loss: 0.5983200669288635
recon_loss: 0.027888203039765358, dist_loss: 0.7534128427505493
recon_loss: 0.02788817696273327, dist_loss: 0.37598586082458496
recon_loss: 0.02788776345551014, dist_loss: 0.6514963507652283
recon_loss: 0.02788737416267395, dist_loss: 0.7446190118789673
recon_loss: 0.027887022122740746, dist_loss: 0.4752376675605774
recon_loss: 0.02788688987493515, dist_loss: 0.44396597146987915
recon_loss: 0.027887029573321342, dist_loss: 0.7044413089752197
recon_loss: 0.027886727824807167, dist_loss: 0.44329285621643066
recon_loss: 0.027887290343642235, dist_loss: 0.42698097229003906
recon_loss: 0.027886902913451195, dist_loss: 0.7132048606872559
recon_loss: 0.027886943891644478, dist_loss: 0.7031698226928711
recon_loss: 0.027887139469385147, dist_loss: 0.8451342582702637
recon_loss: 0.02788647450506687, dist_loss: 0.583378791809082
recon_loss: 0.027886375784873962, dist_loss: 0.5233684182167053
recon_loss: 0.027886182069778442, dist_loss: 0.9193180799484253
recon_loss: 0.02788630872964859, dist_loss: 0.7360340356826782
recon_loss: 0.02788633294403553, dist_loss: 0.5388718247413635
recon_loss: 0.02788625657558441, dist_loss: 0.9157673716545105
recon_loss: 0.02788621373474598, dist_loss: 0.9078226089477539
recon_loss: 0.027886297553777695, dist_loss: 0.545653223991394
recon_loss: 0.02788609452545643, dist_loss: 1.1841334104537964
recon_loss: 0.027885885909199715, dist_loss: 0.7348935604095459
recon_loss: 0.027885455638170242, dist_loss: 0.6263431310653687
recon_loss: 0.027885323390364647, dist_loss: 0.3698800206184387
recon_loss: 0.027885189279913902, dist_loss: 0.729459285736084
recon_loss: 0.027885429561138153, dist_loss: 0.6054460406303406
recon_loss: 0.027885286137461662, dist_loss: 0.6288493871688843
recon_loss: 0.027885492891073227, dist_loss: 0.39528489112854004
recon_loss: 0.027885306626558304, dist_loss: 0.4374575614929199
recon_loss: 0.027884716168045998, dist_loss: 0.5114974975585938
recon_loss: 0.02788476087152958, dist_loss: 0.5997352600097656
recon_loss: 0.02788473106920719, dist_loss: 0.49444377422332764
recon_loss: 0.027884699404239655, dist_loss: 0.8155673742294312
recon_loss: 0.0278855599462986, dist_loss: 0.9166723489761353
recon_loss: 0.02788596972823143, dist_loss: 0.8663598299026489
recon_loss: 0.027887223288416862, dist_loss: 0.39865922927856445
recon_loss: 0.027889098972082138, dist_loss: 0.5151368975639343
recon_loss: 0.027889812365174294, dist_loss: 0.6184852123260498
recon_loss: 0.0278907623142004, dist_loss: 0.5694606304168701
recon_loss: 0.027891559526324272, dist_loss: 0.39924702048301697
recon_loss: 0.02789226360619068, dist_loss: 0.3903431296348572
recon_loss: 0.027892475947737694, dist_loss: 1.1317273378372192
recon_loss: 0.027891729027032852, dist_loss: 0.6517970561981201
recon_loss: 0.027890903875231743, dist_loss: 0.44013118743896484
recon_loss: 0.027889657765626907, dist_loss: 0.5529470443725586
recon_loss: 0.02788846753537655, dist_loss: 0.6792702674865723
recon_loss: 0.027887701988220215, dist_loss: 0.4243689179420471
recon_loss: 0.027886979281902313, dist_loss: 0.9922586679458618
recon_loss: 0.027886586263775826, dist_loss: 0.33008795976638794
recon_loss: 0.027885669842362404, dist_loss: 1.2416843175888062
recon_loss: 0.02788534387946129, dist_loss: 0.5395728349685669
recon_loss: 0.02788497321307659, dist_loss: 0.579440712928772
recon_loss: 0.027884619310498238, dist_loss: 1.007781982421875
recon_loss: 0.027884311974048615, dist_loss: 0.5959063768386841
recon_loss: 0.02788406051695347, dist_loss: 0.5284976959228516
recon_loss: 0.027884013950824738, dist_loss: 0.2873368263244629
recon_loss: 0.027883823961019516, dist_loss: 0.6467872858047485
recon_loss: 0.027883943170309067, dist_loss: 0.6338170766830444
recon_loss: 0.027884021401405334, dist_loss: 0.9399325847625732
recon_loss: 0.027884572744369507, dist_loss: 0.9935575723648071
recon_loss: 0.027884505689144135, dist_loss: 0.5687524080276489
recon_loss: 0.027884166687726974, dist_loss: 0.6271871328353882
recon_loss: 0.027884654700756073, dist_loss: 0.9113937616348267
recon_loss: 0.027883658185601234, dist_loss: 0.4020816683769226
recon_loss: 0.027883756905794144, dist_loss: 0.9094457626342773
recon_loss: 0.02788318507373333, dist_loss: 0.7770670056343079
recon_loss: 0.027882900089025497, dist_loss: 0.6426163911819458
recon_loss: 0.02788267470896244, dist_loss: 0.7713201642036438
recon_loss: 0.027882488444447517, dist_loss: 0.9296172857284546
recon_loss: 0.027882209047675133, dist_loss: 0.42640596628189087
recon_loss: 0.027882209047675133, dist_loss: 0.663638710975647
recon_loss: 0.027882032096385956, dist_loss: 0.5322343111038208
recon_loss: 0.027882516384124756, dist_loss: 0.694718062877655
recon_loss: 0.027882946655154228, dist_loss: 0.4174368679523468
recon_loss: 0.027882222086191177, dist_loss: 0.5487468838691711
recon_loss: 0.02788275107741356, dist_loss: 0.6920962333679199
recon_loss: 0.027882225811481476, dist_loss: 0.5062105655670166
recon_loss: 0.027882272377610207, dist_loss: 0.4656670391559601
recon_loss: 0.02788246050477028, dist_loss: 0.7532758712768555
recon_loss: 0.02788192592561245, dist_loss: 0.6479750871658325
recon_loss: 0.027883334085345268, dist_loss: 0.914747953414917
recon_loss: 0.027881348505616188, dist_loss: 0.5935057401657104
recon_loss: 0.02788267843425274, dist_loss: 0.44650524854660034
recon_loss: 0.027881763875484467, dist_loss: 0.7297321557998657
recon_loss: 0.027881577610969543, dist_loss: 0.7574284076690674
recon_loss: 0.027881288900971413, dist_loss: 0.45134201645851135
recon_loss: 0.02788049913942814, dist_loss: 0.6195046901702881
recon_loss: 0.02788093499839306, dist_loss: 0.4842679500579834
recon_loss: 0.0278805922716856, dist_loss: 0.8454070687294006
recon_loss: 0.027880989015102386, dist_loss: 0.748053789138794
recon_loss: 0.027880342677235603, dist_loss: 0.7831176519393921
recon_loss: 0.027879813686013222, dist_loss: 0.5873490571975708
recon_loss: 0.027880480512976646, dist_loss: 0.436767041683197
recon_loss: 0.027879372239112854, dist_loss: 0.6848123073577881
recon_loss: 0.027880094945430756, dist_loss: 0.7341340780258179
recon_loss: 0.027880361303687096, dist_loss: 0.8220221996307373
recon_loss: 0.027879657223820686, dist_loss: 0.8699278831481934
recon_loss: 0.027879606932401657, dist_loss: 0.6895478367805481
recon_loss: 0.02787964418530464, dist_loss: 0.8442585468292236
recon_loss: 0.027879174798727036, dist_loss: 0.457004189491272
recon_loss: 0.027879225090146065, dist_loss: 0.6104991436004639
recon_loss: 0.02787906304001808, dist_loss: 0.6584645509719849
recon_loss: 0.027878962457180023, dist_loss: 0.5360205769538879
recon_loss: 0.027878500521183014, dist_loss: 0.6831443309783936
recon_loss: 0.027878083288669586, dist_loss: 0.5546810626983643
recon_loss: 0.02787780575454235, dist_loss: 0.7103203535079956
recon_loss: 0.027877628803253174, dist_loss: 0.6114570498466492
recon_loss: 0.02787749655544758, dist_loss: 0.9766792058944702
recon_loss: 0.027877409011125565, dist_loss: 0.6336250305175781
recon_loss: 0.02787734940648079, dist_loss: 0.6327745318412781
recon_loss: 0.027877068147063255, dist_loss: 0.5457180142402649
recon_loss: 0.027877159416675568, dist_loss: 0.49051588773727417
recon_loss: 0.0278772059828043, dist_loss: 0.6770737767219543
recon_loss: 0.027877384796738625, dist_loss: 0.7302674055099487
recon_loss: 0.0278776828199625, dist_loss: 0.6631341576576233
recon_loss: 0.02787771262228489, dist_loss: 0.4855971932411194
recon_loss: 0.027877863496541977, dist_loss: 0.764625072479248
recon_loss: 0.027877481654286385, dist_loss: 0.7884302139282227
recon_loss: 0.027877232059836388, dist_loss: 1.1627898216247559
recon_loss: 0.02787686139345169, dist_loss: 0.6723312139511108
recon_loss: 0.02787676826119423, dist_loss: 1.1383867263793945
recon_loss: 0.027877142652869225, dist_loss: 0.43593108654022217
recon_loss: 0.02787768468260765, dist_loss: 0.5422927141189575
recon_loss: 0.02787790447473526, dist_loss: 0.7281817197799683
recon_loss: 0.0278787724673748, dist_loss: 0.6496176719665527
Pre-training Epoch 85:  37%|███▋      | 135/367 [00:00<00:01, 163.46it/s]Pre-training Epoch 85:  42%|████▏     | 153/367 [00:00<00:01, 166.53it/s]Pre-training Epoch 85:  47%|████▋     | 173/367 [00:01<00:01, 175.11it/s]Pre-training Epoch 85:  53%|█████▎    | 193/367 [00:01<00:00, 181.06it/s]Pre-training Epoch 85:  58%|█████▊    | 213/367 [00:01<00:00, 185.17it/s]Pre-training Epoch 85:  63%|██████▎   | 232/367 [00:01<00:00, 184.29it/s]Pre-training Epoch 85:  69%|██████▊   | 252/367 [00:01<00:00, 187.23it/s]recon_loss: 0.027879688888788223, dist_loss: 0.7349468469619751
recon_loss: 0.027880007401108742, dist_loss: 0.727651059627533
recon_loss: 0.02788015641272068, dist_loss: 0.5076510906219482
recon_loss: 0.027879968285560608, dist_loss: 0.6368752121925354
recon_loss: 0.02787969820201397, dist_loss: 0.531852662563324
recon_loss: 0.027879348024725914, dist_loss: 0.8648244738578796
recon_loss: 0.02787865698337555, dist_loss: 0.6438916325569153
recon_loss: 0.027877649292349815, dist_loss: 0.6112679243087769
recon_loss: 0.027877124026417732, dist_loss: 0.46873393654823303
recon_loss: 0.02787686325609684, dist_loss: 0.8430466055870056
recon_loss: 0.027877498418092728, dist_loss: 0.7285999059677124
recon_loss: 0.027878567576408386, dist_loss: 0.807316780090332
recon_loss: 0.027878599241375923, dist_loss: 0.45458829402923584
recon_loss: 0.027879593893885612, dist_loss: 0.8125134110450745
recon_loss: 0.02787957526743412, dist_loss: 0.5538259744644165
recon_loss: 0.027880262583494186, dist_loss: 1.001936674118042
recon_loss: 0.027880510315299034, dist_loss: 0.5393669009208679
recon_loss: 0.027879996225237846, dist_loss: 0.7842146158218384
recon_loss: 0.027880219742655754, dist_loss: 0.4989517331123352
recon_loss: 0.027880098670721054, dist_loss: 0.8094660043716431
recon_loss: 0.027880243957042694, dist_loss: 0.5714765191078186
recon_loss: 0.027880247682332993, dist_loss: 0.6782156229019165
recon_loss: 0.027879757806658745, dist_loss: 0.648086428642273
recon_loss: 0.027879199013113976, dist_loss: 0.4149651825428009
recon_loss: 0.027878060936927795, dist_loss: 0.45460498332977295
recon_loss: 0.027877509593963623, dist_loss: 0.5469409227371216
recon_loss: 0.0278767179697752, dist_loss: 0.8431437015533447
recon_loss: 0.02787630818784237, dist_loss: 0.5759512186050415
recon_loss: 0.02787599340081215, dist_loss: 1.0051794052124023
recon_loss: 0.027875639498233795, dist_loss: 0.6633442640304565
recon_loss: 0.027876393869519234, dist_loss: 0.4733813405036926
recon_loss: 0.027876554057002068, dist_loss: 0.9157199859619141
recon_loss: 0.0278766006231308, dist_loss: 0.27430063486099243
recon_loss: 0.027876993641257286, dist_loss: 0.7790061831474304
recon_loss: 0.027876708656549454, dist_loss: 0.5232058167457581
recon_loss: 0.027877366170287132, dist_loss: 0.9461413621902466
recon_loss: 0.027877070009708405, dist_loss: 0.6865435242652893
recon_loss: 0.027876753360033035, dist_loss: 0.620344877243042
recon_loss: 0.027876263484358788, dist_loss: 0.49742525815963745
recon_loss: 0.027875905856490135, dist_loss: 0.6215858459472656
recon_loss: 0.027876026928424835, dist_loss: 0.6649819612503052
recon_loss: 0.02787528932094574, dist_loss: 0.6507985591888428
recon_loss: 0.02787545882165432, dist_loss: 1.0916985273361206
recon_loss: 0.027875490486621857, dist_loss: 0.6111642122268677
recon_loss: 0.02787511795759201, dist_loss: 0.8799080848693848
recon_loss: 0.02787560597062111, dist_loss: 0.9886046648025513
recon_loss: 0.027874859049916267, dist_loss: 0.8207297325134277
recon_loss: 0.027875373139977455, dist_loss: 0.6963015794754028
recon_loss: 0.027874784544110298, dist_loss: 0.6664780378341675
recon_loss: 0.027874570339918137, dist_loss: 0.3752223253250122
recon_loss: 0.02787473425269127, dist_loss: 0.4674333333969116
recon_loss: 0.027874935418367386, dist_loss: 0.815021276473999
recon_loss: 0.027876397594809532, dist_loss: 0.46404457092285156
recon_loss: 0.02787713147699833, dist_loss: 0.4198485314846039
recon_loss: 0.02787906490266323, dist_loss: 0.5240265727043152
recon_loss: 0.02787931263446808, dist_loss: 0.6169451475143433
recon_loss: 0.02787960134446621, dist_loss: 0.6121336817741394
recon_loss: 0.027879269793629646, dist_loss: 0.3173415958881378
recon_loss: 0.027878545224666595, dist_loss: 1.1492457389831543
recon_loss: 0.027878548949956894, dist_loss: 0.7133039832115173
recon_loss: 0.02787727490067482, dist_loss: 1.0577576160430908
recon_loss: 0.027876291424036026, dist_loss: 0.49714595079421997
recon_loss: 0.027875395491719246, dist_loss: 0.6098494529724121
recon_loss: 0.027874378487467766, dist_loss: 0.3279583752155304
recon_loss: 0.027874073013663292, dist_loss: 0.4883606433868408
recon_loss: 0.027873104438185692, dist_loss: 0.8319410085678101
recon_loss: 0.027873728424310684, dist_loss: 0.41361069679260254
recon_loss: 0.027873437851667404, dist_loss: 1.1759275197982788
recon_loss: 0.02787443809211254, dist_loss: 0.5358220338821411
recon_loss: 0.027875004336237907, dist_loss: 0.5942836999893188
recon_loss: 0.02787485159933567, dist_loss: 0.4340047240257263
recon_loss: 0.027875550091266632, dist_loss: 0.4683747887611389
recon_loss: 0.027873871847987175, dist_loss: 0.9399423599243164
recon_loss: 0.027874642983078957, dist_loss: 0.714745283126831
recon_loss: 0.0278741754591465, dist_loss: 0.47968363761901855
recon_loss: 0.027873782441020012, dist_loss: 0.5334742665290833
recon_loss: 0.027874350547790527, dist_loss: 0.5512750148773193
recon_loss: 0.027873169630765915, dist_loss: 0.3190625309944153
recon_loss: 0.027872931212186813, dist_loss: 0.6311518549919128
recon_loss: 0.02787221595644951, dist_loss: 0.7218849062919617
recon_loss: 0.027872178703546524, dist_loss: 0.8089882135391235
recon_loss: 0.027871685102581978, dist_loss: 0.5329052209854126
recon_loss: 0.027871189638972282, dist_loss: 0.7301394939422607
recon_loss: 0.027871595695614815, dist_loss: 0.6526052355766296
recon_loss: 0.027871498838067055, dist_loss: 0.3505576252937317
recon_loss: 0.0278719924390316, dist_loss: 0.43226656317710876
recon_loss: 0.027871819213032722, dist_loss: 0.7451727390289307
recon_loss: 0.027871713042259216, dist_loss: 1.10354483127594
recon_loss: 0.02787075564265251, dist_loss: 0.5748728513717651
recon_loss: 0.027870750054717064, dist_loss: 0.48467159271240234
recon_loss: 0.027870850637555122, dist_loss: 0.5553956627845764
recon_loss: 0.027871176600456238, dist_loss: 0.3888847827911377
recon_loss: 0.027871660888195038, dist_loss: 1.1509734392166138
recon_loss: 0.027872182428836823, dist_loss: 0.8195105791091919
recon_loss: 0.027872787788510323, dist_loss: 0.8864423036575317
recon_loss: 0.027872804552316666, dist_loss: 0.8995295763015747
recon_loss: 0.027872134000062943, dist_loss: 0.47177594900131226
recon_loss: 0.027871225029230118, dist_loss: 0.9062033295631409
recon_loss: 0.027870329096913338, dist_loss: 0.569464921951294
recon_loss: 0.027869269251823425, dist_loss: 0.6363512277603149
recon_loss: 0.02786954492330551, dist_loss: 0.47398048639297485
recon_loss: 0.02786952629685402, dist_loss: 0.7522355318069458
recon_loss: 0.027868593111634254, dist_loss: 0.42678189277648926
recon_loss: 0.027868669480085373, dist_loss: 0.6252002716064453
recon_loss: 0.027868235483765602, dist_loss: 0.8624469041824341
recon_loss: 0.027868103235960007, dist_loss: 0.4772758185863495
recon_loss: 0.027868228033185005, dist_loss: 1.7059667110443115
recon_loss: 0.027867646887898445, dist_loss: 0.622812807559967
recon_loss: 0.027868065983057022, dist_loss: 0.6737171411514282
recon_loss: 0.02786722593009472, dist_loss: 0.2795781195163727
recon_loss: 0.02786719799041748, dist_loss: 0.5413361191749573
recon_loss: 0.027867358177900314, dist_loss: 1.3038909435272217
recon_loss: 0.027867289260029793, dist_loss: 0.8751460313796997
recon_loss: 0.027867505326867104, dist_loss: 0.8367347717285156
recon_loss: 0.027867596596479416, dist_loss: 0.5660567283630371
recon_loss: 0.027867857366800308, dist_loss: 0.6173373460769653
recon_loss: 0.027869118377566338, dist_loss: 0.37753012776374817
recon_loss: 0.027870288118720055, dist_loss: 0.4614638090133667
recon_loss: 0.027870943769812584, dist_loss: 0.8407381176948547
recon_loss: 0.027871355414390564, dist_loss: 0.6016284823417664
recon_loss: 0.027871347963809967, dist_loss: 0.48278263211250305
recon_loss: 0.0278712697327137, dist_loss: 0.685887336730957
recon_loss: 0.027870850637555122, dist_loss: 1.3067588806152344
recon_loss: 0.02787049487233162, dist_loss: 0.37630927562713623
recon_loss: 0.027869848534464836, dist_loss: 0.9601597189903259
recon_loss: 0.027869412675499916, dist_loss: 0.7098013758659363
recon_loss: 0.027869192883372307, dist_loss: 0.5847231149673462
recon_loss: 0.02786889113485813, dist_loss: 0.6070945262908936
Pre-training Epoch 85:  74%|███████▍  | 272/367 [00:01<00:00, 189.01it/s]Pre-training Epoch 85:  80%|███████▉  | 292/367 [00:01<00:00, 189.91it/s]Pre-training Epoch 85:  85%|████████▌ | 312/367 [00:01<00:00, 191.03it/s]Pre-training Epoch 85:  90%|█████████ | 332/367 [00:01<00:00, 191.77it/s]Pre-training Epoch 85:  96%|█████████▌| 352/367 [00:01<00:00, 192.32it/s]Pre-training Epoch 85: 100%|██████████| 367/367 [00:02<00:00, 178.76it/s]
recon_loss: 0.02786872908473015, dist_loss: 0.7414788007736206
recon_loss: 0.02786831371486187, dist_loss: 0.5699172616004944
recon_loss: 0.0278682429343462, dist_loss: 1.0494863986968994
recon_loss: 0.027868369594216347, dist_loss: 0.5661618113517761
recon_loss: 0.027868401259183884, dist_loss: 0.597922682762146
recon_loss: 0.027868257835507393, dist_loss: 0.4188940227031708
recon_loss: 0.027868077158927917, dist_loss: 0.6813420057296753
recon_loss: 0.027867931872606277, dist_loss: 1.0133204460144043
recon_loss: 0.027868082746863365, dist_loss: 0.7885794639587402
recon_loss: 0.027867887169122696, dist_loss: 0.4988058805465698
recon_loss: 0.027867721393704414, dist_loss: 0.7300638556480408
recon_loss: 0.02786765992641449, dist_loss: 1.0029150247573853
recon_loss: 0.027867857366800308, dist_loss: 0.5636897087097168
recon_loss: 0.027868250384926796, dist_loss: 0.557948112487793
recon_loss: 0.027867918834090233, dist_loss: 0.38281068205833435
recon_loss: 0.027867291122674942, dist_loss: 0.5397495031356812
recon_loss: 0.027866320684552193, dist_loss: 0.6636381149291992
recon_loss: 0.027865974232554436, dist_loss: 0.8672584891319275
recon_loss: 0.027865789830684662, dist_loss: 0.6026182174682617
recon_loss: 0.027865491807460785, dist_loss: 0.652230978012085
recon_loss: 0.02786518819630146, dist_loss: 0.6303496360778809
recon_loss: 0.02786502242088318, dist_loss: 0.7463940382003784
recon_loss: 0.027864838019013405, dist_loss: 0.361630916595459
recon_loss: 0.027864821255207062, dist_loss: 0.8392857313156128
recon_loss: 0.027864711359143257, dist_loss: 0.6129868030548096
recon_loss: 0.027864625677466393, dist_loss: 0.49202731251716614
recon_loss: 0.02786451391875744, dist_loss: 0.6857079267501831
recon_loss: 0.027864711359143257, dist_loss: 0.5008960962295532
recon_loss: 0.027864577248692513, dist_loss: 1.0137122869491577
recon_loss: 0.027864277362823486, dist_loss: 0.5785706639289856
recon_loss: 0.027865095064044, dist_loss: 0.4213567078113556
recon_loss: 0.02786361426115036, dist_loss: 0.3591444790363312
recon_loss: 0.027864018455147743, dist_loss: 0.7329999208450317
recon_loss: 0.027863793075084686, dist_loss: 0.5414516925811768
recon_loss: 0.02786416932940483, dist_loss: 0.43265968561172485
recon_loss: 0.027864065021276474, dist_loss: 0.9925538301467896
recon_loss: 0.027863536030054092, dist_loss: 0.860614538192749
recon_loss: 0.027863867580890656, dist_loss: 0.5149477124214172
recon_loss: 0.027863232418894768, dist_loss: 0.9662638902664185
recon_loss: 0.02786349691450596, dist_loss: 0.6605530977249146
recon_loss: 0.0278635211288929, dist_loss: 0.42362600564956665
recon_loss: 0.027864061295986176, dist_loss: 0.8095585107803345
recon_loss: 0.027865398675203323, dist_loss: 0.495348185300827
recon_loss: 0.027867043390870094, dist_loss: 0.543091893196106
recon_loss: 0.027868589386343956, dist_loss: 0.7830684185028076
recon_loss: 0.027868736535310745, dist_loss: 0.5899292230606079
recon_loss: 0.027867259457707405, dist_loss: 0.4305631220340729
recon_loss: 0.027866538614034653, dist_loss: 0.6176614761352539
recon_loss: 0.027865706011652946, dist_loss: 0.6826611757278442
recon_loss: 0.027864957228302956, dist_loss: 0.6071658134460449
recon_loss: 0.02786458469927311, dist_loss: 0.5597289800643921
recon_loss: 0.027864253148436546, dist_loss: 0.5524735450744629
recon_loss: 0.027864478528499603, dist_loss: 0.3503216505050659
recon_loss: 0.027865899726748466, dist_loss: 1.2630858421325684
recon_loss: 0.02786707878112793, dist_loss: 0.4753206670284271
recon_loss: 0.027866661548614502, dist_loss: 0.6531336903572083
recon_loss: 0.02786891721189022, dist_loss: 0.360520601272583
recon_loss: 0.02787042036652565, dist_loss: 0.5017490386962891
recon_loss: 0.027871841564774513, dist_loss: 0.3848147392272949
recon_loss: 0.027873003855347633, dist_loss: 0.7661001086235046
recon_loss: 0.02787262387573719, dist_loss: 0.87720787525177
recon_loss: 0.027872346341609955, dist_loss: 0.6679044961929321
recon_loss: 0.02787077985703945, dist_loss: 0.8327978253364563
recon_loss: 0.02786947414278984, dist_loss: 0.60787034034729
recon_loss: 0.027868062257766724, dist_loss: 0.7188723087310791
recon_loss: 0.02786763198673725, dist_loss: 0.7238184809684753
recon_loss: 0.02786616049706936, dist_loss: 0.8387472033500671
recon_loss: 0.0278652161359787, dist_loss: 0.7263422012329102
recon_loss: 0.027864113450050354, dist_loss: 1.121222734451294
recon_loss: 0.027863634750247, dist_loss: 1.3451356887817383
recon_loss: 0.0278631541877985, dist_loss: 0.9780318140983582
recon_loss: 0.027863964438438416, dist_loss: 0.4759025275707245
recon_loss: 0.027864089235663414, dist_loss: 0.7679455280303955
recon_loss: 0.027864821255207062, dist_loss: 0.35147586464881897
recon_loss: 0.027866190299391747, dist_loss: 0.39640945196151733
recon_loss: 0.02786603383719921, dist_loss: 1.1226730346679688
recon_loss: 0.027867911383509636, dist_loss: 0.5687216520309448
recon_loss: 0.027866384014487267, dist_loss: 0.6920656561851501
recon_loss: 0.027867592871189117, dist_loss: 0.6142807602882385
recon_loss: 0.02786410041153431, dist_loss: 0.40458816289901733
recon_loss: 0.027863362804055214, dist_loss: 0.8572105765342712
recon_loss: 0.02786256931722164, dist_loss: 0.5741802453994751
recon_loss: 0.027861882001161575, dist_loss: 0.45109719038009644
recon_loss: 0.02786320447921753, dist_loss: 0.7054771184921265
recon_loss: 0.027862276881933212, dist_loss: 0.5755691528320312
recon_loss: 0.0278638806194067, dist_loss: 0.4723811149597168
recon_loss: 0.02786308526992798, dist_loss: 0.44294342398643494
recon_loss: 0.027863692492246628, dist_loss: 0.43659982085227966
recon_loss: 0.027863726019859314, dist_loss: 0.5306770205497742
recon_loss: 0.027863753959536552, dist_loss: 0.6911565065383911
recon_loss: 0.02786422148346901, dist_loss: 0.4720252752304077
recon_loss: 0.027863625437021255, dist_loss: 0.5566091537475586
recon_loss: 0.027862751856446266, dist_loss: 0.6237845420837402
recon_loss: 0.027861744165420532, dist_loss: 0.407621294260025
recon_loss: 0.02786153182387352, dist_loss: 0.8038387298583984
recon_loss: 0.027862003073096275, dist_loss: 0.4606810212135315
recon_loss: 0.027863604947924614, dist_loss: 0.41465455293655396
recon_loss: 0.02786533534526825, dist_loss: 0.3680240511894226
recon_loss: 0.027867533266544342, dist_loss: 0.7155836224555969
recon_loss: 0.02786913700401783, dist_loss: 0.6228636503219604
recon_loss: 0.02787027135491371, dist_loss: 0.5861281752586365
recon_loss: 0.027871210128068924, dist_loss: 0.6385247707366943
recon_loss: 0.027870938181877136, dist_loss: 0.3445681929588318
recon_loss: 0.0278707817196846, dist_loss: 0.6405541896820068
recon_loss: 0.027869127690792084, dist_loss: 0.5234435200691223
recon_loss: 0.02786814421415329, dist_loss: 0.5297665596008301
recon_loss: 0.027867212891578674, dist_loss: 1.0961651802062988
recon_loss: 0.027865756303071976, dist_loss: 1.09479558467865
recon_loss: 0.027865098789334297, dist_loss: 0.3036192059516907
recon_loss: 0.027863215655088425, dist_loss: 0.7877696752548218
recon_loss: 0.02786191739141941, dist_loss: 1.330322265625
Pre-training Epoch 86:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 86:   5%|▌         | 19/367 [00:00<00:01, 183.10it/s]Pre-training Epoch 86:  11%|█         | 39/367 [00:00<00:01, 189.91it/s]Pre-training Epoch 86:  16%|█▌        | 58/367 [00:00<00:01, 188.24it/s]Pre-training Epoch 86:  21%|██▏       | 78/367 [00:00<00:01, 190.70it/s]Pre-training Epoch 86:  27%|██▋       | 98/367 [00:00<00:01, 192.10it/s]Pre-training Epoch 86:  32%|███▏      | 118/367 [00:00<00:01, 193.03it/s]recon_loss: 0.027861353009939194, dist_loss: 0.4999138414859772
recon_loss: 0.02786099538207054, dist_loss: 0.861305832862854
recon_loss: 0.02786158211529255, dist_loss: 0.5670770406723022
recon_loss: 0.027861453592777252, dist_loss: 0.8903322219848633
recon_loss: 0.02786242589354515, dist_loss: 0.5035231709480286
recon_loss: 0.027862465009093285, dist_loss: 0.7347473502159119
recon_loss: 0.027862567454576492, dist_loss: 1.063187837600708
recon_loss: 0.02786288410425186, dist_loss: 0.547964334487915
recon_loss: 0.02786228619515896, dist_loss: 0.7029454708099365
recon_loss: 0.027862323448061943, dist_loss: 0.8370486497879028
recon_loss: 0.02786214090883732, dist_loss: 0.682815670967102
recon_loss: 0.027861686423420906, dist_loss: 0.9749802350997925
recon_loss: 0.0278620608150959, dist_loss: 0.2767845392227173
recon_loss: 0.027860991656780243, dist_loss: 0.6967861652374268
recon_loss: 0.0278612170368433, dist_loss: 0.602164089679718
recon_loss: 0.027860354632139206, dist_loss: 1.0072017908096313
recon_loss: 0.027859626337885857, dist_loss: 0.5845595598220825
recon_loss: 0.02785968966782093, dist_loss: 0.4538588225841522
recon_loss: 0.027859143912792206, dist_loss: 0.5767278075218201
recon_loss: 0.027859818190336227, dist_loss: 0.20490320026874542
recon_loss: 0.027859250083565712, dist_loss: 0.6699579358100891
recon_loss: 0.027859434485435486, dist_loss: 0.8872231245040894
recon_loss: 0.027859847992658615, dist_loss: 0.4896436035633087
recon_loss: 0.02785978838801384, dist_loss: 0.5815995335578918
recon_loss: 0.0278603658080101, dist_loss: 0.6120903491973877
recon_loss: 0.0278603658080101, dist_loss: 0.2762218117713928
recon_loss: 0.02786102518439293, dist_loss: 0.5253651142120361
recon_loss: 0.027860820293426514, dist_loss: 0.7280275821685791
recon_loss: 0.02786077745258808, dist_loss: 0.7987848520278931
recon_loss: 0.027860447764396667, dist_loss: 0.5625638365745544
recon_loss: 0.02785981073975563, dist_loss: 0.6387189030647278
recon_loss: 0.027858970686793327, dist_loss: 1.0799545049667358
recon_loss: 0.027858493849635124, dist_loss: 0.6030561327934265
recon_loss: 0.02785802073776722, dist_loss: 0.5397221446037292
recon_loss: 0.027857696637511253, dist_loss: 0.8007297515869141
recon_loss: 0.027857353910803795, dist_loss: 0.5942877531051636
recon_loss: 0.02785714529454708, dist_loss: 0.563755214214325
recon_loss: 0.027857009321451187, dist_loss: 1.000240445137024
recon_loss: 0.027856938540935516, dist_loss: 0.5019553899765015
recon_loss: 0.027856869623064995, dist_loss: 0.4215160012245178
recon_loss: 0.0278568547219038, dist_loss: 0.6606398820877075
recon_loss: 0.027856934815645218, dist_loss: 0.7239116430282593
recon_loss: 0.027857061475515366, dist_loss: 0.34934234619140625
recon_loss: 0.027857346460223198, dist_loss: 0.47044050693511963
recon_loss: 0.027857763692736626, dist_loss: 0.6251282691955566
recon_loss: 0.027858437970280647, dist_loss: 0.8474917411804199
recon_loss: 0.027858547866344452, dist_loss: 0.5163208246231079
recon_loss: 0.027858564630150795, dist_loss: 0.8148912191390991
recon_loss: 0.027858927845954895, dist_loss: 0.630244255065918
recon_loss: 0.02785932645201683, dist_loss: 0.7168238162994385
recon_loss: 0.027859464287757874, dist_loss: 0.4776695966720581
recon_loss: 0.027859587222337723, dist_loss: 0.5988034009933472
recon_loss: 0.027859704568982124, dist_loss: 0.46496325731277466
recon_loss: 0.027860233560204506, dist_loss: 0.7033971548080444
recon_loss: 0.02786080911755562, dist_loss: 0.674928605556488
recon_loss: 0.02786034345626831, dist_loss: 0.6200840473175049
recon_loss: 0.027860021218657494, dist_loss: 0.27592334151268005
recon_loss: 0.027858790010213852, dist_loss: 0.2640817165374756
recon_loss: 0.027857933193445206, dist_loss: 0.4467525780200958
recon_loss: 0.027856694534420967, dist_loss: 1.0476815700531006
recon_loss: 0.027856536209583282, dist_loss: 0.533759355545044
recon_loss: 0.027856195345520973, dist_loss: 0.6518248319625854
recon_loss: 0.02785615809261799, dist_loss: 0.5274368524551392
recon_loss: 0.027856912463903427, dist_loss: 0.3825584650039673
recon_loss: 0.027856482192873955, dist_loss: 0.3874272108078003
recon_loss: 0.027857216075062752, dist_loss: 0.5076197385787964
recon_loss: 0.027856877073645592, dist_loss: 0.7326211333274841
recon_loss: 0.027857519686222076, dist_loss: 0.3791618347167969
recon_loss: 0.027856845408678055, dist_loss: 0.6049002408981323
recon_loss: 0.02785644307732582, dist_loss: 0.5616845488548279
recon_loss: 0.027856003493070602, dist_loss: 1.6741917133331299
recon_loss: 0.027856556698679924, dist_loss: 0.9028763175010681
recon_loss: 0.027857275679707527, dist_loss: 0.6811356544494629
recon_loss: 0.027857184410095215, dist_loss: 0.7061945199966431
recon_loss: 0.027858255431056023, dist_loss: 1.2106034755706787
recon_loss: 0.02785717509686947, dist_loss: 1.2748987674713135
recon_loss: 0.02785760909318924, dist_loss: 0.5228216648101807
recon_loss: 0.027857378125190735, dist_loss: 0.6876239776611328
recon_loss: 0.02785671502351761, dist_loss: 0.6587117314338684
recon_loss: 0.02785707823932171, dist_loss: 0.4457441568374634
recon_loss: 0.02785610593855381, dist_loss: 0.4980725347995758
recon_loss: 0.02785602957010269, dist_loss: 0.5162420272827148
recon_loss: 0.02785572037100792, dist_loss: 0.7183666825294495
recon_loss: 0.027855176478624344, dist_loss: 0.7120153903961182
recon_loss: 0.027855610474944115, dist_loss: 0.7605330348014832
recon_loss: 0.027855057269334793, dist_loss: 0.5988835692405701
recon_loss: 0.027855195105075836, dist_loss: 0.4599894881248474
recon_loss: 0.027855493128299713, dist_loss: 0.5334776043891907
recon_loss: 0.02785594016313553, dist_loss: 0.7587877511978149
recon_loss: 0.027856718748807907, dist_loss: 0.7464547157287598
recon_loss: 0.027856960892677307, dist_loss: 0.6054389476776123
recon_loss: 0.027857782319188118, dist_loss: 0.7333682775497437
recon_loss: 0.027857955545186996, dist_loss: 0.7342746257781982
recon_loss: 0.027857834473252296, dist_loss: 0.8719367980957031
recon_loss: 0.02785652130842209, dist_loss: 0.8559108376502991
recon_loss: 0.02785567380487919, dist_loss: 0.6407307982444763
recon_loss: 0.027854997664690018, dist_loss: 0.7228758335113525
recon_loss: 0.027854731306433678, dist_loss: 0.8114221096038818
recon_loss: 0.02785385586321354, dist_loss: 0.7952022552490234
recon_loss: 0.027853574603796005, dist_loss: 0.5125985741615295
recon_loss: 0.027852915227413177, dist_loss: 0.8158261775970459
recon_loss: 0.027852674946188927, dist_loss: 0.9713634252548218
recon_loss: 0.02785320393741131, dist_loss: 0.9731685519218445
recon_loss: 0.027853457257151604, dist_loss: 0.7754091024398804
recon_loss: 0.027854744344949722, dist_loss: 0.7208637595176697
recon_loss: 0.02785450965166092, dist_loss: 0.7128489017486572
recon_loss: 0.02785567380487919, dist_loss: 0.7665811777114868
recon_loss: 0.02785487473011017, dist_loss: 0.6312893033027649
recon_loss: 0.027854515239596367, dist_loss: 0.8142975568771362
recon_loss: 0.027854442596435547, dist_loss: 0.6378000378608704
recon_loss: 0.027853412553668022, dist_loss: 0.4110264182090759
recon_loss: 0.02785347029566765, dist_loss: 0.7080017328262329
recon_loss: 0.027853287756443024, dist_loss: 0.5660847425460815
recon_loss: 0.027853360399603844, dist_loss: 0.2011207938194275
recon_loss: 0.027853025123476982, dist_loss: 0.8984424471855164
recon_loss: 0.027852516621351242, dist_loss: 0.47363993525505066
recon_loss: 0.02785247005522251, dist_loss: 0.6815221309661865
recon_loss: 0.02785203978419304, dist_loss: 0.784278929233551
recon_loss: 0.02785242721438408, dist_loss: 0.6279280185699463
recon_loss: 0.02785327471792698, dist_loss: 0.896645188331604
recon_loss: 0.027853848412632942, dist_loss: 0.5377525091171265
recon_loss: 0.02785567007958889, dist_loss: 0.5426723957061768
recon_loss: 0.0278579480946064, dist_loss: 0.5390053391456604
recon_loss: 0.027860114350914955, dist_loss: 0.803130030632019
recon_loss: 0.02786118909716606, dist_loss: 0.5053710341453552
recon_loss: 0.02786026895046234, dist_loss: 0.8226099014282227
recon_loss: 0.027861421927809715, dist_loss: 0.7913061380386353
recon_loss: 0.027860652655363083, dist_loss: 0.6390435695648193
Pre-training Epoch 86:  38%|███▊      | 138/367 [00:00<00:01, 193.53it/s]Pre-training Epoch 86:  43%|████▎     | 158/367 [00:00<00:01, 193.99it/s]Pre-training Epoch 86:  49%|████▊     | 178/367 [00:00<00:00, 194.21it/s]Pre-training Epoch 86:  54%|█████▍    | 198/367 [00:01<00:00, 192.43it/s]Pre-training Epoch 86:  59%|█████▉    | 218/367 [00:01<00:00, 188.53it/s]Pre-training Epoch 86:  65%|██████▍   | 237/367 [00:01<00:00, 185.89it/s]Pre-training Epoch 86:  70%|██████▉   | 256/367 [00:01<00:00, 182.72it/s]recon_loss: 0.02786000818014145, dist_loss: 0.6228405237197876
recon_loss: 0.027858398854732513, dist_loss: 0.9834717512130737
recon_loss: 0.02785605937242508, dist_loss: 0.8578876256942749
recon_loss: 0.027856387197971344, dist_loss: 0.4406677782535553
recon_loss: 0.027853837236762047, dist_loss: 0.8532230257987976
recon_loss: 0.027853602543473244, dist_loss: 0.6955264806747437
recon_loss: 0.027852529659867287, dist_loss: 0.47851064801216125
recon_loss: 0.02785121463239193, dist_loss: 0.6528037190437317
recon_loss: 0.027850868180394173, dist_loss: 0.37171173095703125
recon_loss: 0.027850085869431496, dist_loss: 0.4557996690273285
recon_loss: 0.027850236743688583, dist_loss: 0.4502808451652527
recon_loss: 0.027850089594721794, dist_loss: 0.5666192770004272
recon_loss: 0.02785060927271843, dist_loss: 0.2795395255088806
recon_loss: 0.027851227670907974, dist_loss: 1.055045247077942
recon_loss: 0.027852023020386696, dist_loss: 0.3639751672744751
recon_loss: 0.027852622792124748, dist_loss: 0.4755883812904358
recon_loss: 0.02785274013876915, dist_loss: 1.233344554901123
recon_loss: 0.02785315178334713, dist_loss: 1.1210272312164307
recon_loss: 0.027852462604641914, dist_loss: 0.8801369667053223
recon_loss: 0.02785232849419117, dist_loss: 0.43812263011932373
recon_loss: 0.02785160206258297, dist_loss: 0.5810438394546509
recon_loss: 0.027851151302456856, dist_loss: 0.663308322429657
recon_loss: 0.02785063348710537, dist_loss: 0.9460203647613525
recon_loss: 0.027849750593304634, dist_loss: 0.5140140056610107
recon_loss: 0.02784944511950016, dist_loss: 0.7313416004180908
recon_loss: 0.027848755940794945, dist_loss: 0.47893595695495605
recon_loss: 0.027848536148667336, dist_loss: 0.7555348873138428
recon_loss: 0.02784840576350689, dist_loss: 0.609019935131073
recon_loss: 0.027848253026604652, dist_loss: 0.6342657804489136
recon_loss: 0.027848239988088608, dist_loss: 0.5542274713516235
recon_loss: 0.027848215773701668, dist_loss: 0.617668867111206
recon_loss: 0.02784816175699234, dist_loss: 0.8482513427734375
recon_loss: 0.027848180383443832, dist_loss: 0.7308027744293213
recon_loss: 0.027848409488797188, dist_loss: 0.6363842487335205
recon_loss: 0.027848679572343826, dist_loss: 0.8987009525299072
recon_loss: 0.027848495170474052, dist_loss: 0.5994400978088379
recon_loss: 0.027848713099956512, dist_loss: 0.6081004738807678
recon_loss: 0.02784881182014942, dist_loss: 0.43451428413391113
recon_loss: 0.027848107740283012, dist_loss: 0.8323599696159363
recon_loss: 0.027847882360219955, dist_loss: 1.4783433675765991
recon_loss: 0.027847198769450188, dist_loss: 0.7857532501220703
recon_loss: 0.02784702554345131, dist_loss: 0.41366681456565857
recon_loss: 0.027846798300743103, dist_loss: 0.6308355927467346
recon_loss: 0.027846913784742355, dist_loss: 0.6261060237884521
recon_loss: 0.027846725657582283, dist_loss: 0.5316634178161621
recon_loss: 0.0278466809540987, dist_loss: 0.6150081753730774
recon_loss: 0.027846962213516235, dist_loss: 0.6455044746398926
recon_loss: 0.027846820652484894, dist_loss: 0.4459429979324341
recon_loss: 0.02784717082977295, dist_loss: 0.26693183183670044
recon_loss: 0.027847466990351677, dist_loss: 0.6588340401649475
recon_loss: 0.027847371995449066, dist_loss: 0.4391172528266907
recon_loss: 0.02784765511751175, dist_loss: 1.2333595752716064
recon_loss: 0.027847616001963615, dist_loss: 0.33548489212989807
recon_loss: 0.027847537770867348, dist_loss: 0.8650727272033691
recon_loss: 0.02784719504415989, dist_loss: 0.593737781047821
recon_loss: 0.027846764773130417, dist_loss: 1.1285008192062378
recon_loss: 0.027846887707710266, dist_loss: 1.1832122802734375
recon_loss: 0.027846887707710266, dist_loss: 0.3646758794784546
recon_loss: 0.02784738689661026, dist_loss: 0.8519288301467896
recon_loss: 0.02784736268222332, dist_loss: 0.7102792859077454
recon_loss: 0.027847062796354294, dist_loss: 0.5281959772109985
recon_loss: 0.027847059071063995, dist_loss: 0.6554328799247742
recon_loss: 0.02784719131886959, dist_loss: 0.535212516784668
recon_loss: 0.027846693992614746, dist_loss: 0.8992953300476074
recon_loss: 0.02784602716565132, dist_loss: 0.5068682432174683
recon_loss: 0.02784554846584797, dist_loss: 0.46702075004577637
recon_loss: 0.02784535102546215, dist_loss: 0.5723162889480591
recon_loss: 0.02784520946443081, dist_loss: 0.9117991924285889
recon_loss: 0.02784518525004387, dist_loss: 0.7199828624725342
recon_loss: 0.027845237404108047, dist_loss: 0.40943652391433716
recon_loss: 0.027844738215208054, dist_loss: 0.8951195478439331
recon_loss: 0.027845067903399467, dist_loss: 0.6163728833198547
recon_loss: 0.02784557081758976, dist_loss: 0.7003656625747681
recon_loss: 0.027845632284879684, dist_loss: 1.1158447265625
recon_loss: 0.02784552611410618, dist_loss: 0.6570810675621033
recon_loss: 0.027845339849591255, dist_loss: 0.4686869978904724
recon_loss: 0.027845334261655807, dist_loss: 0.47887730598449707
recon_loss: 0.02784537523984909, dist_loss: 0.5184941291809082
recon_loss: 0.027845187112689018, dist_loss: 0.4816284775733948
recon_loss: 0.027844687923789024, dist_loss: 0.8651342391967773
recon_loss: 0.027844974771142006, dist_loss: 1.2449421882629395
recon_loss: 0.027844756841659546, dist_loss: 0.6081494092941284
recon_loss: 0.027845516800880432, dist_loss: 0.7099902629852295
recon_loss: 0.027845844626426697, dist_loss: 0.7759628891944885
recon_loss: 0.0278465636074543, dist_loss: 0.2856718897819519
recon_loss: 0.027846891433000565, dist_loss: 0.7383238077163696
recon_loss: 0.027847154065966606, dist_loss: 0.5057652592658997
recon_loss: 0.02784692496061325, dist_loss: 0.7646082639694214
recon_loss: 0.02784585766494274, dist_loss: 0.5658694505691528
recon_loss: 0.027845734730362892, dist_loss: 0.5820098519325256
recon_loss: 0.027844855561852455, dist_loss: 0.4280679225921631
recon_loss: 0.02784515544772148, dist_loss: 0.9378561973571777
recon_loss: 0.02784496173262596, dist_loss: 0.5766680240631104
recon_loss: 0.027844859287142754, dist_loss: 0.6153287291526794
recon_loss: 0.027844689786434174, dist_loss: 1.0310181379318237
recon_loss: 0.027844037860631943, dist_loss: 0.4546966254711151
recon_loss: 0.027844199910759926, dist_loss: 0.9492202401161194
recon_loss: 0.027844518423080444, dist_loss: 0.5471338033676147
recon_loss: 0.027844905853271484, dist_loss: 0.49048084020614624
recon_loss: 0.02784487046301365, dist_loss: 0.5344895720481873
recon_loss: 0.027844814583659172, dist_loss: 0.950470507144928
recon_loss: 0.027844306081533432, dist_loss: 0.8020807504653931
recon_loss: 0.02784435637295246, dist_loss: 0.660630464553833
recon_loss: 0.027844125404953957, dist_loss: 0.39498817920684814
recon_loss: 0.027843579649925232, dist_loss: 0.9427582025527954
recon_loss: 0.027843568474054337, dist_loss: 1.1852540969848633
recon_loss: 0.027843493968248367, dist_loss: 0.6618379354476929
recon_loss: 0.027844306081533432, dist_loss: 0.6342087388038635
recon_loss: 0.0278442595154047, dist_loss: 1.0417543649673462
recon_loss: 0.027845202013850212, dist_loss: 1.0666680335998535
recon_loss: 0.02784634940326214, dist_loss: 0.6126750707626343
recon_loss: 0.027845371514558792, dist_loss: 0.3918900489807129
recon_loss: 0.0278454776853323, dist_loss: 0.3620532155036926
recon_loss: 0.027844786643981934, dist_loss: 0.5724508762359619
recon_loss: 0.027843698859214783, dist_loss: 0.7702366709709167
recon_loss: 0.02784305065870285, dist_loss: 0.686629056930542
recon_loss: 0.02784198522567749, dist_loss: 0.6462016701698303
recon_loss: 0.027842799201607704, dist_loss: 0.5210822224617004
recon_loss: 0.027841709554195404, dist_loss: 0.5015953183174133
recon_loss: 0.02784324437379837, dist_loss: 0.7251665592193604
recon_loss: 0.027843166142702103, dist_loss: 0.43792662024497986
recon_loss: 0.027844425290822983, dist_loss: 0.5184728503227234
recon_loss: 0.027845321223139763, dist_loss: 0.8340412378311157
recon_loss: 0.027843458577990532, dist_loss: 1.0057942867279053
recon_loss: 0.027843473479151726, dist_loss: 0.4623449146747589
recon_loss: 0.027843398973345757, dist_loss: 0.677594780921936
recon_loss: 0.027842026203870773, dist_loss: 0.5669331550598145
recon_loss: 0.027842629700899124, dist_loss: 0.6078838109970093
Pre-training Epoch 86:  75%|███████▍  | 275/367 [00:01<00:00, 182.09it/s]Pre-training Epoch 86:  80%|████████  | 294/367 [00:01<00:00, 180.94it/s]Pre-training Epoch 86:  85%|████████▌ | 313/367 [00:01<00:00, 175.80it/s]Pre-training Epoch 86:  90%|█████████ | 331/367 [00:01<00:00, 176.45it/s]Pre-training Epoch 86:  95%|█████████▌| 349/367 [00:01<00:00, 176.04it/s]Pre-training Epoch 86: 100%|██████████| 367/367 [00:01<00:00, 171.73it/s]Pre-training Epoch 86: 100%|██████████| 367/367 [00:01<00:00, 183.69it/s]
recon_loss: 0.02784225530922413, dist_loss: 0.5601235628128052
recon_loss: 0.02784252166748047, dist_loss: 0.5129001140594482
recon_loss: 0.027843914926052094, dist_loss: 0.4464246928691864
recon_loss: 0.027842378243803978, dist_loss: 0.24338506162166595
recon_loss: 0.02784385159611702, dist_loss: 0.7274208068847656
recon_loss: 0.02784167416393757, dist_loss: 0.42759162187576294
recon_loss: 0.027842383831739426, dist_loss: 0.5124335289001465
recon_loss: 0.027841635048389435, dist_loss: 0.9034055471420288
recon_loss: 0.02784130349755287, dist_loss: 0.8039506673812866
recon_loss: 0.02784154564142227, dist_loss: 0.42195144295692444
recon_loss: 0.027839945629239082, dist_loss: 0.7766491174697876
recon_loss: 0.02784087508916855, dist_loss: 0.5719249248504639
recon_loss: 0.027839958667755127, dist_loss: 0.9188176393508911
recon_loss: 0.027840446680784225, dist_loss: 0.7700526714324951
recon_loss: 0.027840299531817436, dist_loss: 0.37041035294532776
recon_loss: 0.027840470895171165, dist_loss: 0.418011873960495
recon_loss: 0.027841461822390556, dist_loss: 0.3261534571647644
recon_loss: 0.02784264087677002, dist_loss: 0.867103099822998
recon_loss: 0.027843741700053215, dist_loss: 0.8940737247467041
recon_loss: 0.027844669297337532, dist_loss: 0.5865389108657837
recon_loss: 0.027844471856951714, dist_loss: 0.20030811429023743
recon_loss: 0.02784411609172821, dist_loss: 0.5929267406463623
recon_loss: 0.027844222262501717, dist_loss: 0.6898765563964844
recon_loss: 0.027843762189149857, dist_loss: 0.4847869277000427
recon_loss: 0.027843935415148735, dist_loss: 0.8967170119285583
recon_loss: 0.027844008058309555, dist_loss: 0.5937711000442505
recon_loss: 0.02784416824579239, dist_loss: 1.1129685640335083
recon_loss: 0.027843520045280457, dist_loss: 1.081634759902954
recon_loss: 0.027843192219734192, dist_loss: 0.499532014131546
recon_loss: 0.027842774987220764, dist_loss: 0.7406976222991943
recon_loss: 0.02784176543354988, dist_loss: 0.430444598197937
recon_loss: 0.027840763330459595, dist_loss: 0.5962076783180237
recon_loss: 0.027840029448270798, dist_loss: 0.7015584707260132
recon_loss: 0.027838991954922676, dist_loss: 0.4649290442466736
recon_loss: 0.027838997542858124, dist_loss: 1.1344358921051025
recon_loss: 0.027838628739118576, dist_loss: 0.7077540755271912
recon_loss: 0.027839016169309616, dist_loss: 0.5656094551086426
recon_loss: 0.027839012444019318, dist_loss: 0.6521550416946411
recon_loss: 0.027838924899697304, dist_loss: 0.4547417163848877
recon_loss: 0.027838842943310738, dist_loss: 0.3891640901565552
recon_loss: 0.02783835679292679, dist_loss: 0.71233069896698
recon_loss: 0.027838440611958504, dist_loss: 0.5815507769584656
recon_loss: 0.027838468551635742, dist_loss: 0.7276486754417419
recon_loss: 0.02783847600221634, dist_loss: 0.6556181907653809
recon_loss: 0.02783820405602455, dist_loss: 0.5874755382537842
recon_loss: 0.027837852016091347, dist_loss: 0.8634803295135498
recon_loss: 0.027837904170155525, dist_loss: 0.8105118274688721
recon_loss: 0.02783813886344433, dist_loss: 0.7032105922698975
recon_loss: 0.02783811278641224, dist_loss: 0.7279587984085083
recon_loss: 0.02783821150660515, dist_loss: 0.6542803049087524
recon_loss: 0.02783794142305851, dist_loss: 0.6900143623352051
recon_loss: 0.027837716042995453, dist_loss: 0.5908553600311279
recon_loss: 0.02783714048564434, dist_loss: 0.7631367444992065
recon_loss: 0.027836939319968224, dist_loss: 0.5521714687347412
recon_loss: 0.027836907655000687, dist_loss: 0.7455716729164124
recon_loss: 0.027836982160806656, dist_loss: 0.5427470207214355
recon_loss: 0.02783673256635666, dist_loss: 0.4018319249153137
recon_loss: 0.027836622670292854, dist_loss: 0.29105913639068604
recon_loss: 0.027836408466100693, dist_loss: 0.23160681128501892
recon_loss: 0.02783588506281376, dist_loss: 0.8471130728721619
recon_loss: 0.027835803106427193, dist_loss: 0.6699669361114502
recon_loss: 0.027835523709654808, dist_loss: 0.8498342037200928
recon_loss: 0.02783546969294548, dist_loss: 0.38545259833335876
recon_loss: 0.027835866436362267, dist_loss: 0.6465097069740295
recon_loss: 0.02783583290874958, dist_loss: 0.7041289806365967
recon_loss: 0.027835946530103683, dist_loss: 0.34883564710617065
recon_loss: 0.027836021035909653, dist_loss: 0.4443226456642151
recon_loss: 0.02783632092177868, dist_loss: 0.3727782964706421
recon_loss: 0.027836402878165245, dist_loss: 0.5822224020957947
recon_loss: 0.027836190536618233, dist_loss: 0.5696773529052734
recon_loss: 0.027836138382554054, dist_loss: 0.7588366270065308
recon_loss: 0.02783551625907421, dist_loss: 0.7316322326660156
recon_loss: 0.027835888788104057, dist_loss: 0.36119645833969116
recon_loss: 0.027835732325911522, dist_loss: 0.5815544128417969
recon_loss: 0.027835356071591377, dist_loss: 0.44759058952331543
recon_loss: 0.027835741639137268, dist_loss: 0.8806288838386536
recon_loss: 0.02783600240945816, dist_loss: 0.5821624994277954
recon_loss: 0.027836430817842484, dist_loss: 0.6332998871803284
recon_loss: 0.027836540713906288, dist_loss: 0.6492516994476318
recon_loss: 0.0278363935649395, dist_loss: 0.521246612071991
recon_loss: 0.027835849672555923, dist_loss: 0.799425482749939
recon_loss: 0.027835320681333542, dist_loss: 0.489713579416275
recon_loss: 0.02783510461449623, dist_loss: 0.6598978638648987
recon_loss: 0.027834637090563774, dist_loss: 0.4813728630542755
recon_loss: 0.027834394946694374, dist_loss: 0.4031202793121338
recon_loss: 0.027833908796310425, dist_loss: 0.5971441268920898
recon_loss: 0.027833720669150352, dist_loss: 0.9835596084594727
recon_loss: 0.02783351019024849, dist_loss: 0.6253612637519836
recon_loss: 0.02783379890024662, dist_loss: 0.767257571220398
recon_loss: 0.027833450585603714, dist_loss: 0.47071573138237
recon_loss: 0.027833061292767525, dist_loss: 0.7197160720825195
recon_loss: 0.02783302776515484, dist_loss: 0.5922819375991821
recon_loss: 0.027832647785544395, dist_loss: 0.777675449848175
recon_loss: 0.027833307161927223, dist_loss: 0.6390102505683899
recon_loss: 0.02783266268670559, dist_loss: 0.902535617351532
recon_loss: 0.027833452448248863, dist_loss: 0.3887150287628174
recon_loss: 0.02783321961760521, dist_loss: 0.660660982131958
recon_loss: 0.02783402055501938, dist_loss: 0.8616036772727966
recon_loss: 0.027834532782435417, dist_loss: 0.6441552639007568
recon_loss: 0.027835173532366753, dist_loss: 0.8091371655464172
recon_loss: 0.02783634513616562, dist_loss: 0.49380937218666077
recon_loss: 0.027836324647068977, dist_loss: 0.5885916948318481
recon_loss: 0.027835950255393982, dist_loss: 0.7639174461364746
recon_loss: 0.02783592976629734, dist_loss: 0.6826827526092529
recon_loss: 0.027835754677653313, dist_loss: 0.46106475591659546
recon_loss: 0.02783561870455742, dist_loss: 0.493827223777771
recon_loss: 0.027835426852107048, dist_loss: 1.1088392734527588
recon_loss: 0.02783471718430519, dist_loss: 0.4847590923309326
recon_loss: 0.027834828943014145, dist_loss: 0.7863796353340149
recon_loss: 0.0278346985578537, dist_loss: 0.6640610694885254
recon_loss: 0.027834463864564896, dist_loss: 0.8604076504707336
Pre-training Epoch 87:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 87:   4%|▍         | 15/367 [00:00<00:02, 145.53it/s]Pre-training Epoch 87:   8%|▊         | 31/367 [00:00<00:02, 151.95it/s]Pre-training Epoch 87:  13%|█▎        | 47/367 [00:00<00:02, 154.94it/s]Pre-training Epoch 87:  17%|█▋        | 63/367 [00:00<00:01, 155.25it/s]Pre-training Epoch 87:  22%|██▏       | 79/367 [00:00<00:01, 155.59it/s]Pre-training Epoch 87:  26%|██▌       | 95/367 [00:00<00:01, 155.25it/s]Pre-training Epoch 87:  30%|███       | 111/367 [00:00<00:01, 154.21it/s]recon_loss: 0.02783430926501751, dist_loss: 0.7903982400894165
recon_loss: 0.02783500961959362, dist_loss: 0.5151275396347046
recon_loss: 0.027834612876176834, dist_loss: 0.6803428530693054
recon_loss: 0.027835382148623466, dist_loss: 0.5139114260673523
recon_loss: 0.027834052219986916, dist_loss: 1.0855402946472168
recon_loss: 0.027833275496959686, dist_loss: 0.8851568698883057
recon_loss: 0.02783324383199215, dist_loss: 1.5075526237487793
recon_loss: 0.027833018451929092, dist_loss: 0.6638969779014587
recon_loss: 0.0278346985578537, dist_loss: 0.5188853740692139
recon_loss: 0.02783501334488392, dist_loss: 0.5223634243011475
recon_loss: 0.02783716470003128, dist_loss: 0.7152301073074341
recon_loss: 0.027838151901960373, dist_loss: 0.8931748867034912
recon_loss: 0.027840424329042435, dist_loss: 0.8558197021484375
recon_loss: 0.027841126546263695, dist_loss: 0.6407643556594849
recon_loss: 0.027841920033097267, dist_loss: 0.8262524008750916
recon_loss: 0.027841489762067795, dist_loss: 0.6947389841079712
recon_loss: 0.027839915826916695, dist_loss: 0.6393542289733887
recon_loss: 0.027840333059430122, dist_loss: 0.6305797100067139
recon_loss: 0.02783815935254097, dist_loss: 0.5299150943756104
recon_loss: 0.027837460860610008, dist_loss: 0.43029218912124634
recon_loss: 0.02783738262951374, dist_loss: 0.39382612705230713
recon_loss: 0.027835125103592873, dist_loss: 0.8945204019546509
recon_loss: 0.027835939079523087, dist_loss: 0.4600343108177185
recon_loss: 0.027834873646497726, dist_loss: 0.6664078235626221
recon_loss: 0.02783522941172123, dist_loss: 0.42848265171051025
recon_loss: 0.027835164219141006, dist_loss: 0.521369457244873
recon_loss: 0.027833130210638046, dist_loss: 0.5965536236763
recon_loss: 0.027833878993988037, dist_loss: 0.6343562602996826
recon_loss: 0.02783360704779625, dist_loss: 0.39153915643692017
recon_loss: 0.02783481404185295, dist_loss: 0.4781840741634369
recon_loss: 0.02783467434346676, dist_loss: 0.723612368106842
recon_loss: 0.02783442661166191, dist_loss: 0.7814598083496094
recon_loss: 0.027834966778755188, dist_loss: 0.8934191465377808
recon_loss: 0.027833793312311172, dist_loss: 1.0165040493011475
recon_loss: 0.027832848951220512, dist_loss: 0.526145339012146
recon_loss: 0.02783215418457985, dist_loss: 0.8707442879676819
recon_loss: 0.027831682935357094, dist_loss: 0.6539835333824158
recon_loss: 0.027831632643938065, dist_loss: 0.4722664952278137
recon_loss: 0.027831649407744408, dist_loss: 0.7637588977813721
recon_loss: 0.027831627056002617, dist_loss: 0.4526131749153137
recon_loss: 0.027831176295876503, dist_loss: 0.5410782098770142
recon_loss: 0.0278304573148489, dist_loss: 0.801537036895752
recon_loss: 0.02783084474503994, dist_loss: 0.5041868686676025
recon_loss: 0.027830718085169792, dist_loss: 1.2303365468978882
recon_loss: 0.027830639854073524, dist_loss: 0.6420671939849854
recon_loss: 0.02783006615936756, dist_loss: 0.5767326354980469
recon_loss: 0.02782968431711197, dist_loss: 0.4440213441848755
recon_loss: 0.027829669415950775, dist_loss: 0.7265114784240723
recon_loss: 0.027829671278595924, dist_loss: 0.3014630675315857
recon_loss: 0.027829596772789955, dist_loss: 0.3829489052295685
recon_loss: 0.027829179540276527, dist_loss: 0.40136978030204773
recon_loss: 0.027829162776470184, dist_loss: 0.8163145184516907
recon_loss: 0.02782939374446869, dist_loss: 0.7204456329345703
recon_loss: 0.02782958373427391, dist_loss: 0.49143847823143005
recon_loss: 0.02782985009253025, dist_loss: 0.8113051652908325
recon_loss: 0.027829796075820923, dist_loss: 0.5007372498512268
recon_loss: 0.027829697355628014, dist_loss: 0.523297905921936
recon_loss: 0.027829842641949654, dist_loss: 0.8606818318367004
recon_loss: 0.027829617261886597, dist_loss: 0.8123087882995605
recon_loss: 0.027829786762595177, dist_loss: 0.9062508344650269
recon_loss: 0.027829334139823914, dist_loss: 0.654273271560669
recon_loss: 0.02782892994582653, dist_loss: 0.3672778606414795
recon_loss: 0.027829192578792572, dist_loss: 0.5343177318572998
recon_loss: 0.02782844938337803, dist_loss: 0.587407648563385
recon_loss: 0.027828555554151535, dist_loss: 0.6266441345214844
recon_loss: 0.027828507125377655, dist_loss: 0.5255230069160461
recon_loss: 0.027827901765704155, dist_loss: 0.729640543460846
recon_loss: 0.027828631922602654, dist_loss: 0.6103231906890869
recon_loss: 0.027827680110931396, dist_loss: 0.2843050956726074
recon_loss: 0.02782810479402542, dist_loss: 0.5789934396743774
recon_loss: 0.027827393263578415, dist_loss: 1.299858570098877
recon_loss: 0.027827203273773193, dist_loss: 0.6756957769393921
recon_loss: 0.027827249839901924, dist_loss: 0.8823559284210205
recon_loss: 0.027826806530356407, dist_loss: 1.146480917930603
recon_loss: 0.027826914563775063, dist_loss: 0.9234926700592041
recon_loss: 0.027826599776744843, dist_loss: 0.6619918346405029
recon_loss: 0.027826635167002678, dist_loss: 0.7758833765983582
recon_loss: 0.027827123180031776, dist_loss: 0.6335711479187012
recon_loss: 0.027827972546219826, dist_loss: 0.5000011920928955
recon_loss: 0.027829941362142563, dist_loss: 0.8027397394180298
recon_loss: 0.027831148356199265, dist_loss: 0.7704140543937683
recon_loss: 0.02783237397670746, dist_loss: 0.7912495136260986
recon_loss: 0.02783203311264515, dist_loss: 0.4384602904319763
recon_loss: 0.02783159352838993, dist_loss: 0.8677045702934265
recon_loss: 0.02782994508743286, dist_loss: 0.43142956495285034
recon_loss: 0.027828514575958252, dist_loss: 0.5365330576896667
recon_loss: 0.027827830985188484, dist_loss: 0.7370198965072632
recon_loss: 0.027827681973576546, dist_loss: 0.8121881484985352
recon_loss: 0.02782873436808586, dist_loss: 0.9862415790557861
recon_loss: 0.027829375118017197, dist_loss: 0.5636159181594849
recon_loss: 0.027830252423882484, dist_loss: 1.033064365386963
recon_loss: 0.027831334620714188, dist_loss: 0.3163977861404419
recon_loss: 0.027831334620714188, dist_loss: 1.0807098150253296
recon_loss: 0.027832550927996635, dist_loss: 0.45773983001708984
recon_loss: 0.027832115069031715, dist_loss: 0.7453405261039734
recon_loss: 0.027832776308059692, dist_loss: 0.2702734172344208
recon_loss: 0.027832213789224625, dist_loss: 0.5763285160064697
recon_loss: 0.02783161588013172, dist_loss: 0.5409680008888245
recon_loss: 0.027831818908452988, dist_loss: 0.6330634355545044
recon_loss: 0.027829773724079132, dist_loss: 1.017221450805664
recon_loss: 0.027830414474010468, dist_loss: 1.0905961990356445
recon_loss: 0.027828224003314972, dist_loss: 0.8070511221885681
recon_loss: 0.027829408645629883, dist_loss: 0.6695995926856995
recon_loss: 0.027828261256217957, dist_loss: 0.866782546043396
recon_loss: 0.027828048914670944, dist_loss: 0.5347527861595154
recon_loss: 0.027828073129057884, dist_loss: 0.5151346921920776
recon_loss: 0.02782714180648327, dist_loss: 0.5971348881721497
recon_loss: 0.027827376499772072, dist_loss: 0.5007413625717163
recon_loss: 0.027827510610222816, dist_loss: 0.8307543992996216
recon_loss: 0.0278276689350605, dist_loss: 0.721542477607727
recon_loss: 0.027828311547636986, dist_loss: 0.5731261372566223
recon_loss: 0.02782716602087021, dist_loss: 0.3406018614768982
recon_loss: 0.027827993035316467, dist_loss: 0.34873661398887634
recon_loss: 0.027827715501189232, dist_loss: 0.5743300914764404
recon_loss: 0.027827223762869835, dist_loss: 0.5682530403137207
recon_loss: 0.027828283607959747, dist_loss: 0.9971975684165955
recon_loss: 0.027826787903904915, dist_loss: 0.5639770030975342
recon_loss: 0.02782600373029709, dist_loss: 0.45369237661361694
recon_loss: 0.027824942022562027, dist_loss: 1.0024030208587646
recon_loss: 0.02782510779798031, dist_loss: 0.38675981760025024
recon_loss: 0.02782493084669113, dist_loss: 0.49545982480049133
recon_loss: 0.027825145050883293, dist_loss: 0.5003825426101685
recon_loss: 0.027825545519590378, dist_loss: 0.5976566076278687
recon_loss: 0.027825424447655678, dist_loss: 0.5794017314910889
recon_loss: 0.027825558558106422, dist_loss: 1.1012691259384155
recon_loss: 0.02782543934881687, dist_loss: 0.6827856302261353
recon_loss: 0.027825770899653435, dist_loss: 0.4631621837615967
recon_loss: 0.02782556414604187, dist_loss: 0.44123637676239014
Pre-training Epoch 87:  35%|███▌      | 129/367 [00:00<00:01, 160.33it/s]Pre-training Epoch 87:  40%|████      | 147/367 [00:00<00:01, 163.29it/s]Pre-training Epoch 87:  45%|████▍     | 164/367 [00:01<00:01, 156.24it/s]Pre-training Epoch 87:  49%|████▉     | 180/367 [00:01<00:01, 156.29it/s]Pre-training Epoch 87:  53%|█████▎    | 196/367 [00:01<00:01, 155.94it/s]Pre-training Epoch 87:  58%|█████▊    | 212/367 [00:01<00:00, 156.21it/s]Pre-training Epoch 87:  62%|██████▏   | 228/367 [00:01<00:00, 156.69it/s]Pre-training Epoch 87:  66%|██████▋   | 244/367 [00:01<00:00, 156.12it/s]recon_loss: 0.027825387194752693, dist_loss: 0.5743535757064819
recon_loss: 0.027825625613331795, dist_loss: 0.5737835168838501
recon_loss: 0.027824891731142998, dist_loss: 0.4654539227485657
recon_loss: 0.02782508358359337, dist_loss: 0.5597977638244629
recon_loss: 0.027824588119983673, dist_loss: 0.5929980278015137
recon_loss: 0.02782480977475643, dist_loss: 0.6951299905776978
recon_loss: 0.02782452292740345, dist_loss: 0.6723490953445435
recon_loss: 0.027824006974697113, dist_loss: 0.589631974697113
recon_loss: 0.0278245210647583, dist_loss: 0.45337751507759094
recon_loss: 0.027825061231851578, dist_loss: 0.45845600962638855
recon_loss: 0.027825672179460526, dist_loss: 0.8059993386268616
recon_loss: 0.027825623750686646, dist_loss: 0.6167158484458923
recon_loss: 0.027825530618429184, dist_loss: 0.5416460037231445
recon_loss: 0.027824971824884415, dist_loss: 0.510383665561676
recon_loss: 0.027824323624372482, dist_loss: 0.831108808517456
recon_loss: 0.02782393991947174, dist_loss: 1.1597744226455688
recon_loss: 0.02782336249947548, dist_loss: 0.8127787113189697
recon_loss: 0.027822962030768394, dist_loss: 0.4704878628253937
recon_loss: 0.027822885662317276, dist_loss: 0.7370575666427612
recon_loss: 0.02782297693192959, dist_loss: 0.8739186525344849
recon_loss: 0.02782285585999489, dist_loss: 0.7814289331436157
recon_loss: 0.027822677046060562, dist_loss: 0.604274332523346
recon_loss: 0.027822386473417282, dist_loss: 0.5582065582275391
recon_loss: 0.027822792530059814, dist_loss: 0.6239717602729797
recon_loss: 0.027822982519865036, dist_loss: 0.6088342666625977
recon_loss: 0.02782338112592697, dist_loss: 0.5542970299720764
recon_loss: 0.027822988107800484, dist_loss: 0.7763028144836426
recon_loss: 0.027822444215416908, dist_loss: 0.4793444275856018
recon_loss: 0.02782190591096878, dist_loss: 0.7236204147338867
recon_loss: 0.027821719646453857, dist_loss: 0.6602585315704346
recon_loss: 0.027821533381938934, dist_loss: 0.8435799479484558
recon_loss: 0.027821075171232224, dist_loss: 0.40290290117263794
recon_loss: 0.0278208926320076, dist_loss: 0.6872168183326721
recon_loss: 0.02782118134200573, dist_loss: 0.4952867329120636
recon_loss: 0.027821414172649384, dist_loss: 0.7805310487747192
recon_loss: 0.027822250500321388, dist_loss: 0.4718441665172577
recon_loss: 0.027822695672512054, dist_loss: 0.44297316670417786
recon_loss: 0.027822744101285934, dist_loss: 0.8789794445037842
recon_loss: 0.027823548763990402, dist_loss: 0.40342336893081665
recon_loss: 0.027823155745863914, dist_loss: 0.4991840124130249
recon_loss: 0.02782338671386242, dist_loss: 0.838397204875946
recon_loss: 0.027823196724057198, dist_loss: 0.7565691471099854
recon_loss: 0.027822984382510185, dist_loss: 0.6157927513122559
recon_loss: 0.027823226526379585, dist_loss: 0.5749754905700684
recon_loss: 0.027823250740766525, dist_loss: 0.7897015810012817
recon_loss: 0.02782341092824936, dist_loss: 1.1118125915527344
recon_loss: 0.02782297134399414, dist_loss: 0.40605002641677856
recon_loss: 0.027822619304060936, dist_loss: 0.571667492389679
recon_loss: 0.027822529897093773, dist_loss: 0.899097740650177
recon_loss: 0.02782190404832363, dist_loss: 0.569251298904419
recon_loss: 0.02782181277871132, dist_loss: 0.5900770425796509
recon_loss: 0.027821514755487442, dist_loss: 0.9074101448059082
recon_loss: 0.027821222320199013, dist_loss: 0.7270883321762085
recon_loss: 0.02782088704407215, dist_loss: 0.6962495446205139
recon_loss: 0.027820613235235214, dist_loss: 0.5518026947975159
recon_loss: 0.027820337563753128, dist_loss: 0.7808472514152527
recon_loss: 0.02781999483704567, dist_loss: 0.3442519009113312
recon_loss: 0.02781970053911209, dist_loss: 0.9548733830451965
recon_loss: 0.02781953662633896, dist_loss: 0.30261117219924927
recon_loss: 0.02781963348388672, dist_loss: 0.6054286956787109
recon_loss: 0.027819568291306496, dist_loss: 0.47849729657173157
recon_loss: 0.02781960368156433, dist_loss: 0.418676495552063
recon_loss: 0.027819804847240448, dist_loss: 0.56882244348526
recon_loss: 0.027819838374853134, dist_loss: 0.6083108186721802
recon_loss: 0.027820086106657982, dist_loss: 0.582373857498169
recon_loss: 0.027820389717817307, dist_loss: 0.526429295539856
recon_loss: 0.027819974347949028, dist_loss: 0.7223201990127563
recon_loss: 0.027819477021694183, dist_loss: 0.5515459775924683
recon_loss: 0.02781950868666172, dist_loss: 1.0311553478240967
recon_loss: 0.027819206938147545, dist_loss: 0.37476062774658203
recon_loss: 0.02781914547085762, dist_loss: 0.2602483034133911
recon_loss: 0.027820097282528877, dist_loss: 0.5266494750976562
recon_loss: 0.027819713577628136, dist_loss: 0.863493800163269
recon_loss: 0.027820682153105736, dist_loss: 0.5776915550231934
recon_loss: 0.027820967137813568, dist_loss: 0.5486631393432617
recon_loss: 0.02782142534852028, dist_loss: 0.38413774967193604
recon_loss: 0.02782268263399601, dist_loss: 0.7112181186676025
recon_loss: 0.02782212570309639, dist_loss: 0.6994364857673645
recon_loss: 0.0278230719268322, dist_loss: 0.37593090534210205
recon_loss: 0.027821915224194527, dist_loss: 0.5001075267791748
recon_loss: 0.02782190404832363, dist_loss: 0.38984930515289307
recon_loss: 0.0278206504881382, dist_loss: 0.8450551629066467
recon_loss: 0.027820231392979622, dist_loss: 0.6215181350708008
recon_loss: 0.027819747105240822, dist_loss: 0.7380666732788086
recon_loss: 0.027818135917186737, dist_loss: 0.6806698441505432
recon_loss: 0.0278182215988636, dist_loss: 0.4060131907463074
recon_loss: 0.02781742252409458, dist_loss: 0.5921527743339539
recon_loss: 0.0278178583830595, dist_loss: 0.7216546535491943
recon_loss: 0.02781858667731285, dist_loss: 0.38526368141174316
recon_loss: 0.027818184345960617, dist_loss: 0.4491083323955536
recon_loss: 0.02781939134001732, dist_loss: 0.8186639547348022
recon_loss: 0.027819406241178513, dist_loss: 0.464555561542511
recon_loss: 0.027822624891996384, dist_loss: 0.44320061802864075
recon_loss: 0.027822956442832947, dist_loss: 0.5925707221031189
recon_loss: 0.027823621407151222, dist_loss: 0.922864556312561
recon_loss: 0.027825288474559784, dist_loss: 0.33337026834487915
recon_loss: 0.02782447822391987, dist_loss: 0.37955766916275024
recon_loss: 0.027826182544231415, dist_loss: 0.5852162837982178
recon_loss: 0.02782558463513851, dist_loss: 0.5482949018478394
recon_loss: 0.02782547101378441, dist_loss: 0.8477321267127991
recon_loss: 0.027823707088828087, dist_loss: 0.6322593092918396
recon_loss: 0.027820395305752754, dist_loss: 1.0470333099365234
recon_loss: 0.02782190404832363, dist_loss: 0.6402830481529236
recon_loss: 0.027818379923701286, dist_loss: 0.37753766775131226
recon_loss: 0.02781878598034382, dist_loss: 0.548583984375
recon_loss: 0.027817821130156517, dist_loss: 0.6634137034416199
recon_loss: 0.02781699411571026, dist_loss: 0.655550479888916
recon_loss: 0.02781735546886921, dist_loss: 0.4444175362586975
recon_loss: 0.027816185727715492, dist_loss: 0.7362862229347229
recon_loss: 0.027818113565444946, dist_loss: 0.4312116503715515
recon_loss: 0.027816858142614365, dist_loss: 0.2349521964788437
recon_loss: 0.02781827747821808, dist_loss: 0.4072704315185547
recon_loss: 0.02781871147453785, dist_loss: 0.6300526261329651
recon_loss: 0.027819300070405006, dist_loss: 0.7300734519958496
recon_loss: 0.027820318937301636, dist_loss: 0.9598429203033447
recon_loss: 0.027821477502584457, dist_loss: 0.5160606503486633
recon_loss: 0.02782261371612549, dist_loss: 0.6395004391670227
recon_loss: 0.02782384864985943, dist_loss: 0.5147000551223755
recon_loss: 0.027825510129332542, dist_loss: 0.8197296857833862
recon_loss: 0.02782624587416649, dist_loss: 1.236774206161499
recon_loss: 0.027826691046357155, dist_loss: 0.6196937561035156
recon_loss: 0.027826780453324318, dist_loss: 1.1962544918060303
recon_loss: 0.02782481163740158, dist_loss: 0.9890996217727661
recon_loss: 0.027822962030768394, dist_loss: 1.076809287071228
recon_loss: 0.02782101184129715, dist_loss: 0.6157400012016296
recon_loss: 0.02781924605369568, dist_loss: 0.6204012036323547
recon_loss: 0.02781771868467331, dist_loss: 0.5329570174217224
recon_loss: 0.027816787362098694, dist_loss: 0.44820526242256165
recon_loss: 0.027816640213131905, dist_loss: 0.9656689167022705Pre-training Epoch 87:  71%|███████   | 260/367 [00:01<00:00, 156.15it/s]Pre-training Epoch 87:  75%|███████▌  | 276/367 [00:01<00:00, 155.60it/s]Pre-training Epoch 87:  80%|███████▉  | 292/367 [00:01<00:00, 156.13it/s]Pre-training Epoch 87:  84%|████████▍ | 308/367 [00:01<00:00, 154.19it/s]Pre-training Epoch 87:  89%|████████▉ | 326/367 [00:02<00:00, 161.57it/s]Pre-training Epoch 87:  94%|█████████▍| 346/367 [00:02<00:00, 171.48it/s]Pre-training Epoch 87: 100%|█████████▉| 366/367 [00:02<00:00, 178.34it/s]Pre-training Epoch 87: 100%|██████████| 367/367 [00:02<00:00, 160.39it/s]

recon_loss: 0.02781706675887108, dist_loss: 0.551440954208374
recon_loss: 0.02781766839325428, dist_loss: 0.4030334949493408
recon_loss: 0.027818135917186737, dist_loss: 0.48079434037208557
recon_loss: 0.027818456292152405, dist_loss: 0.6171301603317261
recon_loss: 0.027818597853183746, dist_loss: 0.8719960451126099
recon_loss: 0.027818556874990463, dist_loss: 0.5397230386734009
recon_loss: 0.027818411588668823, dist_loss: 0.5722025632858276
recon_loss: 0.02781803347170353, dist_loss: 0.32756859064102173
recon_loss: 0.027817655354738235, dist_loss: 0.48401767015457153
recon_loss: 0.02781694009900093, dist_loss: 0.5793577432632446
recon_loss: 0.027816008776426315, dist_loss: 0.6204938888549805
recon_loss: 0.0278156828135252, dist_loss: 0.7319539189338684
recon_loss: 0.027815112844109535, dist_loss: 0.7674305438995361
recon_loss: 0.02781488560140133, dist_loss: 0.5817564129829407
recon_loss: 0.027814824134111404, dist_loss: 0.6664767861366272
recon_loss: 0.02781473845243454, dist_loss: 0.5982364416122437
recon_loss: 0.027814479544758797, dist_loss: 0.7897250652313232
recon_loss: 0.027814127504825592, dist_loss: 1.105433464050293
recon_loss: 0.027813909575343132, dist_loss: 0.8481757640838623
recon_loss: 0.027813415974378586, dist_loss: 0.6470000743865967
recon_loss: 0.02781318500638008, dist_loss: 0.9209229946136475
recon_loss: 0.027813278138637543, dist_loss: 0.5190820097923279
recon_loss: 0.02781335636973381, dist_loss: 1.0081456899642944
recon_loss: 0.02781367488205433, dist_loss: 0.46031710505485535
recon_loss: 0.02781389281153679, dist_loss: 0.4554794728755951
recon_loss: 0.027813855558633804, dist_loss: 0.6886827945709229
recon_loss: 0.027814069762825966, dist_loss: 0.559760570526123
recon_loss: 0.027814321219921112, dist_loss: 0.6237782835960388
recon_loss: 0.027813903987407684, dist_loss: 0.8511478304862976
recon_loss: 0.027814336121082306, dist_loss: 1.027048945426941
recon_loss: 0.027814533561468124, dist_loss: 0.5303146839141846
recon_loss: 0.027814801782369614, dist_loss: 0.9946072697639465
recon_loss: 0.02781444415450096, dist_loss: 1.1033751964569092
recon_loss: 0.027814123779535294, dist_loss: 0.49289438128471375
recon_loss: 0.027813544496893883, dist_loss: 0.6708335876464844
recon_loss: 0.027812765911221504, dist_loss: 0.6338480710983276
recon_loss: 0.027812214568257332, dist_loss: 0.5735749006271362
recon_loss: 0.027811922132968903, dist_loss: 0.6568653583526611
recon_loss: 0.02781175822019577, dist_loss: 0.47796279191970825
recon_loss: 0.027811963111162186, dist_loss: 0.8970706462860107
recon_loss: 0.02781185880303383, dist_loss: 0.8090972900390625
recon_loss: 0.027811959385871887, dist_loss: 0.7791391611099243
recon_loss: 0.027811741456389427, dist_loss: 0.7317506074905396
recon_loss: 0.027811141684651375, dist_loss: 1.137857437133789
recon_loss: 0.02781108394265175, dist_loss: 0.3786269426345825
recon_loss: 0.0278110820800066, dist_loss: 0.736283540725708
recon_loss: 0.027811037376523018, dist_loss: 0.4562097191810608
recon_loss: 0.027811434119939804, dist_loss: 0.7946701049804688
recon_loss: 0.027811359614133835, dist_loss: 0.5025112628936768
recon_loss: 0.027810921892523766, dist_loss: 0.6619234085083008
recon_loss: 0.027811558917164803, dist_loss: 0.45725324749946594
recon_loss: 0.02781057357788086, dist_loss: 0.4352343678474426
recon_loss: 0.027811601758003235, dist_loss: 1.008899450302124
recon_loss: 0.027810323983430862, dist_loss: 0.5173269510269165
recon_loss: 0.027810944244265556, dist_loss: 1.2590267658233643
recon_loss: 0.027811145409941673, dist_loss: 0.43399226665496826
recon_loss: 0.027810202911496162, dist_loss: 0.7414199113845825
recon_loss: 0.027811629697680473, dist_loss: 1.1172360181808472
recon_loss: 0.027810798957943916, dist_loss: 0.4314442574977875
recon_loss: 0.02781098335981369, dist_loss: 0.7025789618492126
recon_loss: 0.027810707688331604, dist_loss: 0.4272574782371521
recon_loss: 0.027810459956526756, dist_loss: 0.6806057691574097
recon_loss: 0.027810631319880486, dist_loss: 0.3119240403175354
recon_loss: 0.02781005948781967, dist_loss: 0.6377195715904236
recon_loss: 0.027809906750917435, dist_loss: 0.8029213547706604
recon_loss: 0.027809608727693558, dist_loss: 1.1196695566177368
recon_loss: 0.0278095081448555, dist_loss: 0.3581661283969879
recon_loss: 0.02780945599079132, dist_loss: 0.27033019065856934
recon_loss: 0.027809031307697296, dist_loss: 0.6919134259223938
recon_loss: 0.027809105813503265, dist_loss: 1.1860275268554688
recon_loss: 0.02780917100608349, dist_loss: 0.5346442461013794
recon_loss: 0.027808746322989464, dist_loss: 0.8211076259613037
recon_loss: 0.027809424325823784, dist_loss: 0.8441014289855957
recon_loss: 0.02780895121395588, dist_loss: 0.6743659973144531
recon_loss: 0.027808714658021927, dist_loss: 0.9890950918197632
recon_loss: 0.027809977531433105, dist_loss: 0.6028770208358765
recon_loss: 0.0278082937002182, dist_loss: 1.3812634944915771
recon_loss: 0.02780948020517826, dist_loss: 0.7954348921775818
recon_loss: 0.02780812792479992, dist_loss: 0.6103496551513672
recon_loss: 0.027807725593447685, dist_loss: 0.8151394724845886
recon_loss: 0.02780800126492977, dist_loss: 0.4715549349784851
recon_loss: 0.027807531878352165, dist_loss: 0.5432520508766174
recon_loss: 0.027808777987957, dist_loss: 0.6295666694641113
recon_loss: 0.027807550504803658, dist_loss: 0.8941907286643982
recon_loss: 0.02780883014202118, dist_loss: 0.44073373079299927
recon_loss: 0.02780867926776409, dist_loss: 0.6665446162223816
recon_loss: 0.027808060869574547, dist_loss: 0.936249315738678
recon_loss: 0.027808384969830513, dist_loss: 0.7992364764213562
recon_loss: 0.02780771255493164, dist_loss: 0.46238094568252563
recon_loss: 0.027808181941509247, dist_loss: 0.5536515712738037
recon_loss: 0.027807578444480896, dist_loss: 0.5272502899169922
recon_loss: 0.027808234095573425, dist_loss: 0.6104848384857178
recon_loss: 0.027807557955384254, dist_loss: 0.6093704700469971
recon_loss: 0.02780756726861, dist_loss: 0.31759124994277954
recon_loss: 0.027807820588350296, dist_loss: 0.5269440412521362
recon_loss: 0.027806999161839485, dist_loss: 0.5794363617897034
recon_loss: 0.027807112783193588, dist_loss: 0.7162152528762817
recon_loss: 0.02780657447874546, dist_loss: 0.5503747463226318
recon_loss: 0.027806369587779045, dist_loss: 0.38220393657684326
recon_loss: 0.027806950733065605, dist_loss: 0.5265401601791382
recon_loss: 0.02780701033771038, dist_loss: 0.8132609724998474
recon_loss: 0.02780766598880291, dist_loss: 0.5315282940864563
recon_loss: 0.027808060869574547, dist_loss: 0.5269137620925903
recon_loss: 0.02780887857079506, dist_loss: 1.24021577835083
recon_loss: 0.027808532118797302, dist_loss: 0.6751959919929504
recon_loss: 0.027808288112282753, dist_loss: 0.7669167518615723
recon_loss: 0.02780783548951149, dist_loss: 0.554327666759491
recon_loss: 0.027807362377643585, dist_loss: 0.9123507142066956
recon_loss: 0.027807295322418213, dist_loss: 0.29621171951293945
recon_loss: 0.02780715562403202, dist_loss: 0.8998794555664062
Pre-training Epoch 88:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 88:   5%|▌         | 19/367 [00:00<00:01, 184.57it/s]Pre-training Epoch 88:  10%|█         | 38/367 [00:00<00:01, 173.93it/s]Pre-training Epoch 88:  15%|█▌        | 56/367 [00:00<00:01, 176.29it/s]Pre-training Epoch 88:  20%|██        | 75/367 [00:00<00:01, 178.50it/s]Pre-training Epoch 88:  26%|██▌       | 94/367 [00:00<00:01, 179.32it/s]Pre-training Epoch 88:  31%|███       | 113/367 [00:00<00:01, 180.55it/s]recon_loss: 0.027806958183646202, dist_loss: 0.8671965003013611
recon_loss: 0.027806784957647324, dist_loss: 0.8820753693580627
recon_loss: 0.027806371450424194, dist_loss: 0.7708146572113037
recon_loss: 0.02780621498823166, dist_loss: 0.5667724609375
recon_loss: 0.027806516736745834, dist_loss: 0.9681804180145264
recon_loss: 0.027806023135781288, dist_loss: 0.727253794670105
recon_loss: 0.027806315571069717, dist_loss: 0.5041153430938721
recon_loss: 0.027806062251329422, dist_loss: 0.4806998670101166
recon_loss: 0.027805320918560028, dist_loss: 0.29636847972869873
recon_loss: 0.027804994955658913, dist_loss: 0.5422066450119019
recon_loss: 0.02780487760901451, dist_loss: 0.8073597550392151
recon_loss: 0.027804909273982048, dist_loss: 0.6758111715316772
recon_loss: 0.027804622426629066, dist_loss: 0.5828546285629272
recon_loss: 0.027804575860500336, dist_loss: 1.1095058917999268
recon_loss: 0.027804572135210037, dist_loss: 0.6914163827896118
recon_loss: 0.02780480869114399, dist_loss: 0.6256117820739746
recon_loss: 0.027805322781205177, dist_loss: 0.8990206718444824
recon_loss: 0.027805574238300323, dist_loss: 0.7657936811447144
recon_loss: 0.027806106954813004, dist_loss: 0.6654461622238159
recon_loss: 0.027805723249912262, dist_loss: 0.7109119296073914
recon_loss: 0.02780572883784771, dist_loss: 0.5584502220153809
recon_loss: 0.027805672958493233, dist_loss: 0.5699046850204468
recon_loss: 0.027805160731077194, dist_loss: 0.8842591643333435
recon_loss: 0.02780471369624138, dist_loss: 0.9138836860656738
recon_loss: 0.02780437096953392, dist_loss: 0.6774402260780334
recon_loss: 0.02780425362288952, dist_loss: 0.623820424079895
recon_loss: 0.027804559096693993, dist_loss: 0.49210047721862793
recon_loss: 0.02780466340482235, dist_loss: 0.44485029578208923
recon_loss: 0.027804624289274216, dist_loss: 0.5318449139595032
recon_loss: 0.027804354205727577, dist_loss: 0.5356473922729492
recon_loss: 0.027804765850305557, dist_loss: 0.8238276243209839
recon_loss: 0.02780447155237198, dist_loss: 0.8879023194313049
recon_loss: 0.027804847806692123, dist_loss: 0.44117164611816406
recon_loss: 0.027805089950561523, dist_loss: 0.7152413129806519
recon_loss: 0.027804575860500336, dist_loss: 0.7481517791748047
recon_loss: 0.02780478075146675, dist_loss: 0.6576853394508362
recon_loss: 0.027804482728242874, dist_loss: 0.9029268026351929
recon_loss: 0.027804024517536163, dist_loss: 0.43521761894226074
recon_loss: 0.027805348858237267, dist_loss: 0.8487836122512817
recon_loss: 0.027803726494312286, dist_loss: 0.6401132345199585
recon_loss: 0.027804752811789513, dist_loss: 0.47843265533447266
recon_loss: 0.027805622667074203, dist_loss: 0.6280879974365234
recon_loss: 0.02780521661043167, dist_loss: 0.5229483246803284
recon_loss: 0.027806369587779045, dist_loss: 0.5073321461677551
recon_loss: 0.02780495397746563, dist_loss: 0.4288027882575989
recon_loss: 0.027806201949715614, dist_loss: 0.5550881028175354
recon_loss: 0.02780466340482235, dist_loss: 0.5722289681434631
recon_loss: 0.02780495211482048, dist_loss: 0.6366714239120483
recon_loss: 0.02780517190694809, dist_loss: 0.3289419412612915
recon_loss: 0.02780434675514698, dist_loss: 0.3359062671661377
recon_loss: 0.027805499732494354, dist_loss: 0.6786119341850281
recon_loss: 0.027803612872958183, dist_loss: 0.5883036851882935
recon_loss: 0.02780432440340519, dist_loss: 0.43239760398864746
recon_loss: 0.027804039418697357, dist_loss: 0.7497962713241577
recon_loss: 0.02780359983444214, dist_loss: 0.7017532587051392
recon_loss: 0.02780373953282833, dist_loss: 0.7584033608436584
recon_loss: 0.027802878990769386, dist_loss: 0.4983155131340027
recon_loss: 0.027803171426057816, dist_loss: 0.8619124889373779
recon_loss: 0.027802184224128723, dist_loss: 0.9067901372909546
recon_loss: 0.027802500873804092, dist_loss: 0.790315568447113
recon_loss: 0.027802327647805214, dist_loss: 0.47445812821388245
recon_loss: 0.027802536264061928, dist_loss: 0.6272687911987305
recon_loss: 0.027803601697087288, dist_loss: 0.5930514335632324
recon_loss: 0.02780432067811489, dist_loss: 0.49346035718917847
recon_loss: 0.027805203571915627, dist_loss: 0.6319243907928467
recon_loss: 0.027806827798485756, dist_loss: 0.534074604511261
recon_loss: 0.027807733044028282, dist_loss: 0.5598699450492859
recon_loss: 0.02780928649008274, dist_loss: 0.6252630949020386
recon_loss: 0.027809573337435722, dist_loss: 0.3057551085948944
recon_loss: 0.027809958904981613, dist_loss: 0.5931999683380127
recon_loss: 0.02780945599079132, dist_loss: 0.4886387586593628
recon_loss: 0.027809076011180878, dist_loss: 0.518562912940979
recon_loss: 0.027808446437120438, dist_loss: 0.4071875214576721
recon_loss: 0.02780751883983612, dist_loss: 0.5766005516052246
recon_loss: 0.02780698612332344, dist_loss: 0.7991961240768433
recon_loss: 0.027806056663393974, dist_loss: 0.7417774796485901
recon_loss: 0.02780531346797943, dist_loss: 0.3580012917518616
recon_loss: 0.027804430574178696, dist_loss: 0.5893852710723877
recon_loss: 0.027803951874375343, dist_loss: 0.6739851236343384
recon_loss: 0.02780386619269848, dist_loss: 0.4904353618621826
recon_loss: 0.027804221957921982, dist_loss: 0.8121331930160522
recon_loss: 0.027804993093013763, dist_loss: 0.7606379985809326
recon_loss: 0.02780660055577755, dist_loss: 1.2470589876174927
recon_loss: 0.02780783176422119, dist_loss: 0.728262186050415
recon_loss: 0.02780928462743759, dist_loss: 0.8733766078948975
recon_loss: 0.02781025692820549, dist_loss: 0.4404726028442383
recon_loss: 0.027811599895358086, dist_loss: 0.4149428606033325
recon_loss: 0.027812888845801353, dist_loss: 0.5917829871177673
recon_loss: 0.027813835069537163, dist_loss: 0.552620530128479
recon_loss: 0.027814222499728203, dist_loss: 0.43903231620788574
recon_loss: 0.02781389094889164, dist_loss: 1.0161668062210083
recon_loss: 0.027812613174319267, dist_loss: 0.8156760931015015
recon_loss: 0.027811480686068535, dist_loss: 0.7318105101585388
recon_loss: 0.02781016193330288, dist_loss: 0.3097211718559265
recon_loss: 0.02780850976705551, dist_loss: 0.7180512547492981
recon_loss: 0.027806079015135765, dist_loss: 0.3822437524795532
recon_loss: 0.027804160490632057, dist_loss: 0.5301700830459595
recon_loss: 0.02780379168689251, dist_loss: 0.7950334548950195
recon_loss: 0.027803411707282066, dist_loss: 0.7649704217910767
recon_loss: 0.027804484590888023, dist_loss: 0.5647032260894775
recon_loss: 0.02780533954501152, dist_loss: 0.5165799856185913
recon_loss: 0.02780633233487606, dist_loss: 1.078071117401123
recon_loss: 0.02780669368803501, dist_loss: 0.7382504343986511
recon_loss: 0.027806701138615608, dist_loss: 0.5352081656455994
recon_loss: 0.02780640497803688, dist_loss: 0.39093536138534546
recon_loss: 0.027805665507912636, dist_loss: 0.5835152864456177
recon_loss: 0.027804747223854065, dist_loss: 0.5875875353813171
recon_loss: 0.02780425362288952, dist_loss: 0.542700469493866
recon_loss: 0.027804145589470863, dist_loss: 0.7532339096069336
recon_loss: 0.02780386246740818, dist_loss: 0.35003840923309326
recon_loss: 0.027803463861346245, dist_loss: 0.5414097905158997
recon_loss: 0.027802620083093643, dist_loss: 0.6347430944442749
recon_loss: 0.027802539989352226, dist_loss: 0.6817641854286194
recon_loss: 0.02780267968773842, dist_loss: 0.5178611278533936
recon_loss: 0.02780226804316044, dist_loss: 0.5491464734077454
recon_loss: 0.02780255675315857, dist_loss: 0.8909385204315186
recon_loss: 0.027801502496004105, dist_loss: 1.052872896194458
recon_loss: 0.02780042588710785, dist_loss: 0.6740832328796387
recon_loss: 0.027800165116786957, dist_loss: 0.5640937089920044
recon_loss: 0.02779952622950077, dist_loss: 0.3836185932159424
recon_loss: 0.027799589559435844, dist_loss: 0.5173019766807556
recon_loss: 0.027799956500530243, dist_loss: 0.7847555875778198
recon_loss: 0.027800608426332474, dist_loss: 0.7625336647033691
recon_loss: 0.027801336720585823, dist_loss: 0.46305936574935913
recon_loss: 0.027801744639873505, dist_loss: 0.5020570755004883
recon_loss: 0.02780155837535858, dist_loss: 0.40698498487472534
recon_loss: 0.02780189737677574, dist_loss: 0.5363348722457886
recon_loss: 0.027801858261227608, dist_loss: 0.9845350384712219
Pre-training Epoch 88:  36%|███▌      | 132/367 [00:00<00:01, 179.83it/s]Pre-training Epoch 88:  41%|████      | 150/367 [00:00<00:01, 178.82it/s]Pre-training Epoch 88:  46%|████▌     | 168/367 [00:00<00:01, 176.90it/s]Pre-training Epoch 88:  51%|█████     | 186/367 [00:01<00:01, 176.64it/s]Pre-training Epoch 88:  56%|█████▌    | 204/367 [00:01<00:00, 171.49it/s]Pre-training Epoch 88:  60%|██████    | 222/367 [00:01<00:00, 166.16it/s]Pre-training Epoch 88:  65%|██████▌   | 239/367 [00:01<00:00, 162.30it/s]Pre-training Epoch 88:  70%|██████▉   | 256/367 [00:01<00:00, 160.42it/s]recon_loss: 0.027801761403679848, dist_loss: 0.8322169184684753
recon_loss: 0.027801137417554855, dist_loss: 0.652756929397583
recon_loss: 0.027801016345620155, dist_loss: 0.7449908256530762
recon_loss: 0.027800466865301132, dist_loss: 0.5734022259712219
recon_loss: 0.027800338342785835, dist_loss: 0.6919927597045898
recon_loss: 0.027800047770142555, dist_loss: 0.8695271611213684
recon_loss: 0.027800902724266052, dist_loss: 0.6305131912231445
recon_loss: 0.027801545336842537, dist_loss: 0.640645444393158
recon_loss: 0.02780163288116455, dist_loss: 0.3337762653827667
recon_loss: 0.027801135554909706, dist_loss: 0.7293416261672974
recon_loss: 0.027799664065241814, dist_loss: 0.6176182627677917
recon_loss: 0.027799388393759727, dist_loss: 0.6936678290367126
recon_loss: 0.027798300608992577, dist_loss: 0.39724546670913696
recon_loss: 0.02779851108789444, dist_loss: 0.3449327349662781
recon_loss: 0.027797389775514603, dist_loss: 0.5446205139160156
recon_loss: 0.027798326686024666, dist_loss: 0.5418416261672974
recon_loss: 0.027798248454928398, dist_loss: 0.8341001272201538
recon_loss: 0.0277978777885437, dist_loss: 0.6017707586288452
recon_loss: 0.027798542752861977, dist_loss: 0.48606055974960327
recon_loss: 0.027798010036349297, dist_loss: 0.6730939149856567
recon_loss: 0.027799243107438087, dist_loss: 0.8218942880630493
recon_loss: 0.027799218893051147, dist_loss: 0.44691020250320435
recon_loss: 0.027799565345048904, dist_loss: 0.5167087316513062
recon_loss: 0.02779991738498211, dist_loss: 0.378628671169281
recon_loss: 0.02779954858124256, dist_loss: 0.9796735644340515
recon_loss: 0.027800101786851883, dist_loss: 0.5822084546089172
recon_loss: 0.02779950387775898, dist_loss: 1.1807725429534912
recon_loss: 0.02779996208846569, dist_loss: 1.1753957271575928
recon_loss: 0.027798675000667572, dist_loss: 0.5564939975738525
recon_loss: 0.027797726914286613, dist_loss: 0.542305052280426
recon_loss: 0.027797643095254898, dist_loss: 1.0962313413619995
recon_loss: 0.027796994894742966, dist_loss: 0.2831335663795471
recon_loss: 0.027798136696219444, dist_loss: 0.9122599959373474
recon_loss: 0.027797412127256393, dist_loss: 0.4800078868865967
recon_loss: 0.027797268703579903, dist_loss: 0.7373545169830322
recon_loss: 0.0277972761541605, dist_loss: 0.7818895578384399
recon_loss: 0.027796195819973946, dist_loss: 0.698477029800415
recon_loss: 0.027796270325779915, dist_loss: 0.4388881325721741
recon_loss: 0.02779553085565567, dist_loss: 0.7469078302383423
recon_loss: 0.02779531665146351, dist_loss: 0.8290231227874756
recon_loss: 0.02779550664126873, dist_loss: 0.4514070749282837
recon_loss: 0.027795327827334404, dist_loss: 0.7138348817825317
recon_loss: 0.02779626101255417, dist_loss: 0.7378066182136536
recon_loss: 0.02779681235551834, dist_loss: 0.6186591982841492
recon_loss: 0.027796700596809387, dist_loss: 0.31526684761047363
recon_loss: 0.027796870097517967, dist_loss: 0.9489258527755737
recon_loss: 0.02779717929661274, dist_loss: 0.7635636329650879
recon_loss: 0.027797428891062737, dist_loss: 0.5465442538261414
recon_loss: 0.027797672897577286, dist_loss: 0.3899577558040619
recon_loss: 0.027797240763902664, dist_loss: 0.9997929334640503
recon_loss: 0.027796946465969086, dist_loss: 0.5817049145698547
recon_loss: 0.02779657579958439, dist_loss: 0.5251405835151672
recon_loss: 0.027795908972620964, dist_loss: 0.40835773944854736
recon_loss: 0.027795566245913506, dist_loss: 0.7005857229232788
recon_loss: 0.02779507264494896, dist_loss: 1.1058646440505981
recon_loss: 0.027794847264885902, dist_loss: 0.5581063628196716
recon_loss: 0.027794351801276207, dist_loss: 0.5453944206237793
recon_loss: 0.027794014662504196, dist_loss: 0.40098661184310913
recon_loss: 0.027793867513537407, dist_loss: 0.5967614054679871
recon_loss: 0.02779366634786129, dist_loss: 0.5842374563217163
recon_loss: 0.027793357148766518, dist_loss: 0.2893938422203064
recon_loss: 0.02779369056224823, dist_loss: 0.3253924250602722
recon_loss: 0.027793508023023605, dist_loss: 0.47572556138038635
recon_loss: 0.027793560177087784, dist_loss: 0.34309709072113037
recon_loss: 0.027794798836112022, dist_loss: 0.7368696928024292
recon_loss: 0.027794325724244118, dist_loss: 1.047364592552185
recon_loss: 0.02779710292816162, dist_loss: 0.5235256552696228
recon_loss: 0.027798054739832878, dist_loss: 0.53236323595047
recon_loss: 0.02779960073530674, dist_loss: 0.9110403060913086
recon_loss: 0.02780098095536232, dist_loss: 0.6947145462036133
recon_loss: 0.02780144289135933, dist_loss: 0.3400736451148987
recon_loss: 0.0278020016849041, dist_loss: 1.043642520904541
recon_loss: 0.027800599113106728, dist_loss: 0.46368998289108276
recon_loss: 0.027800213545560837, dist_loss: 0.4122009873390198
recon_loss: 0.02779899537563324, dist_loss: 0.9490940570831299
recon_loss: 0.02779865264892578, dist_loss: 0.28402256965637207
recon_loss: 0.027797674760222435, dist_loss: 0.6647710800170898
recon_loss: 0.0277960654348135, dist_loss: 1.1555503606796265
recon_loss: 0.027795270085334778, dist_loss: 0.5990785956382751
recon_loss: 0.027794430032372475, dist_loss: 1.075299859046936
recon_loss: 0.02779420092701912, dist_loss: 0.6945945024490356
recon_loss: 0.027794452384114265, dist_loss: 0.6109271049499512
recon_loss: 0.027794601395726204, dist_loss: 0.4009196162223816
recon_loss: 0.027794886380434036, dist_loss: 0.7825925350189209
recon_loss: 0.027794810011982918, dist_loss: 0.5863337516784668
recon_loss: 0.02779538743197918, dist_loss: 0.7756825685501099
recon_loss: 0.027795739471912384, dist_loss: 0.7305878400802612
recon_loss: 0.02779599092900753, dist_loss: 0.6901776790618896
recon_loss: 0.027795782312750816, dist_loss: 0.7940043210983276
recon_loss: 0.02779550664126873, dist_loss: 0.8054088354110718
recon_loss: 0.027795951813459396, dist_loss: 0.39166805148124695
recon_loss: 0.027794942259788513, dist_loss: 0.56112140417099
recon_loss: 0.027795210480690002, dist_loss: 0.9779396653175354
recon_loss: 0.027794547379016876, dist_loss: 0.98245769739151
recon_loss: 0.027794798836112022, dist_loss: 0.617280900478363
recon_loss: 0.027794377878308296, dist_loss: 0.6100661158561707
recon_loss: 0.027794281020760536, dist_loss: 0.5197890400886536
recon_loss: 0.02779419533908367, dist_loss: 0.351854145526886
recon_loss: 0.027793504297733307, dist_loss: 0.5905592441558838
recon_loss: 0.027792640030384064, dist_loss: 0.5630249381065369
recon_loss: 0.02779238112270832, dist_loss: 0.6187114715576172
recon_loss: 0.027791988104581833, dist_loss: 0.770399808883667
recon_loss: 0.027792394161224365, dist_loss: 1.0807075500488281
recon_loss: 0.02779151313006878, dist_loss: 0.7519842386245728
recon_loss: 0.0277918241918087, dist_loss: 0.8286032676696777
recon_loss: 0.027791226282715797, dist_loss: 0.5722388625144958
recon_loss: 0.02779085375368595, dist_loss: 0.5476492643356323
recon_loss: 0.027790376916527748, dist_loss: 1.1509764194488525
recon_loss: 0.027790077030658722, dist_loss: 0.5183511972427368
recon_loss: 0.02778983674943447, dist_loss: 0.4837628901004791
recon_loss: 0.02778962068259716, dist_loss: 0.49989715218544006
recon_loss: 0.027789419516921043, dist_loss: 0.7448871731758118
recon_loss: 0.027789410203695297, dist_loss: 0.5924563407897949
recon_loss: 0.02778947725892067, dist_loss: 0.5292497277259827
recon_loss: 0.027789337560534477, dist_loss: 0.5750981569290161
recon_loss: 0.027789441868662834, dist_loss: 0.6127588748931885
recon_loss: 0.027789078652858734, dist_loss: 0.596444845199585
recon_loss: 0.027789637446403503, dist_loss: 0.5303213596343994
recon_loss: 0.027789335697889328, dist_loss: 1.0822107791900635
recon_loss: 0.02778995968401432, dist_loss: 0.6837651133537292
recon_loss: 0.027789153158664703, dist_loss: 0.9505555629730225
recon_loss: 0.027788715437054634, dist_loss: 0.9369431734085083
recon_loss: 0.027789026498794556, dist_loss: 0.6445969939231873
recon_loss: 0.027788635343313217, dist_loss: 0.8794775009155273
recon_loss: 0.027789795771241188, dist_loss: 0.6084984540939331
recon_loss: 0.027788760140538216, dist_loss: 0.6906086206436157
recon_loss: 0.02778901346027851, dist_loss: 1.4260920286178589
recon_loss: 0.027789121493697166, dist_loss: 0.6480191946029663
Pre-training Epoch 88:  74%|███████▍  | 273/367 [00:01<00:00, 159.60it/s]Pre-training Epoch 88:  79%|███████▊  | 289/367 [00:01<00:00, 159.18it/s]Pre-training Epoch 88:  83%|████████▎ | 305/367 [00:01<00:00, 158.71it/s]Pre-training Epoch 88:  87%|████████▋ | 321/367 [00:01<00:00, 157.83it/s]Pre-training Epoch 88:  92%|█████████▏| 338/367 [00:02<00:00, 160.22it/s]Pre-training Epoch 88:  97%|█████████▋| 356/367 [00:02<00:00, 165.32it/s]Pre-training Epoch 88: 100%|██████████| 367/367 [00:02<00:00, 168.26it/s]
recon_loss: 0.027789335697889328, dist_loss: 0.6155231595039368
recon_loss: 0.027789168059825897, dist_loss: 0.5141684412956238
recon_loss: 0.02778891660273075, dist_loss: 0.6433854103088379
recon_loss: 0.02778836153447628, dist_loss: 0.5414096713066101
recon_loss: 0.02778773568570614, dist_loss: 0.8336268067359924
recon_loss: 0.02778789959847927, dist_loss: 0.3962770998477936
recon_loss: 0.027787327766418457, dist_loss: 0.42033660411834717
recon_loss: 0.02778763696551323, dist_loss: 0.8605072498321533
recon_loss: 0.027786992490291595, dist_loss: 0.4400548040866852
recon_loss: 0.027786821126937866, dist_loss: 0.5992496013641357
recon_loss: 0.027786895632743835, dist_loss: 0.5836099982261658
recon_loss: 0.02778632566332817, dist_loss: 0.6307231187820435
recon_loss: 0.02778671681880951, dist_loss: 0.4935572147369385
recon_loss: 0.027786171063780785, dist_loss: 0.7072799205780029
recon_loss: 0.027786077931523323, dist_loss: 0.7528525590896606
recon_loss: 0.02778613194823265, dist_loss: 0.7943825721740723
recon_loss: 0.027786100283265114, dist_loss: 0.9037954807281494
recon_loss: 0.02778685837984085, dist_loss: 0.671093225479126
recon_loss: 0.027787085622549057, dist_loss: 0.5740194320678711
recon_loss: 0.02778768166899681, dist_loss: 0.48506879806518555
recon_loss: 0.027788255363702774, dist_loss: 0.7259567975997925
recon_loss: 0.02778700366616249, dist_loss: 1.176990032196045
recon_loss: 0.027787066996097565, dist_loss: 0.6591349840164185
recon_loss: 0.027786344289779663, dist_loss: 0.5012465715408325
recon_loss: 0.02778579294681549, dist_loss: 0.815075159072876
recon_loss: 0.027785714715719223, dist_loss: 0.5292260050773621
recon_loss: 0.027785122394561768, dist_loss: 0.5708328485488892
recon_loss: 0.027785276994109154, dist_loss: 0.7205442190170288
recon_loss: 0.027785420417785645, dist_loss: 0.6144741773605347
recon_loss: 0.0277868565171957, dist_loss: 0.8642673492431641
recon_loss: 0.02778700366616249, dist_loss: 0.714857816696167
recon_loss: 0.027788985520601273, dist_loss: 0.6266101598739624
recon_loss: 0.027789099141955376, dist_loss: 0.7562175393104553
recon_loss: 0.027787642553448677, dist_loss: 0.340629905462265
recon_loss: 0.027788430452346802, dist_loss: 0.5641868114471436
recon_loss: 0.027786657214164734, dist_loss: 0.3662779927253723
recon_loss: 0.027787303552031517, dist_loss: 1.0240302085876465
recon_loss: 0.02778618410229683, dist_loss: 0.9616287350654602
recon_loss: 0.027786921709775925, dist_loss: 0.7069802284240723
recon_loss: 0.027786588296294212, dist_loss: 0.7816423177719116
recon_loss: 0.027785710990428925, dist_loss: 0.971867561340332
recon_loss: 0.02778666466474533, dist_loss: 0.6548969149589539
recon_loss: 0.02778466045856476, dist_loss: 0.6803607940673828
recon_loss: 0.02778633125126362, dist_loss: 1.179231882095337
recon_loss: 0.02778528816998005, dist_loss: 0.6443844437599182
recon_loss: 0.027784399688243866, dist_loss: 0.693509578704834
recon_loss: 0.027785733342170715, dist_loss: 0.3908466696739197
recon_loss: 0.027783965691924095, dist_loss: 0.31491726636886597
recon_loss: 0.027785219252109528, dist_loss: 0.9961397647857666
recon_loss: 0.027783839032053947, dist_loss: 0.7984007596969604
recon_loss: 0.027784770354628563, dist_loss: 0.8071125745773315
recon_loss: 0.027786964550614357, dist_loss: 0.39140382409095764
recon_loss: 0.027785906568169594, dist_loss: 0.5697135925292969
recon_loss: 0.02778889238834381, dist_loss: 0.36786025762557983
recon_loss: 0.02778620272874832, dist_loss: 0.6467031240463257
recon_loss: 0.027785781770944595, dist_loss: 0.5179893374443054
recon_loss: 0.02778649888932705, dist_loss: 1.2936168909072876
recon_loss: 0.027784505859017372, dist_loss: 0.71100914478302
recon_loss: 0.02778642438352108, dist_loss: 1.2342703342437744
recon_loss: 0.027784783393144608, dist_loss: 0.7304877042770386
recon_loss: 0.027786703780293465, dist_loss: 0.594454288482666
recon_loss: 0.02778765931725502, dist_loss: 0.3894208073616028
recon_loss: 0.027785465121269226, dist_loss: 0.5712070465087891
recon_loss: 0.027785858139395714, dist_loss: 0.5738765001296997
recon_loss: 0.027783885598182678, dist_loss: 0.6683223247528076
recon_loss: 0.027785446494817734, dist_loss: 0.7484272718429565
recon_loss: 0.02778392657637596, dist_loss: 0.5429617166519165
recon_loss: 0.027784081175923347, dist_loss: 0.37644076347351074
recon_loss: 0.027785522863268852, dist_loss: 0.6197139620780945
recon_loss: 0.027783630415797234, dist_loss: 0.7252077460289001
recon_loss: 0.02778581902384758, dist_loss: 0.48145753145217896
recon_loss: 0.027784621343016624, dist_loss: 1.033536434173584
recon_loss: 0.027786262333393097, dist_loss: 0.8114950060844421
recon_loss: 0.02778634801506996, dist_loss: 0.951552152633667
recon_loss: 0.027783989906311035, dist_loss: 0.5562384128570557
recon_loss: 0.02778576873242855, dist_loss: 0.5134886503219604
recon_loss: 0.027784502133727074, dist_loss: 0.5266318321228027
recon_loss: 0.027785299345850945, dist_loss: 1.117005705833435
recon_loss: 0.027784977108240128, dist_loss: 0.4379567503929138
recon_loss: 0.027783937752246857, dist_loss: 0.8272589445114136
recon_loss: 0.027784716337919235, dist_loss: 0.6903468370437622
recon_loss: 0.02778424508869648, dist_loss: 0.7643365859985352
recon_loss: 0.027783215045928955, dist_loss: 0.65468430519104
recon_loss: 0.027783334255218506, dist_loss: 0.8113502860069275
recon_loss: 0.027782130986452103, dist_loss: 0.5287520885467529
recon_loss: 0.02778184972703457, dist_loss: 0.8308062553405762
recon_loss: 0.027781875804066658, dist_loss: 0.48771610856056213
recon_loss: 0.027781564742326736, dist_loss: 0.6750978231430054
recon_loss: 0.02778201550245285, dist_loss: 0.6263436079025269
recon_loss: 0.027781404554843903, dist_loss: 0.723611056804657
recon_loss: 0.027781575918197632, dist_loss: 0.5101343989372253
recon_loss: 0.027782078832387924, dist_loss: 0.623153567314148
recon_loss: 0.027782099321484566, dist_loss: 0.45411449670791626
recon_loss: 0.027781682088971138, dist_loss: 0.5464965105056763
recon_loss: 0.027780981734395027, dist_loss: 0.26977425813674927
recon_loss: 0.027780475094914436, dist_loss: 0.7890158891677856
recon_loss: 0.027780238538980484, dist_loss: 0.41426777839660645
recon_loss: 0.02778019942343235, dist_loss: 0.6246193647384644
recon_loss: 0.027780281379818916, dist_loss: 0.8420790433883667
recon_loss: 0.027780357748270035, dist_loss: 1.1396907567977905
recon_loss: 0.027780085802078247, dist_loss: 0.9424911737442017
recon_loss: 0.027780111879110336, dist_loss: 0.6474953889846802
recon_loss: 0.02777986228466034, dist_loss: 0.634361743927002
recon_loss: 0.02777988463640213, dist_loss: 0.5165621042251587
recon_loss: 0.027780715376138687, dist_loss: 0.532046377658844
recon_loss: 0.027780847623944283, dist_loss: 0.49227774143218994
recon_loss: 0.02778070606291294, dist_loss: 0.5908399820327759
recon_loss: 0.027780232951045036, dist_loss: 0.7521985769271851
recon_loss: 0.027779635041952133, dist_loss: 0.8535765409469604
recon_loss: 0.027779286727309227, dist_loss: 0.6036152243614197
recon_loss: 0.027779245749115944, dist_loss: 0.37022456526756287
Pre-training Epoch 89:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 89:   4%|▍         | 16/367 [00:00<00:02, 156.46it/s]Pre-training Epoch 89:   9%|▉         | 33/367 [00:00<00:02, 161.36it/s]Pre-training Epoch 89:  14%|█▎        | 50/367 [00:00<00:02, 157.20it/s]Pre-training Epoch 89:  18%|█▊        | 67/367 [00:00<00:01, 160.36it/s]Pre-training Epoch 89:  23%|██▎       | 84/367 [00:00<00:01, 161.56it/s]Pre-training Epoch 89:  28%|██▊       | 101/367 [00:00<00:01, 162.45it/s]Pre-training Epoch 89:  32%|███▏      | 118/367 [00:00<00:01, 163.60it/s]recon_loss: 0.02777925878763199, dist_loss: 0.68122398853302
recon_loss: 0.027780024334788322, dist_loss: 1.0162802934646606
recon_loss: 0.027781253680586815, dist_loss: 0.5749640464782715
recon_loss: 0.027782190591096878, dist_loss: 0.7890358567237854
recon_loss: 0.02778279036283493, dist_loss: 0.8804829120635986
recon_loss: 0.027782943099737167, dist_loss: 0.7903264760971069
recon_loss: 0.02778209187090397, dist_loss: 0.6598594188690186
recon_loss: 0.027781931683421135, dist_loss: 0.7730125188827515
recon_loss: 0.027781285345554352, dist_loss: 0.3580233156681061
recon_loss: 0.027780568227171898, dist_loss: 0.6807982921600342
recon_loss: 0.02778000570833683, dist_loss: 0.4707302451133728
recon_loss: 0.02777966856956482, dist_loss: 0.9276354908943176
recon_loss: 0.027779879048466682, dist_loss: 0.3982638120651245
recon_loss: 0.027779750525951385, dist_loss: 0.49091288447380066
recon_loss: 0.027780232951045036, dist_loss: 0.8764710426330566
recon_loss: 0.02778044529259205, dist_loss: 0.6947943568229675
recon_loss: 0.027781104668974876, dist_loss: 0.7884068489074707
recon_loss: 0.027781443670392036, dist_loss: 0.3956069350242615
recon_loss: 0.02778082899749279, dist_loss: 0.6594348549842834
recon_loss: 0.027780713513493538, dist_loss: 0.9736080765724182
recon_loss: 0.027779471129179, dist_loss: 0.6789687275886536
recon_loss: 0.027778910472989082, dist_loss: 0.8740488886833191
recon_loss: 0.02777961827814579, dist_loss: 0.3751060962677002
recon_loss: 0.027779432013630867, dist_loss: 0.6367859840393066
recon_loss: 0.027779679745435715, dist_loss: 0.9640715718269348
recon_loss: 0.02778022177517414, dist_loss: 0.7529434561729431
recon_loss: 0.02777993679046631, dist_loss: 0.9443767070770264
recon_loss: 0.0277798380702734, dist_loss: 0.5889009237289429
recon_loss: 0.027778947725892067, dist_loss: 0.5124645233154297
recon_loss: 0.02777828462421894, dist_loss: 0.8529077768325806
recon_loss: 0.027777977287769318, dist_loss: 0.6889448761940002
recon_loss: 0.02777763456106186, dist_loss: 0.6319470405578613
recon_loss: 0.027777565643191338, dist_loss: 0.770885705947876
recon_loss: 0.02777748741209507, dist_loss: 0.36983630061149597
recon_loss: 0.02777729369699955, dist_loss: 0.25706374645233154
recon_loss: 0.02777712047100067, dist_loss: 0.5334553718566895
recon_loss: 0.027776969596743584, dist_loss: 0.6091213822364807
recon_loss: 0.027776768431067467, dist_loss: 0.6815096735954285
recon_loss: 0.027776746079325676, dist_loss: 0.6171584725379944
recon_loss: 0.027776651084423065, dist_loss: 0.5462905764579773
recon_loss: 0.027776800096035004, dist_loss: 0.43306758999824524
recon_loss: 0.027776896953582764, dist_loss: 0.5502091646194458
recon_loss: 0.02777685411274433, dist_loss: 0.5715203285217285
recon_loss: 0.027776751667261124, dist_loss: 0.5377639532089233
recon_loss: 0.027776705101132393, dist_loss: 0.3853599727153778
recon_loss: 0.027776531875133514, dist_loss: 0.4723849594593048
recon_loss: 0.02777615189552307, dist_loss: 0.935368537902832
recon_loss: 0.02777629718184471, dist_loss: 0.6791104078292847
recon_loss: 0.027776570990681648, dist_loss: 0.5625016689300537
recon_loss: 0.02777715213596821, dist_loss: 0.5889581441879272
recon_loss: 0.02777746506035328, dist_loss: 0.8028691411018372
recon_loss: 0.02777724713087082, dist_loss: 0.5949813723564148
recon_loss: 0.027777574956417084, dist_loss: 0.8141350746154785
recon_loss: 0.02777794376015663, dist_loss: 0.43353548645973206
recon_loss: 0.02777799591422081, dist_loss: 1.289083480834961
recon_loss: 0.027777429670095444, dist_loss: 0.42461517453193665
recon_loss: 0.027776828035712242, dist_loss: 0.4473680853843689
recon_loss: 0.0277765691280365, dist_loss: 0.4619370698928833
recon_loss: 0.027776191011071205, dist_loss: 0.5939693450927734
recon_loss: 0.027776386588811874, dist_loss: 0.4081800580024719
recon_loss: 0.027775973081588745, dist_loss: 0.7862592935562134
recon_loss: 0.027775892987847328, dist_loss: 0.6270380616188049
recon_loss: 0.027775809168815613, dist_loss: 0.24177658557891846
recon_loss: 0.027775779366493225, dist_loss: 0.5385538935661316
recon_loss: 0.027776306495070457, dist_loss: 0.4302331805229187
recon_loss: 0.027776390314102173, dist_loss: 0.7650521993637085
recon_loss: 0.027776433154940605, dist_loss: 0.6847376227378845
recon_loss: 0.027776721864938736, dist_loss: 0.6959208846092224
recon_loss: 0.027776746079325676, dist_loss: 0.524712085723877
recon_loss: 0.02777782641351223, dist_loss: 0.987598180770874
recon_loss: 0.027777794748544693, dist_loss: 0.6117931008338928
recon_loss: 0.027778690680861473, dist_loss: 1.1221723556518555
recon_loss: 0.02777840942144394, dist_loss: 0.3977220058441162
recon_loss: 0.027777770534157753, dist_loss: 0.6319361925125122
recon_loss: 0.02777831256389618, dist_loss: 0.982317328453064
recon_loss: 0.027777280658483505, dist_loss: 0.588868260383606
recon_loss: 0.027778368443250656, dist_loss: 1.347606897354126
recon_loss: 0.027777589857578278, dist_loss: 1.0392078161239624
recon_loss: 0.027777738869190216, dist_loss: 0.6495203375816345
recon_loss: 0.027777548879384995, dist_loss: 0.5733304023742676
recon_loss: 0.027776481583714485, dist_loss: 0.4614226520061493
recon_loss: 0.027776937931776047, dist_loss: 0.5219274759292603
recon_loss: 0.02777542732656002, dist_loss: 0.6479882597923279
recon_loss: 0.027774818241596222, dist_loss: 0.6557937264442444
recon_loss: 0.027773702517151833, dist_loss: 0.4105076789855957
recon_loss: 0.027773214504122734, dist_loss: 0.6724792122840881
recon_loss: 0.02777295932173729, dist_loss: 0.44986283779144287
recon_loss: 0.027772696688771248, dist_loss: 0.6090549230575562
recon_loss: 0.02777297981083393, dist_loss: 0.5336084961891174
recon_loss: 0.027773596346378326, dist_loss: 0.9778957962989807
recon_loss: 0.027775989845395088, dist_loss: 0.5369649529457092
recon_loss: 0.027779003605246544, dist_loss: 1.1216858625411987
recon_loss: 0.027780605480074883, dist_loss: 0.807020902633667
recon_loss: 0.027781933546066284, dist_loss: 0.8285702466964722
recon_loss: 0.0277810450643301, dist_loss: 0.6673451662063599
recon_loss: 0.02778151072561741, dist_loss: 0.7051652669906616
recon_loss: 0.027781669050455093, dist_loss: 0.8802329897880554
recon_loss: 0.027780789881944656, dist_loss: 0.5711648464202881
recon_loss: 0.02778080850839615, dist_loss: 0.6853747963905334
recon_loss: 0.02777751535177231, dist_loss: 0.6784980297088623
recon_loss: 0.027777057141065598, dist_loss: 0.721531867980957
recon_loss: 0.02777525782585144, dist_loss: 1.0402209758758545
recon_loss: 0.027774369344115257, dist_loss: 0.5864484310150146
recon_loss: 0.027774592861533165, dist_loss: 0.8801065683364868
recon_loss: 0.02777303196489811, dist_loss: 0.604301929473877
recon_loss: 0.027774684131145477, dist_loss: 0.7654033899307251
recon_loss: 0.027772655710577965, dist_loss: 0.4775317907333374
recon_loss: 0.02777320332825184, dist_loss: 0.3347460627555847
recon_loss: 0.02777349203824997, dist_loss: 0.9389722943305969
recon_loss: 0.027772201225161552, dist_loss: 0.8578555583953857
recon_loss: 0.02777344360947609, dist_loss: 0.8986104130744934
recon_loss: 0.027771493420004845, dist_loss: 0.7544748783111572
recon_loss: 0.02777179703116417, dist_loss: 0.41846755146980286
recon_loss: 0.02777104265987873, dist_loss: 0.9088977575302124
recon_loss: 0.02777208387851715, dist_loss: 0.5498060584068298
recon_loss: 0.027771364897489548, dist_loss: 0.3707519769668579
recon_loss: 0.027771737426519394, dist_loss: 0.7442166209220886
recon_loss: 0.02777247503399849, dist_loss: 0.8402636647224426
recon_loss: 0.0277717262506485, dist_loss: 0.7280384302139282
recon_loss: 0.02777145430445671, dist_loss: 1.128401279449463
recon_loss: 0.027772074565291405, dist_loss: 0.9600563645362854
recon_loss: 0.027771105989813805, dist_loss: 0.444667249917984
recon_loss: 0.0277717262506485, dist_loss: 0.6929094195365906
recon_loss: 0.027772320434451103, dist_loss: 0.47621217370033264
recon_loss: 0.027772363275289536, dist_loss: 0.4677967429161072
recon_loss: 0.027774477377533913, dist_loss: 0.813658595085144
recon_loss: 0.027776073664426804, dist_loss: 0.35560160875320435
recon_loss: 0.02777961455285549, dist_loss: 0.5847291350364685
Pre-training Epoch 89:  37%|███▋      | 135/367 [00:00<00:01, 164.36it/s]Pre-training Epoch 89:  41%|████▏     | 152/367 [00:00<00:01, 164.40it/s]Pre-training Epoch 89:  46%|████▌     | 169/367 [00:01<00:01, 162.00it/s]Pre-training Epoch 89:  51%|█████     | 187/367 [00:01<00:01, 166.89it/s]Pre-training Epoch 89:  56%|█████▌    | 206/367 [00:01<00:00, 171.04it/s]Pre-training Epoch 89:  61%|██████    | 224/367 [00:01<00:00, 166.65it/s]Pre-training Epoch 89:  66%|██████▌   | 241/367 [00:01<00:00, 164.62it/s]recon_loss: 0.02778148278594017, dist_loss: 1.1429455280303955
recon_loss: 0.0277837123721838, dist_loss: 1.0055807828903198
recon_loss: 0.02778484858572483, dist_loss: 0.7969432473182678
recon_loss: 0.027783719822764397, dist_loss: 0.5704448819160461
recon_loss: 0.02778099849820137, dist_loss: 0.5039085745811462
recon_loss: 0.027778292074799538, dist_loss: 0.596246063709259
recon_loss: 0.02777603454887867, dist_loss: 0.8107705116271973
recon_loss: 0.02777462638914585, dist_loss: 0.4050169587135315
recon_loss: 0.027773773297667503, dist_loss: 0.5904431343078613
recon_loss: 0.027773283421993256, dist_loss: 0.7859946489334106
recon_loss: 0.027773380279541016, dist_loss: 0.4093822240829468
recon_loss: 0.027773182839155197, dist_loss: 0.4600062668323517
recon_loss: 0.027773762121796608, dist_loss: 0.9458668231964111
recon_loss: 0.02777387760579586, dist_loss: 0.5210329294204712
recon_loss: 0.027774130925536156, dist_loss: 1.2499401569366455
recon_loss: 0.027775205671787262, dist_loss: 0.759792685508728
recon_loss: 0.027774160727858543, dist_loss: 0.49521511793136597
recon_loss: 0.02777424454689026, dist_loss: 0.4268289804458618
recon_loss: 0.02777383103966713, dist_loss: 0.5433827638626099
recon_loss: 0.027773108333349228, dist_loss: 0.5329464673995972
recon_loss: 0.027772819623351097, dist_loss: 0.9611349105834961
recon_loss: 0.027771832421422005, dist_loss: 0.5742758512496948
recon_loss: 0.027771446853876114, dist_loss: 0.9845436811447144
recon_loss: 0.027771368622779846, dist_loss: 0.3877441883087158
recon_loss: 0.027771059423685074, dist_loss: 0.5862429141998291
recon_loss: 0.02777147851884365, dist_loss: 0.5785064101219177
recon_loss: 0.027771107852458954, dist_loss: 0.5402464866638184
recon_loss: 0.027771396562457085, dist_loss: 0.3179734945297241
recon_loss: 0.02777153253555298, dist_loss: 0.8781861066818237
recon_loss: 0.027771227061748505, dist_loss: 0.8232678174972534
recon_loss: 0.027771158143877983, dist_loss: 0.5438646674156189
recon_loss: 0.027770940214395523, dist_loss: 0.6260643005371094
recon_loss: 0.027770835906267166, dist_loss: 0.748651385307312
recon_loss: 0.027771202847361565, dist_loss: 0.8559975624084473
recon_loss: 0.027771251276135445, dist_loss: 0.7241404056549072
recon_loss: 0.02777133136987686, dist_loss: 0.9319072365760803
recon_loss: 0.02777108922600746, dist_loss: 0.5761358737945557
recon_loss: 0.027771655470132828, dist_loss: 0.6784813404083252
recon_loss: 0.02777155674993992, dist_loss: 0.7650351524353027
recon_loss: 0.02777247317135334, dist_loss: 0.4983307719230652
recon_loss: 0.027772659435868263, dist_loss: 0.9157694578170776
recon_loss: 0.027772290632128716, dist_loss: 0.896398663520813
recon_loss: 0.027773810550570488, dist_loss: 0.5089566707611084
recon_loss: 0.027772879227995872, dist_loss: 0.3978855609893799
recon_loss: 0.02777361311018467, dist_loss: 0.6274454593658447
recon_loss: 0.027773715555667877, dist_loss: 0.47670215368270874
recon_loss: 0.02777356468141079, dist_loss: 0.8252379298210144
recon_loss: 0.027772916480898857, dist_loss: 0.44197598099708557
recon_loss: 0.027772311121225357, dist_loss: 0.4768000841140747
recon_loss: 0.02777188830077648, dist_loss: 0.8094164133071899
recon_loss: 0.02777276188135147, dist_loss: 0.34169623255729675
recon_loss: 0.027771562337875366, dist_loss: 0.3457185924053192
recon_loss: 0.027771390974521637, dist_loss: 0.7814214825630188
recon_loss: 0.027771340683102608, dist_loss: 0.4775600731372833
recon_loss: 0.027770275250077248, dist_loss: 0.4086385667324066
recon_loss: 0.027771489694714546, dist_loss: 1.1582390069961548
recon_loss: 0.027770377695560455, dist_loss: 0.6958163976669312
recon_loss: 0.02777041308581829, dist_loss: 0.6495760679244995
recon_loss: 0.027771025896072388, dist_loss: 0.5746853351593018
recon_loss: 0.027769198641180992, dist_loss: 0.8822988867759705
recon_loss: 0.027770133689045906, dist_loss: 0.9706668853759766
recon_loss: 0.02776843123137951, dist_loss: 0.5906692743301392
recon_loss: 0.027768783271312714, dist_loss: 0.5987473130226135
recon_loss: 0.02776866964995861, dist_loss: 0.6984068155288696
recon_loss: 0.027768608182668686, dist_loss: 0.5777876377105713
recon_loss: 0.02776884287595749, dist_loss: 0.6047347187995911
recon_loss: 0.02776866964995861, dist_loss: 0.544211208820343
recon_loss: 0.027769561856985092, dist_loss: 0.5151134729385376
recon_loss: 0.027769463136792183, dist_loss: 0.917674720287323
recon_loss: 0.027769895270466805, dist_loss: 0.37855657935142517
recon_loss: 0.02777043916285038, dist_loss: 0.7822080850601196
recon_loss: 0.02777007780969143, dist_loss: 0.4833987057209015
recon_loss: 0.027771158143877983, dist_loss: 0.7603517770767212
recon_loss: 0.027770277112722397, dist_loss: 0.4921734631061554
recon_loss: 0.027770427986979485, dist_loss: 0.6378255486488342
recon_loss: 0.027770355343818665, dist_loss: 0.530537486076355
recon_loss: 0.0277712382376194, dist_loss: 1.0028014183044434
recon_loss: 0.027770424261689186, dist_loss: 0.79029381275177
recon_loss: 0.027770215645432472, dist_loss: 0.4041769802570343
recon_loss: 0.0277693048119545, dist_loss: 0.8026214838027954
recon_loss: 0.027767973020672798, dist_loss: 0.3601873219013214
recon_loss: 0.027769241482019424, dist_loss: 0.42018115520477295
recon_loss: 0.027766704559326172, dist_loss: 0.4764726161956787
recon_loss: 0.027767520397901535, dist_loss: 0.7146598100662231
recon_loss: 0.027767488732933998, dist_loss: 0.3900681734085083
recon_loss: 0.027766726911067963, dist_loss: 0.8394289016723633
recon_loss: 0.027768423780798912, dist_loss: 0.42646482586860657
recon_loss: 0.027769384905695915, dist_loss: 0.8663492202758789
recon_loss: 0.027770645916461945, dist_loss: 0.7346415519714355
recon_loss: 0.027771521359682083, dist_loss: 0.5921868085861206
recon_loss: 0.0277709998190403, dist_loss: 1.1557530164718628
recon_loss: 0.027771037071943283, dist_loss: 1.0321319103240967
recon_loss: 0.02776975929737091, dist_loss: 0.33209896087646484
recon_loss: 0.027770433574914932, dist_loss: 0.7264721393585205
recon_loss: 0.027770129963755608, dist_loss: 0.5960685014724731
recon_loss: 0.02776920422911644, dist_loss: 0.4808080196380615
recon_loss: 0.027769695967435837, dist_loss: 0.537903904914856
recon_loss: 0.027768269181251526, dist_loss: 0.4974339008331299
recon_loss: 0.027768060564994812, dist_loss: 1.2013828754425049
recon_loss: 0.02776753157377243, dist_loss: 0.4382021725177765
recon_loss: 0.02776697650551796, dist_loss: 0.5607985258102417
recon_loss: 0.027767177671194077, dist_loss: 0.5737468004226685
recon_loss: 0.027766253799200058, dist_loss: 0.3947456479072571
recon_loss: 0.027766358107328415, dist_loss: 0.7156753540039062
recon_loss: 0.027766147628426552, dist_loss: 0.9577420949935913
recon_loss: 0.027766192331910133, dist_loss: 0.6165077686309814
recon_loss: 0.027766425162553787, dist_loss: 0.6608599424362183
recon_loss: 0.027766592800617218, dist_loss: 0.7010781168937683
recon_loss: 0.027766987681388855, dist_loss: 0.6070290803909302
recon_loss: 0.027767229825258255, dist_loss: 0.780825138092041
recon_loss: 0.027767259627580643, dist_loss: 0.6392679214477539
recon_loss: 0.02776729315519333, dist_loss: 0.4914000928401947
recon_loss: 0.027767512947320938, dist_loss: 0.6607927083969116
recon_loss: 0.027767175808548927, dist_loss: 0.4440905749797821
recon_loss: 0.02776733972132206, dist_loss: 0.474331796169281
recon_loss: 0.027767639607191086, dist_loss: 0.6362823247909546
recon_loss: 0.02776850201189518, dist_loss: 0.48124563694000244
recon_loss: 0.027768831700086594, dist_loss: 0.6576572060585022
recon_loss: 0.02777010202407837, dist_loss: 0.872691810131073
recon_loss: 0.027770208194851875, dist_loss: 0.4908030927181244
recon_loss: 0.02777077816426754, dist_loss: 0.6389328837394714
recon_loss: 0.027771327644586563, dist_loss: 0.559788703918457
recon_loss: 0.027771765366196632, dist_loss: 0.35944825410842896
recon_loss: 0.02777169831097126, dist_loss: 0.825222373008728
recon_loss: 0.02777179330587387, dist_loss: 1.0716052055358887
recon_loss: 0.027771031484007835, dist_loss: 1.0727906227111816
recon_loss: 0.027770306915044785, dist_loss: 0.43669506907463074
recon_loss: 0.027769243344664574, dist_loss: 0.8756022453308105
Pre-training Epoch 89:  70%|███████   | 258/367 [00:01<00:00, 164.91it/s]Pre-training Epoch 89:  75%|███████▍  | 275/367 [00:01<00:00, 165.11it/s]Pre-training Epoch 89:  80%|███████▉  | 292/367 [00:01<00:00, 165.36it/s]Pre-training Epoch 89:  84%|████████▍ | 309/367 [00:01<00:00, 165.01it/s]Pre-training Epoch 89:  89%|████████▉ | 326/367 [00:01<00:00, 162.47it/s]Pre-training Epoch 89:  93%|█████████▎| 343/367 [00:02<00:00, 159.74it/s]Pre-training Epoch 89:  98%|█████████▊| 360/367 [00:02<00:00, 161.15it/s]Pre-training Epoch 89: 100%|██████████| 367/367 [00:02<00:00, 163.32it/s]
recon_loss: 0.027768021449446678, dist_loss: 0.7238852977752686
recon_loss: 0.027767470106482506, dist_loss: 0.8262745141983032
recon_loss: 0.027767259627580643, dist_loss: 0.8934492468833923
recon_loss: 0.027767391875386238, dist_loss: 0.48457059264183044
recon_loss: 0.027767512947320938, dist_loss: 0.540339469909668
recon_loss: 0.027767639607191086, dist_loss: 1.0620853900909424
recon_loss: 0.02776782400906086, dist_loss: 0.5004965662956238
recon_loss: 0.02776777744293213, dist_loss: 0.40764790773391724
recon_loss: 0.02776840142905712, dist_loss: 0.4065861701965332
recon_loss: 0.027768565341830254, dist_loss: 0.6147317886352539
recon_loss: 0.027769338339567184, dist_loss: 0.47899383306503296
recon_loss: 0.02776983007788658, dist_loss: 0.7675732374191284
recon_loss: 0.027769209817051888, dist_loss: 0.3212902843952179
recon_loss: 0.027768349274992943, dist_loss: 0.6422621011734009
recon_loss: 0.027767762541770935, dist_loss: 0.7719041705131531
recon_loss: 0.027766825631260872, dist_loss: 0.6308043599128723
recon_loss: 0.02776617929339409, dist_loss: 0.6583154201507568
recon_loss: 0.027765173465013504, dist_loss: 0.532112717628479
recon_loss: 0.02776414528489113, dist_loss: 0.7953078746795654
recon_loss: 0.027763444930315018, dist_loss: 0.5842392444610596
recon_loss: 0.027763279154896736, dist_loss: 0.7657312750816345
recon_loss: 0.02776290662586689, dist_loss: 0.7106456756591797
recon_loss: 0.027762528508901596, dist_loss: 0.6463135480880737
recon_loss: 0.027762269601225853, dist_loss: 0.6701868772506714
recon_loss: 0.027762072160840034, dist_loss: 0.8905458450317383
recon_loss: 0.027761956676840782, dist_loss: 0.5368880033493042
recon_loss: 0.02776181884109974, dist_loss: 0.665444016456604
recon_loss: 0.027761852368712425, dist_loss: 0.5344349145889282
recon_loss: 0.02776140719652176, dist_loss: 0.4317019581794739
recon_loss: 0.02776106260716915, dist_loss: 0.5854740142822266
recon_loss: 0.027760770171880722, dist_loss: 0.5370022058486938
recon_loss: 0.027760488912463188, dist_loss: 0.5890719890594482
recon_loss: 0.027760539203882217, dist_loss: 0.6316519379615784
recon_loss: 0.027760695666074753, dist_loss: 0.8119354248046875
recon_loss: 0.027760393917560577, dist_loss: 0.6145817637443542
recon_loss: 0.027760297060012817, dist_loss: 0.2799699306488037
recon_loss: 0.027760222554206848, dist_loss: 0.2740465998649597
recon_loss: 0.02776017226278782, dist_loss: 0.9553046226501465
recon_loss: 0.027760200202465057, dist_loss: 0.6691088676452637
recon_loss: 0.027760080993175507, dist_loss: 0.43287667632102966
recon_loss: 0.027759945020079613, dist_loss: 0.9449570178985596
recon_loss: 0.027759898453950882, dist_loss: 0.5106745958328247
recon_loss: 0.027759844437241554, dist_loss: 0.5335251688957214
recon_loss: 0.02775951288640499, dist_loss: 0.738461971282959
recon_loss: 0.027759436517953873, dist_loss: 0.8471670150756836
recon_loss: 0.027759641408920288, dist_loss: 0.9041811227798462
recon_loss: 0.027759727090597153, dist_loss: 0.6172529458999634
recon_loss: 0.027759728953242302, dist_loss: 0.227809339761734
recon_loss: 0.02775946445763111, dist_loss: 0.6586439609527588
recon_loss: 0.027759529650211334, dist_loss: 0.571800947189331
recon_loss: 0.027759555727243423, dist_loss: 0.766620934009552
recon_loss: 0.02775942161679268, dist_loss: 0.8504906296730042
recon_loss: 0.0277598574757576, dist_loss: 0.46150538325309753
recon_loss: 0.027758939191699028, dist_loss: 0.39829304814338684
recon_loss: 0.0277597326785326, dist_loss: 0.5807376503944397
recon_loss: 0.027758801355957985, dist_loss: 0.608588695526123
recon_loss: 0.02775838039815426, dist_loss: 1.0714976787567139
recon_loss: 0.0277593731880188, dist_loss: 0.6174185276031494
recon_loss: 0.027758777141571045, dist_loss: 0.700238823890686
recon_loss: 0.027760149911046028, dist_loss: 0.35762661695480347
recon_loss: 0.027761436998844147, dist_loss: 0.6259036064147949
recon_loss: 0.027762828394770622, dist_loss: 0.49251770973205566
recon_loss: 0.02776459977030754, dist_loss: 0.6124717593193054
recon_loss: 0.02776527963578701, dist_loss: 0.6406149864196777
recon_loss: 0.0277662742882967, dist_loss: 0.7141966819763184
recon_loss: 0.02776665799319744, dist_loss: 0.583309531211853
recon_loss: 0.027764802798628807, dist_loss: 0.6872543692588806
recon_loss: 0.027763204649090767, dist_loss: 0.42405229806900024
recon_loss: 0.027762016281485558, dist_loss: 0.4958459138870239
recon_loss: 0.02776140347123146, dist_loss: 0.6651784181594849
recon_loss: 0.02776041068136692, dist_loss: 0.5262037515640259
recon_loss: 0.027759810909628868, dist_loss: 0.9073647260665894
recon_loss: 0.027760198339819908, dist_loss: 0.6131042838096619
recon_loss: 0.027761725708842278, dist_loss: 0.5637316107749939
recon_loss: 0.027763133868575096, dist_loss: 0.7285060882568359
recon_loss: 0.027763694524765015, dist_loss: 0.5472818613052368
recon_loss: 0.02776443585753441, dist_loss: 0.46949270367622375
recon_loss: 0.0277646966278553, dist_loss: 0.5975136160850525
recon_loss: 0.02776494435966015, dist_loss: 0.5520249009132385
recon_loss: 0.02776472084224224, dist_loss: 1.0153775215148926
recon_loss: 0.027765067294239998, dist_loss: 0.8827930688858032
recon_loss: 0.02776299975812435, dist_loss: 0.677364706993103
recon_loss: 0.027762170881032944, dist_loss: 0.6043726801872253
recon_loss: 0.02776070311665535, dist_loss: 0.4311853051185608
recon_loss: 0.027759958058595657, dist_loss: 0.9239521026611328
recon_loss: 0.02776038832962513, dist_loss: 0.559586763381958
recon_loss: 0.027760474011301994, dist_loss: 0.632055401802063
recon_loss: 0.027761172503232956, dist_loss: 0.48554885387420654
recon_loss: 0.027760999277234077, dist_loss: 1.17599618434906
recon_loss: 0.027761630713939667, dist_loss: 1.030310869216919
recon_loss: 0.027761757373809814, dist_loss: 0.6259168386459351
recon_loss: 0.027761677280068398, dist_loss: 0.8071918487548828
recon_loss: 0.0277614276856184, dist_loss: 0.6237984895706177
recon_loss: 0.027760736644268036, dist_loss: 0.6556607484817505
recon_loss: 0.02776014618575573, dist_loss: 0.7110378742218018
recon_loss: 0.027759194374084473, dist_loss: 0.7007328867912292
recon_loss: 0.027758348733186722, dist_loss: 0.49323636293411255
recon_loss: 0.027758585289120674, dist_loss: 0.5485563278198242
recon_loss: 0.02775764651596546, dist_loss: 0.3914969265460968
recon_loss: 0.027757955715060234, dist_loss: 0.5957783460617065
recon_loss: 0.02775736339390278, dist_loss: 1.125685453414917
recon_loss: 0.02775750868022442, dist_loss: 0.45197921991348267
recon_loss: 0.02775692380964756, dist_loss: 0.43561434745788574
recon_loss: 0.027756575495004654, dist_loss: 0.7453931570053101
recon_loss: 0.027756908908486366, dist_loss: 0.44584453105926514
recon_loss: 0.02775765210390091, dist_loss: 0.5274240374565125
recon_loss: 0.027758240699768066, dist_loss: 0.4344886541366577
recon_loss: 0.027759376913309097, dist_loss: 0.7782076597213745
recon_loss: 0.02776058204472065, dist_loss: 0.961638331413269
recon_loss: 0.027761271223425865, dist_loss: 0.8952178955078125
recon_loss: 0.027760639786720276, dist_loss: 0.36315208673477173
Pre-training Epoch 90:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 90:   4%|▍         | 16/367 [00:00<00:02, 159.06it/s]Pre-training Epoch 90:   9%|▉         | 33/367 [00:00<00:02, 162.46it/s]Pre-training Epoch 90:  14%|█▎        | 50/367 [00:00<00:01, 163.71it/s]Pre-training Epoch 90:  18%|█▊        | 67/367 [00:00<00:01, 163.37it/s]Pre-training Epoch 90:  23%|██▎       | 84/367 [00:00<00:01, 159.04it/s]Pre-training Epoch 90:  28%|██▊       | 101/367 [00:00<00:01, 161.07it/s]Pre-training Epoch 90:  32%|███▏      | 118/367 [00:00<00:01, 160.11it/s]recon_loss: 0.027759583666920662, dist_loss: 0.5830836296081543
recon_loss: 0.027758581563830376, dist_loss: 0.9363316297531128
recon_loss: 0.02775847725570202, dist_loss: 0.7291340231895447
recon_loss: 0.027758536860346794, dist_loss: 1.0373632907867432
recon_loss: 0.027758313342928886, dist_loss: 0.879932165145874
recon_loss: 0.027757976204156876, dist_loss: 0.5781906843185425
recon_loss: 0.027757082134485245, dist_loss: 0.4777888357639313
recon_loss: 0.0277565810829401, dist_loss: 0.8281561136245728
recon_loss: 0.0277565810829401, dist_loss: 0.5377333760261536
recon_loss: 0.027756348252296448, dist_loss: 0.4296760559082031
recon_loss: 0.02775641717016697, dist_loss: 0.5975356101989746
recon_loss: 0.027756189927458763, dist_loss: 0.6689491271972656
recon_loss: 0.02775605395436287, dist_loss: 0.6993337869644165
recon_loss: 0.027756035327911377, dist_loss: 0.8540658950805664
recon_loss: 0.027755968272686005, dist_loss: 0.41241806745529175
recon_loss: 0.02775619924068451, dist_loss: 0.4249083995819092
recon_loss: 0.027756787836551666, dist_loss: 0.2730570435523987
recon_loss: 0.027757123112678528, dist_loss: 0.6083613634109497
recon_loss: 0.027757054194808006, dist_loss: 0.7154219150543213
recon_loss: 0.027756880968809128, dist_loss: 0.47424986958503723
recon_loss: 0.027756107971072197, dist_loss: 0.35091230273246765
recon_loss: 0.027756040915846825, dist_loss: 0.5420206785202026
recon_loss: 0.02775586023926735, dist_loss: 0.7990168333053589
recon_loss: 0.02775602415204048, dist_loss: 0.6352974772453308
recon_loss: 0.02775605581700802, dist_loss: 0.8587054014205933
recon_loss: 0.027755744755268097, dist_loss: 0.5631276965141296
recon_loss: 0.027756115421652794, dist_loss: 0.9152633547782898
recon_loss: 0.02775527536869049, dist_loss: 0.5725582838058472
recon_loss: 0.027755554765462875, dist_loss: 0.40903595089912415
recon_loss: 0.027754738926887512, dist_loss: 0.4207375943660736
recon_loss: 0.02775467187166214, dist_loss: 0.6012365818023682
recon_loss: 0.027755124494433403, dist_loss: 0.46968746185302734
recon_loss: 0.027754032984375954, dist_loss: 1.046258568763733
recon_loss: 0.02775445394217968, dist_loss: 0.5508994460105896
recon_loss: 0.027753634378314018, dist_loss: 0.49765557050704956
recon_loss: 0.02775377407670021, dist_loss: 0.3990338444709778
recon_loss: 0.027753818780183792, dist_loss: 0.5884902477264404
recon_loss: 0.027753310278058052, dist_loss: 0.38061079382896423
recon_loss: 0.027753375470638275, dist_loss: 0.7087900638580322
recon_loss: 0.027752937749028206, dist_loss: 0.6290216445922852
recon_loss: 0.027753127738833427, dist_loss: 0.6479960680007935
recon_loss: 0.027752796187996864, dist_loss: 0.7442617416381836
recon_loss: 0.027752943336963654, dist_loss: 0.7467230558395386
recon_loss: 0.027753258123993874, dist_loss: 0.406136155128479
recon_loss: 0.027753889560699463, dist_loss: 0.48992595076560974
recon_loss: 0.02775385044515133, dist_loss: 0.7600125670433044
recon_loss: 0.02775333635509014, dist_loss: 0.8464097380638123
recon_loss: 0.027753084897994995, dist_loss: 0.7514635324478149
recon_loss: 0.027753349393606186, dist_loss: 0.5865558385848999
recon_loss: 0.027753453701734543, dist_loss: 0.6628097891807556
recon_loss: 0.027753669768571854, dist_loss: 0.3812740743160248
recon_loss: 0.027753692120313644, dist_loss: 0.8389436602592468
recon_loss: 0.027753716334700584, dist_loss: 0.7163614630699158
recon_loss: 0.027753660455346107, dist_loss: 0.9766167998313904
recon_loss: 0.027753673493862152, dist_loss: 0.44467589259147644
recon_loss: 0.02775386907160282, dist_loss: 0.8016632795333862
recon_loss: 0.02775469981133938, dist_loss: 0.4977303147315979
recon_loss: 0.027754705399274826, dist_loss: 0.5023598670959473
recon_loss: 0.02775508351624012, dist_loss: 0.31024712324142456
recon_loss: 0.02775503695011139, dist_loss: 0.7253730297088623
recon_loss: 0.027754375711083412, dist_loss: 0.3825915455818176
recon_loss: 0.0277546476572752, dist_loss: 0.5456104278564453
recon_loss: 0.027754096314311028, dist_loss: 0.9418222904205322
recon_loss: 0.027754297479987144, dist_loss: 0.593045711517334
recon_loss: 0.027754297479987144, dist_loss: 1.0661413669586182
recon_loss: 0.027754075825214386, dist_loss: 1.3189301490783691
recon_loss: 0.027754420414566994, dist_loss: 0.5440140962600708
recon_loss: 0.0277524683624506, dist_loss: 0.38062387704849243
recon_loss: 0.027752598747611046, dist_loss: 0.5436106324195862
recon_loss: 0.02775387093424797, dist_loss: 0.4600839912891388
recon_loss: 0.027751265093684196, dist_loss: 0.651382565498352
recon_loss: 0.027753664180636406, dist_loss: 0.8002303838729858
recon_loss: 0.027751455083489418, dist_loss: 0.5746660232543945
recon_loss: 0.027753345668315887, dist_loss: 0.3685287833213806
recon_loss: 0.027751682326197624, dist_loss: 0.767998456954956
recon_loss: 0.027752097696065903, dist_loss: 0.6674169301986694
recon_loss: 0.027752520516514778, dist_loss: 0.5793126821517944
recon_loss: 0.027752051129937172, dist_loss: 0.5250518918037415
recon_loss: 0.027753109112381935, dist_loss: 0.671878457069397
recon_loss: 0.02775108814239502, dist_loss: 0.5575892329216003
recon_loss: 0.027751276269555092, dist_loss: 0.6391006708145142
recon_loss: 0.027751518413424492, dist_loss: 0.5626567602157593
recon_loss: 0.027751808986067772, dist_loss: 0.3939218521118164
recon_loss: 0.027751605957746506, dist_loss: 0.5153575539588928
recon_loss: 0.027752071619033813, dist_loss: 0.612900972366333
recon_loss: 0.027752267196774483, dist_loss: 0.37569573521614075
recon_loss: 0.027752792462706566, dist_loss: 0.7655103206634521
recon_loss: 0.02775295451283455, dist_loss: 0.6243464350700378
recon_loss: 0.027752596884965897, dist_loss: 0.5509042739868164
recon_loss: 0.027752164751291275, dist_loss: 0.577171802520752
recon_loss: 0.027751866728067398, dist_loss: 0.8185055255889893
recon_loss: 0.027751725167036057, dist_loss: 1.1909761428833008
recon_loss: 0.027751902118325233, dist_loss: 0.3493803143501282
recon_loss: 0.02775171957910061, dist_loss: 0.5025684237480164
recon_loss: 0.027751384302973747, dist_loss: 0.5736368894577026
recon_loss: 0.02775106392800808, dist_loss: 0.7036948204040527
recon_loss: 0.02775214985013008, dist_loss: 0.5139663815498352
recon_loss: 0.027753343805670738, dist_loss: 0.41300904750823975
recon_loss: 0.027753664180636406, dist_loss: 0.5894727110862732
recon_loss: 0.027753634378314018, dist_loss: 0.5403454899787903
recon_loss: 0.027754023671150208, dist_loss: 0.8037301301956177
recon_loss: 0.027755774557590485, dist_loss: 1.0967334508895874
recon_loss: 0.027755558490753174, dist_loss: 1.032003402709961
recon_loss: 0.02775746025145054, dist_loss: 0.6460957527160645
recon_loss: 0.027757061645388603, dist_loss: 0.9133220314979553
recon_loss: 0.02775619924068451, dist_loss: 1.1623027324676514
recon_loss: 0.027754658833146095, dist_loss: 0.49857252836227417
recon_loss: 0.027754101902246475, dist_loss: 0.6714937090873718
recon_loss: 0.027753861621022224, dist_loss: 0.8201353549957275
recon_loss: 0.027753064408898354, dist_loss: 0.6882733106613159
recon_loss: 0.027751654386520386, dist_loss: 0.6307873725891113
recon_loss: 0.027751250192523003, dist_loss: 0.4763600528240204
recon_loss: 0.027750950306653976, dist_loss: 0.6508963108062744
recon_loss: 0.027750108391046524, dist_loss: 0.6262744665145874
recon_loss: 0.027750063687562943, dist_loss: 0.5610224604606628
recon_loss: 0.027749348431825638, dist_loss: 1.3007080554962158
recon_loss: 0.027748987078666687, dist_loss: 0.7569334506988525
recon_loss: 0.027749178931117058, dist_loss: 0.7641779184341431
recon_loss: 0.027749480679631233, dist_loss: 0.525785505771637
recon_loss: 0.027749987319111824, dist_loss: 0.6520591378211975
recon_loss: 0.027750130742788315, dist_loss: 0.39219456911087036
recon_loss: 0.027750417590141296, dist_loss: 0.5389319658279419
recon_loss: 0.027751093730330467, dist_loss: 0.5406907200813293
recon_loss: 0.02775152586400509, dist_loss: 0.679085910320282
recon_loss: 0.02775203436613083, dist_loss: 0.56559157371521
recon_loss: 0.02775297686457634, dist_loss: 0.9563813805580139
recon_loss: 0.02775455079972744, dist_loss: 0.7983782291412354
recon_loss: 0.027756713330745697, dist_loss: 1.0226516723632812
Pre-training Epoch 90:  37%|███▋      | 136/367 [00:00<00:01, 165.73it/s]Pre-training Epoch 90:  42%|████▏     | 155/367 [00:00<00:01, 170.51it/s]Pre-training Epoch 90:  47%|████▋     | 173/367 [00:01<00:01, 173.03it/s]Pre-training Epoch 90:  52%|█████▏    | 191/367 [00:01<00:01, 173.77it/s]Pre-training Epoch 90:  57%|█████▋    | 209/367 [00:01<00:00, 175.35it/s]Pre-training Epoch 90:  62%|██████▏   | 227/367 [00:01<00:00, 176.57it/s]Pre-training Epoch 90:  67%|██████▋   | 245/367 [00:01<00:00, 168.45it/s]recon_loss: 0.027757417410612106, dist_loss: 0.6172381639480591
recon_loss: 0.02775774896144867, dist_loss: 0.6368474960327148
recon_loss: 0.027756718918681145, dist_loss: 0.8555439710617065
recon_loss: 0.027754686772823334, dist_loss: 0.6468786597251892
recon_loss: 0.027753857895731926, dist_loss: 0.8650788068771362
recon_loss: 0.0277517419308424, dist_loss: 0.5725368857383728
recon_loss: 0.02775125950574875, dist_loss: 0.7790732979774475
recon_loss: 0.027749668806791306, dist_loss: 0.5795199871063232
recon_loss: 0.027750113978981972, dist_loss: 0.5320494174957275
recon_loss: 0.027749821543693542, dist_loss: 0.48737722635269165
recon_loss: 0.027750879526138306, dist_loss: 1.1166274547576904
recon_loss: 0.027751225978136063, dist_loss: 0.5967441201210022
recon_loss: 0.0277511365711689, dist_loss: 0.4999755620956421
recon_loss: 0.027751488611102104, dist_loss: 0.41061973571777344
recon_loss: 0.027750307694077492, dist_loss: 0.47389692068099976
recon_loss: 0.027750946581363678, dist_loss: 0.5445500612258911
recon_loss: 0.027749698609113693, dist_loss: 0.4368768334388733
recon_loss: 0.02774977870285511, dist_loss: 0.36765533685684204
recon_loss: 0.027749095112085342, dist_loss: 1.4203598499298096
recon_loss: 0.02774801105260849, dist_loss: 0.32276520133018494
recon_loss: 0.027747994288802147, dist_loss: 0.9288430213928223
recon_loss: 0.027748482301831245, dist_loss: 0.710080623626709
recon_loss: 0.027749521657824516, dist_loss: 0.9078807830810547
recon_loss: 0.027750717476010323, dist_loss: 0.5698200464248657
recon_loss: 0.02775208279490471, dist_loss: 0.42530518770217896
recon_loss: 0.027753207832574844, dist_loss: 0.3223804235458374
recon_loss: 0.027754154056310654, dist_loss: 0.6515862345695496
recon_loss: 0.027756106108427048, dist_loss: 0.7443327903747559
recon_loss: 0.027756351977586746, dist_loss: 0.5143400430679321
recon_loss: 0.027757029980421066, dist_loss: 0.7780534625053406
recon_loss: 0.0277557373046875, dist_loss: 0.8749502897262573
recon_loss: 0.027757136151194572, dist_loss: 0.5612584948539734
recon_loss: 0.027754835784435272, dist_loss: 0.5824634432792664
recon_loss: 0.02775457873940468, dist_loss: 0.5640120506286621
recon_loss: 0.027753038331866264, dist_loss: 0.5253324508666992
recon_loss: 0.027750056236982346, dist_loss: 0.5019539594650269
recon_loss: 0.027749190106987953, dist_loss: 0.6011667251586914
recon_loss: 0.027747459709644318, dist_loss: 0.7995530962944031
recon_loss: 0.027747727930545807, dist_loss: 0.44340214133262634
recon_loss: 0.02774779312312603, dist_loss: 0.6491400003433228
recon_loss: 0.027748728170990944, dist_loss: 0.6819547414779663
recon_loss: 0.02774951234459877, dist_loss: 0.48865365982055664
recon_loss: 0.027749184519052505, dist_loss: 0.5877580642700195
recon_loss: 0.027749577537178993, dist_loss: 0.8038706183433533
recon_loss: 0.02774975635111332, dist_loss: 0.5804932117462158
recon_loss: 0.02774905227124691, dist_loss: 0.9168072938919067
recon_loss: 0.02774941548705101, dist_loss: 0.3324459493160248
recon_loss: 0.027748147025704384, dist_loss: 0.8696497082710266
recon_loss: 0.027748459950089455, dist_loss: 0.37592047452926636
recon_loss: 0.027747340500354767, dist_loss: 0.6644835472106934
recon_loss: 0.027747593820095062, dist_loss: 0.7209385633468628
recon_loss: 0.027748173102736473, dist_loss: 0.9545415043830872
recon_loss: 0.027748050168156624, dist_loss: 0.2905363142490387
recon_loss: 0.027749016880989075, dist_loss: 0.3218736946582794
recon_loss: 0.027748597785830498, dist_loss: 0.6284041404724121
recon_loss: 0.02774885483086109, dist_loss: 0.4836079776287079
recon_loss: 0.02774857170879841, dist_loss: 0.7332773208618164
recon_loss: 0.027748268097639084, dist_loss: 0.8370873332023621
recon_loss: 0.027748500928282738, dist_loss: 0.47332191467285156
recon_loss: 0.02774796634912491, dist_loss: 0.9106400012969971
recon_loss: 0.027747178450226784, dist_loss: 0.6063821315765381
recon_loss: 0.027747217565774918, dist_loss: 0.6270751357078552
recon_loss: 0.027746330946683884, dist_loss: 0.5526701211929321
recon_loss: 0.027746077626943588, dist_loss: 1.250826120376587
recon_loss: 0.02774522267282009, dist_loss: 1.0425806045532227
recon_loss: 0.027744784951210022, dist_loss: 0.7731210589408875
recon_loss: 0.027744902297854424, dist_loss: 0.6172897815704346
recon_loss: 0.027744954451918602, dist_loss: 0.8690640926361084
recon_loss: 0.02774534747004509, dist_loss: 0.6000862717628479
recon_loss: 0.027745980769395828, dist_loss: 0.2834760248661041
recon_loss: 0.027746492996811867, dist_loss: 0.5231751203536987
recon_loss: 0.027747243642807007, dist_loss: 1.1268582344055176
recon_loss: 0.027747860178351402, dist_loss: 0.7989991903305054
recon_loss: 0.0277476254850626, dist_loss: 0.8553147315979004
recon_loss: 0.02774752303957939, dist_loss: 0.4900640845298767
recon_loss: 0.027747076004743576, dist_loss: 0.5295924544334412
recon_loss: 0.02774692140519619, dist_loss: 0.7211989164352417
recon_loss: 0.02774643898010254, dist_loss: 0.3844737410545349
recon_loss: 0.027745848521590233, dist_loss: 0.9752457737922668
recon_loss: 0.027745625004172325, dist_loss: 0.7528131008148193
recon_loss: 0.027744781225919724, dist_loss: 0.5396267175674438
recon_loss: 0.027744317427277565, dist_loss: 0.7949928641319275
recon_loss: 0.02774396724998951, dist_loss: 0.6930242776870728
recon_loss: 0.027743397280573845, dist_loss: 0.30627378821372986
recon_loss: 0.027742523699998856, dist_loss: 0.4741218686103821
recon_loss: 0.027742207050323486, dist_loss: 0.7284179329872131
recon_loss: 0.027741987258195877, dist_loss: 0.8147011995315552
recon_loss: 0.027742162346839905, dist_loss: 0.7260445356369019
recon_loss: 0.027742207050323486, dist_loss: 1.2360517978668213
recon_loss: 0.02774183265864849, dist_loss: 0.42431384325027466
recon_loss: 0.027741819620132446, dist_loss: 0.729682981967926
recon_loss: 0.027741655707359314, dist_loss: 0.8184560537338257
recon_loss: 0.027742059901356697, dist_loss: 0.5870743989944458
recon_loss: 0.02774129994213581, dist_loss: 0.6605759859085083
recon_loss: 0.02774175815284252, dist_loss: 0.5013667345046997
recon_loss: 0.02774188481271267, dist_loss: 0.48281002044677734
recon_loss: 0.027742037549614906, dist_loss: 0.5592610239982605
recon_loss: 0.027742207050323486, dist_loss: 0.5032590627670288
recon_loss: 0.02774239331483841, dist_loss: 0.9776970148086548
recon_loss: 0.027742452919483185, dist_loss: 0.6224581003189087
recon_loss: 0.02774219959974289, dist_loss: 0.6202448606491089
recon_loss: 0.027741845697164536, dist_loss: 0.7717807292938232
recon_loss: 0.027741016820073128, dist_loss: 0.32797783613204956
recon_loss: 0.027741169556975365, dist_loss: 0.8951362371444702
recon_loss: 0.027740713208913803, dist_loss: 0.4311659038066864
recon_loss: 0.0277405995875597, dist_loss: 0.7368953227996826
recon_loss: 0.027741018682718277, dist_loss: 0.8984876871109009
recon_loss: 0.02774016372859478, dist_loss: 0.8127635717391968
recon_loss: 0.027741216123104095, dist_loss: 0.641832709312439
recon_loss: 0.027739884331822395, dist_loss: 1.1381560564041138
recon_loss: 0.027740569785237312, dist_loss: 0.8159787654876709
recon_loss: 0.02774016372859478, dist_loss: 0.49914848804473877
recon_loss: 0.027739128097891808, dist_loss: 0.7898186445236206
recon_loss: 0.027738971635699272, dist_loss: 0.6308107972145081
recon_loss: 0.027738777920603752, dist_loss: 0.301983118057251
recon_loss: 0.02773858979344368, dist_loss: 0.3679155707359314
recon_loss: 0.027738913893699646, dist_loss: 0.689910888671875
recon_loss: 0.02773895673453808, dist_loss: 0.6158931255340576
recon_loss: 0.027739934623241425, dist_loss: 0.8042125701904297
recon_loss: 0.0277410876005888, dist_loss: 0.4029708802700043
recon_loss: 0.02774212881922722, dist_loss: 0.4493217468261719
recon_loss: 0.02774295024573803, dist_loss: 0.3803139626979828
recon_loss: 0.02774377167224884, dist_loss: 0.9907470345497131
recon_loss: 0.02774466574192047, dist_loss: 0.9679020643234253
recon_loss: 0.027744902297854424, dist_loss: 0.43904751539230347
recon_loss: 0.02774430811405182, dist_loss: 1.3369570970535278
recon_loss: 0.0277445986866951, dist_loss: 0.5050252676010132
recon_loss: 0.027745215222239494, dist_loss: 0.7829556465148926
Pre-training Epoch 90:  71%|███████▏  | 262/367 [00:01<00:00, 162.63it/s]Pre-training Epoch 90:  76%|███████▌  | 279/367 [00:01<00:00, 159.75it/s]Pre-training Epoch 90:  81%|████████  | 296/367 [00:01<00:00, 156.95it/s]Pre-training Epoch 90:  85%|████████▌ | 312/367 [00:01<00:00, 155.84it/s]Pre-training Epoch 90:  89%|████████▉ | 328/367 [00:02<00:00, 154.99it/s]Pre-training Epoch 90:  94%|█████████▎| 344/367 [00:02<00:00, 154.36it/s]Pre-training Epoch 90:  98%|█████████▊| 360/367 [00:02<00:00, 153.87it/s]Pre-training Epoch 90: 100%|██████████| 367/367 [00:02<00:00, 162.20it/s]
recon_loss: 0.027744170278310776, dist_loss: 0.6579063534736633
recon_loss: 0.02774396911263466, dist_loss: 0.5005547404289246
recon_loss: 0.027743032202124596, dist_loss: 0.694015622138977
recon_loss: 0.027742009609937668, dist_loss: 0.43425312638282776
recon_loss: 0.02774105593562126, dist_loss: 0.6132736206054688
recon_loss: 0.02774045616388321, dist_loss: 0.9531944990158081
recon_loss: 0.02773979678750038, dist_loss: 1.2886813879013062
recon_loss: 0.02773960493505001, dist_loss: 0.7595590949058533
recon_loss: 0.0277389083057642, dist_loss: 0.36302995681762695
recon_loss: 0.027738604694604874, dist_loss: 0.7386910915374756
recon_loss: 0.02773856185376644, dist_loss: 0.5659742951393127
recon_loss: 0.02773875556886196, dist_loss: 0.4895804226398468
recon_loss: 0.02773967757821083, dist_loss: 0.6310715079307556
recon_loss: 0.027740439400076866, dist_loss: 0.4765949845314026
recon_loss: 0.027741791680455208, dist_loss: 0.6478523015975952
recon_loss: 0.02774209715425968, dist_loss: 0.8081066012382507
recon_loss: 0.02774340659379959, dist_loss: 0.6278104782104492
recon_loss: 0.0277426615357399, dist_loss: 0.49262136220932007
recon_loss: 0.02774372696876526, dist_loss: 0.6755256652832031
recon_loss: 0.027744188904762268, dist_loss: 0.6212408542633057
recon_loss: 0.027744771912693977, dist_loss: 0.8902230262756348
recon_loss: 0.027746370062232018, dist_loss: 0.6460846662521362
recon_loss: 0.02774534747004509, dist_loss: 0.6572210788726807
recon_loss: 0.027743060141801834, dist_loss: 0.9481836557388306
recon_loss: 0.027743050828576088, dist_loss: 0.5564690828323364
recon_loss: 0.027741383761167526, dist_loss: 0.6583131551742554
recon_loss: 0.027741048485040665, dist_loss: 0.5321372747421265
recon_loss: 0.027740107849240303, dist_loss: 0.7811883687973022
recon_loss: 0.027739267796278, dist_loss: 0.8726460337638855
recon_loss: 0.027739059180021286, dist_loss: 0.7393248081207275
recon_loss: 0.027738459408283234, dist_loss: 0.5694758296012878
recon_loss: 0.027738455682992935, dist_loss: 0.8146945238113403
recon_loss: 0.027737941592931747, dist_loss: 0.5586082339286804
recon_loss: 0.027737373486161232, dist_loss: 0.46535545587539673
recon_loss: 0.027738025411963463, dist_loss: 0.3975556492805481
recon_loss: 0.027738584205508232, dist_loss: 0.8369994759559631
recon_loss: 0.027740422636270523, dist_loss: 0.4069177508354187
recon_loss: 0.027742017060518265, dist_loss: 0.7755270004272461
recon_loss: 0.027742527425289154, dist_loss: 0.5703750848770142
recon_loss: 0.027744056656956673, dist_loss: 0.6528297662734985
recon_loss: 0.027744749560952187, dist_loss: 0.5864039659500122
recon_loss: 0.02774558775126934, dist_loss: 0.8156598806381226
recon_loss: 0.027747655287384987, dist_loss: 0.4814659059047699
recon_loss: 0.02774946764111519, dist_loss: 0.47833898663520813
recon_loss: 0.027750661596655846, dist_loss: 0.5625782608985901
recon_loss: 0.027750164270401, dist_loss: 0.6931933164596558
recon_loss: 0.027748679742217064, dist_loss: 0.39649492502212524
recon_loss: 0.02774820849299431, dist_loss: 0.6329468488693237
recon_loss: 0.02774602733552456, dist_loss: 0.4451894760131836
recon_loss: 0.027744796127080917, dist_loss: 0.9146429300308228
recon_loss: 0.027742693200707436, dist_loss: 0.47936609387397766
recon_loss: 0.027740854769945145, dist_loss: 1.0231990814208984
recon_loss: 0.027739571407437325, dist_loss: 0.5693708062171936
recon_loss: 0.027738044038414955, dist_loss: 0.2843286991119385
recon_loss: 0.027737870812416077, dist_loss: 0.614997148513794
recon_loss: 0.027737556025385857, dist_loss: 0.985507071018219
recon_loss: 0.027738001197576523, dist_loss: 0.6538074016571045
recon_loss: 0.027738945558667183, dist_loss: 0.9091190695762634
recon_loss: 0.027740390971302986, dist_loss: 0.5102031230926514
recon_loss: 0.027741260826587677, dist_loss: 0.40303662419319153
recon_loss: 0.02774209715425968, dist_loss: 0.40597036480903625
recon_loss: 0.027742916718125343, dist_loss: 0.5643497109413147
recon_loss: 0.027743518352508545, dist_loss: 0.5552589893341064
recon_loss: 0.027743427082896233, dist_loss: 0.5934209823608398
recon_loss: 0.027742700651288033, dist_loss: 0.9654969573020935
recon_loss: 0.027741311118006706, dist_loss: 0.6079767346382141
recon_loss: 0.027740132063627243, dist_loss: 0.7117964029312134
recon_loss: 0.027739115059375763, dist_loss: 0.31989777088165283
recon_loss: 0.027737978845834732, dist_loss: 0.8034793138504028
recon_loss: 0.027736835181713104, dist_loss: 0.9084660410881042
recon_loss: 0.027735818177461624, dist_loss: 0.9478250741958618
recon_loss: 0.027735499665141106, dist_loss: 0.853821873664856
recon_loss: 0.027734749019145966, dist_loss: 0.6751102209091187
recon_loss: 0.027734478935599327, dist_loss: 0.5438961386680603
recon_loss: 0.027735328301787376, dist_loss: 0.551247239112854
recon_loss: 0.027734901756048203, dist_loss: 0.6632307171821594
recon_loss: 0.027735717594623566, dist_loss: 0.7512267827987671
recon_loss: 0.02773544006049633, dist_loss: 1.085272192955017
recon_loss: 0.027734972536563873, dist_loss: 0.5802326202392578
recon_loss: 0.0277352724224329, dist_loss: 0.6829260587692261
recon_loss: 0.027734002098441124, dist_loss: 0.7482258081436157
recon_loss: 0.027734210714697838, dist_loss: 0.444316029548645
recon_loss: 0.02773367427289486, dist_loss: 0.9273970723152161
recon_loss: 0.027734259143471718, dist_loss: 1.1244566440582275
recon_loss: 0.027733149006962776, dist_loss: 0.8972921371459961
recon_loss: 0.027733752503991127, dist_loss: 0.9099237322807312
recon_loss: 0.027733759954571724, dist_loss: 0.5481387376785278
recon_loss: 0.02773277834057808, dist_loss: 0.780555248260498
recon_loss: 0.027732791379094124, dist_loss: 0.8123307228088379
recon_loss: 0.02773246169090271, dist_loss: 1.0609781742095947
recon_loss: 0.027733713388442993, dist_loss: 0.6247223019599915
recon_loss: 0.027733566239476204, dist_loss: 0.5962088704109192
recon_loss: 0.027734937146306038, dist_loss: 0.33582231402397156
recon_loss: 0.027737149968743324, dist_loss: 0.5289011597633362
recon_loss: 0.027737220749258995, dist_loss: 0.7003782987594604
recon_loss: 0.027737723663449287, dist_loss: 0.6624159812927246
recon_loss: 0.027739109471440315, dist_loss: 0.4766138195991516
recon_loss: 0.027737798169255257, dist_loss: 0.49808451533317566
recon_loss: 0.02773856185376644, dist_loss: 0.5893235206604004
recon_loss: 0.02773698978126049, dist_loss: 0.5463698506355286
recon_loss: 0.027737097814679146, dist_loss: 0.3074781000614166
recon_loss: 0.027737213298678398, dist_loss: 0.6971356868743896
recon_loss: 0.02773643098771572, dist_loss: 0.4029121994972229
recon_loss: 0.027737069875001907, dist_loss: 0.37855443358421326
recon_loss: 0.0277345422655344, dist_loss: 0.5679658651351929
recon_loss: 0.02773681841790676, dist_loss: 1.0592613220214844
recon_loss: 0.027735117822885513, dist_loss: 0.3472128212451935
recon_loss: 0.02773476019501686, dist_loss: 0.6833351254463196
recon_loss: 0.027736680582165718, dist_loss: 0.8644364476203918
recon_loss: 0.027733992785215378, dist_loss: 0.4820590317249298
recon_loss: 0.027736743912100792, dist_loss: 1.6024353504180908
Pre-train Epoch: 90
Train - Total Loss: 0.0936, Recon Loss: 0.0277, Dist Loss: 0.6581, l1 regularization: 0.0000
Val - Total Loss: 0.0980, Recon Loss: 0.0277, Dist Loss: 0.7025, l1 regularization: 0.0000
Pre-training Epoch 91:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 91:   4%|▍         | 15/367 [00:00<00:02, 148.87it/s]Pre-training Epoch 91:   8%|▊         | 30/367 [00:00<00:02, 142.73it/s]Pre-training Epoch 91:  13%|█▎        | 46/367 [00:00<00:02, 149.13it/s]Pre-training Epoch 91:  17%|█▋        | 62/367 [00:00<00:02, 152.25it/s]Pre-training Epoch 91:  21%|██▏       | 78/367 [00:00<00:01, 154.01it/s]Pre-training Epoch 91:  26%|██▌       | 94/367 [00:00<00:01, 154.92it/s]Pre-training Epoch 91:  30%|██▉       | 110/367 [00:00<00:01, 155.48it/s]Pre-training Epoch 91:  34%|███▍      | 126/367 [00:00<00:01, 154.86it/s]recon_loss: 0.027736276388168335, dist_loss: 0.7454730868339539
recon_loss: 0.027733534574508667, dist_loss: 0.9681559801101685
recon_loss: 0.02773539163172245, dist_loss: 0.90752112865448
recon_loss: 0.027732837945222855, dist_loss: 0.7811344265937805
recon_loss: 0.027734490111470222, dist_loss: 0.667261004447937
recon_loss: 0.027734078466892242, dist_loss: 0.7032712697982788
recon_loss: 0.027733992785215378, dist_loss: 0.5180550813674927
recon_loss: 0.02773405984044075, dist_loss: 0.4961968660354614
recon_loss: 0.0277328509837389, dist_loss: 1.607035517692566
recon_loss: 0.02773500792682171, dist_loss: 0.4970831871032715
recon_loss: 0.02773313783109188, dist_loss: 0.8684225082397461
recon_loss: 0.02773510292172432, dist_loss: 0.5583417415618896
recon_loss: 0.027734750881791115, dist_loss: 0.44933509826660156
recon_loss: 0.027733324095606804, dist_loss: 0.30135947465896606
recon_loss: 0.027734948322176933, dist_loss: 0.548786997795105
recon_loss: 0.02773289568722248, dist_loss: 0.8157079815864563
recon_loss: 0.027734126895666122, dist_loss: 0.5760020017623901
recon_loss: 0.027732333168387413, dist_loss: 0.29220616817474365
recon_loss: 0.027732234448194504, dist_loss: 0.6343220472335815
recon_loss: 0.02773241139948368, dist_loss: 0.25630873441696167
recon_loss: 0.027731768786907196, dist_loss: 1.0699622631072998
recon_loss: 0.027734041213989258, dist_loss: 0.5833694934844971
recon_loss: 0.027732815593481064, dist_loss: 0.7094518542289734
recon_loss: 0.02773367054760456, dist_loss: 0.4860267639160156
recon_loss: 0.027734294533729553, dist_loss: 0.6946371793746948
recon_loss: 0.027732281014323235, dist_loss: 0.3576575517654419
recon_loss: 0.027733301743865013, dist_loss: 0.7341092824935913
recon_loss: 0.027732787653803825, dist_loss: 0.5328371524810791
recon_loss: 0.027732068672776222, dist_loss: 0.5316729545593262
recon_loss: 0.02773335762321949, dist_loss: 0.36156967282295227
recon_loss: 0.02773234061896801, dist_loss: 0.6502672433853149
recon_loss: 0.02773262746632099, dist_loss: 0.9007562398910522
recon_loss: 0.027732186019420624, dist_loss: 0.45973557233810425
recon_loss: 0.027731692418456078, dist_loss: 0.39763763546943665
recon_loss: 0.02773200534284115, dist_loss: 0.5775637626647949
recon_loss: 0.0277310311794281, dist_loss: 0.47158515453338623
recon_loss: 0.027731608599424362, dist_loss: 0.5879002213478088
recon_loss: 0.027730628848075867, dist_loss: 0.5781517624855042
recon_loss: 0.02773153968155384, dist_loss: 0.7452627420425415
recon_loss: 0.027731258422136307, dist_loss: 0.5802881717681885
recon_loss: 0.02773074246942997, dist_loss: 0.6329933404922485
recon_loss: 0.02773226797580719, dist_loss: 0.4080609381198883
recon_loss: 0.027732476592063904, dist_loss: 0.7842511534690857
recon_loss: 0.027734000235795975, dist_loss: 0.4167807698249817
recon_loss: 0.027734573930501938, dist_loss: 0.6147528886795044
recon_loss: 0.02773468755185604, dist_loss: 0.5676889419555664
recon_loss: 0.027735471725463867, dist_loss: 0.3914669156074524
recon_loss: 0.027735209092497826, dist_loss: 0.2729759216308594
recon_loss: 0.027735570445656776, dist_loss: 0.6514362096786499
recon_loss: 0.027734680101275444, dist_loss: 0.4150751829147339
recon_loss: 0.027734005823731422, dist_loss: 0.6466560363769531
recon_loss: 0.027733424678444862, dist_loss: 0.40035751461982727
recon_loss: 0.027732329443097115, dist_loss: 0.6051297783851624
recon_loss: 0.027731401845812798, dist_loss: 0.7664263248443604
recon_loss: 0.027730664238333702, dist_loss: 0.4993646740913391
recon_loss: 0.02773020975291729, dist_loss: 0.5611600875854492
recon_loss: 0.027730049565434456, dist_loss: 0.48096171021461487
recon_loss: 0.027729885652661324, dist_loss: 0.49647098779678345
recon_loss: 0.027729732915759087, dist_loss: 0.5880262851715088
recon_loss: 0.027729589492082596, dist_loss: 0.5547083020210266
recon_loss: 0.02772996388375759, dist_loss: 0.45698052644729614
recon_loss: 0.0277306716889143, dist_loss: 0.595138430595398
recon_loss: 0.027731791138648987, dist_loss: 0.837826132774353
recon_loss: 0.02773256041109562, dist_loss: 0.45363491773605347
recon_loss: 0.02773263119161129, dist_loss: 0.8339963555335999
recon_loss: 0.02773190289735794, dist_loss: 0.4566257894039154
recon_loss: 0.027730874717235565, dist_loss: 0.592876672744751
recon_loss: 0.02773045003414154, dist_loss: 0.4728206396102905
recon_loss: 0.02772936224937439, dist_loss: 0.8808419704437256
recon_loss: 0.027728356420993805, dist_loss: 0.5394232273101807
recon_loss: 0.027728678658604622, dist_loss: 0.4558037519454956
recon_loss: 0.027729203924536705, dist_loss: 0.8809161186218262
recon_loss: 0.027729053050279617, dist_loss: 0.34696799516677856
recon_loss: 0.027729347348213196, dist_loss: 0.5019451379776001
recon_loss: 0.027729686349630356, dist_loss: 0.674088180065155
recon_loss: 0.027729995548725128, dist_loss: 0.5736080408096313
recon_loss: 0.027730533853173256, dist_loss: 0.4736948609352112
recon_loss: 0.027730315923690796, dist_loss: 0.571679949760437
recon_loss: 0.02772982232272625, dist_loss: 0.856389045715332
recon_loss: 0.027729127556085587, dist_loss: 1.109734058380127
recon_loss: 0.027729175984859467, dist_loss: 0.5823268890380859
recon_loss: 0.02772873267531395, dist_loss: 0.7564990520477295
recon_loss: 0.027727792039513588, dist_loss: 0.807371973991394
recon_loss: 0.027727263048291206, dist_loss: 0.5812839269638062
recon_loss: 0.02772633358836174, dist_loss: 0.8038855791091919
recon_loss: 0.027725713327527046, dist_loss: 0.5380567312240601
recon_loss: 0.027725407853722572, dist_loss: 0.38239747285842896
recon_loss: 0.027725234627723694, dist_loss: 0.5813798308372498
recon_loss: 0.02772529236972332, dist_loss: 0.6894966959953308
recon_loss: 0.0277253445237875, dist_loss: 0.6889396905899048
recon_loss: 0.027725590392947197, dist_loss: 0.718573808670044
recon_loss: 0.02772589772939682, dist_loss: 0.8235632181167603
recon_loss: 0.027725763618946075, dist_loss: 0.9344319701194763
recon_loss: 0.027725154533982277, dist_loss: 0.5364760160446167
recon_loss: 0.027725009247660637, dist_loss: 0.6697254776954651
recon_loss: 0.027724701911211014, dist_loss: 0.41414907574653625
recon_loss: 0.027725113555788994, dist_loss: 0.6776519417762756
recon_loss: 0.02772565744817257, dist_loss: 0.5690302848815918
recon_loss: 0.02772532030940056, dist_loss: 0.5653394460678101
recon_loss: 0.027725834399461746, dist_loss: 0.6702998876571655
recon_loss: 0.027725331485271454, dist_loss: 1.0104498863220215
recon_loss: 0.02772449515759945, dist_loss: 0.4610968232154846
recon_loss: 0.0277244970202446, dist_loss: 0.6845256090164185
recon_loss: 0.02772405371069908, dist_loss: 0.6814686059951782
recon_loss: 0.027725549414753914, dist_loss: 0.4957708418369293
recon_loss: 0.027726801112294197, dist_loss: 0.5388085842132568
recon_loss: 0.02772873267531395, dist_loss: 0.577932596206665
recon_loss: 0.02772952988743782, dist_loss: 0.47576698660850525
recon_loss: 0.02772768959403038, dist_loss: 0.9424619674682617
recon_loss: 0.027727672830224037, dist_loss: 0.7382000088691711
recon_loss: 0.02772662043571472, dist_loss: 1.126983880996704
recon_loss: 0.027726631611585617, dist_loss: 0.35017409920692444
recon_loss: 0.02772725373506546, dist_loss: 0.9181009531021118
recon_loss: 0.027725448831915855, dist_loss: 0.6254358887672424
recon_loss: 0.027726992964744568, dist_loss: 0.3569019138813019
recon_loss: 0.027725866064429283, dist_loss: 0.6245037317276001
recon_loss: 0.02772512473165989, dist_loss: 0.5379841327667236
recon_loss: 0.027726121246814728, dist_loss: 0.8655977249145508
recon_loss: 0.027725128456950188, dist_loss: 0.553429365158081
recon_loss: 0.027725284919142723, dist_loss: 0.8873723745346069
recon_loss: 0.027725450694561005, dist_loss: 0.4187176823616028
recon_loss: 0.027724197134375572, dist_loss: 0.595468282699585
recon_loss: 0.027724288403987885, dist_loss: 0.7147841453552246
recon_loss: 0.027723249047994614, dist_loss: 0.813102126121521
recon_loss: 0.0277230367064476, dist_loss: 0.3966667652130127
recon_loss: 0.027722910046577454, dist_loss: 1.0136635303497314
recon_loss: 0.027722783386707306, dist_loss: 0.6404110789299011
recon_loss: 0.0277229156345129, dist_loss: 0.5756887197494507
Pre-training Epoch 91:  39%|███▊      | 142/367 [00:00<00:01, 153.86it/s]Pre-training Epoch 91:  43%|████▎     | 158/367 [00:01<00:01, 152.86it/s]Pre-training Epoch 91:  47%|████▋     | 174/367 [00:01<00:01, 154.18it/s]Pre-training Epoch 91:  52%|█████▏    | 190/367 [00:01<00:01, 152.30it/s]Pre-training Epoch 91:  56%|█████▌    | 206/367 [00:01<00:01, 152.64it/s]Pre-training Epoch 91:  60%|██████    | 222/367 [00:01<00:00, 153.49it/s]Pre-training Epoch 91:  65%|██████▍   | 238/367 [00:01<00:00, 154.27it/s]Pre-training Epoch 91:  69%|██████▉   | 254/367 [00:01<00:00, 154.88it/s]recon_loss: 0.027722971513867378, dist_loss: 1.2547099590301514
recon_loss: 0.027723398059606552, dist_loss: 0.996859073638916
recon_loss: 0.027724387124180794, dist_loss: 0.5550370812416077
recon_loss: 0.027725588530302048, dist_loss: 0.8340001702308655
recon_loss: 0.027726473286747932, dist_loss: 0.6540073752403259
recon_loss: 0.02772790938615799, dist_loss: 0.48878738284111023
recon_loss: 0.027729548513889313, dist_loss: 0.4652041792869568
recon_loss: 0.027730420231819153, dist_loss: 0.7511136531829834
recon_loss: 0.027730777859687805, dist_loss: 0.45871585607528687
recon_loss: 0.027730721980333328, dist_loss: 0.5144577026367188
recon_loss: 0.02772979438304901, dist_loss: 0.9451613426208496
recon_loss: 0.027729226276278496, dist_loss: 0.49727314710617065
recon_loss: 0.027728376910090446, dist_loss: 0.6350017786026001
recon_loss: 0.02772819623351097, dist_loss: 0.8293878436088562
recon_loss: 0.027726339176297188, dist_loss: 0.4684760868549347
recon_loss: 0.02772418037056923, dist_loss: 0.5297207832336426
recon_loss: 0.027724996209144592, dist_loss: 0.5162574052810669
recon_loss: 0.02772310934960842, dist_loss: 1.0178310871124268
recon_loss: 0.027723701670765877, dist_loss: 0.4966447055339813
recon_loss: 0.027722351253032684, dist_loss: 0.7347646951675415
recon_loss: 0.027723435312509537, dist_loss: 0.6431740522384644
recon_loss: 0.02772383764386177, dist_loss: 0.5459338426589966
recon_loss: 0.02772236242890358, dist_loss: 1.2043694257736206
recon_loss: 0.02772444859147072, dist_loss: 0.392240434885025
recon_loss: 0.02772272191941738, dist_loss: 0.7867965698242188
recon_loss: 0.027723805978894234, dist_loss: 0.8607652187347412
recon_loss: 0.027722520753741264, dist_loss: 0.5365958213806152
recon_loss: 0.027722133323550224, dist_loss: 0.6260727643966675
recon_loss: 0.027721896767616272, dist_loss: 0.5304516553878784
recon_loss: 0.027721207588911057, dist_loss: 0.6739128828048706
recon_loss: 0.02772117406129837, dist_loss: 0.5131641626358032
recon_loss: 0.027720816433429718, dist_loss: 0.3509289622306824
recon_loss: 0.02772141806781292, dist_loss: 0.5272367596626282
recon_loss: 0.02772136963903904, dist_loss: 0.6241699457168579
recon_loss: 0.027721526101231575, dist_loss: 0.48214638233184814
recon_loss: 0.027722347527742386, dist_loss: 0.35353732109069824
recon_loss: 0.02772158943116665, dist_loss: 0.6560606956481934
recon_loss: 0.027720745652914047, dist_loss: 0.4688680171966553
recon_loss: 0.027720412239432335, dist_loss: 0.8701411485671997
recon_loss: 0.027719933539628983, dist_loss: 0.7668467164039612
recon_loss: 0.02771999128162861, dist_loss: 0.7041002511978149
recon_loss: 0.027719849720597267, dist_loss: 0.5257842540740967
recon_loss: 0.027719713747501373, dist_loss: 0.8449789881706238
recon_loss: 0.027719862759113312, dist_loss: 0.3450040817260742
recon_loss: 0.027719678357243538, dist_loss: 1.0190900564193726
recon_loss: 0.02771960012614727, dist_loss: 0.6916021108627319
recon_loss: 0.027719324454665184, dist_loss: 0.9652997255325317
recon_loss: 0.02771914191544056, dist_loss: 1.2529897689819336
recon_loss: 0.02771909162402153, dist_loss: 1.0691297054290771
recon_loss: 0.02771907113492489, dist_loss: 0.678479015827179
recon_loss: 0.027718886733055115, dist_loss: 0.5148398876190186
recon_loss: 0.027718909084796906, dist_loss: 1.1000685691833496
recon_loss: 0.02771889790892601, dist_loss: 0.5292620658874512
recon_loss: 0.027718843892216682, dist_loss: 0.7639636993408203
recon_loss: 0.027719127014279366, dist_loss: 0.5565309524536133
recon_loss: 0.02771874889731407, dist_loss: 0.6729369163513184
recon_loss: 0.027718711644411087, dist_loss: 0.42549845576286316
recon_loss: 0.027719169855117798, dist_loss: 0.5027399063110352
recon_loss: 0.027719974517822266, dist_loss: 0.7500489354133606
recon_loss: 0.027720389887690544, dist_loss: 0.981121301651001
recon_loss: 0.027720287442207336, dist_loss: 0.3820923864841461
recon_loss: 0.027719493955373764, dist_loss: 0.698623538017273
recon_loss: 0.02771919034421444, dist_loss: 0.7478963136672974
recon_loss: 0.02771911211311817, dist_loss: 0.6400700211524963
recon_loss: 0.02771882340312004, dist_loss: 0.36707550287246704
recon_loss: 0.027718767523765564, dist_loss: 0.4311503469944
recon_loss: 0.027718378230929375, dist_loss: 0.7745716571807861
recon_loss: 0.02771812677383423, dist_loss: 0.7627773284912109
recon_loss: 0.02771786041557789, dist_loss: 0.6760146617889404
recon_loss: 0.027717633172869682, dist_loss: 0.8288019895553589
recon_loss: 0.02771768718957901, dist_loss: 0.7768331170082092
recon_loss: 0.02771778590977192, dist_loss: 0.7630862593650818
recon_loss: 0.02771790698170662, dist_loss: 0.7468829154968262
recon_loss: 0.027718795463442802, dist_loss: 0.8529422879219055
recon_loss: 0.02771882340312004, dist_loss: 0.1993163377046585
recon_loss: 0.02771935984492302, dist_loss: 0.7232222557067871
recon_loss: 0.027719812467694283, dist_loss: 0.8444604873657227
recon_loss: 0.027720153331756592, dist_loss: 0.5450986623764038
recon_loss: 0.02772006392478943, dist_loss: 1.0088131427764893
recon_loss: 0.027719853445887566, dist_loss: 0.8958210945129395
recon_loss: 0.02771986462175846, dist_loss: 0.6441769003868103
recon_loss: 0.027719706296920776, dist_loss: 0.9936538934707642
recon_loss: 0.0277191624045372, dist_loss: 0.9258923530578613
recon_loss: 0.027719205245375633, dist_loss: 0.7569947838783264
recon_loss: 0.0277188029140234, dist_loss: 0.7198588848114014
recon_loss: 0.02771930582821369, dist_loss: 0.47109997272491455
recon_loss: 0.027719546109437943, dist_loss: 1.5965609550476074
recon_loss: 0.02772248536348343, dist_loss: 0.5362133383750916
recon_loss: 0.027723195031285286, dist_loss: 0.6821465492248535
recon_loss: 0.02772441878914833, dist_loss: 0.38279202580451965
recon_loss: 0.027724899351596832, dist_loss: 0.5198887586593628
recon_loss: 0.027724802494049072, dist_loss: 1.0503453016281128
recon_loss: 0.0277246180921793, dist_loss: 0.6422375440597534
recon_loss: 0.02772357314825058, dist_loss: 0.4305109679698944
recon_loss: 0.027723250910639763, dist_loss: 0.49010515213012695
recon_loss: 0.02772313728928566, dist_loss: 0.4060688018798828
recon_loss: 0.027722982689738274, dist_loss: 0.9158637523651123
recon_loss: 0.027722284197807312, dist_loss: 0.6922489404678345
recon_loss: 0.02772156149148941, dist_loss: 0.3739173710346222
recon_loss: 0.02772054821252823, dist_loss: 0.503213107585907
recon_loss: 0.027720315381884575, dist_loss: 1.1690566539764404
recon_loss: 0.027720218524336815, dist_loss: 0.3389497697353363
recon_loss: 0.027719954028725624, dist_loss: 0.39255639910697937
recon_loss: 0.027720147743821144, dist_loss: 0.6858055591583252
recon_loss: 0.02772013656795025, dist_loss: 0.2903990149497986
recon_loss: 0.027720920741558075, dist_loss: 0.8174067735671997
recon_loss: 0.027721621096134186, dist_loss: 0.4750221371650696
recon_loss: 0.0277213416993618, dist_loss: 0.6386696100234985
recon_loss: 0.02772139199078083, dist_loss: 0.6151105761528015
recon_loss: 0.027720501646399498, dist_loss: 0.9383000135421753
recon_loss: 0.02772001549601555, dist_loss: 0.31226325035095215
recon_loss: 0.027719253674149513, dist_loss: 1.1457414627075195
recon_loss: 0.027718622237443924, dist_loss: 0.45574885606765747
recon_loss: 0.02771822363138199, dist_loss: 0.5258259177207947
recon_loss: 0.02771783247590065, dist_loss: 0.5599108934402466
recon_loss: 0.02771742269396782, dist_loss: 0.8668180704116821
recon_loss: 0.027717122808098793, dist_loss: 0.813450813293457
recon_loss: 0.027716828510165215, dist_loss: 0.9199835658073425
recon_loss: 0.027716541662812233, dist_loss: 0.8583788275718689
recon_loss: 0.02771659381687641, dist_loss: 0.5867306590080261
recon_loss: 0.027716968208551407, dist_loss: 0.655536413192749
recon_loss: 0.027717068791389465, dist_loss: 0.33397960662841797
recon_loss: 0.027717487886548042, dist_loss: 0.8324767351150513
recon_loss: 0.027717210352420807, dist_loss: 0.9593024849891663
recon_loss: 0.027716901153326035, dist_loss: 0.7322729229927063
recon_loss: 0.02771647647023201, dist_loss: 0.5587987899780273
recon_loss: 0.027715809643268585, dist_loss: 0.5189339518547058
recon_loss: 0.027715520933270454, dist_loss: 0.6343648433685303
Pre-training Epoch 91:  74%|███████▎  | 270/367 [00:01<00:00, 155.16it/s]Pre-training Epoch 91:  78%|███████▊  | 286/367 [00:01<00:00, 153.07it/s]Pre-training Epoch 91:  82%|████████▏ | 302/367 [00:01<00:00, 151.39it/s]Pre-training Epoch 91:  87%|████████▋ | 318/367 [00:02<00:00, 149.84it/s]Pre-training Epoch 91:  91%|█████████ | 334/367 [00:02<00:00, 150.53it/s]Pre-training Epoch 91:  95%|█████████▌| 350/367 [00:02<00:00, 149.28it/s]Pre-training Epoch 91: 100%|█████████▉| 366/367 [00:02<00:00, 151.70it/s]Pre-training Epoch 91: 100%|██████████| 367/367 [00:02<00:00, 152.40it/s]
recon_loss: 0.027714550495147705, dist_loss: 0.9012249708175659
recon_loss: 0.027714546769857407, dist_loss: 0.8338214755058289
recon_loss: 0.027714727446436882, dist_loss: 0.5938926935195923
recon_loss: 0.027713965624570847, dist_loss: 1.1874247789382935
recon_loss: 0.027714407071471214, dist_loss: 0.5983689427375793
recon_loss: 0.0277142021805048, dist_loss: 1.049748420715332
recon_loss: 0.02771485038101673, dist_loss: 0.5286967754364014
recon_loss: 0.02771456353366375, dist_loss: 0.5824090838432312
recon_loss: 0.027714412659406662, dist_loss: 0.8429205417633057
recon_loss: 0.027714574709534645, dist_loss: 0.577301561832428
recon_loss: 0.027714040130376816, dist_loss: 0.5478724837303162
recon_loss: 0.02771412953734398, dist_loss: 0.5402081608772278
recon_loss: 0.02771369367837906, dist_loss: 0.5731115341186523
recon_loss: 0.027712924405932426, dist_loss: 0.7125965356826782
recon_loss: 0.027712468057870865, dist_loss: 0.3837123513221741
recon_loss: 0.027712056413292885, dist_loss: 0.6184788346290588
recon_loss: 0.02771228924393654, dist_loss: 1.0791021585464478
recon_loss: 0.027713241055607796, dist_loss: 1.1009516716003418
recon_loss: 0.027714388445019722, dist_loss: 0.7206977009773254
recon_loss: 0.027715912088751793, dist_loss: 0.46744704246520996
recon_loss: 0.027716390788555145, dist_loss: 0.9669805765151978
recon_loss: 0.02771812118589878, dist_loss: 0.8540627360343933
recon_loss: 0.02771848998963833, dist_loss: 0.8796780705451965
recon_loss: 0.0277179554104805, dist_loss: 0.3469594419002533
recon_loss: 0.027716917917132378, dist_loss: 1.0823826789855957
recon_loss: 0.02771541103720665, dist_loss: 0.5309313535690308
recon_loss: 0.027714641764760017, dist_loss: 1.1313310861587524
recon_loss: 0.027713458985090256, dist_loss: 0.6878902912139893
recon_loss: 0.02771250158548355, dist_loss: 0.964821457862854
recon_loss: 0.027712684124708176, dist_loss: 0.6875028014183044
recon_loss: 0.027712862938642502, dist_loss: 0.504059910774231
recon_loss: 0.02771322801709175, dist_loss: 0.6189566850662231
recon_loss: 0.027713924646377563, dist_loss: 0.879680335521698
recon_loss: 0.027714017778635025, dist_loss: 0.7467834949493408
recon_loss: 0.027714762836694717, dist_loss: 0.34222209453582764
recon_loss: 0.027714772149920464, dist_loss: 0.5497193336486816
recon_loss: 0.027715221047401428, dist_loss: 0.5507543683052063
recon_loss: 0.02771509438753128, dist_loss: 0.5372992753982544
recon_loss: 0.02771443873643875, dist_loss: 0.7651533484458923
recon_loss: 0.027714256197214127, dist_loss: 0.6412445902824402
recon_loss: 0.027713244780898094, dist_loss: 0.5812503099441528
recon_loss: 0.027713075280189514, dist_loss: 0.6829965114593506
recon_loss: 0.027712292969226837, dist_loss: 0.7452055811882019
recon_loss: 0.027711886912584305, dist_loss: 0.8836421370506287
recon_loss: 0.027711249887943268, dist_loss: 0.7082810401916504
recon_loss: 0.02771090157330036, dist_loss: 0.43898385763168335
recon_loss: 0.027710609138011932, dist_loss: 0.5457366704940796
recon_loss: 0.027710871770977974, dist_loss: 0.4715718924999237
recon_loss: 0.027710584923624992, dist_loss: 0.4944227337837219
recon_loss: 0.02771090902388096, dist_loss: 0.8409081101417542
recon_loss: 0.0277105662971735, dist_loss: 0.9047400951385498
recon_loss: 0.027710722759366035, dist_loss: 0.49906134605407715
recon_loss: 0.02771063707768917, dist_loss: 1.018166184425354
recon_loss: 0.02771061845123768, dist_loss: 0.6153324842453003
recon_loss: 0.027710767462849617, dist_loss: 0.7444608211517334
recon_loss: 0.02771107852458954, dist_loss: 0.7869867086410522
recon_loss: 0.027711009606719017, dist_loss: 1.1462959051132202
recon_loss: 0.0277110543102026, dist_loss: 0.3871106505393982
recon_loss: 0.02771039865911007, dist_loss: 0.5966300368309021
recon_loss: 0.027710679918527603, dist_loss: 0.4892604351043701
recon_loss: 0.027710163965821266, dist_loss: 0.6416215300559998
recon_loss: 0.027710458263754845, dist_loss: 0.858910083770752
recon_loss: 0.027709929272532463, dist_loss: 0.5399730205535889
recon_loss: 0.02770986407995224, dist_loss: 0.4579627513885498
recon_loss: 0.027709638699889183, dist_loss: 0.487013578414917
recon_loss: 0.027709687128663063, dist_loss: 0.5690636038780212
recon_loss: 0.027709808200597763, dist_loss: 0.7347931861877441
recon_loss: 0.02770964987576008, dist_loss: 0.4173803925514221
recon_loss: 0.02770989201962948, dist_loss: 0.9757711887359619
recon_loss: 0.02771024964749813, dist_loss: 0.2145044356584549
recon_loss: 0.02771065942943096, dist_loss: 0.33936846256256104
recon_loss: 0.02771090157330036, dist_loss: 0.5360836386680603
recon_loss: 0.02771078422665596, dist_loss: 0.38593488931655884
recon_loss: 0.02771053835749626, dist_loss: 0.8782535195350647
recon_loss: 0.02771027572453022, dist_loss: 0.6600191593170166
recon_loss: 0.02770993858575821, dist_loss: 0.581174373626709
recon_loss: 0.027709895744919777, dist_loss: 0.9119453430175781
recon_loss: 0.0277099646627903, dist_loss: 0.428999662399292
recon_loss: 0.027710260823369026, dist_loss: 0.6032097935676575
recon_loss: 0.02771059237420559, dist_loss: 0.5137863159179688
recon_loss: 0.027711132541298866, dist_loss: 0.4124559164047241
recon_loss: 0.02771180495619774, dist_loss: 0.855292558670044
recon_loss: 0.02771127223968506, dist_loss: 0.5195645689964294
recon_loss: 0.027711542323231697, dist_loss: 0.6988499164581299
recon_loss: 0.02771158143877983, dist_loss: 0.619518518447876
recon_loss: 0.02771109901368618, dist_loss: 0.4945164620876312
recon_loss: 0.027710700407624245, dist_loss: 0.4989100694656372
recon_loss: 0.02771008014678955, dist_loss: 0.7096735239028931
recon_loss: 0.027709970250725746, dist_loss: 0.45838457345962524
recon_loss: 0.027709756046533585, dist_loss: 0.49208348989486694
recon_loss: 0.027709893882274628, dist_loss: 0.6366746425628662
recon_loss: 0.027709221467375755, dist_loss: 0.7488195896148682
recon_loss: 0.0277092307806015, dist_loss: 0.49593526124954224
recon_loss: 0.027708861976861954, dist_loss: 0.9023764133453369
recon_loss: 0.02770853415131569, dist_loss: 0.8427271246910095
recon_loss: 0.02770889736711979, dist_loss: 0.6305988430976868
recon_loss: 0.027709228917956352, dist_loss: 0.6377865076065063
recon_loss: 0.027710672467947006, dist_loss: 0.5414220094680786
recon_loss: 0.02771017700433731, dist_loss: 0.5141188502311707
recon_loss: 0.02771185338497162, dist_loss: 0.2704450190067291
recon_loss: 0.02771076001226902, dist_loss: 1.0504693984985352
recon_loss: 0.0277109332382679, dist_loss: 0.7839609384536743
recon_loss: 0.02771063707768917, dist_loss: 0.4061678647994995
recon_loss: 0.02770935744047165, dist_loss: 0.4987325072288513
recon_loss: 0.02770981751382351, dist_loss: 0.7948517203330994
recon_loss: 0.027708658948540688, dist_loss: 0.5983127355575562
recon_loss: 0.02770952321588993, dist_loss: 0.5163655877113342
recon_loss: 0.027709243819117546, dist_loss: 0.7311404347419739
recon_loss: 0.027708159759640694, dist_loss: 0.3283287286758423
recon_loss: 0.02770843543112278, dist_loss: 0.9435867071151733
recon_loss: 0.027707325294613838, dist_loss: 0.42892012000083923
Pre-training Epoch 92:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 92:   5%|▍         | 18/367 [00:00<00:02, 172.44it/s]Pre-training Epoch 92:  10%|▉         | 36/367 [00:00<00:01, 171.11it/s]Pre-training Epoch 92:  15%|█▍        | 54/367 [00:00<00:01, 162.05it/s]Pre-training Epoch 92:  19%|█▉        | 71/367 [00:00<00:01, 158.84it/s]Pre-training Epoch 92:  24%|██▎       | 87/367 [00:00<00:01, 152.50it/s]Pre-training Epoch 92:  28%|██▊       | 103/367 [00:00<00:01, 153.49it/s]Pre-training Epoch 92:  32%|███▏      | 119/367 [00:00<00:01, 153.94it/s]recon_loss: 0.02770858071744442, dist_loss: 0.5063730478286743
recon_loss: 0.02770814672112465, dist_loss: 0.4745250940322876
recon_loss: 0.027709022164344788, dist_loss: 0.4188193082809448
recon_loss: 0.027709970250725746, dist_loss: 0.5716648101806641
recon_loss: 0.027710042893886566, dist_loss: 0.81314617395401
recon_loss: 0.02771075814962387, dist_loss: 0.6033275127410889
recon_loss: 0.02771037071943283, dist_loss: 0.9020577073097229
recon_loss: 0.02771018259227276, dist_loss: 0.3817459046840668
recon_loss: 0.027709972113370895, dist_loss: 0.444786936044693
recon_loss: 0.027708908542990685, dist_loss: 1.0082733631134033
recon_loss: 0.027707967907190323, dist_loss: 0.49826541543006897
recon_loss: 0.02770731784403324, dist_loss: 0.7235075235366821
recon_loss: 0.027707815170288086, dist_loss: 0.7402650713920593
recon_loss: 0.027708400040864944, dist_loss: 0.46915769577026367
recon_loss: 0.0277093518525362, dist_loss: 0.46976238489151
recon_loss: 0.027710627764463425, dist_loss: 0.5318933129310608
recon_loss: 0.027710696682333946, dist_loss: 0.30898016691207886
recon_loss: 0.027711832895874977, dist_loss: 0.3330407738685608
recon_loss: 0.02771276980638504, dist_loss: 0.5269942283630371
recon_loss: 0.027713600546121597, dist_loss: 0.8568097352981567
recon_loss: 0.027714461088180542, dist_loss: 0.732694149017334
recon_loss: 0.027713827788829803, dist_loss: 0.5982253551483154
recon_loss: 0.02771366387605667, dist_loss: 0.5432769060134888
recon_loss: 0.027714300900697708, dist_loss: 0.42594754695892334
recon_loss: 0.02771308273077011, dist_loss: 1.1032543182373047
recon_loss: 0.027712931856513023, dist_loss: 0.5790678858757019
recon_loss: 0.0277096014469862, dist_loss: 0.43501660227775574
recon_loss: 0.027709076181054115, dist_loss: 0.6943370699882507
recon_loss: 0.027707085013389587, dist_loss: 1.082754373550415
recon_loss: 0.027708249166607857, dist_loss: 0.48271888494491577
recon_loss: 0.02770894579589367, dist_loss: 0.5351926684379578
recon_loss: 0.027709070593118668, dist_loss: 0.7992448210716248
recon_loss: 0.027711868286132812, dist_loss: 0.4466875493526459
recon_loss: 0.027711903676390648, dist_loss: 0.4571954607963562
recon_loss: 0.027712324634194374, dist_loss: 0.6885661482810974
recon_loss: 0.02771245874464512, dist_loss: 0.3253924250602722
recon_loss: 0.02771180123090744, dist_loss: 0.5431351661682129
recon_loss: 0.02771247737109661, dist_loss: 0.37680885195732117
recon_loss: 0.027710285037755966, dist_loss: 0.7563009858131409
recon_loss: 0.02770964615046978, dist_loss: 0.5468765497207642
recon_loss: 0.02770867384970188, dist_loss: 0.38497617840766907
recon_loss: 0.027706915512681007, dist_loss: 0.5909773111343384
recon_loss: 0.027708258479833603, dist_loss: 0.4256274402141571
recon_loss: 0.02770663984119892, dist_loss: 0.6369695067405701
recon_loss: 0.027706390246748924, dist_loss: 0.8747199773788452
recon_loss: 0.0277083907276392, dist_loss: 0.4377748668193817
recon_loss: 0.027707036584615707, dist_loss: 0.6640276908874512
recon_loss: 0.027709651738405228, dist_loss: 0.6006771326065063
recon_loss: 0.027708111330866814, dist_loss: 0.793149471282959
recon_loss: 0.02770824171602726, dist_loss: 0.6612576842308044
recon_loss: 0.027707764878869057, dist_loss: 0.5847026109695435
recon_loss: 0.02770671807229519, dist_loss: 0.45266568660736084
recon_loss: 0.02770669013261795, dist_loss: 0.47112101316452026
recon_loss: 0.027705848217010498, dist_loss: 0.40556472539901733
recon_loss: 0.027705684304237366, dist_loss: 0.47245049476623535
recon_loss: 0.027705594897270203, dist_loss: 0.7599818706512451
recon_loss: 0.02770385332405567, dist_loss: 0.5851295590400696
recon_loss: 0.02770480513572693, dist_loss: 0.432754784822464
recon_loss: 0.027703162282705307, dist_loss: 0.7967063188552856
recon_loss: 0.02770361304283142, dist_loss: 0.5247213244438171
recon_loss: 0.027703214436769485, dist_loss: 1.1072866916656494
recon_loss: 0.0277022123336792, dist_loss: 0.7549524903297424
recon_loss: 0.02770281583070755, dist_loss: 0.4467224180698395
recon_loss: 0.02770283631980419, dist_loss: 0.46831536293029785
recon_loss: 0.027704214677214622, dist_loss: 0.8147461414337158
recon_loss: 0.027704553678631783, dist_loss: 0.9733354449272156
recon_loss: 0.027706285938620567, dist_loss: 0.7091788053512573
recon_loss: 0.027707813307642937, dist_loss: 0.45547133684158325
recon_loss: 0.027708759531378746, dist_loss: 0.9770818948745728
recon_loss: 0.027711283415555954, dist_loss: 0.6910048723220825
recon_loss: 0.027712136507034302, dist_loss: 0.5516010522842407
recon_loss: 0.027712076902389526, dist_loss: 0.9480100870132446
recon_loss: 0.02771257422864437, dist_loss: 0.5326688885688782
recon_loss: 0.027709515765309334, dist_loss: 0.7994571924209595
recon_loss: 0.02770926058292389, dist_loss: 0.8747273683547974
recon_loss: 0.027707358822226524, dist_loss: 0.7746576070785522
recon_loss: 0.027706537395715714, dist_loss: 0.6124342679977417
recon_loss: 0.027705684304237366, dist_loss: 0.4786127805709839
recon_loss: 0.027704374864697456, dist_loss: 0.4028748869895935
recon_loss: 0.027704646810889244, dist_loss: 1.082146167755127
recon_loss: 0.0277056023478508, dist_loss: 0.6427304744720459
recon_loss: 0.027706986293196678, dist_loss: 0.7827757596969604
recon_loss: 0.027708297595381737, dist_loss: 0.3683296740055084
recon_loss: 0.027709022164344788, dist_loss: 0.3470926284790039
recon_loss: 0.02770877070724964, dist_loss: 0.5449700355529785
recon_loss: 0.027707811444997787, dist_loss: 0.5465489625930786
recon_loss: 0.02770697884261608, dist_loss: 0.43401575088500977
recon_loss: 0.027706347405910492, dist_loss: 0.45706114172935486
recon_loss: 0.027705803513526917, dist_loss: 0.5026499032974243
recon_loss: 0.027705082669854164, dist_loss: 0.504478931427002
recon_loss: 0.027703752741217613, dist_loss: 0.7993696928024292
recon_loss: 0.02770317904651165, dist_loss: 0.7277716398239136
recon_loss: 0.02770221419632435, dist_loss: 0.9477130770683289
recon_loss: 0.027702130377292633, dist_loss: 0.547646164894104
recon_loss: 0.027701953426003456, dist_loss: 0.33502286672592163
recon_loss: 0.0277018491178751, dist_loss: 0.652301549911499
recon_loss: 0.027701960876584053, dist_loss: 0.7013624906539917
recon_loss: 0.027701321989297867, dist_loss: 0.8007842302322388
recon_loss: 0.027701254934072495, dist_loss: 1.0496512651443481
recon_loss: 0.027700884267687798, dist_loss: 0.680732250213623
recon_loss: 0.027700647711753845, dist_loss: 0.7449009418487549
recon_loss: 0.027700623497366905, dist_loss: 0.7055627703666687
recon_loss: 0.027700399979948997, dist_loss: 0.4607273042201996
recon_loss: 0.027699952945113182, dist_loss: 0.7373467683792114
recon_loss: 0.027699626982212067, dist_loss: 0.406913697719574
recon_loss: 0.02769944630563259, dist_loss: 0.5987961888313293
recon_loss: 0.027699759230017662, dist_loss: 0.9056834578514099
recon_loss: 0.027699945494532585, dist_loss: 0.5483618974685669
recon_loss: 0.027700431644916534, dist_loss: 0.6906144618988037
recon_loss: 0.027700887992978096, dist_loss: 0.7397415637969971
recon_loss: 0.027701077982783318, dist_loss: 0.6262651085853577
recon_loss: 0.02770175226032734, dist_loss: 0.8037306070327759
recon_loss: 0.02770237810909748, dist_loss: 1.0748335123062134
recon_loss: 0.027703100815415382, dist_loss: 1.092771053314209
recon_loss: 0.027702733874320984, dist_loss: 0.6116859912872314
recon_loss: 0.02770223468542099, dist_loss: 0.7114042043685913
recon_loss: 0.027700798586010933, dist_loss: 1.0989744663238525
recon_loss: 0.027699599042534828, dist_loss: 0.5330734252929688
recon_loss: 0.027698658406734467, dist_loss: 0.630455493927002
recon_loss: 0.027698775753378868, dist_loss: 0.8089509606361389
recon_loss: 0.027698788791894913, dist_loss: 0.5609238743782043
recon_loss: 0.027699289843440056, dist_loss: 0.5763310194015503
recon_loss: 0.027699865400791168, dist_loss: 0.6276904940605164
recon_loss: 0.027700211852788925, dist_loss: 0.7042876482009888
recon_loss: 0.02770182117819786, dist_loss: 0.7111395001411438
recon_loss: 0.02770076133310795, dist_loss: 0.5784436464309692
recon_loss: 0.027701983228325844, dist_loss: 0.765549898147583
recon_loss: 0.027700606733560562, dist_loss: 0.5204155445098877
Pre-training Epoch 92:  37%|███▋      | 135/367 [00:00<00:01, 153.12it/s]Pre-training Epoch 92:  41%|████      | 151/367 [00:00<00:01, 152.65it/s]Pre-training Epoch 92:  46%|████▌     | 167/367 [00:01<00:01, 152.73it/s]Pre-training Epoch 92:  50%|█████     | 184/367 [00:01<00:01, 155.54it/s]Pre-training Epoch 92:  55%|█████▍    | 201/367 [00:01<00:01, 156.99it/s]Pre-training Epoch 92:  59%|█████▉    | 217/367 [00:01<00:00, 156.56it/s]Pre-training Epoch 92:  63%|██████▎   | 233/367 [00:01<00:00, 155.81it/s]Pre-training Epoch 92:  68%|██████▊   | 249/367 [00:01<00:00, 152.96it/s]recon_loss: 0.027700666338205338, dist_loss: 0.5329577326774597
recon_loss: 0.02770020067691803, dist_loss: 0.3479969799518585
recon_loss: 0.02769939973950386, dist_loss: 0.5381730794906616
recon_loss: 0.02769934944808483, dist_loss: 0.6512228846549988
recon_loss: 0.027699002996087074, dist_loss: 0.6315728425979614
recon_loss: 0.027698736637830734, dist_loss: 0.7313849925994873
recon_loss: 0.02769838646054268, dist_loss: 0.5857117176055908
recon_loss: 0.027698254212737083, dist_loss: 0.8727124929428101
recon_loss: 0.027697863057255745, dist_loss: 0.8459393382072449
recon_loss: 0.027697525918483734, dist_loss: 0.6886066198348999
recon_loss: 0.027697529643774033, dist_loss: 0.31292450428009033
recon_loss: 0.027697226032614708, dist_loss: 0.7578827142715454
recon_loss: 0.027697144076228142, dist_loss: 0.8365625739097595
recon_loss: 0.027697164565324783, dist_loss: 0.4798135757446289
recon_loss: 0.027696404606103897, dist_loss: 0.6497774720191956
recon_loss: 0.027696803212165833, dist_loss: 0.44739699363708496
recon_loss: 0.02769671380519867, dist_loss: 0.3934679627418518
recon_loss: 0.02769656293094158, dist_loss: 0.5115864276885986
recon_loss: 0.027697142213582993, dist_loss: 0.4976990222930908
recon_loss: 0.027696842327713966, dist_loss: 0.4079781174659729
recon_loss: 0.02769758738577366, dist_loss: 0.6432603597640991
recon_loss: 0.027697352692484856, dist_loss: 0.4440074563026428
recon_loss: 0.027697104960680008, dist_loss: 0.9639893770217896
recon_loss: 0.027697542682290077, dist_loss: 0.4012494683265686
recon_loss: 0.027697093784809113, dist_loss: 0.7761913537979126
recon_loss: 0.027697723358869553, dist_loss: 0.8101335167884827
recon_loss: 0.02769780158996582, dist_loss: 0.8607298731803894
recon_loss: 0.027697540819644928, dist_loss: 1.0311541557312012
recon_loss: 0.027697540819644928, dist_loss: 0.7753394842147827
recon_loss: 0.027697371318936348, dist_loss: 0.48282477259635925
recon_loss: 0.027697009965777397, dist_loss: 0.7049098014831543
recon_loss: 0.02769657038152218, dist_loss: 0.5403009057044983
recon_loss: 0.027695730328559875, dist_loss: 0.24870269000530243
recon_loss: 0.02769552916288376, dist_loss: 0.5091164112091064
recon_loss: 0.027695585042238235, dist_loss: 0.8541545867919922
recon_loss: 0.02769544906914234, dist_loss: 0.5249896049499512
recon_loss: 0.027696259319782257, dist_loss: 0.5139607787132263
recon_loss: 0.027696406468749046, dist_loss: 0.6777941584587097
recon_loss: 0.027696583420038223, dist_loss: 0.5968085527420044
recon_loss: 0.027696475386619568, dist_loss: 0.5184805989265442
recon_loss: 0.027696439996361732, dist_loss: 0.3778970241546631
recon_loss: 0.027696317061781883, dist_loss: 0.4349594712257385
recon_loss: 0.02769661135971546, dist_loss: 0.9179180264472961
recon_loss: 0.02769661694765091, dist_loss: 0.4518653154373169
recon_loss: 0.0276960339397192, dist_loss: 0.26779478788375854
recon_loss: 0.027696140110492706, dist_loss: 0.49984675645828247
recon_loss: 0.02769552171230316, dist_loss: 0.5091533660888672
recon_loss: 0.02769547514617443, dist_loss: 0.9449173212051392
recon_loss: 0.027696149423718452, dist_loss: 0.7383094429969788
recon_loss: 0.027696657925844193, dist_loss: 0.5221537351608276
recon_loss: 0.027696548029780388, dist_loss: 0.5384341478347778
recon_loss: 0.02769629843533039, dist_loss: 0.8959672451019287
recon_loss: 0.027695991098880768, dist_loss: 1.1654284000396729
recon_loss: 0.027695724740624428, dist_loss: 0.6021754145622253
recon_loss: 0.02769540622830391, dist_loss: 0.5782889723777771
recon_loss: 0.0276950653642416, dist_loss: 0.5374693870544434
recon_loss: 0.02769496478140354, dist_loss: 1.040389060974121
recon_loss: 0.027694862335920334, dist_loss: 0.6143060922622681
recon_loss: 0.02769486978650093, dist_loss: 0.6246703863143921
recon_loss: 0.02769513800740242, dist_loss: 1.175304889678955
recon_loss: 0.027695463970303535, dist_loss: 0.3416653275489807
recon_loss: 0.027695560827851295, dist_loss: 0.7128974795341492
recon_loss: 0.027695676311850548, dist_loss: 0.7903631329536438
recon_loss: 0.02769554778933525, dist_loss: 0.7535444498062134
recon_loss: 0.027695680037140846, dist_loss: 0.34575963020324707
recon_loss: 0.027695946395397186, dist_loss: 0.690305233001709
recon_loss: 0.027695387601852417, dist_loss: 0.5560738444328308
recon_loss: 0.027694709599018097, dist_loss: 0.928816020488739
recon_loss: 0.027694622054696083, dist_loss: 0.6192088723182678
recon_loss: 0.02769412286579609, dist_loss: 0.8161012530326843
recon_loss: 0.027694132179021835, dist_loss: 0.5866304039955139
recon_loss: 0.02769431471824646, dist_loss: 0.7330909371376038
recon_loss: 0.027693722397089005, dist_loss: 0.7151352763175964
recon_loss: 0.027693836018443108, dist_loss: 0.7138776183128357
recon_loss: 0.027693672105669975, dist_loss: 0.7779306769371033
recon_loss: 0.02769356034696102, dist_loss: 0.834663987159729
recon_loss: 0.027693701907992363, dist_loss: 1.1440880298614502
recon_loss: 0.027693090960383415, dist_loss: 0.8081842064857483
recon_loss: 0.027693070471286774, dist_loss: 0.8318273425102234
recon_loss: 0.027693122625350952, dist_loss: 0.5045943856239319
recon_loss: 0.027693143114447594, dist_loss: 0.5215022563934326
recon_loss: 0.027693595737218857, dist_loss: 0.8086557388305664
recon_loss: 0.027693897485733032, dist_loss: 0.2473887801170349
recon_loss: 0.02769405022263527, dist_loss: 0.45818692445755005
recon_loss: 0.027694597840309143, dist_loss: 0.4661538600921631
recon_loss: 0.027694495394825935, dist_loss: 0.8761699199676514
recon_loss: 0.02769508771598339, dist_loss: 0.6484191417694092
recon_loss: 0.027695322409272194, dist_loss: 0.5657624006271362
recon_loss: 0.027695810422301292, dist_loss: 0.6509875059127808
recon_loss: 0.027696117758750916, dist_loss: 0.5391601324081421
recon_loss: 0.027695616707205772, dist_loss: 0.6002656817436218
recon_loss: 0.0276946984231472, dist_loss: 0.7802854776382446
recon_loss: 0.027694113552570343, dist_loss: 0.7911598682403564
recon_loss: 0.027693530544638634, dist_loss: 0.7532185316085815
recon_loss: 0.02769302763044834, dist_loss: 0.8195659518241882
recon_loss: 0.027692684903740883, dist_loss: 0.5216744542121887
recon_loss: 0.02769239991903305, dist_loss: 0.6070931553840637
recon_loss: 0.027692275121808052, dist_loss: 0.6951488256454468
recon_loss: 0.02769201621413231, dist_loss: 0.7775908708572388
recon_loss: 0.027691761031746864, dist_loss: 0.6703017950057983
recon_loss: 0.027691708877682686, dist_loss: 0.44764500856399536
recon_loss: 0.02769196592271328, dist_loss: 0.79261314868927
recon_loss: 0.027692019939422607, dist_loss: 0.44886475801467896
recon_loss: 0.02769227884709835, dist_loss: 0.5376108884811401
recon_loss: 0.02769233100116253, dist_loss: 0.6708042025566101
recon_loss: 0.027692493051290512, dist_loss: 0.5613775849342346
recon_loss: 0.02769244834780693, dist_loss: 0.735103964805603
recon_loss: 0.02769244834780693, dist_loss: 0.662613034248352
recon_loss: 0.027692561969161034, dist_loss: 0.7934437394142151
recon_loss: 0.02769324742257595, dist_loss: 0.4053410589694977
recon_loss: 0.027693629264831543, dist_loss: 0.5445220470428467
recon_loss: 0.02769339829683304, dist_loss: 0.5026198029518127
recon_loss: 0.02769375778734684, dist_loss: 1.1626505851745605
recon_loss: 0.027693796902894974, dist_loss: 0.5319903492927551
recon_loss: 0.02769404463469982, dist_loss: 0.975820779800415
recon_loss: 0.027694759890437126, dist_loss: 0.7019064426422119
recon_loss: 0.027694430202245712, dist_loss: 0.5505529642105103
recon_loss: 0.0276943426579237, dist_loss: 0.5355224013328552
recon_loss: 0.027693284675478935, dist_loss: 0.6907822489738464
recon_loss: 0.027692601084709167, dist_loss: 0.7979024052619934
recon_loss: 0.02769201248884201, dist_loss: 0.6760610938072205
recon_loss: 0.02769206091761589, dist_loss: 0.6219282150268555
recon_loss: 0.027692565694451332, dist_loss: 0.3729233741760254
recon_loss: 0.02769354358315468, dist_loss: 0.47517824172973633
recon_loss: 0.02769547514617443, dist_loss: 0.6071435809135437
recon_loss: 0.02769683487713337, dist_loss: 0.5415432453155518
recon_loss: 0.02769777737557888, dist_loss: 1.18587064743042
recon_loss: 0.02769872173666954, dist_loss: 0.5617506504058838
Pre-training Epoch 92:  72%|███████▏  | 265/367 [00:01<00:00, 151.73it/s]Pre-training Epoch 92:  77%|███████▋  | 281/367 [00:01<00:00, 152.24it/s]Pre-training Epoch 92:  81%|████████  | 297/367 [00:01<00:00, 152.99it/s]Pre-training Epoch 92:  85%|████████▌ | 313/367 [00:02<00:00, 152.28it/s]Pre-training Epoch 92:  90%|████████▉ | 329/367 [00:02<00:00, 152.56it/s]Pre-training Epoch 92:  94%|█████████▍| 345/367 [00:02<00:00, 153.34it/s]Pre-training Epoch 92:  98%|█████████▊| 361/367 [00:02<00:00, 155.25it/s]Pre-training Epoch 92: 100%|██████████| 367/367 [00:02<00:00, 155.06it/s]
recon_loss: 0.027698133140802383, dist_loss: 0.7227526903152466
recon_loss: 0.027697226032614708, dist_loss: 0.6567186117172241
recon_loss: 0.027695532888174057, dist_loss: 0.5336101651191711
recon_loss: 0.027695005759596825, dist_loss: 0.8616383075714111
recon_loss: 0.027694301679730415, dist_loss: 0.8219715356826782
recon_loss: 0.02769412472844124, dist_loss: 0.7478234171867371
recon_loss: 0.027693800628185272, dist_loss: 0.9050003290176392
recon_loss: 0.02769339270889759, dist_loss: 0.6622012853622437
recon_loss: 0.0276932530105114, dist_loss: 0.47415122389793396
recon_loss: 0.027692945674061775, dist_loss: 0.5342421531677246
recon_loss: 0.027693049982190132, dist_loss: 0.7578920722007751
recon_loss: 0.027693800628185272, dist_loss: 0.37089234590530396
recon_loss: 0.02769487164914608, dist_loss: 0.7488631010055542
recon_loss: 0.027696089819073677, dist_loss: 1.3777546882629395
recon_loss: 0.027696629986166954, dist_loss: 0.8622567653656006
recon_loss: 0.027696209028363228, dist_loss: 0.7679178714752197
recon_loss: 0.02769559621810913, dist_loss: 0.8013039827346802
recon_loss: 0.02769429050385952, dist_loss: 0.8274732828140259
recon_loss: 0.02769249491393566, dist_loss: 0.6065961122512817
recon_loss: 0.027691463008522987, dist_loss: 0.7680016756057739
recon_loss: 0.027691245079040527, dist_loss: 0.6223161220550537
recon_loss: 0.027691548690199852, dist_loss: 1.056178092956543
recon_loss: 0.027691734954714775, dist_loss: 0.5343475937843323
recon_loss: 0.027692127972841263, dist_loss: 0.2642362713813782
recon_loss: 0.027691563591361046, dist_loss: 0.4898024797439575
recon_loss: 0.027691373601555824, dist_loss: 0.9442042708396912
recon_loss: 0.027691015973687172, dist_loss: 1.108487606048584
recon_loss: 0.027690637856721878, dist_loss: 0.4643454849720001
recon_loss: 0.027690816670656204, dist_loss: 0.4926959276199341
recon_loss: 0.027690613642334938, dist_loss: 0.4262539744377136
recon_loss: 0.027690140530467033, dist_loss: 0.6698900461196899
recon_loss: 0.027689537033438683, dist_loss: 0.8072439432144165
recon_loss: 0.027689313516020775, dist_loss: 0.5020850896835327
recon_loss: 0.027688561007380486, dist_loss: 0.3396795988082886
recon_loss: 0.027688466012477875, dist_loss: 0.789737343788147
recon_loss: 0.027688097208738327, dist_loss: 0.5189684629440308
recon_loss: 0.02768796682357788, dist_loss: 0.5715643167495728
recon_loss: 0.0276875589042902, dist_loss: 0.848745584487915
recon_loss: 0.027687465772032738, dist_loss: 0.6525503993034363
recon_loss: 0.027687182649970055, dist_loss: 0.6763054132461548
recon_loss: 0.0276871919631958, dist_loss: 0.5091239213943481
recon_loss: 0.027686893939971924, dist_loss: 0.6400190591812134
recon_loss: 0.027687184512615204, dist_loss: 0.4367557764053345
recon_loss: 0.027687229216098785, dist_loss: 0.5460788011550903
recon_loss: 0.02768693119287491, dist_loss: 0.8130924701690674
recon_loss: 0.027687352150678635, dist_loss: 0.5394496917724609
recon_loss: 0.027686690911650658, dist_loss: 0.7087911367416382
recon_loss: 0.02768627367913723, dist_loss: 0.6904683113098145
recon_loss: 0.027686143293976784, dist_loss: 0.778518557548523
recon_loss: 0.027686122804880142, dist_loss: 0.7944783568382263
recon_loss: 0.027686329558491707, dist_loss: 0.3093326687812805
recon_loss: 0.02768666110932827, dist_loss: 0.6999992728233337
recon_loss: 0.0276865866035223, dist_loss: 0.9429749846458435
recon_loss: 0.027686558663845062, dist_loss: 0.9324065446853638
recon_loss: 0.027686940506100655, dist_loss: 0.4451688230037689
recon_loss: 0.0276881605386734, dist_loss: 0.8700551390647888
recon_loss: 0.027689240872859955, dist_loss: 0.8136489987373352
recon_loss: 0.027690701186656952, dist_loss: 0.661278247833252
recon_loss: 0.02769152820110321, dist_loss: 0.7108258605003357
recon_loss: 0.02769339643418789, dist_loss: 0.5977048873901367
recon_loss: 0.027692977339029312, dist_loss: 0.582789957523346
recon_loss: 0.027693135663866997, dist_loss: 0.6618664264678955
recon_loss: 0.02769293822348118, dist_loss: 0.4139691889286041
recon_loss: 0.027692297473549843, dist_loss: 0.42328697443008423
recon_loss: 0.027692105621099472, dist_loss: 0.6456724405288696
recon_loss: 0.027692222967743874, dist_loss: 0.9618957042694092
recon_loss: 0.027691679075360298, dist_loss: 0.8964159488677979
recon_loss: 0.027690764516592026, dist_loss: 0.6009200811386108
recon_loss: 0.027690976858139038, dist_loss: 1.1670217514038086
recon_loss: 0.0276902187615633, dist_loss: 0.9894000291824341
recon_loss: 0.0276902187615633, dist_loss: 0.9272288680076599
recon_loss: 0.027689887210726738, dist_loss: 0.30814749002456665
recon_loss: 0.027688821777701378, dist_loss: 0.8394472002983093
recon_loss: 0.027689829468727112, dist_loss: 0.6307494044303894
recon_loss: 0.027688082307577133, dist_loss: 0.48848336935043335
recon_loss: 0.02768842689692974, dist_loss: 0.8656100630760193
recon_loss: 0.027687791734933853, dist_loss: 0.8118737936019897
recon_loss: 0.0276873130351305, dist_loss: 0.993844747543335
recon_loss: 0.027687761932611465, dist_loss: 0.5858051776885986
recon_loss: 0.027687445282936096, dist_loss: 0.8099308013916016
recon_loss: 0.02768942154943943, dist_loss: 0.5654631853103638
recon_loss: 0.027689412236213684, dist_loss: 0.6619125604629517
recon_loss: 0.02769160456955433, dist_loss: 0.5522303581237793
recon_loss: 0.02769276686012745, dist_loss: 0.4960215091705322
recon_loss: 0.027693120762705803, dist_loss: 0.6517935991287231
recon_loss: 0.027695544064044952, dist_loss: 0.4343165159225464
recon_loss: 0.0276953037828207, dist_loss: 0.5578259229660034
recon_loss: 0.027696847915649414, dist_loss: 0.49889954924583435
recon_loss: 0.02769567258656025, dist_loss: 0.6521797180175781
recon_loss: 0.02769595757126808, dist_loss: 0.3298608660697937
recon_loss: 0.02769543044269085, dist_loss: 1.0649596452713013
recon_loss: 0.027694648131728172, dist_loss: 0.7678911089897156
recon_loss: 0.02769470401108265, dist_loss: 1.019791603088379
recon_loss: 0.027692724019289017, dist_loss: 1.290565013885498
recon_loss: 0.027693044394254684, dist_loss: 0.6803218126296997
recon_loss: 0.027690622955560684, dist_loss: 0.9208023548126221
recon_loss: 0.0276902187615633, dist_loss: 0.845642626285553
recon_loss: 0.027688780799508095, dist_loss: 0.30885177850723267
recon_loss: 0.027687611058354378, dist_loss: 0.4718265235424042
recon_loss: 0.027686623856425285, dist_loss: 0.5184991955757141
recon_loss: 0.027685899287462234, dist_loss: 0.6174033880233765
recon_loss: 0.027686089277267456, dist_loss: 0.6041523218154907
recon_loss: 0.027685828506946564, dist_loss: 0.3205946385860443
recon_loss: 0.027686482295393944, dist_loss: 0.7330461740493774
recon_loss: 0.02768653817474842, dist_loss: 0.5466670989990234
recon_loss: 0.027686817571520805, dist_loss: 0.4262892007827759
recon_loss: 0.027686651796102524, dist_loss: 0.5964909791946411
recon_loss: 0.027686063200235367, dist_loss: 0.6509105563163757
recon_loss: 0.02768591418862343, dist_loss: 0.6288051605224609
recon_loss: 0.027684573084115982, dist_loss: 0.8564038276672363
recon_loss: 0.02768537774682045, dist_loss: 0.6317804455757141
Pre-training Epoch 93:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 93:   5%|▍         | 17/367 [00:00<00:02, 165.45it/s]Pre-training Epoch 93:   9%|▉         | 34/367 [00:00<00:02, 162.27it/s]Pre-training Epoch 93:  14%|█▍        | 51/367 [00:00<00:01, 162.09it/s]Pre-training Epoch 93:  19%|█▊        | 68/367 [00:00<00:01, 163.17it/s]Pre-training Epoch 93:  23%|██▎       | 85/367 [00:00<00:01, 154.93it/s]Pre-training Epoch 93:  28%|██▊       | 101/367 [00:00<00:01, 153.80it/s]Pre-training Epoch 93:  32%|███▏      | 117/367 [00:00<00:01, 152.51it/s]recon_loss: 0.02768440917134285, dist_loss: 0.610257625579834
recon_loss: 0.027684638276696205, dist_loss: 0.7749258279800415
recon_loss: 0.027684221044182777, dist_loss: 0.5594584345817566
recon_loss: 0.02768375352025032, dist_loss: 0.7352070212364197
recon_loss: 0.027683693915605545, dist_loss: 0.41193729639053345
recon_loss: 0.027683353051543236, dist_loss: 0.7705610990524292
recon_loss: 0.027683641761541367, dist_loss: 0.357354998588562
recon_loss: 0.02768273651599884, dist_loss: 0.560943603515625
recon_loss: 0.027682388201355934, dist_loss: 0.5141555070877075
recon_loss: 0.027683112770318985, dist_loss: 0.6496857404708862
recon_loss: 0.027682671323418617, dist_loss: 0.5471257567405701
recon_loss: 0.02768324874341488, dist_loss: 1.124184250831604
recon_loss: 0.027683041989803314, dist_loss: 0.4881117343902588
recon_loss: 0.02768241986632347, dist_loss: 0.6337490677833557
recon_loss: 0.027682410553097725, dist_loss: 0.6540289521217346
recon_loss: 0.027682719752192497, dist_loss: 0.4214317202568054
recon_loss: 0.02768339030444622, dist_loss: 0.3816378116607666
recon_loss: 0.027683334425091743, dist_loss: 0.4205244779586792
recon_loss: 0.027683353051543236, dist_loss: 0.5528140068054199
recon_loss: 0.027683017775416374, dist_loss: 0.6482419967651367
recon_loss: 0.027682727202773094, dist_loss: 0.6165608167648315
recon_loss: 0.02768268622457981, dist_loss: 0.7714492082595825
recon_loss: 0.027682315558195114, dist_loss: 0.40529918670654297
recon_loss: 0.027682289481163025, dist_loss: 0.4064253568649292
recon_loss: 0.027682583779096603, dist_loss: 0.9293856620788574
recon_loss: 0.027682647109031677, dist_loss: 0.8044441938400269
recon_loss: 0.02768251672387123, dist_loss: 0.654327392578125
recon_loss: 0.02768208459019661, dist_loss: 0.6939380168914795
recon_loss: 0.027681704610586166, dist_loss: 0.46218356490135193
recon_loss: 0.02768176794052124, dist_loss: 0.5592457056045532
recon_loss: 0.027681536972522736, dist_loss: 0.3798063099384308
recon_loss: 0.027681764215230942, dist_loss: 0.6888340711593628
recon_loss: 0.027682028710842133, dist_loss: 0.6433027386665344
recon_loss: 0.02768191695213318, dist_loss: 0.7799268960952759
recon_loss: 0.027682198211550713, dist_loss: 0.5106887817382812
recon_loss: 0.027682114392518997, dist_loss: 0.8769680857658386
recon_loss: 0.027682123705744743, dist_loss: 0.5544089674949646
recon_loss: 0.02768179401755333, dist_loss: 0.36100488901138306
recon_loss: 0.027681859210133553, dist_loss: 0.35129013657569885
recon_loss: 0.027681933715939522, dist_loss: 0.6609050035476685
recon_loss: 0.027681756764650345, dist_loss: 0.42638304829597473
recon_loss: 0.02768172137439251, dist_loss: 0.8968813419342041
recon_loss: 0.027681708335876465, dist_loss: 0.6235320568084717
recon_loss: 0.027681617066264153, dist_loss: 0.7947705984115601
recon_loss: 0.027681509032845497, dist_loss: 0.7509112358093262
recon_loss: 0.02768135257065296, dist_loss: 0.5680042505264282
recon_loss: 0.027681002393364906, dist_loss: 0.49068209528923035
recon_loss: 0.02768072672188282, dist_loss: 0.6335304975509644
recon_loss: 0.0276806503534317, dist_loss: 0.8380230665206909
recon_loss: 0.02768045663833618, dist_loss: 0.8572648763656616
recon_loss: 0.027680199593305588, dist_loss: 0.7315446138381958
recon_loss: 0.027680091559886932, dist_loss: 0.6561909914016724
recon_loss: 0.02768000029027462, dist_loss: 0.299852192401886
recon_loss: 0.02768029272556305, dist_loss: 0.7268162965774536
recon_loss: 0.027680275961756706, dist_loss: 0.8110364079475403
recon_loss: 0.027679935097694397, dist_loss: 0.6665307879447937
recon_loss: 0.027680162340402603, dist_loss: 0.9712988138198853
recon_loss: 0.02767997980117798, dist_loss: 0.8943595886230469
recon_loss: 0.027679946273565292, dist_loss: 0.7875820994377136
recon_loss: 0.027679983526468277, dist_loss: 0.7830674648284912
recon_loss: 0.027680307626724243, dist_loss: 0.40526533126831055
recon_loss: 0.02768057957291603, dist_loss: 0.6768718957901001
recon_loss: 0.02768123522400856, dist_loss: 0.5083469748497009
recon_loss: 0.027681397274136543, dist_loss: 0.8857311010360718
recon_loss: 0.027680370956659317, dist_loss: 0.6859731674194336
recon_loss: 0.02768002822995186, dist_loss: 0.3672080338001251
recon_loss: 0.027679480612277985, dist_loss: 0.7698318362236023
recon_loss: 0.02767951600253582, dist_loss: 1.0956592559814453
recon_loss: 0.027679799124598503, dist_loss: 0.34929999709129333
recon_loss: 0.027680113911628723, dist_loss: 0.49394506216049194
recon_loss: 0.027680281549692154, dist_loss: 0.7770088315010071
recon_loss: 0.02768055349588394, dist_loss: 0.5856429934501648
recon_loss: 0.027680641040205956, dist_loss: 0.6458905935287476
recon_loss: 0.027680782601237297, dist_loss: 0.9172898530960083
recon_loss: 0.027681071311235428, dist_loss: 0.5275883674621582
recon_loss: 0.027680881321430206, dist_loss: 0.9653753042221069
recon_loss: 0.027680885046720505, dist_loss: 0.69535893201828
recon_loss: 0.027680538594722748, dist_loss: 0.5156841278076172
recon_loss: 0.027680031955242157, dist_loss: 0.3872472047805786
recon_loss: 0.027679992839694023, dist_loss: 0.45070379972457886
recon_loss: 0.02767922356724739, dist_loss: 0.6587257981300354
recon_loss: 0.02767930179834366, dist_loss: 0.851526141166687
recon_loss: 0.027678966522216797, dist_loss: 0.5279333591461182
recon_loss: 0.027679238468408585, dist_loss: 0.5427747964859009
recon_loss: 0.027679841965436935, dist_loss: 0.613675594329834
recon_loss: 0.027679286897182465, dist_loss: 0.3088728189468384
recon_loss: 0.027680397033691406, dist_loss: 0.6164867281913757
recon_loss: 0.027679774910211563, dist_loss: 0.8282598257064819
recon_loss: 0.02767973206937313, dist_loss: 0.4648009240627289
recon_loss: 0.027679363265633583, dist_loss: 0.5678818225860596
recon_loss: 0.02767854928970337, dist_loss: 0.9267322421073914
recon_loss: 0.027678415179252625, dist_loss: 0.3563060760498047
recon_loss: 0.027678340673446655, dist_loss: 0.9685689806938171
recon_loss: 0.027678243815898895, dist_loss: 0.9816636443138123
recon_loss: 0.027677910402417183, dist_loss: 0.5632052421569824
recon_loss: 0.02767767570912838, dist_loss: 1.0778616666793823
recon_loss: 0.02767772786319256, dist_loss: 0.46790069341659546
recon_loss: 0.027677802368998528, dist_loss: 0.7006515860557556
recon_loss: 0.02767791412770748, dist_loss: 0.4783024191856384
recon_loss: 0.02767796814441681, dist_loss: 0.44417181611061096
recon_loss: 0.027677521109580994, dist_loss: 0.5233229994773865
recon_loss: 0.02767736092209816, dist_loss: 0.5526846647262573
recon_loss: 0.027677172794938087, dist_loss: 0.7591873407363892
recon_loss: 0.02767685055732727, dist_loss: 0.3843954801559448
recon_loss: 0.02767690271139145, dist_loss: 0.5362187027931213
recon_loss: 0.027677342295646667, dist_loss: 0.8475478291511536
recon_loss: 0.027677448466420174, dist_loss: 0.7360711097717285
recon_loss: 0.027677809819579124, dist_loss: 0.5375128984451294
recon_loss: 0.0276781115680933, dist_loss: 0.6879185438156128
recon_loss: 0.027678390964865685, dist_loss: 0.6233235001564026
recon_loss: 0.02767876721918583, dist_loss: 0.447776198387146
recon_loss: 0.027678726240992546, dist_loss: 0.5068430304527283
recon_loss: 0.02767854370176792, dist_loss: 0.7451999187469482
recon_loss: 0.02767816372215748, dist_loss: 1.2566075325012207
recon_loss: 0.02767784707248211, dist_loss: 0.509611964225769
recon_loss: 0.027677981182932854, dist_loss: 0.421804815530777
recon_loss: 0.027679331600666046, dist_loss: 0.7491306066513062
recon_loss: 0.02768123522400856, dist_loss: 0.4606029987335205
recon_loss: 0.027682723477482796, dist_loss: 0.5106440782546997
recon_loss: 0.027683619409799576, dist_loss: 0.8696657419204712
recon_loss: 0.027684343978762627, dist_loss: 0.8805593848228455
recon_loss: 0.027684517204761505, dist_loss: 0.7267796397209167
recon_loss: 0.02768477238714695, dist_loss: 0.3925311863422394
recon_loss: 0.027683746069669724, dist_loss: 1.073063850402832
recon_loss: 0.027681590989232063, dist_loss: 0.5337045192718506
recon_loss: 0.027679912745952606, dist_loss: 0.7103246450424194
recon_loss: 0.02767910808324814, dist_loss: 0.5101971626281738
recon_loss: 0.027678493410348892, dist_loss: 1.1772379875183105
Pre-training Epoch 93:  36%|███▌      | 133/367 [00:00<00:01, 150.51it/s]Pre-training Epoch 93:  41%|████      | 149/367 [00:00<00:01, 150.67it/s]Pre-training Epoch 93:  45%|████▍     | 165/367 [00:01<00:01, 148.44it/s]Pre-training Epoch 93:  49%|████▉     | 181/367 [00:01<00:01, 149.93it/s]Pre-training Epoch 93:  54%|█████▎    | 197/367 [00:01<00:01, 150.37it/s]Pre-training Epoch 93:  58%|█████▊    | 213/367 [00:01<00:01, 150.75it/s]Pre-training Epoch 93:  62%|██████▏   | 229/367 [00:01<00:00, 149.55it/s]Pre-training Epoch 93:  67%|██████▋   | 245/367 [00:01<00:00, 150.63it/s]recon_loss: 0.027678031474351883, dist_loss: 0.5476253032684326
recon_loss: 0.027677997946739197, dist_loss: 0.5311239957809448
recon_loss: 0.0276788379997015, dist_loss: 0.9038094878196716
recon_loss: 0.02767964079976082, dist_loss: 0.9315915703773499
recon_loss: 0.027680952101945877, dist_loss: 0.6876300573348999
recon_loss: 0.02768179588019848, dist_loss: 0.7714979648590088
recon_loss: 0.027682507410645485, dist_loss: 0.5190734267234802
recon_loss: 0.027682967483997345, dist_loss: 0.45220357179641724
recon_loss: 0.027682848274707794, dist_loss: 0.7695434093475342
recon_loss: 0.0276817437261343, dist_loss: 0.6498465538024902
recon_loss: 0.02768007479608059, dist_loss: 0.5293259620666504
recon_loss: 0.027679305523633957, dist_loss: 0.7956417202949524
recon_loss: 0.027678003534674644, dist_loss: 0.4871450364589691
recon_loss: 0.027677929028868675, dist_loss: 0.6777920722961426
recon_loss: 0.027676725760102272, dist_loss: 0.7195252776145935
recon_loss: 0.027676206082105637, dist_loss: 0.6148756146430969
recon_loss: 0.027677465230226517, dist_loss: 0.9482520818710327
recon_loss: 0.027677373960614204, dist_loss: 0.3861464262008667
recon_loss: 0.027676623314619064, dist_loss: 0.32049769163131714
recon_loss: 0.027677375823259354, dist_loss: 0.48199662566185
recon_loss: 0.027677344158291817, dist_loss: 0.4982931911945343
recon_loss: 0.027677444741129875, dist_loss: 1.0547313690185547
recon_loss: 0.027677219361066818, dist_loss: 0.592029333114624
recon_loss: 0.027677254751324654, dist_loss: 0.3729677200317383
recon_loss: 0.027676641941070557, dist_loss: 0.5589313507080078
recon_loss: 0.027675829827785492, dist_loss: 0.5464032292366028
recon_loss: 0.027675248682498932, dist_loss: 0.4176827073097229
recon_loss: 0.027674594894051552, dist_loss: 0.7158426642417908
recon_loss: 0.027674246579408646, dist_loss: 0.8277722597122192
recon_loss: 0.0276738703250885, dist_loss: 0.5384307503700256
recon_loss: 0.027673877775669098, dist_loss: 0.5114686489105225
recon_loss: 0.027673624455928802, dist_loss: 0.48536375164985657
recon_loss: 0.027673399075865746, dist_loss: 0.6887779235839844
recon_loss: 0.02767316810786724, dist_loss: 0.5995652079582214
recon_loss: 0.027673201635479927, dist_loss: 0.4828260838985443
recon_loss: 0.027673490345478058, dist_loss: 0.5416915416717529
recon_loss: 0.02767351269721985, dist_loss: 0.8991833925247192
recon_loss: 0.027673672884702682, dist_loss: 1.229203224182129
recon_loss: 0.02767377905547619, dist_loss: 0.5489464998245239
recon_loss: 0.02767370268702507, dist_loss: 0.8235579133033752
recon_loss: 0.027673762291669846, dist_loss: 0.6151531934738159
recon_loss: 0.027673494070768356, dist_loss: 0.5914031267166138
recon_loss: 0.02767321839928627, dist_loss: 0.8207295536994934
recon_loss: 0.027673419564962387, dist_loss: 0.8243130445480347
recon_loss: 0.027672862634062767, dist_loss: 0.9556244611740112
recon_loss: 0.0276737529784441, dist_loss: 0.8969127535820007
recon_loss: 0.027672970667481422, dist_loss: 0.47614115476608276
recon_loss: 0.027673250064253807, dist_loss: 0.48066967725753784
recon_loss: 0.027672531083226204, dist_loss: 0.3429532051086426
recon_loss: 0.02767230197787285, dist_loss: 0.7590519785881042
recon_loss: 0.027671944350004196, dist_loss: 0.531182050704956
recon_loss: 0.027672098949551582, dist_loss: 0.6088526844978333
recon_loss: 0.02767227590084076, dist_loss: 0.620924711227417
recon_loss: 0.02767215296626091, dist_loss: 0.6230618953704834
recon_loss: 0.027672341093420982, dist_loss: 0.9485325813293457
recon_loss: 0.02767256274819374, dist_loss: 0.7479724884033203
recon_loss: 0.02767264097929001, dist_loss: 0.5013903379440308
recon_loss: 0.027672436088323593, dist_loss: 0.5575869083404541
recon_loss: 0.027672626078128815, dist_loss: 0.9154416918754578
recon_loss: 0.02767203375697136, dist_loss: 0.7809207439422607
recon_loss: 0.02767201140522957, dist_loss: 0.6475566625595093
recon_loss: 0.02767256647348404, dist_loss: 0.6041827201843262
recon_loss: 0.02767423540353775, dist_loss: 0.6103415489196777
recon_loss: 0.0276739913970232, dist_loss: 0.3106843829154968
recon_loss: 0.02767539955675602, dist_loss: 0.7144289612770081
recon_loss: 0.027675887569785118, dist_loss: 0.5762062072753906
recon_loss: 0.02767561748623848, dist_loss: 0.6346995830535889
recon_loss: 0.027676833793520927, dist_loss: 0.834175169467926
recon_loss: 0.027677437290549278, dist_loss: 0.8392322063446045
recon_loss: 0.02767815813422203, dist_loss: 0.640997588634491
recon_loss: 0.02767842262983322, dist_loss: 0.6078221797943115
recon_loss: 0.02767663076519966, dist_loss: 0.6804149150848389
recon_loss: 0.027675265446305275, dist_loss: 1.1962881088256836
recon_loss: 0.027674594894051552, dist_loss: 0.5449134111404419
recon_loss: 0.02767358534038067, dist_loss: 0.580877423286438
recon_loss: 0.027673425152897835, dist_loss: 0.7216959595680237
recon_loss: 0.02767217345535755, dist_loss: 1.0116910934448242
recon_loss: 0.02767161652445793, dist_loss: 0.4222382605075836
recon_loss: 0.027671286836266518, dist_loss: 1.0820107460021973
recon_loss: 0.027670523151755333, dist_loss: 0.655552089214325
recon_loss: 0.02767050452530384, dist_loss: 0.8115107417106628
recon_loss: 0.027670398354530334, dist_loss: 0.5759098529815674
recon_loss: 0.027671154588460922, dist_loss: 0.3425794839859009
recon_loss: 0.027672825381159782, dist_loss: 0.5398868918418884
recon_loss: 0.027674442157149315, dist_loss: 0.6815767288208008
recon_loss: 0.027676153928041458, dist_loss: 0.5851758122444153
recon_loss: 0.027677951380610466, dist_loss: 0.6855912208557129
recon_loss: 0.027679093182086945, dist_loss: 0.41479265689849854
recon_loss: 0.02768057957291603, dist_loss: 0.4726596474647522
recon_loss: 0.02768065594136715, dist_loss: 0.7946557998657227
recon_loss: 0.027680138126015663, dist_loss: 0.7186805009841919
recon_loss: 0.02768155187368393, dist_loss: 1.1978027820587158
recon_loss: 0.027681715786457062, dist_loss: 0.5881351232528687
recon_loss: 0.027682501822710037, dist_loss: 0.5433529615402222
recon_loss: 0.02768169716000557, dist_loss: 0.8025432825088501
recon_loss: 0.027680210769176483, dist_loss: 0.9920048713684082
recon_loss: 0.02767782285809517, dist_loss: 0.7775102257728577
recon_loss: 0.027676334604620934, dist_loss: 0.6000569462776184
recon_loss: 0.027674416080117226, dist_loss: 1.0991840362548828
recon_loss: 0.027673231437802315, dist_loss: 0.6146706938743591
recon_loss: 0.027672650292515755, dist_loss: 0.42764750123023987
recon_loss: 0.027673853561282158, dist_loss: 0.6009028553962708
recon_loss: 0.027675166726112366, dist_loss: 0.6934344172477722
recon_loss: 0.027677437290549278, dist_loss: 1.025863766670227
recon_loss: 0.027678759768605232, dist_loss: 0.718826949596405
recon_loss: 0.027678247541189194, dist_loss: 0.38675355911254883
recon_loss: 0.027679050341248512, dist_loss: 0.931840717792511
recon_loss: 0.027678579092025757, dist_loss: 0.6503515243530273
recon_loss: 0.02767786756157875, dist_loss: 0.3895464241504669
recon_loss: 0.027676863595843315, dist_loss: 0.5497481226921082
recon_loss: 0.027673805132508278, dist_loss: 0.5629720687866211
recon_loss: 0.027673296630382538, dist_loss: 0.45984476804733276
recon_loss: 0.027671419084072113, dist_loss: 0.33046507835388184
recon_loss: 0.027671467512845993, dist_loss: 0.7979904413223267
recon_loss: 0.027670446783304214, dist_loss: 0.7787991762161255
recon_loss: 0.02767002210021019, dist_loss: 0.5559954047203064
recon_loss: 0.027670253068208694, dist_loss: 0.602426290512085
recon_loss: 0.02767033502459526, dist_loss: 0.27583345770835876
recon_loss: 0.027671150863170624, dist_loss: 0.6633138060569763
recon_loss: 0.027672072872519493, dist_loss: 1.1832408905029297
recon_loss: 0.02767431177198887, dist_loss: 0.5205471515655518
recon_loss: 0.027675680816173553, dist_loss: 0.7854776382446289
recon_loss: 0.027675561606884003, dist_loss: 0.7017364501953125
recon_loss: 0.027674537152051926, dist_loss: 0.6706797480583191
recon_loss: 0.02767370268702507, dist_loss: 0.4806715250015259
recon_loss: 0.027672909200191498, dist_loss: 0.7387292385101318
recon_loss: 0.027671275660395622, dist_loss: 1.000550627708435
recon_loss: 0.02766970917582512, dist_loss: 1.0338611602783203
Pre-training Epoch 93:  71%|███████   | 261/367 [00:01<00:00, 151.10it/s]Pre-training Epoch 93:  75%|███████▌  | 277/367 [00:01<00:00, 150.61it/s]Pre-training Epoch 93:  80%|███████▉  | 293/367 [00:01<00:00, 150.98it/s]Pre-training Epoch 93:  84%|████████▍ | 309/367 [00:02<00:00, 152.23it/s]Pre-training Epoch 93:  89%|████████▊ | 325/367 [00:02<00:00, 151.11it/s]Pre-training Epoch 93:  93%|█████████▎| 341/367 [00:02<00:00, 149.75it/s]Pre-training Epoch 93:  97%|█████████▋| 356/367 [00:02<00:00, 149.04it/s]Pre-training Epoch 93: 100%|██████████| 367/367 [00:02<00:00, 151.81it/s]
recon_loss: 0.027668388560414314, dist_loss: 0.5747906565666199
recon_loss: 0.027667805552482605, dist_loss: 0.5150269269943237
recon_loss: 0.027668528258800507, dist_loss: 0.41094255447387695
recon_loss: 0.0276701170951128, dist_loss: 1.14516282081604
recon_loss: 0.02767305076122284, dist_loss: 0.7661730647087097
recon_loss: 0.027675289660692215, dist_loss: 0.46842408180236816
recon_loss: 0.027678122743964195, dist_loss: 0.6528762578964233
recon_loss: 0.02768043801188469, dist_loss: 0.6189917922019958
recon_loss: 0.02768026664853096, dist_loss: 0.32810667157173157
recon_loss: 0.027680208906531334, dist_loss: 0.6003320217132568
recon_loss: 0.027679113671183586, dist_loss: 0.5502629280090332
recon_loss: 0.02767726592719555, dist_loss: 0.7335963249206543
recon_loss: 0.02767547219991684, dist_loss: 0.5269604921340942
recon_loss: 0.02767445705831051, dist_loss: 0.5347276329994202
recon_loss: 0.0276727844029665, dist_loss: 0.48306432366371155
recon_loss: 0.027671407908201218, dist_loss: 0.9884291887283325
recon_loss: 0.02766994759440422, dist_loss: 1.1096382141113281
recon_loss: 0.027668744325637817, dist_loss: 0.6101136207580566
recon_loss: 0.027667706832289696, dist_loss: 0.6835490465164185
recon_loss: 0.027667393907904625, dist_loss: 0.9450543522834778
recon_loss: 0.027667855843901634, dist_loss: 0.7010369300842285
recon_loss: 0.027668815106153488, dist_loss: 1.2743721008300781
recon_loss: 0.027670137584209442, dist_loss: 0.7316956520080566
recon_loss: 0.027671119198203087, dist_loss: 0.6461809277534485
recon_loss: 0.027671514078974724, dist_loss: 0.8563978672027588
recon_loss: 0.027671633288264275, dist_loss: 0.5343691110610962
recon_loss: 0.027670789510011673, dist_loss: 0.8866333961486816
recon_loss: 0.027670390903949738, dist_loss: 0.6354706287384033
recon_loss: 0.02767103910446167, dist_loss: 0.9565409421920776
recon_loss: 0.027670325711369514, dist_loss: 0.9822813272476196
recon_loss: 0.027669312432408333, dist_loss: 0.46882885694503784
recon_loss: 0.027667608112096786, dist_loss: 0.6542679071426392
recon_loss: 0.027666514739394188, dist_loss: 0.4936225116252899
recon_loss: 0.02766614966094494, dist_loss: 0.6031193733215332
recon_loss: 0.02766507863998413, dist_loss: 0.558657169342041
recon_loss: 0.02766498737037182, dist_loss: 0.61280357837677
recon_loss: 0.027664488181471825, dist_loss: 0.7451295852661133
recon_loss: 0.02766397036612034, dist_loss: 0.5478729605674744
recon_loss: 0.027664009481668472, dist_loss: 0.8578199148178101
recon_loss: 0.027663318440318108, dist_loss: 0.9057427048683167
recon_loss: 0.027664296329021454, dist_loss: 0.7920240163803101
recon_loss: 0.02766365185379982, dist_loss: 0.6501511335372925
recon_loss: 0.027664100751280785, dist_loss: 0.3667570948600769
recon_loss: 0.027664318680763245, dist_loss: 0.39986464381217957
recon_loss: 0.027664665132761, dist_loss: 0.6170305013656616
recon_loss: 0.027664948254823685, dist_loss: 0.8612393140792847
recon_loss: 0.027665529400110245, dist_loss: 0.8233397006988525
recon_loss: 0.027666116133332253, dist_loss: 0.41536518931388855
recon_loss: 0.027666620910167694, dist_loss: 0.5423835515975952
recon_loss: 0.027667248621582985, dist_loss: 0.800862193107605
recon_loss: 0.027667568996548653, dist_loss: 0.34637317061424255
recon_loss: 0.027667246758937836, dist_loss: 0.4764503240585327
recon_loss: 0.02766677923500538, dist_loss: 0.5201932191848755
recon_loss: 0.02766578271985054, dist_loss: 0.46345973014831543
recon_loss: 0.027664322406053543, dist_loss: 0.499214231967926
recon_loss: 0.02766355313360691, dist_loss: 0.9090662002563477
recon_loss: 0.02766256220638752, dist_loss: 0.5200456380844116
recon_loss: 0.027662208303809166, dist_loss: 0.48164305090904236
recon_loss: 0.027662504464387894, dist_loss: 0.6114490032196045
recon_loss: 0.027663063257932663, dist_loss: 0.676201581954956
recon_loss: 0.0276647862046957, dist_loss: 1.3324406147003174
recon_loss: 0.027666062116622925, dist_loss: 0.5912770628929138
recon_loss: 0.027666423469781876, dist_loss: 0.5379270911216736
recon_loss: 0.02766691893339157, dist_loss: 0.4227573573589325
recon_loss: 0.027666499838232994, dist_loss: 0.5178936719894409
recon_loss: 0.027666565030813217, dist_loss: 0.6775259971618652
recon_loss: 0.02766610123217106, dist_loss: 1.0298688411712646
recon_loss: 0.027664748951792717, dist_loss: 0.4904577136039734
recon_loss: 0.027663467451930046, dist_loss: 0.3886902332305908
recon_loss: 0.027662992477416992, dist_loss: 0.7725142240524292
recon_loss: 0.027662383392453194, dist_loss: 0.8115586638450623
recon_loss: 0.02766244485974312, dist_loss: 0.5989303588867188
recon_loss: 0.02766229957342148, dist_loss: 0.4954167604446411
recon_loss: 0.027662605047225952, dist_loss: 0.526578426361084
recon_loss: 0.027662502601742744, dist_loss: 0.7387813329696655
recon_loss: 0.027662096545100212, dist_loss: 0.632603645324707
recon_loss: 0.027661923319101334, dist_loss: 0.6116700172424316
recon_loss: 0.02766234613955021, dist_loss: 0.4612838923931122
recon_loss: 0.027662774547934532, dist_loss: 0.717508852481842
recon_loss: 0.027663204818964005, dist_loss: 0.6554186344146729
recon_loss: 0.027663525193929672, dist_loss: 0.966684103012085
recon_loss: 0.027663560584187508, dist_loss: 0.7928242683410645
recon_loss: 0.027663879096508026, dist_loss: 0.6089524030685425
recon_loss: 0.02766311913728714, dist_loss: 0.646437406539917
recon_loss: 0.027662696316838264, dist_loss: 0.73853600025177
recon_loss: 0.02766183577477932, dist_loss: 0.40438270568847656
recon_loss: 0.027663463726639748, dist_loss: 0.6306416392326355
recon_loss: 0.0276623722165823, dist_loss: 0.5143104791641235
recon_loss: 0.02766360715031624, dist_loss: 0.5851689577102661
recon_loss: 0.027662621811032295, dist_loss: 0.6123851537704468
recon_loss: 0.027662739157676697, dist_loss: 0.783915102481842
recon_loss: 0.02766188234090805, dist_loss: 0.6299974918365479
recon_loss: 0.027661507949233055, dist_loss: 0.3737180233001709
recon_loss: 0.02766232006251812, dist_loss: 0.26125359535217285
recon_loss: 0.027659444138407707, dist_loss: 1.1828076839447021
recon_loss: 0.027661176398396492, dist_loss: 0.7127383351325989
recon_loss: 0.027661168947815895, dist_loss: 1.277616024017334
recon_loss: 0.027666475623846054, dist_loss: 0.7258455753326416
recon_loss: 0.027666393667459488, dist_loss: 0.5091223120689392
recon_loss: 0.027668267488479614, dist_loss: 0.51948481798172
recon_loss: 0.02766944095492363, dist_loss: 0.6340957283973694
recon_loss: 0.027668211609125137, dist_loss: 0.48350101709365845
recon_loss: 0.027668511494994164, dist_loss: 0.6608222126960754
recon_loss: 0.027666965499520302, dist_loss: 1.0479819774627686
recon_loss: 0.027666961774230003, dist_loss: 0.51540607213974
recon_loss: 0.027664991095662117, dist_loss: 0.6377044916152954
recon_loss: 0.0276639461517334, dist_loss: 0.39598774909973145
recon_loss: 0.027663009241223335, dist_loss: 0.638877272605896
recon_loss: 0.027661915868520737, dist_loss: 0.2567221522331238
recon_loss: 0.02766217477619648, dist_loss: 0.7566403746604919
recon_loss: 0.027661239728331566, dist_loss: 0.23049603402614594
Pre-training Epoch 94:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 94:   5%|▍         | 17/367 [00:00<00:02, 167.14it/s]Pre-training Epoch 94:  10%|▉         | 35/367 [00:00<00:01, 172.99it/s]Pre-training Epoch 94:  14%|█▍        | 53/367 [00:00<00:01, 176.09it/s]Pre-training Epoch 94:  19%|█▉        | 71/367 [00:00<00:01, 166.10it/s]Pre-training Epoch 94:  24%|██▍       | 88/367 [00:00<00:01, 159.75it/s]Pre-training Epoch 94:  29%|██▊       | 105/367 [00:00<00:01, 158.60it/s]Pre-training Epoch 94:  33%|███▎      | 121/367 [00:00<00:01, 157.66it/s]recon_loss: 0.027661006897687912, dist_loss: 0.6002734899520874
recon_loss: 0.027661023661494255, dist_loss: 0.4135434627532959
recon_loss: 0.027661295607686043, dist_loss: 0.574867844581604
recon_loss: 0.027661578729748726, dist_loss: 0.5367851257324219
recon_loss: 0.027661705389618874, dist_loss: 0.44111233949661255
recon_loss: 0.027661753818392754, dist_loss: 0.25525784492492676
recon_loss: 0.027661848813295364, dist_loss: 0.68201744556427
recon_loss: 0.02766193076968193, dist_loss: 0.829091489315033
recon_loss: 0.027662916108965874, dist_loss: 1.0133740901947021
recon_loss: 0.027663378044962883, dist_loss: 0.9867825508117676
recon_loss: 0.027663422748446465, dist_loss: 0.5319218039512634
recon_loss: 0.027663957327604294, dist_loss: 0.8298637866973877
recon_loss: 0.0276632122695446, dist_loss: 0.7703572511672974
recon_loss: 0.027662772685289383, dist_loss: 0.7366447448730469
recon_loss: 0.02766197733581066, dist_loss: 0.4975002408027649
recon_loss: 0.02766100876033306, dist_loss: 0.4208798110485077
recon_loss: 0.027660710737109184, dist_loss: 0.9067244529724121
recon_loss: 0.02766030840575695, dist_loss: 0.6749926209449768
recon_loss: 0.027659982442855835, dist_loss: 0.5955901145935059
recon_loss: 0.02765950933098793, dist_loss: 0.507969856262207
recon_loss: 0.02765941433608532, dist_loss: 0.5961585640907288
recon_loss: 0.027659494429826736, dist_loss: 0.3405689597129822
recon_loss: 0.02765919640660286, dist_loss: 0.7983644604682922
recon_loss: 0.027659302577376366, dist_loss: 0.8899368047714233
recon_loss: 0.027658509090542793, dist_loss: 1.009530782699585
recon_loss: 0.02765825390815735, dist_loss: 0.3327043652534485
recon_loss: 0.02765788696706295, dist_loss: 1.0030521154403687
recon_loss: 0.027657808735966682, dist_loss: 0.9725732803344727
recon_loss: 0.027658144012093544, dist_loss: 0.5929470658302307
recon_loss: 0.027657944709062576, dist_loss: 0.578321099281311
recon_loss: 0.02765895240008831, dist_loss: 1.0275475978851318
recon_loss: 0.027658959850668907, dist_loss: 0.6382065415382385
recon_loss: 0.02765997312963009, dist_loss: 0.7717452645301819
recon_loss: 0.027659432962536812, dist_loss: 0.8671905994415283
recon_loss: 0.027659256011247635, dist_loss: 0.47250911593437195
recon_loss: 0.027659321203827858, dist_loss: 0.5235952138900757
recon_loss: 0.0276578888297081, dist_loss: 0.3392066955566406
recon_loss: 0.027658550068736076, dist_loss: 0.44261130690574646
recon_loss: 0.02765766903758049, dist_loss: 0.2693033516407013
recon_loss: 0.027657704427838326, dist_loss: 0.8769038915634155
recon_loss: 0.027659086510539055, dist_loss: 0.45159608125686646
recon_loss: 0.027660047635436058, dist_loss: 0.46165281534194946
recon_loss: 0.027660876512527466, dist_loss: 0.5824621319770813
recon_loss: 0.027661241590976715, dist_loss: 1.2794387340545654
recon_loss: 0.027661021798849106, dist_loss: 0.5546498894691467
recon_loss: 0.027660736814141273, dist_loss: 0.8121110200881958
recon_loss: 0.027660047635436058, dist_loss: 0.7230762839317322
recon_loss: 0.0276589784771204, dist_loss: 0.3274587392807007
recon_loss: 0.027658894658088684, dist_loss: 1.1323509216308594
recon_loss: 0.027658473700284958, dist_loss: 0.48165032267570496
recon_loss: 0.027658499777317047, dist_loss: 0.7064146995544434
recon_loss: 0.027658455073833466, dist_loss: 0.8979240655899048
recon_loss: 0.02765778638422489, dist_loss: 0.49564266204833984
recon_loss: 0.027658293023705482, dist_loss: 0.40961289405822754
recon_loss: 0.02765858918428421, dist_loss: 0.8900713324546814
recon_loss: 0.02766016125679016, dist_loss: 0.9105244874954224
recon_loss: 0.027661804109811783, dist_loss: 0.5052564740180969
recon_loss: 0.02766340784728527, dist_loss: 0.5294395089149475
recon_loss: 0.02766573429107666, dist_loss: 0.4437568783760071
recon_loss: 0.027666756883263588, dist_loss: 0.8873275518417358
recon_loss: 0.027668844908475876, dist_loss: 0.6957569122314453
recon_loss: 0.02766791172325611, dist_loss: 0.6669291257858276
recon_loss: 0.027669347822666168, dist_loss: 1.1411125659942627
recon_loss: 0.027666987851262093, dist_loss: 0.9505721926689148
recon_loss: 0.027664992958307266, dist_loss: 0.5739068984985352
recon_loss: 0.027664344757795334, dist_loss: 0.5706489086151123
recon_loss: 0.02766149677336216, dist_loss: 0.38609206676483154
recon_loss: 0.027662554755806923, dist_loss: 1.1572600603103638
recon_loss: 0.027659766376018524, dist_loss: 0.9384296536445618
recon_loss: 0.02766069397330284, dist_loss: 0.43594396114349365
recon_loss: 0.027659641578793526, dist_loss: 0.7200337648391724
recon_loss: 0.027659155428409576, dist_loss: 0.6834355592727661
recon_loss: 0.027660399675369263, dist_loss: 0.85658860206604
recon_loss: 0.027658889070153236, dist_loss: 0.5332353115081787
recon_loss: 0.027660228312015533, dist_loss: 0.4615737497806549
recon_loss: 0.027658013626933098, dist_loss: 0.44595861434936523
recon_loss: 0.027658706530928612, dist_loss: 0.6010209321975708
recon_loss: 0.0276581272482872, dist_loss: 0.5591532588005066
recon_loss: 0.027656598016619682, dist_loss: 0.7833952903747559
recon_loss: 0.02765836752951145, dist_loss: 0.5692758560180664
recon_loss: 0.02765539288520813, dist_loss: 0.6765308380126953
recon_loss: 0.02765798009932041, dist_loss: 0.5708638429641724
recon_loss: 0.02765609696507454, dist_loss: 0.8108831644058228
recon_loss: 0.02765682525932789, dist_loss: 0.5916398167610168
recon_loss: 0.027657242491841316, dist_loss: 0.5013238191604614
recon_loss: 0.02765478752553463, dist_loss: 0.8107308745384216
recon_loss: 0.027655551210045815, dist_loss: 0.8686004877090454
recon_loss: 0.0276557058095932, dist_loss: 0.8777686953544617
recon_loss: 0.027656840160489082, dist_loss: 0.6486915349960327
recon_loss: 0.02765747532248497, dist_loss: 0.8796215057373047
recon_loss: 0.027658142149448395, dist_loss: 0.4113440215587616
recon_loss: 0.027659352868795395, dist_loss: 0.8250688910484314
recon_loss: 0.027659166604280472, dist_loss: 0.345991849899292
recon_loss: 0.027659432962536812, dist_loss: 0.7723169326782227
recon_loss: 0.02765788324177265, dist_loss: 0.7864375114440918
recon_loss: 0.027657389640808105, dist_loss: 0.5359830260276794
recon_loss: 0.027656394988298416, dist_loss: 0.5423457622528076
recon_loss: 0.027656234800815582, dist_loss: 0.908964216709137
recon_loss: 0.027657128870487213, dist_loss: 1.5744049549102783
recon_loss: 0.027658674865961075, dist_loss: 0.43418121337890625
recon_loss: 0.027661118656396866, dist_loss: 0.45415955781936646
recon_loss: 0.027663342654705048, dist_loss: 0.3554452359676361
recon_loss: 0.027664929628372192, dist_loss: 0.9050926566123962
recon_loss: 0.027665523812174797, dist_loss: 0.8529552221298218
recon_loss: 0.0276651494204998, dist_loss: 0.7956511378288269
recon_loss: 0.027663571760058403, dist_loss: 0.9143665432929993
recon_loss: 0.027661465108394623, dist_loss: 0.4976242780685425
recon_loss: 0.02765979990363121, dist_loss: 0.7512742280960083
recon_loss: 0.027658702805638313, dist_loss: 0.5927595496177673
recon_loss: 0.02765788324177265, dist_loss: 0.7576594948768616
recon_loss: 0.027657320722937584, dist_loss: 0.7078747153282166
recon_loss: 0.027656743302941322, dist_loss: 0.6422135829925537
recon_loss: 0.02765575237572193, dist_loss: 0.49965178966522217
recon_loss: 0.027654793113470078, dist_loss: 0.3822358548641205
recon_loss: 0.027653999626636505, dist_loss: 0.4106619358062744
recon_loss: 0.02765391767024994, dist_loss: 0.6989896297454834
recon_loss: 0.027654599398374557, dist_loss: 0.50643390417099
recon_loss: 0.027654269710183144, dist_loss: 0.6424219608306885
recon_loss: 0.027654631063342094, dist_loss: 0.46457579731941223
recon_loss: 0.027654429897665977, dist_loss: 0.4553685784339905
recon_loss: 0.027653861790895462, dist_loss: 0.8255019187927246
recon_loss: 0.027654292061924934, dist_loss: 0.8803337216377258
recon_loss: 0.027654044330120087, dist_loss: 0.9260857701301575
recon_loss: 0.02765439823269844, dist_loss: 0.6162219047546387
recon_loss: 0.02765505015850067, dist_loss: 0.40983861684799194
recon_loss: 0.027653180062770844, dist_loss: 0.3156341314315796
recon_loss: 0.027655353769659996, dist_loss: 0.822492241859436
recon_loss: 0.027653632685542107, dist_loss: 0.9294540882110596
Pre-training Epoch 94:  37%|███▋      | 137/367 [00:00<00:01, 157.34it/s]Pre-training Epoch 94:  42%|████▏     | 153/367 [00:00<00:01, 155.13it/s]Pre-training Epoch 94:  47%|████▋     | 171/367 [00:01<00:01, 161.11it/s]Pre-training Epoch 94:  51%|█████     | 188/367 [00:01<00:01, 163.59it/s]Pre-training Epoch 94:  56%|█████▌    | 205/367 [00:01<00:00, 165.34it/s]Pre-training Epoch 94:  60%|██████    | 222/367 [00:01<00:00, 165.20it/s]Pre-training Epoch 94:  65%|██████▌   | 240/367 [00:01<00:00, 169.24it/s]recon_loss: 0.02765427716076374, dist_loss: 0.9166941046714783
recon_loss: 0.027653368189930916, dist_loss: 0.6325745582580566
recon_loss: 0.027652617543935776, dist_loss: 0.7163227796554565
recon_loss: 0.027652641758322716, dist_loss: 0.7125158309936523
recon_loss: 0.027651358395814896, dist_loss: 0.5631122589111328
recon_loss: 0.02765245921909809, dist_loss: 0.8459384441375732
recon_loss: 0.027651628479361534, dist_loss: 0.44520944356918335
recon_loss: 0.027653345838189125, dist_loss: 0.7824679613113403
recon_loss: 0.027653614059090614, dist_loss: 1.287084937095642
recon_loss: 0.027653740718960762, dist_loss: 1.1469939947128296
recon_loss: 0.027656733989715576, dist_loss: 1.132866382598877
recon_loss: 0.02765573188662529, dist_loss: 0.7191498875617981
recon_loss: 0.02765759825706482, dist_loss: 0.642217218875885
recon_loss: 0.02765829674899578, dist_loss: 0.39415282011032104
recon_loss: 0.027657799422740936, dist_loss: 0.8500468134880066
recon_loss: 0.027657780796289444, dist_loss: 0.6204005479812622
recon_loss: 0.027656804770231247, dist_loss: 0.5145883560180664
recon_loss: 0.027656806632876396, dist_loss: 0.7180565595626831
recon_loss: 0.027657397091388702, dist_loss: 0.672701895236969
recon_loss: 0.027659861370921135, dist_loss: 0.3227219581604004
recon_loss: 0.027660580351948738, dist_loss: 0.6144673824310303
recon_loss: 0.027661679312586784, dist_loss: 0.40304502844810486
recon_loss: 0.02766154333949089, dist_loss: 0.6211481094360352
recon_loss: 0.027659818530082703, dist_loss: 0.7518154382705688
recon_loss: 0.027659332379698753, dist_loss: 0.6640444993972778
recon_loss: 0.027656903490424156, dist_loss: 0.7949464321136475
recon_loss: 0.027656113728880882, dist_loss: 0.5151620507240295
recon_loss: 0.027654612436890602, dist_loss: 0.5037081837654114
recon_loss: 0.02765452302992344, dist_loss: 0.5572146773338318
recon_loss: 0.027653692290186882, dist_loss: 1.040761947631836
recon_loss: 0.02765270695090294, dist_loss: 1.0158932209014893
recon_loss: 0.02765277773141861, dist_loss: 0.8534683585166931
recon_loss: 0.027651656419038773, dist_loss: 0.8299705982208252
recon_loss: 0.027651574462652206, dist_loss: 0.5393484234809875
recon_loss: 0.027651479467749596, dist_loss: 0.5429670810699463
recon_loss: 0.027651701122522354, dist_loss: 0.7221891283988953
recon_loss: 0.027652202174067497, dist_loss: 0.5997979640960693
recon_loss: 0.02765253372490406, dist_loss: 0.6415755748748779
recon_loss: 0.02765306457877159, dist_loss: 0.4736853241920471
recon_loss: 0.027653198689222336, dist_loss: 0.7065342664718628
recon_loss: 0.02765253745019436, dist_loss: 0.33760780096054077
recon_loss: 0.02765200100839138, dist_loss: 0.5595684051513672
recon_loss: 0.027651110664010048, dist_loss: 1.4280496835708618
recon_loss: 0.02765057235956192, dist_loss: 0.7511019110679626
recon_loss: 0.027650155127048492, dist_loss: 0.5273316502571106
recon_loss: 0.027649907395243645, dist_loss: 0.8221496343612671
recon_loss: 0.027649959549307823, dist_loss: 0.80789715051651
recon_loss: 0.027649447321891785, dist_loss: 0.8459615111351013
recon_loss: 0.02765057235956192, dist_loss: 0.68546462059021
recon_loss: 0.027649691328406334, dist_loss: 0.47881945967674255
recon_loss: 0.027650155127048492, dist_loss: 0.8029662370681763
recon_loss: 0.027650555595755577, dist_loss: 0.5087679624557495
recon_loss: 0.02764967828989029, dist_loss: 0.574078381061554
recon_loss: 0.027650130912661552, dist_loss: 0.42651528120040894
recon_loss: 0.027649441733956337, dist_loss: 0.7386342883110046
recon_loss: 0.027650056406855583, dist_loss: 1.2053442001342773
recon_loss: 0.02764907293021679, dist_loss: 0.6012247204780579
recon_loss: 0.027649933472275734, dist_loss: 0.6808232069015503
recon_loss: 0.027649052441120148, dist_loss: 0.3408231735229492
recon_loss: 0.027648918330669403, dist_loss: 0.30693209171295166
recon_loss: 0.02765023708343506, dist_loss: 0.3447284996509552
recon_loss: 0.027647754177451134, dist_loss: 0.9874001741409302
recon_loss: 0.027648789808154106, dist_loss: 0.34392398595809937
recon_loss: 0.02764863148331642, dist_loss: 0.5908844470977783
recon_loss: 0.027647703886032104, dist_loss: 0.600435733795166
recon_loss: 0.027648761868476868, dist_loss: 0.6853746175765991
recon_loss: 0.027647623792290688, dist_loss: 0.36318495869636536
recon_loss: 0.02764909341931343, dist_loss: 0.663365364074707
recon_loss: 0.02764865756034851, dist_loss: 1.06769597530365
recon_loss: 0.02764720469713211, dist_loss: 0.6535749435424805
recon_loss: 0.02764934115111828, dist_loss: 0.7753360867500305
recon_loss: 0.02764727734029293, dist_loss: 0.6193819642066956
recon_loss: 0.027647830545902252, dist_loss: 0.45847728848457336
recon_loss: 0.027647558599710464, dist_loss: 0.5306622385978699
recon_loss: 0.027646338567137718, dist_loss: 0.3392831087112427
recon_loss: 0.027647441253066063, dist_loss: 0.6931068897247314
recon_loss: 0.027646953240036964, dist_loss: 0.5028599500656128
recon_loss: 0.02764681912958622, dist_loss: 0.7461095452308655
recon_loss: 0.027647770941257477, dist_loss: 0.5449490547180176
recon_loss: 0.02764725685119629, dist_loss: 0.606171727180481
recon_loss: 0.027647489681839943, dist_loss: 0.4036528766155243
recon_loss: 0.027647409588098526, dist_loss: 0.3257518708705902
recon_loss: 0.0276472270488739, dist_loss: 0.881657600402832
recon_loss: 0.027647128328680992, dist_loss: 0.255058228969574
recon_loss: 0.027647001668810844, dist_loss: 0.5521881580352783
recon_loss: 0.027647048234939575, dist_loss: 0.9991778135299683
recon_loss: 0.02764710783958435, dist_loss: 0.318653404712677
recon_loss: 0.027647029608488083, dist_loss: 0.7592445015907288
recon_loss: 0.027646902948617935, dist_loss: 0.30494993925094604
recon_loss: 0.027647143229842186, dist_loss: 0.5232045650482178
recon_loss: 0.02764706127345562, dist_loss: 0.917059600353241
recon_loss: 0.02764683961868286, dist_loss: 0.6423565149307251
recon_loss: 0.02764693833887577, dist_loss: 0.6365479230880737
recon_loss: 0.0276462584733963, dist_loss: 0.5204251408576965
recon_loss: 0.027646441012620926, dist_loss: 0.5952903032302856
recon_loss: 0.027645999565720558, dist_loss: 0.6604695320129395
recon_loss: 0.027646835893392563, dist_loss: 0.5567619800567627
recon_loss: 0.027647322043776512, dist_loss: 0.2979191243648529
recon_loss: 0.027648158371448517, dist_loss: 0.5227537155151367
recon_loss: 0.02764960005879402, dist_loss: 0.2913588285446167
recon_loss: 0.027649562805891037, dist_loss: 0.9555153846740723
recon_loss: 0.027650026604533195, dist_loss: 0.3888103663921356
recon_loss: 0.02765045501291752, dist_loss: 0.5952330231666565
recon_loss: 0.027649926021695137, dist_loss: 0.4572882652282715
recon_loss: 0.027650531381368637, dist_loss: 1.2041559219360352
recon_loss: 0.027648858726024628, dist_loss: 0.5480995178222656
recon_loss: 0.027647871524095535, dist_loss: 0.6518898010253906
recon_loss: 0.027647461742162704, dist_loss: 0.6660670638084412
recon_loss: 0.027646366506814957, dist_loss: 0.579275906085968
recon_loss: 0.027646616101264954, dist_loss: 0.9089416265487671
recon_loss: 0.027646267786622047, dist_loss: 0.7005140781402588
recon_loss: 0.02764616161584854, dist_loss: 0.5115207433700562
recon_loss: 0.02764616347849369, dist_loss: 0.8120497465133667
recon_loss: 0.027646305039525032, dist_loss: 0.4713239073753357
recon_loss: 0.02764672413468361, dist_loss: 0.31381383538246155
recon_loss: 0.027646875008940697, dist_loss: 0.866782009601593
recon_loss: 0.027647284790873528, dist_loss: 0.5461111664772034
recon_loss: 0.02764742635190487, dist_loss: 0.6934390664100647
recon_loss: 0.027647564187645912, dist_loss: 0.5246068835258484
recon_loss: 0.027646981179714203, dist_loss: 0.6387565732002258
recon_loss: 0.027646508067846298, dist_loss: 0.4361773729324341
recon_loss: 0.027646081522107124, dist_loss: 0.4809425175189972
recon_loss: 0.027645839378237724, dist_loss: 0.6587021946907043
recon_loss: 0.027645282447338104, dist_loss: 0.45440855622291565
recon_loss: 0.027644691988825798, dist_loss: 0.6170698404312134
recon_loss: 0.02764398604631424, dist_loss: 0.8030410408973694
recon_loss: 0.027643989771604538, dist_loss: 0.5501358509063721
recon_loss: 0.027643369510769844, dist_loss: 0.9234709739685059
Pre-training Epoch 94:  71%|███████   | 259/367 [00:01<00:00, 172.77it/s]Pre-training Epoch 94:  76%|███████▌  | 278/367 [00:01<00:00, 175.53it/s]Pre-training Epoch 94:  81%|████████  | 297/367 [00:01<00:00, 176.98it/s]Pre-training Epoch 94:  86%|████████▌ | 316/367 [00:01<00:00, 178.05it/s]Pre-training Epoch 94:  91%|█████████ | 334/367 [00:01<00:00, 177.25it/s]Pre-training Epoch 94:  96%|█████████▌| 352/367 [00:02<00:00, 167.52it/s]Pre-training Epoch 94: 100%|██████████| 367/367 [00:02<00:00, 166.57it/s]
recon_loss: 0.027643198147416115, dist_loss: 0.4715195298194885
recon_loss: 0.027642855420708656, dist_loss: 0.4669845402240753
recon_loss: 0.0276425089687109, dist_loss: 0.8113695383071899
recon_loss: 0.027642739936709404, dist_loss: 0.8728739619255066
recon_loss: 0.02764204889535904, dist_loss: 1.0170929431915283
recon_loss: 0.027641959488391876, dist_loss: 0.7925425171852112
recon_loss: 0.027642369270324707, dist_loss: 0.6501193046569824
recon_loss: 0.027642207220196724, dist_loss: 0.5658124685287476
recon_loss: 0.027642499655485153, dist_loss: 0.7349199056625366
recon_loss: 0.0276426263153553, dist_loss: 0.30986088514328003
recon_loss: 0.0276425089687109, dist_loss: 0.6607780456542969
recon_loss: 0.02764250338077545, dist_loss: 0.4112692177295685
recon_loss: 0.02764224261045456, dist_loss: 0.49889639019966125
recon_loss: 0.02764260768890381, dist_loss: 0.6220592260360718
recon_loss: 0.027642838656902313, dist_loss: 0.580939769744873
recon_loss: 0.0276437196880579, dist_loss: 1.0255184173583984
recon_loss: 0.027645187452435493, dist_loss: 0.38100582361221313
recon_loss: 0.027646636590361595, dist_loss: 0.9346108436584473
recon_loss: 0.027648240327835083, dist_loss: 0.9026443958282471
recon_loss: 0.027648378163576126, dist_loss: 1.0160112380981445
recon_loss: 0.02764856070280075, dist_loss: 0.429849237203598
recon_loss: 0.02764815092086792, dist_loss: 0.5526089072227478
recon_loss: 0.027647795155644417, dist_loss: 0.8743168711662292
recon_loss: 0.02764761447906494, dist_loss: 0.4271717667579651
recon_loss: 0.02764732949435711, dist_loss: 1.1946215629577637
recon_loss: 0.027647826820611954, dist_loss: 0.9206932187080383
recon_loss: 0.02764810621738434, dist_loss: 1.1882565021514893
recon_loss: 0.02764981798827648, dist_loss: 0.6057382822036743
recon_loss: 0.027650510892271996, dist_loss: 0.6306256055831909
recon_loss: 0.02765107899904251, dist_loss: 0.5694162845611572
recon_loss: 0.027649812400341034, dist_loss: 0.7676733732223511
recon_loss: 0.02764805033802986, dist_loss: 0.5916319489479065
recon_loss: 0.027646305039525032, dist_loss: 0.4640948176383972
recon_loss: 0.027644604444503784, dist_loss: 0.5962673425674438
recon_loss: 0.02764434926211834, dist_loss: 0.7390475273132324
recon_loss: 0.027644531801342964, dist_loss: 0.7410026788711548
recon_loss: 0.027645636349916458, dist_loss: 0.8467996120452881
recon_loss: 0.027647022157907486, dist_loss: 0.5835828185081482
recon_loss: 0.027648307383060455, dist_loss: 1.2591273784637451
recon_loss: 0.02765052020549774, dist_loss: 1.602911353111267
recon_loss: 0.027653692290186882, dist_loss: 0.6792919039726257
recon_loss: 0.027656415477395058, dist_loss: 1.1638586521148682
recon_loss: 0.027659662067890167, dist_loss: 0.6893455982208252
recon_loss: 0.02766146883368492, dist_loss: 0.637086033821106
recon_loss: 0.027661090716719627, dist_loss: 0.7481852769851685
recon_loss: 0.02766086719930172, dist_loss: 0.4672425389289856
recon_loss: 0.02765974961221218, dist_loss: 0.6058096289634705
recon_loss: 0.027659788727760315, dist_loss: 0.8903754949569702
recon_loss: 0.02765859104692936, dist_loss: 0.46965670585632324
recon_loss: 0.027656877413392067, dist_loss: 0.9046807289123535
recon_loss: 0.027654528617858887, dist_loss: 0.5285325646400452
recon_loss: 0.02765076421201229, dist_loss: 0.7840999364852905
recon_loss: 0.02764810249209404, dist_loss: 1.0453611612319946
recon_loss: 0.02764645777642727, dist_loss: 0.29436641931533813
recon_loss: 0.027644818648695946, dist_loss: 0.5476802587509155
recon_loss: 0.027644289657473564, dist_loss: 0.7164602875709534
recon_loss: 0.027643898501992226, dist_loss: 0.5262895226478577
recon_loss: 0.027643589302897453, dist_loss: 0.567524254322052
recon_loss: 0.027643941342830658, dist_loss: 0.5530252456665039
recon_loss: 0.027643907815217972, dist_loss: 0.6571562886238098
recon_loss: 0.027644263580441475, dist_loss: 0.4900842010974884
recon_loss: 0.02764492854475975, dist_loss: 0.4395626485347748
recon_loss: 0.027645202353596687, dist_loss: 0.5155110359191895
recon_loss: 0.027646159753203392, dist_loss: 0.6314283609390259
recon_loss: 0.0276462621986866, dist_loss: 0.7675275802612305
recon_loss: 0.027645643800497055, dist_loss: 0.4076575040817261
recon_loss: 0.02764482982456684, dist_loss: 0.34353235363960266
recon_loss: 0.027643967419862747, dist_loss: 0.6517984867095947
recon_loss: 0.027643272653222084, dist_loss: 0.48677653074264526
recon_loss: 0.027642445638775826, dist_loss: 0.47639021277427673
recon_loss: 0.027641966938972473, dist_loss: 0.7107762694358826
recon_loss: 0.027641242370009422, dist_loss: 0.4689292311668396
recon_loss: 0.027640657499432564, dist_loss: 0.5617268085479736
recon_loss: 0.027640487998723984, dist_loss: 0.49028480052948
recon_loss: 0.027641022577881813, dist_loss: 0.46018901467323303
recon_loss: 0.027640586718916893, dist_loss: 0.3891220688819885
recon_loss: 0.027641259133815765, dist_loss: 0.6109859943389893
recon_loss: 0.027641162276268005, dist_loss: 0.6697392463684082
recon_loss: 0.02764063887298107, dist_loss: 0.5420660972595215
recon_loss: 0.027641301974654198, dist_loss: 0.6250369548797607
recon_loss: 0.027640502899885178, dist_loss: 0.6126784086227417
recon_loss: 0.027641072869300842, dist_loss: 0.6352390050888062
recon_loss: 0.02764020673930645, dist_loss: 0.7818655967712402
recon_loss: 0.02764003723859787, dist_loss: 0.47121256589889526
recon_loss: 0.02764006517827511, dist_loss: 0.3235563039779663
recon_loss: 0.027639728039503098, dist_loss: 0.594964861869812
recon_loss: 0.027640365064144135, dist_loss: 0.466680645942688
recon_loss: 0.0276398453861475, dist_loss: 0.4265277683734894
recon_loss: 0.02764008566737175, dist_loss: 0.36209267377853394
recon_loss: 0.027640169486403465, dist_loss: 0.9694082736968994
recon_loss: 0.02763945795595646, dist_loss: 0.43417078256607056
recon_loss: 0.02763962373137474, dist_loss: 0.5141100883483887
recon_loss: 0.02763923816382885, dist_loss: 0.8006587028503418
recon_loss: 0.027639169245958328, dist_loss: 0.5002841949462891
recon_loss: 0.027638966217637062, dist_loss: 0.6103848814964294
recon_loss: 0.027638306841254234, dist_loss: 0.5192830562591553
recon_loss: 0.027637921273708344, dist_loss: 0.7033541202545166
recon_loss: 0.027637967839837074, dist_loss: 0.7587158679962158
recon_loss: 0.027637824416160583, dist_loss: 0.52376389503479
recon_loss: 0.02763977274298668, dist_loss: 0.8626548647880554
recon_loss: 0.027638614177703857, dist_loss: 0.4864113926887512
recon_loss: 0.02764110267162323, dist_loss: 0.8746988773345947
recon_loss: 0.02763913758099079, dist_loss: 0.33381426334381104
recon_loss: 0.02763967029750347, dist_loss: 0.36026498675346375
recon_loss: 0.027639027684926987, dist_loss: 0.8552983403205872
recon_loss: 0.02763761207461357, dist_loss: 0.5627696514129639
recon_loss: 0.027638399973511696, dist_loss: 0.5390148758888245
recon_loss: 0.027636781334877014, dist_loss: 0.5465028285980225
recon_loss: 0.02763691358268261, dist_loss: 0.5965092778205872
recon_loss: 0.02763698250055313, dist_loss: 0.5620918273925781
recon_loss: 0.02763615921139717, dist_loss: 1.3474286794662476
Pre-training Epoch 95:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 95:   4%|▍         | 16/367 [00:00<00:02, 156.81it/s]Pre-training Epoch 95:   9%|▉         | 33/367 [00:00<00:02, 161.31it/s]Pre-training Epoch 95:  14%|█▎        | 50/367 [00:00<00:02, 156.78it/s]Pre-training Epoch 95:  18%|█▊        | 66/367 [00:00<00:01, 155.96it/s]Pre-training Epoch 95:  22%|██▏       | 82/367 [00:00<00:01, 152.13it/s]Pre-training Epoch 95:  27%|██▋       | 98/367 [00:00<00:01, 151.98it/s]Pre-training Epoch 95:  31%|███       | 114/367 [00:00<00:01, 152.42it/s]recon_loss: 0.027636293321847916, dist_loss: 0.5903415679931641
recon_loss: 0.027635425329208374, dist_loss: 0.6936043500900269
recon_loss: 0.027635520324110985, dist_loss: 1.1469085216522217
recon_loss: 0.02763526700437069, dist_loss: 0.30311447381973267
recon_loss: 0.027635401114821434, dist_loss: 0.4638337194919586
recon_loss: 0.027635538950562477, dist_loss: 0.44556641578674316
recon_loss: 0.027635276317596436, dist_loss: 0.496566504240036
recon_loss: 0.02763565629720688, dist_loss: 0.8048104643821716
recon_loss: 0.02763553522527218, dist_loss: 0.8755031824111938
recon_loss: 0.02763543650507927, dist_loss: 0.7065551280975342
recon_loss: 0.027635183185338974, dist_loss: 0.5387613773345947
recon_loss: 0.027635470032691956, dist_loss: 0.5524309873580933
recon_loss: 0.02763543650507927, dist_loss: 0.5264993906021118
recon_loss: 0.0276363305747509, dist_loss: 0.38840940594673157
recon_loss: 0.027636632323265076, dist_loss: 0.5501946210861206
recon_loss: 0.027637215331196785, dist_loss: 0.8285011649131775
recon_loss: 0.027637772262096405, dist_loss: 0.6643800139427185
recon_loss: 0.027638306841254234, dist_loss: 0.6855498552322388
recon_loss: 0.027639292180538177, dist_loss: 0.5989251732826233
recon_loss: 0.02763979695737362, dist_loss: 0.802735447883606
recon_loss: 0.02764108031988144, dist_loss: 0.7433418035507202
recon_loss: 0.02764020301401615, dist_loss: 0.6821430325508118
recon_loss: 0.027639878913760185, dist_loss: 0.7372145652770996
recon_loss: 0.027639217674732208, dist_loss: 0.5132460594177246
recon_loss: 0.027637725695967674, dist_loss: 0.5275483727455139
recon_loss: 0.027637308463454247, dist_loss: 0.5614123344421387
recon_loss: 0.027636243030428886, dist_loss: 0.7118125557899475
recon_loss: 0.02763611264526844, dist_loss: 0.4930022954940796
recon_loss: 0.02763611078262329, dist_loss: 0.5751777291297913
recon_loss: 0.027636779472231865, dist_loss: 0.5118687152862549
recon_loss: 0.02763812430202961, dist_loss: 0.45136094093322754
recon_loss: 0.02763999067246914, dist_loss: 0.9652073979377747
recon_loss: 0.027641087770462036, dist_loss: 0.40953660011291504
recon_loss: 0.027641762048006058, dist_loss: 0.3978704512119293
recon_loss: 0.02764185331761837, dist_loss: 0.7516434788703918
recon_loss: 0.02764216810464859, dist_loss: 0.5836988687515259
recon_loss: 0.02764192782342434, dist_loss: 0.5749344825744629
recon_loss: 0.027641652151942253, dist_loss: 0.9046775698661804
recon_loss: 0.02764163911342621, dist_loss: 1.2169926166534424
recon_loss: 0.027640942484140396, dist_loss: 0.5921115279197693
recon_loss: 0.027640316635370255, dist_loss: 0.7086897492408752
recon_loss: 0.0276388768106699, dist_loss: 0.7237979769706726
recon_loss: 0.027637828141450882, dist_loss: 0.7223302125930786
recon_loss: 0.027637120336294174, dist_loss: 0.37906891107559204
recon_loss: 0.02763620764017105, dist_loss: 0.8617725372314453
recon_loss: 0.027635421603918076, dist_loss: 0.4134824872016907
recon_loss: 0.027634840458631516, dist_loss: 0.537407636642456
recon_loss: 0.027634482830762863, dist_loss: 0.7471712231636047
recon_loss: 0.027633970603346825, dist_loss: 0.4772036671638489
recon_loss: 0.027633698657155037, dist_loss: 0.483332097530365
recon_loss: 0.02763359248638153, dist_loss: 0.454743891954422
recon_loss: 0.0276345144957304, dist_loss: 0.5516685247421265
recon_loss: 0.027635201811790466, dist_loss: 0.46634727716445923
recon_loss: 0.027636868879199028, dist_loss: 0.5434369444847107
recon_loss: 0.027637580409646034, dist_loss: 0.4959365129470825
recon_loss: 0.02763897180557251, dist_loss: 0.3266007602214813
recon_loss: 0.02763962373137474, dist_loss: 0.6904606819152832
recon_loss: 0.027639256790280342, dist_loss: 0.4693394899368286
recon_loss: 0.027638209983706474, dist_loss: 0.5940015316009521
recon_loss: 0.027637341991066933, dist_loss: 0.43745240569114685
recon_loss: 0.02763640321791172, dist_loss: 0.5692211389541626
recon_loss: 0.02763575315475464, dist_loss: 0.6297228336334229
recon_loss: 0.027635078877210617, dist_loss: 0.6195699572563171
recon_loss: 0.027634484693408012, dist_loss: 0.5755237340927124
recon_loss: 0.02763400413095951, dist_loss: 0.6702500581741333
recon_loss: 0.0276345144957304, dist_loss: 0.5318331122398376
recon_loss: 0.027634674683213234, dist_loss: 0.608218789100647
recon_loss: 0.027633430436253548, dist_loss: 0.482531875371933
recon_loss: 0.027633290737867355, dist_loss: 0.4309093952178955
recon_loss: 0.02763311378657818, dist_loss: 0.6494184136390686
recon_loss: 0.027633074671030045, dist_loss: 0.3554539084434509
recon_loss: 0.027633488178253174, dist_loss: 0.8029744625091553
recon_loss: 0.02763216570019722, dist_loss: 0.8524767756462097
recon_loss: 0.027633965015411377, dist_loss: 0.4785175025463104
recon_loss: 0.027632659301161766, dist_loss: 0.5832394957542419
recon_loss: 0.027634337544441223, dist_loss: 1.1223520040512085
recon_loss: 0.027634719386696815, dist_loss: 0.3723779320716858
recon_loss: 0.027633704245090485, dist_loss: 0.7547508478164673
recon_loss: 0.027635086327791214, dist_loss: 0.4167135953903198
recon_loss: 0.02763342298567295, dist_loss: 0.6822371482849121
recon_loss: 0.027633994817733765, dist_loss: 1.1054048538208008
recon_loss: 0.02763340063393116, dist_loss: 0.846327006816864
recon_loss: 0.027632681652903557, dist_loss: 0.8222642540931702
recon_loss: 0.027634024620056152, dist_loss: 0.591465413570404
recon_loss: 0.027633968740701675, dist_loss: 0.6190707683563232
recon_loss: 0.027635646983981133, dist_loss: 0.2768670618534088
recon_loss: 0.027636244893074036, dist_loss: 0.8072729110717773
recon_loss: 0.02763739414513111, dist_loss: 0.42318618297576904
recon_loss: 0.02763771452009678, dist_loss: 1.8419944047927856
recon_loss: 0.027637425810098648, dist_loss: 0.34422528743743896
recon_loss: 0.027637969702482224, dist_loss: 0.6752761602401733
recon_loss: 0.027637021616101265, dist_loss: 0.9216328859329224
recon_loss: 0.027637749910354614, dist_loss: 0.9046546220779419
recon_loss: 0.027636170387268066, dist_loss: 0.6423656344413757
recon_loss: 0.027633998543024063, dist_loss: 0.8350030183792114
recon_loss: 0.0276329442858696, dist_loss: 0.403980553150177
recon_loss: 0.02763255313038826, dist_loss: 0.7213802933692932
recon_loss: 0.027633346617221832, dist_loss: 0.34754714369773865
recon_loss: 0.027635421603918076, dist_loss: 0.9951176643371582
recon_loss: 0.027637140825390816, dist_loss: 0.8083922863006592
recon_loss: 0.027639390900731087, dist_loss: 0.8984323740005493
recon_loss: 0.027639998123049736, dist_loss: 0.5685052275657654
recon_loss: 0.02764120325446129, dist_loss: 0.6748077273368835
recon_loss: 0.027639469131827354, dist_loss: 0.6466906070709229
recon_loss: 0.027638845145702362, dist_loss: 0.37147223949432373
recon_loss: 0.027636714279651642, dist_loss: 0.44044601917266846
recon_loss: 0.027635319158434868, dist_loss: 0.7156816720962524
recon_loss: 0.027633914723992348, dist_loss: 0.6400535106658936
recon_loss: 0.02763262763619423, dist_loss: 0.6283930540084839
recon_loss: 0.027631867676973343, dist_loss: 0.5055636167526245
recon_loss: 0.027631700038909912, dist_loss: 0.6421027183532715
recon_loss: 0.027630962431430817, dist_loss: 0.4438086748123169
recon_loss: 0.027630822733044624, dist_loss: 0.583521842956543
recon_loss: 0.027630852535367012, dist_loss: 0.3937593698501587
recon_loss: 0.027630390599370003, dist_loss: 0.9694892764091492
recon_loss: 0.0276299100369215, dist_loss: 0.8171817064285278
recon_loss: 0.02762957662343979, dist_loss: 0.5682785511016846
recon_loss: 0.027629254385828972, dist_loss: 0.5719363689422607
recon_loss: 0.027628948912024498, dist_loss: 0.4658958911895752
recon_loss: 0.027628924697637558, dist_loss: 1.0742270946502686
recon_loss: 0.02762872539460659, dist_loss: 0.6866667866706848
recon_loss: 0.027628425508737564, dist_loss: 0.41903963685035706
recon_loss: 0.02762836031615734, dist_loss: 0.5720013976097107
recon_loss: 0.027628473937511444, dist_loss: 0.5306092500686646
recon_loss: 0.027628879994153976, dist_loss: 0.5047426819801331
recon_loss: 0.027629707008600235, dist_loss: 0.7663002610206604
recon_loss: 0.027630552649497986, dist_loss: 0.8508214950561523
recon_loss: 0.02763114683330059, dist_loss: 0.6094212532043457
Pre-training Epoch 95:  35%|███▌      | 130/367 [00:00<00:01, 152.81it/s]Pre-training Epoch 95:  40%|███▉      | 146/367 [00:00<00:01, 152.52it/s]Pre-training Epoch 95:  44%|████▍     | 162/367 [00:01<00:01, 151.39it/s]Pre-training Epoch 95:  49%|████▊     | 178/367 [00:01<00:01, 150.22it/s]Pre-training Epoch 95:  53%|█████▎    | 194/367 [00:01<00:01, 150.00it/s]Pre-training Epoch 95:  57%|█████▋    | 210/367 [00:01<00:01, 150.62it/s]Pre-training Epoch 95:  62%|██████▏   | 226/367 [00:01<00:00, 149.39it/s]Pre-training Epoch 95:  66%|██████▌   | 242/367 [00:01<00:00, 150.59it/s]recon_loss: 0.027631619945168495, dist_loss: 0.4928687512874603
recon_loss: 0.02763204462826252, dist_loss: 0.3967954218387604
recon_loss: 0.02763248234987259, dist_loss: 0.360759437084198
recon_loss: 0.027632202953100204, dist_loss: 1.0411438941955566
recon_loss: 0.027632128447294235, dist_loss: 0.5961574912071228
recon_loss: 0.027631614357233047, dist_loss: 0.8069206476211548
recon_loss: 0.02763095125555992, dist_loss: 0.49968406558036804
recon_loss: 0.027630509808659554, dist_loss: 0.7952835559844971
recon_loss: 0.027629708871245384, dist_loss: 1.3368394374847412
recon_loss: 0.027628974989056587, dist_loss: 0.6648259162902832
recon_loss: 0.02762872725725174, dist_loss: 0.7802573442459106
recon_loss: 0.027627764269709587, dist_loss: 0.624951958656311
recon_loss: 0.027627920731902122, dist_loss: 0.7048759460449219
recon_loss: 0.027627399191260338, dist_loss: 0.8031494617462158
recon_loss: 0.027627388015389442, dist_loss: 0.8801697492599487
recon_loss: 0.027627836912870407, dist_loss: 0.5120065808296204
recon_loss: 0.027628177776932716, dist_loss: 0.8696947693824768
recon_loss: 0.027628252282738686, dist_loss: 0.5417968034744263
recon_loss: 0.027627941220998764, dist_loss: 0.6954634189605713
recon_loss: 0.02762746438384056, dist_loss: 0.9605423212051392
recon_loss: 0.027627013623714447, dist_loss: 0.7267283797264099
recon_loss: 0.027626724913716316, dist_loss: 0.5236608982086182
recon_loss: 0.027626797556877136, dist_loss: 0.5660024881362915
recon_loss: 0.027627024799585342, dist_loss: 0.5186386108398438
recon_loss: 0.027627255767583847, dist_loss: 0.5840809345245361
recon_loss: 0.02762734517455101, dist_loss: 0.7103042602539062
recon_loss: 0.02762683667242527, dist_loss: 0.8295102715492249
recon_loss: 0.027626844123005867, dist_loss: 0.5782535076141357
recon_loss: 0.02762705832719803, dist_loss: 0.5777851343154907
recon_loss: 0.027627088129520416, dist_loss: 0.606063723564148
recon_loss: 0.027626829221844673, dist_loss: 0.41577744483947754
recon_loss: 0.027626777067780495, dist_loss: 0.5776338577270508
recon_loss: 0.027626752853393555, dist_loss: 0.3663822412490845
recon_loss: 0.027626756578683853, dist_loss: 0.5612820982933044
recon_loss: 0.027626946568489075, dist_loss: 0.6559061408042908
recon_loss: 0.027626659721136093, dist_loss: 0.6621707677841187
recon_loss: 0.02762669138610363, dist_loss: 0.5129608511924744
recon_loss: 0.027626724913716316, dist_loss: 0.5453442335128784
recon_loss: 0.02762618660926819, dist_loss: 0.5410228967666626
recon_loss: 0.02762709930539131, dist_loss: 0.8134763240814209
recon_loss: 0.027625922113656998, dist_loss: 0.5227482318878174
recon_loss: 0.027625763788819313, dist_loss: 0.4934404492378235
recon_loss: 0.02762638032436371, dist_loss: 0.7942075133323669
recon_loss: 0.027626119554042816, dist_loss: 0.66173255443573
recon_loss: 0.02762627974152565, dist_loss: 0.5033740997314453
recon_loss: 0.027625538408756256, dist_loss: 0.7306835651397705
recon_loss: 0.02762516774237156, dist_loss: 0.886228084564209
recon_loss: 0.027624722570180893, dist_loss: 0.5983657836914062
recon_loss: 0.02762446179986, dist_loss: 0.835667610168457
recon_loss: 0.02762432023882866, dist_loss: 0.7261567711830139
recon_loss: 0.027624446898698807, dist_loss: 0.554092288017273
recon_loss: 0.027624547481536865, dist_loss: 0.7400551438331604
recon_loss: 0.027624884620308876, dist_loss: 0.5299602746963501
recon_loss: 0.027624698355793953, dist_loss: 0.4968148469924927
recon_loss: 0.02762514352798462, dist_loss: 1.0763695240020752
recon_loss: 0.02762559801340103, dist_loss: 0.7810403108596802
recon_loss: 0.027625882998108864, dist_loss: 0.3218823969364166
recon_loss: 0.027626218274235725, dist_loss: 0.9868463277816772
recon_loss: 0.027625983580946922, dist_loss: 0.7266649603843689
recon_loss: 0.027625715360045433, dist_loss: 0.37267500162124634
recon_loss: 0.027625739574432373, dist_loss: 0.568459153175354
recon_loss: 0.027625367045402527, dist_loss: 0.6193394660949707
recon_loss: 0.02762663923203945, dist_loss: 0.5898370146751404
recon_loss: 0.027626413851976395, dist_loss: 0.8636945486068726
recon_loss: 0.027628226205706596, dist_loss: 0.5407320857048035
recon_loss: 0.027627483010292053, dist_loss: 0.5936002135276794
recon_loss: 0.027627287432551384, dist_loss: 0.48039814829826355
recon_loss: 0.027627455070614815, dist_loss: 0.5899139642715454
recon_loss: 0.027626441791653633, dist_loss: 0.9880641102790833
recon_loss: 0.02762693352997303, dist_loss: 0.6704289317131042
recon_loss: 0.027624858543276787, dist_loss: 0.6702790856361389
recon_loss: 0.027625039219856262, dist_loss: 0.5161443948745728
recon_loss: 0.027623647823929787, dist_loss: 0.7365578413009644
recon_loss: 0.027623336762189865, dist_loss: 0.6294539570808411
recon_loss: 0.02762371115386486, dist_loss: 0.40128254890441895
recon_loss: 0.027623040601611137, dist_loss: 0.3664715886116028
recon_loss: 0.027624109759926796, dist_loss: 0.6675910353660583
recon_loss: 0.027623726055026054, dist_loss: 0.37191176414489746
recon_loss: 0.027624158188700676, dist_loss: 0.39207714796066284
recon_loss: 0.02762417681515217, dist_loss: 0.5970794558525085
recon_loss: 0.02762364037334919, dist_loss: 0.31636011600494385
recon_loss: 0.027623850852251053, dist_loss: 0.7201305031776428
recon_loss: 0.027623217552900314, dist_loss: 1.027936339378357
recon_loss: 0.027622930705547333, dist_loss: 0.926074206829071
recon_loss: 0.027622874826192856, dist_loss: 0.5999209880828857
recon_loss: 0.027622118592262268, dist_loss: 1.155415654182434
recon_loss: 0.027621861547231674, dist_loss: 1.0213165283203125
recon_loss: 0.02762189507484436, dist_loss: 0.4497894048690796
recon_loss: 0.027621865272521973, dist_loss: 0.7119611501693726
recon_loss: 0.02762192115187645, dist_loss: 0.7217670679092407
recon_loss: 0.02762233093380928, dist_loss: 0.5701703429222107
recon_loss: 0.027621595188975334, dist_loss: 0.5936311483383179
recon_loss: 0.027621960267424583, dist_loss: 0.896868109703064
recon_loss: 0.02762148529291153, dist_loss: 0.6134733557701111
recon_loss: 0.02762158215045929, dist_loss: 0.3310227394104004
recon_loss: 0.027621887624263763, dist_loss: 0.44502994418144226
recon_loss: 0.027621785178780556, dist_loss: 0.8664001226425171
recon_loss: 0.02762211300432682, dist_loss: 0.369279146194458
recon_loss: 0.02762211672961712, dist_loss: 1.0402089357376099
recon_loss: 0.02762155421078205, dist_loss: 0.6330599784851074
recon_loss: 0.02762133628129959, dist_loss: 0.7050527334213257
recon_loss: 0.027621036395430565, dist_loss: 0.5589926242828369
recon_loss: 0.02762109600007534, dist_loss: 0.8022661805152893
recon_loss: 0.027620980516076088, dist_loss: 0.46180105209350586
recon_loss: 0.02762088179588318, dist_loss: 1.4080978631973267
recon_loss: 0.027620578184723854, dist_loss: 0.38201379776000977
recon_loss: 0.027620499953627586, dist_loss: 0.5019372701644897
recon_loss: 0.027620630338788033, dist_loss: 1.112725019454956
recon_loss: 0.0276210717856884, dist_loss: 1.1929659843444824
recon_loss: 0.0276210717856884, dist_loss: 0.8191296458244324
recon_loss: 0.02762082777917385, dist_loss: 0.5550297498703003
recon_loss: 0.027620799839496613, dist_loss: 0.6867772340774536
recon_loss: 0.027620645239949226, dist_loss: 0.4453107714653015
recon_loss: 0.02762061543762684, dist_loss: 1.028366208076477
recon_loss: 0.02762078121304512, dist_loss: 0.6119311451911926
recon_loss: 0.02762104943394661, dist_loss: 0.4576984643936157
recon_loss: 0.027621285989880562, dist_loss: 0.6601086854934692
recon_loss: 0.027621615678071976, dist_loss: 0.6269960403442383
recon_loss: 0.0276222862303257, dist_loss: 0.7414084076881409
recon_loss: 0.027622820809483528, dist_loss: 0.5864850282669067
recon_loss: 0.02762237749993801, dist_loss: 0.4947516918182373
recon_loss: 0.027622584253549576, dist_loss: 0.5558774471282959
recon_loss: 0.0276221614331007, dist_loss: 0.8697412014007568
recon_loss: 0.027622055262327194, dist_loss: 0.7375521063804626
recon_loss: 0.027621949091553688, dist_loss: 0.9166210293769836
recon_loss: 0.027622047811746597, dist_loss: 0.6695802211761475
recon_loss: 0.02762160263955593, dist_loss: 0.6802307367324829
recon_loss: 0.027621060609817505, dist_loss: 0.9170000553131104
Pre-training Epoch 95:  70%|███████   | 258/367 [00:01<00:00, 150.85it/s]Pre-training Epoch 95:  75%|███████▍  | 274/367 [00:01<00:00, 152.03it/s]Pre-training Epoch 95:  79%|███████▉  | 290/367 [00:01<00:00, 152.54it/s]Pre-training Epoch 95:  83%|████████▎ | 306/367 [00:02<00:00, 152.60it/s]Pre-training Epoch 95:  88%|████████▊ | 322/367 [00:02<00:00, 154.46it/s]Pre-training Epoch 95:  93%|█████████▎| 341/367 [00:02<00:00, 162.86it/s]Pre-training Epoch 95:  98%|█████████▊| 358/367 [00:02<00:00, 159.42it/s]Pre-training Epoch 95: 100%|██████████| 367/367 [00:02<00:00, 153.89it/s]
recon_loss: 0.027620898559689522, dist_loss: 0.2462635338306427
recon_loss: 0.02762141451239586, dist_loss: 0.31844791769981384
recon_loss: 0.02762092649936676, dist_loss: 0.8013978004455566
recon_loss: 0.027621783316135406, dist_loss: 0.577128529548645
recon_loss: 0.027621375396847725, dist_loss: 0.6105955839157104
recon_loss: 0.027623256668448448, dist_loss: 0.35375598073005676
recon_loss: 0.027622461318969727, dist_loss: 0.6448788642883301
recon_loss: 0.027622923254966736, dist_loss: 0.7998659014701843
recon_loss: 0.027623672038316727, dist_loss: 0.6510785818099976
recon_loss: 0.02762063406407833, dist_loss: 1.2140741348266602
recon_loss: 0.027623284608125687, dist_loss: 0.5761368274688721
recon_loss: 0.027621278539299965, dist_loss: 1.464184045791626
recon_loss: 0.027622917667031288, dist_loss: 0.40107834339141846
recon_loss: 0.027623333036899567, dist_loss: 0.6099331378936768
recon_loss: 0.027622172608971596, dist_loss: 0.44381314516067505
recon_loss: 0.027624284848570824, dist_loss: 0.5660476684570312
recon_loss: 0.027623316273093224, dist_loss: 0.435844361782074
recon_loss: 0.02762555703520775, dist_loss: 1.0806059837341309
recon_loss: 0.027627062052488327, dist_loss: 0.7481658458709717
recon_loss: 0.027627266943454742, dist_loss: 0.5946481227874756
recon_loss: 0.027629876509308815, dist_loss: 0.8550660610198975
recon_loss: 0.02762776054441929, dist_loss: 0.4643709063529968
recon_loss: 0.027628248557448387, dist_loss: 0.8181759715080261
recon_loss: 0.027626395225524902, dist_loss: 0.7733532190322876
recon_loss: 0.02762565203011036, dist_loss: 0.4088115692138672
recon_loss: 0.027625543996691704, dist_loss: 0.9424813389778137
recon_loss: 0.027621565386652946, dist_loss: 0.7308828830718994
recon_loss: 0.027624616399407387, dist_loss: 0.635582685470581
recon_loss: 0.027622109279036522, dist_loss: 0.3790537118911743
recon_loss: 0.027623552829027176, dist_loss: 0.40264666080474854
recon_loss: 0.027623586356639862, dist_loss: 0.7934093475341797
recon_loss: 0.027622725814580917, dist_loss: 1.0380696058273315
recon_loss: 0.02762424387037754, dist_loss: 0.7041748762130737
recon_loss: 0.027622368186712265, dist_loss: 0.8496619462966919
recon_loss: 0.02762284129858017, dist_loss: 0.6250572800636292
recon_loss: 0.027622012421488762, dist_loss: 1.0191699266433716
recon_loss: 0.027622133493423462, dist_loss: 0.546165943145752
recon_loss: 0.02762170135974884, dist_loss: 0.37297970056533813
recon_loss: 0.027619363740086555, dist_loss: 0.43472933769226074
recon_loss: 0.027620334178209305, dist_loss: 0.9224454760551453
recon_loss: 0.027618559077382088, dist_loss: 0.6996715664863586
recon_loss: 0.027619102969765663, dist_loss: 0.5532746315002441
recon_loss: 0.027618665248155594, dist_loss: 0.4910823702812195
recon_loss: 0.02761853113770485, dist_loss: 0.5789048075675964
recon_loss: 0.027619313448667526, dist_loss: 0.6360956430435181
recon_loss: 0.027617568150162697, dist_loss: 0.7590134143829346
recon_loss: 0.027619032189249992, dist_loss: 0.7216656804084778
recon_loss: 0.027618499472737312, dist_loss: 0.6022801399230957
recon_loss: 0.027617791667580605, dist_loss: 0.629568338394165
recon_loss: 0.027619410306215286, dist_loss: 0.7678713798522949
recon_loss: 0.027616942301392555, dist_loss: 0.4392094016075134
recon_loss: 0.02761860005557537, dist_loss: 0.48135000467300415
recon_loss: 0.027617497369647026, dist_loss: 0.6011608242988586
recon_loss: 0.02761796861886978, dist_loss: 0.5245043039321899
recon_loss: 0.02761772647500038, dist_loss: 0.5922356843948364
recon_loss: 0.027616893872618675, dist_loss: 0.5964788198471069
recon_loss: 0.027617761865258217, dist_loss: 0.676546573638916
recon_loss: 0.027617322281003, dist_loss: 0.5210312008857727
recon_loss: 0.027617480605840683, dist_loss: 0.9593942165374756
recon_loss: 0.027617797255516052, dist_loss: 0.6147691011428833
recon_loss: 0.0276175569742918, dist_loss: 0.5907429456710815
recon_loss: 0.027618860825896263, dist_loss: 0.6586423516273499
recon_loss: 0.027619021013379097, dist_loss: 0.49832576513290405
recon_loss: 0.02761872112751007, dist_loss: 0.5123754739761353
recon_loss: 0.02761828526854515, dist_loss: 0.4738207161426544
recon_loss: 0.02761789597570896, dist_loss: 0.8687474727630615
recon_loss: 0.02761811763048172, dist_loss: 0.4452804923057556
recon_loss: 0.02761811949312687, dist_loss: 0.8574866652488708
recon_loss: 0.02761758491396904, dist_loss: 0.5393604040145874
recon_loss: 0.027618717402219772, dist_loss: 0.4818952679634094
recon_loss: 0.027619319036602974, dist_loss: 0.9665451645851135
recon_loss: 0.027619479224085808, dist_loss: 0.691378116607666
recon_loss: 0.02761903963983059, dist_loss: 0.479608416557312
recon_loss: 0.027617713436484337, dist_loss: 0.5776297450065613
recon_loss: 0.027617251500487328, dist_loss: 0.6335126757621765
recon_loss: 0.027617190033197403, dist_loss: 0.6611520648002625
recon_loss: 0.0276175569742918, dist_loss: 0.7440235018730164
recon_loss: 0.027617909014225006, dist_loss: 0.7626504898071289
recon_loss: 0.02761705033481121, dist_loss: 0.635046124458313
recon_loss: 0.0276175569742918, dist_loss: 0.611366868019104
recon_loss: 0.02761758677661419, dist_loss: 0.5957556962966919
recon_loss: 0.027618594467639923, dist_loss: 0.7067638635635376
recon_loss: 0.0276187751442194, dist_loss: 0.5326775312423706
recon_loss: 0.027619559317827225, dist_loss: 0.44428780674934387
recon_loss: 0.02761963941156864, dist_loss: 0.7586294412612915
recon_loss: 0.027619952335953712, dist_loss: 0.5493435859680176
recon_loss: 0.02762024849653244, dist_loss: 0.7405523061752319
recon_loss: 0.027620160952210426, dist_loss: 0.3552477955818176
recon_loss: 0.027620742097496986, dist_loss: 0.7173980474472046
recon_loss: 0.027621086686849594, dist_loss: 0.6908978223800659
recon_loss: 0.027622221037745476, dist_loss: 0.7353943586349487
recon_loss: 0.02762262150645256, dist_loss: 0.6147675514221191
recon_loss: 0.027622275054454803, dist_loss: 0.5725928544998169
recon_loss: 0.02762162871658802, dist_loss: 0.7738033533096313
recon_loss: 0.027621114626526833, dist_loss: 0.6303016543388367
recon_loss: 0.027620291337370872, dist_loss: 1.0253267288208008
recon_loss: 0.0276191383600235, dist_loss: 0.4627385139465332
recon_loss: 0.02761792205274105, dist_loss: 0.5903835296630859
recon_loss: 0.027617070823907852, dist_loss: 0.5197619199752808
recon_loss: 0.027616802603006363, dist_loss: 0.3220643401145935
recon_loss: 0.02761690877377987, dist_loss: 0.5175654888153076
recon_loss: 0.027617312967777252, dist_loss: 1.3598439693450928
recon_loss: 0.027616629377007484, dist_loss: 1.252429723739624
recon_loss: 0.027616135776042938, dist_loss: 0.6394177675247192
recon_loss: 0.027616918087005615, dist_loss: 0.6539491415023804
recon_loss: 0.027616029605269432, dist_loss: 0.4467948079109192
recon_loss: 0.02761724963784218, dist_loss: 0.4264485239982605
recon_loss: 0.027617324143648148, dist_loss: 0.730566680431366
recon_loss: 0.027617324143648148, dist_loss: 1.1869659423828125
recon_loss: 0.02761840634047985, dist_loss: 0.7276670336723328
recon_loss: 0.027617866173386574, dist_loss: 0.9160050749778748
Pre-training Epoch 96:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 96:   5%|▍         | 17/367 [00:00<00:02, 169.53it/s]Pre-training Epoch 96:  10%|▉         | 35/367 [00:00<00:01, 172.75it/s]Pre-training Epoch 96:  14%|█▍        | 53/367 [00:00<00:01, 175.52it/s]Pre-training Epoch 96:  20%|█▉        | 72/367 [00:00<00:01, 178.28it/s]Pre-training Epoch 96:  25%|██▍       | 90/367 [00:00<00:01, 171.25it/s]Pre-training Epoch 96:  29%|██▉       | 108/367 [00:00<00:01, 168.45it/s]Pre-training Epoch 96:  34%|███▍      | 126/367 [00:00<00:01, 171.62it/s]recon_loss: 0.027616774663329124, dist_loss: 0.3215549886226654
recon_loss: 0.027615990489721298, dist_loss: 0.9335402846336365
recon_loss: 0.027615895494818687, dist_loss: 0.9664172530174255
recon_loss: 0.027615778148174286, dist_loss: 0.7466506958007812
recon_loss: 0.027616042643785477, dist_loss: 0.5004469752311707
recon_loss: 0.027616064995527267, dist_loss: 0.5653470754623413
recon_loss: 0.027616314589977264, dist_loss: 0.6562314629554749
recon_loss: 0.02761678397655487, dist_loss: 1.0291246175765991
recon_loss: 0.027616946026682854, dist_loss: 0.6206735372543335
recon_loss: 0.027617445215582848, dist_loss: 0.6011245250701904
recon_loss: 0.02761761285364628, dist_loss: 0.480779767036438
recon_loss: 0.027617542073130608, dist_loss: 0.627408504486084
recon_loss: 0.02761733904480934, dist_loss: 0.6068416833877563
recon_loss: 0.02761700749397278, dist_loss: 1.0219788551330566
recon_loss: 0.027616508305072784, dist_loss: 0.7163070440292358
recon_loss: 0.027616294100880623, dist_loss: 0.7493979334831238
recon_loss: 0.027616607025265694, dist_loss: 0.8193325400352478
recon_loss: 0.02761615626513958, dist_loss: 0.5167235136032104
recon_loss: 0.027617070823907852, dist_loss: 0.46293655037879944
recon_loss: 0.02761712297797203, dist_loss: 0.7743778228759766
recon_loss: 0.027617808431386948, dist_loss: 0.542537271976471
recon_loss: 0.02761758118867874, dist_loss: 0.5384521484375
recon_loss: 0.027617357671260834, dist_loss: 0.36661046743392944
recon_loss: 0.027616918087005615, dist_loss: 0.6401206254959106
recon_loss: 0.027615267783403397, dist_loss: 0.8632991313934326
recon_loss: 0.027615897357463837, dist_loss: 0.5435248613357544
recon_loss: 0.027615346014499664, dist_loss: 0.5537054538726807
recon_loss: 0.02761591412127018, dist_loss: 0.5520645380020142
recon_loss: 0.027618365362286568, dist_loss: 0.7010036110877991
recon_loss: 0.027618583291769028, dist_loss: 0.597692608833313
recon_loss: 0.02762126922607422, dist_loss: 0.6483689546585083
recon_loss: 0.027622247114777565, dist_loss: 0.8679619431495667
recon_loss: 0.027622483670711517, dist_loss: 0.3582497835159302
recon_loss: 0.027623524889349937, dist_loss: 0.6053361296653748
recon_loss: 0.027624087408185005, dist_loss: 0.27724340558052063
recon_loss: 0.02762523479759693, dist_loss: 0.8053834438323975
recon_loss: 0.027625255286693573, dist_loss: 0.7190325856208801
recon_loss: 0.02762380614876747, dist_loss: 1.141656756401062
recon_loss: 0.027622776105999947, dist_loss: 0.9103822112083435
recon_loss: 0.027621136978268623, dist_loss: 0.627893328666687
recon_loss: 0.027619680389761925, dist_loss: 0.43541625142097473
recon_loss: 0.027619246393442154, dist_loss: 0.38217437267303467
recon_loss: 0.027617063373327255, dist_loss: 0.9566744565963745
recon_loss: 0.02761608362197876, dist_loss: 0.66759192943573
recon_loss: 0.02761528082191944, dist_loss: 0.8478219509124756
recon_loss: 0.027614127844572067, dist_loss: 0.7784111499786377
recon_loss: 0.027614574879407883, dist_loss: 0.4798344671726227
recon_loss: 0.02761484496295452, dist_loss: 0.7128758430480957
recon_loss: 0.027615096420049667, dist_loss: 0.3774621784687042
recon_loss: 0.02761741541326046, dist_loss: 0.5514112710952759
recon_loss: 0.027617977932095528, dist_loss: 0.6650987863540649
recon_loss: 0.027619261294603348, dist_loss: 0.8598780632019043
recon_loss: 0.027618806809186935, dist_loss: 1.2295724153518677
recon_loss: 0.02761852741241455, dist_loss: 0.6116836071014404
recon_loss: 0.027617499232292175, dist_loss: 0.6026632785797119
recon_loss: 0.0276148933917284, dist_loss: 0.4528408646583557
recon_loss: 0.027613647282123566, dist_loss: 0.7329156398773193
recon_loss: 0.02761232480406761, dist_loss: 0.7067505121231079
recon_loss: 0.027611877769231796, dist_loss: 0.7344432473182678
recon_loss: 0.027611512690782547, dist_loss: 0.36139994859695435
recon_loss: 0.027611523866653442, dist_loss: 1.1163604259490967
recon_loss: 0.027611469849944115, dist_loss: 0.512452244758606
recon_loss: 0.02761145867407322, dist_loss: 1.2164497375488281
recon_loss: 0.02761234901845455, dist_loss: 0.7669600248336792
recon_loss: 0.027611806988716125, dist_loss: 0.5635824799537659
recon_loss: 0.02761239930987358, dist_loss: 0.39381739497184753
recon_loss: 0.027612833306193352, dist_loss: 0.38761287927627563
recon_loss: 0.02761324867606163, dist_loss: 0.8991583585739136
recon_loss: 0.02761293761432171, dist_loss: 0.6095329523086548
recon_loss: 0.027612753212451935, dist_loss: 0.3440417945384979
recon_loss: 0.02761160209774971, dist_loss: 0.44149819016456604
recon_loss: 0.027610836550593376, dist_loss: 0.5370811820030212
recon_loss: 0.027610385790467262, dist_loss: 0.6114670038223267
recon_loss: 0.027610044926404953, dist_loss: 0.4700303077697754
recon_loss: 0.027610095217823982, dist_loss: 0.511410117149353
recon_loss: 0.027610430493950844, dist_loss: 0.3188049793243408
recon_loss: 0.02760949730873108, dist_loss: 0.6311600208282471
recon_loss: 0.027610132470726967, dist_loss: 0.49001544713974
recon_loss: 0.02761007845401764, dist_loss: 0.9582492113113403
recon_loss: 0.027611741796135902, dist_loss: 0.3938350975513458
recon_loss: 0.02761255018413067, dist_loss: 0.4615723788738251
recon_loss: 0.027614561840891838, dist_loss: 0.6094952821731567
recon_loss: 0.027616014704108238, dist_loss: 1.0679272413253784
recon_loss: 0.027616415172815323, dist_loss: 0.8286324739456177
recon_loss: 0.027615489438176155, dist_loss: 0.6114239692687988
recon_loss: 0.0276161078363657, dist_loss: 0.5336273312568665
recon_loss: 0.02761467732489109, dist_loss: 0.8332744240760803
recon_loss: 0.027614744380116463, dist_loss: 0.4582875370979309
recon_loss: 0.027614349499344826, dist_loss: 0.46598923206329346
recon_loss: 0.027612650766968727, dist_loss: 0.7937853336334229
recon_loss: 0.02761286497116089, dist_loss: 0.6773380041122437
recon_loss: 0.027610108256340027, dist_loss: 0.6272446513175964
recon_loss: 0.02761220373213291, dist_loss: 0.8028901815414429
recon_loss: 0.027609454467892647, dist_loss: 0.8639693856239319
recon_loss: 0.02761184796690941, dist_loss: 0.8769527077674866
recon_loss: 0.027611883357167244, dist_loss: 1.1046199798583984
recon_loss: 0.02761346660554409, dist_loss: 0.6708089113235474
recon_loss: 0.027616165578365326, dist_loss: 0.4988790452480316
recon_loss: 0.027615727856755257, dist_loss: 0.46242573857307434
recon_loss: 0.027619119733572006, dist_loss: 0.7946533560752869
recon_loss: 0.02761835791170597, dist_loss: 0.5862497091293335
recon_loss: 0.027619415894150734, dist_loss: 0.40958109498023987
recon_loss: 0.02761710248887539, dist_loss: 0.6642252206802368
recon_loss: 0.027616428211331367, dist_loss: 0.6855566501617432
recon_loss: 0.02761453203856945, dist_loss: 0.8459697961807251
recon_loss: 0.027612686157226562, dist_loss: 0.750953197479248
recon_loss: 0.027612842619419098, dist_loss: 0.33635759353637695
recon_loss: 0.027611808851361275, dist_loss: 0.4122040867805481
recon_loss: 0.02761206403374672, dist_loss: 0.8575171232223511
recon_loss: 0.027612833306193352, dist_loss: 0.8489577770233154
recon_loss: 0.027610963210463524, dist_loss: 0.5299198031425476
recon_loss: 0.027612736448645592, dist_loss: 0.7785030603408813
recon_loss: 0.027611257508397102, dist_loss: 0.5531363487243652
recon_loss: 0.02761060930788517, dist_loss: 0.5940372943878174
recon_loss: 0.02761160582304001, dist_loss: 0.5518579483032227
recon_loss: 0.027609746903181076, dist_loss: 0.5800848007202148
recon_loss: 0.02761043608188629, dist_loss: 0.7362510561943054
recon_loss: 0.027610013261437416, dist_loss: 0.7607563138008118
recon_loss: 0.02760959416627884, dist_loss: 0.5102405548095703
recon_loss: 0.027609655633568764, dist_loss: 0.5785099267959595
recon_loss: 0.02760842815041542, dist_loss: 0.6426095366477966
recon_loss: 0.0276094451546669, dist_loss: 0.8066819906234741
recon_loss: 0.027607934549450874, dist_loss: 0.5127075910568237
recon_loss: 0.02760879509150982, dist_loss: 1.130650520324707
recon_loss: 0.027609460055828094, dist_loss: 0.8128290176391602
recon_loss: 0.027608530595898628, dist_loss: 0.7377973198890686
recon_loss: 0.027609359472990036, dist_loss: 0.5471758246421814
recon_loss: 0.027608517557382584, dist_loss: 0.435152530670166
Pre-training Epoch 96:  39%|███▉      | 144/367 [00:00<00:01, 173.93it/s]Pre-training Epoch 96:  44%|████▍     | 162/367 [00:00<00:01, 164.35it/s]Pre-training Epoch 96:  49%|████▉     | 179/367 [00:01<00:01, 161.88it/s]Pre-training Epoch 96:  53%|█████▎    | 196/367 [00:01<00:01, 159.73it/s]Pre-training Epoch 96:  58%|█████▊    | 213/367 [00:01<00:00, 159.12it/s]Pre-training Epoch 96:  62%|██████▏   | 229/367 [00:01<00:00, 157.26it/s]Pre-training Epoch 96:  67%|██████▋   | 245/367 [00:01<00:00, 155.48it/s]recon_loss: 0.027609003707766533, dist_loss: 1.1512796878814697
recon_loss: 0.02760883793234825, dist_loss: 0.9834208488464355
recon_loss: 0.027607787400484085, dist_loss: 0.5882447957992554
recon_loss: 0.0276077538728714, dist_loss: 0.47452959418296814
recon_loss: 0.027607373893260956, dist_loss: 0.6049271821975708
recon_loss: 0.027607401832938194, dist_loss: 0.8605667352676392
recon_loss: 0.027607811614871025, dist_loss: 0.9474838972091675
recon_loss: 0.027607686817646027, dist_loss: 0.4941464960575104
recon_loss: 0.027608655393123627, dist_loss: 0.8590914011001587
recon_loss: 0.027607807889580727, dist_loss: 0.5666145086288452
recon_loss: 0.027607643976807594, dist_loss: 0.5552797317504883
recon_loss: 0.02760789357125759, dist_loss: 0.4949442744255066
recon_loss: 0.027606932446360588, dist_loss: 0.5864328742027283
recon_loss: 0.027607064694166183, dist_loss: 0.736649751663208
recon_loss: 0.027606135234236717, dist_loss: 0.5475168228149414
recon_loss: 0.02760608121752739, dist_loss: 0.6463549137115479
recon_loss: 0.027605891227722168, dist_loss: 0.3949199318885803
recon_loss: 0.027605539187788963, dist_loss: 0.3826531171798706
recon_loss: 0.02760571986436844, dist_loss: 0.679920494556427
recon_loss: 0.027605535462498665, dist_loss: 0.42007148265838623
recon_loss: 0.027605686336755753, dist_loss: 1.2493290901184082
recon_loss: 0.02760586142539978, dist_loss: 0.8412416577339172
recon_loss: 0.027605554088950157, dist_loss: 0.592215895652771
recon_loss: 0.027605418115854263, dist_loss: 0.8613483309745789
recon_loss: 0.027606159448623657, dist_loss: 0.7418592572212219
recon_loss: 0.027605535462498665, dist_loss: 1.0849695205688477
recon_loss: 0.0276058129966259, dist_loss: 0.46359413862228394
recon_loss: 0.027606463059782982, dist_loss: 0.5674461722373962
recon_loss: 0.027606258168816566, dist_loss: 0.8499759435653687
recon_loss: 0.027606705203652382, dist_loss: 0.6444727182388306
recon_loss: 0.027606992051005363, dist_loss: 0.9240992069244385
recon_loss: 0.02760697528719902, dist_loss: 0.6105852127075195
recon_loss: 0.027607811614871025, dist_loss: 0.6753732562065125
recon_loss: 0.027605179697275162, dist_loss: 0.5460524559020996
recon_loss: 0.027606667950749397, dist_loss: 0.3410543203353882
recon_loss: 0.02760465070605278, dist_loss: 0.776271402835846
recon_loss: 0.02760561741888523, dist_loss: 0.8199087381362915
recon_loss: 0.027605602517724037, dist_loss: 0.5115808844566345
recon_loss: 0.027604738250374794, dist_loss: 0.38330382108688354
recon_loss: 0.027606094256043434, dist_loss: 0.45179417729377747
recon_loss: 0.027604686096310616, dist_loss: 0.7049461007118225
recon_loss: 0.02760598435997963, dist_loss: 0.7700743675231934
recon_loss: 0.027605384588241577, dist_loss: 0.3894592225551605
recon_loss: 0.02760511264204979, dist_loss: 0.581553041934967
recon_loss: 0.02760617807507515, dist_loss: 0.4638522267341614
recon_loss: 0.027605634182691574, dist_loss: 0.47937214374542236
recon_loss: 0.02760613150894642, dist_loss: 0.27900171279907227
recon_loss: 0.02760600484907627, dist_loss: 0.4168204665184021
recon_loss: 0.027605894953012466, dist_loss: 0.6098342537879944
recon_loss: 0.027606256306171417, dist_loss: 1.0777864456176758
recon_loss: 0.02760595642030239, dist_loss: 0.8276307582855225
recon_loss: 0.027607113122940063, dist_loss: 0.6376904249191284
recon_loss: 0.02760760672390461, dist_loss: 0.26887547969818115
recon_loss: 0.027608096599578857, dist_loss: 0.8461795449256897
recon_loss: 0.027608411386609077, dist_loss: 0.6815931797027588
recon_loss: 0.027606913819909096, dist_loss: 0.6462928056716919
recon_loss: 0.027605969458818436, dist_loss: 0.5887145400047302
recon_loss: 0.027605729177594185, dist_loss: 0.5009157657623291
recon_loss: 0.027604687958955765, dist_loss: 0.9689640998840332
recon_loss: 0.027604836970567703, dist_loss: 0.5388091802597046
recon_loss: 0.027605043724179268, dist_loss: 0.8670375347137451
recon_loss: 0.027604682371020317, dist_loss: 0.3761487305164337
recon_loss: 0.02760569378733635, dist_loss: 0.3665466606616974
recon_loss: 0.027606047689914703, dist_loss: 0.393725723028183
recon_loss: 0.027606410905718803, dist_loss: 0.7021670341491699
recon_loss: 0.02760699950158596, dist_loss: 0.5784224271774292
recon_loss: 0.02760673128068447, dist_loss: 0.3624544143676758
recon_loss: 0.027607180178165436, dist_loss: 0.36361315846443176
recon_loss: 0.027607673779129982, dist_loss: 0.7491129636764526
recon_loss: 0.027607709169387817, dist_loss: 0.8284212946891785
recon_loss: 0.027607854455709457, dist_loss: 0.723056972026825
recon_loss: 0.027607141062617302, dist_loss: 0.39996570348739624
recon_loss: 0.027606690302491188, dist_loss: 0.5845820903778076
recon_loss: 0.027605969458818436, dist_loss: 0.5780630707740784
recon_loss: 0.027605637907981873, dist_loss: 0.6510229110717773
recon_loss: 0.02760535106062889, dist_loss: 1.0674269199371338
recon_loss: 0.02760540135204792, dist_loss: 0.4955919682979584
recon_loss: 0.027605587616562843, dist_loss: 0.907442569732666
recon_loss: 0.027605589479207993, dist_loss: 0.750505805015564
recon_loss: 0.027605336159467697, dist_loss: 0.6153993010520935
recon_loss: 0.027605023235082626, dist_loss: 0.5382139682769775
recon_loss: 0.027604520320892334, dist_loss: 0.6554434299468994
recon_loss: 0.02760397270321846, dist_loss: 0.4829137921333313
recon_loss: 0.027603602036833763, dist_loss: 0.4690987169742584
recon_loss: 0.027603205293416977, dist_loss: 0.4670049548149109
recon_loss: 0.027603210881352425, dist_loss: 0.8405183553695679
recon_loss: 0.027602866291999817, dist_loss: 0.807857871055603
recon_loss: 0.027602698653936386, dist_loss: 0.5599022507667542
recon_loss: 0.02760281227529049, dist_loss: 0.4127434492111206
recon_loss: 0.02760295383632183, dist_loss: 0.8215378522872925
recon_loss: 0.02760312519967556, dist_loss: 0.6084774136543274
recon_loss: 0.027603084221482277, dist_loss: 0.7610046863555908
recon_loss: 0.027603570371866226, dist_loss: 0.9071220755577087
recon_loss: 0.027603330090641975, dist_loss: 0.46905457973480225
recon_loss: 0.027603372931480408, dist_loss: 0.5469677448272705
recon_loss: 0.02760230377316475, dist_loss: 0.3841548562049866
recon_loss: 0.027602722868323326, dist_loss: 0.43172016739845276
recon_loss: 0.027601901441812515, dist_loss: 0.5769592523574829
recon_loss: 0.027601683512330055, dist_loss: 0.6497505307197571
recon_loss: 0.02760186418890953, dist_loss: 0.5075576305389404
recon_loss: 0.02760128676891327, dist_loss: 0.8513967394828796
recon_loss: 0.027601424604654312, dist_loss: 0.6279643774032593
recon_loss: 0.027600908651947975, dist_loss: 0.39919400215148926
recon_loss: 0.027601100504398346, dist_loss: 1.0041968822479248
recon_loss: 0.027601877227425575, dist_loss: 0.4486698806285858
recon_loss: 0.027601148933172226, dist_loss: 0.6954414248466492
recon_loss: 0.027601301670074463, dist_loss: 0.9651741981506348
recon_loss: 0.027601061388850212, dist_loss: 0.4137285351753235
recon_loss: 0.027602212503552437, dist_loss: 0.6393776535987854
recon_loss: 0.02760191075503826, dist_loss: 0.8378629088401794
recon_loss: 0.027602316811680794, dist_loss: 0.4773753881454468
recon_loss: 0.02760167606174946, dist_loss: 0.938468337059021
recon_loss: 0.027601182460784912, dist_loss: 0.6119548082351685
recon_loss: 0.027601666748523712, dist_loss: 0.32204288244247437
recon_loss: 0.02760157361626625, dist_loss: 0.6737514138221741
recon_loss: 0.027600839734077454, dist_loss: 1.287928819656372
recon_loss: 0.02760135941207409, dist_loss: 0.7041328549385071
recon_loss: 0.027600537985563278, dist_loss: 0.6423759460449219
recon_loss: 0.02760137803852558, dist_loss: 0.8621498346328735
recon_loss: 0.02760053612291813, dist_loss: 0.882172167301178
recon_loss: 0.027600551024079323, dist_loss: 0.6579561829566956
recon_loss: 0.027600493282079697, dist_loss: 0.44951653480529785
recon_loss: 0.027600202709436417, dist_loss: 0.7086495161056519
recon_loss: 0.027600623667240143, dist_loss: 0.7900937795639038
recon_loss: 0.02760033868253231, dist_loss: 0.5153679847717285
recon_loss: 0.02759999968111515, dist_loss: 0.3874927759170532
recon_loss: 0.02760043367743492, dist_loss: 0.7119709849357605
recon_loss: 0.027599181979894638, dist_loss: 0.8082424402236938
Pre-training Epoch 96:  71%|███████   | 261/367 [00:01<00:00, 149.23it/s]Pre-training Epoch 96:  75%|███████▌  | 277/367 [00:01<00:00, 149.98it/s]Pre-training Epoch 96:  80%|███████▉  | 293/367 [00:01<00:00, 152.22it/s]Pre-training Epoch 96:  84%|████████▍ | 309/367 [00:01<00:00, 151.58it/s]Pre-training Epoch 96:  89%|████████▊ | 325/367 [00:02<00:00, 152.39it/s]Pre-training Epoch 96:  93%|█████████▎| 341/367 [00:02<00:00, 153.01it/s]Pre-training Epoch 96:  97%|█████████▋| 357/367 [00:02<00:00, 153.52it/s]Pre-training Epoch 96: 100%|██████████| 367/367 [00:02<00:00, 159.64it/s]
recon_loss: 0.02759988233447075, dist_loss: 0.47356927394866943
recon_loss: 0.027599569410085678, dist_loss: 0.7764570713043213
recon_loss: 0.02759988233447075, dist_loss: 0.7899160981178284
recon_loss: 0.027599912136793137, dist_loss: 0.8594855070114136
recon_loss: 0.02759966067969799, dist_loss: 0.49055880308151245
recon_loss: 0.02759973146021366, dist_loss: 0.7362041473388672
recon_loss: 0.027599211782217026, dist_loss: 0.9170011878013611
recon_loss: 0.027599379420280457, dist_loss: 0.7151088714599609
recon_loss: 0.027598777785897255, dist_loss: 0.5089575052261353
recon_loss: 0.02759908325970173, dist_loss: 0.42915886640548706
recon_loss: 0.027598584070801735, dist_loss: 0.992311418056488
recon_loss: 0.02759871445596218, dist_loss: 0.8932396173477173
recon_loss: 0.02759830839931965, dist_loss: 1.0224034786224365
recon_loss: 0.027598941698670387, dist_loss: 0.3801676630973816
recon_loss: 0.027599170804023743, dist_loss: 0.5842282772064209
recon_loss: 0.02759944647550583, dist_loss: 0.9830239415168762
recon_loss: 0.02760053612291813, dist_loss: 0.5175021886825562
recon_loss: 0.027601314708590508, dist_loss: 0.5061289072036743
recon_loss: 0.02760237082839012, dist_loss: 0.7575893402099609
recon_loss: 0.027603287249803543, dist_loss: 0.7176861763000488
recon_loss: 0.027604086324572563, dist_loss: 0.4111642837524414
recon_loss: 0.027604665607213974, dist_loss: 0.38314834237098694
recon_loss: 0.027604276314377785, dist_loss: 0.614290714263916
recon_loss: 0.027603385969996452, dist_loss: 0.5626862645149231
recon_loss: 0.027602579444646835, dist_loss: 0.799078106880188
recon_loss: 0.027602016925811768, dist_loss: 0.6617740988731384
recon_loss: 0.027601368725299835, dist_loss: 0.5070669651031494
recon_loss: 0.027600780129432678, dist_loss: 0.7883658409118652
recon_loss: 0.027599917724728584, dist_loss: 0.5668630003929138
recon_loss: 0.027598930522799492, dist_loss: 0.8890143036842346
recon_loss: 0.02759885974228382, dist_loss: 0.684269905090332
recon_loss: 0.027599282562732697, dist_loss: 0.5419820547103882
recon_loss: 0.027598220854997635, dist_loss: 0.7825456857681274
recon_loss: 0.02759871818125248, dist_loss: 0.7974921464920044
recon_loss: 0.027598410844802856, dist_loss: 0.4418729543685913
recon_loss: 0.027599414810538292, dist_loss: 0.7490541934967041
recon_loss: 0.0275997556746006, dist_loss: 0.8438796401023865
recon_loss: 0.027600429952144623, dist_loss: 0.4840856194496155
recon_loss: 0.027601392939686775, dist_loss: 0.45015567541122437
recon_loss: 0.027599075809121132, dist_loss: 0.8852418065071106
recon_loss: 0.027601590380072594, dist_loss: 0.4871043562889099
recon_loss: 0.027598891407251358, dist_loss: 1.034987211227417
recon_loss: 0.02760114148259163, dist_loss: 0.6054573059082031
recon_loss: 0.027599671855568886, dist_loss: 0.6018201112747192
recon_loss: 0.027600297704339027, dist_loss: 0.7990210056304932
recon_loss: 0.02760080248117447, dist_loss: 0.6492545008659363
recon_loss: 0.027599643915891647, dist_loss: 0.4262804388999939
recon_loss: 0.027600856497883797, dist_loss: 0.5542821884155273
recon_loss: 0.02759978547692299, dist_loss: 0.2774503827095032
recon_loss: 0.027600416913628578, dist_loss: 1.2227810621261597
recon_loss: 0.02759995311498642, dist_loss: 1.12489652633667
recon_loss: 0.027599681168794632, dist_loss: 0.3941221237182617
recon_loss: 0.027600200846791267, dist_loss: 0.541957437992096
recon_loss: 0.027598757296800613, dist_loss: 0.5633798241615295
recon_loss: 0.027599459514021873, dist_loss: 0.6322065591812134
recon_loss: 0.027599189430475235, dist_loss: 0.9847431182861328
recon_loss: 0.02759857103228569, dist_loss: 0.7124590873718262
recon_loss: 0.02760026417672634, dist_loss: 0.5618643760681152
recon_loss: 0.027599148452281952, dist_loss: 0.8113619089126587
recon_loss: 0.02760034240782261, dist_loss: 0.7535349130630493
recon_loss: 0.027600035071372986, dist_loss: 0.6451451778411865
recon_loss: 0.0275998804718256, dist_loss: 0.7049620151519775
recon_loss: 0.027599727734923363, dist_loss: 0.41669559478759766
recon_loss: 0.0275985486805439, dist_loss: 0.7463712692260742
recon_loss: 0.027598945423960686, dist_loss: 0.7192137837409973
recon_loss: 0.027597971260547638, dist_loss: 0.5064980983734131
recon_loss: 0.027597999200224876, dist_loss: 0.7070469856262207
recon_loss: 0.02759811095893383, dist_loss: 0.7295215129852295
recon_loss: 0.027597036212682724, dist_loss: 0.4759702682495117
recon_loss: 0.027598947286605835, dist_loss: 0.4093542695045471
recon_loss: 0.02759733609855175, dist_loss: 0.7159380316734314
recon_loss: 0.027597861364483833, dist_loss: 0.9598134756088257
recon_loss: 0.027597952634096146, dist_loss: 0.607872486114502
recon_loss: 0.02759717032313347, dist_loss: 0.6356496810913086
recon_loss: 0.027598481625318527, dist_loss: 0.9346296787261963
recon_loss: 0.027599167078733444, dist_loss: 0.5545110702514648
recon_loss: 0.02760016918182373, dist_loss: 0.29645076394081116
recon_loss: 0.02760177105665207, dist_loss: 0.45763587951660156
recon_loss: 0.027603160589933395, dist_loss: 1.3431141376495361
recon_loss: 0.027605492621660233, dist_loss: 0.3642473816871643
recon_loss: 0.027606584131717682, dist_loss: 0.9446461200714111
recon_loss: 0.027607407420873642, dist_loss: 0.7643706798553467
recon_loss: 0.02760886959731579, dist_loss: 0.9048377871513367
recon_loss: 0.027609268203377724, dist_loss: 0.9094704389572144
recon_loss: 0.0276084765791893, dist_loss: 0.39182373881340027
recon_loss: 0.02760654129087925, dist_loss: 0.6204409599304199
recon_loss: 0.027604855597019196, dist_loss: 0.4970417618751526
recon_loss: 0.027602998539805412, dist_loss: 0.5210047960281372
recon_loss: 0.027601372450590134, dist_loss: 0.5236120223999023
recon_loss: 0.027599601075053215, dist_loss: 0.7144638299942017
recon_loss: 0.027597876265645027, dist_loss: 0.5717037320137024
recon_loss: 0.02759685181081295, dist_loss: 0.8150938749313354
recon_loss: 0.02759677730500698, dist_loss: 0.5336750149726868
recon_loss: 0.027596939355134964, dist_loss: 0.3794102072715759
recon_loss: 0.02759818732738495, dist_loss: 0.8895062208175659
recon_loss: 0.027599873021245003, dist_loss: 0.6641464233398438
recon_loss: 0.027600688859820366, dist_loss: 0.5487895011901855
recon_loss: 0.02760128863155842, dist_loss: 0.48799654841423035
recon_loss: 0.027601802721619606, dist_loss: 0.5122753381729126
recon_loss: 0.02760203182697296, dist_loss: 0.31157732009887695
recon_loss: 0.02760145626962185, dist_loss: 0.47979745268821716
recon_loss: 0.027600347995758057, dist_loss: 0.5330517292022705
recon_loss: 0.0275997556746006, dist_loss: 0.6031149625778198
recon_loss: 0.027598876506090164, dist_loss: 0.8158676624298096
recon_loss: 0.027597881853580475, dist_loss: 0.5130017995834351
recon_loss: 0.027596626430749893, dist_loss: 0.4964459538459778
recon_loss: 0.02759562060236931, dist_loss: 0.769233226776123
recon_loss: 0.027594678103923798, dist_loss: 0.752846360206604
recon_loss: 0.02759428881108761, dist_loss: 0.8804826736450195
recon_loss: 0.027593668550252914, dist_loss: 0.7055356502532959
recon_loss: 0.027593599632382393, dist_loss: 0.5764304995536804
Pre-training Epoch 97:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 97:   4%|▍         | 15/367 [00:00<00:02, 144.43it/s]Pre-training Epoch 97:   8%|▊         | 31/367 [00:00<00:02, 149.67it/s]Pre-training Epoch 97:  13%|█▎        | 48/367 [00:00<00:02, 154.46it/s]Pre-training Epoch 97:  18%|█▊        | 67/367 [00:00<00:01, 164.52it/s]Pre-training Epoch 97:  23%|██▎       | 84/367 [00:00<00:01, 158.66it/s]Pre-training Epoch 97:  27%|██▋       | 100/367 [00:00<00:01, 155.07it/s]Pre-training Epoch 97:  32%|███▏      | 116/367 [00:00<00:01, 154.80it/s]recon_loss: 0.02759338729083538, dist_loss: 0.9047134518623352
recon_loss: 0.027592862024903297, dist_loss: 0.6229720115661621
recon_loss: 0.02759292908012867, dist_loss: 0.9295908808708191
recon_loss: 0.027592213824391365, dist_loss: 0.6055912971496582
recon_loss: 0.027592066675424576, dist_loss: 0.8689489960670471
recon_loss: 0.027591625228524208, dist_loss: 0.534993052482605
recon_loss: 0.02759137749671936, dist_loss: 0.3113672137260437
recon_loss: 0.027591237798333168, dist_loss: 0.7054240107536316
recon_loss: 0.027590762823820114, dist_loss: 0.7974967360496521
recon_loss: 0.027590811252593994, dist_loss: 0.5347493886947632
recon_loss: 0.02759116142988205, dist_loss: 0.5329260230064392
recon_loss: 0.027590472251176834, dist_loss: 0.6807236671447754
recon_loss: 0.027591129764914513, dist_loss: 0.24707427620887756
recon_loss: 0.027590997517108917, dist_loss: 1.0274505615234375
recon_loss: 0.027590440586209297, dist_loss: 0.9747748970985413
recon_loss: 0.027591293677687645, dist_loss: 0.6573022603988647
recon_loss: 0.027591047808527946, dist_loss: 0.6489046812057495
recon_loss: 0.027591653168201447, dist_loss: 0.9776239395141602
recon_loss: 0.027592333033680916, dist_loss: 0.9682475924491882
recon_loss: 0.027593061327934265, dist_loss: 0.5365777015686035
recon_loss: 0.027594128623604774, dist_loss: 0.4890577793121338
recon_loss: 0.027594322338700294, dist_loss: 0.4595576524734497
recon_loss: 0.027595065534114838, dist_loss: 0.49709755182266235
recon_loss: 0.027594979852437973, dist_loss: 0.5553522706031799
recon_loss: 0.027594689279794693, dist_loss: 0.9852386713027954
recon_loss: 0.027594637125730515, dist_loss: 0.5222818851470947
recon_loss: 0.027593422681093216, dist_loss: 0.771117091178894
recon_loss: 0.027592694386839867, dist_loss: 0.6219742298126221
recon_loss: 0.02759196236729622, dist_loss: 0.9773476123809814
recon_loss: 0.027591099962592125, dist_loss: 0.8074190616607666
recon_loss: 0.027591394260525703, dist_loss: 1.0147132873535156
recon_loss: 0.027590807527303696, dist_loss: 1.151989459991455
recon_loss: 0.027591342106461525, dist_loss: 0.8003354072570801
recon_loss: 0.027591636404395103, dist_loss: 0.969769299030304
recon_loss: 0.027592042461037636, dist_loss: 0.5362858176231384
recon_loss: 0.027592578902840614, dist_loss: 0.5391919612884521
recon_loss: 0.02759331278502941, dist_loss: 0.48156094551086426
recon_loss: 0.027594013139605522, dist_loss: 0.6857307553291321
recon_loss: 0.027594231069087982, dist_loss: 0.6632064580917358
recon_loss: 0.02759483829140663, dist_loss: 0.4449629783630371
recon_loss: 0.027594787999987602, dist_loss: 0.6906175017356873
recon_loss: 0.027594760060310364, dist_loss: 0.5715889930725098
recon_loss: 0.02759397029876709, dist_loss: 0.653256893157959
recon_loss: 0.027593228965997696, dist_loss: 0.7233902215957642
recon_loss: 0.02759259007871151, dist_loss: 0.8650828003883362
recon_loss: 0.02759140357375145, dist_loss: 0.5294645428657532
recon_loss: 0.027592290192842484, dist_loss: 0.5644922852516174
recon_loss: 0.027590330690145493, dist_loss: 0.9159142971038818
recon_loss: 0.027590997517108917, dist_loss: 0.6923080682754517
recon_loss: 0.02758999541401863, dist_loss: 0.5319421291351318
recon_loss: 0.027591394260525703, dist_loss: 0.4790024757385254
recon_loss: 0.02759101614356041, dist_loss: 0.8241434097290039
recon_loss: 0.02759150043129921, dist_loss: 0.5265435576438904
recon_loss: 0.02759232185781002, dist_loss: 0.4213973879814148
recon_loss: 0.0275921318680048, dist_loss: 0.7920006513595581
recon_loss: 0.02759186178445816, dist_loss: 0.46303635835647583
recon_loss: 0.027591047808527946, dist_loss: 0.5498967170715332
recon_loss: 0.027590587735176086, dist_loss: 0.7492752075195312
recon_loss: 0.02758926898241043, dist_loss: 0.24888554215431213
recon_loss: 0.027588598430156708, dist_loss: 0.5763784050941467
recon_loss: 0.027588514611124992, dist_loss: 0.30090612173080444
recon_loss: 0.027588726952672005, dist_loss: 0.490322470664978
recon_loss: 0.027590161189436913, dist_loss: 0.9393988847732544
recon_loss: 0.027590645477175713, dist_loss: 0.510224461555481
recon_loss: 0.027592036873102188, dist_loss: 0.785384476184845
recon_loss: 0.02759311906993389, dist_loss: 0.7303762435913086
recon_loss: 0.027593621984124184, dist_loss: 0.5502150058746338
recon_loss: 0.027593476697802544, dist_loss: 0.8392038345336914
recon_loss: 0.027593383565545082, dist_loss: 0.5149821043014526
recon_loss: 0.027592727914452553, dist_loss: 0.957358717918396
recon_loss: 0.027592148631811142, dist_loss: 0.36721065640449524
recon_loss: 0.02759157307446003, dist_loss: 0.4649142622947693
recon_loss: 0.027591630816459656, dist_loss: 0.6681702136993408
recon_loss: 0.027590937912464142, dist_loss: 0.9056440591812134
recon_loss: 0.027590354904532433, dist_loss: 0.5418145656585693
recon_loss: 0.027589665725827217, dist_loss: 0.6116026639938354
recon_loss: 0.027588877826929092, dist_loss: 0.7891607284545898
recon_loss: 0.027588477358222008, dist_loss: 0.7718613743782043
recon_loss: 0.02758873626589775, dist_loss: 0.45007115602493286
recon_loss: 0.02758967876434326, dist_loss: 0.35422953963279724
recon_loss: 0.027590762823820114, dist_loss: 0.5826012492179871
recon_loss: 0.027592748403549194, dist_loss: 0.7326356172561646
recon_loss: 0.02759409137070179, dist_loss: 0.5393178462982178
recon_loss: 0.027594594284892082, dist_loss: 0.5424699783325195
recon_loss: 0.02759505622088909, dist_loss: 0.3702787756919861
recon_loss: 0.02759486809372902, dist_loss: 0.6041584014892578
recon_loss: 0.027593588456511497, dist_loss: 0.7236881256103516
recon_loss: 0.027592137455940247, dist_loss: 0.6129746437072754
recon_loss: 0.027590112760663033, dist_loss: 0.4881904125213623
recon_loss: 0.027588646858930588, dist_loss: 0.815009355545044
recon_loss: 0.027588186785578728, dist_loss: 0.48732733726501465
recon_loss: 0.027588309720158577, dist_loss: 0.8357788324356079
recon_loss: 0.027588026598095894, dist_loss: 0.4968813359737396
recon_loss: 0.027589766308665276, dist_loss: 0.5931564569473267
recon_loss: 0.027588941156864166, dist_loss: 0.595709502696991
recon_loss: 0.02759058214724064, dist_loss: 0.4945356249809265
recon_loss: 0.02758883871138096, dist_loss: 1.0294451713562012
recon_loss: 0.02759014628827572, dist_loss: 0.46449801325798035
recon_loss: 0.02758968621492386, dist_loss: 0.6633281111717224
recon_loss: 0.027589816600084305, dist_loss: 0.37251412868499756
recon_loss: 0.02759116142988205, dist_loss: 0.4624673128128052
recon_loss: 0.027588361874222755, dist_loss: 0.8282731771469116
recon_loss: 0.02758892811834812, dist_loss: 1.0415575504302979
recon_loss: 0.027587292715907097, dist_loss: 0.9606441259384155
recon_loss: 0.027587387710809708, dist_loss: 0.6617699861526489
recon_loss: 0.02758662961423397, dist_loss: 0.5373407602310181
recon_loss: 0.027586163952946663, dist_loss: 0.6028077602386475
recon_loss: 0.02758718468248844, dist_loss: 1.0442702770233154
recon_loss: 0.027585582807660103, dist_loss: 0.5166455507278442
recon_loss: 0.027586795389652252, dist_loss: 0.6815072298049927
recon_loss: 0.02758605219423771, dist_loss: 0.5050140619277954
recon_loss: 0.02758662961423397, dist_loss: 0.21727420389652252
recon_loss: 0.02758736163377762, dist_loss: 0.9540812373161316
recon_loss: 0.02758697234094143, dist_loss: 0.5861681699752808
recon_loss: 0.027588101103901863, dist_loss: 0.45886296033859253
recon_loss: 0.027586940675973892, dist_loss: 0.4767552614212036
recon_loss: 0.027589229866862297, dist_loss: 0.7781510949134827
recon_loss: 0.027586540207266808, dist_loss: 1.0059430599212646
recon_loss: 0.02758834883570671, dist_loss: 0.4080212116241455
recon_loss: 0.02758713997900486, dist_loss: 0.8543848395347595
recon_loss: 0.02758604660630226, dist_loss: 0.6306750774383545
recon_loss: 0.027587298303842545, dist_loss: 0.8216477632522583
recon_loss: 0.027585389092564583, dist_loss: 0.8259038925170898
recon_loss: 0.02758665569126606, dist_loss: 0.5381135940551758
recon_loss: 0.02758541703224182, dist_loss: 0.46960508823394775
recon_loss: 0.02758636884391308, dist_loss: 0.5176600217819214
recon_loss: 0.027586305513978004, dist_loss: 0.37437811493873596
recon_loss: 0.027586454525589943, dist_loss: 0.5198654532432556
Pre-training Epoch 97:  36%|███▌      | 132/367 [00:00<00:01, 153.60it/s]Pre-training Epoch 97:  40%|████      | 148/367 [00:00<00:01, 151.82it/s]Pre-training Epoch 97:  45%|████▍     | 164/367 [00:01<00:01, 150.91it/s]Pre-training Epoch 97:  49%|████▉     | 180/367 [00:01<00:01, 151.10it/s]Pre-training Epoch 97:  53%|█████▎    | 196/367 [00:01<00:01, 152.31it/s]Pre-training Epoch 97:  58%|█████▊    | 212/367 [00:01<00:01, 152.61it/s]Pre-training Epoch 97:  62%|██████▏   | 228/367 [00:01<00:00, 154.13it/s]Pre-training Epoch 97:  67%|██████▋   | 246/367 [00:01<00:00, 159.90it/s]recon_loss: 0.0275874063372612, dist_loss: 0.6110508441925049
recon_loss: 0.027586298063397408, dist_loss: 0.2902396321296692
recon_loss: 0.027587037533521652, dist_loss: 1.011622428894043
recon_loss: 0.02758631482720375, dist_loss: 0.6166853308677673
recon_loss: 0.02758609689772129, dist_loss: 0.4215804934501648
recon_loss: 0.027586057782173157, dist_loss: 0.3915279507637024
recon_loss: 0.027585018426179886, dist_loss: 0.5086585283279419
recon_loss: 0.02758546732366085, dist_loss: 0.5476446151733398
recon_loss: 0.02758631855249405, dist_loss: 0.4317169189453125
recon_loss: 0.0275884922593832, dist_loss: 0.5624643564224243
recon_loss: 0.02759023755788803, dist_loss: 0.7178349494934082
recon_loss: 0.027591167017817497, dist_loss: 0.8155760765075684
recon_loss: 0.027592163532972336, dist_loss: 1.0850900411605835
recon_loss: 0.027592597529292107, dist_loss: 0.6338027715682983
recon_loss: 0.02759370394051075, dist_loss: 1.151026725769043
recon_loss: 0.027591489255428314, dist_loss: 0.5351016521453857
recon_loss: 0.027591250836849213, dist_loss: 0.7233023047447205
recon_loss: 0.02758813090622425, dist_loss: 0.5738758444786072
recon_loss: 0.027587449178099632, dist_loss: 0.5814003348350525
recon_loss: 0.027586951851844788, dist_loss: 0.744182288646698
recon_loss: 0.027588218450546265, dist_loss: 0.9288376569747925
recon_loss: 0.0275897029787302, dist_loss: 0.6557175517082214
recon_loss: 0.027591805905103683, dist_loss: 0.4194091558456421
recon_loss: 0.027594905346632004, dist_loss: 0.8832994103431702
recon_loss: 0.02759646438062191, dist_loss: 0.7694660425186157
recon_loss: 0.027599504217505455, dist_loss: 0.590125560760498
recon_loss: 0.02760041132569313, dist_loss: 0.7197626829147339
recon_loss: 0.027601048350334167, dist_loss: 1.3831210136413574
recon_loss: 0.027600154280662537, dist_loss: 0.7713428735733032
recon_loss: 0.02759758196771145, dist_loss: 0.5100468993186951
recon_loss: 0.027594998478889465, dist_loss: 0.4105776250362396
recon_loss: 0.027592815458774567, dist_loss: 0.38590672612190247
recon_loss: 0.027590865269303322, dist_loss: 0.7917159199714661
recon_loss: 0.02758939191699028, dist_loss: 0.7581321597099304
recon_loss: 0.027587922289967537, dist_loss: 0.5671586990356445
recon_loss: 0.027587462216615677, dist_loss: 0.9420969486236572
recon_loss: 0.02758733183145523, dist_loss: 0.2317318618297577
recon_loss: 0.027588114142417908, dist_loss: 0.4614610970020294
recon_loss: 0.02758941799402237, dist_loss: 0.42300620675086975
recon_loss: 0.027591465041041374, dist_loss: 0.39626964926719666
recon_loss: 0.027593234553933144, dist_loss: 0.4106719493865967
recon_loss: 0.027595272287726402, dist_loss: 0.5075933933258057
recon_loss: 0.027596643194556236, dist_loss: 0.539679765701294
recon_loss: 0.027599239721894264, dist_loss: 0.6825414299964905
recon_loss: 0.027599742636084557, dist_loss: 0.5896487236022949
recon_loss: 0.02760065346956253, dist_loss: 0.440727174282074
recon_loss: 0.027600286528468132, dist_loss: 0.6170771718025208
recon_loss: 0.027599632740020752, dist_loss: 0.4315636157989502
recon_loss: 0.027598842978477478, dist_loss: 0.6122811436653137
recon_loss: 0.027596691623330116, dist_loss: 0.7549477815628052
recon_loss: 0.027594584971666336, dist_loss: 0.3436899781227112
recon_loss: 0.02759067341685295, dist_loss: 0.5123462677001953
recon_loss: 0.027588263154029846, dist_loss: 0.2962654232978821
recon_loss: 0.027587775141000748, dist_loss: 0.8852996230125427
recon_loss: 0.02758636884391308, dist_loss: 0.587103009223938
recon_loss: 0.027586719021201134, dist_loss: 0.4745340347290039
recon_loss: 0.027586888521909714, dist_loss: 0.5601745843887329
recon_loss: 0.027586709707975388, dist_loss: 0.5736954212188721
recon_loss: 0.027587667107582092, dist_loss: 1.1747021675109863
recon_loss: 0.027587395161390305, dist_loss: 0.6661466956138611
recon_loss: 0.027588849887251854, dist_loss: 1.0000121593475342
recon_loss: 0.027587592601776123, dist_loss: 0.3426896333694458
recon_loss: 0.027587292715907097, dist_loss: 1.2942012548446655
recon_loss: 0.027587564662098885, dist_loss: 0.6348106861114502
recon_loss: 0.027585504576563835, dist_loss: 1.4105850458145142
recon_loss: 0.02758612297475338, dist_loss: 0.7142236232757568
recon_loss: 0.027585381641983986, dist_loss: 0.5811426043510437
recon_loss: 0.027584196999669075, dist_loss: 0.9211359024047852
recon_loss: 0.02758488431572914, dist_loss: 0.4440493583679199
recon_loss: 0.027583912014961243, dist_loss: 0.8282909989356995
recon_loss: 0.027585430070757866, dist_loss: 0.5844545960426331
recon_loss: 0.02758508175611496, dist_loss: 0.9611775875091553
recon_loss: 0.027585631236433983, dist_loss: 0.7641699910163879
recon_loss: 0.027586527168750763, dist_loss: 0.5114262700080872
recon_loss: 0.02758513204753399, dist_loss: 0.7478358745574951
recon_loss: 0.02758820727467537, dist_loss: 0.5810109972953796
recon_loss: 0.02758786641061306, dist_loss: 0.38488510251045227
recon_loss: 0.027588015422225, dist_loss: 0.6852298974990845
recon_loss: 0.02758982963860035, dist_loss: 0.5851837396621704
recon_loss: 0.027585988864302635, dist_loss: 0.6925115585327148
recon_loss: 0.027585558593273163, dist_loss: 1.0182178020477295
recon_loss: 0.02758345939218998, dist_loss: 0.6439328193664551
recon_loss: 0.02758333832025528, dist_loss: 0.43101033568382263
recon_loss: 0.027584275230765343, dist_loss: 0.39016056060791016
recon_loss: 0.027583247050642967, dist_loss: 0.4785658121109009
recon_loss: 0.027584992349147797, dist_loss: 0.7758347988128662
recon_loss: 0.027585145086050034, dist_loss: 0.7178152203559875
recon_loss: 0.027587728574872017, dist_loss: 0.3836398720741272
recon_loss: 0.02758914977312088, dist_loss: 0.5639926195144653
recon_loss: 0.027591293677687645, dist_loss: 0.7465566396713257
recon_loss: 0.02759579010307789, dist_loss: 0.8284716010093689
recon_loss: 0.02760010026395321, dist_loss: 0.7848745584487915
recon_loss: 0.027601929381489754, dist_loss: 0.4152812957763672
recon_loss: 0.027602825313806534, dist_loss: 0.6420162916183472
recon_loss: 0.02760239690542221, dist_loss: 0.5263344645500183
recon_loss: 0.02760245092213154, dist_loss: 0.36531001329421997
recon_loss: 0.02760164998471737, dist_loss: 0.7503798007965088
recon_loss: 0.027600852772593498, dist_loss: 0.5540244579315186
recon_loss: 0.027601035311818123, dist_loss: 0.6907976865768433
recon_loss: 0.02759988233447075, dist_loss: 0.44495296478271484
recon_loss: 0.02759825997054577, dist_loss: 0.5860793590545654
recon_loss: 0.027595888823270798, dist_loss: 0.4381340742111206
recon_loss: 0.02759414166212082, dist_loss: 1.0752358436584473
recon_loss: 0.027592889964580536, dist_loss: 0.7603811025619507
recon_loss: 0.027589920908212662, dist_loss: 0.8000205159187317
recon_loss: 0.02758653089404106, dist_loss: 0.8008409142494202
recon_loss: 0.027587415650486946, dist_loss: 0.5621438026428223
recon_loss: 0.027587158605456352, dist_loss: 0.37654823064804077
recon_loss: 0.027588054537773132, dist_loss: 0.7113398313522339
recon_loss: 0.027589844539761543, dist_loss: 0.6342320442199707
recon_loss: 0.027590187266469002, dist_loss: 1.3013194799423218
recon_loss: 0.02759251743555069, dist_loss: 0.2745225429534912
recon_loss: 0.027593644335865974, dist_loss: 0.7560895681381226
recon_loss: 0.027593499049544334, dist_loss: 0.4516335427761078
recon_loss: 0.027593553066253662, dist_loss: 0.4658220708370209
recon_loss: 0.027592523023486137, dist_loss: 0.9291605949401855
recon_loss: 0.027590926736593246, dist_loss: 0.8027614951133728
recon_loss: 0.02759028971195221, dist_loss: 0.4394737482070923
recon_loss: 0.02759011648595333, dist_loss: 0.888441801071167
recon_loss: 0.02758951671421528, dist_loss: 0.47409939765930176
recon_loss: 0.027588531374931335, dist_loss: 0.8698728680610657
recon_loss: 0.027586914598941803, dist_loss: 0.7064975500106812
recon_loss: 0.027585232630372047, dist_loss: 0.7426726222038269
recon_loss: 0.027585292235016823, dist_loss: 0.7983776330947876
recon_loss: 0.02758331410586834, dist_loss: 0.8304624557495117
recon_loss: 0.02758256159722805, dist_loss: 1.001917839050293
recon_loss: 0.027581799775362015, dist_loss: 0.684116542339325
recon_loss: 0.027580691501498222, dist_loss: 0.4267388582229614
Pre-training Epoch 97:  72%|███████▏  | 264/367 [00:01<00:00, 164.87it/s]Pre-training Epoch 97:  77%|███████▋  | 282/367 [00:01<00:00, 168.73it/s]Pre-training Epoch 97:  81%|████████▏ | 299/367 [00:01<00:00, 168.95it/s]Pre-training Epoch 97:  86%|████████▌ | 316/367 [00:01<00:00, 166.88it/s]Pre-training Epoch 97:  91%|█████████ | 333/367 [00:02<00:00, 164.78it/s]Pre-training Epoch 97:  95%|█████████▌| 350/367 [00:02<00:00, 161.09it/s]Pre-training Epoch 97: 100%|██████████| 367/367 [00:02<00:00, 159.53it/s]Pre-training Epoch 97: 100%|██████████| 367/367 [00:02<00:00, 158.16it/s]
recon_loss: 0.027580691501498222, dist_loss: 0.47799694538116455
recon_loss: 0.027579672634601593, dist_loss: 1.1416265964508057
recon_loss: 0.02758028358221054, dist_loss: 0.29889756441116333
recon_loss: 0.027580292895436287, dist_loss: 0.6883382201194763
recon_loss: 0.027580641210079193, dist_loss: 0.5561512112617493
recon_loss: 0.02758181095123291, dist_loss: 0.709413468837738
recon_loss: 0.027579065412282944, dist_loss: 0.5013337135314941
recon_loss: 0.027579179033637047, dist_loss: 0.5881670713424683
recon_loss: 0.027578504756093025, dist_loss: 0.5824994444847107
recon_loss: 0.027579274028539658, dist_loss: 0.6764097809791565
recon_loss: 0.027579287067055702, dist_loss: 0.44093477725982666
recon_loss: 0.02757914364337921, dist_loss: 0.4274827241897583
recon_loss: 0.027580250054597855, dist_loss: 0.43264132738113403
recon_loss: 0.027579333633184433, dist_loss: 0.9410484433174133
recon_loss: 0.02757887728512287, dist_loss: 0.5451769828796387
recon_loss: 0.027578819543123245, dist_loss: 0.7071444988250732
recon_loss: 0.02757820300757885, dist_loss: 1.380779504776001
recon_loss: 0.02757934480905533, dist_loss: 0.8498584628105164
recon_loss: 0.02757924608886242, dist_loss: 0.7634546160697937
recon_loss: 0.027580028399825096, dist_loss: 0.5458451509475708
recon_loss: 0.027581872418522835, dist_loss: 0.4698486924171448
recon_loss: 0.027580970898270607, dist_loss: 0.7848307490348816
recon_loss: 0.02758151665329933, dist_loss: 0.5483095645904541
recon_loss: 0.027580851688981056, dist_loss: 0.5334469079971313
recon_loss: 0.027579622343182564, dist_loss: 0.6109418869018555
recon_loss: 0.027579473331570625, dist_loss: 0.46676263213157654
recon_loss: 0.027578288689255714, dist_loss: 0.9945579767227173
recon_loss: 0.027578022330999374, dist_loss: 0.37882083654403687
recon_loss: 0.027578245848417282, dist_loss: 1.0916746854782104
recon_loss: 0.027577988803386688, dist_loss: 0.5261495113372803
recon_loss: 0.027577798813581467, dist_loss: 0.2247840166091919
recon_loss: 0.02757749706506729, dist_loss: 1.211460828781128
recon_loss: 0.027577156201004982, dist_loss: 0.8633377552032471
recon_loss: 0.027577092871069908, dist_loss: 0.43660426139831543
recon_loss: 0.027577608823776245, dist_loss: 0.9371495246887207
recon_loss: 0.027577389031648636, dist_loss: 0.7192931771278381
recon_loss: 0.027577310800552368, dist_loss: 0.7946918606758118
recon_loss: 0.02757740020751953, dist_loss: 0.5168423056602478
recon_loss: 0.027577223256230354, dist_loss: 1.1764767169952393
recon_loss: 0.027578452602028847, dist_loss: 1.3582539558410645
recon_loss: 0.02757890336215496, dist_loss: 1.097379446029663
recon_loss: 0.02757990173995495, dist_loss: 0.7143232822418213
recon_loss: 0.027582842856645584, dist_loss: 0.8125765323638916
recon_loss: 0.02758163772523403, dist_loss: 0.5884999632835388
recon_loss: 0.027582986280322075, dist_loss: 0.8119738101959229
recon_loss: 0.02758317068219185, dist_loss: 0.5438567399978638
recon_loss: 0.027583325281739235, dist_loss: 0.3388507068157196
recon_loss: 0.027584051713347435, dist_loss: 0.5253421068191528
recon_loss: 0.027580788359045982, dist_loss: 0.6490597724914551
recon_loss: 0.02757970802485943, dist_loss: 0.48056498169898987
recon_loss: 0.02757810428738594, dist_loss: 0.6303809285163879
recon_loss: 0.027578525245189667, dist_loss: 0.5543071627616882
recon_loss: 0.027579234912991524, dist_loss: 0.5609983205795288
recon_loss: 0.027578627690672874, dist_loss: 0.4957974851131439
recon_loss: 0.027581172063946724, dist_loss: 0.5898036956787109
recon_loss: 0.027581535279750824, dist_loss: 0.7905443906784058
recon_loss: 0.027584372088313103, dist_loss: 0.41577428579330444
recon_loss: 0.027583377435803413, dist_loss: 0.5181200504302979
recon_loss: 0.02758363075554371, dist_loss: 1.1216001510620117
recon_loss: 0.02758307382464409, dist_loss: 0.568621039390564
recon_loss: 0.02758135460317135, dist_loss: 0.5524983406066895
recon_loss: 0.02758204936981201, dist_loss: 0.9933143258094788
recon_loss: 0.027580302208662033, dist_loss: 0.5996401309967041
recon_loss: 0.027580363675951958, dist_loss: 0.6586114168167114
recon_loss: 0.02757992595434189, dist_loss: 0.5723329186439514
recon_loss: 0.027578508481383324, dist_loss: 0.6074922680854797
recon_loss: 0.02757832035422325, dist_loss: 0.8941657543182373
recon_loss: 0.02757790870964527, dist_loss: 0.3741055727005005
recon_loss: 0.027576975524425507, dist_loss: 0.8357403874397278
recon_loss: 0.027576759457588196, dist_loss: 0.3846403956413269
recon_loss: 0.0275766309350729, dist_loss: 0.6454963684082031
recon_loss: 0.02757631614804268, dist_loss: 0.5686788558959961
recon_loss: 0.02757631242275238, dist_loss: 1.1197999715805054
recon_loss: 0.027576761320233345, dist_loss: 0.3386216163635254
recon_loss: 0.027576619759202003, dist_loss: 0.607024610042572
recon_loss: 0.027576232329010963, dist_loss: 0.6111828088760376
recon_loss: 0.02757609449326992, dist_loss: 0.551425576210022
recon_loss: 0.027575658634305, dist_loss: 0.5357524156570435
recon_loss: 0.027575667947530746, dist_loss: 0.5064897537231445
recon_loss: 0.027575671672821045, dist_loss: 0.9068095088005066
recon_loss: 0.027575939893722534, dist_loss: 0.8869507908821106
recon_loss: 0.02757650427520275, dist_loss: 0.28996288776397705
recon_loss: 0.02757682465016842, dist_loss: 0.5774426460266113
recon_loss: 0.02757706120610237, dist_loss: 0.5308020710945129
recon_loss: 0.02757730893790722, dist_loss: 0.520176887512207
recon_loss: 0.027577968314290047, dist_loss: 0.5559030771255493
recon_loss: 0.027578366920351982, dist_loss: 0.8364145755767822
recon_loss: 0.027577489614486694, dist_loss: 0.514487087726593
recon_loss: 0.02757747657597065, dist_loss: 0.5653319358825684
recon_loss: 0.027576515451073647, dist_loss: 0.36523839831352234
recon_loss: 0.02757556177675724, dist_loss: 0.7261841297149658
recon_loss: 0.027574988082051277, dist_loss: 0.6610841751098633
recon_loss: 0.027574662119150162, dist_loss: 0.5700460076332092
recon_loss: 0.027574777603149414, dist_loss: 1.033750295639038
recon_loss: 0.027574975043535233, dist_loss: 0.27219241857528687
recon_loss: 0.02757488377392292, dist_loss: 0.6121105551719666
recon_loss: 0.02757469192147255, dist_loss: 0.7127169370651245
recon_loss: 0.02757462114095688, dist_loss: 0.6635088920593262
recon_loss: 0.027574429288506508, dist_loss: 0.8760929703712463
recon_loss: 0.027574334293603897, dist_loss: 0.8009569644927979
recon_loss: 0.02757379598915577, dist_loss: 0.6751042008399963
recon_loss: 0.027573544532060623, dist_loss: 0.4767434298992157
recon_loss: 0.027573183178901672, dist_loss: 0.3255399465560913
recon_loss: 0.027573024854063988, dist_loss: 0.7788735628128052
recon_loss: 0.02757333591580391, dist_loss: 0.46162188053131104
recon_loss: 0.02757302112877369, dist_loss: 0.9447490572929382
recon_loss: 0.027574069797992706, dist_loss: 0.5483825206756592
recon_loss: 0.027573775500059128, dist_loss: 0.508677065372467
recon_loss: 0.02757366932928562, dist_loss: 0.6191130876541138
recon_loss: 0.02757498435676098, dist_loss: 0.7842931747436523
recon_loss: 0.027573347091674805, dist_loss: 1.1603078842163086
Pre-training Epoch 98:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 98:   4%|▍         | 15/367 [00:00<00:02, 147.39it/s]Pre-training Epoch 98:   8%|▊         | 31/367 [00:00<00:02, 150.96it/s]Pre-training Epoch 98:  13%|█▎        | 47/367 [00:00<00:02, 153.89it/s]Pre-training Epoch 98:  17%|█▋        | 63/367 [00:00<00:01, 155.58it/s]Pre-training Epoch 98:  22%|██▏       | 79/367 [00:00<00:01, 152.82it/s]Pre-training Epoch 98:  26%|██▌       | 95/367 [00:00<00:01, 153.04it/s]Pre-training Epoch 98:  30%|███       | 111/367 [00:00<00:01, 154.92it/s]Pre-training Epoch 98:  35%|███▍      | 128/367 [00:00<00:01, 158.17it/s]recon_loss: 0.02757384069263935, dist_loss: 0.6142874956130981
recon_loss: 0.02757340669631958, dist_loss: 0.6862806081771851
recon_loss: 0.027573203667998314, dist_loss: 0.7856090068817139
recon_loss: 0.027573857456445694, dist_loss: 0.5818853974342346
recon_loss: 0.027573296800255775, dist_loss: 0.798265814781189
recon_loss: 0.027574053034186363, dist_loss: 0.6990984082221985
recon_loss: 0.02757429890334606, dist_loss: 0.48997610807418823
recon_loss: 0.027573715895414352, dist_loss: 0.9383032917976379
recon_loss: 0.02757444605231285, dist_loss: 0.741923987865448
recon_loss: 0.02757352963089943, dist_loss: 0.4207209348678589
recon_loss: 0.027574103325605392, dist_loss: 0.4765816032886505
recon_loss: 0.02757350169122219, dist_loss: 0.42946597933769226
recon_loss: 0.02757379226386547, dist_loss: 0.7552441358566284
recon_loss: 0.027574002742767334, dist_loss: 0.624953031539917
recon_loss: 0.02757296897470951, dist_loss: 0.4838983416557312
recon_loss: 0.027572767809033394, dist_loss: 0.5119922161102295
recon_loss: 0.027572643011808395, dist_loss: 0.6994801759719849
recon_loss: 0.027572665363550186, dist_loss: 0.6467655897140503
recon_loss: 0.027572788298130035, dist_loss: 0.5644367933273315
recon_loss: 0.027572939172387123, dist_loss: 0.6383621692657471
recon_loss: 0.02757304534316063, dist_loss: 0.3691885769367218
recon_loss: 0.027573011815547943, dist_loss: 0.8639757633209229
recon_loss: 0.02757290191948414, dist_loss: 0.3599679172039032
recon_loss: 0.027573266997933388, dist_loss: 0.6097109317779541
recon_loss: 0.027572641149163246, dist_loss: 0.5286598205566406
recon_loss: 0.027573127299547195, dist_loss: 0.8023090362548828
recon_loss: 0.02757261134684086, dist_loss: 0.756995439529419
recon_loss: 0.02757265232503414, dist_loss: 0.6706764698028564
recon_loss: 0.02757279947400093, dist_loss: 0.5807434320449829
recon_loss: 0.02757285162806511, dist_loss: 0.5708392858505249
recon_loss: 0.027573052793741226, dist_loss: 0.7837541103363037
recon_loss: 0.02757279947400093, dist_loss: 0.8069207072257996
recon_loss: 0.027572661638259888, dist_loss: 0.540137767791748
recon_loss: 0.027572322636842728, dist_loss: 0.5674924850463867
recon_loss: 0.027572093531489372, dist_loss: 0.5351960062980652
recon_loss: 0.027571935206651688, dist_loss: 0.6660431027412415
recon_loss: 0.02757146768271923, dist_loss: 0.6862156391143799
recon_loss: 0.027571098878979683, dist_loss: 0.49041157960891724
recon_loss: 0.027570681646466255, dist_loss: 0.828348696231842
recon_loss: 0.027570465579628944, dist_loss: 0.7945331931114197
recon_loss: 0.027570169419050217, dist_loss: 0.8653359413146973
recon_loss: 0.027570128440856934, dist_loss: 0.5740835666656494
recon_loss: 0.0275699645280838, dist_loss: 0.39813822507858276
recon_loss: 0.027569590136408806, dist_loss: 0.5877484083175659
recon_loss: 0.027569418773055077, dist_loss: 0.4187471866607666
recon_loss: 0.02756943553686142, dist_loss: 0.8831049799919128
recon_loss: 0.0275697223842144, dist_loss: 0.8394601345062256
recon_loss: 0.027569884434342384, dist_loss: 0.3241247832775116
recon_loss: 0.0275700893253088, dist_loss: 0.6236844062805176
recon_loss: 0.027570193633437157, dist_loss: 1.0094295740127563
recon_loss: 0.027570294216275215, dist_loss: 0.6514476537704468
recon_loss: 0.02757062204182148, dist_loss: 0.8832364678382874
recon_loss: 0.027570480480790138, dist_loss: 0.42370957136154175
recon_loss: 0.02757057175040245, dist_loss: 0.8505096435546875
recon_loss: 0.027570512145757675, dist_loss: 0.8607236742973328
recon_loss: 0.02757061831653118, dist_loss: 0.7555521130561829
recon_loss: 0.027570011094212532, dist_loss: 0.3339197635650635
recon_loss: 0.0275694839656353, dist_loss: 0.6910514831542969
recon_loss: 0.02756921574473381, dist_loss: 0.657233476638794
recon_loss: 0.027569087222218513, dist_loss: 0.7362937927246094
recon_loss: 0.027569087222218513, dist_loss: 0.3503512740135193
recon_loss: 0.02756878361105919, dist_loss: 0.6811524629592896
recon_loss: 0.027568751946091652, dist_loss: 0.6548379063606262
recon_loss: 0.027568966150283813, dist_loss: 0.8367375135421753
recon_loss: 0.027569027617573738, dist_loss: 0.4881671667098999
recon_loss: 0.02756989747285843, dist_loss: 0.6075150966644287
recon_loss: 0.02757076732814312, dist_loss: 0.5740224123001099
recon_loss: 0.027571532875299454, dist_loss: 0.99504554271698
recon_loss: 0.027572279796004295, dist_loss: 0.6121137142181396
recon_loss: 0.027572324499487877, dist_loss: 0.923839271068573
recon_loss: 0.027572542428970337, dist_loss: 1.0897607803344727
recon_loss: 0.027571095153689384, dist_loss: 0.39825496077537537
recon_loss: 0.02757079340517521, dist_loss: 0.6165180802345276
recon_loss: 0.027570413425564766, dist_loss: 0.6717836260795593
recon_loss: 0.027570724487304688, dist_loss: 0.5558395981788635
recon_loss: 0.0275708120316267, dist_loss: 0.4585021734237671
recon_loss: 0.027570081874728203, dist_loss: 0.4922950267791748
recon_loss: 0.027570314705371857, dist_loss: 0.9828500151634216
recon_loss: 0.027569608762860298, dist_loss: 0.8315314054489136
recon_loss: 0.027569852769374847, dist_loss: 0.7671617269515991
recon_loss: 0.027569813653826714, dist_loss: 1.0143827199935913
recon_loss: 0.027568673714995384, dist_loss: 1.1138792037963867
recon_loss: 0.027569834142923355, dist_loss: 0.6762181520462036
recon_loss: 0.02756856195628643, dist_loss: 0.8075693845748901
recon_loss: 0.027569718658924103, dist_loss: 0.9156005382537842
recon_loss: 0.027569444850087166, dist_loss: 0.4163992404937744
recon_loss: 0.027568241581320763, dist_loss: 0.7388325929641724
recon_loss: 0.027568837627768517, dist_loss: 0.5223082304000854
recon_loss: 0.02756786160171032, dist_loss: 0.7648004293441772
recon_loss: 0.027568398043513298, dist_loss: 0.42946696281433105
recon_loss: 0.02756834588944912, dist_loss: 0.5610278844833374
recon_loss: 0.027568545192480087, dist_loss: 1.0791996717453003
recon_loss: 0.027569247409701347, dist_loss: 0.47864416241645813
recon_loss: 0.027568699792027473, dist_loss: 0.7437705993652344
recon_loss: 0.027568906545639038, dist_loss: 0.40085166692733765
recon_loss: 0.02756866067647934, dist_loss: 0.6093857288360596
recon_loss: 0.02756856009364128, dist_loss: 0.7724308967590332
recon_loss: 0.027568843215703964, dist_loss: 0.7544237971305847
recon_loss: 0.027568630874156952, dist_loss: 0.7116446495056152
recon_loss: 0.027568867430090904, dist_loss: 0.5069999694824219
recon_loss: 0.027568267658352852, dist_loss: 0.6370455622673035
recon_loss: 0.027567820623517036, dist_loss: 0.4827122092247009
recon_loss: 0.027568623423576355, dist_loss: 1.0490665435791016
recon_loss: 0.027568260207772255, dist_loss: 0.5327537059783936
recon_loss: 0.027569014579057693, dist_loss: 0.6892316937446594
recon_loss: 0.027569083496928215, dist_loss: 0.6281928420066833
recon_loss: 0.027567695826292038, dist_loss: 0.5485707521438599
recon_loss: 0.027568228542804718, dist_loss: 0.6563760042190552
recon_loss: 0.027567552402615547, dist_loss: 0.7126584053039551
recon_loss: 0.027567658573389053, dist_loss: 1.1452537775039673
recon_loss: 0.027566898614168167, dist_loss: 0.45111238956451416
recon_loss: 0.027566397562623024, dist_loss: 0.6251580119132996
recon_loss: 0.0275664571672678, dist_loss: 0.8110429644584656
recon_loss: 0.027565957978367805, dist_loss: 0.8845710158348083
recon_loss: 0.027565961703658104, dist_loss: 0.6883113980293274
recon_loss: 0.027565697208046913, dist_loss: 0.7081468105316162
recon_loss: 0.027565855532884598, dist_loss: 0.7150534391403198
recon_loss: 0.027566585689783096, dist_loss: 0.3953528106212616
recon_loss: 0.02756626345217228, dist_loss: 0.8932380676269531
recon_loss: 0.027565978467464447, dist_loss: 0.3569718599319458
recon_loss: 0.02756541408598423, dist_loss: 0.697884202003479
recon_loss: 0.02756604179739952, dist_loss: 0.8580317497253418
recon_loss: 0.027565347030758858, dist_loss: 0.8577152490615845
recon_loss: 0.02756625786423683, dist_loss: 0.3995634615421295
recon_loss: 0.02756783924996853, dist_loss: 0.5973437428474426
recon_loss: 0.027568867430090904, dist_loss: 0.4971413314342499
recon_loss: 0.027569711208343506, dist_loss: 0.6985398530960083
recon_loss: 0.02757006511092186, dist_loss: 1.2319080829620361
Pre-training Epoch 98:  39%|███▉      | 144/367 [00:00<00:01, 158.12it/s]Pre-training Epoch 98:  44%|████▍     | 161/367 [00:01<00:01, 160.01it/s]Pre-training Epoch 98:  49%|████▊     | 178/367 [00:01<00:01, 161.29it/s]Pre-training Epoch 98:  53%|█████▎    | 195/367 [00:01<00:01, 162.24it/s]Pre-training Epoch 98:  58%|█████▊    | 212/367 [00:01<00:00, 162.70it/s]Pre-training Epoch 98:  62%|██████▏   | 229/367 [00:01<00:00, 162.42it/s]Pre-training Epoch 98:  67%|██████▋   | 246/367 [00:01<00:00, 163.14it/s]recon_loss: 0.027569668367505074, dist_loss: 0.8776163458824158
recon_loss: 0.027569441124796867, dist_loss: 0.6830672025680542
recon_loss: 0.027568375691771507, dist_loss: 0.6568799018859863
recon_loss: 0.027568446472287178, dist_loss: 0.3761626183986664
recon_loss: 0.027568332850933075, dist_loss: 0.3332030773162842
recon_loss: 0.02756752260029316, dist_loss: 0.5298131704330444
recon_loss: 0.027568550780415535, dist_loss: 0.390239417552948
recon_loss: 0.02756650373339653, dist_loss: 0.45272207260131836
recon_loss: 0.027566328644752502, dist_loss: 0.7157366275787354
recon_loss: 0.02756602130830288, dist_loss: 0.7297674417495728
recon_loss: 0.027565551921725273, dist_loss: 0.5480177402496338
recon_loss: 0.027566200122237206, dist_loss: 0.9039723873138428
recon_loss: 0.02756517194211483, dist_loss: 0.5939188003540039
recon_loss: 0.02756597101688385, dist_loss: 0.9901368618011475
recon_loss: 0.027566595003008842, dist_loss: 0.7311862707138062
recon_loss: 0.027567990124225616, dist_loss: 0.567435622215271
recon_loss: 0.0275685153901577, dist_loss: 0.9765561819076538
recon_loss: 0.027569442987442017, dist_loss: 1.0208449363708496
recon_loss: 0.02757103554904461, dist_loss: 0.5154048204421997
recon_loss: 0.0275714211165905, dist_loss: 1.1168999671936035
recon_loss: 0.027571190148591995, dist_loss: 0.4185447096824646
recon_loss: 0.027569951489567757, dist_loss: 0.4179095923900604
recon_loss: 0.02756977453827858, dist_loss: 0.5332456827163696
recon_loss: 0.027568405494093895, dist_loss: 0.5528374910354614
recon_loss: 0.02756769210100174, dist_loss: 0.4428836703300476
recon_loss: 0.027566729113459587, dist_loss: 0.35346049070358276
recon_loss: 0.02756587602198124, dist_loss: 0.5041550397872925
recon_loss: 0.027565358206629753, dist_loss: 0.9440250396728516
recon_loss: 0.027565157040953636, dist_loss: 0.5050037503242493
recon_loss: 0.02756553143262863, dist_loss: 0.8191957473754883
recon_loss: 0.027565306052565575, dist_loss: 0.6003429889678955
recon_loss: 0.027565674856305122, dist_loss: 0.766831636428833
recon_loss: 0.02756560780107975, dist_loss: 1.1117135286331177
recon_loss: 0.027566658332943916, dist_loss: 0.7352920770645142
recon_loss: 0.02756619267165661, dist_loss: 0.5103576183319092
recon_loss: 0.02756647579371929, dist_loss: 0.5447174310684204
recon_loss: 0.027566634118556976, dist_loss: 0.973884105682373
recon_loss: 0.027566056698560715, dist_loss: 1.023648977279663
recon_loss: 0.027566557750105858, dist_loss: 0.6461858749389648
recon_loss: 0.027566716074943542, dist_loss: 0.7313594222068787
recon_loss: 0.02756744995713234, dist_loss: 0.5311882495880127
recon_loss: 0.02756892889738083, dist_loss: 0.8244749307632446
recon_loss: 0.02756991609930992, dist_loss: 0.6201790571212769
recon_loss: 0.027570081874728203, dist_loss: 0.802800178527832
recon_loss: 0.027569249272346497, dist_loss: 0.7425600290298462
recon_loss: 0.027568945661187172, dist_loss: 1.1557928323745728
recon_loss: 0.02756824716925621, dist_loss: 0.5209168195724487
recon_loss: 0.027567319571971893, dist_loss: 0.6190785765647888
recon_loss: 0.02756650745868683, dist_loss: 0.6569698452949524
recon_loss: 0.02756592445075512, dist_loss: 0.637700080871582
recon_loss: 0.027566125616431236, dist_loss: 1.128723382949829
recon_loss: 0.027566904202103615, dist_loss: 0.6200451850891113
recon_loss: 0.027568181976675987, dist_loss: 0.813381552696228
recon_loss: 0.027570102363824844, dist_loss: 0.8897266983985901
recon_loss: 0.027570638805627823, dist_loss: 0.5414619445800781
recon_loss: 0.027570689097046852, dist_loss: 0.5533145070075989
recon_loss: 0.02757086604833603, dist_loss: 0.41521769762039185
recon_loss: 0.027570338919758797, dist_loss: 0.7503589391708374
recon_loss: 0.0275708120316267, dist_loss: 0.4590817391872406
recon_loss: 0.027570707723498344, dist_loss: 0.6720424890518188
recon_loss: 0.027570175006985664, dist_loss: 0.4757087826728821
recon_loss: 0.027569076046347618, dist_loss: 0.4147489368915558
recon_loss: 0.027567462995648384, dist_loss: 0.6466598510742188
recon_loss: 0.027566242963075638, dist_loss: 0.7470411062240601
recon_loss: 0.027565132826566696, dist_loss: 0.8384912610054016
recon_loss: 0.02756470814347267, dist_loss: 0.5735947489738464
recon_loss: 0.0275642778724432, dist_loss: 0.36036616563796997
recon_loss: 0.02756398171186447, dist_loss: 0.5446044206619263
recon_loss: 0.027563773095607758, dist_loss: 0.6850322484970093
recon_loss: 0.02756396308541298, dist_loss: 0.6105126142501831
recon_loss: 0.027563920244574547, dist_loss: 0.4197925627231598
recon_loss: 0.027564028277993202, dist_loss: 0.615009069442749
recon_loss: 0.027563534677028656, dist_loss: 1.0424302816390991
recon_loss: 0.027563223615288734, dist_loss: 0.5972824096679688
recon_loss: 0.02756240777671337, dist_loss: 0.48316293954849243
recon_loss: 0.027562033385038376, dist_loss: 0.6793033480644226
recon_loss: 0.027561422437429428, dist_loss: 1.0730338096618652
recon_loss: 0.027561919763684273, dist_loss: 0.3708049952983856
recon_loss: 0.02756187506020069, dist_loss: 0.5565490126609802
recon_loss: 0.027562638744711876, dist_loss: 0.3718608021736145
recon_loss: 0.02756347320973873, dist_loss: 0.613178014755249
recon_loss: 0.027563786134123802, dist_loss: 0.545103907585144
recon_loss: 0.027564365416765213, dist_loss: 0.6122539639472961
recon_loss: 0.02756495773792267, dist_loss: 0.6434943675994873
recon_loss: 0.027565767988562584, dist_loss: 0.8866773843765259
recon_loss: 0.027566932141780853, dist_loss: 0.4955803155899048
recon_loss: 0.027566973119974136, dist_loss: 1.020571231842041
recon_loss: 0.02756737917661667, dist_loss: 0.6607347726821899
recon_loss: 0.027566678822040558, dist_loss: 0.5671825408935547
recon_loss: 0.027567051351070404, dist_loss: 0.54067063331604
recon_loss: 0.02756679616868496, dist_loss: 0.7787876129150391
recon_loss: 0.027566727250814438, dist_loss: 0.609991192817688
recon_loss: 0.027565959841012955, dist_loss: 0.5997331142425537
recon_loss: 0.02756529487669468, dist_loss: 0.5895771980285645
recon_loss: 0.027564601972699165, dist_loss: 0.4457496702671051
recon_loss: 0.027564842253923416, dist_loss: 0.9463925957679749
recon_loss: 0.02756495401263237, dist_loss: 0.4089429974555969
recon_loss: 0.02756582945585251, dist_loss: 1.01067316532135
recon_loss: 0.027565989643335342, dist_loss: 0.4360261559486389
recon_loss: 0.02756623923778534, dist_loss: 0.7658884525299072
recon_loss: 0.027566559612751007, dist_loss: 0.9853761196136475
recon_loss: 0.02756638266146183, dist_loss: 0.7379385828971863
recon_loss: 0.0275677889585495, dist_loss: 0.7610317468643188
recon_loss: 0.027567436918616295, dist_loss: 0.37954583764076233
recon_loss: 0.027567142620682716, dist_loss: 0.5071088671684265
recon_loss: 0.02756640501320362, dist_loss: 0.41305726766586304
recon_loss: 0.02756471559405327, dist_loss: 1.1996320486068726
recon_loss: 0.027563955634832382, dist_loss: 0.4123225808143616
recon_loss: 0.027562513947486877, dist_loss: 0.31060338020324707
recon_loss: 0.027562126517295837, dist_loss: 0.8137255907058716
recon_loss: 0.027562763541936874, dist_loss: 0.5628652572631836
recon_loss: 0.027561916038393974, dist_loss: 0.6292762756347656
recon_loss: 0.027563130483031273, dist_loss: 0.5066670179367065
recon_loss: 0.02756352536380291, dist_loss: 0.5133114457130432
recon_loss: 0.027563882991671562, dist_loss: 0.6280149817466736
recon_loss: 0.027565065771341324, dist_loss: 0.5777256488800049
recon_loss: 0.02756495401263237, dist_loss: 0.5729355812072754
recon_loss: 0.027565917000174522, dist_loss: 0.4310269355773926
recon_loss: 0.027564601972699165, dist_loss: 0.8199757933616638
recon_loss: 0.02756371535360813, dist_loss: 0.3834708333015442
recon_loss: 0.02756262570619583, dist_loss: 0.8825605511665344
recon_loss: 0.027561815455555916, dist_loss: 0.45185887813568115
recon_loss: 0.027561401948332787, dist_loss: 0.618181586265564
recon_loss: 0.027560967952013016, dist_loss: 0.943074107170105
recon_loss: 0.027560286223888397, dist_loss: 0.29297935962677
recon_loss: 0.02756042405962944, dist_loss: 0.29369908571243286
recon_loss: 0.027560463175177574, dist_loss: 0.7263107299804688
recon_loss: 0.02756088227033615, dist_loss: 1.2845886945724487
recon_loss: 0.02756074257194996, dist_loss: 0.545962929725647
Pre-training Epoch 98:  72%|███████▏  | 263/367 [00:01<00:00, 160.55it/s]Pre-training Epoch 98:  76%|███████▋  | 280/367 [00:01<00:00, 158.42it/s]Pre-training Epoch 98:  81%|████████  | 296/367 [00:01<00:00, 156.36it/s]Pre-training Epoch 98:  86%|████████▌ | 314/367 [00:01<00:00, 162.86it/s]Pre-training Epoch 98:  90%|█████████ | 332/367 [00:02<00:00, 167.73it/s]Pre-training Epoch 98:  96%|█████████▌| 351/367 [00:02<00:00, 172.06it/s]Pre-training Epoch 98: 100%|██████████| 367/367 [00:02<00:00, 161.88it/s]
recon_loss: 0.027560696005821228, dist_loss: 0.4372885823249817
recon_loss: 0.02756098099052906, dist_loss: 0.6560919284820557
recon_loss: 0.027561288326978683, dist_loss: 0.49139082431793213
recon_loss: 0.027561280876398087, dist_loss: 0.6516780853271484
recon_loss: 0.027561169117689133, dist_loss: 0.6767507195472717
recon_loss: 0.027561048045754433, dist_loss: 0.49548566341400146
recon_loss: 0.027560783550143242, dist_loss: 0.9028012156486511
recon_loss: 0.027559801936149597, dist_loss: 1.2450981140136719
recon_loss: 0.0275591891258955, dist_loss: 0.7094805836677551
recon_loss: 0.02755800448358059, dist_loss: 0.7544081807136536
recon_loss: 0.02755744196474552, dist_loss: 0.6655560731887817
recon_loss: 0.02755706198513508, dist_loss: 0.7531479001045227
recon_loss: 0.027557088062167168, dist_loss: 0.8883026838302612
recon_loss: 0.02755730226635933, dist_loss: 0.46345317363739014
recon_loss: 0.027558237314224243, dist_loss: 0.7898350954055786
recon_loss: 0.027559712529182434, dist_loss: 1.0413436889648438
recon_loss: 0.02756103128194809, dist_loss: 0.5037375688552856
recon_loss: 0.027561882510781288, dist_loss: 0.31297338008880615
recon_loss: 0.027562227100133896, dist_loss: 0.5814308524131775
recon_loss: 0.027563389390707016, dist_loss: 1.0337069034576416
recon_loss: 0.02756350487470627, dist_loss: 0.5310153365135193
recon_loss: 0.027563737705349922, dist_loss: 0.6287695169448853
recon_loss: 0.027563970535993576, dist_loss: 0.783221960067749
recon_loss: 0.027564747259020805, dist_loss: 0.43596577644348145
recon_loss: 0.027564246207475662, dist_loss: 0.6435059309005737
recon_loss: 0.027564173564314842, dist_loss: 0.6243022084236145
recon_loss: 0.027563106268644333, dist_loss: 0.4232689440250397
recon_loss: 0.027560915797948837, dist_loss: 0.25208383798599243
recon_loss: 0.027561016380786896, dist_loss: 0.6070738434791565
recon_loss: 0.027559373527765274, dist_loss: 0.43760907649993896
recon_loss: 0.02755916863679886, dist_loss: 0.827826976776123
recon_loss: 0.02755928225815296, dist_loss: 0.8534428477287292
recon_loss: 0.027558473870158195, dist_loss: 0.6831086874008179
recon_loss: 0.027559150010347366, dist_loss: 0.6547049283981323
recon_loss: 0.027559109032154083, dist_loss: 0.5309963822364807
recon_loss: 0.02756027691066265, dist_loss: 0.5839692950248718
recon_loss: 0.027560679242014885, dist_loss: 0.5405558347702026
recon_loss: 0.027561090886592865, dist_loss: 0.6819731593132019
recon_loss: 0.02756187878549099, dist_loss: 0.31194406747817993
recon_loss: 0.027561098337173462, dist_loss: 0.7895616292953491
recon_loss: 0.027560990303754807, dist_loss: 0.2930384576320648
recon_loss: 0.027559973299503326, dist_loss: 0.622616171836853
recon_loss: 0.027559729292988777, dist_loss: 0.6769527792930603
recon_loss: 0.027559274807572365, dist_loss: 0.649442195892334
recon_loss: 0.027558568865060806, dist_loss: 0.434506356716156
recon_loss: 0.027558112516999245, dist_loss: 0.5242254137992859
recon_loss: 0.02755754441022873, dist_loss: 0.48854130506515503
recon_loss: 0.02755734510719776, dist_loss: 0.4809054732322693
recon_loss: 0.027557073161005974, dist_loss: 0.6544144153594971
recon_loss: 0.02755710482597351, dist_loss: 0.5387175679206848
recon_loss: 0.027556924149394035, dist_loss: 1.025364637374878
recon_loss: 0.02755659632384777, dist_loss: 0.39196842908859253
recon_loss: 0.027556162327528, dist_loss: 0.9280797839164734
recon_loss: 0.027555713430047035, dist_loss: 0.6200799345970154
recon_loss: 0.02755550853908062, dist_loss: 0.9402071237564087
recon_loss: 0.02755502238869667, dist_loss: 0.7275562286376953
recon_loss: 0.027555378153920174, dist_loss: 0.4944363832473755
recon_loss: 0.027555005624890327, dist_loss: 0.8627635836601257
recon_loss: 0.02755567617714405, dist_loss: 0.6932404041290283
recon_loss: 0.027554797008633614, dist_loss: 0.5386258959770203
recon_loss: 0.027554599568247795, dist_loss: 0.42598262429237366
recon_loss: 0.02755451202392578, dist_loss: 0.7396532297134399
recon_loss: 0.027553847059607506, dist_loss: 0.4792710542678833
recon_loss: 0.027553826570510864, dist_loss: 0.404610812664032
recon_loss: 0.027553478255867958, dist_loss: 0.7401289939880371
recon_loss: 0.02755386009812355, dist_loss: 0.6276092529296875
recon_loss: 0.02755383402109146, dist_loss: 0.7259799838066101
recon_loss: 0.027553820982575417, dist_loss: 0.4571068286895752
recon_loss: 0.027553478255867958, dist_loss: 0.7757465243339539
recon_loss: 0.027553262189030647, dist_loss: 0.5240653157234192
recon_loss: 0.02755342796444893, dist_loss: 0.8222339153289795
recon_loss: 0.027553364634513855, dist_loss: 0.966629683971405
recon_loss: 0.027553237974643707, dist_loss: 0.4070017337799072
recon_loss: 0.027553262189030647, dist_loss: 0.6279687881469727
recon_loss: 0.027553843334317207, dist_loss: 0.7954164743423462
recon_loss: 0.027554359287023544, dist_loss: 0.8147976398468018
recon_loss: 0.02755500189960003, dist_loss: 0.38976871967315674
recon_loss: 0.027555933222174644, dist_loss: 0.46661001443862915
recon_loss: 0.027556873857975006, dist_loss: 0.633421778678894
recon_loss: 0.027556417509913445, dist_loss: 0.7061336040496826
recon_loss: 0.027556929737329483, dist_loss: 0.6219799518585205
recon_loss: 0.027556229382753372, dist_loss: 0.41168850660324097
recon_loss: 0.027555814012885094, dist_loss: 0.4422861337661743
recon_loss: 0.027555041015148163, dist_loss: 0.6887315511703491
recon_loss: 0.027554282918572426, dist_loss: 0.5810538530349731
recon_loss: 0.027553360909223557, dist_loss: 0.5171686410903931
recon_loss: 0.02755286917090416, dist_loss: 0.5659173130989075
recon_loss: 0.027553556486964226, dist_loss: 0.49502068758010864
recon_loss: 0.027553243562579155, dist_loss: 0.6109180450439453
recon_loss: 0.027554217725992203, dist_loss: 0.7880224585533142
recon_loss: 0.027554137632250786, dist_loss: 0.7181863188743591
recon_loss: 0.027554715052247047, dist_loss: 0.6540476083755493
recon_loss: 0.027554715052247047, dist_loss: 0.8912976980209351
recon_loss: 0.02755519561469555, dist_loss: 0.676459014415741
recon_loss: 0.027555033564567566, dist_loss: 0.5444989204406738
recon_loss: 0.02755557745695114, dist_loss: 0.5616010427474976
recon_loss: 0.027556683868169785, dist_loss: 0.47316843271255493
recon_loss: 0.027557728812098503, dist_loss: 0.6015089750289917
recon_loss: 0.027557671070098877, dist_loss: 0.7943118810653687
recon_loss: 0.027557989582419395, dist_loss: 0.658461332321167
recon_loss: 0.0275573693215847, dist_loss: 0.6018301844596863
recon_loss: 0.027555830776691437, dist_loss: 0.8090094327926636
recon_loss: 0.02755509689450264, dist_loss: 0.6244139671325684
recon_loss: 0.027553224936127663, dist_loss: 0.8759129047393799
recon_loss: 0.027553748339414597, dist_loss: 0.33921754360198975
recon_loss: 0.027552636340260506, dist_loss: 0.9531757831573486
recon_loss: 0.0275538619607687, dist_loss: 0.5547723770141602
recon_loss: 0.027555735781788826, dist_loss: 0.6679593324661255
recon_loss: 0.027555566281080246, dist_loss: 0.47941988706588745
recon_loss: 0.027557583525776863, dist_loss: 0.5967833399772644
Pre-training Epoch 99:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 99:   5%|▍         | 17/367 [00:00<00:02, 162.39it/s]Pre-training Epoch 99:  10%|▉         | 35/367 [00:00<00:01, 172.55it/s]Pre-training Epoch 99:  14%|█▍        | 53/367 [00:00<00:01, 168.48it/s]Pre-training Epoch 99:  19%|█▉        | 70/367 [00:00<00:01, 161.77it/s]Pre-training Epoch 99:  24%|██▎       | 87/367 [00:00<00:01, 159.51it/s]Pre-training Epoch 99:  28%|██▊       | 103/367 [00:00<00:01, 158.25it/s]Pre-training Epoch 99:  32%|███▏      | 119/367 [00:00<00:01, 157.55it/s]recon_loss: 0.027557456865906715, dist_loss: 0.5763883590698242
recon_loss: 0.0275577362626791, dist_loss: 0.893683671951294
recon_loss: 0.027558866888284683, dist_loss: 0.7817084789276123
recon_loss: 0.027557983994483948, dist_loss: 0.8090754151344299
recon_loss: 0.02755574882030487, dist_loss: 0.5101950168609619
recon_loss: 0.02755414880812168, dist_loss: 0.6638438701629639
recon_loss: 0.027553074061870575, dist_loss: 0.5853335857391357
recon_loss: 0.02755235694348812, dist_loss: 0.6871048212051392
recon_loss: 0.027551814913749695, dist_loss: 0.7471731901168823
recon_loss: 0.0275521669536829, dist_loss: 0.6351786851882935
recon_loss: 0.02755245380103588, dist_loss: 0.6930567622184753
recon_loss: 0.027552621439099312, dist_loss: 1.2737749814987183
recon_loss: 0.02755332738161087, dist_loss: 0.4750552475452423
recon_loss: 0.027553891763091087, dist_loss: 0.6248915791511536
recon_loss: 0.027554191648960114, dist_loss: 0.9764441847801208
recon_loss: 0.027554089203476906, dist_loss: 0.699021577835083
recon_loss: 0.027553677558898926, dist_loss: 0.8393995761871338
recon_loss: 0.027553847059607506, dist_loss: 0.6195526123046875
recon_loss: 0.027553068473935127, dist_loss: 0.808853030204773
recon_loss: 0.027552776038646698, dist_loss: 0.5698785781860352
recon_loss: 0.027551915496587753, dist_loss: 0.33741265535354614
recon_loss: 0.027551133185625076, dist_loss: 0.352596253156662
recon_loss: 0.027550453320145607, dist_loss: 0.7662111520767212
recon_loss: 0.027550294995307922, dist_loss: 0.8088536262512207
recon_loss: 0.027550721541047096, dist_loss: 0.47231733798980713
recon_loss: 0.02755061164498329, dist_loss: 0.7843682765960693
recon_loss: 0.027550142258405685, dist_loss: 0.509413480758667
recon_loss: 0.027551760897040367, dist_loss: 0.4626895785331726
recon_loss: 0.02755093201994896, dist_loss: 0.4356367290019989
recon_loss: 0.027553018182516098, dist_loss: 0.5767563581466675
recon_loss: 0.027553007006645203, dist_loss: 0.5389382839202881
recon_loss: 0.027553822845220566, dist_loss: 0.6739071011543274
recon_loss: 0.02755446918308735, dist_loss: 0.6305699348449707
recon_loss: 0.027552474290132523, dist_loss: 1.0055276155471802
recon_loss: 0.027553729712963104, dist_loss: 0.6702631711959839
recon_loss: 0.027553046122193336, dist_loss: 0.6508069038391113
recon_loss: 0.027553526684641838, dist_loss: 0.47611096501350403
recon_loss: 0.027554938569664955, dist_loss: 0.37816768884658813
recon_loss: 0.02755325846374035, dist_loss: 0.46821191906929016
recon_loss: 0.02755502238869667, dist_loss: 0.5528066754341125
recon_loss: 0.02755298651754856, dist_loss: 0.7404720783233643
recon_loss: 0.0275549478828907, dist_loss: 0.9883092045783997
recon_loss: 0.027553442865610123, dist_loss: 0.4740031957626343
recon_loss: 0.027551239356398582, dist_loss: 0.6698408722877502
recon_loss: 0.02755463309586048, dist_loss: 0.45571964979171753
recon_loss: 0.027551181614398956, dist_loss: 0.4312576651573181
recon_loss: 0.02755548059940338, dist_loss: 0.733718752861023
recon_loss: 0.027553880587220192, dist_loss: 0.8118247985839844
recon_loss: 0.027554797008633614, dist_loss: 0.574170708656311
recon_loss: 0.02755606919527054, dist_loss: 0.6192612648010254
recon_loss: 0.02755492553114891, dist_loss: 0.2701568007469177
recon_loss: 0.027556773275136948, dist_loss: 0.4245774447917938
recon_loss: 0.027554485946893692, dist_loss: 0.5355060696601868
recon_loss: 0.027554983273148537, dist_loss: 0.5952427983283997
recon_loss: 0.027553681284189224, dist_loss: 0.38839709758758545
recon_loss: 0.027552427724003792, dist_loss: 0.5512584447860718
recon_loss: 0.027552878484129906, dist_loss: 0.8329659700393677
recon_loss: 0.027550693601369858, dist_loss: 0.8047438859939575
recon_loss: 0.027552178129553795, dist_loss: 0.7200149893760681
recon_loss: 0.02755039744079113, dist_loss: 0.7435351610183716
recon_loss: 0.02755141071975231, dist_loss: 0.6216164827346802
recon_loss: 0.02755204401910305, dist_loss: 0.5447064638137817
recon_loss: 0.027551164850592613, dist_loss: 0.5357901453971863
recon_loss: 0.027552103623747826, dist_loss: 0.594691812992096
recon_loss: 0.027550507336854935, dist_loss: 0.46014636754989624
recon_loss: 0.027550814673304558, dist_loss: 0.5461573600769043
recon_loss: 0.0275492612272501, dist_loss: 0.6196029782295227
recon_loss: 0.02755013480782509, dist_loss: 0.9692472219467163
recon_loss: 0.027548836544156075, dist_loss: 0.3839372992515564
recon_loss: 0.027549225836992264, dist_loss: 0.983289361000061
recon_loss: 0.027548328042030334, dist_loss: 0.41953209042549133
recon_loss: 0.027547644451260567, dist_loss: 0.7770670056343079
recon_loss: 0.02754783071577549, dist_loss: 0.9534592628479004
recon_loss: 0.027547726407647133, dist_loss: 0.8996045589447021
recon_loss: 0.02754836343228817, dist_loss: 0.3915737271308899
recon_loss: 0.027548642829060555, dist_loss: 0.5407472848892212
recon_loss: 0.02754816599190235, dist_loss: 0.8503623604774475
recon_loss: 0.02754933387041092, dist_loss: 0.8289906978607178
recon_loss: 0.027548784390091896, dist_loss: 0.5336026549339294
recon_loss: 0.02754903770983219, dist_loss: 0.6102480292320251
recon_loss: 0.027548763900995255, dist_loss: 0.5099769830703735
recon_loss: 0.027548138052225113, dist_loss: 0.5012953281402588
recon_loss: 0.027548473328351974, dist_loss: 0.5095705389976501
recon_loss: 0.027547553181648254, dist_loss: 0.6039668321609497
recon_loss: 0.027547813951969147, dist_loss: 0.47517821192741394
recon_loss: 0.027547607198357582, dist_loss: 0.5018943548202515
recon_loss: 0.027547402307391167, dist_loss: 0.7406734228134155
recon_loss: 0.02754753641784191, dist_loss: 0.3917098641395569
recon_loss: 0.02754717506468296, dist_loss: 0.42781561613082886
recon_loss: 0.027546823024749756, dist_loss: 0.7396945953369141
recon_loss: 0.027546394616365433, dist_loss: 0.5542961359024048
recon_loss: 0.027546102181077003, dist_loss: 0.7621339559555054
recon_loss: 0.027546003460884094, dist_loss: 0.8236004114151001
recon_loss: 0.027545562013983727, dist_loss: 0.5742645263671875
recon_loss: 0.027545280754566193, dist_loss: 0.3929167091846466
recon_loss: 0.027545029297471046, dist_loss: 1.0483381748199463
recon_loss: 0.027545418590307236, dist_loss: 0.4971725642681122
recon_loss: 0.027544546872377396, dist_loss: 1.0195937156677246
recon_loss: 0.027544884011149406, dist_loss: 0.71431565284729
recon_loss: 0.027544625103473663, dist_loss: 1.1005523204803467
recon_loss: 0.02754482999444008, dist_loss: 1.234699010848999
recon_loss: 0.027544889599084854, dist_loss: 0.38083526492118835
recon_loss: 0.027544958516955376, dist_loss: 0.6494925022125244
recon_loss: 0.027545038610696793, dist_loss: 0.5507267117500305
recon_loss: 0.027544954791665077, dist_loss: 0.37426865100860596
recon_loss: 0.02754494920372963, dist_loss: 0.34089070558547974
recon_loss: 0.027544798329472542, dist_loss: 1.3099665641784668
recon_loss: 0.02754472941160202, dist_loss: 0.8181438446044922
recon_loss: 0.02754468470811844, dist_loss: 0.3826899826526642
recon_loss: 0.02754455991089344, dist_loss: 0.6712981462478638
recon_loss: 0.027544310316443443, dist_loss: 0.3381533622741699
recon_loss: 0.02754410356283188, dist_loss: 0.5395705103874207
recon_loss: 0.027543971315026283, dist_loss: 0.7511593699455261
recon_loss: 0.027543872594833374, dist_loss: 0.5884718894958496
recon_loss: 0.027543745934963226, dist_loss: 0.6740627884864807
recon_loss: 0.027543533593416214, dist_loss: 0.7362059354782104
recon_loss: 0.027543634176254272, dist_loss: 0.7684047818183899
recon_loss: 0.027543678879737854, dist_loss: 0.519919753074646
recon_loss: 0.027543533593416214, dist_loss: 0.8602725267410278
recon_loss: 0.027543392032384872, dist_loss: 0.7752676010131836
recon_loss: 0.027543364092707634, dist_loss: 0.8868942260742188
recon_loss: 0.02754342369735241, dist_loss: 0.6116780042648315
recon_loss: 0.027543501928448677, dist_loss: 0.5406762957572937
recon_loss: 0.027543440461158752, dist_loss: 0.9497393369674683
recon_loss: 0.027543513104319572, dist_loss: 1.036137580871582
recon_loss: 0.027543433010578156, dist_loss: 0.4373418986797333
recon_loss: 0.027543723583221436, dist_loss: 0.5709414482116699
recon_loss: 0.02754404954612255, dist_loss: 0.6003037691116333
Pre-training Epoch 99:  37%|███▋      | 135/367 [00:00<00:01, 156.15it/s]Pre-training Epoch 99:  41%|████      | 151/367 [00:00<00:01, 154.43it/s]Pre-training Epoch 99:  46%|████▌     | 169/367 [00:01<00:01, 160.58it/s]Pre-training Epoch 99:  51%|█████     | 186/367 [00:01<00:01, 160.84it/s]Pre-training Epoch 99:  56%|█████▌    | 204/367 [00:01<00:00, 165.84it/s]Pre-training Epoch 99:  60%|██████    | 221/367 [00:01<00:00, 166.70it/s]Pre-training Epoch 99:  65%|██████▍   | 238/367 [00:01<00:00, 164.87it/s]Pre-training Epoch 99:  69%|██████▉   | 255/367 [00:01<00:00, 160.90it/s]recon_loss: 0.02754451148211956, dist_loss: 0.4275822043418884
recon_loss: 0.02754473313689232, dist_loss: 0.4090694189071655
recon_loss: 0.027545085176825523, dist_loss: 0.6204487085342407
recon_loss: 0.02754543162882328, dist_loss: 0.5388432145118713
recon_loss: 0.027545545250177383, dist_loss: 0.6149674654006958
recon_loss: 0.027545562013983727, dist_loss: 0.6814722418785095
recon_loss: 0.027545766904950142, dist_loss: 1.1385561227798462
recon_loss: 0.027545100077986717, dist_loss: 0.6720879673957825
recon_loss: 0.027544965967535973, dist_loss: 0.44237327575683594
recon_loss: 0.02754507213830948, dist_loss: 0.7923521995544434
recon_loss: 0.02754480019211769, dist_loss: 0.626850962638855
recon_loss: 0.027544569224119186, dist_loss: 0.3574478328227997
recon_loss: 0.027544278651475906, dist_loss: 0.48197922110557556
recon_loss: 0.0275440514087677, dist_loss: 0.5839720964431763
recon_loss: 0.02754404954612255, dist_loss: 0.4489973783493042
recon_loss: 0.027543433010578156, dist_loss: 0.32220160961151123
recon_loss: 0.0275432076305151, dist_loss: 0.8597492575645447
recon_loss: 0.027543287724256516, dist_loss: 0.6379026174545288
recon_loss: 0.0275426022708416, dist_loss: 0.7722780704498291
recon_loss: 0.02754257805645466, dist_loss: 0.8330525159835815
recon_loss: 0.02754330076277256, dist_loss: 0.9803357124328613
recon_loss: 0.027541978284716606, dist_loss: 0.9641097784042358
recon_loss: 0.027542516589164734, dist_loss: 0.7842364311218262
recon_loss: 0.027542108669877052, dist_loss: 0.6216754913330078
recon_loss: 0.027542179450392723, dist_loss: 0.8620092272758484
recon_loss: 0.027542753145098686, dist_loss: 0.6747041940689087
recon_loss: 0.027542728930711746, dist_loss: 0.8231000304222107
recon_loss: 0.027543287724256516, dist_loss: 0.613275408744812
recon_loss: 0.027543583884835243, dist_loss: 0.36495158076286316
recon_loss: 0.02754371054470539, dist_loss: 0.5820121765136719
recon_loss: 0.0275434497743845, dist_loss: 0.5535604953765869
recon_loss: 0.027543051168322563, dist_loss: 0.5204951167106628
recon_loss: 0.027543189004063606, dist_loss: 0.9480539560317993
recon_loss: 0.027542494237422943, dist_loss: 0.45073193311691284
recon_loss: 0.02754281833767891, dist_loss: 0.7729870080947876
recon_loss: 0.02754233404994011, dist_loss: 0.5201196670532227
recon_loss: 0.02754252590239048, dist_loss: 0.6089247465133667
recon_loss: 0.027542881667613983, dist_loss: 0.6279730200767517
recon_loss: 0.02754313126206398, dist_loss: 0.5179499387741089
recon_loss: 0.027543382719159126, dist_loss: 0.5068178772926331
recon_loss: 0.027543509379029274, dist_loss: 0.6072661876678467
recon_loss: 0.02754341810941696, dist_loss: 0.5764303207397461
recon_loss: 0.02754356898367405, dist_loss: 0.5891910791397095
recon_loss: 0.027543656527996063, dist_loss: 0.8570118546485901
recon_loss: 0.027543406933546066, dist_loss: 0.5651957988739014
recon_loss: 0.027542874217033386, dist_loss: 0.6442631483078003
recon_loss: 0.0275424774736166, dist_loss: 0.8306198716163635
recon_loss: 0.027542084455490112, dist_loss: 0.5728818774223328
recon_loss: 0.027541974559426308, dist_loss: 0.5408774614334106
recon_loss: 0.02754233591258526, dist_loss: 0.3543351888656616
recon_loss: 0.02754310704767704, dist_loss: 0.8876485824584961
recon_loss: 0.027543408796191216, dist_loss: 0.3934115767478943
recon_loss: 0.02754346653819084, dist_loss: 0.8921389579772949
recon_loss: 0.02754313126206398, dist_loss: 0.7986941337585449
recon_loss: 0.027543392032384872, dist_loss: 1.0580850839614868
recon_loss: 0.027543213218450546, dist_loss: 0.6339225769042969
recon_loss: 0.027543313801288605, dist_loss: 0.8062407374382019
recon_loss: 0.027542918920516968, dist_loss: 0.47337982058525085
recon_loss: 0.027542386204004288, dist_loss: 0.25235068798065186
recon_loss: 0.027542123571038246, dist_loss: 0.7813530564308167
recon_loss: 0.027541616931557655, dist_loss: 0.455638587474823
recon_loss: 0.027541695162653923, dist_loss: 0.9509165287017822
recon_loss: 0.027541296556591988, dist_loss: 1.4524935483932495
recon_loss: 0.027540912851691246, dist_loss: 0.902417004108429
recon_loss: 0.027541384100914, dist_loss: 0.3414260745048523
recon_loss: 0.027541231364011765, dist_loss: 0.7581411004066467
recon_loss: 0.02754220925271511, dist_loss: 0.5854786038398743
recon_loss: 0.027541905641555786, dist_loss: 0.319352924823761
recon_loss: 0.027542848140001297, dist_loss: 0.7469124794006348
recon_loss: 0.027544045820832253, dist_loss: 0.4281397759914398
recon_loss: 0.027544129639863968, dist_loss: 0.4301927089691162
recon_loss: 0.02754548192024231, dist_loss: 0.4301605820655823
recon_loss: 0.027544673532247543, dist_loss: 0.40950924158096313
recon_loss: 0.02754606120288372, dist_loss: 0.44116801023483276
recon_loss: 0.027544936165213585, dist_loss: 1.016992211341858
recon_loss: 0.027546856552362442, dist_loss: 0.7073156237602234
recon_loss: 0.027547650039196014, dist_loss: 0.7882784605026245
recon_loss: 0.027547786012291908, dist_loss: 0.8706976771354675
recon_loss: 0.027549806982278824, dist_loss: 0.534974217414856
recon_loss: 0.027546968311071396, dist_loss: 0.5430290699005127
recon_loss: 0.027545735239982605, dist_loss: 0.4597265124320984
recon_loss: 0.02754567563533783, dist_loss: 0.5520565509796143
recon_loss: 0.027543583884835243, dist_loss: 0.4783928394317627
recon_loss: 0.027544721961021423, dist_loss: 0.6437267661094666
recon_loss: 0.02754218317568302, dist_loss: 0.5318455696105957
recon_loss: 0.027542099356651306, dist_loss: 0.5067665576934814
recon_loss: 0.027541399002075195, dist_loss: 0.5863522291183472
recon_loss: 0.027539916336536407, dist_loss: 0.7340170741081238
recon_loss: 0.02754056081175804, dist_loss: 0.6655420064926147
recon_loss: 0.027539875358343124, dist_loss: 0.5623288154602051
recon_loss: 0.027541067451238632, dist_loss: 1.0478544235229492
recon_loss: 0.02754204161465168, dist_loss: 0.5032009482383728
recon_loss: 0.027542652562260628, dist_loss: 0.4240325391292572
recon_loss: 0.02754395268857479, dist_loss: 0.8520859479904175
recon_loss: 0.027544798329472542, dist_loss: 0.49996453523635864
recon_loss: 0.027545025572180748, dist_loss: 0.3293977975845337
recon_loss: 0.027544913813471794, dist_loss: 0.9641405940055847
recon_loss: 0.0275433287024498, dist_loss: 0.46883368492126465
recon_loss: 0.02754286304116249, dist_loss: 0.7998442053794861
recon_loss: 0.02754099667072296, dist_loss: 0.9021592736244202
recon_loss: 0.027540696784853935, dist_loss: 0.5239217281341553
recon_loss: 0.02753991261124611, dist_loss: 0.32518625259399414
recon_loss: 0.027540050446987152, dist_loss: 0.5487631559371948
recon_loss: 0.0275415126234293, dist_loss: 0.45947080850601196
recon_loss: 0.02754363790154457, dist_loss: 0.37319961190223694
recon_loss: 0.027547558769583702, dist_loss: 0.7181439399719238
recon_loss: 0.027549652382731438, dist_loss: 0.5269420146942139
recon_loss: 0.027551433071494102, dist_loss: 0.6333513855934143
recon_loss: 0.02755165472626686, dist_loss: 0.5641729831695557
recon_loss: 0.02755066566169262, dist_loss: 0.9123490452766418
recon_loss: 0.02754971571266651, dist_loss: 1.0858328342437744
recon_loss: 0.027547718957066536, dist_loss: 0.6081236600875854
recon_loss: 0.027547111734747887, dist_loss: 0.6589452624320984
recon_loss: 0.02754659205675125, dist_loss: 0.5456063747406006
recon_loss: 0.027545001357793808, dist_loss: 0.5029817223548889
recon_loss: 0.02754335105419159, dist_loss: 0.3755107820034027
recon_loss: 0.027542173862457275, dist_loss: 0.5631065964698792
recon_loss: 0.027541454881429672, dist_loss: 0.8991522789001465
recon_loss: 0.027541065588593483, dist_loss: 0.7593085765838623
recon_loss: 0.027540771290659904, dist_loss: 0.8968845009803772
recon_loss: 0.02754085883498192, dist_loss: 0.804407000541687
recon_loss: 0.02754083275794983, dist_loss: 0.5787877440452576
recon_loss: 0.027541033923625946, dist_loss: 0.5108155608177185
recon_loss: 0.027541248127818108, dist_loss: 0.6340104937553406
recon_loss: 0.027541007846593857, dist_loss: 0.5461887717247009
recon_loss: 0.027540849521756172, dist_loss: 0.6071112155914307
recon_loss: 0.0275406651198864, dist_loss: 0.6398200988769531
recon_loss: 0.02754007652401924, dist_loss: 0.6997625827789307
Pre-training Epoch 99:  74%|███████▍  | 272/367 [00:01<00:00, 158.87it/s]Pre-training Epoch 99:  78%|███████▊  | 288/367 [00:01<00:00, 158.04it/s]Pre-training Epoch 99:  83%|████████▎ | 304/367 [00:01<00:00, 156.58it/s]Pre-training Epoch 99:  87%|████████▋ | 320/367 [00:02<00:00, 154.82it/s]Pre-training Epoch 99:  92%|█████████▏| 336/367 [00:02<00:00, 156.08it/s]Pre-training Epoch 99:  96%|█████████▌| 352/367 [00:02<00:00, 156.43it/s]Pre-training Epoch 99: 100%|██████████| 367/367 [00:02<00:00, 159.76it/s]
recon_loss: 0.027539601549506187, dist_loss: 0.6125295758247375
recon_loss: 0.027539189904928207, dist_loss: 0.3742588758468628
recon_loss: 0.027539189904928207, dist_loss: 0.7812055349349976
recon_loss: 0.027539154514670372, dist_loss: 1.0359607934951782
recon_loss: 0.027539342641830444, dist_loss: 0.6578090190887451
recon_loss: 0.027538873255252838, dist_loss: 0.8158151507377625
recon_loss: 0.027538985013961792, dist_loss: 0.7365922927856445
recon_loss: 0.02753923460841179, dist_loss: 0.4475058615207672
recon_loss: 0.027539260685443878, dist_loss: 0.9327718019485474
recon_loss: 0.027538971975445747, dist_loss: 0.43541643023490906
recon_loss: 0.027538247406482697, dist_loss: 0.35385799407958984
recon_loss: 0.02753775380551815, dist_loss: 0.6279393434524536
recon_loss: 0.027536896988749504, dist_loss: 0.6291089057922363
recon_loss: 0.027536479756236076, dist_loss: 0.9427762627601624
recon_loss: 0.027535870671272278, dist_loss: 0.4415096044540405
recon_loss: 0.027535641565918922, dist_loss: 0.6246483325958252
recon_loss: 0.027535706758499146, dist_loss: 0.4663717746734619
recon_loss: 0.02753615938127041, dist_loss: 0.7294615507125854
recon_loss: 0.027536215260624886, dist_loss: 0.8376864790916443
recon_loss: 0.02753717638552189, dist_loss: 0.9851021766662598
recon_loss: 0.02753722295165062, dist_loss: 0.5223618745803833
recon_loss: 0.027537459507584572, dist_loss: 0.7976548671722412
recon_loss: 0.0275381151586771, dist_loss: 0.26451075077056885
recon_loss: 0.027537066489458084, dist_loss: 0.5268506407737732
recon_loss: 0.027538180351257324, dist_loss: 0.6398110389709473
recon_loss: 0.027537323534488678, dist_loss: 0.7552452683448792
recon_loss: 0.027537738904356956, dist_loss: 0.464591920375824
recon_loss: 0.027537671849131584, dist_loss: 0.751099169254303
recon_loss: 0.027537234127521515, dist_loss: 0.38505232334136963
recon_loss: 0.027537303045392036, dist_loss: 0.41387939453125
recon_loss: 0.027537204325199127, dist_loss: 0.4942547380924225
recon_loss: 0.02753671258687973, dist_loss: 0.7561081647872925
recon_loss: 0.02753634564578533, dist_loss: 0.6799871921539307
recon_loss: 0.02753603272140026, dist_loss: 0.5410438776016235
recon_loss: 0.02753540500998497, dist_loss: 0.6131818294525146
recon_loss: 0.027535168454051018, dist_loss: 0.4303681254386902
recon_loss: 0.027534762397408485, dist_loss: 0.6634113192558289
recon_loss: 0.0275346040725708, dist_loss: 0.9406787157058716
recon_loss: 0.027534469962120056, dist_loss: 0.8009211421012878
recon_loss: 0.02753431908786297, dist_loss: 0.5047824382781982
recon_loss: 0.02753424644470215, dist_loss: 0.7791721820831299
recon_loss: 0.027534374967217445, dist_loss: 0.6548178195953369
recon_loss: 0.027534274384379387, dist_loss: 0.7730250358581543
recon_loss: 0.027534397318959236, dist_loss: 0.3796774744987488
recon_loss: 0.027534766122698784, dist_loss: 0.5971787571907043
recon_loss: 0.02753484807908535, dist_loss: 0.7543128132820129
recon_loss: 0.02753494493663311, dist_loss: 0.6737912893295288
recon_loss: 0.02753489650785923, dist_loss: 0.6424027681350708
recon_loss: 0.027534419670701027, dist_loss: 0.3491845726966858
recon_loss: 0.02753456123173237, dist_loss: 0.46723124384880066
recon_loss: 0.02753409370779991, dist_loss: 0.5616368055343628
recon_loss: 0.027534008026123047, dist_loss: 0.5823864340782166
recon_loss: 0.02753400057554245, dist_loss: 0.8667525053024292
recon_loss: 0.027534175664186478, dist_loss: 0.7643367052078247
recon_loss: 0.027534732595086098, dist_loss: 0.6035659909248352
recon_loss: 0.027534974738955498, dist_loss: 0.5459085702896118
recon_loss: 0.02753499522805214, dist_loss: 0.7713347673416138
recon_loss: 0.027535133063793182, dist_loss: 0.8074950575828552
recon_loss: 0.027535008266568184, dist_loss: 0.7863730192184448
recon_loss: 0.02753474749624729, dist_loss: 1.0387016534805298
recon_loss: 0.02753453701734543, dist_loss: 0.6453709602355957
recon_loss: 0.02753428928554058, dist_loss: 0.5836453437805176
recon_loss: 0.02753436379134655, dist_loss: 0.46285784244537354
recon_loss: 0.027534296736121178, dist_loss: 0.784136176109314
recon_loss: 0.02753436379134655, dist_loss: 0.7934041023254395
recon_loss: 0.02753468230366707, dist_loss: 0.43202853202819824
recon_loss: 0.027535105124115944, dist_loss: 1.0905859470367432
recon_loss: 0.027535608038306236, dist_loss: 0.6833022236824036
recon_loss: 0.027535567060112953, dist_loss: 0.5502951145172119
recon_loss: 0.027535254135727882, dist_loss: 0.45529869198799133
recon_loss: 0.02753583900630474, dist_loss: 0.7805556058883667
recon_loss: 0.027535833418369293, dist_loss: 0.3834523558616638
recon_loss: 0.027535784989595413, dist_loss: 0.6131576299667358
recon_loss: 0.02753605507314205, dist_loss: 0.40127477049827576
recon_loss: 0.027536261826753616, dist_loss: 0.9217959642410278
recon_loss: 0.02753644809126854, dist_loss: 0.977236270904541
recon_loss: 0.02753700688481331, dist_loss: 0.6887058615684509
recon_loss: 0.02753736637532711, dist_loss: 0.7575748562812805
recon_loss: 0.027537710964679718, dist_loss: 0.6585702300071716
recon_loss: 0.02753826230764389, dist_loss: 0.6074380278587341
recon_loss: 0.027538279071450233, dist_loss: 0.568342387676239
recon_loss: 0.027538657188415527, dist_loss: 1.0767732858657837
recon_loss: 0.02753896452486515, dist_loss: 0.6677241325378418
recon_loss: 0.02753898873925209, dist_loss: 0.9643638730049133
recon_loss: 0.027537794783711433, dist_loss: 0.620758593082428
recon_loss: 0.027536435052752495, dist_loss: 0.6090006232261658
recon_loss: 0.027536706998944283, dist_loss: 0.5727401971817017
recon_loss: 0.02753600664436817, dist_loss: 0.6354025602340698
recon_loss: 0.027536332607269287, dist_loss: 0.8664669394493103
recon_loss: 0.02753610722720623, dist_loss: 0.8182276487350464
recon_loss: 0.02753538265824318, dist_loss: 0.8763791918754578
recon_loss: 0.02753584273159504, dist_loss: 0.93439781665802
recon_loss: 0.02753605507314205, dist_loss: 0.5233939290046692
recon_loss: 0.027537083253264427, dist_loss: 0.769778847694397
recon_loss: 0.02753734216094017, dist_loss: 0.603402853012085
recon_loss: 0.027537627145648003, dist_loss: 0.7986102104187012
recon_loss: 0.02753761224448681, dist_loss: 0.7649593353271484
recon_loss: 0.027538301423192024, dist_loss: 0.6269875764846802
recon_loss: 0.027539445087313652, dist_loss: 0.9255555272102356
recon_loss: 0.02753940038383007, dist_loss: 0.6553770303726196
recon_loss: 0.027540747076272964, dist_loss: 0.4535132050514221
recon_loss: 0.02753923088312149, dist_loss: 0.5192648768424988
recon_loss: 0.027538780122995377, dist_loss: 0.9631606340408325
recon_loss: 0.027537699788808823, dist_loss: 0.6188509464263916
recon_loss: 0.0275366622954607, dist_loss: 0.45431405305862427
recon_loss: 0.02753603272140026, dist_loss: 0.6909934282302856
recon_loss: 0.027534984052181244, dist_loss: 0.7180958986282349
recon_loss: 0.02753569558262825, dist_loss: 0.4040508568286896
recon_loss: 0.02753470465540886, dist_loss: 0.6388081312179565
recon_loss: 0.027534691616892815, dist_loss: 0.6992990970611572
recon_loss: 0.02753473073244095, dist_loss: 1.4465335607528687
Pre-training Epoch 100:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 100:   4%|▍         | 16/367 [00:00<00:02, 157.37it/s]Pre-training Epoch 100:   9%|▉         | 33/367 [00:00<00:02, 160.52it/s]Pre-training Epoch 100:  14%|█▎        | 50/367 [00:00<00:01, 160.74it/s]Pre-training Epoch 100:  18%|█▊        | 67/367 [00:00<00:01, 158.22it/s]Pre-training Epoch 100:  23%|██▎       | 83/367 [00:00<00:01, 152.87it/s]Pre-training Epoch 100:  27%|██▋       | 99/367 [00:00<00:01, 154.48it/s]Pre-training Epoch 100:  31%|███▏      | 115/367 [00:00<00:01, 154.17it/s]recon_loss: 0.027534596621990204, dist_loss: 0.5284506678581238
recon_loss: 0.027534056454896927, dist_loss: 1.0191752910614014
recon_loss: 0.027533764019608498, dist_loss: 0.716063380241394
recon_loss: 0.027532994747161865, dist_loss: 0.3262300491333008
recon_loss: 0.027532808482646942, dist_loss: 0.5391027927398682
recon_loss: 0.027532489970326424, dist_loss: 0.5796498656272888
recon_loss: 0.02753245085477829, dist_loss: 1.1048638820648193
recon_loss: 0.02753225341439247, dist_loss: 0.43040212988853455
recon_loss: 0.027531666681170464, dist_loss: 0.603270411491394
recon_loss: 0.027531497180461884, dist_loss: 1.2181485891342163
recon_loss: 0.027531655505299568, dist_loss: 0.5784345865249634
recon_loss: 0.027531687170267105, dist_loss: 0.49369654059410095
recon_loss: 0.027531716972589493, dist_loss: 0.5228680372238159
recon_loss: 0.02753187157213688, dist_loss: 0.9549198746681213
recon_loss: 0.027532223612070084, dist_loss: 0.896870493888855
recon_loss: 0.027532098814845085, dist_loss: 0.5438315868377686
recon_loss: 0.027531547471880913, dist_loss: 0.5662474036216736
recon_loss: 0.0275314562022686, dist_loss: 0.5612955689430237
recon_loss: 0.02753152884542942, dist_loss: 1.0141565799713135
recon_loss: 0.027532503008842468, dist_loss: 0.7994183301925659
recon_loss: 0.027533456683158875, dist_loss: 0.9577543139457703
recon_loss: 0.027533989399671555, dist_loss: 0.456371009349823
recon_loss: 0.027534570544958115, dist_loss: 0.5394369959831238
recon_loss: 0.027535319328308105, dist_loss: 0.7278633713722229
recon_loss: 0.02753634937107563, dist_loss: 0.478532612323761
recon_loss: 0.027537288144230843, dist_loss: 0.7852442264556885
recon_loss: 0.02753777615725994, dist_loss: 0.49842894077301025
recon_loss: 0.027537809684872627, dist_loss: 0.4342710077762604
recon_loss: 0.027537792921066284, dist_loss: 0.9991719722747803
recon_loss: 0.027537312358617783, dist_loss: 0.4118034541606903
recon_loss: 0.0275364238768816, dist_loss: 0.6163644194602966
recon_loss: 0.02753576450049877, dist_loss: 0.7250624299049377
recon_loss: 0.027534261345863342, dist_loss: 0.8955444693565369
recon_loss: 0.027532879263162613, dist_loss: 0.6580960750579834
recon_loss: 0.027532752603292465, dist_loss: 0.6501278877258301
recon_loss: 0.027533438056707382, dist_loss: 0.42642006278038025
recon_loss: 0.027534687891602516, dist_loss: 0.37345272302627563
recon_loss: 0.027536077424883842, dist_loss: 0.9816157221794128
recon_loss: 0.027536600828170776, dist_loss: 0.660490870475769
recon_loss: 0.02753688395023346, dist_loss: 0.6443819999694824
recon_loss: 0.027536019682884216, dist_loss: 0.5504882335662842
recon_loss: 0.027536088600754738, dist_loss: 0.3962526023387909
recon_loss: 0.02753560058772564, dist_loss: 0.9912766218185425
recon_loss: 0.02753547951579094, dist_loss: 0.30530834197998047
recon_loss: 0.027535095810890198, dist_loss: 0.497111439704895
recon_loss: 0.02753310650587082, dist_loss: 0.43360936641693115
recon_loss: 0.02753194235265255, dist_loss: 0.46236783266067505
recon_loss: 0.027530724182724953, dist_loss: 0.3750874996185303
recon_loss: 0.027530720457434654, dist_loss: 0.8161152005195618
recon_loss: 0.027530096471309662, dist_loss: 0.9851869940757751
recon_loss: 0.027529804036021233, dist_loss: 0.43663132190704346
recon_loss: 0.027530023828148842, dist_loss: 0.650255560874939
recon_loss: 0.027529973536729813, dist_loss: 0.6619954109191895
recon_loss: 0.027530662715435028, dist_loss: 0.522026002407074
recon_loss: 0.02753070741891861, dist_loss: 0.5445740818977356
recon_loss: 0.027530713006854057, dist_loss: 0.7959187030792236
recon_loss: 0.027530765160918236, dist_loss: 0.6764969825744629
recon_loss: 0.027530916035175323, dist_loss: 0.5814602971076965
recon_loss: 0.02753056213259697, dist_loss: 0.9281042814254761
recon_loss: 0.027530347928404808, dist_loss: 0.5330860614776611
recon_loss: 0.027530517429113388, dist_loss: 0.9087482690811157
recon_loss: 0.02753031626343727, dist_loss: 0.6186705827713013
recon_loss: 0.027530506253242493, dist_loss: 0.4551656246185303
recon_loss: 0.027530666440725327, dist_loss: 0.7292959690093994
recon_loss: 0.027530241757631302, dist_loss: 0.6208912134170532
recon_loss: 0.02753026969730854, dist_loss: 0.22302192449569702
recon_loss: 0.02752985991537571, dist_loss: 0.8153021931648254
recon_loss: 0.02752942219376564, dist_loss: 0.7956253290176392
recon_loss: 0.027528993785381317, dist_loss: 0.4190216064453125
recon_loss: 0.0275285504758358, dist_loss: 0.7746286392211914
recon_loss: 0.027528569102287292, dist_loss: 0.30337589979171753
recon_loss: 0.02752886712551117, dist_loss: 0.5121002793312073
recon_loss: 0.027529384940862656, dist_loss: 0.4833875894546509
recon_loss: 0.027530143037438393, dist_loss: 0.571009635925293
recon_loss: 0.02753094770014286, dist_loss: 0.786462664604187
recon_loss: 0.02753152698278427, dist_loss: 0.261165976524353
recon_loss: 0.02753155492246151, dist_loss: 0.7896140217781067
recon_loss: 0.027531374245882034, dist_loss: 0.8052129149436951
recon_loss: 0.02753102220594883, dist_loss: 0.3573196530342102
recon_loss: 0.027530554682016373, dist_loss: 0.7273914217948914
recon_loss: 0.027529945597052574, dist_loss: 1.0592715740203857
recon_loss: 0.027529215440154076, dist_loss: 0.46238845586776733
recon_loss: 0.027528561651706696, dist_loss: 0.7814755439758301
recon_loss: 0.027527621015906334, dist_loss: 0.5209408402442932
recon_loss: 0.027526969090104103, dist_loss: 1.1782879829406738
recon_loss: 0.02752675861120224, dist_loss: 0.4817018508911133
recon_loss: 0.027526896446943283, dist_loss: 0.5337333679199219
recon_loss: 0.027527598664164543, dist_loss: 0.6400426030158997
recon_loss: 0.027528492733836174, dist_loss: 0.5326349139213562
recon_loss: 0.02752974070608616, dist_loss: 0.5358276963233948
recon_loss: 0.02753118798136711, dist_loss: 0.6578799486160278
recon_loss: 0.027532270178198814, dist_loss: 0.5532616972923279
recon_loss: 0.027533428743481636, dist_loss: 0.5135893821716309
recon_loss: 0.02753329463303089, dist_loss: 0.5826961994171143
recon_loss: 0.02753276936709881, dist_loss: 0.5213748216629028
recon_loss: 0.027530958876013756, dist_loss: 0.7832357883453369
recon_loss: 0.027529679238796234, dist_loss: 0.8711439967155457
recon_loss: 0.02752828784286976, dist_loss: 0.4911467730998993
recon_loss: 0.027528004720807076, dist_loss: 0.5005443692207336
recon_loss: 0.027528705075383186, dist_loss: 0.992940366268158
recon_loss: 0.02753007970750332, dist_loss: 0.4856993556022644
recon_loss: 0.027532093226909637, dist_loss: 0.5222470760345459
recon_loss: 0.027533672749996185, dist_loss: 0.7923623323440552
recon_loss: 0.027534889057278633, dist_loss: 1.1234891414642334
recon_loss: 0.02753552421927452, dist_loss: 0.8928405046463013
recon_loss: 0.02753441222012043, dist_loss: 0.42596930265426636
recon_loss: 0.02753331884741783, dist_loss: 0.5636017322540283
recon_loss: 0.027533188462257385, dist_loss: 0.46442705392837524
recon_loss: 0.027531420812010765, dist_loss: 0.6184035539627075
recon_loss: 0.02753087878227234, dist_loss: 0.6626081466674805
recon_loss: 0.027529830113053322, dist_loss: 0.5011693835258484
recon_loss: 0.027529705315828323, dist_loss: 0.2392381727695465
recon_loss: 0.027529599145054817, dist_loss: 0.9724510908126831
recon_loss: 0.02752913348376751, dist_loss: 0.7351312637329102
recon_loss: 0.027529200538992882, dist_loss: 0.9663666486740112
recon_loss: 0.02752991020679474, dist_loss: 0.8607380390167236
recon_loss: 0.02752922847867012, dist_loss: 0.7823483347892761
recon_loss: 0.02753097005188465, dist_loss: 0.6021182537078857
recon_loss: 0.027530644088983536, dist_loss: 0.5358337759971619
recon_loss: 0.027530042454600334, dist_loss: 0.9237852096557617
recon_loss: 0.027529476210474968, dist_loss: 0.5992851257324219
recon_loss: 0.027528835460543633, dist_loss: 0.5193256735801697
recon_loss: 0.027529217302799225, dist_loss: 1.189746618270874
recon_loss: 0.02752808667719364, dist_loss: 0.4836775064468384
recon_loss: 0.02752861939370632, dist_loss: 0.39150315523147583
recon_loss: 0.027528055012226105, dist_loss: 0.4693945050239563
recon_loss: 0.027528537437319756, dist_loss: 0.5077031850814819
recon_loss: 0.027528071776032448, dist_loss: 0.5551145076751709
Pre-training Epoch 100:  36%|███▌      | 132/367 [00:00<00:01, 156.31it/s]Pre-training Epoch 100:  41%|████      | 149/367 [00:00<00:01, 159.61it/s]Pre-training Epoch 100:  45%|████▌     | 166/367 [00:01<00:01, 161.72it/s]Pre-training Epoch 100:  50%|████▉     | 183/367 [00:01<00:01, 162.65it/s]Pre-training Epoch 100:  54%|█████▍    | 200/367 [00:01<00:01, 163.70it/s]Pre-training Epoch 100:  59%|█████▉    | 217/367 [00:01<00:00, 163.05it/s]Pre-training Epoch 100:  64%|██████▍   | 234/367 [00:01<00:00, 160.08it/s]Pre-training Epoch 100:  68%|██████▊   | 251/367 [00:01<00:00, 158.04it/s]recon_loss: 0.02752775140106678, dist_loss: 0.6809424161911011
recon_loss: 0.027528241276741028, dist_loss: 0.9735986590385437
recon_loss: 0.027527306228876114, dist_loss: 0.7791648507118225
recon_loss: 0.027527838945388794, dist_loss: 0.6378846764564514
recon_loss: 0.027526821941137314, dist_loss: 0.5481306910514832
recon_loss: 0.027527151629328728, dist_loss: 1.0655382871627808
recon_loss: 0.027526477351784706, dist_loss: 0.8498548865318298
recon_loss: 0.027525845915079117, dist_loss: 0.5480297803878784
recon_loss: 0.02752683125436306, dist_loss: 0.8791356682777405
recon_loss: 0.02752542868256569, dist_loss: 0.7178035974502563
recon_loss: 0.027526086196303368, dist_loss: 0.6445301175117493
recon_loss: 0.02752692438662052, dist_loss: 0.7264904379844666
recon_loss: 0.027527598664164543, dist_loss: 0.5222605466842651
recon_loss: 0.027527468279004097, dist_loss: 0.42045000195503235
recon_loss: 0.0275275819003582, dist_loss: 0.9117807149887085
recon_loss: 0.027526678517460823, dist_loss: 0.5569194555282593
recon_loss: 0.027525581419467926, dist_loss: 0.8662039041519165
recon_loss: 0.027525242418050766, dist_loss: 0.4612382650375366
recon_loss: 0.027525562793016434, dist_loss: 0.7190659046173096
recon_loss: 0.02752625197172165, dist_loss: 0.647247314453125
recon_loss: 0.027526726946234703, dist_loss: 0.3629249632358551
recon_loss: 0.027526691555976868, dist_loss: 0.596858024597168
recon_loss: 0.02752659097313881, dist_loss: 0.9281092882156372
recon_loss: 0.0275273397564888, dist_loss: 0.999071478843689
recon_loss: 0.02752717211842537, dist_loss: 0.6221798062324524
recon_loss: 0.02752705290913582, dist_loss: 0.3796832859516144
recon_loss: 0.027526794001460075, dist_loss: 0.7852926850318909
recon_loss: 0.027526143938302994, dist_loss: 0.8820464611053467
recon_loss: 0.0275255274027586, dist_loss: 0.7164499759674072
recon_loss: 0.027525732293725014, dist_loss: 1.1076247692108154
recon_loss: 0.027526970952749252, dist_loss: 0.5048367977142334
recon_loss: 0.027527835220098495, dist_loss: 0.3784620761871338
recon_loss: 0.027529127895832062, dist_loss: 0.7369582653045654
recon_loss: 0.027529185637831688, dist_loss: 0.5680423974990845
recon_loss: 0.027528394013643265, dist_loss: 0.8880981206893921
recon_loss: 0.02752845734357834, dist_loss: 0.3352270722389221
recon_loss: 0.02752823755145073, dist_loss: 0.9197244644165039
recon_loss: 0.027527956292033195, dist_loss: 0.8372693061828613
recon_loss: 0.02752743661403656, dist_loss: 0.46819591522216797
recon_loss: 0.027526890859007835, dist_loss: 0.6706497669219971
recon_loss: 0.027526699006557465, dist_loss: 0.5068246722221375
recon_loss: 0.027527084574103355, dist_loss: 0.7609485387802124
recon_loss: 0.027527377009391785, dist_loss: 0.776931643486023
recon_loss: 0.027528326958417892, dist_loss: 0.43015778064727783
recon_loss: 0.02752973698079586, dist_loss: 0.6863353252410889
recon_loss: 0.027530429884791374, dist_loss: 0.41142305731773376
recon_loss: 0.027530856430530548, dist_loss: 0.576077938079834
recon_loss: 0.027531379833817482, dist_loss: 1.0209927558898926
recon_loss: 0.027531342580914497, dist_loss: 0.25654083490371704
recon_loss: 0.027531154453754425, dist_loss: 0.6808229684829712
recon_loss: 0.02753068320453167, dist_loss: 0.2813398838043213
recon_loss: 0.027530580759048462, dist_loss: 0.5944140553474426
recon_loss: 0.02753007970750332, dist_loss: 0.2753955125808716
recon_loss: 0.027529401704669, dist_loss: 0.8877899050712585
recon_loss: 0.02752913162112236, dist_loss: 0.6401278972625732
recon_loss: 0.027528837323188782, dist_loss: 0.606338381767273
recon_loss: 0.027530048042535782, dist_loss: 0.41721782088279724
recon_loss: 0.02752966433763504, dist_loss: 0.6050821542739868
recon_loss: 0.027529893442988396, dist_loss: 0.6303262710571289
recon_loss: 0.027529148384928703, dist_loss: 0.7843601703643799
recon_loss: 0.0275286678224802, dist_loss: 0.6312035918235779
recon_loss: 0.027528483420610428, dist_loss: 0.47304803133010864
recon_loss: 0.027527889236807823, dist_loss: 0.4081733524799347
recon_loss: 0.027525566518306732, dist_loss: 0.3972223997116089
recon_loss: 0.027525298297405243, dist_loss: 0.28516262769699097
recon_loss: 0.027524767443537712, dist_loss: 0.30763208866119385
recon_loss: 0.027524452656507492, dist_loss: 0.5650314092636108
recon_loss: 0.027524584904313087, dist_loss: 0.6069771647453308
recon_loss: 0.027523986995220184, dist_loss: 0.9163477420806885
recon_loss: 0.0275245513767004, dist_loss: 0.4863446354866028
recon_loss: 0.027524709701538086, dist_loss: 0.4939851760864258
recon_loss: 0.02752661146223545, dist_loss: 0.7410674095153809
recon_loss: 0.027526263147592545, dist_loss: 0.6750574111938477
recon_loss: 0.027526775375008583, dist_loss: 0.6472518444061279
recon_loss: 0.027526549994945526, dist_loss: 1.0007119178771973
recon_loss: 0.02752712182700634, dist_loss: 0.6075574159622192
recon_loss: 0.027528177946805954, dist_loss: 0.7085058093070984
recon_loss: 0.02752838097512722, dist_loss: 0.9930688142776489
recon_loss: 0.027529168874025345, dist_loss: 0.31418511271476746
recon_loss: 0.027529142796993256, dist_loss: 0.48441028594970703
recon_loss: 0.02752869389951229, dist_loss: 0.6592041254043579
recon_loss: 0.02752791717648506, dist_loss: 0.997710108757019
recon_loss: 0.0275272149592638, dist_loss: 0.6276718974113464
recon_loss: 0.027526330202817917, dist_loss: 0.6515928506851196
recon_loss: 0.027525288984179497, dist_loss: 0.869949996471405
recon_loss: 0.0275247935205698, dist_loss: 0.8662834167480469
recon_loss: 0.027524547651410103, dist_loss: 0.7481085062026978
recon_loss: 0.027524186298251152, dist_loss: 0.6885315775871277
recon_loss: 0.027523798868060112, dist_loss: 0.43379151821136475
recon_loss: 0.02752360887825489, dist_loss: 0.5500275492668152
recon_loss: 0.02752380259335041, dist_loss: 0.9047428369522095
recon_loss: 0.027524415403604507, dist_loss: 0.5229209661483765
recon_loss: 0.027525652199983597, dist_loss: 0.374234139919281
recon_loss: 0.027526864781975746, dist_loss: 0.6008678078651428
recon_loss: 0.027528882026672363, dist_loss: 1.1028772592544556
recon_loss: 0.027529696002602577, dist_loss: 1.0435988903045654
recon_loss: 0.027530351653695107, dist_loss: 0.48323941230773926
recon_loss: 0.027531208470463753, dist_loss: 0.5243692398071289
recon_loss: 0.027530090883374214, dist_loss: 0.6515605449676514
recon_loss: 0.02752932906150818, dist_loss: 0.6509355306625366
recon_loss: 0.027526650577783585, dist_loss: 0.5082734823226929
recon_loss: 0.02752481959760189, dist_loss: 0.6068153381347656
recon_loss: 0.027523599565029144, dist_loss: 0.907505452632904
recon_loss: 0.0275227352976799, dist_loss: 0.3509008288383484
recon_loss: 0.02752223052084446, dist_loss: 1.3263317346572876
recon_loss: 0.027521688491106033, dist_loss: 0.722637414932251
recon_loss: 0.02752169966697693, dist_loss: 0.7398863434791565
recon_loss: 0.027521952986717224, dist_loss: 0.5874857306480408
recon_loss: 0.027521837502717972, dist_loss: 0.655573308467865
recon_loss: 0.027522342279553413, dist_loss: 0.5557652711868286
recon_loss: 0.027522051706910133, dist_loss: 1.0070979595184326
recon_loss: 0.027522720396518707, dist_loss: 0.6147118806838989
recon_loss: 0.027522113174200058, dist_loss: 0.5048588514328003
recon_loss: 0.027522971853613853, dist_loss: 0.5636367201805115
recon_loss: 0.027523107826709747, dist_loss: 0.41775596141815186
recon_loss: 0.0275214035063982, dist_loss: 0.6647346615791321
recon_loss: 0.027522681280970573, dist_loss: 0.8590164184570312
recon_loss: 0.02752104215323925, dist_loss: 0.45543935894966125
recon_loss: 0.027521533891558647, dist_loss: 0.3408483564853668
recon_loss: 0.027521032840013504, dist_loss: 0.5368497371673584
recon_loss: 0.027520567178726196, dist_loss: 1.2502135038375854
recon_loss: 0.027521224692463875, dist_loss: 1.8310221433639526
recon_loss: 0.02752050571143627, dist_loss: 0.6650620698928833
recon_loss: 0.027521833777427673, dist_loss: 1.3812854290008545
recon_loss: 0.02752099186182022, dist_loss: 0.6300216913223267
recon_loss: 0.027520690113306046, dist_loss: 0.6402385234832764
recon_loss: 0.02752087078988552, dist_loss: 0.8374078869819641
recon_loss: 0.02752196043729782, dist_loss: 0.6488415002822876
Pre-training Epoch 100:  73%|███████▎  | 267/367 [00:01<00:00, 156.58it/s]Pre-training Epoch 100:  77%|███████▋  | 283/367 [00:01<00:00, 153.49it/s]Pre-training Epoch 100:  82%|████████▏ | 300/367 [00:01<00:00, 156.85it/s]Pre-training Epoch 100:  86%|████████▋ | 317/367 [00:02<00:00, 159.20it/s]Pre-training Epoch 100:  91%|█████████ | 334/367 [00:02<00:00, 160.93it/s]Pre-training Epoch 100:  96%|█████████▌| 351/367 [00:02<00:00, 161.54it/s]Pre-training Epoch 100: 100%|██████████| 367/367 [00:02<00:00, 159.14it/s]
recon_loss: 0.027522962540388107, dist_loss: 0.49400293827056885
recon_loss: 0.027523960918188095, dist_loss: 0.5316219925880432
recon_loss: 0.027524523437023163, dist_loss: 0.6617832183837891
recon_loss: 0.027525270357728004, dist_loss: 0.7025549411773682
recon_loss: 0.027525128796696663, dist_loss: 0.708751380443573
recon_loss: 0.027523959055542946, dist_loss: 0.7002127170562744
recon_loss: 0.02752283774316311, dist_loss: 0.6656439304351807
recon_loss: 0.027522144839167595, dist_loss: 0.5148493647575378
recon_loss: 0.027521777898073196, dist_loss: 0.5754700899124146
recon_loss: 0.027521157637238503, dist_loss: 0.5134837627410889
recon_loss: 0.027520833536982536, dist_loss: 0.5680853128433228
recon_loss: 0.027520863339304924, dist_loss: 0.5940660238265991
recon_loss: 0.027520708739757538, dist_loss: 0.7857751846313477
recon_loss: 0.027520397678017616, dist_loss: 0.6135157346725464
recon_loss: 0.027520043775439262, dist_loss: 0.6463941335678101
recon_loss: 0.027518853545188904, dist_loss: 0.6636163592338562
recon_loss: 0.02751821279525757, dist_loss: 0.5954118967056274
recon_loss: 0.02751810848712921, dist_loss: 0.9792962670326233
recon_loss: 0.02751866914331913, dist_loss: 0.3717409372329712
recon_loss: 0.027519483119249344, dist_loss: 0.39983028173446655
recon_loss: 0.02752080000936985, dist_loss: 0.4311005175113678
recon_loss: 0.027521660551428795, dist_loss: 0.4099836051464081
recon_loss: 0.0275211650878191, dist_loss: 0.9005461931228638
recon_loss: 0.027520202100276947, dist_loss: 0.5206538438796997
recon_loss: 0.027519812807440758, dist_loss: 0.8638968467712402
recon_loss: 0.027519535273313522, dist_loss: 0.5339556932449341
recon_loss: 0.02751966007053852, dist_loss: 0.4678802192211151
recon_loss: 0.02751925215125084, dist_loss: 1.1744272708892822
recon_loss: 0.02751859650015831, dist_loss: 0.5670579671859741
recon_loss: 0.027518510818481445, dist_loss: 0.5305042266845703
recon_loss: 0.027517929673194885, dist_loss: 0.4905943274497986
recon_loss: 0.027517814189195633, dist_loss: 0.5247892141342163
recon_loss: 0.02751767449080944, dist_loss: 0.8795592784881592
recon_loss: 0.02751765586435795, dist_loss: 0.7593696117401123
recon_loss: 0.027517903596162796, dist_loss: 0.509981632232666
recon_loss: 0.02751760743558407, dist_loss: 0.31674662232398987
recon_loss: 0.027517829090356827, dist_loss: 0.5405929684638977
recon_loss: 0.02751738950610161, dist_loss: 0.6411375999450684
recon_loss: 0.027517151087522507, dist_loss: 0.5657692551612854
recon_loss: 0.027516894042491913, dist_loss: 0.42642104625701904
recon_loss: 0.02751641534268856, dist_loss: 0.6597815155982971
recon_loss: 0.02751692570745945, dist_loss: 0.5461491346359253
recon_loss: 0.027515500783920288, dist_loss: 0.8923174738883972
recon_loss: 0.027516135945916176, dist_loss: 0.7502910494804382
recon_loss: 0.02751483954489231, dist_loss: 0.623924732208252
recon_loss: 0.027515185996890068, dist_loss: 0.5583980083465576
recon_loss: 0.027514543384313583, dist_loss: 0.8526932001113892
recon_loss: 0.027514265850186348, dist_loss: 0.8366261720657349
recon_loss: 0.02751406840980053, dist_loss: 0.3512483835220337
recon_loss: 0.027513710781931877, dist_loss: 0.6379479169845581
recon_loss: 0.027513885870575905, dist_loss: 0.3991711735725403
recon_loss: 0.02751343883574009, dist_loss: 0.7501353621482849
recon_loss: 0.027513450011610985, dist_loss: 0.43359315395355225
recon_loss: 0.02751323953270912, dist_loss: 0.9104158282279968
recon_loss: 0.02751314267516136, dist_loss: 0.4873073995113373
recon_loss: 0.027513062581419945, dist_loss: 0.5846929550170898
recon_loss: 0.027512654662132263, dist_loss: 0.765872061252594
recon_loss: 0.027512451633810997, dist_loss: 0.4579581022262573
recon_loss: 0.02751237340271473, dist_loss: 0.47138136625289917
recon_loss: 0.027512522414326668, dist_loss: 0.6091741323471069
recon_loss: 0.027512796223163605, dist_loss: 0.639858067035675
recon_loss: 0.02751282975077629, dist_loss: 0.47319918870925903
recon_loss: 0.027512606233358383, dist_loss: 1.2254765033721924
recon_loss: 0.02751239947974682, dist_loss: 0.566493570804596
recon_loss: 0.027512570843100548, dist_loss: 0.5311613082885742
recon_loss: 0.027512261644005775, dist_loss: 0.529139518737793
recon_loss: 0.02751222625374794, dist_loss: 0.5214458107948303
recon_loss: 0.027512144297361374, dist_loss: 0.2463115155696869
recon_loss: 0.027512401342391968, dist_loss: 0.6974508762359619
recon_loss: 0.027513012290000916, dist_loss: 0.36944660544395447
recon_loss: 0.02751397155225277, dist_loss: 0.413341760635376
recon_loss: 0.027514105662703514, dist_loss: 0.8617488145828247
recon_loss: 0.027514658868312836, dist_loss: 0.700832724571228
recon_loss: 0.027514364570379257, dist_loss: 0.4918372333049774
recon_loss: 0.02751491405069828, dist_loss: 0.9610613584518433
recon_loss: 0.027514709159731865, dist_loss: 0.65615314245224
recon_loss: 0.027515027672052383, dist_loss: 0.735236406326294
recon_loss: 0.02751530334353447, dist_loss: 1.3270320892333984
recon_loss: 0.027515754103660583, dist_loss: 0.6954689025878906
recon_loss: 0.027513841167092323, dist_loss: 0.5819518566131592
recon_loss: 0.027514170855283737, dist_loss: 0.6344491243362427
recon_loss: 0.02751314640045166, dist_loss: 0.7124683856964111
recon_loss: 0.02751285955309868, dist_loss: 0.742361307144165
recon_loss: 0.02751299738883972, dist_loss: 0.3763548731803894
recon_loss: 0.02751169726252556, dist_loss: 0.5885645747184753
recon_loss: 0.02751222625374794, dist_loss: 0.6398110389709473
recon_loss: 0.02751157619059086, dist_loss: 0.3911837637424469
recon_loss: 0.027511611580848694, dist_loss: 1.1358675956726074
recon_loss: 0.027512095868587494, dist_loss: 0.5519634485244751
recon_loss: 0.027511540800333023, dist_loss: 0.4983089864253998
recon_loss: 0.027512038126587868, dist_loss: 0.614625096321106
recon_loss: 0.02751326374709606, dist_loss: 0.3769029378890991
recon_loss: 0.027514640241861343, dist_loss: 0.9254270792007446
recon_loss: 0.027515796944499016, dist_loss: 0.4852651059627533
recon_loss: 0.02751641720533371, dist_loss: 0.5100302696228027
recon_loss: 0.027516191825270653, dist_loss: 0.5338518023490906
recon_loss: 0.027515500783920288, dist_loss: 0.45926541090011597
recon_loss: 0.027514846995472908, dist_loss: 0.5915155410766602
recon_loss: 0.027513917535543442, dist_loss: 0.7780112028121948
recon_loss: 0.027513327077031136, dist_loss: 1.006179928779602
recon_loss: 0.0275128036737442, dist_loss: 0.515906810760498
recon_loss: 0.027512313798069954, dist_loss: 0.5089774131774902
recon_loss: 0.027511537075042725, dist_loss: 0.8973633050918579
recon_loss: 0.027510829269886017, dist_loss: 0.9544652104377747
recon_loss: 0.02751024439930916, dist_loss: 0.6819362044334412
recon_loss: 0.027511412277817726, dist_loss: 0.7030096650123596
recon_loss: 0.027510400861501694, dist_loss: 0.7229562997817993
recon_loss: 0.02751069702208042, dist_loss: 0.6720945835113525
recon_loss: 0.027510544285178185, dist_loss: 0.7547110915184021
recon_loss: 0.027510400861501694, dist_loss: 0.6516573429107666
recon_loss: 0.027510467916727066, dist_loss: 1.0132931470870972
Pre-train Epoch: 100
Train - Total Loss: 0.0928, Recon Loss: 0.0275, Dist Loss: 0.6527, l1 regularization: 0.0000
Val - Total Loss: 0.0974, Recon Loss: 0.0275, Dist Loss: 0.6988, l1 regularization: 0.0000
Pre-training Epoch 101:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 101:   4%|▍         | 16/367 [00:00<00:02, 159.87it/s]Pre-training Epoch 101:   9%|▉         | 33/367 [00:00<00:02, 161.63it/s]Pre-training Epoch 101:  14%|█▍        | 51/367 [00:00<00:01, 169.56it/s]Pre-training Epoch 101:  19%|█▊        | 68/367 [00:00<00:01, 163.78it/s]Pre-training Epoch 101:  23%|██▎       | 85/367 [00:00<00:01, 163.91it/s]Pre-training Epoch 101:  29%|██▊       | 105/367 [00:00<00:01, 173.82it/s]Pre-training Epoch 101:  34%|███▍      | 125/367 [00:00<00:01, 178.63it/s]recon_loss: 0.027510473504662514, dist_loss: 0.8881939053535461
recon_loss: 0.02751149982213974, dist_loss: 0.6533548831939697
recon_loss: 0.027510544285178185, dist_loss: 0.5770994424819946
recon_loss: 0.027513867244124413, dist_loss: 0.8230157494544983
recon_loss: 0.027513563632965088, dist_loss: 0.7132197022438049
recon_loss: 0.027516759932041168, dist_loss: 0.4091891646385193
recon_loss: 0.027515754103660583, dist_loss: 0.7774753570556641
recon_loss: 0.027516042813658714, dist_loss: 0.530706524848938
recon_loss: 0.027515631169080734, dist_loss: 0.5167015790939331
recon_loss: 0.027515225112438202, dist_loss: 0.7292948365211487
recon_loss: 0.027516204863786697, dist_loss: 0.9525295495986938
recon_loss: 0.027514265850186348, dist_loss: 0.5779927372932434
recon_loss: 0.027514511719346046, dist_loss: 0.6799577474594116
recon_loss: 0.02751232124865055, dist_loss: 0.579094648361206
recon_loss: 0.02751176990568638, dist_loss: 0.7060486078262329
recon_loss: 0.02751166932284832, dist_loss: 0.49409863352775574
recon_loss: 0.027511242777109146, dist_loss: 0.9701377153396606
recon_loss: 0.027511371299624443, dist_loss: 0.6836656332015991
recon_loss: 0.02751125581562519, dist_loss: 0.8242948651313782
recon_loss: 0.02751144766807556, dist_loss: 0.4797871708869934
recon_loss: 0.027511149644851685, dist_loss: 0.6748099327087402
recon_loss: 0.02751087211072445, dist_loss: 0.3685343265533447
recon_loss: 0.02751084230840206, dist_loss: 0.7820760011672974
recon_loss: 0.027510715648531914, dist_loss: 0.44168543815612793
recon_loss: 0.02751040644943714, dist_loss: 0.6153249740600586
recon_loss: 0.02750982902944088, dist_loss: 0.2903273105621338
recon_loss: 0.0275095347315073, dist_loss: 0.32510441541671753
recon_loss: 0.027509525418281555, dist_loss: 0.647616982460022
recon_loss: 0.02750968560576439, dist_loss: 0.7025985717773438
recon_loss: 0.027509702369570732, dist_loss: 0.8058791160583496
recon_loss: 0.02750997059047222, dist_loss: 0.5950878858566284
recon_loss: 0.02751043625175953, dist_loss: 0.42938292026519775
recon_loss: 0.02751087211072445, dist_loss: 0.8041034936904907
recon_loss: 0.027510879561305046, dist_loss: 0.7528285980224609
recon_loss: 0.027510955929756165, dist_loss: 0.4315412640571594
recon_loss: 0.02751070447266102, dist_loss: 0.764107346534729
recon_loss: 0.027510758489370346, dist_loss: 0.30716419219970703
recon_loss: 0.02751121111214161, dist_loss: 0.4511321187019348
recon_loss: 0.027511660009622574, dist_loss: 0.7503520250320435
recon_loss: 0.0275117214769125, dist_loss: 0.7391063570976257
recon_loss: 0.027512380853295326, dist_loss: 0.8807416558265686
recon_loss: 0.02751295268535614, dist_loss: 0.775113582611084
recon_loss: 0.027513230219483376, dist_loss: 0.7026388645172119
recon_loss: 0.027512850239872932, dist_loss: 0.47476428747177124
recon_loss: 0.027512194588780403, dist_loss: 0.6149904727935791
recon_loss: 0.027511492371559143, dist_loss: 1.0333467721939087
recon_loss: 0.027510933578014374, dist_loss: 0.48815038800239563
recon_loss: 0.02751033753156662, dist_loss: 0.5748001933097839
recon_loss: 0.027509836480021477, dist_loss: 0.5172243714332581
recon_loss: 0.02750953659415245, dist_loss: 0.3123602867126465
recon_loss: 0.027509359642863274, dist_loss: 0.4505155682563782
recon_loss: 0.027509255334734917, dist_loss: 0.4671693444252014
recon_loss: 0.027509454637765884, dist_loss: 0.42925482988357544
recon_loss: 0.027509136125445366, dist_loss: 0.5287275314331055
recon_loss: 0.027508744969964027, dist_loss: 0.9655987024307251
recon_loss: 0.027508683502674103, dist_loss: 1.0146452188491821
recon_loss: 0.02750861644744873, dist_loss: 0.4157102406024933
recon_loss: 0.02750874124467373, dist_loss: 0.5504435896873474
recon_loss: 0.027509192004799843, dist_loss: 0.9300718307495117
recon_loss: 0.027509327977895737, dist_loss: 0.4775465726852417
recon_loss: 0.027509428560733795, dist_loss: 0.9315989017486572
recon_loss: 0.027509603649377823, dist_loss: 1.00830078125
recon_loss: 0.027509795501828194, dist_loss: 0.43133556842803955
recon_loss: 0.027510909363627434, dist_loss: 0.4251948595046997
recon_loss: 0.02751171961426735, dist_loss: 0.8824558854103088
recon_loss: 0.02751273289322853, dist_loss: 0.5175833702087402
recon_loss: 0.027513213455677032, dist_loss: 0.4886228144168854
recon_loss: 0.027513349428772926, dist_loss: 0.5311878323554993
recon_loss: 0.027512729167938232, dist_loss: 0.7660955786705017
recon_loss: 0.027512308210134506, dist_loss: 0.5424590706825256
recon_loss: 0.027512328699231148, dist_loss: 0.5817722678184509
recon_loss: 0.027512211352586746, dist_loss: 0.9350959062576294
recon_loss: 0.027512265369296074, dist_loss: 0.9433465600013733
recon_loss: 0.027512282133102417, dist_loss: 0.4746733605861664
recon_loss: 0.027511432766914368, dist_loss: 0.538404107093811
recon_loss: 0.027509871870279312, dist_loss: 0.7214776873588562
recon_loss: 0.027509042993187904, dist_loss: 0.4794595539569855
recon_loss: 0.02750920131802559, dist_loss: 0.5482883453369141
recon_loss: 0.02750869281589985, dist_loss: 0.9382792711257935
recon_loss: 0.027509339153766632, dist_loss: 0.6435657739639282
recon_loss: 0.02750881388783455, dist_loss: 0.30773216485977173
recon_loss: 0.027509503066539764, dist_loss: 0.3961673974990845
recon_loss: 0.027509326115250587, dist_loss: 0.4366740584373474
recon_loss: 0.027508370578289032, dist_loss: 0.9421693682670593
recon_loss: 0.027508459985256195, dist_loss: 0.70941162109375
recon_loss: 0.027507716789841652, dist_loss: 0.3060658574104309
recon_loss: 0.02750830166041851, dist_loss: 0.7695500254631042
recon_loss: 0.02750716172158718, dist_loss: 0.8860331773757935
recon_loss: 0.027506466954946518, dist_loss: 0.4776158928871155
recon_loss: 0.027506418526172638, dist_loss: 0.7396093010902405
recon_loss: 0.027506517246365547, dist_loss: 0.8732462525367737
recon_loss: 0.027506742626428604, dist_loss: 0.4337220788002014
recon_loss: 0.027506669983267784, dist_loss: 0.932027280330658
recon_loss: 0.02750740572810173, dist_loss: 0.4366500675678253
recon_loss: 0.027507934719324112, dist_loss: 0.7444721460342407
recon_loss: 0.027507992461323738, dist_loss: 0.42710626125335693
recon_loss: 0.027508212253451347, dist_loss: 0.5190110802650452
recon_loss: 0.02750815451145172, dist_loss: 0.6317334771156311
recon_loss: 0.02750764973461628, dist_loss: 0.5426589250564575
recon_loss: 0.02750706672668457, dist_loss: 0.5718542337417603
recon_loss: 0.027506470680236816, dist_loss: 0.7031792998313904
recon_loss: 0.027506450191140175, dist_loss: 0.7034577131271362
recon_loss: 0.0275071170181036, dist_loss: 0.5757870674133301
recon_loss: 0.02750847488641739, dist_loss: 0.7344678044319153
recon_loss: 0.02751045487821102, dist_loss: 0.38454481959342957
recon_loss: 0.02751239202916622, dist_loss: 0.3008641302585602
recon_loss: 0.027515137568116188, dist_loss: 0.9689229726791382
recon_loss: 0.027518993243575096, dist_loss: 0.4974958896636963
recon_loss: 0.02752039022743702, dist_loss: 0.4881831407546997
recon_loss: 0.027520092204213142, dist_loss: 0.3861568570137024
recon_loss: 0.027518026530742645, dist_loss: 0.6971373558044434
recon_loss: 0.027515072375535965, dist_loss: 0.8202284574508667
recon_loss: 0.027512794360518456, dist_loss: 0.47842833399772644
recon_loss: 0.027511151507496834, dist_loss: 0.9436080455780029
recon_loss: 0.02751019597053528, dist_loss: 0.545833170413971
recon_loss: 0.027508830651640892, dist_loss: 0.49118873476982117
recon_loss: 0.02750845067203045, dist_loss: 0.5390356779098511
recon_loss: 0.0275069922208786, dist_loss: 0.4514669179916382
recon_loss: 0.027508443221449852, dist_loss: 0.37815338373184204
recon_loss: 0.02750798873603344, dist_loss: 0.5675427913665771
recon_loss: 0.02751021459698677, dist_loss: 0.39993008971214294
recon_loss: 0.027508482336997986, dist_loss: 0.9617116451263428
recon_loss: 0.027508923783898354, dist_loss: 0.6869482398033142
recon_loss: 0.027509169653058052, dist_loss: 0.48749014735221863
recon_loss: 0.02750813402235508, dist_loss: 0.402027428150177
recon_loss: 0.027509748935699463, dist_loss: 0.6944204568862915
recon_loss: 0.02750864252448082, dist_loss: 0.5605031251907349
recon_loss: 0.027508994564414024, dist_loss: 0.6395089030265808
Pre-training Epoch 101:  39%|███▉      | 144/367 [00:00<00:01, 180.25it/s]Pre-training Epoch 101:  45%|████▍     | 164/367 [00:00<00:01, 184.39it/s]Pre-training Epoch 101:  50%|█████     | 184/367 [00:01<00:00, 187.19it/s]Pre-training Epoch 101:  56%|█████▌    | 204/367 [00:01<00:00, 188.94it/s]Pre-training Epoch 101:  61%|██████    | 224/367 [00:01<00:00, 189.50it/s]Pre-training Epoch 101:  66%|██████▌   | 243/367 [00:01<00:00, 189.00it/s]recon_loss: 0.027508247643709183, dist_loss: 0.7799150347709656
recon_loss: 0.02750726230442524, dist_loss: 0.6323307156562805
recon_loss: 0.027507232502102852, dist_loss: 0.8331103920936584
recon_loss: 0.02750634029507637, dist_loss: 0.2583758533000946
recon_loss: 0.02750677801668644, dist_loss: 0.6681256294250488
recon_loss: 0.027505800127983093, dist_loss: 0.42415404319763184
recon_loss: 0.027506008744239807, dist_loss: 0.9368312358856201
recon_loss: 0.027505822479724884, dist_loss: 0.6043598651885986
recon_loss: 0.027506396174430847, dist_loss: 0.46577560901641846
recon_loss: 0.0275083277374506, dist_loss: 0.6819096803665161
recon_loss: 0.02750951237976551, dist_loss: 0.5359705090522766
recon_loss: 0.02751064859330654, dist_loss: 0.983741819858551
recon_loss: 0.027510860934853554, dist_loss: 0.8219058513641357
recon_loss: 0.0275108702480793, dist_loss: 0.8020775318145752
recon_loss: 0.027510525658726692, dist_loss: 0.999160885810852
recon_loss: 0.027509773150086403, dist_loss: 0.743542492389679
recon_loss: 0.027507835999131203, dist_loss: 0.5174614191055298
recon_loss: 0.027506880462169647, dist_loss: 0.5834224224090576
recon_loss: 0.02750585600733757, dist_loss: 0.9008412957191467
recon_loss: 0.027505531907081604, dist_loss: 0.710848867893219
recon_loss: 0.027505967766046524, dist_loss: 0.4596084952354431
recon_loss: 0.027506839483976364, dist_loss: 0.6134603023529053
recon_loss: 0.02750709280371666, dist_loss: 0.7663955688476562
recon_loss: 0.027506781741976738, dist_loss: 0.38733410835266113
recon_loss: 0.027506619691848755, dist_loss: 1.5739794969558716
recon_loss: 0.02750597707927227, dist_loss: 0.6605739593505859
recon_loss: 0.027505863457918167, dist_loss: 0.29066789150238037
recon_loss: 0.027505360543727875, dist_loss: 0.4176112413406372
recon_loss: 0.027504924684762955, dist_loss: 0.473281592130661
recon_loss: 0.027504319325089455, dist_loss: 0.6891731023788452
recon_loss: 0.02750389277935028, dist_loss: 0.819500744342804
recon_loss: 0.027503760531544685, dist_loss: 1.0212403535842896
recon_loss: 0.0275036059319973, dist_loss: 0.5686097741127014
recon_loss: 0.0275032427161932, dist_loss: 0.4751039743423462
recon_loss: 0.027503255754709244, dist_loss: 1.0866889953613281
recon_loss: 0.027503274381160736, dist_loss: 0.3831219971179962
recon_loss: 0.027503326535224915, dist_loss: 0.7421391010284424
recon_loss: 0.027503574267029762, dist_loss: 0.5108141303062439
recon_loss: 0.027503518387675285, dist_loss: 0.8344149589538574
recon_loss: 0.02750321477651596, dist_loss: 0.5880824327468872
recon_loss: 0.027503030374646187, dist_loss: 0.6409686207771301
recon_loss: 0.027503129094839096, dist_loss: 0.8109411001205444
recon_loss: 0.02750340849161148, dist_loss: 1.1442813873291016
recon_loss: 0.02750345692038536, dist_loss: 0.3567885756492615
recon_loss: 0.02750367671251297, dist_loss: 0.5211065411567688
recon_loss: 0.027503108605742455, dist_loss: 0.6893788576126099
recon_loss: 0.02750270627439022, dist_loss: 0.3969098627567291
recon_loss: 0.02750285342335701, dist_loss: 0.8828873634338379
recon_loss: 0.0275026336312294, dist_loss: 0.2562398612499237
recon_loss: 0.027503009885549545, dist_loss: 0.9327927827835083
recon_loss: 0.02750299498438835, dist_loss: 0.46224862337112427
recon_loss: 0.02750365436077118, dist_loss: 1.0184606313705444
recon_loss: 0.02750445157289505, dist_loss: 0.5618318915367126
recon_loss: 0.027504602447152138, dist_loss: 0.6441634893417358
recon_loss: 0.027504069730639458, dist_loss: 0.9986482858657837
recon_loss: 0.02750355191528797, dist_loss: 0.7432156205177307
recon_loss: 0.027503717690706253, dist_loss: 0.5645513534545898
recon_loss: 0.027504127472639084, dist_loss: 0.6043656468391418
recon_loss: 0.0275043286383152, dist_loss: 0.37682586908340454
recon_loss: 0.02750462107360363, dist_loss: 0.7874864339828491
recon_loss: 0.02750498801469803, dist_loss: 1.1108959913253784
recon_loss: 0.027504881843924522, dist_loss: 0.4752541780471802
recon_loss: 0.02750452049076557, dist_loss: 0.5773389935493469
recon_loss: 0.027504220604896545, dist_loss: 0.5328710079193115
recon_loss: 0.027503646910190582, dist_loss: 0.4102553725242615
recon_loss: 0.027503814548254013, dist_loss: 0.48012590408325195
recon_loss: 0.02750347927212715, dist_loss: 0.9400935769081116
recon_loss: 0.0275040864944458, dist_loss: 0.8398475646972656
recon_loss: 0.027503453195095062, dist_loss: 0.45150795578956604
recon_loss: 0.027503609657287598, dist_loss: 0.613990068435669
recon_loss: 0.0275032427161932, dist_loss: 0.6974740028381348
recon_loss: 0.02750333771109581, dist_loss: 0.8757976293563843
recon_loss: 0.02750391885638237, dist_loss: 0.4085516333580017
recon_loss: 0.027504272758960724, dist_loss: 0.5891456604003906
recon_loss: 0.027504822239279747, dist_loss: 0.6033591032028198
recon_loss: 0.02750532142817974, dist_loss: 0.41213029623031616
recon_loss: 0.027506213635206223, dist_loss: 0.5359626412391663
recon_loss: 0.027507035061717033, dist_loss: 0.8561153411865234
recon_loss: 0.027508778497576714, dist_loss: 0.7859482765197754
recon_loss: 0.02751045487821102, dist_loss: 0.671870231628418
recon_loss: 0.02751186117529869, dist_loss: 0.27173998951911926
recon_loss: 0.027511918917298317, dist_loss: 0.9431936144828796
recon_loss: 0.027509063482284546, dist_loss: 0.8204830884933472
recon_loss: 0.027507193386554718, dist_loss: 0.6620302200317383
recon_loss: 0.027506113052368164, dist_loss: 0.39930063486099243
recon_loss: 0.027504749596118927, dist_loss: 0.6156392693519592
recon_loss: 0.027503523975610733, dist_loss: 0.716965913772583
recon_loss: 0.027502981945872307, dist_loss: 0.7012569904327393
recon_loss: 0.027502991259098053, dist_loss: 0.4565625786781311
recon_loss: 0.027502985671162605, dist_loss: 0.3278852105140686
recon_loss: 0.02750268578529358, dist_loss: 0.9241254329681396
recon_loss: 0.02750183828175068, dist_loss: 0.8315163254737854
recon_loss: 0.02750161848962307, dist_loss: 0.43719834089279175
recon_loss: 0.027501463890075684, dist_loss: 0.6536878347396851
recon_loss: 0.02750115469098091, dist_loss: 0.6758853197097778
recon_loss: 0.027500338852405548, dist_loss: 0.4349500238895416
recon_loss: 0.02749963290989399, dist_loss: 0.787458062171936
recon_loss: 0.027499215677380562, dist_loss: 0.5870760679244995
recon_loss: 0.02749912068247795, dist_loss: 0.5419483184814453
recon_loss: 0.027499040588736534, dist_loss: 0.6159566640853882
recon_loss: 0.02749876119196415, dist_loss: 0.6573193073272705
recon_loss: 0.02749883569777012, dist_loss: 0.9392316341400146
recon_loss: 0.02749890647828579, dist_loss: 0.6874208450317383
recon_loss: 0.027498986572027206, dist_loss: 0.3475726544857025
recon_loss: 0.02749912068247795, dist_loss: 0.7487646341323853
recon_loss: 0.027498548850417137, dist_loss: 0.8088725805282593
recon_loss: 0.02749849483370781, dist_loss: 0.6296493411064148
recon_loss: 0.027497751638293266, dist_loss: 0.5154526829719543
recon_loss: 0.027497518807649612, dist_loss: 0.6254213452339172
recon_loss: 0.02749737538397312, dist_loss: 0.752724826335907
recon_loss: 0.02749737538397312, dist_loss: 0.47540411353111267
recon_loss: 0.02749829925596714, dist_loss: 0.6951245069503784
recon_loss: 0.02749788388609886, dist_loss: 0.6330268383026123
recon_loss: 0.027498707175254822, dist_loss: 0.6091740131378174
recon_loss: 0.027498610317707062, dist_loss: 1.136612057685852
recon_loss: 0.02749832347035408, dist_loss: 0.6108424067497253
recon_loss: 0.027498258277773857, dist_loss: 0.5374013185501099
recon_loss: 0.027497924864292145, dist_loss: 1.0771907567977905
recon_loss: 0.027497533708810806, dist_loss: 0.785480260848999
recon_loss: 0.02749679610133171, dist_loss: 0.802794873714447
recon_loss: 0.02749653533101082, dist_loss: 1.0774164199829102
recon_loss: 0.02749651111662388, dist_loss: 0.5323043465614319
recon_loss: 0.027496717870235443, dist_loss: 0.7309306859970093
recon_loss: 0.02749697118997574, dist_loss: 0.5971368551254272
recon_loss: 0.027496786788105965, dist_loss: 0.8793814182281494
recon_loss: 0.027497123926877975, dist_loss: 0.6039941906929016
recon_loss: 0.027497025206685066, dist_loss: 0.3352259397506714
recon_loss: 0.02749715931713581, dist_loss: 0.9594956636428833
recon_loss: 0.0274977944791317, dist_loss: 0.6189085841178894
Pre-training Epoch 101:  71%|███████▏  | 262/367 [00:01<00:00, 189.00it/s]Pre-training Epoch 101:  77%|███████▋  | 281/367 [00:01<00:00, 181.26it/s]Pre-training Epoch 101:  82%|████████▏ | 300/367 [00:01<00:00, 176.04it/s]Pre-training Epoch 101:  87%|████████▋ | 318/367 [00:01<00:00, 171.11it/s]Pre-training Epoch 101:  92%|█████████▏| 336/367 [00:01<00:00, 169.51it/s]Pre-training Epoch 101:  96%|█████████▌| 353/367 [00:02<00:00, 168.32it/s]Pre-training Epoch 101: 100%|██████████| 367/367 [00:02<00:00, 175.85it/s]
recon_loss: 0.02749880962073803, dist_loss: 0.3515039086341858
recon_loss: 0.027500560507178307, dist_loss: 0.5569669008255005
recon_loss: 0.027500849217176437, dist_loss: 0.7174596786499023
recon_loss: 0.027501167729496956, dist_loss: 0.7496173977851868
recon_loss: 0.027500305324792862, dist_loss: 0.6703376173973083
recon_loss: 0.027498945593833923, dist_loss: 0.6394951343536377
recon_loss: 0.027498118579387665, dist_loss: 0.6005517840385437
recon_loss: 0.027497433125972748, dist_loss: 0.8332632780075073
recon_loss: 0.02749738097190857, dist_loss: 0.9556152820587158
recon_loss: 0.02749716304242611, dist_loss: 0.5741450786590576
recon_loss: 0.027497177943587303, dist_loss: 0.7338273525238037
recon_loss: 0.027496861293911934, dist_loss: 0.6391846537590027
recon_loss: 0.0274967048317194, dist_loss: 1.1854331493377686
recon_loss: 0.02749657817184925, dist_loss: 0.713890552520752
recon_loss: 0.027496229857206345, dist_loss: 0.7294209599494934
recon_loss: 0.027496157214045525, dist_loss: 0.4456693232059479
recon_loss: 0.027496187016367912, dist_loss: 0.8256658315658569
recon_loss: 0.027496058493852615, dist_loss: 0.8829218149185181
recon_loss: 0.02749588154256344, dist_loss: 0.35990801453590393
recon_loss: 0.027495454996824265, dist_loss: 0.23507893085479736
recon_loss: 0.027495361864566803, dist_loss: 0.6173573136329651
recon_loss: 0.027495332062244415, dist_loss: 0.8294746279716492
recon_loss: 0.027495233342051506, dist_loss: 0.697572648525238
recon_loss: 0.027494870126247406, dist_loss: 0.480506956577301
recon_loss: 0.027494287118315697, dist_loss: 0.5363357067108154
recon_loss: 0.027493765577673912, dist_loss: 0.49058929085731506
recon_loss: 0.027493536472320557, dist_loss: 0.3912784457206726
recon_loss: 0.027493733912706375, dist_loss: 0.3759278655052185
recon_loss: 0.02749355137348175, dist_loss: 0.543329119682312
recon_loss: 0.027493515983223915, dist_loss: 0.6011863946914673
recon_loss: 0.02749348245561123, dist_loss: 0.8297483921051025
recon_loss: 0.027493560686707497, dist_loss: 0.5264068841934204
recon_loss: 0.027493631467223167, dist_loss: 0.5646674633026123
recon_loss: 0.02749311551451683, dist_loss: 1.1063153743743896
recon_loss: 0.0274930689483881, dist_loss: 0.9283243417739868
recon_loss: 0.027493245899677277, dist_loss: 0.5901280641555786
recon_loss: 0.027493193745613098, dist_loss: 0.2465951144695282
recon_loss: 0.027493149042129517, dist_loss: 0.5833780765533447
recon_loss: 0.02749321423470974, dist_loss: 1.3405592441558838
recon_loss: 0.027492934837937355, dist_loss: 0.42973124980926514
recon_loss: 0.027492567896842957, dist_loss: 0.4722454249858856
recon_loss: 0.027492089197039604, dist_loss: 0.518531084060669
recon_loss: 0.027492035180330276, dist_loss: 0.7280887365341187
recon_loss: 0.02749190852046013, dist_loss: 0.817173957824707
recon_loss: 0.027491796761751175, dist_loss: 0.5239921808242798
recon_loss: 0.027491604909300804, dist_loss: 1.0805492401123047
recon_loss: 0.027491524815559387, dist_loss: 0.600532054901123
recon_loss: 0.027491256594657898, dist_loss: 0.5668060779571533
recon_loss: 0.0274912491440773, dist_loss: 0.6300625801086426
recon_loss: 0.02749103121459484, dist_loss: 0.6190751194953918
recon_loss: 0.02749115228652954, dist_loss: 0.7035344839096069
recon_loss: 0.027490945532917976, dist_loss: 0.7170818448066711
recon_loss: 0.027491265907883644, dist_loss: 0.5929139852523804
recon_loss: 0.027491502463817596, dist_loss: 0.7168976664543152
recon_loss: 0.027491368353366852, dist_loss: 0.9701645374298096
recon_loss: 0.027492424473166466, dist_loss: 0.7890483736991882
recon_loss: 0.027492614462971687, dist_loss: 0.7613792419433594
recon_loss: 0.027493854984641075, dist_loss: 0.5113379955291748
recon_loss: 0.027493419125676155, dist_loss: 0.7117331624031067
recon_loss: 0.027494536712765694, dist_loss: 0.3906533420085907
recon_loss: 0.02749413065612316, dist_loss: 0.7174492478370667
recon_loss: 0.02749442122876644, dist_loss: 0.5717118382453918
recon_loss: 0.027494024485349655, dist_loss: 0.4116699695587158
recon_loss: 0.027493512257933617, dist_loss: 0.7582484483718872
recon_loss: 0.027493350207805634, dist_loss: 0.8747502565383911
recon_loss: 0.027492299675941467, dist_loss: 0.6172356009483337
recon_loss: 0.027492152526974678, dist_loss: 0.39112764596939087
recon_loss: 0.02749103121459484, dist_loss: 0.6796023845672607
recon_loss: 0.027490835636854172, dist_loss: 0.5929705500602722
recon_loss: 0.02749056927859783, dist_loss: 0.7373196482658386
recon_loss: 0.027490418404340744, dist_loss: 0.9271783828735352
recon_loss: 0.02749026007950306, dist_loss: 0.44806554913520813
recon_loss: 0.027490023523569107, dist_loss: 0.5638104677200317
recon_loss: 0.02749028615653515, dist_loss: 0.5758947134017944
recon_loss: 0.027490003034472466, dist_loss: 0.7138879299163818
recon_loss: 0.02749006263911724, dist_loss: 0.9035444259643555
recon_loss: 0.02749025635421276, dist_loss: 0.3310821056365967
recon_loss: 0.027490416541695595, dist_loss: 0.7163705825805664
recon_loss: 0.02749054506421089, dist_loss: 0.3449550271034241
recon_loss: 0.027490567415952682, dist_loss: 0.7879317402839661
recon_loss: 0.027490204200148582, dist_loss: 0.613410472869873
recon_loss: 0.02748948149383068, dist_loss: 0.9958989024162292
recon_loss: 0.027489300817251205, dist_loss: 0.5193067193031311
recon_loss: 0.027489203959703445, dist_loss: 0.6388300657272339
recon_loss: 0.027489352971315384, dist_loss: 0.7824894189834595
recon_loss: 0.027489813044667244, dist_loss: 0.7211349010467529
recon_loss: 0.027489574626088142, dist_loss: 0.8159012198448181
recon_loss: 0.027489980682730675, dist_loss: 0.6747359037399292
recon_loss: 0.027489425614476204, dist_loss: 0.6706267595291138
recon_loss: 0.027489935979247093, dist_loss: 0.6580885648727417
recon_loss: 0.027490191161632538, dist_loss: 0.8142225742340088
recon_loss: 0.02749023213982582, dist_loss: 0.7729417681694031
recon_loss: 0.027490677312016487, dist_loss: 0.6435242891311646
recon_loss: 0.027489637956023216, dist_loss: 0.35401445627212524
recon_loss: 0.027489935979247093, dist_loss: 0.757779598236084
recon_loss: 0.02748899720609188, dist_loss: 0.4214542508125305
recon_loss: 0.02748958393931389, dist_loss: 0.5233389139175415
recon_loss: 0.027488892897963524, dist_loss: 0.5095992088317871
recon_loss: 0.027488332241773605, dist_loss: 0.5923318266868591
recon_loss: 0.027488859370350838, dist_loss: 1.5396968126296997
recon_loss: 0.02748856693506241, dist_loss: 0.5598832368850708
recon_loss: 0.02748972922563553, dist_loss: 1.0933518409729004
recon_loss: 0.027489226311445236, dist_loss: 0.6396158337593079
recon_loss: 0.027489744126796722, dist_loss: 0.4758203625679016
recon_loss: 0.02748964913189411, dist_loss: 0.4222927391529083
recon_loss: 0.02748972736299038, dist_loss: 0.7474720478057861
recon_loss: 0.027490029111504555, dist_loss: 1.209306001663208
recon_loss: 0.027489976957440376, dist_loss: 0.6530676484107971
recon_loss: 0.02749047987163067, dist_loss: 0.7094541788101196
recon_loss: 0.027489790692925453, dist_loss: 0.3922901451587677
Pre-training Epoch 102:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 102:   4%|▍         | 16/367 [00:00<00:02, 152.46it/s]Pre-training Epoch 102:   9%|▉         | 33/367 [00:00<00:02, 160.30it/s]Pre-training Epoch 102:  14%|█▎        | 50/367 [00:00<00:01, 163.04it/s]Pre-training Epoch 102:  18%|█▊        | 67/367 [00:00<00:01, 161.48it/s]Pre-training Epoch 102:  23%|██▎       | 84/367 [00:00<00:01, 162.48it/s]Pre-training Epoch 102:  28%|██▊       | 101/367 [00:00<00:01, 163.43it/s]Pre-training Epoch 102:  32%|███▏      | 118/367 [00:00<00:01, 164.43it/s]recon_loss: 0.027489395812153816, dist_loss: 0.4787575602531433
recon_loss: 0.02748907171189785, dist_loss: 0.9508440494537354
recon_loss: 0.02748788706958294, dist_loss: 0.600515604019165
recon_loss: 0.027487900108098984, dist_loss: 0.6489534974098206
recon_loss: 0.027487508952617645, dist_loss: 0.5691930651664734
recon_loss: 0.027487346902489662, dist_loss: 0.488583505153656
recon_loss: 0.02748701721429825, dist_loss: 0.8840504884719849
recon_loss: 0.027486758306622505, dist_loss: 0.7570666074752808
recon_loss: 0.027486652135849, dist_loss: 0.5283679962158203
recon_loss: 0.027486616745591164, dist_loss: 0.686726450920105
recon_loss: 0.027486449107527733, dist_loss: 0.5361955761909485
recon_loss: 0.027486147359013557, dist_loss: 0.5462006330490112
recon_loss: 0.02748614363372326, dist_loss: 0.648736834526062
recon_loss: 0.027486424893140793, dist_loss: 0.6300165057182312
recon_loss: 0.027487007901072502, dist_loss: 0.6316630840301514
recon_loss: 0.02748793363571167, dist_loss: 0.615890622138977
recon_loss: 0.02748948335647583, dist_loss: 0.5090616941452026
recon_loss: 0.02749083936214447, dist_loss: 1.1083037853240967
recon_loss: 0.027493556961417198, dist_loss: 0.35101842880249023
recon_loss: 0.027494221925735474, dist_loss: 0.4660911560058594
recon_loss: 0.02749473601579666, dist_loss: 0.6531373262405396
recon_loss: 0.027493366971611977, dist_loss: 0.3648824095726013
recon_loss: 0.02749205008149147, dist_loss: 1.2077724933624268
recon_loss: 0.02749045006930828, dist_loss: 0.5179088115692139
recon_loss: 0.027489857748150826, dist_loss: 0.6425762176513672
recon_loss: 0.027488743886351585, dist_loss: 0.34094804525375366
recon_loss: 0.02748819999396801, dist_loss: 0.5164729356765747
recon_loss: 0.02748779207468033, dist_loss: 0.3759958744049072
recon_loss: 0.027486946433782578, dist_loss: 0.5246727466583252
recon_loss: 0.027486812323331833, dist_loss: 0.7335200905799866
recon_loss: 0.027486568316817284, dist_loss: 0.44286900758743286
recon_loss: 0.027486301958560944, dist_loss: 0.6229960322380066
recon_loss: 0.02748640812933445, dist_loss: 0.41762062907218933
recon_loss: 0.0274861641228199, dist_loss: 0.8156355619430542
recon_loss: 0.027486532926559448, dist_loss: 0.5891451835632324
recon_loss: 0.02748585119843483, dist_loss: 0.2523730397224426
recon_loss: 0.027485422790050507, dist_loss: 0.8477489948272705
recon_loss: 0.02748519368469715, dist_loss: 0.47102412581443787
recon_loss: 0.0274849571287632, dist_loss: 0.9659734964370728
recon_loss: 0.02748512476682663, dist_loss: 0.5338574647903442
recon_loss: 0.027485162019729614, dist_loss: 0.42627114057540894
recon_loss: 0.027484863996505737, dist_loss: 0.2812345027923584
recon_loss: 0.027485297992825508, dist_loss: 0.9565728902816772
recon_loss: 0.027485165745019913, dist_loss: 0.5135467052459717
recon_loss: 0.0274856798350811, dist_loss: 0.4157569110393524
recon_loss: 0.027485588565468788, dist_loss: 0.8144361972808838
recon_loss: 0.02748613990843296, dist_loss: 0.4994952082633972
recon_loss: 0.027485722675919533, dist_loss: 0.9244034290313721
recon_loss: 0.027485152706503868, dist_loss: 0.7679266333580017
recon_loss: 0.027485627681016922, dist_loss: 0.9386911392211914
recon_loss: 0.027484439313411713, dist_loss: 0.8727662563323975
recon_loss: 0.027484582737088203, dist_loss: 0.55816650390625
recon_loss: 0.027484314516186714, dist_loss: 0.5146569013595581
recon_loss: 0.027484428137540817, dist_loss: 0.7988694310188293
recon_loss: 0.02748466283082962, dist_loss: 0.5380618572235107
recon_loss: 0.027484292164444923, dist_loss: 0.6644257307052612
recon_loss: 0.027484647929668427, dist_loss: 0.9930243492126465
recon_loss: 0.027484558522701263, dist_loss: 0.6042299866676331
recon_loss: 0.02748493291437626, dist_loss: 0.5513871312141418
recon_loss: 0.027485141530632973, dist_loss: 0.5952761173248291
recon_loss: 0.027486005797982216, dist_loss: 0.4672457277774811
recon_loss: 0.027486274018883705, dist_loss: 0.6804501414299011
recon_loss: 0.027486762031912804, dist_loss: 0.5018609762191772
recon_loss: 0.027487311512231827, dist_loss: 0.8097277879714966
recon_loss: 0.02748671919107437, dist_loss: 0.7026649117469788
recon_loss: 0.027488628402352333, dist_loss: 1.5730804204940796
recon_loss: 0.02748977765440941, dist_loss: 0.538888692855835
recon_loss: 0.027492187917232513, dist_loss: 0.5823487639427185
recon_loss: 0.02749376930296421, dist_loss: 0.599735677242279
recon_loss: 0.027494074776768684, dist_loss: 0.6627589464187622
recon_loss: 0.02749493718147278, dist_loss: 0.4349699318408966
recon_loss: 0.027494600042700768, dist_loss: 0.4388071298599243
recon_loss: 0.027495037764310837, dist_loss: 0.4860804080963135
recon_loss: 0.027494234964251518, dist_loss: 0.6233903765678406
recon_loss: 0.027494346722960472, dist_loss: 0.35500824451446533
recon_loss: 0.027494072914123535, dist_loss: 0.8659517765045166
recon_loss: 0.02749290131032467, dist_loss: 0.4302002787590027
recon_loss: 0.027491239830851555, dist_loss: 0.7697821855545044
recon_loss: 0.02748967707157135, dist_loss: 0.6996177434921265
recon_loss: 0.027488788589835167, dist_loss: 0.36877644062042236
recon_loss: 0.02748800627887249, dist_loss: 0.6890546083450317
recon_loss: 0.027487216517329216, dist_loss: 1.1768381595611572
recon_loss: 0.027486542239785194, dist_loss: 1.0450220108032227
recon_loss: 0.027486387640237808, dist_loss: 0.566110372543335
recon_loss: 0.027486657723784447, dist_loss: 0.6893796920776367
recon_loss: 0.02748887985944748, dist_loss: 0.4156583547592163
recon_loss: 0.027488429099321365, dist_loss: 0.6339207291603088
recon_loss: 0.02748982235789299, dist_loss: 0.7196470499038696
recon_loss: 0.027489006519317627, dist_loss: 0.6073920726776123
recon_loss: 0.027488458901643753, dist_loss: 0.8219839930534363
recon_loss: 0.027488362044095993, dist_loss: 0.41758039593696594
recon_loss: 0.02748754806816578, dist_loss: 0.6731305122375488
recon_loss: 0.02748759277164936, dist_loss: 0.7617100477218628
recon_loss: 0.027486570179462433, dist_loss: 0.6711233854293823
recon_loss: 0.027487147599458694, dist_loss: 0.4279855489730835
recon_loss: 0.027486400678753853, dist_loss: 0.6068365573883057
recon_loss: 0.027487196028232574, dist_loss: 0.49373871088027954
recon_loss: 0.027486514300107956, dist_loss: 0.6834113001823425
recon_loss: 0.02748604491353035, dist_loss: 0.5565398931503296
recon_loss: 0.027485812082886696, dist_loss: 1.0000627040863037
recon_loss: 0.027485216036438942, dist_loss: 0.4103223383426666
recon_loss: 0.027485905215144157, dist_loss: 0.7676829099655151
recon_loss: 0.0274854376912117, dist_loss: 0.5860856771469116
recon_loss: 0.027486231178045273, dist_loss: 0.6142531633377075
recon_loss: 0.027486274018883705, dist_loss: 0.6702789068222046
recon_loss: 0.027485402300953865, dist_loss: 0.5574093461036682
recon_loss: 0.027485908940434456, dist_loss: 1.036935567855835
recon_loss: 0.02748473919928074, dist_loss: 0.5999199151992798
recon_loss: 0.027485117316246033, dist_loss: 0.7529902458190918
recon_loss: 0.027483932673931122, dist_loss: 0.6050426363945007
recon_loss: 0.02748352475464344, dist_loss: 0.6209204196929932
recon_loss: 0.027482686564326286, dist_loss: 0.5443861484527588
recon_loss: 0.02748226560652256, dist_loss: 0.5849899649620056
recon_loss: 0.02748282626271248, dist_loss: 1.0228294134140015
recon_loss: 0.02748304046690464, dist_loss: 0.6485892534255981
recon_loss: 0.027484165504574776, dist_loss: 0.5958400964736938
recon_loss: 0.027483521029353142, dist_loss: 0.6120174527168274
recon_loss: 0.0274828989058733, dist_loss: 0.7394551634788513
recon_loss: 0.027483085170388222, dist_loss: 0.5830180048942566
recon_loss: 0.027482563629746437, dist_loss: 1.3479434251785278
recon_loss: 0.02748236060142517, dist_loss: 0.6518595218658447
recon_loss: 0.027482660487294197, dist_loss: 0.5456639528274536
recon_loss: 0.027482787147164345, dist_loss: 0.6893062591552734
recon_loss: 0.027483321726322174, dist_loss: 0.5348427295684814
recon_loss: 0.027483252808451653, dist_loss: 0.35904747247695923
recon_loss: 0.027482442557811737, dist_loss: 0.4454798102378845
recon_loss: 0.027482183650135994, dist_loss: 1.0243914127349854
recon_loss: 0.027482423931360245, dist_loss: 0.3457317054271698
Pre-training Epoch 102:  37%|███▋      | 135/367 [00:00<00:01, 165.08it/s]Pre-training Epoch 102:  41%|████▏     | 152/367 [00:00<00:01, 165.47it/s]Pre-training Epoch 102:  46%|████▌     | 169/367 [00:01<00:01, 163.95it/s]Pre-training Epoch 102:  51%|█████     | 186/367 [00:01<00:01, 160.80it/s]Pre-training Epoch 102:  55%|█████▌    | 203/367 [00:01<00:01, 158.64it/s]Pre-training Epoch 102:  60%|█████▉    | 219/367 [00:01<00:00, 155.30it/s]Pre-training Epoch 102:  64%|██████▍   | 235/367 [00:01<00:00, 154.93it/s]Pre-training Epoch 102:  68%|██████▊   | 251/367 [00:01<00:00, 154.85it/s]recon_loss: 0.027482300996780396, dist_loss: 0.3452218770980835
recon_loss: 0.02748221717774868, dist_loss: 0.8807613849639893
recon_loss: 0.027481673285365105, dist_loss: 0.6713677644729614
recon_loss: 0.0274810828268528, dist_loss: 0.4878714978694916
recon_loss: 0.0274807196110487, dist_loss: 0.8761804103851318
recon_loss: 0.0274807196110487, dist_loss: 0.39278268814086914
recon_loss: 0.027480581775307655, dist_loss: 0.8024643659591675
recon_loss: 0.02748108096420765, dist_loss: 0.47810840606689453
recon_loss: 0.02748221345245838, dist_loss: 0.8829916715621948
recon_loss: 0.02748297154903412, dist_loss: 0.7604416608810425
recon_loss: 0.027484716847538948, dist_loss: 1.0804225206375122
recon_loss: 0.027485134080052376, dist_loss: 0.9039259552955627
recon_loss: 0.027485636994242668, dist_loss: 0.4768206775188446
recon_loss: 0.02748548425734043, dist_loss: 0.5812559127807617
recon_loss: 0.027486665174365044, dist_loss: 0.5370166301727295
recon_loss: 0.027486253529787064, dist_loss: 0.7203819751739502
recon_loss: 0.02748648263514042, dist_loss: 0.4152131974697113
recon_loss: 0.02748587541282177, dist_loss: 0.5453941822052002
recon_loss: 0.027485154569149017, dist_loss: 0.706547200679779
recon_loss: 0.02748444490134716, dist_loss: 0.9770309329032898
recon_loss: 0.0274837464094162, dist_loss: 0.6938743591308594
recon_loss: 0.027482884004712105, dist_loss: 0.5432268381118774
recon_loss: 0.027482323348522186, dist_loss: 0.5850492715835571
recon_loss: 0.027481693774461746, dist_loss: 0.3849875330924988
recon_loss: 0.02748081274330616, dist_loss: 0.9340768456459045
recon_loss: 0.027480866760015488, dist_loss: 0.4705532491207123
recon_loss: 0.027480067685246468, dist_loss: 0.3882865309715271
recon_loss: 0.02748023346066475, dist_loss: 0.5571705102920532
recon_loss: 0.027479877695441246, dist_loss: 0.7418287396430969
recon_loss: 0.027479160577058792, dist_loss: 0.681726336479187
recon_loss: 0.02747929096221924, dist_loss: 0.7989431619644165
recon_loss: 0.027478622272610664, dist_loss: 0.8964484930038452
recon_loss: 0.0274787787348032, dist_loss: 0.8391392827033997
recon_loss: 0.02747819945216179, dist_loss: 0.7354008555412292
recon_loss: 0.02747824415564537, dist_loss: 0.5882126092910767
recon_loss: 0.027477936819195747, dist_loss: 0.41939425468444824
recon_loss: 0.027477851137518883, dist_loss: 0.48197507858276367
recon_loss: 0.02747781202197075, dist_loss: 0.4974202513694763
recon_loss: 0.027477720752358437, dist_loss: 0.4043944776058197
recon_loss: 0.027477925643324852, dist_loss: 1.073169231414795
recon_loss: 0.027478624135255814, dist_loss: 0.5360199213027954
recon_loss: 0.027479179203510284, dist_loss: 0.7253156304359436
recon_loss: 0.027480239048600197, dist_loss: 0.6113541722297668
recon_loss: 0.027480674907565117, dist_loss: 0.7425140142440796
recon_loss: 0.027480052784085274, dist_loss: 0.6409103274345398
recon_loss: 0.027479717507958412, dist_loss: 0.4444514513015747
recon_loss: 0.02747931145131588, dist_loss: 0.48565375804901123
recon_loss: 0.027478797361254692, dist_loss: 0.5093594789505005
recon_loss: 0.027478205040097237, dist_loss: 0.5320834517478943
recon_loss: 0.027477795258164406, dist_loss: 0.967937707901001
recon_loss: 0.02747715264558792, dist_loss: 0.6946172714233398
recon_loss: 0.027476942166686058, dist_loss: 0.6199718713760376
recon_loss: 0.02747683972120285, dist_loss: 0.7950562238693237
recon_loss: 0.0274769589304924, dist_loss: 0.7407824993133545
recon_loss: 0.027477238327264786, dist_loss: 0.6223766803741455
recon_loss: 0.027477383613586426, dist_loss: 0.5132362842559814
recon_loss: 0.027477247640490532, dist_loss: 0.8041069507598877
recon_loss: 0.027476884424686432, dist_loss: 0.4475145637989044
recon_loss: 0.027476651594042778, dist_loss: 0.5987973809242249
recon_loss: 0.027476543560624123, dist_loss: 0.39062976837158203
recon_loss: 0.027476361021399498, dist_loss: 0.708641767501831
recon_loss: 0.027476031333208084, dist_loss: 0.9325495362281799
recon_loss: 0.027475843206048012, dist_loss: 0.871346116065979
recon_loss: 0.027476172894239426, dist_loss: 0.8055402040481567
recon_loss: 0.027476469054818153, dist_loss: 0.8975280523300171
recon_loss: 0.02747715264558792, dist_loss: 0.29673752188682556
recon_loss: 0.027477815747261047, dist_loss: 0.6580632925033569
recon_loss: 0.027477946132421494, dist_loss: 0.6076253652572632
recon_loss: 0.02747827023267746, dist_loss: 0.8586467504501343
recon_loss: 0.027477914467453957, dist_loss: 0.6296608448028564
recon_loss: 0.027477674186229706, dist_loss: 0.7954275012016296
recon_loss: 0.027476750314235687, dist_loss: 0.5023270845413208
recon_loss: 0.02747650071978569, dist_loss: 0.8047178983688354
recon_loss: 0.027475863695144653, dist_loss: 0.36040031909942627
recon_loss: 0.02747623808681965, dist_loss: 0.6246898174285889
recon_loss: 0.027475949376821518, dist_loss: 0.5531200170516968
recon_loss: 0.027476806193590164, dist_loss: 1.0477845668792725
recon_loss: 0.02747773379087448, dist_loss: 0.41625723242759705
recon_loss: 0.02747948281466961, dist_loss: 0.41521668434143066
recon_loss: 0.027480585500597954, dist_loss: 0.4128459692001343
recon_loss: 0.027481352910399437, dist_loss: 0.4254491329193115
recon_loss: 0.027482664212584496, dist_loss: 0.5673967599868774
recon_loss: 0.02748260460793972, dist_loss: 0.708055317401886
recon_loss: 0.027483828365802765, dist_loss: 0.4346376955509186
recon_loss: 0.0274812001734972, dist_loss: 0.49856775999069214
recon_loss: 0.027481015771627426, dist_loss: 0.4976651966571808
recon_loss: 0.02747916430234909, dist_loss: 0.5510283708572388
recon_loss: 0.02747938223183155, dist_loss: 0.7089715003967285
recon_loss: 0.02747812494635582, dist_loss: 0.6666589975357056
recon_loss: 0.02747783251106739, dist_loss: 0.5059109926223755
recon_loss: 0.02747843973338604, dist_loss: 0.7329323887825012
recon_loss: 0.027477681636810303, dist_loss: 0.6587717533111572
recon_loss: 0.02747957967221737, dist_loss: 0.930830717086792
recon_loss: 0.027478493750095367, dist_loss: 0.3311299979686737
recon_loss: 0.027479806914925575, dist_loss: 0.5369895100593567
recon_loss: 0.0274784155189991, dist_loss: 0.4913422465324402
recon_loss: 0.027478192001581192, dist_loss: 0.5511484146118164
recon_loss: 0.027477117255330086, dist_loss: 0.43046697974205017
recon_loss: 0.027475904673337936, dist_loss: 0.4086582660675049
recon_loss: 0.02747585065662861, dist_loss: 0.5079787373542786
recon_loss: 0.02747463993728161, dist_loss: 0.40559619665145874
recon_loss: 0.027475424110889435, dist_loss: 0.8699842691421509
recon_loss: 0.02747463621199131, dist_loss: 0.8606313467025757
recon_loss: 0.027475906535983086, dist_loss: 0.501038670539856
recon_loss: 0.027474816888570786, dist_loss: 0.6534072756767273
recon_loss: 0.027474943548440933, dist_loss: 0.7349942922592163
recon_loss: 0.02747533470392227, dist_loss: 0.8648039698600769
recon_loss: 0.02747681736946106, dist_loss: 0.4925260841846466
recon_loss: 0.027477150782942772, dist_loss: 0.6650393009185791
recon_loss: 0.027477160096168518, dist_loss: 0.781902551651001
recon_loss: 0.02747662179172039, dist_loss: 0.6383947134017944
recon_loss: 0.027476180344820023, dist_loss: 0.7874213457107544
recon_loss: 0.027475502341985703, dist_loss: 1.0648691654205322
recon_loss: 0.027474595233798027, dist_loss: 0.6842015385627747
recon_loss: 0.02747447043657303, dist_loss: 0.586108922958374
recon_loss: 0.027474530041217804, dist_loss: 1.10573148727417
recon_loss: 0.02747463248670101, dist_loss: 0.5345631837844849
recon_loss: 0.027474412694573402, dist_loss: 0.8671920895576477
recon_loss: 0.027474775910377502, dist_loss: 0.45013660192489624
recon_loss: 0.02747443877160549, dist_loss: 0.4557224214076996
recon_loss: 0.027474986389279366, dist_loss: 0.5677590370178223
recon_loss: 0.027475498616695404, dist_loss: 0.6650692224502563
recon_loss: 0.027474844828248024, dist_loss: 1.0039633512496948
recon_loss: 0.027475101873278618, dist_loss: 0.9983524084091187
recon_loss: 0.027474481612443924, dist_loss: 0.5965999364852905
recon_loss: 0.0274749044328928, dist_loss: 1.0493757724761963
recon_loss: 0.027475357055664062, dist_loss: 0.317687451839447
recon_loss: 0.027475597336888313, dist_loss: 0.6648117303848267
Pre-training Epoch 102:  73%|███████▎  | 267/367 [00:01<00:00, 155.43it/s]Pre-training Epoch 102:  77%|███████▋  | 283/367 [00:01<00:00, 155.11it/s]Pre-training Epoch 102:  81%|████████▏ | 299/367 [00:01<00:00, 154.48it/s]Pre-training Epoch 102:  86%|████████▌ | 315/367 [00:01<00:00, 154.73it/s]Pre-training Epoch 102:  91%|█████████ | 333/367 [00:02<00:00, 161.45it/s]Pre-training Epoch 102:  95%|█████████▌| 350/367 [00:02<00:00, 162.66it/s]Pre-training Epoch 102: 100%|██████████| 367/367 [00:02<00:00, 160.61it/s]
recon_loss: 0.02747667022049427, dist_loss: 0.9237977862358093
recon_loss: 0.02747604064643383, dist_loss: 0.426236093044281
recon_loss: 0.027477188035845757, dist_loss: 0.5831165909767151
recon_loss: 0.027477016672492027, dist_loss: 0.5845308899879456
recon_loss: 0.027477432042360306, dist_loss: 0.6306166648864746
recon_loss: 0.027476858347654343, dist_loss: 0.8400280475616455
recon_loss: 0.027476735413074493, dist_loss: 0.42560499906539917
recon_loss: 0.02747628465294838, dist_loss: 0.7091577053070068
recon_loss: 0.02747507207095623, dist_loss: 0.7680877447128296
recon_loss: 0.027475273236632347, dist_loss: 0.5793715715408325
recon_loss: 0.027474280446767807, dist_loss: 0.5166560411453247
recon_loss: 0.02747512422502041, dist_loss: 0.9695674777030945
recon_loss: 0.027475370094180107, dist_loss: 0.5535637140274048
recon_loss: 0.027476290240883827, dist_loss: 0.5524541139602661
recon_loss: 0.027476707473397255, dist_loss: 0.7991616725921631
recon_loss: 0.027475792914628983, dist_loss: 1.2897270917892456
recon_loss: 0.027475232258439064, dist_loss: 0.7833622097969055
recon_loss: 0.0274739358574152, dist_loss: 0.9410717487335205
recon_loss: 0.02747420407831669, dist_loss: 0.8789727687835693
recon_loss: 0.027473706752061844, dist_loss: 0.7675860524177551
recon_loss: 0.027475349605083466, dist_loss: 0.7220205068588257
recon_loss: 0.0274751465767622, dist_loss: 0.42701318860054016
recon_loss: 0.027476156130433083, dist_loss: 0.5939043760299683
recon_loss: 0.027474312111735344, dist_loss: 0.7697888612747192
recon_loss: 0.027474677190184593, dist_loss: 0.7102525234222412
recon_loss: 0.0274738147854805, dist_loss: 0.44099485874176025
recon_loss: 0.027473444119095802, dist_loss: 0.7650294303894043
recon_loss: 0.02747379243373871, dist_loss: 0.4617674946784973
recon_loss: 0.02747245877981186, dist_loss: 0.9554774761199951
recon_loss: 0.027473092079162598, dist_loss: 0.5335721969604492
recon_loss: 0.02747236378490925, dist_loss: 0.6866400241851807
recon_loss: 0.027472304180264473, dist_loss: 0.6432587504386902
recon_loss: 0.027472425252199173, dist_loss: 0.45773670077323914
recon_loss: 0.02747270092368126, dist_loss: 0.8521685004234314
recon_loss: 0.02747313492000103, dist_loss: 0.7270542979240417
recon_loss: 0.02747313492000103, dist_loss: 0.6358028650283813
recon_loss: 0.02747311443090439, dist_loss: 0.8291109800338745
recon_loss: 0.02747267112135887, dist_loss: 1.1135482788085938
recon_loss: 0.027472279965877533, dist_loss: 0.5678253173828125
recon_loss: 0.027471624314785004, dist_loss: 0.4531114101409912
recon_loss: 0.027471644803881645, dist_loss: 0.46819791197776794
recon_loss: 0.027471797540783882, dist_loss: 0.6846693754196167
recon_loss: 0.027471395209431648, dist_loss: 0.6076692342758179
recon_loss: 0.02747088111937046, dist_loss: 0.28081214427948
recon_loss: 0.0274707842618227, dist_loss: 0.5054845809936523
recon_loss: 0.02747076377272606, dist_loss: 0.6822184324264526
recon_loss: 0.02747093327343464, dist_loss: 0.5196409225463867
recon_loss: 0.027470838278532028, dist_loss: 1.1629325151443481
recon_loss: 0.027470318600535393, dist_loss: 0.9331237077713013
recon_loss: 0.027469884604215622, dist_loss: 0.6319166421890259
recon_loss: 0.027469752356410027, dist_loss: 0.9468895196914673
recon_loss: 0.027469588443636894, dist_loss: 0.8075563907623291
recon_loss: 0.02746988646686077, dist_loss: 0.8265414834022522
recon_loss: 0.027470342814922333, dist_loss: 0.6948177814483643
recon_loss: 0.027471069246530533, dist_loss: 0.8834547996520996
recon_loss: 0.027471669018268585, dist_loss: 0.44625937938690186
recon_loss: 0.02747209556400776, dist_loss: 0.5878486633300781
recon_loss: 0.027472984045743942, dist_loss: 0.6890592575073242
recon_loss: 0.02747364155948162, dist_loss: 0.661023736000061
recon_loss: 0.027473753318190575, dist_loss: 0.4971892833709717
recon_loss: 0.02747351862490177, dist_loss: 0.5278863310813904
recon_loss: 0.027473514899611473, dist_loss: 0.879490852355957
recon_loss: 0.02747376263141632, dist_loss: 0.46961045265197754
recon_loss: 0.027473995462059975, dist_loss: 0.6380179524421692
recon_loss: 0.02747507207095623, dist_loss: 0.4894784688949585
recon_loss: 0.02747504971921444, dist_loss: 0.3659588694572449
recon_loss: 0.02747553028166294, dist_loss: 0.551830530166626
recon_loss: 0.027474991977214813, dist_loss: 0.7569231986999512
recon_loss: 0.027474302798509598, dist_loss: 0.25251930952072144
recon_loss: 0.027474170550704002, dist_loss: 0.4379633069038391
recon_loss: 0.027473298832774162, dist_loss: 0.5166065692901611
recon_loss: 0.027472620829939842, dist_loss: 0.5270659923553467
recon_loss: 0.027472255751490593, dist_loss: 0.6869027018547058
recon_loss: 0.027471527457237244, dist_loss: 0.8543300628662109
recon_loss: 0.02747211791574955, dist_loss: 0.7757517099380493
recon_loss: 0.027471933513879776, dist_loss: 0.5104174613952637
recon_loss: 0.027471980080008507, dist_loss: 0.9204006791114807
recon_loss: 0.02747217006981373, dist_loss: 0.9305732846260071
recon_loss: 0.027472058311104774, dist_loss: 0.7399017810821533
recon_loss: 0.027472278103232384, dist_loss: 0.6721916198730469
recon_loss: 0.027471400797367096, dist_loss: 1.1596699953079224
recon_loss: 0.027470970526337624, dist_loss: 0.4974977374076843
recon_loss: 0.027470974251627922, dist_loss: 0.6162376999855042
recon_loss: 0.027471384033560753, dist_loss: 0.6251555681228638
recon_loss: 0.0274726003408432, dist_loss: 0.8291840553283691
recon_loss: 0.02747409977018833, dist_loss: 0.5758189558982849
recon_loss: 0.027474937960505486, dist_loss: 0.42570167779922485
recon_loss: 0.027475029230117798, dist_loss: 0.550606906414032
recon_loss: 0.027474218979477882, dist_loss: 0.7609798312187195
recon_loss: 0.027473561465740204, dist_loss: 0.7166975140571594
recon_loss: 0.027472978457808495, dist_loss: 0.5122493505477905
recon_loss: 0.02747243642807007, dist_loss: 0.8489848375320435
recon_loss: 0.027471916750073433, dist_loss: 0.514833390712738
recon_loss: 0.027471380308270454, dist_loss: 0.6454107761383057
recon_loss: 0.027470748871564865, dist_loss: 0.819249153137207
recon_loss: 0.027470102533698082, dist_loss: 0.3894366919994354
recon_loss: 0.027469968423247337, dist_loss: 0.6632201671600342
recon_loss: 0.027469778433442116, dist_loss: 0.3977389931678772
recon_loss: 0.027469679713249207, dist_loss: 0.4549625813961029
recon_loss: 0.027469491586089134, dist_loss: 0.5453108549118042
recon_loss: 0.027469582855701447, dist_loss: 0.6530468463897705
recon_loss: 0.02746979333460331, dist_loss: 0.9634864926338196
recon_loss: 0.027469923719763756, dist_loss: 1.0466935634613037
recon_loss: 0.027470434084534645, dist_loss: 0.5121579170227051
recon_loss: 0.027470692992210388, dist_loss: 0.3548973798751831
recon_loss: 0.027471451088786125, dist_loss: 0.5687714219093323
recon_loss: 0.027471916750073433, dist_loss: 0.5801120400428772
recon_loss: 0.02747257612645626, dist_loss: 0.6675081253051758
recon_loss: 0.02747296914458275, dist_loss: 0.6199496984481812
recon_loss: 0.02747398428618908, dist_loss: 0.5898804664611816
recon_loss: 0.02747420407831669, dist_loss: 0.826903760433197
Pre-training Epoch 103:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 103:   4%|▍         | 16/367 [00:00<00:02, 158.47it/s]Pre-training Epoch 103:   9%|▉         | 34/367 [00:00<00:01, 170.33it/s]Pre-training Epoch 103:  14%|█▍        | 52/367 [00:00<00:01, 173.71it/s]Pre-training Epoch 103:  19%|█▉        | 70/367 [00:00<00:01, 173.24it/s]Pre-training Epoch 103:  24%|██▍       | 89/367 [00:00<00:01, 175.57it/s]Pre-training Epoch 103:  29%|██▉       | 108/367 [00:00<00:01, 177.55it/s]Pre-training Epoch 103:  34%|███▍      | 126/367 [00:00<00:01, 177.57it/s]recon_loss: 0.027473917230963707, dist_loss: 1.3112791776657104
recon_loss: 0.02747330814599991, dist_loss: 1.0763297080993652
recon_loss: 0.027471644803881645, dist_loss: 0.4728895425796509
recon_loss: 0.02747196890413761, dist_loss: 0.856355607509613
recon_loss: 0.027471518144011497, dist_loss: 0.6988838315010071
recon_loss: 0.027471790090203285, dist_loss: 0.6419588327407837
recon_loss: 0.027471313253045082, dist_loss: 0.6761652827262878
recon_loss: 0.02747083082795143, dist_loss: 0.5534893274307251
recon_loss: 0.027470892295241356, dist_loss: 1.0381791591644287
recon_loss: 0.02747129090130329, dist_loss: 0.6860385537147522
recon_loss: 0.02747309021651745, dist_loss: 0.5114796757698059
recon_loss: 0.027473021298646927, dist_loss: 1.112972378730774
recon_loss: 0.027475181967020035, dist_loss: 0.6388506889343262
recon_loss: 0.027475297451019287, dist_loss: 0.4441388249397278
recon_loss: 0.027475880458950996, dist_loss: 0.3595236539840698
recon_loss: 0.02747647650539875, dist_loss: 0.5133985877037048
recon_loss: 0.027475666254758835, dist_loss: 0.7043007612228394
recon_loss: 0.027477547526359558, dist_loss: 0.7155174016952515
recon_loss: 0.027475588023662567, dist_loss: 0.7129946351051331
recon_loss: 0.02747492678463459, dist_loss: 1.043082594871521
recon_loss: 0.02747880108654499, dist_loss: 0.5575672388076782
recon_loss: 0.027474647387862206, dist_loss: 0.8561956882476807
recon_loss: 0.027480285614728928, dist_loss: 0.7119140625
recon_loss: 0.02747560478746891, dist_loss: 0.6939501762390137
recon_loss: 0.027478549629449844, dist_loss: 0.4241259694099426
recon_loss: 0.027476955205202103, dist_loss: 0.4502044916152954
recon_loss: 0.02747674286365509, dist_loss: 0.68951416015625
recon_loss: 0.027479086071252823, dist_loss: 0.7835145592689514
recon_loss: 0.027476374059915543, dist_loss: 0.8354489803314209
recon_loss: 0.027480553835630417, dist_loss: 0.5174188613891602
recon_loss: 0.027475357055664062, dist_loss: 0.6940747499465942
recon_loss: 0.027476700022816658, dist_loss: 0.6939144134521484
recon_loss: 0.02747403085231781, dist_loss: 0.898726761341095
recon_loss: 0.02747296541929245, dist_loss: 0.6894827485084534
recon_loss: 0.02747279591858387, dist_loss: 0.5516085624694824
recon_loss: 0.027470272034406662, dist_loss: 0.34462639689445496
recon_loss: 0.027471041306853294, dist_loss: 0.41746529936790466
recon_loss: 0.027468744665384293, dist_loss: 0.5026686787605286
recon_loss: 0.027469495311379433, dist_loss: 0.35422956943511963
recon_loss: 0.02746966853737831, dist_loss: 0.7594083547592163
recon_loss: 0.02747090347111225, dist_loss: 0.422167032957077
recon_loss: 0.027472781017422676, dist_loss: 1.0944228172302246
recon_loss: 0.027471337467432022, dist_loss: 0.6577425003051758
recon_loss: 0.027471717447042465, dist_loss: 0.3579303026199341
recon_loss: 0.027470646426081657, dist_loss: 0.552992045879364
recon_loss: 0.027469849213957787, dist_loss: 1.059861421585083
recon_loss: 0.027468828484416008, dist_loss: 0.46670132875442505
recon_loss: 0.02746819518506527, dist_loss: 0.7740567922592163
recon_loss: 0.027467310428619385, dist_loss: 1.0873119831085205
recon_loss: 0.027466822415590286, dist_loss: 0.7717655897140503
recon_loss: 0.02746649831533432, dist_loss: 0.7859282493591309
recon_loss: 0.027466455474495888, dist_loss: 0.8368194103240967
recon_loss: 0.02746640145778656, dist_loss: 0.6477855443954468
recon_loss: 0.027466420084238052, dist_loss: 0.9641110897064209
recon_loss: 0.027465997263789177, dist_loss: 0.6388788223266602
recon_loss: 0.02746601402759552, dist_loss: 0.6880831718444824
recon_loss: 0.027465566992759705, dist_loss: 0.5123023390769958
recon_loss: 0.027465354651212692, dist_loss: 0.7188811302185059
recon_loss: 0.027465922757983208, dist_loss: 0.38502758741378784
recon_loss: 0.027465589344501495, dist_loss: 0.5003718137741089
recon_loss: 0.02746618166565895, dist_loss: 0.6351636648178101
recon_loss: 0.027465729042887688, dist_loss: 0.801134467124939
recon_loss: 0.027466045692563057, dist_loss: 0.5514236688613892
recon_loss: 0.02746494859457016, dist_loss: 1.0469439029693604
recon_loss: 0.02746567130088806, dist_loss: 0.8382925987243652
recon_loss: 0.027465714141726494, dist_loss: 0.389477014541626
recon_loss: 0.027465952560305595, dist_loss: 0.8723249435424805
recon_loss: 0.027467167004942894, dist_loss: 0.4088468849658966
recon_loss: 0.02746693789958954, dist_loss: 0.7552667856216431
recon_loss: 0.027467796579003334, dist_loss: 0.5849363803863525
recon_loss: 0.027467915788292885, dist_loss: 0.8574992418289185
recon_loss: 0.02746758982539177, dist_loss: 0.36117589473724365
recon_loss: 0.027468202635645866, dist_loss: 0.6475626230239868
recon_loss: 0.027466997504234314, dist_loss: 0.9965742826461792
recon_loss: 0.02746693044900894, dist_loss: 0.674557626247406
recon_loss: 0.027466198429465294, dist_loss: 0.6004399061203003
recon_loss: 0.0274649690836668, dist_loss: 0.633110761642456
recon_loss: 0.02746495231986046, dist_loss: 0.27683335542678833
recon_loss: 0.02746441587805748, dist_loss: 0.30296361446380615
recon_loss: 0.027464674785733223, dist_loss: 0.6939696073532104
recon_loss: 0.027465667575597763, dist_loss: 0.8725224137306213
recon_loss: 0.027467133477330208, dist_loss: 0.49728354811668396
recon_loss: 0.027468277141451836, dist_loss: 0.5903433561325073
recon_loss: 0.027468951418995857, dist_loss: 0.7796704769134521
recon_loss: 0.02746897004544735, dist_loss: 0.5495353937149048
recon_loss: 0.027468279004096985, dist_loss: 0.8301530480384827
recon_loss: 0.027467206120491028, dist_loss: 0.6142777800559998
recon_loss: 0.027466604486107826, dist_loss: 0.5601052641868591
recon_loss: 0.02746564894914627, dist_loss: 0.5673876404762268
recon_loss: 0.02746517024934292, dist_loss: 0.5122339725494385
recon_loss: 0.02746482752263546, dist_loss: 0.6623613834381104
recon_loss: 0.02746458724141121, dist_loss: 0.8866638541221619
recon_loss: 0.027464261278510094, dist_loss: 0.4166924059391022
recon_loss: 0.027464069426059723, dist_loss: 0.5636075735092163
recon_loss: 0.027464136481285095, dist_loss: 0.7929650545120239
recon_loss: 0.027463844045996666, dist_loss: 0.6178415417671204
recon_loss: 0.02746390365064144, dist_loss: 0.5458923578262329
recon_loss: 0.027464013546705246, dist_loss: 0.44972896575927734
recon_loss: 0.027463873848319054, dist_loss: 0.7710860967636108
recon_loss: 0.02746366709470749, dist_loss: 0.6675764322280884
recon_loss: 0.027463804930448532, dist_loss: 0.49413588643074036
recon_loss: 0.027463991194963455, dist_loss: 0.5846509337425232
recon_loss: 0.0274637583643198, dist_loss: 0.4663122594356537
recon_loss: 0.02746371366083622, dist_loss: 0.7891730666160583
recon_loss: 0.02746392786502838, dist_loss: 0.4724174439907074
recon_loss: 0.02746388502418995, dist_loss: 0.6666138768196106
recon_loss: 0.027464108541607857, dist_loss: 1.1700414419174194
recon_loss: 0.02746358886361122, dist_loss: 0.6656538248062134
recon_loss: 0.02746313437819481, dist_loss: 0.4643959403038025
recon_loss: 0.02746283821761608, dist_loss: 0.5751340985298157
recon_loss: 0.027462588623166084, dist_loss: 0.95317542552948
recon_loss: 0.027462858706712723, dist_loss: 1.337678074836731
recon_loss: 0.027462810277938843, dist_loss: 0.3251173794269562
recon_loss: 0.027463236823678017, dist_loss: 0.3217944800853729
recon_loss: 0.027463752776384354, dist_loss: 0.4770073890686035
recon_loss: 0.0274643674492836, dist_loss: 0.9256317019462585
recon_loss: 0.027464203536510468, dist_loss: 0.6320117712020874
recon_loss: 0.02746453508734703, dist_loss: 0.7308095097541809
recon_loss: 0.02746494673192501, dist_loss: 0.4877842664718628
recon_loss: 0.027464235201478004, dist_loss: 0.29447802901268005
recon_loss: 0.027464265003800392, dist_loss: 0.45575621724128723
recon_loss: 0.02746410481631756, dist_loss: 0.9309636354446411
recon_loss: 0.027462782338261604, dist_loss: 0.8493388891220093
recon_loss: 0.027462514117360115, dist_loss: 0.45638638734817505
recon_loss: 0.027460919693112373, dist_loss: 0.5075759887695312
recon_loss: 0.027460845187306404, dist_loss: 0.6197952032089233
recon_loss: 0.027460109442472458, dist_loss: 0.4427533745765686
recon_loss: 0.02745986357331276, dist_loss: 0.37046217918395996
Pre-training Epoch 103:  39%|███▉      | 144/367 [00:00<00:01, 176.53it/s]Pre-training Epoch 103:  44%|████▍     | 162/367 [00:00<00:01, 176.98it/s]Pre-training Epoch 103:  49%|████▉     | 180/367 [00:01<00:01, 173.74it/s]Pre-training Epoch 103:  54%|█████▍    | 198/367 [00:01<00:00, 170.73it/s]Pre-training Epoch 103:  59%|█████▉    | 216/367 [00:01<00:00, 172.81it/s]Pre-training Epoch 103:  64%|██████▍   | 234/367 [00:01<00:00, 172.73it/s]Pre-training Epoch 103:  69%|██████▊   | 252/367 [00:01<00:00, 166.40it/s]recon_loss: 0.027459818869829178, dist_loss: 0.46011409163475037
recon_loss: 0.027459081262350082, dist_loss: 0.5593297481536865
recon_loss: 0.02745930291712284, dist_loss: 1.0031901597976685
recon_loss: 0.02745880000293255, dist_loss: 0.46818897128105164
recon_loss: 0.027459489181637764, dist_loss: 0.43085721135139465
recon_loss: 0.027459487318992615, dist_loss: 0.9096713066101074
recon_loss: 0.027459463104605675, dist_loss: 0.5442675948143005
recon_loss: 0.02745951898396015, dist_loss: 0.6564323902130127
recon_loss: 0.027460500597953796, dist_loss: 0.4472407102584839
recon_loss: 0.02746088244020939, dist_loss: 0.7859747409820557
recon_loss: 0.02746126614511013, dist_loss: 0.6559215784072876
recon_loss: 0.0274606104940176, dist_loss: 0.4789075255393982
recon_loss: 0.02746012806892395, dist_loss: 0.5476581454277039
recon_loss: 0.027459759265184402, dist_loss: 1.1930243968963623
recon_loss: 0.0274592787027359, dist_loss: 0.6278169751167297
recon_loss: 0.02745957486331463, dist_loss: 0.5473629236221313
recon_loss: 0.0274595208466053, dist_loss: 0.9122706651687622
recon_loss: 0.02745976857841015, dist_loss: 0.6031337380409241
recon_loss: 0.02745966799557209, dist_loss: 0.4321618676185608
recon_loss: 0.02745932713150978, dist_loss: 0.882209062576294
recon_loss: 0.027458392083644867, dist_loss: 0.8299186825752258
recon_loss: 0.02745867520570755, dist_loss: 0.9543429613113403
recon_loss: 0.027458393946290016, dist_loss: 0.402061402797699
recon_loss: 0.02745969034731388, dist_loss: 0.564633846282959
recon_loss: 0.027460744604468346, dist_loss: 0.6284924745559692
recon_loss: 0.027462847530841827, dist_loss: 0.5348764657974243
recon_loss: 0.027463844045996666, dist_loss: 0.9590588808059692
recon_loss: 0.027463963255286217, dist_loss: 0.4365920424461365
recon_loss: 0.027463247999548912, dist_loss: 0.5630772113800049
recon_loss: 0.027462271973490715, dist_loss: 0.47382432222366333
recon_loss: 0.02746175415813923, dist_loss: 0.44384169578552246
recon_loss: 0.027461279183626175, dist_loss: 0.535359263420105
recon_loss: 0.02746163122355938, dist_loss: 0.7914423942565918
recon_loss: 0.027460977435112, dist_loss: 0.32481953501701355
recon_loss: 0.027460601180791855, dist_loss: 0.9946213364601135
recon_loss: 0.027459852397441864, dist_loss: 0.6345639228820801
recon_loss: 0.02746010012924671, dist_loss: 0.6409531235694885
recon_loss: 0.02746018022298813, dist_loss: 0.3491194248199463
recon_loss: 0.02746003307402134, dist_loss: 0.26649555563926697
recon_loss: 0.027460290119051933, dist_loss: 0.437325656414032
recon_loss: 0.027460286393761635, dist_loss: 0.6554162502288818
recon_loss: 0.027461014688014984, dist_loss: 0.6956049203872681
recon_loss: 0.027460254728794098, dist_loss: 0.4815201163291931
recon_loss: 0.02746010012924671, dist_loss: 0.7366598844528198
recon_loss: 0.027459464967250824, dist_loss: 0.6062175035476685
recon_loss: 0.02745867148041725, dist_loss: 0.8214828968048096
recon_loss: 0.027458712458610535, dist_loss: 0.9171552062034607
recon_loss: 0.02745865285396576, dist_loss: 0.3510993421077728
recon_loss: 0.02745923586189747, dist_loss: 0.6343262791633606
recon_loss: 0.027458908036351204, dist_loss: 0.7125289440155029
recon_loss: 0.027459638193249702, dist_loss: 0.45046740770339966
recon_loss: 0.027460146695375443, dist_loss: 0.5347497463226318
recon_loss: 0.02746010385453701, dist_loss: 0.6153479814529419
recon_loss: 0.027459634467959404, dist_loss: 1.014127492904663
recon_loss: 0.027459969744086266, dist_loss: 0.5172286629676819
recon_loss: 0.027460793033242226, dist_loss: 0.5254456400871277
recon_loss: 0.027462273836135864, dist_loss: 0.8351820111274719
recon_loss: 0.027462389320135117, dist_loss: 0.9514725804328918
recon_loss: 0.027462188154459, dist_loss: 0.5513479709625244
recon_loss: 0.02746242843568325, dist_loss: 1.1671867370605469
recon_loss: 0.027461260557174683, dist_loss: 0.29090216755867004
recon_loss: 0.02746083028614521, dist_loss: 0.8274065256118774
recon_loss: 0.027459735050797462, dist_loss: 0.6994113922119141
recon_loss: 0.027460455894470215, dist_loss: 1.2959415912628174
recon_loss: 0.027460793033242226, dist_loss: 0.6852257251739502
recon_loss: 0.027460984885692596, dist_loss: 0.5137540698051453
recon_loss: 0.02746056206524372, dist_loss: 0.6606239080429077
recon_loss: 0.027459651231765747, dist_loss: 0.30997234582901
recon_loss: 0.02746046520769596, dist_loss: 0.915136456489563
recon_loss: 0.02745964191854, dist_loss: 0.555078387260437
recon_loss: 0.027459928765892982, dist_loss: 0.7545298933982849
recon_loss: 0.027458740398287773, dist_loss: 0.6045782566070557
recon_loss: 0.027458876371383667, dist_loss: 0.5190702080726624
recon_loss: 0.027458881959319115, dist_loss: 0.8919227123260498
recon_loss: 0.027458511292934418, dist_loss: 0.4152366816997528
recon_loss: 0.02745775692164898, dist_loss: 0.7710396647453308
recon_loss: 0.027457745745778084, dist_loss: 0.7235386967658997
recon_loss: 0.027458099648356438, dist_loss: 0.4740275740623474
recon_loss: 0.027458541095256805, dist_loss: 0.8595622777938843
recon_loss: 0.02745855413377285, dist_loss: 0.5486582517623901
recon_loss: 0.027458250522613525, dist_loss: 0.49815160036087036
recon_loss: 0.027458643540740013, dist_loss: 0.5888131856918335
recon_loss: 0.027459489181637764, dist_loss: 0.9260549545288086
recon_loss: 0.02746012806892395, dist_loss: 0.5769296288490295
recon_loss: 0.02745973691344261, dist_loss: 0.6699810028076172
recon_loss: 0.02745877020061016, dist_loss: 0.5213119387626648
recon_loss: 0.027458885684609413, dist_loss: 0.4817599058151245
recon_loss: 0.02745886892080307, dist_loss: 0.639868438243866
recon_loss: 0.02745855040848255, dist_loss: 0.7661887407302856
recon_loss: 0.02745809778571129, dist_loss: 0.9566937685012817
recon_loss: 0.027457287535071373, dist_loss: 0.4967174530029297
recon_loss: 0.027456553652882576, dist_loss: 0.5037802457809448
recon_loss: 0.027456246316432953, dist_loss: 0.607241690158844
recon_loss: 0.027456656098365784, dist_loss: 0.34505051374435425
recon_loss: 0.02745722606778145, dist_loss: 0.599136471748352
recon_loss: 0.027458205819129944, dist_loss: 0.7256499528884888
recon_loss: 0.027459165081381798, dist_loss: 0.9674559235572815
recon_loss: 0.027461154386401176, dist_loss: 0.4953871965408325
recon_loss: 0.02746213600039482, dist_loss: 0.3453042209148407
recon_loss: 0.027463018894195557, dist_loss: 0.6218465566635132
recon_loss: 0.027463190257549286, dist_loss: 1.1914088726043701
recon_loss: 0.027461713179945946, dist_loss: 0.5705488920211792
recon_loss: 0.027460690587759018, dist_loss: 0.6297417879104614
recon_loss: 0.02745969593524933, dist_loss: 0.8611236810684204
recon_loss: 0.0274586770683527, dist_loss: 0.5633893013000488
recon_loss: 0.02745787613093853, dist_loss: 0.7191230654716492
recon_loss: 0.027457555755972862, dist_loss: 0.5406848192214966
recon_loss: 0.027457118034362793, dist_loss: 0.35857856273651123
recon_loss: 0.02745683491230011, dist_loss: 0.5036345720291138
recon_loss: 0.027457160875201225, dist_loss: 0.6477293968200684
recon_loss: 0.02745727449655533, dist_loss: 0.475932240486145
recon_loss: 0.02745809033513069, dist_loss: 0.7574261426925659
recon_loss: 0.02745780348777771, dist_loss: 0.7554745674133301
recon_loss: 0.027457788586616516, dist_loss: 0.5712265968322754
recon_loss: 0.02745731547474861, dist_loss: 0.8931775093078613
recon_loss: 0.027456821873784065, dist_loss: 0.579497754573822
recon_loss: 0.0274561308324337, dist_loss: 0.6415969133377075
recon_loss: 0.027455108240246773, dist_loss: 0.5932045578956604
recon_loss: 0.02745465189218521, dist_loss: 1.1099815368652344
recon_loss: 0.027454013004899025, dist_loss: 0.40843337774276733
recon_loss: 0.027454299852252007, dist_loss: 0.5286341905593872
recon_loss: 0.027454189956188202, dist_loss: 0.644477128982544
recon_loss: 0.027454599738121033, dist_loss: 0.3373640775680542
recon_loss: 0.027454882860183716, dist_loss: 0.5575451254844666
recon_loss: 0.02745528519153595, dist_loss: 0.5887484550476074
recon_loss: 0.02745574526488781, dist_loss: 0.939628541469574
recon_loss: 0.027455806732177734, dist_loss: 0.7150858640670776
recon_loss: 0.02745605632662773, dist_loss: 0.4704015254974365
recon_loss: 0.027455145493149757, dist_loss: 1.0601625442504883
Pre-training Epoch 103:  73%|███████▎  | 269/367 [00:01<00:00, 161.11it/s]Pre-training Epoch 103:  78%|███████▊  | 286/367 [00:01<00:00, 159.80it/s]Pre-training Epoch 103:  83%|████████▎ | 303/367 [00:01<00:00, 157.94it/s]Pre-training Epoch 103:  87%|████████▋ | 319/367 [00:01<00:00, 157.71it/s]Pre-training Epoch 103:  91%|█████████▏| 335/367 [00:02<00:00, 155.66it/s]Pre-training Epoch 103:  96%|█████████▌| 353/367 [00:02<00:00, 161.43it/s]Pre-training Epoch 103: 100%|██████████| 367/367 [00:02<00:00, 166.60it/s]
recon_loss: 0.027453811839222908, dist_loss: 0.840697169303894
recon_loss: 0.027454059571027756, dist_loss: 0.6356059312820435
recon_loss: 0.027452930808067322, dist_loss: 0.7835630178451538
recon_loss: 0.02745392918586731, dist_loss: 0.743708074092865
recon_loss: 0.027453118935227394, dist_loss: 0.7047445774078369
recon_loss: 0.027454227209091187, dist_loss: 0.4260459542274475
recon_loss: 0.027455052360892296, dist_loss: 0.6502255797386169
recon_loss: 0.027455249801278114, dist_loss: 1.1279149055480957
recon_loss: 0.02745681442320347, dist_loss: 0.376661479473114
recon_loss: 0.02745579369366169, dist_loss: 0.5522755980491638
recon_loss: 0.02745671570301056, dist_loss: 0.38113877177238464
recon_loss: 0.02745606191456318, dist_loss: 0.6742539405822754
recon_loss: 0.027454614639282227, dist_loss: 0.6257188320159912
recon_loss: 0.027454817667603493, dist_loss: 0.26845312118530273
recon_loss: 0.027453195303678513, dist_loss: 0.5041489601135254
recon_loss: 0.027453798800706863, dist_loss: 0.6059361696243286
recon_loss: 0.027452189475297928, dist_loss: 0.43719482421875
recon_loss: 0.02745247632265091, dist_loss: 1.0774312019348145
recon_loss: 0.02745215781033039, dist_loss: 0.46205371618270874
recon_loss: 0.02745192125439644, dist_loss: 0.7933179140090942
recon_loss: 0.02745250053703785, dist_loss: 0.5321807861328125
recon_loss: 0.027451885864138603, dist_loss: 0.7627122402191162
recon_loss: 0.027452101930975914, dist_loss: 0.5280518531799316
recon_loss: 0.02745266631245613, dist_loss: 1.026964783668518
recon_loss: 0.027453377842903137, dist_loss: 0.5195805430412292
recon_loss: 0.027454020455479622, dist_loss: 0.8972934484481812
recon_loss: 0.027454478666186333, dist_loss: 0.5070385336875916
recon_loss: 0.027454765513539314, dist_loss: 0.45262137055397034
recon_loss: 0.02745482139289379, dist_loss: 0.5555076599121094
recon_loss: 0.0274545606225729, dist_loss: 0.823487401008606
recon_loss: 0.027453962713479996, dist_loss: 0.6536698341369629
recon_loss: 0.0274534672498703, dist_loss: 0.7512059211730957
recon_loss: 0.027453094720840454, dist_loss: 0.5385627746582031
recon_loss: 0.02745172753930092, dist_loss: 0.8861700296401978
recon_loss: 0.027451805770397186, dist_loss: 0.39727020263671875
recon_loss: 0.027451906353235245, dist_loss: 0.7485048174858093
recon_loss: 0.02745111845433712, dist_loss: 0.950570821762085
recon_loss: 0.02745157852768898, dist_loss: 0.3649342656135559
recon_loss: 0.027450744062662125, dist_loss: 0.7149195075035095
recon_loss: 0.027451377362012863, dist_loss: 0.49444881081581116
recon_loss: 0.027450695633888245, dist_loss: 0.849125862121582
recon_loss: 0.02745063602924347, dist_loss: 0.5442382097244263
recon_loss: 0.02745087817311287, dist_loss: 0.4303320646286011
recon_loss: 0.027450457215309143, dist_loss: 0.6598461866378784
recon_loss: 0.027450134977698326, dist_loss: 0.9023706912994385
recon_loss: 0.027450166642665863, dist_loss: 0.6390103101730347
recon_loss: 0.02744962088763714, dist_loss: 0.5745068788528442
recon_loss: 0.02744957059621811, dist_loss: 0.5514956712722778
recon_loss: 0.027449270710349083, dist_loss: 0.35330337285995483
recon_loss: 0.027449138462543488, dist_loss: 0.5462522506713867
recon_loss: 0.027448926120996475, dist_loss: 0.8247643709182739
recon_loss: 0.027448881417512894, dist_loss: 0.5880467295646667
recon_loss: 0.02744893915951252, dist_loss: 0.8446135520935059
recon_loss: 0.027448318898677826, dist_loss: 0.5480265617370605
recon_loss: 0.02744840644299984, dist_loss: 0.5672838687896729
recon_loss: 0.027448290959000587, dist_loss: 0.42405426502227783
recon_loss: 0.02744811400771141, dist_loss: 0.6672574281692505
recon_loss: 0.027448272332549095, dist_loss: 0.5246922373771667
recon_loss: 0.02744823880493641, dist_loss: 0.507502555847168
recon_loss: 0.027447912842035294, dist_loss: 0.7141340970993042
recon_loss: 0.027447963133454323, dist_loss: 0.5132089257240295
recon_loss: 0.027447955682873726, dist_loss: 0.7799886465072632
recon_loss: 0.027448011562228203, dist_loss: 0.6129039525985718
recon_loss: 0.027447916567325592, dist_loss: 0.793006420135498
recon_loss: 0.027448048815131187, dist_loss: 0.5069236755371094
recon_loss: 0.027448216453194618, dist_loss: 0.4322611689567566
recon_loss: 0.02744929865002632, dist_loss: 0.544393002986908
recon_loss: 0.027449006214737892, dist_loss: 0.7577997446060181
recon_loss: 0.02745017036795616, dist_loss: 0.7121163010597229
recon_loss: 0.027449030429124832, dist_loss: 0.541791558265686
recon_loss: 0.02745009958744049, dist_loss: 0.3597303032875061
recon_loss: 0.027449117973446846, dist_loss: 0.49458831548690796
recon_loss: 0.027449628338217735, dist_loss: 0.5284843444824219
recon_loss: 0.027449866756796837, dist_loss: 1.3356189727783203
recon_loss: 0.027449486777186394, dist_loss: 0.5340598821640015
recon_loss: 0.027449237182736397, dist_loss: 0.41298291087150574
recon_loss: 0.027448827400803566, dist_loss: 0.9919725656509399
recon_loss: 0.02744929865002632, dist_loss: 0.4970813989639282
recon_loss: 0.02744866907596588, dist_loss: 0.3238412141799927
recon_loss: 0.027449022978544235, dist_loss: 0.6947241425514221
recon_loss: 0.02744949609041214, dist_loss: 0.6642025709152222
recon_loss: 0.027449285611510277, dist_loss: 0.6604242324829102
recon_loss: 0.027449794113636017, dist_loss: 0.4466806650161743
recon_loss: 0.02744852751493454, dist_loss: 1.0585384368896484
recon_loss: 0.027448683977127075, dist_loss: 0.8063592910766602
recon_loss: 0.027448683977127075, dist_loss: 0.9092780351638794
recon_loss: 0.027448264881968498, dist_loss: 0.7366436719894409
recon_loss: 0.0274491123855114, dist_loss: 1.0473333597183228
recon_loss: 0.02744986303150654, dist_loss: 0.7927004098892212
recon_loss: 0.027451064437627792, dist_loss: 0.7086122632026672
recon_loss: 0.027451934292912483, dist_loss: 0.7662730813026428
recon_loss: 0.027450667694211006, dist_loss: 0.5801411271095276
recon_loss: 0.027450580149888992, dist_loss: 0.5078131556510925
recon_loss: 0.02744969166815281, dist_loss: 0.6799116730690002
recon_loss: 0.027449481189250946, dist_loss: 0.6430153846740723
recon_loss: 0.02744912914931774, dist_loss: 0.6053308248519897
recon_loss: 0.027449360117316246, dist_loss: 0.9277366399765015
recon_loss: 0.02744959481060505, dist_loss: 0.7134048938751221
recon_loss: 0.027451127767562866, dist_loss: 1.0273268222808838
recon_loss: 0.02745089866220951, dist_loss: 0.30099111795425415
recon_loss: 0.02745215781033039, dist_loss: 0.8803271055221558
recon_loss: 0.027453046292066574, dist_loss: 0.5681630373001099
recon_loss: 0.027455346658825874, dist_loss: 0.34342172741889954
recon_loss: 0.027457429096102715, dist_loss: 0.5198672413825989
recon_loss: 0.02745838463306427, dist_loss: 0.4320552349090576
recon_loss: 0.027460847049951553, dist_loss: 0.7578985095024109
recon_loss: 0.027460699900984764, dist_loss: 0.4254889488220215
recon_loss: 0.02746119722723961, dist_loss: 0.7262386083602905
recon_loss: 0.027458999305963516, dist_loss: 0.6039361953735352
recon_loss: 0.027457913383841515, dist_loss: 0.5409883260726929
Pre-training Epoch 104:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 104:   4%|▍         | 16/367 [00:00<00:02, 150.89it/s]Pre-training Epoch 104:   9%|▊         | 32/367 [00:00<00:02, 153.74it/s]Pre-training Epoch 104:  13%|█▎        | 48/367 [00:00<00:02, 155.52it/s]Pre-training Epoch 104:  17%|█▋        | 64/367 [00:00<00:01, 156.43it/s]Pre-training Epoch 104:  22%|██▏       | 80/367 [00:00<00:01, 152.53it/s]Pre-training Epoch 104:  26%|██▌       | 96/367 [00:00<00:01, 151.13it/s]Pre-training Epoch 104:  31%|███       | 112/367 [00:00<00:01, 153.59it/s]Pre-training Epoch 104:  35%|███▍      | 128/367 [00:00<00:01, 152.49it/s]recon_loss: 0.027456704527139664, dist_loss: 0.7330856919288635
recon_loss: 0.027455797418951988, dist_loss: 0.5913881659507751
recon_loss: 0.027454186230897903, dist_loss: 0.47123268246650696
recon_loss: 0.027454199269413948, dist_loss: 0.4292643070220947
recon_loss: 0.027453234419226646, dist_loss: 0.8046438097953796
recon_loss: 0.027453893795609474, dist_loss: 0.29214271903038025
recon_loss: 0.027455037459731102, dist_loss: 0.6143807172775269
recon_loss: 0.027455104514956474, dist_loss: 0.7468540072441101
recon_loss: 0.02745610661804676, dist_loss: 0.5055640935897827
recon_loss: 0.027455594390630722, dist_loss: 0.6946470737457275
recon_loss: 0.027456233277916908, dist_loss: 0.5949103236198425
recon_loss: 0.02745695225894451, dist_loss: 0.34786996245384216
recon_loss: 0.027457937598228455, dist_loss: 1.06862473487854
recon_loss: 0.027458159253001213, dist_loss: 0.5994784832000732
recon_loss: 0.02745892107486725, dist_loss: 0.6626338958740234
recon_loss: 0.02745913155376911, dist_loss: 0.9079408049583435
recon_loss: 0.0274587981402874, dist_loss: 0.4322754144668579
recon_loss: 0.027457674965262413, dist_loss: 0.5747955441474915
recon_loss: 0.027456600219011307, dist_loss: 0.543636679649353
recon_loss: 0.027455594390630722, dist_loss: 0.39778777956962585
recon_loss: 0.027455538511276245, dist_loss: 0.5249656438827515
recon_loss: 0.027454236522316933, dist_loss: 0.6022840738296509
recon_loss: 0.02745320275425911, dist_loss: 0.5505013465881348
recon_loss: 0.027452044188976288, dist_loss: 1.4208788871765137
recon_loss: 0.02745012566447258, dist_loss: 0.3329524099826813
recon_loss: 0.02744992822408676, dist_loss: 0.44475018978118896
recon_loss: 0.027448441833257675, dist_loss: 0.9952430725097656
recon_loss: 0.027447834610939026, dist_loss: 0.5661195516586304
recon_loss: 0.027447516098618507, dist_loss: 0.6760082244873047
recon_loss: 0.027447089552879333, dist_loss: 1.2415440082550049
recon_loss: 0.02744763158261776, dist_loss: 0.9343735575675964
recon_loss: 0.02744719758629799, dist_loss: 0.8766653537750244
recon_loss: 0.027446990832686424, dist_loss: 0.7076875567436218
recon_loss: 0.027447054162621498, dist_loss: 0.4158722758293152
recon_loss: 0.027446528896689415, dist_loss: 0.42781949043273926
recon_loss: 0.027446726337075233, dist_loss: 0.4947391748428345
recon_loss: 0.02744569629430771, dist_loss: 0.5946298837661743
recon_loss: 0.027446391060948372, dist_loss: 0.5569652318954468
recon_loss: 0.027445347979664803, dist_loss: 0.5801749229431152
recon_loss: 0.02744653820991516, dist_loss: 0.8908740878105164
recon_loss: 0.027444953098893166, dist_loss: 0.528741717338562
recon_loss: 0.027445686981081963, dist_loss: 0.35910701751708984
recon_loss: 0.027445876970887184, dist_loss: 0.8658090233802795
recon_loss: 0.027445022016763687, dist_loss: 0.5585162043571472
recon_loss: 0.027446653693914413, dist_loss: 0.661937952041626
recon_loss: 0.027445778250694275, dist_loss: 0.3613891005516052
recon_loss: 0.027446405962109566, dist_loss: 0.4712352752685547
recon_loss: 0.027446774765849113, dist_loss: 0.43484848737716675
recon_loss: 0.027446847409009933, dist_loss: 0.8249009251594543
recon_loss: 0.02744816057384014, dist_loss: 0.6099928021430969
recon_loss: 0.027447668835520744, dist_loss: 0.5420637130737305
recon_loss: 0.02744850516319275, dist_loss: 0.7272217273712158
recon_loss: 0.02744671329855919, dist_loss: 0.9721084833145142
recon_loss: 0.027446571737527847, dist_loss: 0.7205104827880859
recon_loss: 0.027445143088698387, dist_loss: 0.7127895355224609
recon_loss: 0.027444668114185333, dist_loss: 0.6476892232894897
recon_loss: 0.027444688603281975, dist_loss: 0.7719415426254272
recon_loss: 0.027444621548056602, dist_loss: 0.42508330941200256
recon_loss: 0.027446232736110687, dist_loss: 0.5227420926094055
recon_loss: 0.027446558699011803, dist_loss: 0.5213301777839661
recon_loss: 0.027447683736681938, dist_loss: 0.7273247241973877
recon_loss: 0.02744746208190918, dist_loss: 0.5621458888053894
recon_loss: 0.027447959408164024, dist_loss: 0.44194722175598145
recon_loss: 0.027447625994682312, dist_loss: 0.880885660648346
recon_loss: 0.027448007836937904, dist_loss: 0.48560765385627747
recon_loss: 0.027448173612356186, dist_loss: 0.8040522336959839
recon_loss: 0.02744782343506813, dist_loss: 0.6108723878860474
recon_loss: 0.027447810396552086, dist_loss: 0.5347528457641602
recon_loss: 0.02744794450700283, dist_loss: 0.9041674137115479
recon_loss: 0.027447866275906563, dist_loss: 0.4958939552307129
recon_loss: 0.027447814121842384, dist_loss: 0.8323332071304321
recon_loss: 0.027447238564491272, dist_loss: 0.5193387269973755
recon_loss: 0.02744727022945881, dist_loss: 0.5607522130012512
recon_loss: 0.027446946129202843, dist_loss: 0.6292213201522827
recon_loss: 0.027446256950497627, dist_loss: 0.5258098840713501
recon_loss: 0.02744593285024166, dist_loss: 0.6998652219772339
recon_loss: 0.027445195242762566, dist_loss: 0.4599582552909851
recon_loss: 0.027445321902632713, dist_loss: 0.6368001699447632
recon_loss: 0.02744455076754093, dist_loss: 0.48108023405075073
recon_loss: 0.027444584295153618, dist_loss: 0.5940388441085815
recon_loss: 0.02744407393038273, dist_loss: 1.0266157388687134
recon_loss: 0.02744382992386818, dist_loss: 0.647993803024292
recon_loss: 0.027443986386060715, dist_loss: 0.8339403867721558
recon_loss: 0.027444053441286087, dist_loss: 1.026166558265686
recon_loss: 0.027444027364253998, dist_loss: 0.6683769226074219
recon_loss: 0.027444206178188324, dist_loss: 0.5881794691085815
recon_loss: 0.027443865314126015, dist_loss: 0.8192938566207886
recon_loss: 0.027443908154964447, dist_loss: 0.9850969910621643
recon_loss: 0.027444053441286087, dist_loss: 0.6344718933105469
recon_loss: 0.02744399942457676, dist_loss: 0.5589407682418823
recon_loss: 0.027444005012512207, dist_loss: 0.7882657051086426
recon_loss: 0.027443723753094673, dist_loss: 1.2807726860046387
recon_loss: 0.02744337171316147, dist_loss: 0.5582298040390015
recon_loss: 0.027443284168839455, dist_loss: 0.5759140253067017
recon_loss: 0.027443114668130875, dist_loss: 0.6086699962615967
recon_loss: 0.02744283527135849, dist_loss: 0.5837791562080383
recon_loss: 0.027442768216133118, dist_loss: 0.48280850052833557
recon_loss: 0.02744264341890812, dist_loss: 0.7287894487380981
recon_loss: 0.02744259685277939, dist_loss: 0.7922011613845825
recon_loss: 0.02744249626994133, dist_loss: 0.47170937061309814
recon_loss: 0.02744271606206894, dist_loss: 0.5000393390655518
recon_loss: 0.02744273655116558, dist_loss: 0.6099267601966858
recon_loss: 0.027442555874586105, dist_loss: 0.9703200459480286
recon_loss: 0.02744239754974842, dist_loss: 0.7560202479362488
recon_loss: 0.027442101389169693, dist_loss: 0.6686179041862488
recon_loss: 0.027442149817943573, dist_loss: 0.451730340719223
recon_loss: 0.027441684156656265, dist_loss: 0.8943598866462708
recon_loss: 0.027441954240202904, dist_loss: 0.6602702140808105
recon_loss: 0.02744254842400551, dist_loss: 0.8242616653442383
recon_loss: 0.027443870902061462, dist_loss: 1.1687932014465332
recon_loss: 0.027443911880254745, dist_loss: 0.46853774785995483
recon_loss: 0.02744455449283123, dist_loss: 0.4067434072494507
recon_loss: 0.027444656938314438, dist_loss: 0.4019699990749359
recon_loss: 0.027444401755928993, dist_loss: 0.9749202132225037
recon_loss: 0.02744423970580101, dist_loss: 0.32835936546325684
recon_loss: 0.027443500235676765, dist_loss: 0.6757614612579346
recon_loss: 0.027442721650004387, dist_loss: 0.8863516449928284
recon_loss: 0.027442030608654022, dist_loss: 0.7661416530609131
recon_loss: 0.02744143269956112, dist_loss: 0.6743240356445312
recon_loss: 0.027441948652267456, dist_loss: 0.5256417393684387
recon_loss: 0.02744212932884693, dist_loss: 0.880745530128479
recon_loss: 0.027442824095487595, dist_loss: 0.7798757553100586
recon_loss: 0.027442656457424164, dist_loss: 1.1170732975006104
recon_loss: 0.027442878112196922, dist_loss: 0.7588803768157959
recon_loss: 0.02744288370013237, dist_loss: 0.513283371925354
recon_loss: 0.027442684397101402, dist_loss: 0.7447117567062378
recon_loss: 0.02744286134839058, dist_loss: 0.6599502563476562
recon_loss: 0.02744237706065178, dist_loss: 0.5634914040565491
Pre-training Epoch 104:  39%|███▉      | 144/367 [00:00<00:01, 151.19it/s]Pre-training Epoch 104:  44%|████▎     | 160/367 [00:01<00:01, 151.84it/s]Pre-training Epoch 104:  48%|████▊     | 176/367 [00:01<00:01, 153.32it/s]Pre-training Epoch 104:  52%|█████▏    | 192/367 [00:01<00:01, 153.95it/s]Pre-training Epoch 104:  57%|█████▋    | 208/367 [00:01<00:01, 155.36it/s]Pre-training Epoch 104:  61%|██████    | 224/367 [00:01<00:00, 155.04it/s]Pre-training Epoch 104:  65%|██████▌   | 240/367 [00:01<00:00, 152.40it/s]Pre-training Epoch 104:  70%|██████▉   | 256/367 [00:01<00:00, 151.22it/s]recon_loss: 0.027442123740911484, dist_loss: 0.47974729537963867
recon_loss: 0.02744179405272007, dist_loss: 0.671983003616333
recon_loss: 0.027441084384918213, dist_loss: 1.0182771682739258
recon_loss: 0.027441252022981644, dist_loss: 0.7537692785263062
recon_loss: 0.027440715581178665, dist_loss: 0.4149537682533264
recon_loss: 0.027441062033176422, dist_loss: 0.9233978986740112
recon_loss: 0.02744087018072605, dist_loss: 0.5905195474624634
recon_loss: 0.02744114212691784, dist_loss: 0.6400348544120789
recon_loss: 0.02744092047214508, dist_loss: 0.9729245901107788
recon_loss: 0.027441171929240227, dist_loss: 0.836310863494873
recon_loss: 0.02744164504110813, dist_loss: 0.6151654720306396
recon_loss: 0.027441080659627914, dist_loss: 0.8453048467636108
recon_loss: 0.02744199149310589, dist_loss: 0.6944395303726196
recon_loss: 0.02744138427078724, dist_loss: 0.3827913999557495
recon_loss: 0.02744169719517231, dist_loss: 0.9825984239578247
recon_loss: 0.02744092233479023, dist_loss: 0.5187020897865295
recon_loss: 0.027441052719950676, dist_loss: 0.57598477602005
recon_loss: 0.027440231293439865, dist_loss: 0.7443705797195435
recon_loss: 0.02744113840162754, dist_loss: 0.5517226457595825
recon_loss: 0.027440335601568222, dist_loss: 1.0420254468917847
recon_loss: 0.02744140662252903, dist_loss: 0.6968925595283508
recon_loss: 0.02744179777801037, dist_loss: 0.3851442337036133
recon_loss: 0.027443155646324158, dist_loss: 0.48547956347465515
recon_loss: 0.027443600818514824, dist_loss: 0.45862874388694763
recon_loss: 0.02744491770863533, dist_loss: 0.7142428159713745
recon_loss: 0.027444588020443916, dist_loss: 0.46478360891342163
recon_loss: 0.027444856241345406, dist_loss: 0.45288076996803284
recon_loss: 0.02744448371231556, dist_loss: 0.8400896787643433
recon_loss: 0.027444034814834595, dist_loss: 0.49175524711608887
recon_loss: 0.02744424343109131, dist_loss: 0.757854163646698
recon_loss: 0.027443377301096916, dist_loss: 0.26039284467697144
recon_loss: 0.027442708611488342, dist_loss: 0.32463622093200684
recon_loss: 0.02744193747639656, dist_loss: 0.36442720890045166
recon_loss: 0.0274409968405962, dist_loss: 0.5745419263839722
recon_loss: 0.02744048647582531, dist_loss: 0.5510869026184082
recon_loss: 0.027439868077635765, dist_loss: 0.7058468461036682
recon_loss: 0.027440957725048065, dist_loss: 0.7850168347358704
recon_loss: 0.02744189277291298, dist_loss: 0.48998865485191345
recon_loss: 0.02744409255683422, dist_loss: 1.3269894123077393
recon_loss: 0.027446456253528595, dist_loss: 0.4706617295742035
recon_loss: 0.027448443695902824, dist_loss: 0.28629422187805176
recon_loss: 0.02745174989104271, dist_loss: 0.9893404245376587
recon_loss: 0.02745344489812851, dist_loss: 0.785466194152832
recon_loss: 0.027450812980532646, dist_loss: 0.42968499660491943
recon_loss: 0.027449630200862885, dist_loss: 0.45813173055648804
recon_loss: 0.027448851615190506, dist_loss: 0.5597898364067078
recon_loss: 0.02744767628610134, dist_loss: 0.598419189453125
recon_loss: 0.02744881622493267, dist_loss: 0.570769190788269
recon_loss: 0.0274459607899189, dist_loss: 0.7657523155212402
recon_loss: 0.027446512132883072, dist_loss: 0.6436862945556641
recon_loss: 0.027445411309599876, dist_loss: 0.9358567595481873
recon_loss: 0.02744550071656704, dist_loss: 0.7522149085998535
recon_loss: 0.02744499407708645, dist_loss: 0.3005039691925049
recon_loss: 0.02744455635547638, dist_loss: 0.5121361017227173
recon_loss: 0.027444681152701378, dist_loss: 0.5448423027992249
recon_loss: 0.027443651109933853, dist_loss: 0.8898010849952698
recon_loss: 0.027443140745162964, dist_loss: 0.456988662481308
recon_loss: 0.027441833168268204, dist_loss: 0.531424880027771
recon_loss: 0.02744104154407978, dist_loss: 0.6003246307373047
recon_loss: 0.02743997424840927, dist_loss: 0.4376547932624817
recon_loss: 0.027439292520284653, dist_loss: 0.5370489358901978
recon_loss: 0.027439100667834282, dist_loss: 0.9610182046890259
recon_loss: 0.027438461780548096, dist_loss: 0.5453423857688904
recon_loss: 0.02743872068822384, dist_loss: 0.8049752712249756
recon_loss: 0.027438318356871605, dist_loss: 0.34723910689353943
recon_loss: 0.02743837609887123, dist_loss: 0.43861252069473267
recon_loss: 0.027438413351774216, dist_loss: 0.8000710010528564
recon_loss: 0.027437496930360794, dist_loss: 0.4618128836154938
recon_loss: 0.027437739074230194, dist_loss: 1.0941102504730225
recon_loss: 0.027437232434749603, dist_loss: 0.799148440361023
recon_loss: 0.027437260374426842, dist_loss: 0.4542868733406067
recon_loss: 0.027436699718236923, dist_loss: 0.7148414850234985
recon_loss: 0.027436818927526474, dist_loss: 0.5033595561981201
recon_loss: 0.027436939999461174, dist_loss: 0.7887643575668335
recon_loss: 0.02743667922914028, dist_loss: 0.5503933429718018
recon_loss: 0.02743648737668991, dist_loss: 0.4721187353134155
recon_loss: 0.027436314150691032, dist_loss: 0.6121403574943542
recon_loss: 0.027436388656497, dist_loss: 0.500068187713623
recon_loss: 0.027436265721917152, dist_loss: 0.2864299714565277
recon_loss: 0.02743639051914215, dist_loss: 0.5692049264907837
recon_loss: 0.027435772120952606, dist_loss: 0.5579879879951477
recon_loss: 0.02743632346391678, dist_loss: 0.7323267459869385
recon_loss: 0.027435485273599625, dist_loss: 0.8114908933639526
recon_loss: 0.027436045929789543, dist_loss: 0.40515637397766113
recon_loss: 0.027435939759016037, dist_loss: 0.6739321947097778
recon_loss: 0.027436338365077972, dist_loss: 0.7294920682907104
recon_loss: 0.02743736281991005, dist_loss: 0.8232769966125488
recon_loss: 0.02743702009320259, dist_loss: 0.623482882976532
recon_loss: 0.027438439428806305, dist_loss: 1.0044560432434082
recon_loss: 0.02743948996067047, dist_loss: 0.5734978914260864
recon_loss: 0.027440382167696953, dist_loss: 0.34243443608283997
recon_loss: 0.02744079940021038, dist_loss: 0.6513295769691467
recon_loss: 0.027439380064606667, dist_loss: 1.0087692737579346
recon_loss: 0.02743966318666935, dist_loss: 0.6467452049255371
recon_loss: 0.027437765151262283, dist_loss: 0.7099360823631287
recon_loss: 0.02743767388164997, dist_loss: 0.6274057626724243
recon_loss: 0.027436910197138786, dist_loss: 1.0649383068084717
recon_loss: 0.027435805648565292, dist_loss: 0.5594757795333862
recon_loss: 0.027435800060629845, dist_loss: 0.29798877239227295
recon_loss: 0.02743534743785858, dist_loss: 0.43889620900154114
recon_loss: 0.02743550017476082, dist_loss: 0.9821096658706665
recon_loss: 0.02743505872786045, dist_loss: 0.6667827367782593
recon_loss: 0.027434758841991425, dist_loss: 0.41354554891586304
recon_loss: 0.0274344515055418, dist_loss: 0.9320586919784546
recon_loss: 0.02743418700993061, dist_loss: 0.6525235772132874
recon_loss: 0.02743378095328808, dist_loss: 0.5858972072601318
recon_loss: 0.027433233335614204, dist_loss: 0.685063898563385
recon_loss: 0.02743353880941868, dist_loss: 0.6462867259979248
recon_loss: 0.027433114126324654, dist_loss: 0.4593549966812134
recon_loss: 0.02743307687342167, dist_loss: 0.7304601669311523
recon_loss: 0.027433406561613083, dist_loss: 0.9083951115608215
recon_loss: 0.02743341028690338, dist_loss: 0.4948142170906067
recon_loss: 0.02743362821638584, dist_loss: 0.6090760827064514
recon_loss: 0.02743487060070038, dist_loss: 0.623641848564148
recon_loss: 0.02743404172360897, dist_loss: 0.7267645001411438
recon_loss: 0.027435505762696266, dist_loss: 0.4416651129722595
recon_loss: 0.027436228469014168, dist_loss: 0.46315252780914307
recon_loss: 0.027436289936304092, dist_loss: 0.822587788105011
recon_loss: 0.027436217293143272, dist_loss: 0.7378696799278259
recon_loss: 0.02743604965507984, dist_loss: 0.8282477259635925
recon_loss: 0.027435587719082832, dist_loss: 0.8916957378387451
recon_loss: 0.02743486873805523, dist_loss: 0.805457592010498
recon_loss: 0.02743416838347912, dist_loss: 0.6678453683853149
recon_loss: 0.027433916926383972, dist_loss: 1.4636693000793457
recon_loss: 0.02743418700993061, dist_loss: 0.46062302589416504
recon_loss: 0.027434658259153366, dist_loss: 0.4768350124359131
recon_loss: 0.02743549644947052, dist_loss: 0.37004101276397705
recon_loss: 0.027435606345534325, dist_loss: 0.4917016923427582
Pre-training Epoch 104:  74%|███████▍  | 272/367 [00:01<00:00, 152.44it/s]Pre-training Epoch 104:  78%|███████▊  | 288/367 [00:01<00:00, 150.94it/s]Pre-training Epoch 104:  83%|████████▎ | 304/367 [00:01<00:00, 151.68it/s]Pre-training Epoch 104:  87%|████████▋ | 320/367 [00:02<00:00, 153.26it/s]Pre-training Epoch 104:  92%|█████████▏| 336/367 [00:02<00:00, 154.01it/s]Pre-training Epoch 104:  96%|█████████▌| 352/367 [00:02<00:00, 155.11it/s]Pre-training Epoch 104: 100%|██████████| 367/367 [00:02<00:00, 153.36it/s]
recon_loss: 0.02743592858314514, dist_loss: 0.5554735064506531
recon_loss: 0.027436649426817894, dist_loss: 0.43148350715637207
recon_loss: 0.027437221258878708, dist_loss: 0.8786334991455078
recon_loss: 0.02743668481707573, dist_loss: 0.5289298892021179
recon_loss: 0.027435963973402977, dist_loss: 0.6269946098327637
recon_loss: 0.02743539959192276, dist_loss: 0.6034538149833679
recon_loss: 0.027434470131993294, dist_loss: 0.5797103643417358
recon_loss: 0.027433769777417183, dist_loss: 0.6545345783233643
recon_loss: 0.027434056624770164, dist_loss: 0.3860309422016144
recon_loss: 0.027434682473540306, dist_loss: 0.8602373600006104
recon_loss: 0.02743464708328247, dist_loss: 0.8161367177963257
recon_loss: 0.027434349060058594, dist_loss: 0.4687085449695587
recon_loss: 0.02743414416909218, dist_loss: 0.981843113899231
recon_loss: 0.027434034273028374, dist_loss: 0.31028127670288086
recon_loss: 0.027433566749095917, dist_loss: 0.36632242798805237
recon_loss: 0.027433335781097412, dist_loss: 0.8324358463287354
recon_loss: 0.027433229610323906, dist_loss: 0.6634378433227539
recon_loss: 0.027434196323156357, dist_loss: 0.3423677086830139
recon_loss: 0.027435554191470146, dist_loss: 0.5010973215103149
recon_loss: 0.027436939999461174, dist_loss: 0.7870484590530396
recon_loss: 0.027438495308160782, dist_loss: 0.39018476009368896
recon_loss: 0.02743963524699211, dist_loss: 0.7807036638259888
recon_loss: 0.027440309524536133, dist_loss: 0.7927563786506653
recon_loss: 0.027439750730991364, dist_loss: 0.6126773357391357
recon_loss: 0.02743821032345295, dist_loss: 0.43749433755874634
recon_loss: 0.027437172830104828, dist_loss: 0.6144837141036987
recon_loss: 0.027436600998044014, dist_loss: 0.5233457684516907
recon_loss: 0.02743569388985634, dist_loss: 0.894507646560669
recon_loss: 0.02743547223508358, dist_loss: 0.3732469081878662
recon_loss: 0.02743469551205635, dist_loss: 0.8650957345962524
recon_loss: 0.02743370272219181, dist_loss: 0.5878980159759521
recon_loss: 0.02743353694677353, dist_loss: 0.882909893989563
recon_loss: 0.027432570233941078, dist_loss: 0.5214442014694214
recon_loss: 0.027432657778263092, dist_loss: 0.5672670602798462
recon_loss: 0.027432145550847054, dist_loss: 0.871488630771637
recon_loss: 0.0274319089949131, dist_loss: 0.5217458009719849
recon_loss: 0.027431854978203773, dist_loss: 0.4784930646419525
recon_loss: 0.02743171900510788, dist_loss: 0.7943710088729858
recon_loss: 0.027431566268205643, dist_loss: 0.41056567430496216
recon_loss: 0.027431629598140717, dist_loss: 0.7071403861045837
recon_loss: 0.027431979775428772, dist_loss: 0.851325273513794
recon_loss: 0.027432501316070557, dist_loss: 0.8772633075714111
recon_loss: 0.027432139962911606, dist_loss: 0.42456579208374023
recon_loss: 0.027431748807430267, dist_loss: 0.4936119616031647
recon_loss: 0.027431301772594452, dist_loss: 0.6100126504898071
recon_loss: 0.027431488037109375, dist_loss: 0.6786105036735535
recon_loss: 0.027430668473243713, dist_loss: 0.449360728263855
recon_loss: 0.027431128546595573, dist_loss: 0.4706328511238098
recon_loss: 0.027430541813373566, dist_loss: 0.39833498001098633
recon_loss: 0.027430051937699318, dist_loss: 0.6407790184020996
recon_loss: 0.027430199086666107, dist_loss: 0.7029789090156555
recon_loss: 0.027429187670350075, dist_loss: 0.39739787578582764
recon_loss: 0.027429331094026566, dist_loss: 1.345120906829834
recon_loss: 0.027428895235061646, dist_loss: 0.7166056036949158
recon_loss: 0.027428794652223587, dist_loss: 0.5336241722106934
recon_loss: 0.02742929197847843, dist_loss: 0.8073773384094238
recon_loss: 0.027428923174738884, dist_loss: 0.8727719783782959
recon_loss: 0.027429956942796707, dist_loss: 0.49889084696769714
recon_loss: 0.02742942050099373, dist_loss: 0.3506622016429901
recon_loss: 0.027429740875959396, dist_loss: 0.5427008867263794
recon_loss: 0.027430130168795586, dist_loss: 0.5762818455696106
recon_loss: 0.027430497109889984, dist_loss: 0.5205173492431641
recon_loss: 0.02743065543472767, dist_loss: 1.1677327156066895
recon_loss: 0.02743065543472767, dist_loss: 0.669082760810852
recon_loss: 0.02743063122034073, dist_loss: 0.8470302224159241
recon_loss: 0.027430549263954163, dist_loss: 0.5489155054092407
recon_loss: 0.027430662885308266, dist_loss: 0.757106602191925
recon_loss: 0.027430249378085136, dist_loss: 0.43663325905799866
recon_loss: 0.027430973947048187, dist_loss: 1.2839480638504028
recon_loss: 0.02742990292608738, dist_loss: 0.2313121110200882
recon_loss: 0.027429670095443726, dist_loss: 0.5596272945404053
recon_loss: 0.027428992092609406, dist_loss: 0.38248956203460693
recon_loss: 0.027428848668932915, dist_loss: 0.5406713485717773
recon_loss: 0.02742805890738964, dist_loss: 0.8661220073699951
recon_loss: 0.027428245171904564, dist_loss: 0.681954026222229
recon_loss: 0.02742724120616913, dist_loss: 0.7470859289169312
recon_loss: 0.02742811292409897, dist_loss: 0.5918434858322144
recon_loss: 0.027427829802036285, dist_loss: 0.7229771614074707
recon_loss: 0.027428671717643738, dist_loss: 0.9323649406433105
recon_loss: 0.02742835320532322, dist_loss: 0.5120225548744202
recon_loss: 0.027428753674030304, dist_loss: 0.6526787877082825
recon_loss: 0.027428792789578438, dist_loss: 0.5042848587036133
recon_loss: 0.027428703382611275, dist_loss: 0.35212135314941406
recon_loss: 0.02742886357009411, dist_loss: 0.5893224477767944
recon_loss: 0.027428342029452324, dist_loss: 0.4115467369556427
recon_loss: 0.027428623288869858, dist_loss: 0.7221227884292603
recon_loss: 0.027428148314356804, dist_loss: 1.022348403930664
recon_loss: 0.02742820233106613, dist_loss: 0.5345699787139893
recon_loss: 0.027427593246102333, dist_loss: 0.8341225385665894
recon_loss: 0.02742735855281353, dist_loss: 0.7281977534294128
recon_loss: 0.027427125722169876, dist_loss: 0.6702982783317566
recon_loss: 0.027427366003394127, dist_loss: 0.5918993353843689
recon_loss: 0.027427686378359795, dist_loss: 0.7138704061508179
recon_loss: 0.027427880093455315, dist_loss: 0.8169898986816406
recon_loss: 0.02742796391248703, dist_loss: 0.7414771914482117
recon_loss: 0.027428461238741875, dist_loss: 0.4800935387611389
recon_loss: 0.02742811106145382, dist_loss: 0.5346993207931519
recon_loss: 0.027428006753325462, dist_loss: 0.6491165161132812
recon_loss: 0.027428923174738884, dist_loss: 0.524803638458252
recon_loss: 0.027426516637206078, dist_loss: 1.0471595525741577
recon_loss: 0.027427274733781815, dist_loss: 0.6671698689460754
recon_loss: 0.027428273111581802, dist_loss: 0.6310133934020996
recon_loss: 0.02742905728518963, dist_loss: 1.0597076416015625
recon_loss: 0.02742975577712059, dist_loss: 0.7129696011543274
recon_loss: 0.02743018977344036, dist_loss: 0.601089596748352
recon_loss: 0.0274309441447258, dist_loss: 0.4589325189590454
recon_loss: 0.027431143447756767, dist_loss: 0.5618899464607239
recon_loss: 0.02743157371878624, dist_loss: 0.4242277443408966
recon_loss: 0.027431748807430267, dist_loss: 0.6435259580612183
recon_loss: 0.027431165799498558, dist_loss: 0.8613673448562622
recon_loss: 0.027430659160017967, dist_loss: 0.32886072993278503
Pre-training Epoch 105:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 105:   5%|▍         | 17/367 [00:00<00:02, 169.63it/s]Pre-training Epoch 105:  10%|▉         | 36/367 [00:00<00:01, 176.97it/s]Pre-training Epoch 105:  15%|█▍        | 54/367 [00:00<00:01, 178.16it/s]Pre-training Epoch 105:  20%|█▉        | 73/367 [00:00<00:01, 179.32it/s]Pre-training Epoch 105:  25%|██▍       | 91/367 [00:00<00:01, 176.58it/s]Pre-training Epoch 105:  30%|██▉       | 109/367 [00:00<00:01, 175.40it/s]Pre-training Epoch 105:  35%|███▍      | 127/367 [00:00<00:01, 176.36it/s]recon_loss: 0.027429820969700813, dist_loss: 1.3733162879943848
recon_loss: 0.027429495006799698, dist_loss: 0.6626371741294861
recon_loss: 0.027429621666669846, dist_loss: 0.5220173597335815
recon_loss: 0.0274293702095747, dist_loss: 0.7423408627510071
recon_loss: 0.027429772540926933, dist_loss: 0.8573254346847534
recon_loss: 0.02742924727499485, dist_loss: 1.0016168355941772
recon_loss: 0.027428744360804558, dist_loss: 0.8320435285568237
recon_loss: 0.02742915228009224, dist_loss: 0.7209117412567139
recon_loss: 0.027429349720478058, dist_loss: 0.831148087978363
recon_loss: 0.02743046171963215, dist_loss: 0.9171313047409058
recon_loss: 0.027430955320596695, dist_loss: 0.9543631076812744
recon_loss: 0.027431732043623924, dist_loss: 0.5330426096916199
recon_loss: 0.027431832626461983, dist_loss: 0.4459003210067749
recon_loss: 0.027432067319750786, dist_loss: 0.320027232170105
recon_loss: 0.02743159979581833, dist_loss: 0.7472313642501831
recon_loss: 0.027430959045886993, dist_loss: 0.6269155740737915
recon_loss: 0.027430009096860886, dist_loss: 0.5797548294067383
recon_loss: 0.027428703382611275, dist_loss: 0.9110231995582581
recon_loss: 0.027427712455391884, dist_loss: 0.5918183326721191
recon_loss: 0.027427157387137413, dist_loss: 0.4188857078552246
recon_loss: 0.027427323162555695, dist_loss: 0.5506531596183777
recon_loss: 0.027427295222878456, dist_loss: 0.9243447184562683
recon_loss: 0.027427589520812035, dist_loss: 0.46320486068725586
recon_loss: 0.02742668241262436, dist_loss: 0.5281631946563721
recon_loss: 0.027427490800619125, dist_loss: 0.818001925945282
recon_loss: 0.027426492422819138, dist_loss: 0.5434784889221191
recon_loss: 0.027426498010754585, dist_loss: 0.5188042521476746
recon_loss: 0.02742556668817997, dist_loss: 0.9353389739990234
recon_loss: 0.027425821870565414, dist_loss: 1.2263556718826294
recon_loss: 0.02742563933134079, dist_loss: 0.4105204939842224
recon_loss: 0.027425147593021393, dist_loss: 0.6781141757965088
recon_loss: 0.02742449752986431, dist_loss: 0.5051801204681396
recon_loss: 0.027425315231084824, dist_loss: 0.8950015306472778
recon_loss: 0.027425555512309074, dist_loss: 0.7105881571769714
recon_loss: 0.027425507083535194, dist_loss: 0.462311714887619
recon_loss: 0.027424924075603485, dist_loss: 0.7870736718177795
recon_loss: 0.027425458654761314, dist_loss: 0.7411389946937561
recon_loss: 0.027424488216638565, dist_loss: 1.0087404251098633
recon_loss: 0.027425525709986687, dist_loss: 0.5767654180526733
recon_loss: 0.02742365188896656, dist_loss: 0.3052847385406494
recon_loss: 0.02742408961057663, dist_loss: 0.29507875442504883
recon_loss: 0.027423616498708725, dist_loss: 0.6386509537696838
recon_loss: 0.027423985302448273, dist_loss: 1.0861587524414062
recon_loss: 0.027423717081546783, dist_loss: 0.6398878693580627
recon_loss: 0.02742399275302887, dist_loss: 0.8474715948104858
recon_loss: 0.027424797415733337, dist_loss: 0.37262237071990967
recon_loss: 0.027425356209278107, dist_loss: 0.46170365810394287
recon_loss: 0.027427038177847862, dist_loss: 0.5693306922912598
recon_loss: 0.027426382526755333, dist_loss: 0.4774360954761505
recon_loss: 0.02742723375558853, dist_loss: 0.7615083456039429
recon_loss: 0.02742747776210308, dist_loss: 0.39053910970687866
recon_loss: 0.02742793783545494, dist_loss: 0.5205813646316528
recon_loss: 0.0274276714771986, dist_loss: 0.646440863609314
recon_loss: 0.027427317574620247, dist_loss: 0.3155658543109894
recon_loss: 0.02742822840809822, dist_loss: 0.6948457956314087
recon_loss: 0.02742820605635643, dist_loss: 0.34326261281967163
recon_loss: 0.027428245171904564, dist_loss: 0.6093187928199768
recon_loss: 0.027427680790424347, dist_loss: 0.752768874168396
recon_loss: 0.02742733806371689, dist_loss: 0.738739013671875
recon_loss: 0.02742752991616726, dist_loss: 0.9389744997024536
recon_loss: 0.02742697484791279, dist_loss: 0.5573611259460449
recon_loss: 0.02742713876068592, dist_loss: 0.5913451910018921
recon_loss: 0.027425846084952354, dist_loss: 0.5879072546958923
recon_loss: 0.02742493711411953, dist_loss: 0.6080977320671082
recon_loss: 0.02742503583431244, dist_loss: 0.8154164552688599
recon_loss: 0.02742467075586319, dist_loss: 0.6498587131500244
recon_loss: 0.027424784377217293, dist_loss: 0.7747409343719482
recon_loss: 0.027424614876508713, dist_loss: 0.571610689163208
recon_loss: 0.027425838634371758, dist_loss: 0.7064414024353027
recon_loss: 0.027426445856690407, dist_loss: 0.8479558825492859
recon_loss: 0.027425851672887802, dist_loss: 0.9674628973007202
recon_loss: 0.027425233274698257, dist_loss: 1.1571836471557617
recon_loss: 0.02742478810250759, dist_loss: 0.3987392783164978
recon_loss: 0.027424803003668785, dist_loss: 0.4803873300552368
recon_loss: 0.027424316853284836, dist_loss: 0.8014848232269287
recon_loss: 0.027424130588769913, dist_loss: 0.5660507678985596
recon_loss: 0.027423933148384094, dist_loss: 0.3845239281654358
recon_loss: 0.027423366904258728, dist_loss: 0.6601468920707703
recon_loss: 0.027424078434705734, dist_loss: 0.576088547706604
recon_loss: 0.027423083782196045, dist_loss: 0.6080203056335449
recon_loss: 0.02742464654147625, dist_loss: 0.6024929285049438
recon_loss: 0.027423469349741936, dist_loss: 0.40259408950805664
recon_loss: 0.02742334082722664, dist_loss: 0.7875326871871948
recon_loss: 0.02742365002632141, dist_loss: 0.5890218615531921
recon_loss: 0.02742314338684082, dist_loss: 0.3776194453239441
recon_loss: 0.0274241603910923, dist_loss: 0.8408252000808716
recon_loss: 0.027423182502388954, dist_loss: 0.38533133268356323
recon_loss: 0.027423756197094917, dist_loss: 0.39439213275909424
recon_loss: 0.027423692867159843, dist_loss: 0.6366689205169678
recon_loss: 0.027424244210124016, dist_loss: 0.5916456580162048
recon_loss: 0.027424229308962822, dist_loss: 0.5361567735671997
recon_loss: 0.02742478996515274, dist_loss: 0.40541285276412964
recon_loss: 0.027424875646829605, dist_loss: 0.40643051266670227
recon_loss: 0.02742452546954155, dist_loss: 0.8666980862617493
recon_loss: 0.027424011379480362, dist_loss: 0.43750372529029846
recon_loss: 0.02742379531264305, dist_loss: 0.7295501232147217
recon_loss: 0.02742336131632328, dist_loss: 1.051466941833496
recon_loss: 0.02742278389632702, dist_loss: 0.8209621906280518
recon_loss: 0.027422286570072174, dist_loss: 0.6603280305862427
recon_loss: 0.027422476559877396, dist_loss: 0.966708779335022
recon_loss: 0.02742300182580948, dist_loss: 0.7988020181655884
recon_loss: 0.02742321789264679, dist_loss: 0.49748432636260986
recon_loss: 0.027424514293670654, dist_loss: 0.6467437148094177
recon_loss: 0.02742363139986992, dist_loss: 0.5282901525497437
recon_loss: 0.027424635365605354, dist_loss: 0.9722756743431091
recon_loss: 0.0274235587567091, dist_loss: 0.47717925906181335
recon_loss: 0.027423245832324028, dist_loss: 0.4078972637653351
recon_loss: 0.02742229588329792, dist_loss: 0.7729079723358154
recon_loss: 0.02742188051342964, dist_loss: 0.5252903699874878
recon_loss: 0.02742142789065838, dist_loss: 0.8351757526397705
recon_loss: 0.02742091380059719, dist_loss: 0.4974594712257385
recon_loss: 0.027420522645115852, dist_loss: 0.4866073429584503
recon_loss: 0.027420343831181526, dist_loss: 0.6153054237365723
recon_loss: 0.027420377358794212, dist_loss: 0.3597620725631714
recon_loss: 0.027420740574598312, dist_loss: 0.3487996459007263
recon_loss: 0.02742069959640503, dist_loss: 0.847501277923584
recon_loss: 0.02742101065814495, dist_loss: 0.5167806148529053
recon_loss: 0.027421273291110992, dist_loss: 0.42796507477760315
recon_loss: 0.02742145210504532, dist_loss: 0.7022672891616821
recon_loss: 0.02742174081504345, dist_loss: 0.25320547819137573
recon_loss: 0.027422096580266953, dist_loss: 0.42630594968795776
recon_loss: 0.027422761544585228, dist_loss: 0.7292945384979248
recon_loss: 0.02742372825741768, dist_loss: 0.7006093263626099
recon_loss: 0.027425168082118034, dist_loss: 0.48582929372787476
recon_loss: 0.027427446097135544, dist_loss: 0.865930438041687
recon_loss: 0.027428869158029556, dist_loss: 0.526762843132019
recon_loss: 0.027430392801761627, dist_loss: 0.6305399537086487
recon_loss: 0.02743101678788662, dist_loss: 0.6617165803909302
Pre-training Epoch 105:  40%|███▉      | 145/367 [00:00<00:01, 176.33it/s]Pre-training Epoch 105:  44%|████▍     | 163/367 [00:00<00:01, 171.47it/s]Pre-training Epoch 105:  49%|████▉     | 181/367 [00:01<00:01, 169.26it/s]Pre-training Epoch 105:  54%|█████▍    | 198/367 [00:01<00:01, 167.26it/s]Pre-training Epoch 105:  59%|█████▊    | 215/367 [00:01<00:00, 166.44it/s]Pre-training Epoch 105:  63%|██████▎   | 232/367 [00:01<00:00, 165.96it/s]Pre-training Epoch 105:  68%|██████▊   | 249/367 [00:01<00:00, 164.70it/s]recon_loss: 0.027432534843683243, dist_loss: 1.1541399955749512
recon_loss: 0.027432046830654144, dist_loss: 0.492708683013916
recon_loss: 0.02743244357407093, dist_loss: 0.7493237853050232
recon_loss: 0.027431275695562363, dist_loss: 0.5196346640586853
recon_loss: 0.027428479865193367, dist_loss: 0.7617042064666748
recon_loss: 0.027426650747656822, dist_loss: 0.6786561012268066
recon_loss: 0.02742440439760685, dist_loss: 0.8048973083496094
recon_loss: 0.027424031868577003, dist_loss: 0.5754212737083435
recon_loss: 0.027423355728387833, dist_loss: 0.7280098795890808
recon_loss: 0.027424536645412445, dist_loss: 0.6562716960906982
recon_loss: 0.02742539346218109, dist_loss: 0.5604879260063171
recon_loss: 0.027425773441791534, dist_loss: 0.9298770427703857
recon_loss: 0.027425669133663177, dist_loss: 0.6102172136306763
recon_loss: 0.027424870058894157, dist_loss: 0.8908882141113281
recon_loss: 0.02742370218038559, dist_loss: 0.5672214031219482
recon_loss: 0.02742251567542553, dist_loss: 0.5806264281272888
recon_loss: 0.027421509847044945, dist_loss: 0.6081373691558838
recon_loss: 0.02742016687989235, dist_loss: 0.909806489944458
recon_loss: 0.02741922251880169, dist_loss: 0.5958551168441772
recon_loss: 0.027418863028287888, dist_loss: 0.8918488025665283
recon_loss: 0.02741914987564087, dist_loss: 0.4089825451374054
recon_loss: 0.02742028795182705, dist_loss: 0.738064706325531
recon_loss: 0.02742289938032627, dist_loss: 0.3065745234489441
recon_loss: 0.027424858883023262, dist_loss: 0.8358280062675476
recon_loss: 0.027426138520240784, dist_loss: 0.4632205367088318
recon_loss: 0.027426982298493385, dist_loss: 0.5366814732551575
recon_loss: 0.027427097782492638, dist_loss: 0.7301420569419861
recon_loss: 0.027426591143012047, dist_loss: 0.9873276352882385
recon_loss: 0.027426915243268013, dist_loss: 0.5734268426895142
recon_loss: 0.027426276355981827, dist_loss: 0.7857024669647217
recon_loss: 0.027424896135926247, dist_loss: 0.4337421953678131
recon_loss: 0.027422942221164703, dist_loss: 0.9265949726104736
recon_loss: 0.02742091752588749, dist_loss: 0.41216638684272766
recon_loss: 0.0274197980761528, dist_loss: 1.0274155139923096
recon_loss: 0.027419034391641617, dist_loss: 0.447808176279068
recon_loss: 0.027418827638030052, dist_loss: 0.36852148175239563
recon_loss: 0.027418851852416992, dist_loss: 0.7237285375595093
recon_loss: 0.02741924114525318, dist_loss: 1.1461961269378662
recon_loss: 0.02742007002234459, dist_loss: 0.38752275705337524
recon_loss: 0.02742065116763115, dist_loss: 0.6990588903427124
recon_loss: 0.027420666068792343, dist_loss: 0.5013761520385742
recon_loss: 0.02742054872214794, dist_loss: 0.5593311190605164
recon_loss: 0.02742071822285652, dist_loss: 0.47540274262428284
recon_loss: 0.02741992101073265, dist_loss: 0.5977077484130859
recon_loss: 0.02741939201951027, dist_loss: 0.636174201965332
recon_loss: 0.02741866186261177, dist_loss: 0.9214709997177124
recon_loss: 0.027418002486228943, dist_loss: 0.6656539440155029
recon_loss: 0.027417687699198723, dist_loss: 0.5565791130065918
recon_loss: 0.027416974306106567, dist_loss: 1.0840855836868286
recon_loss: 0.027416875585913658, dist_loss: 0.5765008330345154
recon_loss: 0.02741645649075508, dist_loss: 0.4533662796020508
recon_loss: 0.027416449040174484, dist_loss: 0.7900670766830444
recon_loss: 0.02741674892604351, dist_loss: 0.9985989928245544
recon_loss: 0.027417313307523727, dist_loss: 0.7235748767852783
recon_loss: 0.02741771750152111, dist_loss: 0.6652539968490601
recon_loss: 0.027417734265327454, dist_loss: 0.8612692356109619
recon_loss: 0.027417335659265518, dist_loss: 0.5529574155807495
recon_loss: 0.027416933327913284, dist_loss: 0.528166651725769
recon_loss: 0.027416199445724487, dist_loss: 0.6402283310890198
recon_loss: 0.027415979653596878, dist_loss: 0.6256749629974365
recon_loss: 0.027416029945015907, dist_loss: 0.47629308700561523
recon_loss: 0.02741571143269539, dist_loss: 0.4569494128227234
recon_loss: 0.02741573378443718, dist_loss: 0.6748989820480347
recon_loss: 0.027415703982114792, dist_loss: 0.42747241258621216
recon_loss: 0.02741571143269539, dist_loss: 0.7800259590148926
recon_loss: 0.027415581047534943, dist_loss: 0.7077639102935791
recon_loss: 0.027415594086050987, dist_loss: 0.5271673202514648
recon_loss: 0.02741529978811741, dist_loss: 0.7344326376914978
recon_loss: 0.027415229007601738, dist_loss: 0.6823790073394775
recon_loss: 0.027415592223405838, dist_loss: 0.8745807409286499
recon_loss: 0.027415424585342407, dist_loss: 0.7099863886833191
recon_loss: 0.027415534481406212, dist_loss: 0.6915198564529419
recon_loss: 0.027415450662374496, dist_loss: 0.5492563247680664
recon_loss: 0.027416756376624107, dist_loss: 0.4121672809123993
recon_loss: 0.027417099103331566, dist_loss: 0.46122026443481445
recon_loss: 0.027418628334999084, dist_loss: 0.5418175458908081
recon_loss: 0.02741878479719162, dist_loss: 0.42706573009490967
recon_loss: 0.02741818130016327, dist_loss: 0.9243686199188232
recon_loss: 0.02741897851228714, dist_loss: 0.6453787088394165
recon_loss: 0.027417341247200966, dist_loss: 0.4704139828681946
recon_loss: 0.027417762205004692, dist_loss: 0.5276598930358887
recon_loss: 0.027416083961725235, dist_loss: 0.7118028402328491
recon_loss: 0.027414554730057716, dist_loss: 0.8820307850837708
recon_loss: 0.027415122836828232, dist_loss: 0.7825008034706116
recon_loss: 0.0274139903485775, dist_loss: 0.5152719020843506
recon_loss: 0.027416298165917397, dist_loss: 0.3330438733100891
recon_loss: 0.027416042983531952, dist_loss: 0.524471640586853
recon_loss: 0.027418237179517746, dist_loss: 0.3917272686958313
recon_loss: 0.027417175471782684, dist_loss: 0.6519163846969604
recon_loss: 0.027417529374361038, dist_loss: 0.6204158067703247
recon_loss: 0.02741759456694126, dist_loss: 0.5718967914581299
recon_loss: 0.027416406199336052, dist_loss: 0.7987830638885498
recon_loss: 0.02741716057062149, dist_loss: 0.7609463334083557
recon_loss: 0.02741650678217411, dist_loss: 0.699294924736023
recon_loss: 0.02741684392094612, dist_loss: 0.567373514175415
recon_loss: 0.027416765689849854, dist_loss: 0.38328176736831665
recon_loss: 0.027415797114372253, dist_loss: 0.4590036869049072
recon_loss: 0.02741549164056778, dist_loss: 0.5393857955932617
recon_loss: 0.027414565905928612, dist_loss: 0.5942826271057129
recon_loss: 0.027413832023739815, dist_loss: 1.1882926225662231
recon_loss: 0.027413351461291313, dist_loss: 1.1244196891784668
recon_loss: 0.027413347736001015, dist_loss: 0.45357370376586914
recon_loss: 0.027413683012127876, dist_loss: 0.3799265921115875
recon_loss: 0.02741374261677265, dist_loss: 0.7586374878883362
recon_loss: 0.0274135023355484, dist_loss: 0.46130430698394775
recon_loss: 0.027413398027420044, dist_loss: 1.1584832668304443
recon_loss: 0.027413055300712585, dist_loss: 0.7597519159317017
recon_loss: 0.0274128969758749, dist_loss: 0.5693097114562988
recon_loss: 0.02741265296936035, dist_loss: 0.3787752389907837
recon_loss: 0.027412276715040207, dist_loss: 0.5451536178588867
recon_loss: 0.027412548661231995, dist_loss: 0.9102929830551147
recon_loss: 0.02741279825568199, dist_loss: 0.49267953634262085
recon_loss: 0.02741335518658161, dist_loss: 0.842474102973938
recon_loss: 0.02741350792348385, dist_loss: 0.46979454159736633
recon_loss: 0.027413930743932724, dist_loss: 0.6539468765258789
recon_loss: 0.027413982897996902, dist_loss: 0.47539156675338745
recon_loss: 0.02741415798664093, dist_loss: 0.6420043110847473
recon_loss: 0.027414295822381973, dist_loss: 1.062080979347229
recon_loss: 0.027415407821536064, dist_loss: 0.5233173966407776
recon_loss: 0.02741566114127636, dist_loss: 0.4148925244808197
recon_loss: 0.02741508185863495, dist_loss: 0.5555503368377686
recon_loss: 0.02741551771759987, dist_loss: 0.7347359657287598
recon_loss: 0.027414942160248756, dist_loss: 1.0821434259414673
recon_loss: 0.027414653450250626, dist_loss: 0.8148152828216553
recon_loss: 0.027413560077548027, dist_loss: 0.6014690399169922
recon_loss: 0.027412058785557747, dist_loss: 0.8596557378768921
recon_loss: 0.027411749586462975, dist_loss: 0.909403920173645
recon_loss: 0.027411725372076035, dist_loss: 0.5094279050827026
Pre-training Epoch 105:  72%|███████▏  | 266/367 [00:01<00:00, 164.44it/s]Pre-training Epoch 105:  77%|███████▋  | 283/367 [00:01<00:00, 162.38it/s]Pre-training Epoch 105:  82%|████████▏ | 300/367 [00:01<00:00, 162.91it/s]Pre-training Epoch 105:  86%|████████▋ | 317/367 [00:01<00:00, 162.69it/s]Pre-training Epoch 105:  91%|█████████ | 334/367 [00:01<00:00, 162.76it/s]Pre-training Epoch 105:  96%|█████████▌| 351/367 [00:02<00:00, 163.61it/s]Pre-training Epoch 105: 100%|██████████| 367/367 [00:02<00:00, 168.21it/s]
recon_loss: 0.027413615956902504, dist_loss: 0.7892494201660156
recon_loss: 0.027413347736001015, dist_loss: 0.3576570153236389
recon_loss: 0.027414705604314804, dist_loss: 0.9468895196914673
recon_loss: 0.02741391584277153, dist_loss: 1.0289552211761475
recon_loss: 0.027413969859480858, dist_loss: 0.5423260927200317
recon_loss: 0.02741396613419056, dist_loss: 0.6640921235084534
recon_loss: 0.027413776144385338, dist_loss: 0.4594031274318695
recon_loss: 0.02741353213787079, dist_loss: 0.9296737909317017
recon_loss: 0.027412734925746918, dist_loss: 0.5268514156341553
recon_loss: 0.0274131391197443, dist_loss: 0.7506992816925049
recon_loss: 0.02741263434290886, dist_loss: 0.5366042852401733
recon_loss: 0.027412530034780502, dist_loss: 0.509975790977478
recon_loss: 0.02741255983710289, dist_loss: 0.7599385380744934
recon_loss: 0.027412334457039833, dist_loss: 0.8094621896743774
recon_loss: 0.027411947026848793, dist_loss: 0.3707740604877472
recon_loss: 0.027411559596657753, dist_loss: 0.4220522940158844
recon_loss: 0.02741090953350067, dist_loss: 0.6270615458488464
recon_loss: 0.02741043083369732, dist_loss: 0.4237372577190399
recon_loss: 0.027410436421632767, dist_loss: 0.23964452743530273
recon_loss: 0.027409855276346207, dist_loss: 0.5653356313705444
recon_loss: 0.027410700917243958, dist_loss: 0.664096474647522
recon_loss: 0.02740931138396263, dist_loss: 0.7449283599853516
recon_loss: 0.02740967832505703, dist_loss: 0.6217472553253174
recon_loss: 0.027409996837377548, dist_loss: 0.8551713824272156
recon_loss: 0.027408627793192863, dist_loss: 0.7928208112716675
recon_loss: 0.027409464120864868, dist_loss: 0.6134262084960938
recon_loss: 0.027408422902226448, dist_loss: 0.7346895933151245
recon_loss: 0.027410021051764488, dist_loss: 1.0602385997772217
recon_loss: 0.027408979833126068, dist_loss: 0.5940219163894653
recon_loss: 0.02740972861647606, dist_loss: 0.5322532653808594
recon_loss: 0.02741008810698986, dist_loss: 0.5522269606590271
recon_loss: 0.027408530935645103, dist_loss: 0.6159754395484924
recon_loss: 0.02740958333015442, dist_loss: 0.6193534135818481
recon_loss: 0.027408581227064133, dist_loss: 1.1263656616210938
recon_loss: 0.027410030364990234, dist_loss: 1.148410677909851
recon_loss: 0.027408992871642113, dist_loss: 0.38082313537597656
recon_loss: 0.02741006575524807, dist_loss: 0.6113613247871399
recon_loss: 0.02740863710641861, dist_loss: 0.5713582038879395
recon_loss: 0.027409382164478302, dist_loss: 0.8202024698257446
recon_loss: 0.027408884838223457, dist_loss: 0.6281074285507202
recon_loss: 0.027409425005316734, dist_loss: 0.34085577726364136
recon_loss: 0.027408888563513756, dist_loss: 0.42714405059814453
recon_loss: 0.027408629655838013, dist_loss: 0.3421136736869812
recon_loss: 0.027408067137002945, dist_loss: 0.4988050162792206
recon_loss: 0.027407808229327202, dist_loss: 0.4701344072818756
recon_loss: 0.027407662943005562, dist_loss: 0.4176104664802551
recon_loss: 0.027407554909586906, dist_loss: 0.8121213316917419
recon_loss: 0.027407201007008553, dist_loss: 0.7047682404518127
recon_loss: 0.027407096698880196, dist_loss: 0.5272148847579956
recon_loss: 0.02740684524178505, dist_loss: 0.4556446969509125
recon_loss: 0.02740715816617012, dist_loss: 0.5042452216148376
recon_loss: 0.02740691602230072, dist_loss: 0.8954830169677734
recon_loss: 0.027406923472881317, dist_loss: 0.44791603088378906
recon_loss: 0.027406951412558556, dist_loss: 0.7990996241569519
recon_loss: 0.027407191693782806, dist_loss: 0.40499189496040344
recon_loss: 0.027406999841332436, dist_loss: 0.3832619786262512
recon_loss: 0.027407042682170868, dist_loss: 0.4841887950897217
recon_loss: 0.027406837791204453, dist_loss: 1.0278302431106567
recon_loss: 0.02740642987191677, dist_loss: 0.5469773411750793
recon_loss: 0.027406256645917892, dist_loss: 0.842474102973938
recon_loss: 0.027406305074691772, dist_loss: 0.808158278465271
recon_loss: 0.027406103909015656, dist_loss: 0.6620010137557983
recon_loss: 0.027406392619013786, dist_loss: 0.5475637316703796
recon_loss: 0.02740616537630558, dist_loss: 0.7573730945587158
recon_loss: 0.027406249195337296, dist_loss: 0.7155599594116211
recon_loss: 0.027406135573983192, dist_loss: 0.6154803037643433
recon_loss: 0.027405904605984688, dist_loss: 0.5577433705329895
recon_loss: 0.0274063553661108, dist_loss: 0.41844385862350464
recon_loss: 0.02740616723895073, dist_loss: 0.5603001117706299
recon_loss: 0.02740609273314476, dist_loss: 0.8502097129821777
recon_loss: 0.02740589529275894, dist_loss: 0.47987452149391174
recon_loss: 0.027405673637986183, dist_loss: 0.4941101670265198
recon_loss: 0.02740570157766342, dist_loss: 0.9332529306411743
recon_loss: 0.02740602381527424, dist_loss: 0.7641233801841736
recon_loss: 0.02740599401295185, dist_loss: 0.7713590860366821
recon_loss: 0.027406617999076843, dist_loss: 0.34699952602386475
recon_loss: 0.027406636625528336, dist_loss: 0.47679126262664795
recon_loss: 0.027407001703977585, dist_loss: 0.6914716958999634
recon_loss: 0.027406999841332436, dist_loss: 0.5680727362632751
recon_loss: 0.02740752324461937, dist_loss: 0.5397987365722656
recon_loss: 0.027407892048358917, dist_loss: 0.8301461935043335
recon_loss: 0.027408502995967865, dist_loss: 0.27500659227371216
recon_loss: 0.0274092648178339, dist_loss: 0.6883711814880371
recon_loss: 0.027409978210926056, dist_loss: 1.182152509689331
recon_loss: 0.02741011418402195, dist_loss: 0.5979722738265991
recon_loss: 0.02741030976176262, dist_loss: 0.3845960199832916
recon_loss: 0.027410084381699562, dist_loss: 0.5360910892486572
recon_loss: 0.027409104630351067, dist_loss: 0.3506057858467102
recon_loss: 0.027408458292484283, dist_loss: 0.8753294944763184
recon_loss: 0.027407744899392128, dist_loss: 0.6942405700683594
recon_loss: 0.027407098561525345, dist_loss: 0.4076983332633972
recon_loss: 0.027407046407461166, dist_loss: 0.6965309381484985
recon_loss: 0.027406960725784302, dist_loss: 0.43371695280075073
recon_loss: 0.027407106012105942, dist_loss: 0.7763609886169434
recon_loss: 0.027407338842749596, dist_loss: 0.9752489924430847
recon_loss: 0.027408001944422722, dist_loss: 0.5674030780792236
recon_loss: 0.027409078553318977, dist_loss: 0.7849751114845276
recon_loss: 0.027410654351115227, dist_loss: 0.780396580696106
recon_loss: 0.02741214632987976, dist_loss: 0.5480547547340393
recon_loss: 0.02741273120045662, dist_loss: 0.45775172114372253
recon_loss: 0.027414271607995033, dist_loss: 0.6268112659454346
recon_loss: 0.02741408348083496, dist_loss: 0.5826606750488281
recon_loss: 0.02741374634206295, dist_loss: 0.48393553495407104
recon_loss: 0.027412500232458115, dist_loss: 0.5760202407836914
recon_loss: 0.027410095557570457, dist_loss: 0.8160456418991089
recon_loss: 0.02740895189344883, dist_loss: 1.6468921899795532
recon_loss: 0.027407927438616753, dist_loss: 0.47195500135421753
recon_loss: 0.027408234775066376, dist_loss: 0.5133518576622009
recon_loss: 0.027408849447965622, dist_loss: 0.6737865805625916
recon_loss: 0.027409331873059273, dist_loss: 0.7664227485656738
recon_loss: 0.027409717440605164, dist_loss: 0.9773721694946289
Pre-training Epoch 106:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 106:   4%|▍         | 16/367 [00:00<00:02, 155.59it/s]Pre-training Epoch 106:   9%|▉         | 33/367 [00:00<00:02, 159.13it/s]Pre-training Epoch 106:  14%|█▎        | 50/367 [00:00<00:01, 160.65it/s]Pre-training Epoch 106:  18%|█▊        | 67/367 [00:00<00:01, 162.89it/s]Pre-training Epoch 106:  23%|██▎       | 84/367 [00:00<00:01, 164.02it/s]Pre-training Epoch 106:  28%|██▊       | 101/367 [00:00<00:01, 165.51it/s]Pre-training Epoch 106:  32%|███▏      | 119/367 [00:00<00:01, 167.18it/s]recon_loss: 0.027409464120864868, dist_loss: 0.7991889715194702
recon_loss: 0.02741003781557083, dist_loss: 0.32140833139419556
recon_loss: 0.027409354224801064, dist_loss: 0.5278409719467163
recon_loss: 0.027409236878156662, dist_loss: 0.5039932727813721
recon_loss: 0.027408193796873093, dist_loss: 0.8536897897720337
recon_loss: 0.02740822173655033, dist_loss: 0.6035721898078918
recon_loss: 0.02740764431655407, dist_loss: 0.524478554725647
recon_loss: 0.027407487854361534, dist_loss: 0.8143900632858276
recon_loss: 0.02740786410868168, dist_loss: 0.49742788076400757
recon_loss: 0.027407778427004814, dist_loss: 0.6003510355949402
recon_loss: 0.027409294620156288, dist_loss: 0.57222980260849
recon_loss: 0.0274092648178339, dist_loss: 0.9055241942405701
recon_loss: 0.027411147952079773, dist_loss: 0.4361470937728882
recon_loss: 0.027411311864852905, dist_loss: 0.6738500595092773
recon_loss: 0.027411529794335365, dist_loss: 0.49530643224716187
recon_loss: 0.027412114664912224, dist_loss: 0.9864306449890137
recon_loss: 0.027411820366978645, dist_loss: 0.7215934991836548
recon_loss: 0.027413079515099525, dist_loss: 0.5532666444778442
recon_loss: 0.027410853654146194, dist_loss: 0.5307430028915405
recon_loss: 0.027410509064793587, dist_loss: 0.46660125255584717
recon_loss: 0.027409495785832405, dist_loss: 0.9456274509429932
recon_loss: 0.027408160269260406, dist_loss: 0.9180667400360107
recon_loss: 0.027407359331846237, dist_loss: 0.3993279039859772
recon_loss: 0.027406280860304832, dist_loss: 0.2687993347644806
recon_loss: 0.027405889704823494, dist_loss: 0.84664386510849
recon_loss: 0.02740532159805298, dist_loss: 0.7059280276298523
recon_loss: 0.027404995635151863, dist_loss: 0.8936004042625427
recon_loss: 0.027404865249991417, dist_loss: 0.3575732707977295
recon_loss: 0.027404874563217163, dist_loss: 0.5023651123046875
recon_loss: 0.027404887601733208, dist_loss: 0.3244752883911133
recon_loss: 0.027405407279729843, dist_loss: 0.39091217517852783
recon_loss: 0.027405524626374245, dist_loss: 0.6040582060813904
recon_loss: 0.02740606479346752, dist_loss: 0.6638889312744141
recon_loss: 0.027406569570302963, dist_loss: 0.7633229494094849
recon_loss: 0.02740723267197609, dist_loss: 0.578152060508728
recon_loss: 0.027407757937908173, dist_loss: 0.559648871421814
recon_loss: 0.027408171445131302, dist_loss: 0.4443208575248718
recon_loss: 0.02740873582661152, dist_loss: 0.7670500874519348
recon_loss: 0.02740931697189808, dist_loss: 0.5468410849571228
recon_loss: 0.02740907110273838, dist_loss: 0.9979240894317627
recon_loss: 0.027409562841057777, dist_loss: 0.6809574365615845
recon_loss: 0.027410047128796577, dist_loss: 0.986264705657959
recon_loss: 0.027408691123127937, dist_loss: 0.5138503313064575
recon_loss: 0.027407433837652206, dist_loss: 0.4178008735179901
recon_loss: 0.027406951412558556, dist_loss: 0.42533838748931885
recon_loss: 0.027406271547079086, dist_loss: 0.6994249820709229
recon_loss: 0.02740590274333954, dist_loss: 0.7793629169464111
recon_loss: 0.027405351400375366, dist_loss: 0.7397499084472656
recon_loss: 0.027404848486185074, dist_loss: 0.3737013638019562
recon_loss: 0.027404939755797386, dist_loss: 0.5768581628799438
recon_loss: 0.027404917404055595, dist_loss: 0.6353424787521362
recon_loss: 0.027404947206377983, dist_loss: 0.7017338275909424
recon_loss: 0.02740531787276268, dist_loss: 0.6078009009361267
recon_loss: 0.02740514650940895, dist_loss: 0.3889697790145874
recon_loss: 0.027405349537730217, dist_loss: 0.6821960210800171
recon_loss: 0.027405662462115288, dist_loss: 0.5852759480476379
recon_loss: 0.0274062342941761, dist_loss: 0.5490899085998535
recon_loss: 0.027405913919210434, dist_loss: 0.8350538611412048
recon_loss: 0.027405956760048866, dist_loss: 0.5869721174240112
recon_loss: 0.027405602857470512, dist_loss: 0.558394730091095
recon_loss: 0.027405211701989174, dist_loss: 0.9419528841972351
recon_loss: 0.027405161410570145, dist_loss: 0.4963904619216919
recon_loss: 0.02740499936044216, dist_loss: 0.7469613552093506
recon_loss: 0.027405209839344025, dist_loss: 0.4947010278701782
recon_loss: 0.027404729276895523, dist_loss: 0.542178213596344
recon_loss: 0.027404895052313805, dist_loss: 1.1193594932556152
recon_loss: 0.02740488387644291, dist_loss: 0.7708827257156372
recon_loss: 0.02740480937063694, dist_loss: 0.48938271403312683
recon_loss: 0.027405237779021263, dist_loss: 0.4381864666938782
recon_loss: 0.027404537424445152, dist_loss: 0.44242680072784424
recon_loss: 0.027403954416513443, dist_loss: 0.4507468342781067
recon_loss: 0.02740362659096718, dist_loss: 0.47450608015060425
recon_loss: 0.02740320935845375, dist_loss: 1.254469394683838
recon_loss: 0.027403518557548523, dist_loss: 0.8485565185546875
recon_loss: 0.02740245871245861, dist_loss: 0.8597192764282227
recon_loss: 0.027402766048908234, dist_loss: 0.38511407375335693
recon_loss: 0.02740265615284443, dist_loss: 0.6662943363189697
recon_loss: 0.02740371599793434, dist_loss: 0.9446144104003906
recon_loss: 0.02740485407412052, dist_loss: 1.0803258419036865
recon_loss: 0.02740643173456192, dist_loss: 0.5618786215782166
recon_loss: 0.027408786118030548, dist_loss: 0.7535316944122314
recon_loss: 0.027411801740527153, dist_loss: 0.7731904983520508
recon_loss: 0.027414904907345772, dist_loss: 0.678923487663269
recon_loss: 0.027416924014687538, dist_loss: 1.004146695137024
recon_loss: 0.02741852030158043, dist_loss: 0.5624305009841919
recon_loss: 0.027419768273830414, dist_loss: 0.6128053069114685
recon_loss: 0.02742050401866436, dist_loss: 0.4944627285003662
recon_loss: 0.027419228106737137, dist_loss: 0.5395721197128296
recon_loss: 0.02741742692887783, dist_loss: 0.5080989003181458
recon_loss: 0.027414873242378235, dist_loss: 0.42820292711257935
recon_loss: 0.02741219475865364, dist_loss: 0.9692496061325073
recon_loss: 0.027409987524151802, dist_loss: 0.5056313276290894
recon_loss: 0.027408530935645103, dist_loss: 0.42045021057128906
recon_loss: 0.027407169342041016, dist_loss: 0.5510933995246887
recon_loss: 0.027406850829720497, dist_loss: 0.5702030658721924
recon_loss: 0.027407003566622734, dist_loss: 0.7331143617630005
recon_loss: 0.027407756075263023, dist_loss: 1.3181281089782715
recon_loss: 0.02740960754454136, dist_loss: 0.5467288494110107
recon_loss: 0.02741183713078499, dist_loss: 0.4968634843826294
recon_loss: 0.0274147167801857, dist_loss: 0.6405782103538513
recon_loss: 0.027415823191404343, dist_loss: 0.7244046330451965
recon_loss: 0.027416953817009926, dist_loss: 0.5695420503616333
recon_loss: 0.02741486392915249, dist_loss: 0.8364848494529724
recon_loss: 0.02741244062781334, dist_loss: 0.6620128750801086
recon_loss: 0.027410045266151428, dist_loss: 0.8229602575302124
recon_loss: 0.027408313006162643, dist_loss: 0.5427027344703674
recon_loss: 0.02740645967423916, dist_loss: 0.6972891092300415
recon_loss: 0.027406269684433937, dist_loss: 0.515514612197876
recon_loss: 0.027406593784689903, dist_loss: 0.6138989925384521
recon_loss: 0.027407411485910416, dist_loss: 0.6860806941986084
recon_loss: 0.027409737929701805, dist_loss: 0.6715698838233948
recon_loss: 0.027409963309764862, dist_loss: 0.37531474232673645
recon_loss: 0.027411753311753273, dist_loss: 0.5803489089012146
recon_loss: 0.027410810813307762, dist_loss: 0.8162049055099487
recon_loss: 0.02741088904440403, dist_loss: 0.47210490703582764
recon_loss: 0.027411796152591705, dist_loss: 0.934294581413269
recon_loss: 0.02740992233157158, dist_loss: 0.6831119060516357
recon_loss: 0.02740970253944397, dist_loss: 0.3756050765514374
recon_loss: 0.027406439185142517, dist_loss: 0.7060441374778748
recon_loss: 0.027406971901655197, dist_loss: 0.7225315570831299
recon_loss: 0.027404718101024628, dist_loss: 0.7915638089179993
recon_loss: 0.02740468643605709, dist_loss: 0.3601163923740387
recon_loss: 0.027404069900512695, dist_loss: 0.6045750379562378
recon_loss: 0.02740318514406681, dist_loss: 0.8715606331825256
recon_loss: 0.02740386873483658, dist_loss: 0.47342005372047424
recon_loss: 0.027402950450778008, dist_loss: 0.7129688262939453
recon_loss: 0.027403565123677254, dist_loss: 0.6179905533790588
recon_loss: 0.027402516454458237, dist_loss: 1.0025275945663452
Pre-training Epoch 106:  37%|███▋      | 136/367 [00:00<00:01, 167.59it/s]Pre-training Epoch 106:  43%|████▎     | 156/367 [00:00<00:01, 175.34it/s]Pre-training Epoch 106:  47%|████▋     | 174/367 [00:01<00:01, 160.00it/s]Pre-training Epoch 106:  52%|█████▏    | 191/367 [00:01<00:01, 159.04it/s]Pre-training Epoch 106:  57%|█████▋    | 208/367 [00:01<00:01, 157.09it/s]Pre-training Epoch 106:  61%|██████    | 224/367 [00:01<00:01, 107.31it/s]Pre-training Epoch 106:  65%|██████▌   | 239/367 [00:01<00:01, 116.43it/s]Pre-training Epoch 106:  70%|██████▉   | 256/367 [00:01<00:00, 127.71it/s]recon_loss: 0.027402391657233238, dist_loss: 0.9364818930625916
recon_loss: 0.02740122377872467, dist_loss: 0.5231505632400513
recon_loss: 0.027401315048336983, dist_loss: 0.29595947265625
recon_loss: 0.027401581406593323, dist_loss: 0.5334795713424683
recon_loss: 0.027401600033044815, dist_loss: 0.5877231955528259
recon_loss: 0.02740252949297428, dist_loss: 0.5997602939605713
recon_loss: 0.027402391657233238, dist_loss: 0.6588208079338074
recon_loss: 0.027402719482779503, dist_loss: 1.0385075807571411
recon_loss: 0.027403514832258224, dist_loss: 0.4938545525074005
recon_loss: 0.027403952553868294, dist_loss: 0.6475168466567993
recon_loss: 0.02740473486483097, dist_loss: 0.49455326795578003
recon_loss: 0.027404695749282837, dist_loss: 0.5266505479812622
recon_loss: 0.02740488201379776, dist_loss: 0.6669213771820068
recon_loss: 0.027404161170125008, dist_loss: 0.8170649409294128
recon_loss: 0.02740350179374218, dist_loss: 0.5429970622062683
recon_loss: 0.027402883395552635, dist_loss: 0.7112120389938354
recon_loss: 0.027401898056268692, dist_loss: 0.5501405000686646
recon_loss: 0.027401519939303398, dist_loss: 0.37938791513442993
recon_loss: 0.02740076370537281, dist_loss: 0.30224645137786865
recon_loss: 0.027400674298405647, dist_loss: 0.6306768655776978
recon_loss: 0.027401132509112358, dist_loss: 0.7132518887519836
recon_loss: 0.02740095742046833, dist_loss: 0.3948599100112915
recon_loss: 0.027402091771364212, dist_loss: 0.4934301972389221
recon_loss: 0.027401873841881752, dist_loss: 0.6736240386962891
recon_loss: 0.027401741594076157, dist_loss: 0.5483653545379639
recon_loss: 0.027401989325881004, dist_loss: 0.39339685440063477
recon_loss: 0.027401147410273552, dist_loss: 0.605654239654541
recon_loss: 0.027400873601436615, dist_loss: 0.34413135051727295
recon_loss: 0.027400046586990356, dist_loss: 0.726614773273468
recon_loss: 0.02739947848021984, dist_loss: 0.31060197949409485
recon_loss: 0.0273990947753191, dist_loss: 0.5951135158538818
recon_loss: 0.027398731559515, dist_loss: 0.39812609553337097
recon_loss: 0.0273984856903553, dist_loss: 0.6708659529685974
recon_loss: 0.027398092672228813, dist_loss: 0.43299400806427
recon_loss: 0.027398020029067993, dist_loss: 0.6170828342437744
recon_loss: 0.027397669851779938, dist_loss: 0.7304058074951172
recon_loss: 0.027397558093070984, dist_loss: 0.7404403686523438
recon_loss: 0.02739753946661949, dist_loss: 0.6531189680099487
recon_loss: 0.02739744260907173, dist_loss: 0.26647770404815674
recon_loss: 0.027397319674491882, dist_loss: 0.36806774139404297
recon_loss: 0.02739710547029972, dist_loss: 0.8377479910850525
recon_loss: 0.027397096157073975, dist_loss: 0.7245419025421143
recon_loss: 0.02739684283733368, dist_loss: 0.5661876201629639
recon_loss: 0.027396520599722862, dist_loss: 0.3246794641017914
recon_loss: 0.027396339923143387, dist_loss: 0.6543219685554504
recon_loss: 0.027396423742175102, dist_loss: 0.8833591341972351
recon_loss: 0.027396706864237785, dist_loss: 0.6156612634658813
recon_loss: 0.027396658435463905, dist_loss: 0.5149675607681274
recon_loss: 0.027396827936172485, dist_loss: 0.9227973222732544
recon_loss: 0.027397096157073975, dist_loss: 0.6719115972518921
recon_loss: 0.02739829197525978, dist_loss: 0.5694924592971802
recon_loss: 0.027398942038416862, dist_loss: 0.9609874486923218
recon_loss: 0.027399759739637375, dist_loss: 0.8703685402870178
recon_loss: 0.027401069179177284, dist_loss: 0.5040405988693237
recon_loss: 0.027401724830269814, dist_loss: 0.9255866408348083
recon_loss: 0.027402449399232864, dist_loss: 0.854056179523468
recon_loss: 0.02740269899368286, dist_loss: 0.7582970261573792
recon_loss: 0.027403417974710464, dist_loss: 0.7258868217468262
recon_loss: 0.027402127161622047, dist_loss: 0.6039918065071106
recon_loss: 0.02740158513188362, dist_loss: 0.5339640974998474
recon_loss: 0.027401037514209747, dist_loss: 0.8014625906944275
recon_loss: 0.027400627732276917, dist_loss: 0.9162732362747192
recon_loss: 0.027400584891438484, dist_loss: 0.7092817425727844
recon_loss: 0.027399959042668343, dist_loss: 0.8020238280296326
recon_loss: 0.027400221675634384, dist_loss: 0.5146721601486206
recon_loss: 0.02739979885518551, dist_loss: 0.7098386287689209
recon_loss: 0.02740044705569744, dist_loss: 0.3839968144893646
recon_loss: 0.02740062028169632, dist_loss: 0.87919020652771
recon_loss: 0.027401359751820564, dist_loss: 0.9737553596496582
recon_loss: 0.02740192972123623, dist_loss: 0.96089768409729
recon_loss: 0.02740168198943138, dist_loss: 0.4146779775619507
recon_loss: 0.027401834726333618, dist_loss: 0.5049651861190796
recon_loss: 0.027401266619563103, dist_loss: 0.43876364827156067
recon_loss: 0.027401361614465714, dist_loss: 1.0318371057510376
recon_loss: 0.027401233091950417, dist_loss: 0.6751771569252014
recon_loss: 0.02740067057311535, dist_loss: 0.5267800092697144
recon_loss: 0.02739962562918663, dist_loss: 0.552918553352356
recon_loss: 0.02739853598177433, dist_loss: 0.822295606136322
recon_loss: 0.027397794649004936, dist_loss: 0.2724711298942566
recon_loss: 0.027397705242037773, dist_loss: 0.4638326168060303
recon_loss: 0.02739795297384262, dist_loss: 0.6042213439941406
recon_loss: 0.02739855647087097, dist_loss: 0.8904855847358704
recon_loss: 0.027399713173508644, dist_loss: 0.6818231344223022
recon_loss: 0.027401311323046684, dist_loss: 0.9740254878997803
recon_loss: 0.027400726452469826, dist_loss: 0.45205432176589966
recon_loss: 0.027400869876146317, dist_loss: 0.5510879755020142
recon_loss: 0.02740088291466236, dist_loss: 0.8374569416046143
recon_loss: 0.02740023285150528, dist_loss: 0.542304277420044
recon_loss: 0.027400486171245575, dist_loss: 1.0291123390197754
recon_loss: 0.027399791404604912, dist_loss: 1.0708565711975098
recon_loss: 0.027400201186537743, dist_loss: 0.7366717457771301
recon_loss: 0.027399681508541107, dist_loss: 0.7619359493255615
recon_loss: 0.027399545535445213, dist_loss: 0.41065889596939087
recon_loss: 0.02739918790757656, dist_loss: 0.4324994683265686
recon_loss: 0.02739815041422844, dist_loss: 0.7669023871421814
recon_loss: 0.027397403493523598, dist_loss: 0.7552348375320435
recon_loss: 0.02739674225449562, dist_loss: 0.7805793285369873
recon_loss: 0.027397362515330315, dist_loss: 0.882595956325531
recon_loss: 0.02739645354449749, dist_loss: 0.5714982748031616
recon_loss: 0.02739809826016426, dist_loss: 0.5891216397285461
recon_loss: 0.027397140860557556, dist_loss: 0.5667324662208557
recon_loss: 0.027398988604545593, dist_loss: 0.6732099056243896
recon_loss: 0.027398189529776573, dist_loss: 1.246586561203003
recon_loss: 0.027399588376283646, dist_loss: 0.8414736390113831
recon_loss: 0.027401002123951912, dist_loss: 0.48224395513534546
recon_loss: 0.027401676401495934, dist_loss: 0.4218500554561615
recon_loss: 0.02740241214632988, dist_loss: 0.7753880023956299
recon_loss: 0.02740154042840004, dist_loss: 0.6037688255310059
recon_loss: 0.027400203049182892, dist_loss: 0.4722649157047272
recon_loss: 0.027398142963647842, dist_loss: 0.6064736843109131
recon_loss: 0.027397064492106438, dist_loss: 0.5397320985794067
recon_loss: 0.027395596727728844, dist_loss: 0.5418370962142944
recon_loss: 0.02739514410495758, dist_loss: 0.4380106031894684
recon_loss: 0.027394548058509827, dist_loss: 0.6020141839981079
recon_loss: 0.02739410474896431, dist_loss: 0.538852870464325
recon_loss: 0.027394253760576248, dist_loss: 0.42018288373947144
recon_loss: 0.02739451266825199, dist_loss: 0.6911807060241699
recon_loss: 0.02739466167986393, dist_loss: 0.9336934089660645
recon_loss: 0.027394425123929977, dist_loss: 0.5343267917633057
recon_loss: 0.02739439345896244, dist_loss: 0.8492786288261414
recon_loss: 0.027394602075219154, dist_loss: 0.8717745542526245
recon_loss: 0.027394676581025124, dist_loss: 0.6313966512680054
recon_loss: 0.027394279837608337, dist_loss: 0.5361560583114624
recon_loss: 0.027393680065870285, dist_loss: 0.8381983637809753
recon_loss: 0.027393095195293427, dist_loss: 0.6248252391815186
recon_loss: 0.02739299274981022, dist_loss: 0.8475508689880371
recon_loss: 0.02739272266626358, dist_loss: 0.6710689067840576
recon_loss: 0.02739277295768261, dist_loss: 0.3724955916404724
Pre-training Epoch 106:  74%|███████▍  | 272/367 [00:01<00:00, 134.13it/s]Pre-training Epoch 106:  78%|███████▊  | 288/367 [00:01<00:00, 139.24it/s]Pre-training Epoch 106:  83%|████████▎ | 304/367 [00:02<00:00, 143.73it/s]Pre-training Epoch 106:  87%|████████▋ | 320/367 [00:02<00:00, 147.31it/s]Pre-training Epoch 106:  92%|█████████▏| 336/367 [00:02<00:00, 149.98it/s]Pre-training Epoch 106:  96%|█████████▌| 352/367 [00:02<00:00, 148.93it/s]Pre-training Epoch 106: 100%|██████████| 367/367 [00:02<00:00, 146.43it/s]
recon_loss: 0.02739253081381321, dist_loss: 0.6431214213371277
recon_loss: 0.027392642572522163, dist_loss: 1.0223321914672852
recon_loss: 0.027392078191041946, dist_loss: 0.3269832730293274
recon_loss: 0.027392029762268066, dist_loss: 0.4376412332057953
recon_loss: 0.027391521260142326, dist_loss: 0.437323659658432
recon_loss: 0.027391426265239716, dist_loss: 0.6210376620292664
recon_loss: 0.02739148959517479, dist_loss: 0.3789106011390686
recon_loss: 0.027391770854592323, dist_loss: 0.5116692781448364
recon_loss: 0.027392078191041946, dist_loss: 0.5576648116111755
recon_loss: 0.027392735704779625, dist_loss: 0.8225229978561401
recon_loss: 0.027392759919166565, dist_loss: 0.941114068031311
recon_loss: 0.02739204652607441, dist_loss: 0.6857284307479858
recon_loss: 0.02739146165549755, dist_loss: 0.5253528952598572
recon_loss: 0.027391312643885612, dist_loss: 1.379764437675476
recon_loss: 0.027391260489821434, dist_loss: 0.2690848112106323
recon_loss: 0.027390770614147186, dist_loss: 0.5717284679412842
recon_loss: 0.02739124931395054, dist_loss: 0.6718220710754395
recon_loss: 0.027391036972403526, dist_loss: 1.1256358623504639
recon_loss: 0.027392089366912842, dist_loss: 0.6589159965515137
recon_loss: 0.02739136666059494, dist_loss: 0.6908217668533325
recon_loss: 0.027391493320465088, dist_loss: 0.5037589073181152
recon_loss: 0.02739131636917591, dist_loss: 0.7909743785858154
recon_loss: 0.027391625568270683, dist_loss: 0.873031735420227
recon_loss: 0.027391673997044563, dist_loss: 0.9408256411552429
recon_loss: 0.02739235758781433, dist_loss: 0.637235164642334
recon_loss: 0.02739276923239231, dist_loss: 0.5141454935073853
recon_loss: 0.027392543852329254, dist_loss: 0.7705454230308533
recon_loss: 0.02739216573536396, dist_loss: 0.5223740339279175
recon_loss: 0.02739117480814457, dist_loss: 0.6856347918510437
recon_loss: 0.027391094714403152, dist_loss: 0.8929898738861084
recon_loss: 0.027390839532017708, dist_loss: 0.9376524686813354
recon_loss: 0.027390677481889725, dist_loss: 0.4258989691734314
recon_loss: 0.02739091031253338, dist_loss: 0.7384191751480103
recon_loss: 0.027390819042921066, dist_loss: 0.49825578927993774
recon_loss: 0.02739119902253151, dist_loss: 0.9511963725090027
recon_loss: 0.02739153802394867, dist_loss: 0.6138307452201843
recon_loss: 0.02739148959517479, dist_loss: 0.8074162602424622
recon_loss: 0.027392756193876266, dist_loss: 0.7675371170043945
recon_loss: 0.027393095195293427, dist_loss: 0.6919921636581421
recon_loss: 0.027394291013479233, dist_loss: 0.4168471097946167
recon_loss: 0.02739495411515236, dist_loss: 0.7126094698905945
recon_loss: 0.02739436738193035, dist_loss: 0.7956047058105469
recon_loss: 0.027393126860260963, dist_loss: 1.0547211170196533
recon_loss: 0.027392316609621048, dist_loss: 0.48549824953079224
recon_loss: 0.027391379699110985, dist_loss: 0.6243469715118408
recon_loss: 0.027390871196985245, dist_loss: 0.6242144107818604
recon_loss: 0.02739083394408226, dist_loss: 0.48327943682670593
recon_loss: 0.02739104814827442, dist_loss: 0.6014397144317627
recon_loss: 0.027390997856855392, dist_loss: 0.34015679359436035
recon_loss: 0.02739083021879196, dist_loss: 0.7194079160690308
recon_loss: 0.027390966191887856, dist_loss: 0.7447221279144287
recon_loss: 0.027391284704208374, dist_loss: 0.7928643226623535
recon_loss: 0.027391653507947922, dist_loss: 0.719741702079773
recon_loss: 0.027392325922846794, dist_loss: 1.0657835006713867
recon_loss: 0.027393445372581482, dist_loss: 0.4285529851913452
recon_loss: 0.027394725009799004, dist_loss: 0.5633186101913452
recon_loss: 0.027396760880947113, dist_loss: 0.5083097219467163
recon_loss: 0.027397729456424713, dist_loss: 0.42797237634658813
recon_loss: 0.02739916555583477, dist_loss: 0.42652881145477295
recon_loss: 0.027398912236094475, dist_loss: 0.5090028643608093
recon_loss: 0.02739795297384262, dist_loss: 1.0425218343734741
recon_loss: 0.02739645354449749, dist_loss: 0.8295962810516357
recon_loss: 0.027394693344831467, dist_loss: 0.9060525298118591
recon_loss: 0.027393337339162827, dist_loss: 0.5179468393325806
recon_loss: 0.027392685413360596, dist_loss: 0.5575934052467346
recon_loss: 0.027391359210014343, dist_loss: 0.6305475831031799
recon_loss: 0.027391966432332993, dist_loss: 0.8527426719665527
recon_loss: 0.027391569688916206, dist_loss: 1.237344741821289
recon_loss: 0.027392571792006493, dist_loss: 0.709761381149292
recon_loss: 0.027394093573093414, dist_loss: 0.3688737154006958
recon_loss: 0.02739431895315647, dist_loss: 0.48704561591148376
recon_loss: 0.027395719662308693, dist_loss: 0.5868225693702698
recon_loss: 0.027396399527788162, dist_loss: 0.4675827622413635
recon_loss: 0.02739739790558815, dist_loss: 0.5402315855026245
recon_loss: 0.02739712782204151, dist_loss: 0.8462332487106323
recon_loss: 0.027396004647016525, dist_loss: 0.7273315787315369
recon_loss: 0.02739500068128109, dist_loss: 0.5072705745697021
recon_loss: 0.027393966913223267, dist_loss: 0.7593704462051392
recon_loss: 0.027393553406000137, dist_loss: 0.43725553154945374
recon_loss: 0.027393490076065063, dist_loss: 0.39976966381073
recon_loss: 0.0273937676101923, dist_loss: 0.56611168384552
recon_loss: 0.02739318646490574, dist_loss: 0.7602800130844116
recon_loss: 0.027393698692321777, dist_loss: 0.403714120388031
recon_loss: 0.02739277109503746, dist_loss: 0.4404839873313904
recon_loss: 0.027393437922000885, dist_loss: 0.4989144802093506
recon_loss: 0.02739192172884941, dist_loss: 0.5535963177680969
recon_loss: 0.02739265374839306, dist_loss: 0.3272859454154968
recon_loss: 0.02739093080163002, dist_loss: 0.60419100522995
recon_loss: 0.027390997856855392, dist_loss: 1.2426785230636597
recon_loss: 0.027389798313379288, dist_loss: 0.5402440428733826
recon_loss: 0.02738961949944496, dist_loss: 0.7590664625167847
recon_loss: 0.027389787137508392, dist_loss: 0.533050000667572
recon_loss: 0.027388660237193108, dist_loss: 0.5289347171783447
recon_loss: 0.027389682829380035, dist_loss: 0.5776442885398865
recon_loss: 0.0273875892162323, dist_loss: 0.4415520131587982
recon_loss: 0.02738877572119236, dist_loss: 0.8659365773200989
recon_loss: 0.027387237176299095, dist_loss: 0.6400395631790161
recon_loss: 0.02738780900835991, dist_loss: 0.7986960411071777
recon_loss: 0.0273872222751379, dist_loss: 0.5331827402114868
recon_loss: 0.02738797850906849, dist_loss: 0.6695562601089478
recon_loss: 0.027388427406549454, dist_loss: 0.6473843455314636
recon_loss: 0.0273885615170002, dist_loss: 0.4489537179470062
recon_loss: 0.027389569208025932, dist_loss: 0.7433769702911377
recon_loss: 0.027389395982027054, dist_loss: 0.4646812081336975
recon_loss: 0.02738982066512108, dist_loss: 0.5168907046318054
recon_loss: 0.027389585971832275, dist_loss: 0.6945106387138367
recon_loss: 0.027389444410800934, dist_loss: 1.0543668270111084
recon_loss: 0.027389172464609146, dist_loss: 0.5920373201370239
recon_loss: 0.02738877758383751, dist_loss: 0.9019504189491272
recon_loss: 0.027388185262680054, dist_loss: 0.5734972357749939
recon_loss: 0.027387650683522224, dist_loss: 1.2659395933151245
Pre-training Epoch 107:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 107:   4%|▍         | 14/367 [00:00<00:02, 136.51it/s]Pre-training Epoch 107:   8%|▊         | 29/367 [00:00<00:02, 139.03it/s]Pre-training Epoch 107:  12%|█▏        | 45/367 [00:00<00:02, 141.12it/s]Pre-training Epoch 107:  16%|█▋        | 60/367 [00:00<00:02, 140.73it/s]Pre-training Epoch 107:  21%|██        | 76/367 [00:00<00:02, 141.47it/s]Pre-training Epoch 107:  25%|██▌       | 92/367 [00:00<00:01, 142.57it/s]Pre-training Epoch 107:  29%|██▉       | 107/367 [00:00<00:01, 143.61it/s]Pre-training Epoch 107:  33%|███▎      | 122/367 [00:00<00:01, 142.37it/s]recon_loss: 0.027387946844100952, dist_loss: 0.49393072724342346
recon_loss: 0.027388930320739746, dist_loss: 0.29489341378211975
recon_loss: 0.02739025466144085, dist_loss: 0.5932086706161499
recon_loss: 0.02739090658724308, dist_loss: 0.8727204203605652
recon_loss: 0.027391336858272552, dist_loss: 0.5819414854049683
recon_loss: 0.027390727773308754, dist_loss: 0.7589694261550903
recon_loss: 0.02739044278860092, dist_loss: 0.5572521686553955
recon_loss: 0.02739068865776062, dist_loss: 0.7333520650863647
recon_loss: 0.027390673756599426, dist_loss: 0.9970721006393433
recon_loss: 0.027390984818339348, dist_loss: 0.5568731427192688
recon_loss: 0.027390992268919945, dist_loss: 0.8469842672348022
recon_loss: 0.02739124186336994, dist_loss: 0.6860994100570679
recon_loss: 0.02739097736775875, dist_loss: 0.767155110836029
recon_loss: 0.027390357106924057, dist_loss: 0.5520504713058472
recon_loss: 0.02738986536860466, dist_loss: 0.5757018327713013
recon_loss: 0.027389060705900192, dist_loss: 0.6911396980285645
recon_loss: 0.0273883119225502, dist_loss: 0.7192980051040649
recon_loss: 0.02738778106868267, dist_loss: 0.7069700360298157
recon_loss: 0.027387317270040512, dist_loss: 0.7203727960586548
recon_loss: 0.027387220412492752, dist_loss: 0.5146979093551636
recon_loss: 0.027387507259845734, dist_loss: 1.0186903476715088
recon_loss: 0.02738850750029087, dist_loss: 0.4211729168891907
recon_loss: 0.027390222996473312, dist_loss: 0.353330135345459
recon_loss: 0.027391009032726288, dist_loss: 0.6175696849822998
recon_loss: 0.027391616255044937, dist_loss: 0.6181529760360718
recon_loss: 0.027392273768782616, dist_loss: 0.4322850704193115
recon_loss: 0.027391765266656876, dist_loss: 0.5339652895927429
recon_loss: 0.027390625327825546, dist_loss: 0.6915523409843445
recon_loss: 0.02738937735557556, dist_loss: 0.8807821869850159
recon_loss: 0.02738809958100319, dist_loss: 0.6532831192016602
recon_loss: 0.027387795969843864, dist_loss: 0.4918292164802551
recon_loss: 0.027386795729398727, dist_loss: 0.5567705631256104
recon_loss: 0.027386656031012535, dist_loss: 0.5714804530143738
recon_loss: 0.027386216446757317, dist_loss: 0.6699420213699341
recon_loss: 0.027386143803596497, dist_loss: 0.79666668176651
recon_loss: 0.027386723086237907, dist_loss: 0.5655748844146729
recon_loss: 0.027385706081986427, dist_loss: 0.425030916929245
recon_loss: 0.02738581970334053, dist_loss: 0.8260680437088013
recon_loss: 0.027384627610445023, dist_loss: 0.43861672282218933
recon_loss: 0.027384694665670395, dist_loss: 0.5277020931243896
recon_loss: 0.027383917942643166, dist_loss: 0.3829954266548157
recon_loss: 0.02738375775516033, dist_loss: 0.6668331027030945
recon_loss: 0.02738373354077339, dist_loss: 0.713513970375061
recon_loss: 0.027383185923099518, dist_loss: 1.0433250665664673
recon_loss: 0.027383945882320404, dist_loss: 0.30163174867630005
recon_loss: 0.027383405715227127, dist_loss: 0.6040166616439819
recon_loss: 0.027384085580706596, dist_loss: 0.6450495719909668
recon_loss: 0.02738305740058422, dist_loss: 0.49130985140800476
recon_loss: 0.02738361433148384, dist_loss: 0.6879138946533203
recon_loss: 0.027383046224713326, dist_loss: 0.3342365026473999
recon_loss: 0.027383990585803986, dist_loss: 0.78570556640625
recon_loss: 0.027383897453546524, dist_loss: 0.7121483087539673
recon_loss: 0.027383919805288315, dist_loss: 0.49433934688568115
recon_loss: 0.027384474873542786, dist_loss: 0.8134564757347107
recon_loss: 0.027384448796510696, dist_loss: 0.31282690167427063
recon_loss: 0.027385758236050606, dist_loss: 1.0481116771697998
recon_loss: 0.027386033907532692, dist_loss: 0.41620177030563354
recon_loss: 0.02738831378519535, dist_loss: 0.4527188241481781
recon_loss: 0.02738785557448864, dist_loss: 0.644254207611084
recon_loss: 0.027388179674744606, dist_loss: 0.6556503772735596
recon_loss: 0.02738647721707821, dist_loss: 0.7218285799026489
recon_loss: 0.02738620527088642, dist_loss: 0.7990109324455261
recon_loss: 0.027385331690311432, dist_loss: 0.583498477935791
recon_loss: 0.027385657653212547, dist_loss: 0.7663315534591675
recon_loss: 0.027386553585529327, dist_loss: 0.5636062622070312
recon_loss: 0.027387671172618866, dist_loss: 0.9718371629714966
recon_loss: 0.027388643473386765, dist_loss: 0.7615885734558105
recon_loss: 0.02738933078944683, dist_loss: 0.5413969159126282
recon_loss: 0.02738911099731922, dist_loss: 0.6187574863433838
recon_loss: 0.027389297261834145, dist_loss: 0.5505998730659485
recon_loss: 0.027389347553253174, dist_loss: 0.6633327007293701
recon_loss: 0.027389390394091606, dist_loss: 0.35456231236457825
recon_loss: 0.027388619258999825, dist_loss: 1.191825032234192
recon_loss: 0.02738727442920208, dist_loss: 0.46971118450164795
recon_loss: 0.027386758476495743, dist_loss: 0.6465137004852295
recon_loss: 0.027387497946619987, dist_loss: 0.37773647904396057
recon_loss: 0.027386510744690895, dist_loss: 0.6690179109573364
recon_loss: 0.027386503294110298, dist_loss: 0.8483730554580688
recon_loss: 0.0273860115557909, dist_loss: 0.4236779510974884
recon_loss: 0.02738550677895546, dist_loss: 1.0019989013671875
recon_loss: 0.027384717017412186, dist_loss: 0.55966717004776
recon_loss: 0.027384696528315544, dist_loss: 0.6071749925613403
recon_loss: 0.027385203167796135, dist_loss: 0.5696887373924255
recon_loss: 0.027386439964175224, dist_loss: 0.46898573637008667
recon_loss: 0.02738821879029274, dist_loss: 0.8089873194694519
recon_loss: 0.02738768607378006, dist_loss: 0.5848835706710815
recon_loss: 0.02738938294351101, dist_loss: 0.5510814189910889
recon_loss: 0.02738887071609497, dist_loss: 0.8402128219604492
recon_loss: 0.027390500530600548, dist_loss: 0.6643596887588501
recon_loss: 0.027390196919441223, dist_loss: 0.5553334951400757
recon_loss: 0.027390409260988235, dist_loss: 0.6780716180801392
recon_loss: 0.027389653027057648, dist_loss: 0.6555550694465637
recon_loss: 0.02738913521170616, dist_loss: 0.3399691879749298
recon_loss: 0.027388926595449448, dist_loss: 1.1018307209014893
recon_loss: 0.02738799899816513, dist_loss: 0.846853494644165
recon_loss: 0.027388716116547585, dist_loss: 1.215203881263733
recon_loss: 0.02738756127655506, dist_loss: 0.5968667268753052
recon_loss: 0.027387481182813644, dist_loss: 0.79093337059021
recon_loss: 0.027386361733078957, dist_loss: 0.6383810639381409
recon_loss: 0.027386045083403587, dist_loss: 0.5293588042259216
recon_loss: 0.027385782450437546, dist_loss: 0.350581556558609
recon_loss: 0.02738504856824875, dist_loss: 0.6086511611938477
recon_loss: 0.027385497465729713, dist_loss: 0.7196075916290283
recon_loss: 0.027385296300053596, dist_loss: 0.6678474545478821
recon_loss: 0.027386685833334923, dist_loss: 0.4397086501121521
recon_loss: 0.02738594450056553, dist_loss: 0.4017755091190338
recon_loss: 0.027387110516428947, dist_loss: 0.38251298666000366
recon_loss: 0.02738582156598568, dist_loss: 0.8269745707511902
recon_loss: 0.027386821806430817, dist_loss: 0.7819887399673462
recon_loss: 0.027385316789150238, dist_loss: 0.6852676272392273
recon_loss: 0.027385102584958076, dist_loss: 0.6519541144371033
recon_loss: 0.027384789660573006, dist_loss: 0.9440405964851379
recon_loss: 0.027383163571357727, dist_loss: 1.1433422565460205
recon_loss: 0.027384687215089798, dist_loss: 0.39671242237091064
recon_loss: 0.027383429929614067, dist_loss: 0.5318332314491272
recon_loss: 0.02738546021282673, dist_loss: 0.38045960664749146
recon_loss: 0.027384750545024872, dist_loss: 0.5537334680557251
recon_loss: 0.02738649956882, dist_loss: 1.2660362720489502
recon_loss: 0.027385998517274857, dist_loss: 0.9130061864852905
recon_loss: 0.027385888621211052, dist_loss: 0.570287823677063
recon_loss: 0.027385685592889786, dist_loss: 0.5260452032089233
recon_loss: 0.027384739369153976, dist_loss: 0.5493685007095337
recon_loss: 0.027384387329220772, dist_loss: 0.685614824295044
recon_loss: 0.027382932603359222, dist_loss: 0.7101883888244629
recon_loss: 0.02738272398710251, dist_loss: 0.6693183183670044
recon_loss: 0.02738204039633274, dist_loss: 0.5775327086448669
recon_loss: 0.027382178232073784, dist_loss: 0.6123266816139221
recon_loss: 0.027381792664527893, dist_loss: 0.5303961038589478
Pre-training Epoch 107:  37%|███▋      | 137/367 [00:00<00:01, 134.34it/s]Pre-training Epoch 107:  41%|████      | 151/367 [00:01<00:01, 130.99it/s]Pre-training Epoch 107:  45%|████▍     | 165/367 [00:01<00:01, 131.68it/s]Pre-training Epoch 107:  49%|████▉     | 179/367 [00:01<00:01, 131.11it/s]Pre-training Epoch 107:  53%|█████▎    | 193/367 [00:01<00:01, 129.94it/s]Pre-training Epoch 107:  56%|█████▋    | 207/367 [00:01<00:01, 128.64it/s]Pre-training Epoch 107:  60%|█████▉    | 220/367 [00:01<00:01, 128.17it/s]Pre-training Epoch 107:  64%|██████▍   | 234/367 [00:01<00:01, 128.03it/s]Pre-training Epoch 107:  68%|██████▊   | 249/367 [00:01<00:00, 132.47it/s]recon_loss: 0.0273818988353014, dist_loss: 0.5583983063697815
recon_loss: 0.027381328865885735, dist_loss: 0.49198079109191895
recon_loss: 0.02738059312105179, dist_loss: 0.46658870577812195
recon_loss: 0.027380313724279404, dist_loss: 0.8169817924499512
recon_loss: 0.027380311861634254, dist_loss: 0.869232177734375
recon_loss: 0.027380768209695816, dist_loss: 0.6370227932929993
recon_loss: 0.02738078497350216, dist_loss: 1.420132040977478
recon_loss: 0.02738158591091633, dist_loss: 1.0589580535888672
recon_loss: 0.02738279104232788, dist_loss: 0.4109695255756378
recon_loss: 0.02738376148045063, dist_loss: 1.1308703422546387
recon_loss: 0.027384186163544655, dist_loss: 0.6707693338394165
recon_loss: 0.027383994311094284, dist_loss: 0.5844120979309082
recon_loss: 0.027384234592318535, dist_loss: 0.43991947174072266
recon_loss: 0.02738375775516033, dist_loss: 0.539329469203949
recon_loss: 0.027384690940380096, dist_loss: 0.6117233633995056
recon_loss: 0.027384476736187935, dist_loss: 0.6145840883255005
recon_loss: 0.027384238317608833, dist_loss: 0.9902806878089905
recon_loss: 0.02738342247903347, dist_loss: 0.5983433723449707
recon_loss: 0.02738281711935997, dist_loss: 0.5330032110214233
recon_loss: 0.027383899316191673, dist_loss: 0.32398131489753723
recon_loss: 0.02738318406045437, dist_loss: 0.8167839050292969
recon_loss: 0.027383113279938698, dist_loss: 0.8905872106552124
recon_loss: 0.027382561936974525, dist_loss: 0.6456383466720581
recon_loss: 0.027382325381040573, dist_loss: 0.4042949378490448
recon_loss: 0.02738202176988125, dist_loss: 0.4903847575187683
recon_loss: 0.027381617575883865, dist_loss: 0.4495454430580139
recon_loss: 0.02738133817911148, dist_loss: 0.5664175748825073
recon_loss: 0.027381090447306633, dist_loss: 0.6686718463897705
recon_loss: 0.027380837127566338, dist_loss: 0.7755634188652039
recon_loss: 0.02738071419298649, dist_loss: 0.6830718517303467
recon_loss: 0.027380507439374924, dist_loss: 0.6395530700683594
recon_loss: 0.027380986139178276, dist_loss: 0.5831865072250366
recon_loss: 0.027381563559174538, dist_loss: 0.7032464742660522
recon_loss: 0.027382584288716316, dist_loss: 0.5857702493667603
recon_loss: 0.027384111657738686, dist_loss: 0.480085164308548
recon_loss: 0.027384163811802864, dist_loss: 0.4650462865829468
recon_loss: 0.027384256944060326, dist_loss: 0.5366683006286621
recon_loss: 0.02738373726606369, dist_loss: 0.7976352572441101
recon_loss: 0.027383288368582726, dist_loss: 0.39740389585494995
recon_loss: 0.02738306298851967, dist_loss: 0.30849123001098633
recon_loss: 0.027382731437683105, dist_loss: 0.8844639658927917
recon_loss: 0.02738228626549244, dist_loss: 0.738693356513977
recon_loss: 0.027381855994462967, dist_loss: 0.5911887884140015
recon_loss: 0.027380209416151047, dist_loss: 0.6498318314552307
recon_loss: 0.027380025014281273, dist_loss: 0.33925750851631165
recon_loss: 0.027379678562283516, dist_loss: 1.2438498735427856
recon_loss: 0.027381854131817818, dist_loss: 0.8858934640884399
recon_loss: 0.027382951229810715, dist_loss: 0.674407958984375
recon_loss: 0.027384402230381966, dist_loss: 0.8459541201591492
recon_loss: 0.027385113760828972, dist_loss: 0.5651212334632874
recon_loss: 0.027384914457798004, dist_loss: 0.4796323776245117
recon_loss: 0.027384676039218903, dist_loss: 0.6289881467819214
recon_loss: 0.02738432213664055, dist_loss: 0.3901398479938507
recon_loss: 0.027384988963603973, dist_loss: 0.6771503686904907
recon_loss: 0.0273840744048357, dist_loss: 0.5400850176811218
recon_loss: 0.027385259047150612, dist_loss: 0.7549715042114258
recon_loss: 0.027384839951992035, dist_loss: 0.7716946005821228
recon_loss: 0.02738526463508606, dist_loss: 0.2942856550216675
recon_loss: 0.027385693043470383, dist_loss: 0.36189430952072144
recon_loss: 0.02738555707037449, dist_loss: 0.49204540252685547
recon_loss: 0.02738518826663494, dist_loss: 0.5707765817642212
recon_loss: 0.027383670210838318, dist_loss: 0.8296934366226196
recon_loss: 0.02738245017826557, dist_loss: 1.1341025829315186
recon_loss: 0.027381204068660736, dist_loss: 0.26743921637535095
recon_loss: 0.027380291372537613, dist_loss: 1.0104981660842896
recon_loss: 0.027379535138607025, dist_loss: 0.6689199209213257
recon_loss: 0.02737913839519024, dist_loss: 0.4508085548877716
recon_loss: 0.0273787472397089, dist_loss: 0.7112011909484863
recon_loss: 0.027378462255001068, dist_loss: 0.343845933675766
recon_loss: 0.027378162369132042, dist_loss: 0.6325515508651733
recon_loss: 0.027378041297197342, dist_loss: 0.5657879710197449
recon_loss: 0.027377882972359657, dist_loss: 0.4002102315425873
recon_loss: 0.027377745136618614, dist_loss: 0.29307931661605835
recon_loss: 0.027377674356102943, dist_loss: 0.7179331183433533
recon_loss: 0.02737794816493988, dist_loss: 0.9441782236099243
recon_loss: 0.027377871796488762, dist_loss: 0.4835359454154968
recon_loss: 0.027377914637327194, dist_loss: 0.9298645257949829
recon_loss: 0.02737797610461712, dist_loss: 0.5782808065414429
recon_loss: 0.027376726269721985, dist_loss: 1.2144484519958496
recon_loss: 0.02737710438668728, dist_loss: 0.4961076080799103
recon_loss: 0.027376046404242516, dist_loss: 1.111252784729004
recon_loss: 0.027376700192689896, dist_loss: 0.5643103122711182
recon_loss: 0.02737586572766304, dist_loss: 0.514593243598938
recon_loss: 0.027376122772693634, dist_loss: 0.8376252055168152
recon_loss: 0.027375897392630577, dist_loss: 0.6575597524642944
recon_loss: 0.027375735342502594, dist_loss: 0.5026438236236572
recon_loss: 0.027376051992177963, dist_loss: 0.42207735776901245
recon_loss: 0.027375703677535057, dist_loss: 0.34721893072128296
recon_loss: 0.02737618423998356, dist_loss: 0.9778186082839966
recon_loss: 0.027375653386116028, dist_loss: 0.6131677627563477
recon_loss: 0.02737625688314438, dist_loss: 0.4954773783683777
recon_loss: 0.02737615816295147, dist_loss: 0.5872417092323303
recon_loss: 0.027376418933272362, dist_loss: 0.6482781171798706
recon_loss: 0.027376877143979073, dist_loss: 0.39392542839050293
recon_loss: 0.02737695910036564, dist_loss: 1.1981732845306396
recon_loss: 0.027377137914299965, dist_loss: 0.9793413877487183
recon_loss: 0.02737697958946228, dist_loss: 0.8956194519996643
recon_loss: 0.02737683616578579, dist_loss: 1.2174981832504272
recon_loss: 0.027375631034374237, dist_loss: 0.3507955074310303
recon_loss: 0.027376137673854828, dist_loss: 0.6382003426551819
recon_loss: 0.027375128120183945, dist_loss: 0.617517352104187
recon_loss: 0.02737504616379738, dist_loss: 0.4613083600997925
recon_loss: 0.027375057339668274, dist_loss: 0.7848790287971497
recon_loss: 0.02737404778599739, dist_loss: 0.8005890846252441
recon_loss: 0.027374714612960815, dist_loss: 0.9516828060150146
recon_loss: 0.027373652905225754, dist_loss: 0.4550492465496063
recon_loss: 0.027373921126127243, dist_loss: 0.7585874795913696
recon_loss: 0.02737385779619217, dist_loss: 0.6793084144592285
recon_loss: 0.027373656630516052, dist_loss: 0.42734313011169434
recon_loss: 0.027374275028705597, dist_loss: 0.9023022651672363
recon_loss: 0.0273741502314806, dist_loss: 0.5460560917854309
recon_loss: 0.027374841272830963, dist_loss: 0.7754992246627808
recon_loss: 0.027374880388379097, dist_loss: 0.418712854385376
recon_loss: 0.027375593781471252, dist_loss: 1.136032223701477
recon_loss: 0.027375565841794014, dist_loss: 0.47701823711395264
recon_loss: 0.027374835684895515, dist_loss: 0.6497131586074829
recon_loss: 0.027375275269150734, dist_loss: 0.3229074776172638
recon_loss: 0.02737460844218731, dist_loss: 0.5429781675338745
recon_loss: 0.02737508900463581, dist_loss: 0.4840487241744995
recon_loss: 0.027373922988772392, dist_loss: 0.4998413920402527
recon_loss: 0.027373801916837692, dist_loss: 0.5201677680015564
recon_loss: 0.027373353019356728, dist_loss: 0.5361727476119995
recon_loss: 0.027372805401682854, dist_loss: 0.48634132742881775
recon_loss: 0.027373364195227623, dist_loss: 0.7161452770233154
recon_loss: 0.02737291529774666, dist_loss: 0.9332330822944641
recon_loss: 0.027374625205993652, dist_loss: 0.8416357040405273
recon_loss: 0.02737501822412014, dist_loss: 0.576693594455719
recon_loss: 0.027375459671020508, dist_loss: 0.8942963480949402
Pre-training Epoch 107:  72%|███████▏  | 263/367 [00:01<00:00, 129.71it/s]Pre-training Epoch 107:  75%|███████▌  | 277/367 [00:02<00:00, 131.39it/s]Pre-training Epoch 107:  79%|███████▉  | 291/367 [00:02<00:00, 128.02it/s]Pre-training Epoch 107:  83%|████████▎ | 304/367 [00:02<00:00, 126.19it/s]Pre-training Epoch 107:  86%|████████▋ | 317/367 [00:02<00:00, 125.98it/s]Pre-training Epoch 107:  90%|████████▉ | 330/367 [00:02<00:00, 125.30it/s]Pre-training Epoch 107:  93%|█████████▎| 343/367 [00:02<00:00, 124.13it/s]Pre-training Epoch 107:  97%|█████████▋| 357/367 [00:02<00:00, 126.71it/s]Pre-training Epoch 107: 100%|██████████| 367/367 [00:02<00:00, 131.47it/s]
recon_loss: 0.027375472709536552, dist_loss: 0.7059617042541504
recon_loss: 0.02737554907798767, dist_loss: 0.5551537871360779
recon_loss: 0.02737581543624401, dist_loss: 0.8744844198226929
recon_loss: 0.027375834062695503, dist_loss: 0.5732760429382324
recon_loss: 0.027376674115657806, dist_loss: 0.26894694566726685
recon_loss: 0.02737610787153244, dist_loss: 0.995721697807312
recon_loss: 0.027376217767596245, dist_loss: 0.42934155464172363
recon_loss: 0.027375085279345512, dist_loss: 0.4692242741584778
recon_loss: 0.02737445756793022, dist_loss: 0.6843889951705933
recon_loss: 0.02737397700548172, dist_loss: 0.9298072457313538
recon_loss: 0.027373554185032845, dist_loss: 0.9280517101287842
recon_loss: 0.027375061064958572, dist_loss: 0.4705456495285034
recon_loss: 0.02737625315785408, dist_loss: 0.8716347813606262
recon_loss: 0.02737852931022644, dist_loss: 0.44958844780921936
recon_loss: 0.027381137013435364, dist_loss: 0.5540496110916138
recon_loss: 0.027382967993617058, dist_loss: 0.601189136505127
recon_loss: 0.027384847402572632, dist_loss: 0.5058956146240234
recon_loss: 0.027383698150515556, dist_loss: 0.5843543410301208
recon_loss: 0.027382781729102135, dist_loss: 0.36400461196899414
recon_loss: 0.027380796149373055, dist_loss: 0.27634197473526
recon_loss: 0.02737884409725666, dist_loss: 0.6218293905258179
recon_loss: 0.027378078550100327, dist_loss: 0.5376964807510376
recon_loss: 0.027377037331461906, dist_loss: 0.6668427586555481
recon_loss: 0.02737593464553356, dist_loss: 0.5961118936538696
recon_loss: 0.02737538516521454, dist_loss: 0.5062974095344543
recon_loss: 0.027374643832445145, dist_loss: 0.7676770687103271
recon_loss: 0.027373874559998512, dist_loss: 0.3117680549621582
recon_loss: 0.027373535558581352, dist_loss: 0.7978956699371338
recon_loss: 0.027373528108000755, dist_loss: 0.38421109318733215
recon_loss: 0.027373529970645905, dist_loss: 0.562447190284729
recon_loss: 0.02737353928387165, dist_loss: 0.4990522861480713
recon_loss: 0.027373487129807472, dist_loss: 1.117495059967041
recon_loss: 0.027372945100069046, dist_loss: 1.035430908203125
recon_loss: 0.027372483164072037, dist_loss: 0.693078339099884
recon_loss: 0.02737169899046421, dist_loss: 0.422797292470932
recon_loss: 0.027371516451239586, dist_loss: 0.5687246322631836
recon_loss: 0.027371615171432495, dist_loss: 0.5705578327178955
recon_loss: 0.027371320873498917, dist_loss: 1.00388765335083
recon_loss: 0.02737172320485115, dist_loss: 0.8003151416778564
recon_loss: 0.027371980249881744, dist_loss: 0.8532196879386902
recon_loss: 0.02737319841980934, dist_loss: 0.4569515585899353
recon_loss: 0.027373861521482468, dist_loss: 0.611142635345459
recon_loss: 0.027374058961868286, dist_loss: 1.0148439407348633
recon_loss: 0.027374986559152603, dist_loss: 0.6233129501342773
recon_loss: 0.02737634815275669, dist_loss: 0.8550047278404236
recon_loss: 0.027377445250749588, dist_loss: 0.8557209968566895
recon_loss: 0.027378402650356293, dist_loss: 0.6051020622253418
recon_loss: 0.02737824060022831, dist_loss: 0.4920520782470703
recon_loss: 0.027378875762224197, dist_loss: 0.77147376537323
recon_loss: 0.027378452941775322, dist_loss: 1.3088889122009277
recon_loss: 0.027379479259252548, dist_loss: 1.1411542892456055
recon_loss: 0.027380380779504776, dist_loss: 0.49700257182121277
recon_loss: 0.027380550280213356, dist_loss: 0.7035751342773438
recon_loss: 0.027379373088479042, dist_loss: 0.7198010683059692
recon_loss: 0.02737821638584137, dist_loss: 0.5564218759536743
recon_loss: 0.02737773209810257, dist_loss: 0.683332085609436
recon_loss: 0.027378134429454803, dist_loss: 0.2748548984527588
recon_loss: 0.027379460632801056, dist_loss: 1.1257109642028809
recon_loss: 0.02738030254840851, dist_loss: 0.5216186046600342
recon_loss: 0.027381351217627525, dist_loss: 0.30393972992897034
recon_loss: 0.027382133528590202, dist_loss: 0.813833475112915
recon_loss: 0.0273823831230402, dist_loss: 0.7299779653549194
recon_loss: 0.02738252840936184, dist_loss: 0.8702725768089294
recon_loss: 0.02738180384039879, dist_loss: 0.3952757716178894
recon_loss: 0.027380647137761116, dist_loss: 0.49379587173461914
recon_loss: 0.027378639206290245, dist_loss: 0.5461156368255615
recon_loss: 0.027376724407076836, dist_loss: 0.5946084856987
recon_loss: 0.027375658974051476, dist_loss: 0.5884170532226562
recon_loss: 0.027375532314181328, dist_loss: 0.5106964707374573
recon_loss: 0.027374593541026115, dist_loss: 0.35931605100631714
recon_loss: 0.02737465128302574, dist_loss: 0.42013561725616455
recon_loss: 0.027374640107154846, dist_loss: 0.44365474581718445
recon_loss: 0.02737443521618843, dist_loss: 0.8909540176391602
recon_loss: 0.027374213561415672, dist_loss: 0.6049466133117676
recon_loss: 0.027373451739549637, dist_loss: 0.8681338429450989
recon_loss: 0.027373474091291428, dist_loss: 0.5430196523666382
recon_loss: 0.02737276442348957, dist_loss: 0.7502096891403198
recon_loss: 0.02737186662852764, dist_loss: 0.7114586234092712
recon_loss: 0.02737087570130825, dist_loss: 1.030163288116455
recon_loss: 0.027370240539312363, dist_loss: 0.4784867763519287
recon_loss: 0.027370046824216843, dist_loss: 0.7833045721054077
recon_loss: 0.027369866147637367, dist_loss: 0.8744935393333435
recon_loss: 0.02736993134021759, dist_loss: 0.7560799717903137
recon_loss: 0.02737019583582878, dist_loss: 0.8129258155822754
recon_loss: 0.02737046405673027, dist_loss: 0.47665897011756897
recon_loss: 0.02737060748040676, dist_loss: 0.5346530675888062
recon_loss: 0.027371063828468323, dist_loss: 0.2544250786304474
recon_loss: 0.02737143635749817, dist_loss: 0.9416739344596863
recon_loss: 0.027372820302844048, dist_loss: 0.35809892416000366
recon_loss: 0.02737395279109478, dist_loss: 0.46130573749542236
recon_loss: 0.027374302968382835, dist_loss: 0.6108965873718262
recon_loss: 0.027374576777219772, dist_loss: 0.847112774848938
recon_loss: 0.02737412229180336, dist_loss: 0.47069457173347473
recon_loss: 0.02737381123006344, dist_loss: 0.7165505886077881
recon_loss: 0.02737283520400524, dist_loss: 0.35400235652923584
recon_loss: 0.02737167477607727, dist_loss: 0.9277276992797852
recon_loss: 0.02737102471292019, dist_loss: 0.5445152521133423
recon_loss: 0.027370568364858627, dist_loss: 0.6898723840713501
recon_loss: 0.02737008035182953, dist_loss: 0.8418302536010742
recon_loss: 0.027369320392608643, dist_loss: 0.6423912644386292
recon_loss: 0.027368975803256035, dist_loss: 0.8145501613616943
recon_loss: 0.027368713170289993, dist_loss: 0.7041060328483582
recon_loss: 0.027369920164346695, dist_loss: 0.4793270230293274
recon_loss: 0.027369996532797813, dist_loss: 0.4948328733444214
recon_loss: 0.02737124264240265, dist_loss: 0.555982232093811
recon_loss: 0.02737273834645748, dist_loss: 0.6946794986724854
recon_loss: 0.027374694123864174, dist_loss: 0.5014771819114685
recon_loss: 0.027377208694815636, dist_loss: 1.0701684951782227
recon_loss: 0.0273788720369339, dist_loss: 0.3475569784641266
recon_loss: 0.02738194167613983, dist_loss: 0.5704529285430908
recon_loss: 0.0273823793977499, dist_loss: 0.3536229431629181
Pre-training Epoch 108:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 108:   4%|▍         | 14/367 [00:00<00:02, 125.72it/s]Pre-training Epoch 108:   8%|▊         | 29/367 [00:00<00:02, 136.49it/s]Pre-training Epoch 108:  12%|█▏        | 43/367 [00:00<00:02, 130.24it/s]Pre-training Epoch 108:  16%|█▌        | 57/367 [00:00<00:02, 127.12it/s]Pre-training Epoch 108:  19%|█▉        | 70/367 [00:00<00:02, 126.03it/s]Pre-training Epoch 108:  23%|██▎       | 83/367 [00:00<00:02, 126.59it/s]Pre-training Epoch 108:  26%|██▌       | 96/367 [00:00<00:02, 122.89it/s]Pre-training Epoch 108:  30%|██▉       | 109/367 [00:00<00:02, 122.42it/s]Pre-training Epoch 108:  33%|███▎      | 122/367 [00:00<00:01, 122.99it/s]recon_loss: 0.027385158464312553, dist_loss: 0.5244274139404297
recon_loss: 0.02738494798541069, dist_loss: 0.4868485927581787
recon_loss: 0.027385830879211426, dist_loss: 0.7019475698471069
recon_loss: 0.02738475427031517, dist_loss: 0.5844961404800415
recon_loss: 0.027382750064134598, dist_loss: 0.4261500835418701
recon_loss: 0.027380362153053284, dist_loss: 0.7091004848480225
recon_loss: 0.0273771770298481, dist_loss: 0.7508485317230225
recon_loss: 0.027374867349863052, dist_loss: 0.5972591638565063
recon_loss: 0.02737247385084629, dist_loss: 0.5417703986167908
recon_loss: 0.027372730895876884, dist_loss: 0.7009259462356567
recon_loss: 0.027373965829610825, dist_loss: 0.7752022743225098
recon_loss: 0.027374131605029106, dist_loss: 1.1388827562332153
recon_loss: 0.027376875281333923, dist_loss: 0.2417905181646347
recon_loss: 0.027376804500818253, dist_loss: 0.8285822868347168
recon_loss: 0.027378151193261147, dist_loss: 0.908252477645874
recon_loss: 0.027376700192689896, dist_loss: 0.3510412275791168
recon_loss: 0.027377242222428322, dist_loss: 0.46332603693008423
recon_loss: 0.027376048266887665, dist_loss: 0.6239244937896729
recon_loss: 0.027376588433980942, dist_loss: 0.4621833562850952
recon_loss: 0.027374008670449257, dist_loss: 0.5780404806137085
recon_loss: 0.027373500168323517, dist_loss: 0.4819662868976593
recon_loss: 0.027372166514396667, dist_loss: 0.48539862036705017
recon_loss: 0.02737092599272728, dist_loss: 0.599980354309082
recon_loss: 0.02737056463956833, dist_loss: 1.0045161247253418
recon_loss: 0.027370121330022812, dist_loss: 0.6746846437454224
recon_loss: 0.027370024472475052, dist_loss: 0.4585511386394501
recon_loss: 0.02736915461719036, dist_loss: 0.8405187129974365
recon_loss: 0.027368756011128426, dist_loss: 0.8900831937789917
recon_loss: 0.02736796624958515, dist_loss: 0.5738250613212585
recon_loss: 0.02736756205558777, dist_loss: 0.6154681444168091
recon_loss: 0.027367210015654564, dist_loss: 1.5855686664581299
recon_loss: 0.027368027716875076, dist_loss: 0.6194025278091431
recon_loss: 0.027368692681193352, dist_loss: 0.7508609294891357
recon_loss: 0.027370214462280273, dist_loss: 0.31292593479156494
recon_loss: 0.027370236814022064, dist_loss: 0.9081854820251465
recon_loss: 0.0273690614849329, dist_loss: 0.5893876552581787
recon_loss: 0.027368327602744102, dist_loss: 0.5664296746253967
recon_loss: 0.027367422357201576, dist_loss: 0.5517581701278687
recon_loss: 0.027366794645786285, dist_loss: 0.48540985584259033
recon_loss: 0.027366334572434425, dist_loss: 1.1129425764083862
recon_loss: 0.027366353198885918, dist_loss: 0.8157260417938232
recon_loss: 0.027365855872631073, dist_loss: 0.4525793790817261
recon_loss: 0.027366092428565025, dist_loss: 0.7397810220718384
recon_loss: 0.02736666612327099, dist_loss: 0.9059658050537109
recon_loss: 0.02736707776784897, dist_loss: 0.5786663293838501
recon_loss: 0.0273667611181736, dist_loss: 0.3773219883441925
recon_loss: 0.02736613340675831, dist_loss: 0.4509176015853882
recon_loss: 0.027365511283278465, dist_loss: 0.6176404356956482
recon_loss: 0.027365203946828842, dist_loss: 0.36808764934539795
recon_loss: 0.02736509218811989, dist_loss: 0.6027208566665649
recon_loss: 0.027365000918507576, dist_loss: 0.8671064376831055
recon_loss: 0.02736497111618519, dist_loss: 0.48779013752937317
recon_loss: 0.02736535482108593, dist_loss: 0.4609912931919098
recon_loss: 0.027366062626242638, dist_loss: 0.49261558055877686
recon_loss: 0.027366796508431435, dist_loss: 0.8251969218254089
recon_loss: 0.027366962283849716, dist_loss: 0.5553192496299744
recon_loss: 0.027366623282432556, dist_loss: 0.7295675873756409
recon_loss: 0.027368081733584404, dist_loss: 0.7720063924789429
recon_loss: 0.027368074283003807, dist_loss: 0.27143383026123047
recon_loss: 0.027369577437639236, dist_loss: 0.6674548387527466
recon_loss: 0.02736916020512581, dist_loss: 0.7112617492675781
recon_loss: 0.02736947499215603, dist_loss: 0.8526633977890015
recon_loss: 0.027368444949388504, dist_loss: 1.1450886726379395
recon_loss: 0.02736802212893963, dist_loss: 0.5866861343383789
recon_loss: 0.02736715041100979, dist_loss: 0.5580236911773682
recon_loss: 0.02736523188650608, dist_loss: 0.946492075920105
recon_loss: 0.02736571803689003, dist_loss: 0.5801817178726196
recon_loss: 0.027364779263734818, dist_loss: 0.49031978845596313
recon_loss: 0.027365518733859062, dist_loss: 0.8166853785514832
recon_loss: 0.027365148067474365, dist_loss: 1.1436855792999268
recon_loss: 0.02736545540392399, dist_loss: 0.5679665207862854
recon_loss: 0.027365678921341896, dist_loss: 0.7399964928627014
recon_loss: 0.02736527845263481, dist_loss: 0.9067684412002563
recon_loss: 0.027365030720829964, dist_loss: 0.664833128452301
recon_loss: 0.027364764362573624, dist_loss: 0.2568075656890869
recon_loss: 0.02736464887857437, dist_loss: 0.7616254091262817
recon_loss: 0.027364175766706467, dist_loss: 0.6949582099914551
recon_loss: 0.027363717555999756, dist_loss: 0.8788471817970276
recon_loss: 0.02736336551606655, dist_loss: 0.4345531463623047
recon_loss: 0.02736319601535797, dist_loss: 0.33146145939826965
recon_loss: 0.02736288495361805, dist_loss: 0.39224541187286377
recon_loss: 0.02736268937587738, dist_loss: 0.5802634358406067
recon_loss: 0.02736242115497589, dist_loss: 0.4451131224632263
recon_loss: 0.027362274006009102, dist_loss: 0.5927224159240723
recon_loss: 0.02736242674291134, dist_loss: 0.670815110206604
recon_loss: 0.027361970394849777, dist_loss: 0.668837308883667
recon_loss: 0.02736181579530239, dist_loss: 0.7702822685241699
recon_loss: 0.027361705899238586, dist_loss: 0.615583598613739
recon_loss: 0.027361787855625153, dist_loss: 0.37539583444595337
recon_loss: 0.02736208774149418, dist_loss: 0.6741704940795898
recon_loss: 0.027362216264009476, dist_loss: 0.9593576788902283
recon_loss: 0.02736244723200798, dist_loss: 1.0581527948379517
recon_loss: 0.027362393215298653, dist_loss: 0.4394727647304535
recon_loss: 0.027362409979104996, dist_loss: 0.39797669649124146
recon_loss: 0.027362225577235222, dist_loss: 0.524027407169342
recon_loss: 0.02736154943704605, dist_loss: 0.9586517810821533
recon_loss: 0.027361255139112473, dist_loss: 0.6013968586921692
recon_loss: 0.02736087329685688, dist_loss: 0.37090760469436646
recon_loss: 0.027360882610082626, dist_loss: 1.0242969989776611
recon_loss: 0.027360547333955765, dist_loss: 0.4945429265499115
recon_loss: 0.027360720559954643, dist_loss: 0.6760079860687256
recon_loss: 0.02736075408756733, dist_loss: 0.286155104637146
recon_loss: 0.027361150830984116, dist_loss: 0.816344678401947
recon_loss: 0.02736104279756546, dist_loss: 0.4716072082519531
recon_loss: 0.027361178770661354, dist_loss: 0.4951156675815582
recon_loss: 0.027361415326595306, dist_loss: 0.8983154296875
recon_loss: 0.027362160384655, dist_loss: 0.6562631726264954
recon_loss: 0.02736257016658783, dist_loss: 0.3857360780239105
recon_loss: 0.02736322209239006, dist_loss: 0.48263442516326904
recon_loss: 0.027363227680325508, dist_loss: 0.36908602714538574
recon_loss: 0.027363240718841553, dist_loss: 0.805152416229248
recon_loss: 0.027363207191228867, dist_loss: 0.9001643061637878
recon_loss: 0.02736327238380909, dist_loss: 0.40791821479797363
recon_loss: 0.02736329473555088, dist_loss: 0.4902473986148834
recon_loss: 0.027362432330846786, dist_loss: 0.6520934700965881
recon_loss: 0.02736245095729828, dist_loss: 0.4968458116054535
recon_loss: 0.027361666783690453, dist_loss: 0.5979065895080566
recon_loss: 0.027361540123820305, dist_loss: 0.849186897277832
recon_loss: 0.02736109495162964, dist_loss: 0.7943546772003174
recon_loss: 0.027360856533050537, dist_loss: 0.5420088171958923
recon_loss: 0.027360975742340088, dist_loss: 1.309819221496582
recon_loss: 0.027360618114471436, dist_loss: 1.2041126489639282
recon_loss: 0.027361951768398285, dist_loss: 0.7332963943481445
recon_loss: 0.027361227199435234, dist_loss: 0.997330367565155
recon_loss: 0.027361907064914703, dist_loss: 0.5158755779266357
recon_loss: 0.027361199259757996, dist_loss: 0.36348801851272583
recon_loss: 0.027360718697309494, dist_loss: 0.7975674271583557
recon_loss: 0.02736036665737629, dist_loss: 0.7676160335540771
Pre-training Epoch 108:  37%|███▋      | 136/367 [00:01<00:01, 126.68it/s]Pre-training Epoch 108:  41%|████      | 149/367 [00:01<00:01, 126.46it/s]Pre-training Epoch 108:  44%|████▍     | 162/367 [00:01<00:01, 124.60it/s]Pre-training Epoch 108:  48%|████▊     | 175/367 [00:01<00:01, 122.43it/s]Pre-training Epoch 108:  51%|█████▏    | 189/367 [00:01<00:01, 125.40it/s]Pre-training Epoch 108:  55%|█████▌    | 202/367 [00:01<00:01, 126.13it/s]Pre-training Epoch 108:  59%|█████▊    | 215/367 [00:01<00:01, 124.60it/s]Pre-training Epoch 108:  62%|██████▏   | 228/367 [00:01<00:01, 125.15it/s]Pre-training Epoch 108:  66%|██████▌   | 241/367 [00:01<00:00, 126.50it/s]Pre-training Epoch 108:  69%|██████▉   | 254/367 [00:02<00:00, 124.51it/s]recon_loss: 0.02736000344157219, dist_loss: 0.7150984406471252
recon_loss: 0.027359487488865852, dist_loss: 0.386625200510025
recon_loss: 0.027359485626220703, dist_loss: 0.9815454483032227
recon_loss: 0.02735941857099533, dist_loss: 0.44549015164375305
recon_loss: 0.027359215542674065, dist_loss: 0.3775365352630615
recon_loss: 0.0273591261357069, dist_loss: 0.538311243057251
recon_loss: 0.02735856920480728, dist_loss: 1.5000356435775757
recon_loss: 0.027359217405319214, dist_loss: 0.6672927737236023
recon_loss: 0.027358250692486763, dist_loss: 0.5472118258476257
recon_loss: 0.027358701452612877, dist_loss: 0.4349309802055359
recon_loss: 0.027358127757906914, dist_loss: 0.7803423404693604
recon_loss: 0.027358438819646835, dist_loss: 1.0040841102600098
recon_loss: 0.027358148247003555, dist_loss: 0.4612542986869812
recon_loss: 0.02735835686326027, dist_loss: 0.985938549041748
recon_loss: 0.027357853949069977, dist_loss: 0.4621535837650299
recon_loss: 0.027358125895261765, dist_loss: 0.48998016119003296
recon_loss: 0.027358148247003555, dist_loss: 0.8064622282981873
recon_loss: 0.027358056977391243, dist_loss: 0.311509370803833
recon_loss: 0.027358021587133408, dist_loss: 0.5361119508743286
recon_loss: 0.027358148247003555, dist_loss: 0.5982685685157776
recon_loss: 0.027358703315258026, dist_loss: 0.8243717551231384
recon_loss: 0.027357827872037888, dist_loss: 0.5207362771034241
recon_loss: 0.02735842764377594, dist_loss: 0.6272006034851074
recon_loss: 0.0273574385792017, dist_loss: 0.8708533644676208
recon_loss: 0.02735796757042408, dist_loss: 0.5913273096084595
recon_loss: 0.02735758014023304, dist_loss: 0.9550170302391052
recon_loss: 0.0273575596511364, dist_loss: 0.37397199869155884
recon_loss: 0.02735787257552147, dist_loss: 0.5200425386428833
recon_loss: 0.02735697105526924, dist_loss: 0.40584343671798706
recon_loss: 0.02735779993236065, dist_loss: 0.49917542934417725
recon_loss: 0.027358347550034523, dist_loss: 0.5793482661247253
recon_loss: 0.027359511703252792, dist_loss: 1.2860584259033203
recon_loss: 0.0273603405803442, dist_loss: 0.3817080855369568
recon_loss: 0.0273615512996912, dist_loss: 0.4111407399177551
recon_loss: 0.0273610670119524, dist_loss: 0.5152550935745239
recon_loss: 0.027362296357750893, dist_loss: 0.7727740406990051
recon_loss: 0.027361109852790833, dist_loss: 1.4021260738372803
recon_loss: 0.02736199088394642, dist_loss: 0.5749598741531372
recon_loss: 0.027361024171113968, dist_loss: 0.4909643828868866
recon_loss: 0.02735981158912182, dist_loss: 0.4261775016784668
recon_loss: 0.02735956385731697, dist_loss: 0.4002811312675476
recon_loss: 0.02735886164009571, dist_loss: 0.5164065361022949
recon_loss: 0.02735874615609646, dist_loss: 0.7140040397644043
recon_loss: 0.02735811099410057, dist_loss: 1.1424365043640137
recon_loss: 0.027358269318938255, dist_loss: 0.5253699421882629
recon_loss: 0.027358587831258774, dist_loss: 0.4778326153755188
recon_loss: 0.027359845116734505, dist_loss: 1.0514638423919678
recon_loss: 0.027361221611499786, dist_loss: 0.6213197112083435
recon_loss: 0.027362583205103874, dist_loss: 0.5772675275802612
recon_loss: 0.027365155518054962, dist_loss: 0.4231995940208435
recon_loss: 0.027367275208234787, dist_loss: 0.398143470287323
recon_loss: 0.02736710011959076, dist_loss: 0.828365683555603
recon_loss: 0.027366770431399345, dist_loss: 0.6784971952438354
recon_loss: 0.027366433292627335, dist_loss: 0.7764990329742432
recon_loss: 0.02736560069024563, dist_loss: 1.1964656114578247
recon_loss: 0.027364905923604965, dist_loss: 0.5984930992126465
recon_loss: 0.027364499866962433, dist_loss: 0.8902809619903564
recon_loss: 0.027364365756511688, dist_loss: 0.8303478956222534
recon_loss: 0.027364661917090416, dist_loss: 0.7817770838737488
recon_loss: 0.02736525423824787, dist_loss: 1.022192358970642
recon_loss: 0.027364447712898254, dist_loss: 0.9915685057640076
recon_loss: 0.02736431360244751, dist_loss: 0.5805240869522095
recon_loss: 0.027362577617168427, dist_loss: 0.7532342672348022
recon_loss: 0.027362555265426636, dist_loss: 0.6345372200012207
recon_loss: 0.027360914275050163, dist_loss: 0.41089752316474915
recon_loss: 0.02736075222492218, dist_loss: 0.4109894037246704
recon_loss: 0.027359552681446075, dist_loss: 0.6454459428787231
recon_loss: 0.027358589693903923, dist_loss: 0.36972564458847046
recon_loss: 0.027358103543519974, dist_loss: 0.61506187915802
recon_loss: 0.027358442544937134, dist_loss: 0.5557867884635925
recon_loss: 0.027358487248420715, dist_loss: 0.5174496173858643
recon_loss: 0.027358993887901306, dist_loss: 0.7092568874359131
recon_loss: 0.02735910192131996, dist_loss: 0.6940520405769348
recon_loss: 0.027359219267964363, dist_loss: 0.5910363793373108
recon_loss: 0.027359500527381897, dist_loss: 0.486177533864975
recon_loss: 0.027358822524547577, dist_loss: 0.6833325028419495
recon_loss: 0.027358876541256905, dist_loss: 0.4815613627433777
recon_loss: 0.027358194813132286, dist_loss: 1.0198814868927002
recon_loss: 0.02735905908048153, dist_loss: 0.4983675479888916
recon_loss: 0.027358688414096832, dist_loss: 0.9003152847290039
recon_loss: 0.02735939808189869, dist_loss: 0.4930422902107239
recon_loss: 0.027359597384929657, dist_loss: 0.47742319107055664
recon_loss: 0.027359243482351303, dist_loss: 0.6549605131149292
recon_loss: 0.027358604595065117, dist_loss: 0.7713750004768372
recon_loss: 0.02735825814306736, dist_loss: 0.3161036968231201
recon_loss: 0.027358142659068108, dist_loss: 0.7129925489425659
recon_loss: 0.027357451617717743, dist_loss: 0.5933288335800171
recon_loss: 0.027356434613466263, dist_loss: 0.35689079761505127
recon_loss: 0.027355756610631943, dist_loss: 1.0720387697219849
recon_loss: 0.027355633676052094, dist_loss: 0.6497371196746826
recon_loss: 0.027355914935469627, dist_loss: 0.5128387808799744
recon_loss: 0.02735622599720955, dist_loss: 0.464182049036026
recon_loss: 0.027356281876564026, dist_loss: 0.40469029545783997
recon_loss: 0.02735641784965992, dist_loss: 0.3882593512535095
recon_loss: 0.027356719598174095, dist_loss: 0.32266291975975037
recon_loss: 0.02735714614391327, dist_loss: 0.6133590936660767
recon_loss: 0.027357617393136024, dist_loss: 0.35429859161376953
recon_loss: 0.027358274906873703, dist_loss: 0.5992230772972107
recon_loss: 0.027357308194041252, dist_loss: 0.5007129907608032
recon_loss: 0.02735672891139984, dist_loss: 0.4874799847602844
recon_loss: 0.027355501428246498, dist_loss: 0.5547131299972534
recon_loss: 0.027355073019862175, dist_loss: 0.3740609884262085
recon_loss: 0.027354620397090912, dist_loss: 0.9411245584487915
recon_loss: 0.027354644611477852, dist_loss: 1.0152076482772827
recon_loss: 0.027354665100574493, dist_loss: 0.8911363482475281
recon_loss: 0.027354774996638298, dist_loss: 1.2615056037902832
recon_loss: 0.027354814112186432, dist_loss: 0.7929114699363708
recon_loss: 0.02735450491309166, dist_loss: 0.4606547951698303
recon_loss: 0.02735423855483532, dist_loss: 0.7115288972854614
recon_loss: 0.027354123070836067, dist_loss: 0.6938211917877197
recon_loss: 0.027354389429092407, dist_loss: 0.7165870070457458
recon_loss: 0.027354540303349495, dist_loss: 0.43399590253829956
recon_loss: 0.02735520899295807, dist_loss: 0.5826873183250427
recon_loss: 0.027356013655662537, dist_loss: 0.7573555707931519
recon_loss: 0.0273567084223032, dist_loss: 1.0022318363189697
recon_loss: 0.027356917038559914, dist_loss: 0.8727518916130066
recon_loss: 0.0273568294942379, dist_loss: 0.5913504958152771
recon_loss: 0.02735617570579052, dist_loss: 0.48369890451431274
recon_loss: 0.027354754507541656, dist_loss: 1.0338689088821411
recon_loss: 0.027354782447218895, dist_loss: 0.6170831918716431
recon_loss: 0.027353784069418907, dist_loss: 0.5289034843444824
recon_loss: 0.027353674173355103, dist_loss: 0.7093223333358765
recon_loss: 0.027353759855031967, dist_loss: 0.3104020953178406
recon_loss: 0.027354232966899872, dist_loss: 0.45475637912750244
recon_loss: 0.027354184538125992, dist_loss: 0.8848339319229126
recon_loss: 0.027354605495929718, dist_loss: 0.38451921939849854
recon_loss: 0.027353832498192787, dist_loss: 0.594510555267334
recon_loss: 0.02735346369445324, dist_loss: 1.0692447423934937
Pre-training Epoch 108:  73%|███████▎  | 268/367 [00:02<00:00, 128.70it/s]Pre-training Epoch 108:  77%|███████▋  | 281/367 [00:02<00:00, 128.93it/s]Pre-training Epoch 108:  80%|████████  | 295/367 [00:02<00:00, 130.79it/s]Pre-training Epoch 108:  84%|████████▍ | 309/367 [00:02<00:00, 132.36it/s]Pre-training Epoch 108:  88%|████████▊ | 323/367 [00:02<00:00, 132.00it/s]Pre-training Epoch 108:  92%|█████████▏| 338/367 [00:02<00:00, 135.24it/s]Pre-training Epoch 108:  96%|█████████▌| 353/367 [00:02<00:00, 138.70it/s]Pre-training Epoch 108: 100%|██████████| 367/367 [00:02<00:00, 132.43it/s]Pre-training Epoch 108: 100%|██████████| 367/367 [00:02<00:00, 128.15it/s]
recon_loss: 0.02735304646193981, dist_loss: 0.4838414490222931
recon_loss: 0.027353018522262573, dist_loss: 0.8221220374107361
recon_loss: 0.027353130280971527, dist_loss: 0.5781583786010742
recon_loss: 0.027353668585419655, dist_loss: 0.7213461399078369
recon_loss: 0.027354253455996513, dist_loss: 0.5672363042831421
recon_loss: 0.02735210955142975, dist_loss: 0.6043533086776733
recon_loss: 0.027352849021553993, dist_loss: 0.5725201368331909
recon_loss: 0.027351517230272293, dist_loss: 0.7089437246322632
recon_loss: 0.027352262288331985, dist_loss: 0.6938347220420837
recon_loss: 0.027353374287486076, dist_loss: 0.6168126463890076
recon_loss: 0.027354435995221138, dist_loss: 0.6426135301589966
recon_loss: 0.027355046942830086, dist_loss: 0.6657655239105225
recon_loss: 0.027355100959539413, dist_loss: 0.5763837099075317
recon_loss: 0.027356944978237152, dist_loss: 0.6192299127578735
recon_loss: 0.027357276529073715, dist_loss: 0.5058480501174927
recon_loss: 0.027358688414096832, dist_loss: 0.6303365230560303
recon_loss: 0.027357136830687523, dist_loss: 1.2444500923156738
recon_loss: 0.02735813520848751, dist_loss: 0.66138756275177
recon_loss: 0.027356786653399467, dist_loss: 0.47450265288352966
recon_loss: 0.0273576732724905, dist_loss: 0.665508508682251
recon_loss: 0.02735685557126999, dist_loss: 0.7841286659240723
recon_loss: 0.027356578037142754, dist_loss: 0.6019535064697266
recon_loss: 0.02735581248998642, dist_loss: 0.5494844913482666
recon_loss: 0.027355238795280457, dist_loss: 0.7231354713439941
recon_loss: 0.027355460450053215, dist_loss: 0.47314533591270447
recon_loss: 0.027354637160897255, dist_loss: 1.0421977043151855
recon_loss: 0.02735370583832264, dist_loss: 0.43371257185935974
recon_loss: 0.02735356241464615, dist_loss: 0.4569026231765747
recon_loss: 0.027352415025234222, dist_loss: 0.6495338082313538
recon_loss: 0.02735261246562004, dist_loss: 0.5463828444480896
recon_loss: 0.0273517444729805, dist_loss: 0.6054782271385193
recon_loss: 0.02735164575278759, dist_loss: 0.42364007234573364
recon_loss: 0.027350932359695435, dist_loss: 0.45780467987060547
recon_loss: 0.02735144831240177, dist_loss: 0.7237488627433777
recon_loss: 0.027350682765245438, dist_loss: 0.686240553855896
recon_loss: 0.02735086902976036, dist_loss: 0.5055506229400635
recon_loss: 0.027351632714271545, dist_loss: 0.3850265443325043
recon_loss: 0.027352098375558853, dist_loss: 0.5216251611709595
recon_loss: 0.02735276147723198, dist_loss: 0.376806378364563
recon_loss: 0.027352700009942055, dist_loss: 1.0966367721557617
recon_loss: 0.027352886274456978, dist_loss: 0.6324449777603149
recon_loss: 0.027352582663297653, dist_loss: 0.5801430940628052
recon_loss: 0.027352474629878998, dist_loss: 0.6881716847419739
recon_loss: 0.027352796867489815, dist_loss: 0.679812490940094
recon_loss: 0.02735241688787937, dist_loss: 0.44163841009140015
recon_loss: 0.027352947741746902, dist_loss: 0.6073956489562988
recon_loss: 0.027353325858712196, dist_loss: 0.9483959674835205
recon_loss: 0.027353204786777496, dist_loss: 0.5914121866226196
recon_loss: 0.027352962642908096, dist_loss: 0.43661075830459595
recon_loss: 0.027352318167686462, dist_loss: 0.45174238085746765
recon_loss: 0.027351774275302887, dist_loss: 0.7073140144348145
recon_loss: 0.02735077776014805, dist_loss: 0.7139801383018494
recon_loss: 0.027349865064024925, dist_loss: 0.6610209345817566
recon_loss: 0.02734939195215702, dist_loss: 0.3745790421962738
recon_loss: 0.027349309995770454, dist_loss: 0.7533779144287109
recon_loss: 0.027349254116415977, dist_loss: 0.48978936672210693
recon_loss: 0.02734958566725254, dist_loss: 0.4098667502403259
recon_loss: 0.027349626645445824, dist_loss: 0.5681692361831665
recon_loss: 0.027350082993507385, dist_loss: 0.6619164347648621
recon_loss: 0.027349838986992836, dist_loss: 0.5685944557189941
recon_loss: 0.02735014446079731, dist_loss: 0.4664406180381775
recon_loss: 0.02735039032995701, dist_loss: 0.944002628326416
recon_loss: 0.02735159732401371, dist_loss: 0.5891615748405457
recon_loss: 0.02735161781311035, dist_loss: 0.7356622219085693
recon_loss: 0.027351532131433487, dist_loss: 0.855575442314148
recon_loss: 0.02735201083123684, dist_loss: 0.6611207723617554
recon_loss: 0.02735234424471855, dist_loss: 0.5643305778503418
recon_loss: 0.02735307812690735, dist_loss: 0.5476373434066772
recon_loss: 0.02735183946788311, dist_loss: 0.49702003598213196
recon_loss: 0.02735108882188797, dist_loss: 0.3133419156074524
recon_loss: 0.02735011838376522, dist_loss: 0.48687684535980225
recon_loss: 0.027349673211574554, dist_loss: 0.8359223008155823
recon_loss: 0.027348970994353294, dist_loss: 0.49437519907951355
recon_loss: 0.027348864823579788, dist_loss: 0.5853379964828491
recon_loss: 0.027348855510354042, dist_loss: 0.7469245791435242
recon_loss: 0.027349261566996574, dist_loss: 0.9478738903999329
recon_loss: 0.027350090444087982, dist_loss: 0.3075723648071289
recon_loss: 0.027350768446922302, dist_loss: 0.52244633436203
recon_loss: 0.027351871132850647, dist_loss: 0.9426124095916748
recon_loss: 0.027351487427949905, dist_loss: 0.8164874315261841
recon_loss: 0.02735082432627678, dist_loss: 0.4209407567977905
recon_loss: 0.027350619435310364, dist_loss: 0.37964195013046265
recon_loss: 0.027350472286343575, dist_loss: 0.40744662284851074
recon_loss: 0.02735087275505066, dist_loss: 0.47959238290786743
recon_loss: 0.02735031209886074, dist_loss: 1.0645289421081543
recon_loss: 0.027350623160600662, dist_loss: 0.9568070769309998
recon_loss: 0.02735147438943386, dist_loss: 0.730637788772583
recon_loss: 0.02735150046646595, dist_loss: 0.8266186118125916
recon_loss: 0.027352554723620415, dist_loss: 0.6466586589813232
recon_loss: 0.02735237218439579, dist_loss: 0.644142746925354
recon_loss: 0.027353066951036453, dist_loss: 0.5745717883110046
recon_loss: 0.02735232748091221, dist_loss: 0.523628830909729
recon_loss: 0.02735234797000885, dist_loss: 0.6167982220649719
recon_loss: 0.02735126204788685, dist_loss: 1.123002290725708
recon_loss: 0.027350354939699173, dist_loss: 0.8252137899398804
recon_loss: 0.027350569143891335, dist_loss: 0.6278539299964905
recon_loss: 0.027349282056093216, dist_loss: 0.5500620007514954
recon_loss: 0.027350014075636864, dist_loss: 0.4352697730064392
recon_loss: 0.027348753064870834, dist_loss: 0.5071302056312561
recon_loss: 0.02735007368028164, dist_loss: 0.9772337675094604
recon_loss: 0.027350300922989845, dist_loss: 0.4822862148284912
recon_loss: 0.02735278569161892, dist_loss: 0.9359955191612244
recon_loss: 0.027353733777999878, dist_loss: 0.534965455532074
recon_loss: 0.027354277670383453, dist_loss: 0.7490610480308533
recon_loss: 0.027355048805475235, dist_loss: 0.7276625633239746
recon_loss: 0.027351783588528633, dist_loss: 0.4888942837715149
recon_loss: 0.027354005724191666, dist_loss: 0.8003561496734619
recon_loss: 0.02735181897878647, dist_loss: 0.5994546413421631
recon_loss: 0.02735329233109951, dist_loss: 0.44910699129104614
recon_loss: 0.02735358476638794, dist_loss: 0.8380399346351624
recon_loss: 0.027353618294000626, dist_loss: 0.2740621566772461
Pre-training Epoch 109:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 109:   4%|▍         | 15/367 [00:00<00:02, 135.89it/s]Pre-training Epoch 109:   8%|▊         | 29/367 [00:00<00:02, 136.99it/s]Pre-training Epoch 109:  12%|█▏        | 43/367 [00:00<00:02, 130.55it/s]Pre-training Epoch 109:  16%|█▌        | 57/367 [00:00<00:02, 129.27it/s]Pre-training Epoch 109:  20%|█▉        | 73/367 [00:00<00:02, 136.87it/s]Pre-training Epoch 109:  24%|██▍       | 88/367 [00:00<00:01, 140.58it/s]Pre-training Epoch 109:  29%|██▉       | 106/367 [00:00<00:01, 151.63it/s]Pre-training Epoch 109:  34%|███▍      | 124/367 [00:00<00:01, 159.80it/s]recon_loss: 0.027354780584573746, dist_loss: 0.9445732831954956
recon_loss: 0.027354024350643158, dist_loss: 0.7956549525260925
recon_loss: 0.027354560792446136, dist_loss: 0.4402778744697571
recon_loss: 0.027353636920452118, dist_loss: 0.3975297808647156
recon_loss: 0.027354126796126366, dist_loss: 0.523706316947937
recon_loss: 0.027353057637810707, dist_loss: 1.0389035940170288
recon_loss: 0.027350623160600662, dist_loss: 0.486489474773407
recon_loss: 0.027349727228283882, dist_loss: 0.5274571180343628
recon_loss: 0.027348695322871208, dist_loss: 0.6993610262870789
recon_loss: 0.027348268777132034, dist_loss: 0.32550251483917236
recon_loss: 0.027348026633262634, dist_loss: 0.25756582617759705
recon_loss: 0.027348456904292107, dist_loss: 0.5624297857284546
recon_loss: 0.027349034324288368, dist_loss: 0.47252899408340454
recon_loss: 0.02734972909092903, dist_loss: 0.8690088391304016
recon_loss: 0.027350755408406258, dist_loss: 0.6252827048301697
recon_loss: 0.027351805940270424, dist_loss: 0.5672281384468079
recon_loss: 0.027352040633559227, dist_loss: 0.6094207763671875
recon_loss: 0.02735144831240177, dist_loss: 0.390344500541687
recon_loss: 0.02735079824924469, dist_loss: 0.32942408323287964
recon_loss: 0.027350017800927162, dist_loss: 1.0317819118499756
recon_loss: 0.027348913252353668, dist_loss: 0.5997072458267212
recon_loss: 0.027348218485713005, dist_loss: 0.40313661098480225
recon_loss: 0.027348296716809273, dist_loss: 0.5813372135162354
recon_loss: 0.027347680181264877, dist_loss: 0.3731592893600464
recon_loss: 0.02734813280403614, dist_loss: 0.5524064302444458
recon_loss: 0.027347741648554802, dist_loss: 0.2890082597732544
recon_loss: 0.02734854444861412, dist_loss: 1.2064772844314575
recon_loss: 0.02734922617673874, dist_loss: 0.8826049566268921
recon_loss: 0.027349447831511497, dist_loss: 0.5567197799682617
recon_loss: 0.02734985016286373, dist_loss: 0.2567065358161926
recon_loss: 0.027348998934030533, dist_loss: 0.5272991061210632
recon_loss: 0.02735024504363537, dist_loss: 1.3785851001739502
recon_loss: 0.027348870411515236, dist_loss: 0.8146712779998779
recon_loss: 0.027349691838026047, dist_loss: 0.5700926780700684
recon_loss: 0.027348646894097328, dist_loss: 0.9830283522605896
recon_loss: 0.027348332107067108, dist_loss: 1.24155855178833
recon_loss: 0.027347683906555176, dist_loss: 0.6750131845474243
recon_loss: 0.02734719030559063, dist_loss: 0.9361252784729004
recon_loss: 0.02734725922346115, dist_loss: 0.7904428839683533
recon_loss: 0.027347948402166367, dist_loss: 0.7181800603866577
recon_loss: 0.027348678559064865, dist_loss: 0.6468321681022644
recon_loss: 0.027349377050995827, dist_loss: 0.5341437458992004
recon_loss: 0.027349058538675308, dist_loss: 1.1363584995269775
recon_loss: 0.027348659932613373, dist_loss: 0.5857900381088257
recon_loss: 0.02734939195215702, dist_loss: 0.3432662785053253
recon_loss: 0.027348341420292854, dist_loss: 0.6825078725814819
recon_loss: 0.027349062263965607, dist_loss: 0.632035493850708
recon_loss: 0.02734784595668316, dist_loss: 0.4625647962093353
recon_loss: 0.02734825573861599, dist_loss: 0.4209982752799988
recon_loss: 0.027347583323717117, dist_loss: 0.9061076641082764
recon_loss: 0.02734815701842308, dist_loss: 0.573009192943573
recon_loss: 0.027349045500159264, dist_loss: 0.9166560769081116
recon_loss: 0.027348283678293228, dist_loss: 1.1167657375335693
recon_loss: 0.027348754927515984, dist_loss: 0.5924978256225586
recon_loss: 0.027347147464752197, dist_loss: 1.0215604305267334
recon_loss: 0.02734779193997383, dist_loss: 0.47467678785324097
recon_loss: 0.02734806202352047, dist_loss: 0.6231149435043335
recon_loss: 0.027349859476089478, dist_loss: 0.6441440582275391
recon_loss: 0.027351176366209984, dist_loss: 0.33464622497558594
recon_loss: 0.027352143079042435, dist_loss: 0.9392181634902954
recon_loss: 0.027352135628461838, dist_loss: 0.5099048614501953
recon_loss: 0.027351297438144684, dist_loss: 0.8752014636993408
recon_loss: 0.027349937707185745, dist_loss: 0.6483733654022217
recon_loss: 0.027349045500159264, dist_loss: 0.7920289635658264
recon_loss: 0.027347857132554054, dist_loss: 0.4143744707107544
recon_loss: 0.02734757959842682, dist_loss: 0.5622510313987732
recon_loss: 0.027347171679139137, dist_loss: 0.39597445726394653
recon_loss: 0.027347292751073837, dist_loss: 0.45254918932914734
recon_loss: 0.027347195893526077, dist_loss: 0.7473940849304199
recon_loss: 0.027347292751073837, dist_loss: 0.768999457359314
recon_loss: 0.0273482296615839, dist_loss: 0.3954172432422638
recon_loss: 0.027347706258296967, dist_loss: 0.8557168245315552
recon_loss: 0.027348967269062996, dist_loss: 1.0588746070861816
recon_loss: 0.027347365394234657, dist_loss: 0.4788869023323059
recon_loss: 0.02735000103712082, dist_loss: 0.6784456968307495
recon_loss: 0.02735009975731373, dist_loss: 0.9013907313346863
recon_loss: 0.027351614087820053, dist_loss: 0.7639902830123901
recon_loss: 0.027352506294846535, dist_loss: 0.4489935636520386
recon_loss: 0.027353517711162567, dist_loss: 0.6259186267852783
recon_loss: 0.027354493737220764, dist_loss: 0.6255533695220947
recon_loss: 0.027354609221220016, dist_loss: 1.0278615951538086
recon_loss: 0.027353864163160324, dist_loss: 0.48471176624298096
recon_loss: 0.027351194992661476, dist_loss: 0.6936956644058228
recon_loss: 0.02735191024839878, dist_loss: 0.4200748801231384
recon_loss: 0.027349676936864853, dist_loss: 0.5610202550888062
recon_loss: 0.027350079268217087, dist_loss: 0.8817108869552612
recon_loss: 0.027349362149834633, dist_loss: 0.28947746753692627
recon_loss: 0.027348928153514862, dist_loss: 0.4006301760673523
recon_loss: 0.027350327000021935, dist_loss: 0.8863373398780823
recon_loss: 0.02734874002635479, dist_loss: 0.7635898590087891
recon_loss: 0.02734946273267269, dist_loss: 0.9022185206413269
recon_loss: 0.02734869346022606, dist_loss: 0.5578790307044983
recon_loss: 0.02734905108809471, dist_loss: 0.6110652685165405
recon_loss: 0.027348749339580536, dist_loss: 0.903850793838501
recon_loss: 0.02734721079468727, dist_loss: 0.7009429931640625
recon_loss: 0.027346882969141006, dist_loss: 0.5772103071212769
recon_loss: 0.027346156537532806, dist_loss: 0.5760852098464966
recon_loss: 0.02734607458114624, dist_loss: 0.5464633107185364
recon_loss: 0.027345698326826096, dist_loss: 0.5468865633010864
recon_loss: 0.0273456908762455, dist_loss: 0.9249062538146973
recon_loss: 0.02734546735882759, dist_loss: 0.6911645531654358
recon_loss: 0.027345789596438408, dist_loss: 0.662667989730835
recon_loss: 0.027345791459083557, dist_loss: 0.9182830452919006
recon_loss: 0.027345813810825348, dist_loss: 0.513907790184021
recon_loss: 0.027345703914761543, dist_loss: 0.6695705056190491
recon_loss: 0.027345482259988785, dist_loss: 0.6608554124832153
recon_loss: 0.02734541893005371, dist_loss: 0.47514161467552185
recon_loss: 0.02734539657831192, dist_loss: 0.7409616708755493
recon_loss: 0.027345001697540283, dist_loss: 0.33101528882980347
recon_loss: 0.027344539761543274, dist_loss: 0.7479938864707947
recon_loss: 0.02734464593231678, dist_loss: 0.6362197399139404
recon_loss: 0.027344560250639915, dist_loss: 0.9200960397720337
recon_loss: 0.027344362810254097, dist_loss: 0.5279473662376404
recon_loss: 0.02734369784593582, dist_loss: 0.5689443349838257
recon_loss: 0.02734364941716194, dist_loss: 0.7659170627593994
recon_loss: 0.027343150228261948, dist_loss: 0.3393508195877075
recon_loss: 0.027343137189745903, dist_loss: 0.6898425817489624
recon_loss: 0.027342811226844788, dist_loss: 0.7510225772857666
recon_loss: 0.027342023327946663, dist_loss: 0.4847179055213928
recon_loss: 0.027342073619365692, dist_loss: 0.6225647926330566
recon_loss: 0.027342654764652252, dist_loss: 0.7062957286834717
recon_loss: 0.027342788875102997, dist_loss: 0.33521661162376404
recon_loss: 0.027343273162841797, dist_loss: 0.8854954242706299
recon_loss: 0.027343381196260452, dist_loss: 0.5605466365814209
recon_loss: 0.02734551765024662, dist_loss: 0.4873085618019104
recon_loss: 0.027345281094312668, dist_loss: 0.4950650930404663
recon_loss: 0.027346136048436165, dist_loss: 0.6042519211769104
recon_loss: 0.027344414964318275, dist_loss: 1.0898199081420898
Pre-training Epoch 109:  39%|███▊      | 142/367 [00:00<00:01, 165.03it/s]Pre-training Epoch 109:  43%|████▎     | 159/367 [00:01<00:01, 162.86it/s]Pre-training Epoch 109:  48%|████▊     | 176/367 [00:01<00:01, 159.32it/s]Pre-training Epoch 109:  52%|█████▏    | 192/367 [00:01<00:01, 157.50it/s]Pre-training Epoch 109:  57%|█████▋    | 208/367 [00:01<00:01, 154.63it/s]Pre-training Epoch 109:  61%|██████▏   | 225/367 [00:01<00:00, 159.00it/s]Pre-training Epoch 109:  66%|██████▌   | 243/367 [00:01<00:00, 164.34it/s]recon_loss: 0.02734469063580036, dist_loss: 1.029021978378296
recon_loss: 0.02734554558992386, dist_loss: 0.6578704714775085
recon_loss: 0.02734367921948433, dist_loss: 1.0953474044799805
recon_loss: 0.027345210313796997, dist_loss: 0.6770660281181335
recon_loss: 0.027341557666659355, dist_loss: 0.6455445289611816
recon_loss: 0.027342097833752632, dist_loss: 0.7830066680908203
recon_loss: 0.027341501787304878, dist_loss: 0.8275832533836365
recon_loss: 0.027343496680259705, dist_loss: 0.9415307641029358
recon_loss: 0.027344588190317154, dist_loss: 0.4833601713180542
recon_loss: 0.027344826608896255, dist_loss: 0.6190924644470215
recon_loss: 0.02734738402068615, dist_loss: 0.7020483016967773
recon_loss: 0.02734600193798542, dist_loss: 0.43843165040016174
recon_loss: 0.02734667807817459, dist_loss: 0.4752494692802429
recon_loss: 0.027344709262251854, dist_loss: 0.7572331428527832
recon_loss: 0.0273453276604414, dist_loss: 0.5717108249664307
recon_loss: 0.027344603091478348, dist_loss: 0.3893812894821167
recon_loss: 0.027343597263097763, dist_loss: 0.21740227937698364
recon_loss: 0.027342941612005234, dist_loss: 0.2706909775733948
recon_loss: 0.027341872453689575, dist_loss: 1.0451319217681885
recon_loss: 0.027341557666659355, dist_loss: 0.5683086514472961
recon_loss: 0.027341002598404884, dist_loss: 0.5576573014259338
recon_loss: 0.027340739965438843, dist_loss: 0.6163923144340515
recon_loss: 0.02734052762389183, dist_loss: 0.5021827816963196
recon_loss: 0.027340948581695557, dist_loss: 0.7361993789672852
recon_loss: 0.027340982109308243, dist_loss: 0.6758134365081787
recon_loss: 0.02734134905040264, dist_loss: 0.827349066734314
recon_loss: 0.02734103612601757, dist_loss: 0.6906326413154602
recon_loss: 0.02734151855111122, dist_loss: 0.8672088384628296
recon_loss: 0.027342606335878372, dist_loss: 0.5258559584617615
recon_loss: 0.027343111112713814, dist_loss: 0.7385002374649048
recon_loss: 0.027343053370714188, dist_loss: 0.6993626356124878
recon_loss: 0.027342312037944794, dist_loss: 0.7494571208953857
recon_loss: 0.02734188362956047, dist_loss: 0.48267796635627747
recon_loss: 0.027340948581695557, dist_loss: 0.8229971528053284
recon_loss: 0.027340542525053024, dist_loss: 0.5671638250350952
recon_loss: 0.02733960933983326, dist_loss: 0.4261663556098938
recon_loss: 0.027339588850736618, dist_loss: 0.32125428318977356
recon_loss: 0.027339257299900055, dist_loss: 0.40574926137924194
recon_loss: 0.027338994666934013, dist_loss: 0.5871533751487732
recon_loss: 0.027338869869709015, dist_loss: 0.571691632270813
recon_loss: 0.02733844891190529, dist_loss: 0.6132408976554871
recon_loss: 0.027339117601513863, dist_loss: 0.7162846326828003
recon_loss: 0.027339810505509377, dist_loss: 0.5887980461120605
recon_loss: 0.02734074927866459, dist_loss: 0.6396921873092651
recon_loss: 0.027341943234205246, dist_loss: 0.6486235857009888
recon_loss: 0.027342796325683594, dist_loss: 0.8371275663375854
recon_loss: 0.027344059199094772, dist_loss: 0.9870380163192749
recon_loss: 0.027343420311808586, dist_loss: 1.0010943412780762
recon_loss: 0.02734370343387127, dist_loss: 0.517855703830719
recon_loss: 0.027343690395355225, dist_loss: 0.4042970538139343
recon_loss: 0.027344323694705963, dist_loss: 0.6029830574989319
recon_loss: 0.02734244242310524, dist_loss: 0.7568919658660889
recon_loss: 0.027342287823557854, dist_loss: 0.4999704360961914
recon_loss: 0.027341198176145554, dist_loss: 0.5226743221282959
recon_loss: 0.02734098769724369, dist_loss: 0.255219429731369
recon_loss: 0.027340376749634743, dist_loss: 0.5497623682022095
recon_loss: 0.027339957654476166, dist_loss: 1.137751817703247
recon_loss: 0.027341328561306, dist_loss: 0.5560709238052368
recon_loss: 0.02734263613820076, dist_loss: 0.38923680782318115
recon_loss: 0.02734309621155262, dist_loss: 0.6920661926269531
recon_loss: 0.027343284338712692, dist_loss: 0.8737842440605164
recon_loss: 0.027342582121491432, dist_loss: 0.8502243757247925
recon_loss: 0.027342164888978004, dist_loss: 1.1588051319122314
recon_loss: 0.02734062634408474, dist_loss: 0.8506559133529663
recon_loss: 0.027339959517121315, dist_loss: 0.8581977486610413
recon_loss: 0.027339112013578415, dist_loss: 1.0000629425048828
recon_loss: 0.02733842469751835, dist_loss: 0.5079922080039978
recon_loss: 0.027338333427906036, dist_loss: 0.6908167600631714
recon_loss: 0.027337606996297836, dist_loss: 0.8831311464309692
recon_loss: 0.027338217943906784, dist_loss: 0.7859944105148315
recon_loss: 0.02733815461397171, dist_loss: 0.4923335611820221
recon_loss: 0.027339395135641098, dist_loss: 0.32156747579574585
recon_loss: 0.027339007705450058, dist_loss: 0.7103763818740845
recon_loss: 0.027339493855834007, dist_loss: 0.7050323486328125
recon_loss: 0.027339762076735497, dist_loss: 0.6066284775733948
recon_loss: 0.02733936719596386, dist_loss: 0.708208441734314
recon_loss: 0.027338940650224686, dist_loss: 0.5590711832046509
recon_loss: 0.027338610962033272, dist_loss: 0.6499803066253662
recon_loss: 0.027338389307260513, dist_loss: 0.48992592096328735
recon_loss: 0.027338676154613495, dist_loss: 0.3444550633430481
recon_loss: 0.0273391455411911, dist_loss: 0.4703274071216583
recon_loss: 0.027339980006217957, dist_loss: 0.7443854808807373
recon_loss: 0.027340056374669075, dist_loss: 0.6353170275688171
recon_loss: 0.027340393513441086, dist_loss: 0.8637574911117554
recon_loss: 0.027340902015566826, dist_loss: 0.7282614707946777
recon_loss: 0.027341298758983612, dist_loss: 0.6022465229034424
recon_loss: 0.027341127395629883, dist_loss: 0.7000728845596313
recon_loss: 0.027341192588210106, dist_loss: 0.44582629203796387
recon_loss: 0.027340779080986977, dist_loss: 0.4441564083099365
recon_loss: 0.027340665459632874, dist_loss: 0.660697340965271
recon_loss: 0.027341684326529503, dist_loss: 0.32580333948135376
recon_loss: 0.027339396998286247, dist_loss: 0.8148097991943359
recon_loss: 0.027339927852153778, dist_loss: 0.8023256659507751
recon_loss: 0.02733927220106125, dist_loss: 0.6967348456382751
recon_loss: 0.027339937165379524, dist_loss: 0.8603012561798096
recon_loss: 0.027340583503246307, dist_loss: 0.6816599369049072
recon_loss: 0.027341853827238083, dist_loss: 0.6405611634254456
recon_loss: 0.02734331041574478, dist_loss: 0.5926215052604675
recon_loss: 0.027341166511178017, dist_loss: 0.3307839035987854
recon_loss: 0.027340488508343697, dist_loss: 0.5501243472099304
recon_loss: 0.02733929269015789, dist_loss: 0.8752139210700989
recon_loss: 0.02733878418803215, dist_loss: 1.0598127841949463
recon_loss: 0.027338610962033272, dist_loss: 0.4755106568336487
recon_loss: 0.027338195592164993, dist_loss: 1.2459993362426758
recon_loss: 0.027338610962033272, dist_loss: 0.5484362244606018
recon_loss: 0.02733742631971836, dist_loss: 0.7118692398071289
recon_loss: 0.027338357642292976, dist_loss: 0.4431914687156677
recon_loss: 0.027337409555912018, dist_loss: 0.5842795372009277
recon_loss: 0.027337895706295967, dist_loss: 0.5809057950973511
recon_loss: 0.027337877079844475, dist_loss: 0.5485761165618896
recon_loss: 0.02733728289604187, dist_loss: 0.39766037464141846
recon_loss: 0.02733725495636463, dist_loss: 0.7686249017715454
recon_loss: 0.027337035164237022, dist_loss: 0.8966021537780762
recon_loss: 0.027337169274687767, dist_loss: 0.7580219507217407
recon_loss: 0.02733648009598255, dist_loss: 0.6400119662284851
recon_loss: 0.027336889877915382, dist_loss: 0.7177292108535767
recon_loss: 0.027336006984114647, dist_loss: 0.5444137454032898
recon_loss: 0.027337687090039253, dist_loss: 0.3807317614555359
recon_loss: 0.027335986495018005, dist_loss: 0.41786086559295654
recon_loss: 0.02733749710023403, dist_loss: 1.073620319366455
recon_loss: 0.027336329221725464, dist_loss: 0.3975410759449005
recon_loss: 0.027337364852428436, dist_loss: 0.57069993019104
recon_loss: 0.027336712926626205, dist_loss: 0.6201344728469849
recon_loss: 0.027338413521647453, dist_loss: 0.7999486923217773
recon_loss: 0.02733810991048813, dist_loss: 0.4681243598461151
recon_loss: 0.02733949013054371, dist_loss: 0.4752854108810425
recon_loss: 0.027339410036802292, dist_loss: 0.8899956941604614
recon_loss: 0.027340538799762726, dist_loss: 0.9243483543395996
Pre-training Epoch 109:  71%|███████   | 261/367 [00:01<00:00, 167.77it/s]Pre-training Epoch 109:  76%|███████▌  | 279/367 [00:01<00:00, 168.92it/s]Pre-training Epoch 109:  81%|████████  | 297/367 [00:01<00:00, 170.22it/s]Pre-training Epoch 109:  86%|████████▌ | 315/367 [00:01<00:00, 172.44it/s]Pre-training Epoch 109:  91%|█████████ | 333/367 [00:02<00:00, 171.15it/s]Pre-training Epoch 109:  96%|█████████▌| 351/367 [00:02<00:00, 171.37it/s]Pre-training Epoch 109: 100%|██████████| 367/367 [00:02<00:00, 158.75it/s]
recon_loss: 0.027340156957507133, dist_loss: 0.445537269115448
recon_loss: 0.027340559288859367, dist_loss: 0.7697426080703735
recon_loss: 0.02734040468931198, dist_loss: 0.4671841859817505
recon_loss: 0.027339555323123932, dist_loss: 0.5878271460533142
recon_loss: 0.027338776737451553, dist_loss: 0.7035510540008545
recon_loss: 0.027337538078427315, dist_loss: 0.7340554594993591
recon_loss: 0.02733721397817135, dist_loss: 0.5022847652435303
recon_loss: 0.02733651176095009, dist_loss: 0.5068696737289429
recon_loss: 0.027336403727531433, dist_loss: 0.3621094524860382
recon_loss: 0.027336614206433296, dist_loss: 0.584414541721344
recon_loss: 0.027337035164237022, dist_loss: 0.30331259965896606
recon_loss: 0.02733711153268814, dist_loss: 0.6103866100311279
recon_loss: 0.027337390929460526, dist_loss: 0.5549178719520569
recon_loss: 0.027337880805134773, dist_loss: 0.4028310179710388
recon_loss: 0.027338318526744843, dist_loss: 0.6162847280502319
recon_loss: 0.02733943797647953, dist_loss: 0.4627576768398285
recon_loss: 0.02734026499092579, dist_loss: 0.58780437707901
recon_loss: 0.027340391650795937, dist_loss: 0.5852160453796387
recon_loss: 0.027339834719896317, dist_loss: 1.0280468463897705
recon_loss: 0.027339018881320953, dist_loss: 0.9231854677200317
recon_loss: 0.02733752876520157, dist_loss: 0.683966338634491
recon_loss: 0.027336839586496353, dist_loss: 0.5474498867988586
recon_loss: 0.02733640745282173, dist_loss: 0.2983154356479645
recon_loss: 0.027335794642567635, dist_loss: 0.5651084184646606
recon_loss: 0.027336103841662407, dist_loss: 0.46023011207580566
recon_loss: 0.027336057275533676, dist_loss: 0.36767804622650146
recon_loss: 0.0273366067558527, dist_loss: 0.6513074040412903
recon_loss: 0.02733733505010605, dist_loss: 0.30866917967796326
recon_loss: 0.0273383017629385, dist_loss: 0.5922910571098328
recon_loss: 0.02733929269015789, dist_loss: 0.5556356906890869
recon_loss: 0.027339516207575798, dist_loss: 0.6260793209075928
recon_loss: 0.027339719235897064, dist_loss: 1.0786932706832886
recon_loss: 0.027339091524481773, dist_loss: 0.5440572500228882
recon_loss: 0.027338910847902298, dist_loss: 0.4941136837005615
recon_loss: 0.0273383017629385, dist_loss: 1.1531038284301758
recon_loss: 0.027336474508047104, dist_loss: 0.46062159538269043
recon_loss: 0.027335671707987785, dist_loss: 0.43275001645088196
recon_loss: 0.027334874495863914, dist_loss: 0.6166999340057373
recon_loss: 0.027334485203027725, dist_loss: 0.5181499123573303
recon_loss: 0.027335047721862793, dist_loss: 0.7643709182739258
recon_loss: 0.027335423976182938, dist_loss: 0.4953458309173584
recon_loss: 0.02733849361538887, dist_loss: 0.613588273525238
recon_loss: 0.027341071516275406, dist_loss: 0.5353421568870544
recon_loss: 0.027343302965164185, dist_loss: 0.5804746747016907
recon_loss: 0.027345389127731323, dist_loss: 0.586094856262207
recon_loss: 0.027346640825271606, dist_loss: 0.4717203974723816
recon_loss: 0.027347443625330925, dist_loss: 0.9701998233795166
recon_loss: 0.027346275746822357, dist_loss: 1.1014935970306396
recon_loss: 0.027345139533281326, dist_loss: 0.7072833776473999
recon_loss: 0.02734392136335373, dist_loss: 0.6313345432281494
recon_loss: 0.027344372123479843, dist_loss: 0.9900282621383667
recon_loss: 0.027344336733222008, dist_loss: 0.3965519070625305
recon_loss: 0.027343230322003365, dist_loss: 0.8561526536941528
recon_loss: 0.027341607958078384, dist_loss: 0.6505990028381348
recon_loss: 0.027340130880475044, dist_loss: 0.29227250814437866
recon_loss: 0.027338923886418343, dist_loss: 0.7892580628395081
recon_loss: 0.02733772061765194, dist_loss: 0.6675984859466553
recon_loss: 0.02733662910759449, dist_loss: 1.0080695152282715
recon_loss: 0.02733631432056427, dist_loss: 0.37131357192993164
recon_loss: 0.02733634039759636, dist_loss: 0.689253568649292
recon_loss: 0.02733667753636837, dist_loss: 0.7555824518203735
recon_loss: 0.027337148785591125, dist_loss: 0.5881249904632568
recon_loss: 0.02733764611184597, dist_loss: 0.37288057804107666
recon_loss: 0.027338262647390366, dist_loss: 0.8387408256530762
recon_loss: 0.027338795363903046, dist_loss: 0.4754311442375183
recon_loss: 0.02733970619738102, dist_loss: 0.9499785900115967
recon_loss: 0.027340460568666458, dist_loss: 0.8246526718139648
recon_loss: 0.027340851724147797, dist_loss: 0.4178667664527893
recon_loss: 0.027341896668076515, dist_loss: 0.6214843392372131
recon_loss: 0.0273418128490448, dist_loss: 0.6863589286804199
recon_loss: 0.02734130062162876, dist_loss: 0.6123309135437012
recon_loss: 0.027339985594153404, dist_loss: 0.7399067878723145
recon_loss: 0.02733849734067917, dist_loss: 0.4610947370529175
recon_loss: 0.0273367278277874, dist_loss: 0.9610167741775513
recon_loss: 0.027335602790117264, dist_loss: 0.6240457892417908
recon_loss: 0.027335230261087418, dist_loss: 0.8511540293693542
recon_loss: 0.027335170656442642, dist_loss: 0.9050432443618774
recon_loss: 0.02733617089688778, dist_loss: 0.558779239654541
recon_loss: 0.02733577787876129, dist_loss: 0.6434240341186523
recon_loss: 0.02733655460178852, dist_loss: 0.6666193604469299
recon_loss: 0.027334684506058693, dist_loss: 0.7011396288871765
recon_loss: 0.027334850281476974, dist_loss: 0.49863457679748535
recon_loss: 0.027333969250321388, dist_loss: 0.7233251333236694
recon_loss: 0.02733353152871132, dist_loss: 0.38095003366470337
recon_loss: 0.02733401022851467, dist_loss: 0.3697521984577179
recon_loss: 0.027332400903105736, dist_loss: 0.4802360534667969
recon_loss: 0.02733338251709938, dist_loss: 0.7029126286506653
recon_loss: 0.027332941070199013, dist_loss: 0.45251068472862244
recon_loss: 0.02733435668051243, dist_loss: 0.6373869776725769
recon_loss: 0.027334202080965042, dist_loss: 0.5949485301971436
recon_loss: 0.02733434922993183, dist_loss: 0.37173759937286377
recon_loss: 0.02733430080115795, dist_loss: 0.6959878206253052
recon_loss: 0.027334097772836685, dist_loss: 0.6294881105422974
recon_loss: 0.027333738282322884, dist_loss: 0.6756852865219116
recon_loss: 0.02733275294303894, dist_loss: 0.866592526435852
recon_loss: 0.0273334588855505, dist_loss: 0.5610469579696655
recon_loss: 0.02733161859214306, dist_loss: 0.22671087086200714
recon_loss: 0.027332330122590065, dist_loss: 0.49749547243118286
recon_loss: 0.027331378310918808, dist_loss: 0.8015540838241577
recon_loss: 0.027331732213497162, dist_loss: 0.48478859663009644
recon_loss: 0.02733244001865387, dist_loss: 0.44755756855010986
recon_loss: 0.027332134544849396, dist_loss: 0.48766809701919556
recon_loss: 0.027333103120326996, dist_loss: 0.7965643405914307
recon_loss: 0.027332404628396034, dist_loss: 0.5595768690109253
recon_loss: 0.02733408473432064, dist_loss: 1.203546404838562
recon_loss: 0.027334731072187424, dist_loss: 1.2685784101486206
recon_loss: 0.02733677066862583, dist_loss: 0.5789787173271179
recon_loss: 0.02733790874481201, dist_loss: 0.8175936341285706
recon_loss: 0.027338186278939247, dist_loss: 0.7138016223907471
recon_loss: 0.02733851969242096, dist_loss: 0.5488561987876892
recon_loss: 0.027336763218045235, dist_loss: 1.389197826385498
Pre-training Epoch 110:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 110:   4%|▍         | 15/367 [00:00<00:02, 147.08it/s]Pre-training Epoch 110:   8%|▊         | 31/367 [00:00<00:02, 151.74it/s]Pre-training Epoch 110:  13%|█▎        | 47/367 [00:00<00:02, 152.75it/s]Pre-training Epoch 110:  17%|█▋        | 63/367 [00:00<00:02, 150.34it/s]Pre-training Epoch 110:  22%|██▏       | 81/367 [00:00<00:01, 158.20it/s]Pre-training Epoch 110:  26%|██▋       | 97/367 [00:00<00:01, 158.75it/s]Pre-training Epoch 110:  31%|███▏      | 115/367 [00:00<00:01, 163.83it/s]recon_loss: 0.027336720377206802, dist_loss: 0.9712502956390381
recon_loss: 0.027334677055478096, dist_loss: 0.5541604161262512
recon_loss: 0.027333831414580345, dist_loss: 0.7287470102310181
recon_loss: 0.027331965044140816, dist_loss: 0.8486266136169434
recon_loss: 0.027331454679369926, dist_loss: 0.4819181263446808
recon_loss: 0.027330467477440834, dist_loss: 0.7859879732131958
recon_loss: 0.02733011171221733, dist_loss: 0.5124071836471558
recon_loss: 0.027329744771122932, dist_loss: 0.5952598452568054
recon_loss: 0.027329908683896065, dist_loss: 0.9380818009376526
recon_loss: 0.02733052894473076, dist_loss: 0.3271903395652771
recon_loss: 0.02733151614665985, dist_loss: 0.5627303123474121
recon_loss: 0.027332570403814316, dist_loss: 0.8582476377487183
recon_loss: 0.02733398601412773, dist_loss: 0.4142756462097168
recon_loss: 0.027333572506904602, dist_loss: 0.6280298233032227
recon_loss: 0.02733296900987625, dist_loss: 0.3421475887298584
recon_loss: 0.027331992983818054, dist_loss: 0.9714640378952026
recon_loss: 0.02733183279633522, dist_loss: 0.9289774298667908
recon_loss: 0.027332033962011337, dist_loss: 1.5788562297821045
recon_loss: 0.027331871911883354, dist_loss: 1.2810640335083008
recon_loss: 0.027331527322530746, dist_loss: 0.7327815294265747
recon_loss: 0.027331141754984856, dist_loss: 0.7101159691810608
recon_loss: 0.027330297976732254, dist_loss: 0.7216309309005737
recon_loss: 0.027329349890351295, dist_loss: 0.4042547345161438
recon_loss: 0.027328725904226303, dist_loss: 1.0444289445877075
recon_loss: 0.027328215539455414, dist_loss: 0.6647501587867737
recon_loss: 0.02732819877564907, dist_loss: 0.27694082260131836
recon_loss: 0.027328114956617355, dist_loss: 0.6171486973762512
recon_loss: 0.027328092604875565, dist_loss: 0.5400848984718323
recon_loss: 0.027328696101903915, dist_loss: 0.5080277919769287
recon_loss: 0.027328893542289734, dist_loss: 0.6482803821563721
recon_loss: 0.027328960597515106, dist_loss: 0.59657883644104
recon_loss: 0.027328623458743095, dist_loss: 0.5213570594787598
recon_loss: 0.027328241616487503, dist_loss: 0.6001278162002563
recon_loss: 0.027327939867973328, dist_loss: 0.3428378105163574
recon_loss: 0.027327558025717735, dist_loss: 1.1685868501663208
recon_loss: 0.02732781507074833, dist_loss: 0.7652212381362915
recon_loss: 0.027327897027134895, dist_loss: 0.6162934303283691
recon_loss: 0.027329428121447563, dist_loss: 0.5597683787345886
recon_loss: 0.0273299440741539, dist_loss: 0.5691702365875244
recon_loss: 0.027331212535500526, dist_loss: 0.577037513256073
recon_loss: 0.02732984721660614, dist_loss: 0.5041879415512085
recon_loss: 0.027329053729772568, dist_loss: 0.6106540560722351
recon_loss: 0.027329187840223312, dist_loss: 0.7307586073875427
recon_loss: 0.027328860014677048, dist_loss: 0.47374075651168823
recon_loss: 0.027329029515385628, dist_loss: 0.3643835783004761
recon_loss: 0.027328461408615112, dist_loss: 1.0177505016326904
recon_loss: 0.02732956036925316, dist_loss: 0.6482137441635132
recon_loss: 0.0273312795907259, dist_loss: 0.7446529865264893
recon_loss: 0.027333056554198265, dist_loss: 0.6550406217575073
recon_loss: 0.027335330843925476, dist_loss: 0.6351413726806641
recon_loss: 0.027337485924363136, dist_loss: 0.6949897408485413
recon_loss: 0.027339210733771324, dist_loss: 0.35969993472099304
recon_loss: 0.027339283376932144, dist_loss: 1.0883986949920654
recon_loss: 0.027338707819581032, dist_loss: 0.8328342437744141
recon_loss: 0.027337849140167236, dist_loss: 0.5670382976531982
recon_loss: 0.02733677066862583, dist_loss: 0.5946692228317261
recon_loss: 0.02733582817018032, dist_loss: 0.6662179231643677
recon_loss: 0.027334632351994514, dist_loss: 0.6231834292411804
recon_loss: 0.027334170415997505, dist_loss: 0.5046336650848389
recon_loss: 0.02733265794813633, dist_loss: 0.7960172891616821
recon_loss: 0.0273322444409132, dist_loss: 0.7657700777053833
recon_loss: 0.02733166329562664, dist_loss: 0.5573217868804932
recon_loss: 0.027331015095114708, dist_loss: 0.5872241258621216
recon_loss: 0.027330856770277023, dist_loss: 0.5759468078613281
recon_loss: 0.0273301862180233, dist_loss: 1.2996001243591309
recon_loss: 0.02733043022453785, dist_loss: 0.8696112632751465
recon_loss: 0.027329852804541588, dist_loss: 0.7563759088516235
recon_loss: 0.02732970006763935, dist_loss: 0.7958350777626038
recon_loss: 0.02732994593679905, dist_loss: 0.7117405533790588
recon_loss: 0.027330124750733376, dist_loss: 0.5667948126792908
recon_loss: 0.027329586446285248, dist_loss: 0.47998329997062683
recon_loss: 0.027327878400683403, dist_loss: 0.5541675090789795
recon_loss: 0.02732844091951847, dist_loss: 0.5011672973632812
recon_loss: 0.027327649295330048, dist_loss: 0.6287766695022583
recon_loss: 0.02732853777706623, dist_loss: 0.8306562900543213
recon_loss: 0.02732798457145691, dist_loss: 0.4615839719772339
recon_loss: 0.027327725663781166, dist_loss: 1.113464593887329
recon_loss: 0.027328411117196083, dist_loss: 0.4525182843208313
recon_loss: 0.02732807584106922, dist_loss: 0.3375474810600281
recon_loss: 0.02732822671532631, dist_loss: 0.5267177820205688
recon_loss: 0.0273277647793293, dist_loss: 0.5995021462440491
recon_loss: 0.027327856048941612, dist_loss: 0.23220691084861755
recon_loss: 0.027327127754688263, dist_loss: 0.7810976505279541
recon_loss: 0.027326710522174835, dist_loss: 0.8689661622047424
recon_loss: 0.027326421812176704, dist_loss: 0.712101399898529
recon_loss: 0.027325818315148354, dist_loss: 0.5518087148666382
recon_loss: 0.02732577733695507, dist_loss: 1.0932313203811646
recon_loss: 0.027326086536049843, dist_loss: 0.5952358841896057
recon_loss: 0.02732687070965767, dist_loss: 0.927848219871521
recon_loss: 0.027327556163072586, dist_loss: 0.9582985043525696
recon_loss: 0.02732820250093937, dist_loss: 0.4567692279815674
recon_loss: 0.02732880227267742, dist_loss: 0.6322935819625854
recon_loss: 0.02732989937067032, dist_loss: 0.521384060382843
recon_loss: 0.02733049914240837, dist_loss: 0.9831738471984863
recon_loss: 0.027330992743372917, dist_loss: 0.5879170894622803
recon_loss: 0.027330994606018066, dist_loss: 0.7873899936676025
recon_loss: 0.027330750599503517, dist_loss: 0.7176648378372192
recon_loss: 0.027330072596669197, dist_loss: 0.5006700754165649
recon_loss: 0.02732866071164608, dist_loss: 0.9384082555770874
recon_loss: 0.027328357100486755, dist_loss: 0.7740854620933533
recon_loss: 0.027327464893460274, dist_loss: 0.3834603428840637
recon_loss: 0.027327384799718857, dist_loss: 0.7958672642707825
recon_loss: 0.02732756733894348, dist_loss: 1.0020554065704346
recon_loss: 0.02732863649725914, dist_loss: 0.45936790108680725
recon_loss: 0.02733004279434681, dist_loss: 0.4228527247905731
recon_loss: 0.02733207680284977, dist_loss: 0.3781203329563141
recon_loss: 0.027333874255418777, dist_loss: 0.3225412666797638
recon_loss: 0.027334699407219887, dist_loss: 0.7876579761505127
recon_loss: 0.02733500674366951, dist_loss: 0.45977821946144104
recon_loss: 0.027335120365023613, dist_loss: 0.6850006580352783
recon_loss: 0.02733347937464714, dist_loss: 0.6042561531066895
recon_loss: 0.027332134544849396, dist_loss: 0.5946162939071655
recon_loss: 0.027330933138728142, dist_loss: 0.9043843150138855
recon_loss: 0.02732943743467331, dist_loss: 0.4775959253311157
recon_loss: 0.02732812985777855, dist_loss: 0.5664734840393066
recon_loss: 0.027328092604875565, dist_loss: 0.4771603047847748
recon_loss: 0.027328111231327057, dist_loss: 0.40606170892715454
recon_loss: 0.027329029515385628, dist_loss: 0.9399511218070984
recon_loss: 0.027328798547387123, dist_loss: 1.0394093990325928
recon_loss: 0.027328798547387123, dist_loss: 0.8966027498245239
recon_loss: 0.027328282594680786, dist_loss: 0.28678447008132935
recon_loss: 0.02732810378074646, dist_loss: 0.6287932395935059
recon_loss: 0.027327779680490494, dist_loss: 0.42868831753730774
recon_loss: 0.02732761763036251, dist_loss: 0.4640016257762909
recon_loss: 0.02732713706791401, dist_loss: 0.5203450918197632
recon_loss: 0.027326518669724464, dist_loss: 0.45566728711128235
recon_loss: 0.02732636220753193, dist_loss: 0.764232873916626
recon_loss: 0.027327310293912888, dist_loss: 0.6140197515487671
Pre-training Epoch 110:  36%|███▌      | 132/367 [00:00<00:01, 165.29it/s]Pre-training Epoch 110:  41%|████      | 150/367 [00:00<00:01, 169.49it/s]Pre-training Epoch 110:  46%|████▌     | 169/367 [00:01<00:01, 172.94it/s]Pre-training Epoch 110:  51%|█████     | 187/367 [00:01<00:01, 173.91it/s]Pre-training Epoch 110:  56%|█████▌    | 206/367 [00:01<00:00, 175.93it/s]Pre-training Epoch 110:  61%|██████▏   | 225/367 [00:01<00:00, 177.40it/s]Pre-training Epoch 110:  66%|██████▌   | 243/367 [00:01<00:00, 174.45it/s]recon_loss: 0.02732887677848339, dist_loss: 0.8590707778930664
recon_loss: 0.027329036965966225, dist_loss: 0.6640371084213257
recon_loss: 0.027330363169312477, dist_loss: 0.997701108455658
recon_loss: 0.02732965722680092, dist_loss: 0.4724174439907074
recon_loss: 0.0273301862180233, dist_loss: 0.546485424041748
recon_loss: 0.027329713106155396, dist_loss: 0.7542190551757812
recon_loss: 0.027329476550221443, dist_loss: 0.9495729207992554
recon_loss: 0.027329495176672935, dist_loss: 0.6150016188621521
recon_loss: 0.027327541261911392, dist_loss: 0.4664144515991211
recon_loss: 0.027327770367264748, dist_loss: 0.7650543451309204
recon_loss: 0.027326596900820732, dist_loss: 0.8579646348953247
recon_loss: 0.02732674777507782, dist_loss: 0.6247424483299255
recon_loss: 0.02732582949101925, dist_loss: 0.9434996247291565
recon_loss: 0.027325645089149475, dist_loss: 0.4146845042705536
recon_loss: 0.027325518429279327, dist_loss: 0.5377274751663208
recon_loss: 0.027326421812176704, dist_loss: 0.5691245794296265
recon_loss: 0.027327077463269234, dist_loss: 0.8371195793151855
recon_loss: 0.027327874675393105, dist_loss: 0.4853672385215759
recon_loss: 0.027327436953783035, dist_loss: 0.7927576303482056
recon_loss: 0.027326956391334534, dist_loss: 0.41566595435142517
recon_loss: 0.027326982468366623, dist_loss: 0.5436500906944275
recon_loss: 0.027326447889208794, dist_loss: 0.6662936210632324
recon_loss: 0.027326596900820732, dist_loss: 0.5057909488677979
recon_loss: 0.027325300499796867, dist_loss: 1.4915224313735962
recon_loss: 0.027325179427862167, dist_loss: 1.1403613090515137
recon_loss: 0.027324127033352852, dist_loss: 0.6082428097724915
recon_loss: 0.02732403390109539, dist_loss: 0.6084198951721191
recon_loss: 0.027323227375745773, dist_loss: 0.5221486687660217
recon_loss: 0.02732282504439354, dist_loss: 0.384306401014328
recon_loss: 0.027323288843035698, dist_loss: 0.908063530921936
recon_loss: 0.02732408605515957, dist_loss: 0.6678307056427002
recon_loss: 0.027323998510837555, dist_loss: 0.5953270792961121
recon_loss: 0.027324439957737923, dist_loss: 0.8097711801528931
recon_loss: 0.027324704453349113, dist_loss: 0.8751868009567261
recon_loss: 0.02732471004128456, dist_loss: 0.6645165681838989
recon_loss: 0.027324194088578224, dist_loss: 0.5087465047836304
recon_loss: 0.027323711663484573, dist_loss: 0.5279567837715149
recon_loss: 0.027323313057422638, dist_loss: 0.7358328104019165
recon_loss: 0.027323175221681595, dist_loss: 0.9274557828903198
recon_loss: 0.027323096990585327, dist_loss: 0.45935672521591187
recon_loss: 0.027322646230459213, dist_loss: 0.5700016021728516
recon_loss: 0.027322016656398773, dist_loss: 0.960502028465271
recon_loss: 0.027321692556142807, dist_loss: 1.1873071193695068
recon_loss: 0.027321940287947655, dist_loss: 0.34864097833633423
recon_loss: 0.027321739122271538, dist_loss: 0.7672854661941528
recon_loss: 0.02732177823781967, dist_loss: 0.33206507563591003
recon_loss: 0.027321763336658478, dist_loss: 0.7244729995727539
recon_loss: 0.027321726083755493, dist_loss: 0.5246015787124634
recon_loss: 0.02732200361788273, dist_loss: 0.49791234731674194
recon_loss: 0.027321957051753998, dist_loss: 0.6112104654312134
recon_loss: 0.027321701869368553, dist_loss: 0.7038992047309875
recon_loss: 0.02732132561504841, dist_loss: 0.7578633427619934
recon_loss: 0.027321707457304, dist_loss: 0.5911338925361633
recon_loss: 0.027320904657244682, dist_loss: 0.5853432416915894
recon_loss: 0.02732151560485363, dist_loss: 0.4988887310028076
recon_loss: 0.02732093259692192, dist_loss: 1.3875482082366943
recon_loss: 0.027322562411427498, dist_loss: 0.6135672330856323
recon_loss: 0.02732265554368496, dist_loss: 0.7591313719749451
recon_loss: 0.02732347510755062, dist_loss: 0.5388559699058533
recon_loss: 0.027324382215738297, dist_loss: 0.452146053314209
recon_loss: 0.027323812246322632, dist_loss: 0.5693783164024353
recon_loss: 0.0273248553276062, dist_loss: 0.8314104080200195
recon_loss: 0.027323685586452484, dist_loss: 0.8546499013900757
recon_loss: 0.027323612943291664, dist_loss: 0.5253233909606934
recon_loss: 0.027322545647621155, dist_loss: 0.831802487373352
recon_loss: 0.027321839705109596, dist_loss: 0.49356600642204285
recon_loss: 0.02732175588607788, dist_loss: 0.5625298023223877
recon_loss: 0.027321482077240944, dist_loss: 0.5171266794204712
recon_loss: 0.02732166461646557, dist_loss: 0.6012045741081238
recon_loss: 0.027321357280015945, dist_loss: 0.7485407590866089
recon_loss: 0.027321379631757736, dist_loss: 0.6518025994300842
recon_loss: 0.027320578694343567, dist_loss: 0.42437559366226196
recon_loss: 0.02731986530125141, dist_loss: 0.287061482667923
recon_loss: 0.027319423854351044, dist_loss: 0.6016053557395935
recon_loss: 0.027319520711898804, dist_loss: 0.7043416500091553
recon_loss: 0.027319645509123802, dist_loss: 0.45065611600875854
recon_loss: 0.027319680899381638, dist_loss: 1.043330430984497
recon_loss: 0.027319258078932762, dist_loss: 0.3647845387458801
recon_loss: 0.027318838983774185, dist_loss: 0.5446391105651855
recon_loss: 0.027318201959133148, dist_loss: 0.5800979137420654
recon_loss: 0.027317825704813004, dist_loss: 0.4296720027923584
recon_loss: 0.02731737121939659, dist_loss: 0.8596782684326172
recon_loss: 0.027316920459270477, dist_loss: 0.6142700910568237
recon_loss: 0.027317291125655174, dist_loss: 0.5891691446304321
recon_loss: 0.027317553758621216, dist_loss: 0.6117566227912903
recon_loss: 0.027318762615323067, dist_loss: 0.4823114275932312
recon_loss: 0.027319250628352165, dist_loss: 0.4207681119441986
recon_loss: 0.027321210131049156, dist_loss: 0.6697180867195129
recon_loss: 0.027321673929691315, dist_loss: 0.6621508002281189
recon_loss: 0.027322303503751755, dist_loss: 0.6866909265518188
recon_loss: 0.027322249487042427, dist_loss: 0.6399967074394226
recon_loss: 0.027322236448526382, dist_loss: 0.5281494855880737
recon_loss: 0.02732197195291519, dist_loss: 0.7925647497177124
recon_loss: 0.02732040174305439, dist_loss: 0.5092077851295471
recon_loss: 0.027319876477122307, dist_loss: 0.5100451707839966
recon_loss: 0.02731860615313053, dist_loss: 0.9555610418319702
recon_loss: 0.027318503707647324, dist_loss: 0.6189377903938293
recon_loss: 0.027317732572555542, dist_loss: 0.5959930419921875
recon_loss: 0.02731899358332157, dist_loss: 0.6532968282699585
recon_loss: 0.027318157255649567, dist_loss: 0.8347280025482178
recon_loss: 0.02731853909790516, dist_loss: 0.9186990261077881
recon_loss: 0.02731839381158352, dist_loss: 0.5612521171569824
recon_loss: 0.02731875330209732, dist_loss: 1.0573698282241821
recon_loss: 0.027318447828292847, dist_loss: 0.4631536304950714
recon_loss: 0.02731824293732643, dist_loss: 0.4900094270706177
recon_loss: 0.02731718309223652, dist_loss: 0.5369754433631897
recon_loss: 0.027316713705658913, dist_loss: 0.6192073822021484
recon_loss: 0.027316393330693245, dist_loss: 0.46189960837364197
recon_loss: 0.027316207066178322, dist_loss: 0.5692960023880005
recon_loss: 0.02731647714972496, dist_loss: 0.38596805930137634
recon_loss: 0.027316128835082054, dist_loss: 0.6143183708190918
recon_loss: 0.027316318824887276, dist_loss: 0.4725433588027954
recon_loss: 0.02731620892882347, dist_loss: 0.6879428625106812
recon_loss: 0.02731575444340706, dist_loss: 0.6493869423866272
recon_loss: 0.02731556072831154, dist_loss: 0.3478613495826721
recon_loss: 0.027315398678183556, dist_loss: 0.49849146604537964
recon_loss: 0.027315471321344376, dist_loss: 0.5964350700378418
recon_loss: 0.027315715327858925, dist_loss: 0.7175821661949158
recon_loss: 0.02731623500585556, dist_loss: 1.2001465559005737
recon_loss: 0.02731684036552906, dist_loss: 0.7049733400344849
recon_loss: 0.027316823601722717, dist_loss: 0.7833177447319031
recon_loss: 0.027316315099596977, dist_loss: 0.7373414039611816
recon_loss: 0.02731580100953579, dist_loss: 0.4985214173793793
recon_loss: 0.027315432205796242, dist_loss: 0.5172883868217468
recon_loss: 0.027315862476825714, dist_loss: 0.8231402039527893
recon_loss: 0.027316860854625702, dist_loss: 0.5659434795379639
recon_loss: 0.027319958433508873, dist_loss: 0.34487757086753845
recon_loss: 0.02732268162071705, dist_loss: 0.40777745842933655
Pre-training Epoch 110:  71%|███████   | 261/367 [00:01<00:00, 167.77it/s]Pre-training Epoch 110:  76%|███████▌  | 278/367 [00:01<00:00, 160.71it/s]Pre-training Epoch 110:  80%|████████  | 295/367 [00:01<00:00, 156.37it/s]Pre-training Epoch 110:  85%|████████▌ | 313/367 [00:01<00:00, 162.57it/s]Pre-training Epoch 110:  90%|█████████ | 331/367 [00:02<00:00, 167.24it/s]Pre-training Epoch 110:  95%|█████████▍| 348/367 [00:02<00:00, 163.24it/s]Pre-training Epoch 110:  99%|█████████▉| 365/367 [00:02<00:00, 159.69it/s]Pre-training Epoch 110: 100%|██████████| 367/367 [00:02<00:00, 163.90it/s]
recon_loss: 0.02732713334262371, dist_loss: 0.8134236335754395
recon_loss: 0.027327949181199074, dist_loss: 0.4395078420639038
recon_loss: 0.02732817828655243, dist_loss: 0.7335693836212158
recon_loss: 0.027328571304678917, dist_loss: 0.8785292506217957
recon_loss: 0.027327436953783035, dist_loss: 0.8729180097579956
recon_loss: 0.027326777577400208, dist_loss: 1.1436359882354736
recon_loss: 0.027322469279170036, dist_loss: 0.619581401348114
recon_loss: 0.027321577072143555, dist_loss: 1.5389466285705566
recon_loss: 0.02731851302087307, dist_loss: 1.1179778575897217
recon_loss: 0.02731936052441597, dist_loss: 0.9409630298614502
recon_loss: 0.02732020802795887, dist_loss: 0.5211014151573181
recon_loss: 0.027320675551891327, dist_loss: 0.6381586790084839
recon_loss: 0.027324963361024857, dist_loss: 0.5929327011108398
recon_loss: 0.027326514944434166, dist_loss: 0.4785388112068176
recon_loss: 0.027331577613949776, dist_loss: 0.545448899269104
recon_loss: 0.02733052894473076, dist_loss: 0.755025327205658
recon_loss: 0.027334701269865036, dist_loss: 0.9696561694145203
recon_loss: 0.02733202651143074, dist_loss: 0.4820711612701416
recon_loss: 0.027333000674843788, dist_loss: 0.45688343048095703
recon_loss: 0.027331598103046417, dist_loss: 0.3461798429489136
recon_loss: 0.027329500764608383, dist_loss: 0.5454845428466797
recon_loss: 0.0273292176425457, dist_loss: 0.8419429659843445
recon_loss: 0.02732674963772297, dist_loss: 0.8532345294952393
recon_loss: 0.02732398360967636, dist_loss: 0.5657905340194702
recon_loss: 0.027321308851242065, dist_loss: 0.5720447301864624
recon_loss: 0.02732047438621521, dist_loss: 0.7525558471679688
recon_loss: 0.02731921337544918, dist_loss: 0.6148078441619873
recon_loss: 0.027319345623254776, dist_loss: 0.9602364897727966
recon_loss: 0.027320029214024544, dist_loss: 0.6019120216369629
recon_loss: 0.02732250839471817, dist_loss: 1.0722863674163818
recon_loss: 0.02732313610613346, dist_loss: 0.838056206703186
recon_loss: 0.027324039489030838, dist_loss: 0.7039417028427124
recon_loss: 0.027324287220835686, dist_loss: 0.5988977551460266
recon_loss: 0.027324818074703217, dist_loss: 0.5282362699508667
recon_loss: 0.027325419709086418, dist_loss: 0.5507059097290039
recon_loss: 0.027325309813022614, dist_loss: 0.4737662076950073
recon_loss: 0.02732543647289276, dist_loss: 0.4117434620857239
recon_loss: 0.027325045317411423, dist_loss: 0.5587165355682373
recon_loss: 0.027324821799993515, dist_loss: 0.430820494890213
recon_loss: 0.027324547991156578, dist_loss: 0.4769570231437683
recon_loss: 0.027324479073286057, dist_loss: 0.5751281976699829
recon_loss: 0.027324585244059563, dist_loss: 0.7396676540374756
recon_loss: 0.027325069531798363, dist_loss: 0.37111374735832214
recon_loss: 0.027325984090566635, dist_loss: 0.7950969934463501
recon_loss: 0.02732553891837597, dist_loss: 0.4277164041996002
recon_loss: 0.02732500620186329, dist_loss: 0.446063756942749
recon_loss: 0.02732359804213047, dist_loss: 0.9140294790267944
recon_loss: 0.027322405949234962, dist_loss: 0.36683887243270874
recon_loss: 0.02732086181640625, dist_loss: 0.37330037355422974
recon_loss: 0.02731950767338276, dist_loss: 0.42503005266189575
recon_loss: 0.027318710461258888, dist_loss: 0.5860816240310669
recon_loss: 0.027318833395838737, dist_loss: 0.5264983773231506
recon_loss: 0.027318710461258888, dist_loss: 0.702189028263092
recon_loss: 0.02731926552951336, dist_loss: 0.7635583281517029
recon_loss: 0.02731984108686447, dist_loss: 0.7668775916099548
recon_loss: 0.027320215478539467, dist_loss: 0.49427592754364014
recon_loss: 0.027322201058268547, dist_loss: 0.6095747351646423
recon_loss: 0.02732194773852825, dist_loss: 0.40071427822113037
recon_loss: 0.02732332982122898, dist_loss: 0.7327478528022766
recon_loss: 0.027321629226207733, dist_loss: 0.7111667394638062
recon_loss: 0.027322271838784218, dist_loss: 0.6240488290786743
recon_loss: 0.027320683002471924, dist_loss: 0.675675630569458
recon_loss: 0.02732061594724655, dist_loss: 0.785977840423584
recon_loss: 0.027319401502609253, dist_loss: 0.2624927759170532
recon_loss: 0.027318725362420082, dist_loss: 0.5512169599533081
recon_loss: 0.02731897123157978, dist_loss: 0.3303883671760559
recon_loss: 0.027316920459270477, dist_loss: 0.4702990651130676
recon_loss: 0.027317779138684273, dist_loss: 0.6281583309173584
recon_loss: 0.027315905317664146, dist_loss: 1.1848819255828857
recon_loss: 0.027315283194184303, dist_loss: 0.7940791845321655
recon_loss: 0.02731405757367611, dist_loss: 0.4038347601890564
recon_loss: 0.02731367014348507, dist_loss: 0.5147120952606201
recon_loss: 0.027313118800520897, dist_loss: 0.4122175872325897
recon_loss: 0.02731306664645672, dist_loss: 0.7703984975814819
recon_loss: 0.027312999591231346, dist_loss: 0.8848608732223511
recon_loss: 0.027312984690070152, dist_loss: 0.9868932962417603
recon_loss: 0.027313003316521645, dist_loss: 0.8467011451721191
recon_loss: 0.027313265949487686, dist_loss: 0.5583847761154175
recon_loss: 0.027313634753227234, dist_loss: 0.526427149772644
recon_loss: 0.027314117178320885, dist_loss: 0.495730459690094
recon_loss: 0.02731466107070446, dist_loss: 0.7134829759597778
recon_loss: 0.027314787730574608, dist_loss: 0.7469614744186401
recon_loss: 0.027315229177474976, dist_loss: 0.41854873299598694
recon_loss: 0.027315275743603706, dist_loss: 0.2948867082595825
recon_loss: 0.027315134182572365, dist_loss: 0.7268199920654297
recon_loss: 0.02731434814631939, dist_loss: 0.34835726022720337
recon_loss: 0.0273138377815485, dist_loss: 0.5742104053497314
recon_loss: 0.02731403335928917, dist_loss: 0.7851230502128601
recon_loss: 0.027312610298395157, dist_loss: 0.8226731419563293
recon_loss: 0.02731231600046158, dist_loss: 0.8030227422714233
recon_loss: 0.02731126919388771, dist_loss: 0.5086594820022583
recon_loss: 0.02731229178607464, dist_loss: 0.30760279297828674
recon_loss: 0.027311939746141434, dist_loss: 0.7365057468414307
recon_loss: 0.027313679456710815, dist_loss: 0.7316029667854309
recon_loss: 0.027314456179738045, dist_loss: 0.3826833963394165
recon_loss: 0.027315938845276833, dist_loss: 0.3834001421928406
recon_loss: 0.027316223829984665, dist_loss: 0.40853816270828247
recon_loss: 0.02731582149863243, dist_loss: 0.6150293946266174
recon_loss: 0.027315815910696983, dist_loss: 0.5318875312805176
recon_loss: 0.027314914390444756, dist_loss: 0.766349196434021
recon_loss: 0.02731378935277462, dist_loss: 0.32370519638061523
recon_loss: 0.02731279842555523, dist_loss: 0.6365524530410767
recon_loss: 0.027311958372592926, dist_loss: 0.4023919701576233
recon_loss: 0.027311256155371666, dist_loss: 0.7853275537490845
recon_loss: 0.027310913428664207, dist_loss: 0.6044474840164185
recon_loss: 0.02731047198176384, dist_loss: 0.43455731868743896
recon_loss: 0.027310162782669067, dist_loss: 0.5770877599716187
recon_loss: 0.027309847995638847, dist_loss: 0.5753988027572632
recon_loss: 0.027309676632285118, dist_loss: 0.31365877389907837
recon_loss: 0.027309797704219818, dist_loss: 0.423734188079834
recon_loss: 0.02730965055525303, dist_loss: 0.5257055759429932
Pre-train Epoch: 110
Train - Total Loss: 0.0921, Recon Loss: 0.0273, Dist Loss: 0.6476, l1 regularization: 0.0000
Val - Total Loss: 0.0967, Recon Loss: 0.0273, Dist Loss: 0.6939, l1 regularization: 0.0000
Pre-training Epoch 111:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 111:   4%|▍         | 15/367 [00:00<00:02, 142.92it/s]Pre-training Epoch 111:   8%|▊         | 31/367 [00:00<00:02, 149.05it/s]Pre-training Epoch 111:  13%|█▎        | 48/367 [00:00<00:02, 155.69it/s]Pre-training Epoch 111:  18%|█▊        | 67/367 [00:00<00:01, 166.01it/s]Pre-training Epoch 111:  23%|██▎       | 84/367 [00:00<00:01, 165.10it/s]Pre-training Epoch 111:  28%|██▊       | 102/367 [00:00<00:01, 168.21it/s]Pre-training Epoch 111:  32%|███▏      | 119/367 [00:00<00:01, 163.70it/s]recon_loss: 0.027310069650411606, dist_loss: 0.5570385456085205
recon_loss: 0.027309995144605637, dist_loss: 0.47024112939834595
recon_loss: 0.027310648933053017, dist_loss: 0.49554958939552307
recon_loss: 0.027311258018016815, dist_loss: 0.7169178128242493
recon_loss: 0.027311477810144424, dist_loss: 0.9465901851654053
recon_loss: 0.027311792597174644, dist_loss: 0.3049497604370117
recon_loss: 0.027311868965625763, dist_loss: 0.9941546320915222
recon_loss: 0.027312079444527626, dist_loss: 0.5939575433731079
recon_loss: 0.027311546728014946, dist_loss: 0.8820001482963562
recon_loss: 0.027310948818922043, dist_loss: 0.28054991364479065
recon_loss: 0.027310825884342194, dist_loss: 0.5578359365463257
recon_loss: 0.027310561388731003, dist_loss: 0.6015948057174683
recon_loss: 0.027310537174344063, dist_loss: 0.6530823707580566
recon_loss: 0.02731028012931347, dist_loss: 0.6747002005577087
recon_loss: 0.027310341596603394, dist_loss: 0.345758855342865
recon_loss: 0.027309851720929146, dist_loss: 0.39048832654953003
recon_loss: 0.027310216799378395, dist_loss: 0.5599079132080078
recon_loss: 0.027310222387313843, dist_loss: 0.2690638601779938
recon_loss: 0.027310268953442574, dist_loss: 0.9208173751831055
recon_loss: 0.027310822159051895, dist_loss: 0.7600055932998657
recon_loss: 0.027310525998473167, dist_loss: 0.4881681501865387
recon_loss: 0.027311457321047783, dist_loss: 0.6774985790252686
recon_loss: 0.027310680598020554, dist_loss: 0.6254134178161621
recon_loss: 0.027308758348226547, dist_loss: 0.993045449256897
recon_loss: 0.027309386059641838, dist_loss: 0.8409966826438904
recon_loss: 0.027308233082294464, dist_loss: 1.1314151287078857
recon_loss: 0.027308795601129532, dist_loss: 0.8124808669090271
recon_loss: 0.02730792760848999, dist_loss: 0.2573145627975464
recon_loss: 0.02730787917971611, dist_loss: 0.44206514954566956
recon_loss: 0.027307938784360886, dist_loss: 1.1252341270446777
recon_loss: 0.02730783447623253, dist_loss: 0.5494730472564697
recon_loss: 0.02730872854590416, dist_loss: 0.5865347385406494
recon_loss: 0.02730879932641983, dist_loss: 1.1673049926757812
recon_loss: 0.027309782803058624, dist_loss: 0.37736278772354126
recon_loss: 0.02731061540544033, dist_loss: 0.6740577220916748
recon_loss: 0.02731095626950264, dist_loss: 0.6223753094673157
recon_loss: 0.027310727164149284, dist_loss: 0.7879528999328613
recon_loss: 0.02730948105454445, dist_loss: 0.5994069576263428
recon_loss: 0.027308747172355652, dist_loss: 0.4563291072845459
recon_loss: 0.027307946234941483, dist_loss: 0.5156508088111877
recon_loss: 0.02730722352862358, dist_loss: 0.8798067569732666
recon_loss: 0.027306891977787018, dist_loss: 0.40258896350860596
recon_loss: 0.027306903153657913, dist_loss: 0.38374316692352295
recon_loss: 0.02730681747198105, dist_loss: 0.5185152888298035
recon_loss: 0.02730700559914112, dist_loss: 0.761223316192627
recon_loss: 0.027306994423270226, dist_loss: 0.9486216306686401
recon_loss: 0.027307095006108284, dist_loss: 0.8743138313293457
recon_loss: 0.027307696640491486, dist_loss: 0.5489071607589722
recon_loss: 0.027307992801070213, dist_loss: 0.5182639360427856
recon_loss: 0.027308428660035133, dist_loss: 0.5641670227050781
recon_loss: 0.027308370918035507, dist_loss: 0.39271247386932373
recon_loss: 0.027308175340294838, dist_loss: 0.36062192916870117
recon_loss: 0.02730793133378029, dist_loss: 0.9423191547393799
recon_loss: 0.027307618409395218, dist_loss: 0.7985534071922302
recon_loss: 0.02730775997042656, dist_loss: 0.48170197010040283
recon_loss: 0.027308043092489243, dist_loss: 0.35464006662368774
recon_loss: 0.027307838201522827, dist_loss: 0.9851999282836914
recon_loss: 0.027307622134685516, dist_loss: 1.0488018989562988
recon_loss: 0.027306804433465004, dist_loss: 0.6534153819084167
recon_loss: 0.027307141572237015, dist_loss: 0.5789303183555603
recon_loss: 0.02730811946094036, dist_loss: 0.6755964756011963
recon_loss: 0.027310354635119438, dist_loss: 0.6576522588729858
recon_loss: 0.027311058714985847, dist_loss: 0.5789313316345215
recon_loss: 0.02731289155781269, dist_loss: 0.44252198934555054
recon_loss: 0.02731219120323658, dist_loss: 0.8888804316520691
recon_loss: 0.027312811464071274, dist_loss: 0.626278281211853
recon_loss: 0.027311349287629128, dist_loss: 0.6134194135665894
recon_loss: 0.027311787009239197, dist_loss: 0.5318964719772339
recon_loss: 0.027311118319630623, dist_loss: 0.6794743537902832
recon_loss: 0.02731185592710972, dist_loss: 0.6646871566772461
recon_loss: 0.027310021221637726, dist_loss: 0.4573136568069458
recon_loss: 0.027309108525514603, dist_loss: 0.6650053262710571
recon_loss: 0.027308061718940735, dist_loss: 0.94530189037323
recon_loss: 0.0273074209690094, dist_loss: 0.8006418347358704
recon_loss: 0.027308152988553047, dist_loss: 0.41172903776168823
recon_loss: 0.02730856090784073, dist_loss: 0.9198101758956909
recon_loss: 0.027309441938996315, dist_loss: 0.44095709919929504
recon_loss: 0.027310267090797424, dist_loss: 0.6749972105026245
recon_loss: 0.027311252430081367, dist_loss: 0.43140146136283875
recon_loss: 0.0273111704736948, dist_loss: 0.6578608155250549
recon_loss: 0.02731148526072502, dist_loss: 1.0893672704696655
recon_loss: 0.027310945093631744, dist_loss: 0.6954320073127747
recon_loss: 0.027311502024531364, dist_loss: 0.590935230255127
recon_loss: 0.02731022611260414, dist_loss: 0.5902612209320068
recon_loss: 0.027308888733386993, dist_loss: 0.426503449678421
recon_loss: 0.027307793498039246, dist_loss: 0.36214011907577515
recon_loss: 0.02730829454958439, dist_loss: 0.6924203038215637
recon_loss: 0.02730814553797245, dist_loss: 0.8228391408920288
recon_loss: 0.027309061959385872, dist_loss: 0.5505962371826172
recon_loss: 0.027310214936733246, dist_loss: 0.4643169641494751
recon_loss: 0.0273100808262825, dist_loss: 0.690017819404602
recon_loss: 0.027312008664011955, dist_loss: 0.5100610852241516
recon_loss: 0.027310756966471672, dist_loss: 0.7353764176368713
recon_loss: 0.02731066197156906, dist_loss: 0.9543195962905884
recon_loss: 0.02731107920408249, dist_loss: 0.8224765062332153
recon_loss: 0.02731034904718399, dist_loss: 0.6096984148025513
recon_loss: 0.027309369295835495, dist_loss: 0.7322021722793579
recon_loss: 0.027307631447911263, dist_loss: 0.9482429623603821
recon_loss: 0.02730880118906498, dist_loss: 0.9315376877784729
recon_loss: 0.027310358360409737, dist_loss: 0.48647046089172363
recon_loss: 0.027312064543366432, dist_loss: 0.9857401847839355
recon_loss: 0.027315545827150345, dist_loss: 0.6049164533615112
recon_loss: 0.02731848880648613, dist_loss: 0.505501389503479
recon_loss: 0.027322247624397278, dist_loss: 0.5388908386230469
recon_loss: 0.02732252888381481, dist_loss: 0.5980274677276611
recon_loss: 0.02732274867594242, dist_loss: 0.8114677667617798
recon_loss: 0.027320239692926407, dist_loss: 0.3853391110897064
recon_loss: 0.0273192897439003, dist_loss: 0.7524029016494751
recon_loss: 0.027316907420754433, dist_loss: 0.655035138130188
recon_loss: 0.02731490507721901, dist_loss: 0.5583679676055908
recon_loss: 0.027312003076076508, dist_loss: 0.6141379475593567
recon_loss: 0.027310431003570557, dist_loss: 1.0757591724395752
recon_loss: 0.027310950681567192, dist_loss: 1.0089383125305176
recon_loss: 0.02731236442923546, dist_loss: 0.7059013843536377
recon_loss: 0.027316084131598473, dist_loss: 0.7846248149871826
recon_loss: 0.027317073196172714, dist_loss: 0.8542876243591309
recon_loss: 0.027318323031067848, dist_loss: 0.4306755065917969
recon_loss: 0.027317197993397713, dist_loss: 0.5186564922332764
recon_loss: 0.027316950261592865, dist_loss: 0.8352038860321045
recon_loss: 0.027314266189932823, dist_loss: 0.9277824759483337
recon_loss: 0.027313167229294777, dist_loss: 0.3663730025291443
recon_loss: 0.027309896424412727, dist_loss: 0.40565726161003113
recon_loss: 0.027308253571391106, dist_loss: 0.795844316482544
recon_loss: 0.027307357639074326, dist_loss: 0.8330023288726807
recon_loss: 0.027306998148560524, dist_loss: 0.48103266954421997
recon_loss: 0.027309183031320572, dist_loss: 1.339215874671936
recon_loss: 0.02730938233435154, dist_loss: 0.5823253393173218
recon_loss: 0.027313852682709694, dist_loss: 0.6610693335533142
Pre-training Epoch 111:  37%|███▋      | 136/367 [00:00<00:01, 160.23it/s]Pre-training Epoch 111:  42%|████▏     | 154/367 [00:00<00:01, 165.30it/s]Pre-training Epoch 111:  47%|████▋     | 173/367 [00:01<00:01, 170.03it/s]Pre-training Epoch 111:  52%|█████▏    | 191/367 [00:01<00:01, 172.46it/s]Pre-training Epoch 111:  57%|█████▋    | 209/367 [00:01<00:00, 174.34it/s]Pre-training Epoch 111:  62%|██████▏   | 227/367 [00:01<00:00, 175.60it/s]Pre-training Epoch 111:  67%|██████▋   | 246/367 [00:01<00:00, 177.70it/s]recon_loss: 0.027316339313983917, dist_loss: 0.5407778024673462
recon_loss: 0.02731916680932045, dist_loss: 0.8251081705093384
recon_loss: 0.027318429201841354, dist_loss: 0.564042329788208
recon_loss: 0.027317512780427933, dist_loss: 0.7957226634025574
recon_loss: 0.0273149311542511, dist_loss: 0.4316709637641907
recon_loss: 0.027313008904457092, dist_loss: 0.6688269376754761
recon_loss: 0.027310507372021675, dist_loss: 0.4896399676799774
recon_loss: 0.027308877557516098, dist_loss: 0.6599065065383911
recon_loss: 0.02730698697268963, dist_loss: 0.5841107964515686
recon_loss: 0.02730565518140793, dist_loss: 0.4612414240837097
recon_loss: 0.027306396514177322, dist_loss: 0.6418451070785522
recon_loss: 0.027305616065859795, dist_loss: 0.35952627658843994
recon_loss: 0.027308259159326553, dist_loss: 0.8420151472091675
recon_loss: 0.027308620512485504, dist_loss: 0.8490310907363892
recon_loss: 0.02731245383620262, dist_loss: 0.616431713104248
recon_loss: 0.02731439843773842, dist_loss: 0.6399171948432922
recon_loss: 0.027314919978380203, dist_loss: 0.8209056854248047
recon_loss: 0.027316506952047348, dist_loss: 0.8273285627365112
recon_loss: 0.027315929532051086, dist_loss: 0.4192212224006653
recon_loss: 0.027316156774759293, dist_loss: 0.838591456413269
recon_loss: 0.027314769104123116, dist_loss: 0.9856634140014648
recon_loss: 0.02731247991323471, dist_loss: 0.7173234224319458
recon_loss: 0.027312681078910828, dist_loss: 0.5062252283096313
recon_loss: 0.027311943471431732, dist_loss: 0.864290177822113
recon_loss: 0.027312589809298515, dist_loss: 1.1251769065856934
recon_loss: 0.027311885729432106, dist_loss: 0.7008999586105347
recon_loss: 0.027309216558933258, dist_loss: 0.7725610733032227
recon_loss: 0.027310751378536224, dist_loss: 0.6031279563903809
recon_loss: 0.027307240292429924, dist_loss: 0.8340826034545898
recon_loss: 0.027310889214277267, dist_loss: 0.596677303314209
recon_loss: 0.027307074517011642, dist_loss: 0.41272202134132385
recon_loss: 0.027309678494930267, dist_loss: 0.3772343397140503
recon_loss: 0.02731107920408249, dist_loss: 0.6035316586494446
recon_loss: 0.02730737440288067, dist_loss: 0.6122618317604065
recon_loss: 0.027310257777571678, dist_loss: 0.8926724791526794
recon_loss: 0.02730722911655903, dist_loss: 0.4273236393928528
recon_loss: 0.027308715507388115, dist_loss: 0.5612432956695557
recon_loss: 0.027308017015457153, dist_loss: 0.8477205038070679
recon_loss: 0.027307769283652306, dist_loss: 1.2172064781188965
recon_loss: 0.02730792947113514, dist_loss: 0.5254193544387817
recon_loss: 0.027308320626616478, dist_loss: 0.9925030469894409
recon_loss: 0.027309508994221687, dist_loss: 0.37217891216278076
recon_loss: 0.027310311794281006, dist_loss: 0.5948668122291565
recon_loss: 0.027311725541949272, dist_loss: 0.7108656167984009
recon_loss: 0.02731301449239254, dist_loss: 0.5361603498458862
recon_loss: 0.027313774451613426, dist_loss: 0.4570605754852295
recon_loss: 0.027312608435750008, dist_loss: 0.8893768191337585
recon_loss: 0.027311626821756363, dist_loss: 0.6438359022140503
recon_loss: 0.02731005661189556, dist_loss: 0.8768622875213623
recon_loss: 0.027309373021125793, dist_loss: 0.534142792224884
recon_loss: 0.027308901771903038, dist_loss: 0.36847245693206787
recon_loss: 0.027307873591780663, dist_loss: 0.5763727426528931
recon_loss: 0.0273082684725523, dist_loss: 0.5975926518440247
recon_loss: 0.02730717323720455, dist_loss: 0.780822217464447
recon_loss: 0.02730747126042843, dist_loss: 0.8575222492218018
recon_loss: 0.027307547628879547, dist_loss: 0.5474023818969727
recon_loss: 0.027306651696562767, dist_loss: 0.7772927284240723
recon_loss: 0.027307497337460518, dist_loss: 0.48818427324295044
recon_loss: 0.02730453573167324, dist_loss: 0.656674861907959
recon_loss: 0.027306798845529556, dist_loss: 0.7952532172203064
recon_loss: 0.027303852140903473, dist_loss: 0.5871056914329529
recon_loss: 0.027304138988256454, dist_loss: 0.5029695630073547
recon_loss: 0.0273035429418087, dist_loss: 0.551091194152832
recon_loss: 0.02730436995625496, dist_loss: 0.44761714339256287
recon_loss: 0.027307430282235146, dist_loss: 0.9439609050750732
recon_loss: 0.02730599045753479, dist_loss: 0.5860607624053955
recon_loss: 0.027309546247124672, dist_loss: 0.9183396100997925
recon_loss: 0.027306821197271347, dist_loss: 0.5328339338302612
recon_loss: 0.027305645868182182, dist_loss: 0.6334670186042786
recon_loss: 0.02730637416243553, dist_loss: 0.6016463041305542
recon_loss: 0.027302972972393036, dist_loss: 0.3119567632675171
recon_loss: 0.027305154129862785, dist_loss: 0.6021063327789307
recon_loss: 0.027302246540784836, dist_loss: 0.4314305782318115
recon_loss: 0.027303725481033325, dist_loss: 0.526452362537384
recon_loss: 0.02730405703186989, dist_loss: 0.6272220611572266
recon_loss: 0.02730773575603962, dist_loss: 0.37096208333969116
recon_loss: 0.027311502024531364, dist_loss: 0.598896324634552
recon_loss: 0.027311325073242188, dist_loss: 0.5177491307258606
recon_loss: 0.02731688693165779, dist_loss: 0.5393143892288208
recon_loss: 0.02731471322476864, dist_loss: 1.0396754741668701
recon_loss: 0.027316318824887276, dist_loss: 0.5635080337524414
recon_loss: 0.027315538376569748, dist_loss: 0.4767468571662903
recon_loss: 0.027315828949213028, dist_loss: 0.5781625509262085
recon_loss: 0.027317792177200317, dist_loss: 0.7999714612960815
recon_loss: 0.027317848056554794, dist_loss: 0.5158818364143372
recon_loss: 0.027317853644490242, dist_loss: 0.48207271099090576
recon_loss: 0.027316607534885406, dist_loss: 0.6202695369720459
recon_loss: 0.02731628715991974, dist_loss: 0.6822182536125183
recon_loss: 0.027316445484757423, dist_loss: 0.4694894552230835
recon_loss: 0.027315236628055573, dist_loss: 0.5348563194274902
recon_loss: 0.027314329519867897, dist_loss: 0.5434110164642334
recon_loss: 0.027312638238072395, dist_loss: 0.6701215505599976
recon_loss: 0.02731037698686123, dist_loss: 0.5380876064300537
recon_loss: 0.027309296652674675, dist_loss: 0.5045867562294006
recon_loss: 0.027309872210025787, dist_loss: 0.5058043599128723
recon_loss: 0.02731071226298809, dist_loss: 0.914513885974884
recon_loss: 0.027311762794852257, dist_loss: 0.6329175233840942
recon_loss: 0.027312064543366432, dist_loss: 0.3088092803955078
recon_loss: 0.027312617748975754, dist_loss: 0.8956214189529419
recon_loss: 0.027312567457556725, dist_loss: 0.9321343302726746
recon_loss: 0.02731209248304367, dist_loss: 0.6085617542266846
recon_loss: 0.02731206640601158, dist_loss: 0.6152052879333496
recon_loss: 0.02731255814433098, dist_loss: 0.7698452472686768
recon_loss: 0.027313994243741035, dist_loss: 0.3870161771774292
recon_loss: 0.027315538376569748, dist_loss: 0.4884369969367981
recon_loss: 0.027316484600305557, dist_loss: 1.0621986389160156
recon_loss: 0.027317384257912636, dist_loss: 0.6602132320404053
recon_loss: 0.027316639199852943, dist_loss: 0.5563539862632751
recon_loss: 0.027315862476825714, dist_loss: 0.3875635862350464
recon_loss: 0.02731480449438095, dist_loss: 0.7639553546905518
recon_loss: 0.027313044294714928, dist_loss: 1.2404693365097046
recon_loss: 0.02731175720691681, dist_loss: 1.1294163465499878
recon_loss: 0.027311090379953384, dist_loss: 0.3191538453102112
recon_loss: 0.027310971170663834, dist_loss: 0.35182446241378784
recon_loss: 0.027311351150274277, dist_loss: 0.6745362281799316
recon_loss: 0.02731112390756607, dist_loss: 0.7120076417922974
recon_loss: 0.027310987934470177, dist_loss: 0.7543331384658813
recon_loss: 0.02731087990105152, dist_loss: 0.6438288688659668
recon_loss: 0.02731051668524742, dist_loss: 0.8347153663635254
recon_loss: 0.02730993553996086, dist_loss: 0.7372689247131348
recon_loss: 0.027308937162160873, dist_loss: 0.5925644636154175
recon_loss: 0.027307886630296707, dist_loss: 0.7799755334854126
recon_loss: 0.027306020259857178, dist_loss: 0.5324482917785645
recon_loss: 0.027304720133543015, dist_loss: 0.6986829042434692
recon_loss: 0.027303049340844154, dist_loss: 0.659809947013855
recon_loss: 0.027302570641040802, dist_loss: 0.6093214154243469
recon_loss: 0.02730206772685051, dist_loss: 0.5384823083877563
recon_loss: 0.027302317321300507, dist_loss: 0.6962634325027466
Pre-training Epoch 111:  72%|███████▏  | 264/367 [00:01<00:00, 171.24it/s]Pre-training Epoch 111:  77%|███████▋  | 282/367 [00:01<00:00, 164.13it/s]Pre-training Epoch 111:  81%|████████▏ | 299/367 [00:01<00:00, 161.77it/s]Pre-training Epoch 111:  86%|████████▌ | 316/367 [00:01<00:00, 160.97it/s]Pre-training Epoch 111:  91%|█████████ | 333/367 [00:02<00:00, 162.34it/s]Pre-training Epoch 111:  95%|█████████▌| 350/367 [00:02<00:00, 163.32it/s]Pre-training Epoch 111: 100%|██████████| 367/367 [00:02<00:00, 163.58it/s]Pre-training Epoch 111: 100%|██████████| 367/367 [00:02<00:00, 165.45it/s]
recon_loss: 0.027302447706460953, dist_loss: 0.6403121948242188
recon_loss: 0.0273033007979393, dist_loss: 0.6125269532203674
recon_loss: 0.027303729206323624, dist_loss: 0.5610798597335815
recon_loss: 0.02730393409729004, dist_loss: 0.7857954502105713
recon_loss: 0.027303561568260193, dist_loss: 0.718441367149353
recon_loss: 0.027302714064717293, dist_loss: 0.4039405584335327
recon_loss: 0.027302350848913193, dist_loss: 0.5267954468727112
recon_loss: 0.027302458882331848, dist_loss: 1.2824746370315552
recon_loss: 0.02730230800807476, dist_loss: 1.115902304649353
recon_loss: 0.027301739901304245, dist_loss: 0.7192533016204834
recon_loss: 0.027302144095301628, dist_loss: 0.2615779638290405
recon_loss: 0.027301689609885216, dist_loss: 1.0155898332595825
recon_loss: 0.027301866561174393, dist_loss: 0.48024362325668335
recon_loss: 0.027301030233502388, dist_loss: 0.5026144981384277
recon_loss: 0.027301382273435593, dist_loss: 0.399362713098526
recon_loss: 0.027301309630274773, dist_loss: 0.6934206485748291
recon_loss: 0.027302013710141182, dist_loss: 0.41843223571777344
recon_loss: 0.027303168550133705, dist_loss: 0.5611705780029297
recon_loss: 0.027303827926516533, dist_loss: 0.614471971988678
recon_loss: 0.02730468474328518, dist_loss: 0.586926281452179
recon_loss: 0.027304865419864655, dist_loss: 0.5444794297218323
recon_loss: 0.027305928990244865, dist_loss: 0.9748101234436035
recon_loss: 0.02730488032102585, dist_loss: 0.6424464583396912
recon_loss: 0.027304518967866898, dist_loss: 0.9163661599159241
recon_loss: 0.027303606271743774, dist_loss: 1.2533948421478271
recon_loss: 0.027304256334900856, dist_loss: 0.5248064398765564
recon_loss: 0.027302604168653488, dist_loss: 0.46156805753707886
recon_loss: 0.027303555980324745, dist_loss: 0.5532405376434326
recon_loss: 0.027303140610456467, dist_loss: 0.5215224623680115
recon_loss: 0.02730148658156395, dist_loss: 0.6249226331710815
recon_loss: 0.02730083093047142, dist_loss: 0.534661054611206
recon_loss: 0.02729962021112442, dist_loss: 0.28514760732650757
recon_loss: 0.027300236746668816, dist_loss: 1.076359510421753
recon_loss: 0.02729971334338188, dist_loss: 0.5488334894180298
recon_loss: 0.027300439774990082, dist_loss: 0.6855444312095642
recon_loss: 0.02730165235698223, dist_loss: 0.554458737373352
recon_loss: 0.027305476367473602, dist_loss: 0.7662797570228577
recon_loss: 0.027307583019137383, dist_loss: 0.4396131932735443
recon_loss: 0.027309194207191467, dist_loss: 0.5153547525405884
recon_loss: 0.027310838922858238, dist_loss: 0.43345001339912415
recon_loss: 0.027311338111758232, dist_loss: 0.5834270715713501
recon_loss: 0.027313189581036568, dist_loss: 0.5922185182571411
recon_loss: 0.027311941608786583, dist_loss: 0.4855930507183075
recon_loss: 0.027312077581882477, dist_loss: 0.5650246143341064
recon_loss: 0.02730954810976982, dist_loss: 0.6515415906906128
recon_loss: 0.02730601653456688, dist_loss: 0.5597329139709473
recon_loss: 0.02730487659573555, dist_loss: 0.5163843035697937
recon_loss: 0.027302250266075134, dist_loss: 0.6982583999633789
recon_loss: 0.027302606031298637, dist_loss: 0.3931179642677307
recon_loss: 0.027302412316203117, dist_loss: 0.7521510124206543
recon_loss: 0.02730284444987774, dist_loss: 0.8150736689567566
recon_loss: 0.02730589173734188, dist_loss: 0.8588561415672302
recon_loss: 0.027309518307447433, dist_loss: 0.698567271232605
recon_loss: 0.027313094586133957, dist_loss: 0.5782157778739929
recon_loss: 0.027315860614180565, dist_loss: 0.7401875257492065
recon_loss: 0.027316579595208168, dist_loss: 0.4111519455909729
recon_loss: 0.027315758168697357, dist_loss: 0.6292574405670166
recon_loss: 0.02731289342045784, dist_loss: 0.8232816457748413
recon_loss: 0.027311021462082863, dist_loss: 1.0177466869354248
recon_loss: 0.02730918489396572, dist_loss: 0.53960120677948
recon_loss: 0.027307411655783653, dist_loss: 0.7239811420440674
recon_loss: 0.027305034920573235, dist_loss: 0.5141854286193848
recon_loss: 0.02730325236916542, dist_loss: 0.49745532870292664
recon_loss: 0.02730245143175125, dist_loss: 0.7525543570518494
recon_loss: 0.027300680056214333, dist_loss: 0.6546432971954346
recon_loss: 0.027302494272589684, dist_loss: 1.0404865741729736
recon_loss: 0.027300938963890076, dist_loss: 0.36043861508369446
recon_loss: 0.02730206772685051, dist_loss: 0.36566561460494995
recon_loss: 0.027303023263812065, dist_loss: 0.3878975510597229
recon_loss: 0.027302639558911324, dist_loss: 0.9951345920562744
recon_loss: 0.027308154851198196, dist_loss: 0.5475073456764221
recon_loss: 0.027307504788041115, dist_loss: 1.1525499820709229
recon_loss: 0.027310017496347427, dist_loss: 0.4051222503185272
recon_loss: 0.027309823781251907, dist_loss: 0.6715509295463562
recon_loss: 0.027306847274303436, dist_loss: 0.29994019865989685
recon_loss: 0.027307678014039993, dist_loss: 0.7585247755050659
recon_loss: 0.02730424888432026, dist_loss: 0.5860123634338379
recon_loss: 0.027305031195282936, dist_loss: 0.554943859577179
recon_loss: 0.027303365990519524, dist_loss: 0.4265848398208618
recon_loss: 0.027302807196974754, dist_loss: 0.5990114212036133
recon_loss: 0.02730172872543335, dist_loss: 0.8213688731193542
recon_loss: 0.02730078250169754, dist_loss: 0.6176507472991943
recon_loss: 0.02730070985853672, dist_loss: 0.5721010565757751
recon_loss: 0.027299506589770317, dist_loss: 0.517465353012085
recon_loss: 0.02729957364499569, dist_loss: 0.7578573226928711
recon_loss: 0.027299001812934875, dist_loss: 0.4690767526626587
recon_loss: 0.02729899063706398, dist_loss: 0.4440256357192993
recon_loss: 0.02729903534054756, dist_loss: 0.38023021817207336
recon_loss: 0.02729884907603264, dist_loss: 0.4026322364807129
recon_loss: 0.027299152687191963, dist_loss: 0.5471291542053223
recon_loss: 0.027299685403704643, dist_loss: 0.4914903938770294
recon_loss: 0.02730034664273262, dist_loss: 0.5640641450881958
recon_loss: 0.027300845831632614, dist_loss: 0.9111524820327759
recon_loss: 0.02730049006640911, dist_loss: 0.546088695526123
recon_loss: 0.02730046957731247, dist_loss: 0.3756747245788574
recon_loss: 0.02729959227144718, dist_loss: 0.861355721950531
recon_loss: 0.02729947678744793, dist_loss: 0.4437331259250641
recon_loss: 0.027299677953124046, dist_loss: 0.8173438906669617
recon_loss: 0.027299238368868828, dist_loss: 0.5773854851722717
recon_loss: 0.027299605309963226, dist_loss: 0.5041157007217407
recon_loss: 0.027298424392938614, dist_loss: 0.6088327169418335
recon_loss: 0.02729840576648712, dist_loss: 0.8256080746650696
recon_loss: 0.02729935012757778, dist_loss: 0.6378738880157471
recon_loss: 0.02729937620460987, dist_loss: 1.0188556909561157
recon_loss: 0.02730044536292553, dist_loss: 0.4614306688308716
recon_loss: 0.027298977598547935, dist_loss: 0.6425773501396179
recon_loss: 0.02729833871126175, dist_loss: 0.5154784917831421
recon_loss: 0.02729787304997444, dist_loss: 0.5854963660240173
recon_loss: 0.02729734778404236, dist_loss: 0.5556485652923584
recon_loss: 0.027297191321849823, dist_loss: 0.9855531454086304
recon_loss: 0.027296829968690872, dist_loss: 1.6322901248931885
Pre-training Epoch 112:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 112:   4%|▍         | 16/367 [00:00<00:02, 159.70it/s]Pre-training Epoch 112:   9%|▊         | 32/367 [00:00<00:02, 150.88it/s]Pre-training Epoch 112:  13%|█▎        | 48/367 [00:00<00:02, 151.04it/s]Pre-training Epoch 112:  17%|█▋        | 64/367 [00:00<00:01, 154.19it/s]Pre-training Epoch 112:  22%|██▏       | 81/367 [00:00<00:01, 157.99it/s]Pre-training Epoch 112:  27%|██▋       | 98/367 [00:00<00:01, 160.03it/s]Pre-training Epoch 112:  31%|███▏      | 115/367 [00:00<00:01, 160.68it/s]recon_loss: 0.02729610726237297, dist_loss: 0.5852736234664917
recon_loss: 0.027296559885144234, dist_loss: 0.6461191773414612
recon_loss: 0.02729755826294422, dist_loss: 0.6852104663848877
recon_loss: 0.027298450469970703, dist_loss: 0.7890772819519043
recon_loss: 0.027299119159579277, dist_loss: 0.9659832119941711
recon_loss: 0.027300100773572922, dist_loss: 0.7138338685035706
recon_loss: 0.027300504967570305, dist_loss: 0.3880299925804138
recon_loss: 0.027300970628857613, dist_loss: 0.8641656637191772
recon_loss: 0.027300914749503136, dist_loss: 0.5532904267311096
recon_loss: 0.027300281450152397, dist_loss: 0.5948716402053833
recon_loss: 0.027299748733639717, dist_loss: 0.41564035415649414
recon_loss: 0.027298778295516968, dist_loss: 0.5713773369789124
recon_loss: 0.02729813940823078, dist_loss: 0.784049928188324
recon_loss: 0.027297141030430794, dist_loss: 0.6692131161689758
recon_loss: 0.027296053245663643, dist_loss: 0.4078458547592163
recon_loss: 0.027295218780636787, dist_loss: 0.6908287405967712
recon_loss: 0.02729417383670807, dist_loss: 0.7312959432601929
recon_loss: 0.027293730527162552, dist_loss: 0.6556513905525208
recon_loss: 0.02729366347193718, dist_loss: 0.7828933596611023
recon_loss: 0.027293579652905464, dist_loss: 0.6687214374542236
recon_loss: 0.027293892577290535, dist_loss: 0.3231441378593445
recon_loss: 0.02729429118335247, dist_loss: 1.1181461811065674
recon_loss: 0.027295216917991638, dist_loss: 0.6290259957313538
recon_loss: 0.027295561507344246, dist_loss: 0.615141749382019
recon_loss: 0.027297094464302063, dist_loss: 0.6125916242599487
recon_loss: 0.027298303321003914, dist_loss: 0.6869956254959106
recon_loss: 0.02729850821197033, dist_loss: 0.6558313965797424
recon_loss: 0.027297917753458023, dist_loss: 0.48761260509490967
recon_loss: 0.027296599000692368, dist_loss: 0.6905056238174438
recon_loss: 0.027296369895339012, dist_loss: 0.49161961674690247
recon_loss: 0.027295071631669998, dist_loss: 0.28696057200431824
recon_loss: 0.027294810861349106, dist_loss: 0.7141501307487488
recon_loss: 0.027294714003801346, dist_loss: 0.6316489577293396
recon_loss: 0.02729526162147522, dist_loss: 0.6662354469299316
recon_loss: 0.027294617146253586, dist_loss: 0.8911362886428833
recon_loss: 0.02729470655322075, dist_loss: 0.34232068061828613
recon_loss: 0.0272944625467062, dist_loss: 1.0806964635849
recon_loss: 0.027293730527162552, dist_loss: 0.4640847444534302
recon_loss: 0.02729293331503868, dist_loss: 0.7555727958679199
recon_loss: 0.02729220502078533, dist_loss: 0.5912186503410339
recon_loss: 0.027291761711239815, dist_loss: 0.40254372358322144
recon_loss: 0.02729205973446369, dist_loss: 0.8401650786399841
recon_loss: 0.02729267068207264, dist_loss: 0.6061963438987732
recon_loss: 0.02729330211877823, dist_loss: 0.7607224583625793
recon_loss: 0.02729366160929203, dist_loss: 0.6081680059432983
recon_loss: 0.02729410119354725, dist_loss: 0.638565719127655
recon_loss: 0.027294212952256203, dist_loss: 0.6337394714355469
recon_loss: 0.027294568717479706, dist_loss: 0.35756969451904297
recon_loss: 0.027295639738440514, dist_loss: 0.4743330478668213
recon_loss: 0.027296477928757668, dist_loss: 0.3657880425453186
recon_loss: 0.027296772226691246, dist_loss: 0.6515042781829834
recon_loss: 0.02729775570333004, dist_loss: 0.6123318672180176
recon_loss: 0.02729876898229122, dist_loss: 1.0621625185012817
recon_loss: 0.0272988211363554, dist_loss: 0.6881943345069885
recon_loss: 0.02729932963848114, dist_loss: 0.3038371801376343
recon_loss: 0.027299704030156136, dist_loss: 0.9381956458091736
recon_loss: 0.027299443259835243, dist_loss: 0.332083135843277
recon_loss: 0.027299102395772934, dist_loss: 0.6927658319473267
recon_loss: 0.027298234403133392, dist_loss: 0.6549978256225586
recon_loss: 0.027296902611851692, dist_loss: 0.5670307278633118
recon_loss: 0.027294768020510674, dist_loss: 0.7401483058929443
recon_loss: 0.027293642982840538, dist_loss: 0.6575077772140503
recon_loss: 0.027292780578136444, dist_loss: 0.842491865158081
recon_loss: 0.027293553575873375, dist_loss: 0.651383638381958
recon_loss: 0.02729596570134163, dist_loss: 0.43125128746032715
recon_loss: 0.027299003675580025, dist_loss: 0.623018741607666
recon_loss: 0.027301451191306114, dist_loss: 1.1915059089660645
recon_loss: 0.02730361931025982, dist_loss: 0.9269405603408813
recon_loss: 0.0273065697401762, dist_loss: 0.4045296907424927
recon_loss: 0.027307741343975067, dist_loss: 0.5397976040840149
recon_loss: 0.027308426797389984, dist_loss: 0.7934315204620361
recon_loss: 0.027308164164423943, dist_loss: 0.4649015963077545
recon_loss: 0.027307091280817986, dist_loss: 0.8297141790390015
recon_loss: 0.027304375544190407, dist_loss: 0.5766671895980835
recon_loss: 0.027302872389554977, dist_loss: 1.1088647842407227
recon_loss: 0.02730047143995762, dist_loss: 0.7487306594848633
recon_loss: 0.02729860134422779, dist_loss: 0.8988065719604492
recon_loss: 0.027297243475914, dist_loss: 0.518338143825531
recon_loss: 0.02729642204940319, dist_loss: 0.9281738996505737
recon_loss: 0.027296239510178566, dist_loss: 0.5766302347183228
recon_loss: 0.027297014370560646, dist_loss: 1.0705645084381104
recon_loss: 0.02729807049036026, dist_loss: 0.46567946672439575
recon_loss: 0.02729947492480278, dist_loss: 0.40572214126586914
recon_loss: 0.027300236746668816, dist_loss: 0.7830742001533508
recon_loss: 0.0273014847189188, dist_loss: 0.4018074870109558
recon_loss: 0.027302470058202744, dist_loss: 0.7279314994812012
recon_loss: 0.02730230800807476, dist_loss: 0.8927769660949707
recon_loss: 0.02730274200439453, dist_loss: 0.674308180809021
recon_loss: 0.02730107121169567, dist_loss: 0.946036696434021
recon_loss: 0.027301274240016937, dist_loss: 0.7198030948638916
recon_loss: 0.02730035036802292, dist_loss: 0.503032386302948
recon_loss: 0.027300123125314713, dist_loss: 0.561629056930542
recon_loss: 0.02729874476790428, dist_loss: 0.8533083200454712
recon_loss: 0.02729860693216324, dist_loss: 0.7363131046295166
recon_loss: 0.027297932654619217, dist_loss: 0.6029945015907288
recon_loss: 0.02729729190468788, dist_loss: 0.6309056282043457
recon_loss: 0.027295511215925217, dist_loss: 0.5472792387008667
recon_loss: 0.027294140309095383, dist_loss: 0.6323472261428833
recon_loss: 0.027293099090456963, dist_loss: 0.4095470905303955
recon_loss: 0.027292121201753616, dist_loss: 0.5593388080596924
recon_loss: 0.02729182504117489, dist_loss: 0.34493476152420044
recon_loss: 0.027291929349303246, dist_loss: 0.6048257946968079
recon_loss: 0.02729250304400921, dist_loss: 0.844515323638916
recon_loss: 0.027292795479297638, dist_loss: 0.8705257177352905
recon_loss: 0.027293242514133453, dist_loss: 0.5625697374343872
recon_loss: 0.027293968945741653, dist_loss: 0.44657963514328003
recon_loss: 0.02729438617825508, dist_loss: 0.6118863821029663
recon_loss: 0.027293428778648376, dist_loss: 0.4874792993068695
recon_loss: 0.02729232981801033, dist_loss: 0.39624252915382385
recon_loss: 0.027291422709822655, dist_loss: 0.3218534588813782
recon_loss: 0.027290893718600273, dist_loss: 0.7304929494857788
recon_loss: 0.027290569618344307, dist_loss: 0.7580850124359131
recon_loss: 0.027289999648928642, dist_loss: 0.7739192843437195
recon_loss: 0.02729017660021782, dist_loss: 0.6174513101577759
recon_loss: 0.027289802208542824, dist_loss: 0.6425488591194153
recon_loss: 0.02729005180299282, dist_loss: 0.8449743390083313
recon_loss: 0.027290016412734985, dist_loss: 0.4535137712955475
recon_loss: 0.027289561927318573, dist_loss: 0.3361724019050598
recon_loss: 0.027289019897580147, dist_loss: 0.8658664226531982
recon_loss: 0.027288448065519333, dist_loss: 0.7181203365325928
recon_loss: 0.02728811651468277, dist_loss: 0.8568534851074219
recon_loss: 0.027287829667329788, dist_loss: 1.1882644891738892
recon_loss: 0.027287177741527557, dist_loss: 0.6479054689407349
recon_loss: 0.02728704921901226, dist_loss: 0.49540582299232483
recon_loss: 0.027287527918815613, dist_loss: 0.5490670204162598
recon_loss: 0.02728794701397419, dist_loss: 0.5163646340370178
recon_loss: 0.02728896774351597, dist_loss: 0.8638416528701782
recon_loss: 0.027289463207125664, dist_loss: 1.038343906402588
Pre-training Epoch 112:  36%|███▌      | 132/367 [00:00<00:01, 161.85it/s]Pre-training Epoch 112:  41%|████      | 149/367 [00:00<00:01, 162.73it/s]Pre-training Epoch 112:  45%|████▌     | 166/367 [00:01<00:01, 157.70it/s]Pre-training Epoch 112:  50%|████▉     | 182/367 [00:01<00:01, 153.49it/s]Pre-training Epoch 112:  54%|█████▍    | 199/367 [00:01<00:01, 156.50it/s]Pre-training Epoch 112:  59%|█████▊    | 215/367 [00:01<00:00, 155.90it/s]Pre-training Epoch 112:  63%|██████▎   | 232/367 [00:01<00:00, 158.15it/s]Pre-training Epoch 112:  68%|██████▊   | 249/367 [00:01<00:00, 159.54it/s]recon_loss: 0.02729051187634468, dist_loss: 0.9183800220489502
recon_loss: 0.027289964258670807, dist_loss: 0.5196394920349121
recon_loss: 0.027289895340800285, dist_loss: 0.3377751410007477
recon_loss: 0.02728930488228798, dist_loss: 0.5494323968887329
recon_loss: 0.027289997786283493, dist_loss: 0.7368239164352417
recon_loss: 0.027288787066936493, dist_loss: 0.44789889454841614
recon_loss: 0.027288779616355896, dist_loss: 0.4583183526992798
recon_loss: 0.02728806622326374, dist_loss: 0.6364552974700928
recon_loss: 0.027287332341074944, dist_loss: 1.00773024559021
recon_loss: 0.027287008240818977, dist_loss: 0.4194425940513611
recon_loss: 0.027286415919661522, dist_loss: 0.7104880809783936
recon_loss: 0.02728630043566227, dist_loss: 0.517522394657135
recon_loss: 0.02728603407740593, dist_loss: 0.5646144151687622
recon_loss: 0.02728678472340107, dist_loss: 1.05354642868042
recon_loss: 0.02728664129972458, dist_loss: 0.49130624532699585
recon_loss: 0.02728629671037197, dist_loss: 0.3669714331626892
recon_loss: 0.02728615701198578, dist_loss: 0.4539918601512909
recon_loss: 0.027286160737276077, dist_loss: 0.7785641551017761
recon_loss: 0.027285978198051453, dist_loss: 0.6895884871482849
recon_loss: 0.027285996824502945, dist_loss: 0.6294559836387634
recon_loss: 0.027285831049084663, dist_loss: 1.1740093231201172
recon_loss: 0.027285359799861908, dist_loss: 0.5319252610206604
recon_loss: 0.02728499472141266, dist_loss: 0.7553900480270386
recon_loss: 0.027285007759928703, dist_loss: 0.9093623757362366
recon_loss: 0.027284763753414154, dist_loss: 0.7453989386558533
recon_loss: 0.02728467807173729, dist_loss: 0.7813128232955933
recon_loss: 0.027284955605864525, dist_loss: 0.3663748502731323
recon_loss: 0.02728535607457161, dist_loss: 0.49771878123283386
recon_loss: 0.027286116033792496, dist_loss: 0.824772298336029
recon_loss: 0.027286387979984283, dist_loss: 1.3250113725662231
recon_loss: 0.027286656200885773, dist_loss: 0.4528113305568695
recon_loss: 0.027287248522043228, dist_loss: 0.6721187829971313
recon_loss: 0.027287235483527184, dist_loss: 0.46015089750289917
recon_loss: 0.027288047596812248, dist_loss: 0.5968827605247498
recon_loss: 0.02728843130171299, dist_loss: 0.7260593175888062
recon_loss: 0.027289390563964844, dist_loss: 0.9550508260726929
recon_loss: 0.02728983387351036, dist_loss: 0.5066802501678467
recon_loss: 0.027290338650345802, dist_loss: 0.4665428400039673
recon_loss: 0.02729157730937004, dist_loss: 0.36530184745788574
recon_loss: 0.02729061432182789, dist_loss: 0.6043979525566101
recon_loss: 0.02729041874408722, dist_loss: 0.830060601234436
recon_loss: 0.02728820964694023, dist_loss: 0.8870723247528076
recon_loss: 0.027288317680358887, dist_loss: 0.9878599643707275
recon_loss: 0.027286451309919357, dist_loss: 0.8667313456535339
recon_loss: 0.02728751115500927, dist_loss: 0.42558395862579346
recon_loss: 0.027286482974886894, dist_loss: 0.9417652487754822
recon_loss: 0.027288062497973442, dist_loss: 0.4787503480911255
recon_loss: 0.027287382632493973, dist_loss: 0.7933834195137024
recon_loss: 0.027285823598504066, dist_loss: 0.5718550682067871
recon_loss: 0.027286233380436897, dist_loss: 0.6069648861885071
recon_loss: 0.027284881100058556, dist_loss: 0.6056384444236755
recon_loss: 0.02728567086160183, dist_loss: 0.9723973274230957
recon_loss: 0.02728455886244774, dist_loss: 0.5127163529396057
recon_loss: 0.027284620329737663, dist_loss: 0.932304859161377
recon_loss: 0.02728465385735035, dist_loss: 0.39411789178848267
recon_loss: 0.027285132557153702, dist_loss: 0.7921597361564636
recon_loss: 0.027285320684313774, dist_loss: 0.5853757858276367
recon_loss: 0.027285991236567497, dist_loss: 0.5234509706497192
recon_loss: 0.027286700904369354, dist_loss: 0.6032158732414246
recon_loss: 0.027286510914564133, dist_loss: 0.8198396563529968
recon_loss: 0.027286358177661896, dist_loss: 0.6126054525375366
recon_loss: 0.027287296950817108, dist_loss: 0.7698184847831726
recon_loss: 0.027286579832434654, dist_loss: 1.2907284498214722
recon_loss: 0.027286767959594727, dist_loss: 0.42941635847091675
recon_loss: 0.027285339310765266, dist_loss: 0.4719827175140381
recon_loss: 0.027284467592835426, dist_loss: 0.45126035809516907
recon_loss: 0.027284054085612297, dist_loss: 0.5237576365470886
recon_loss: 0.027282746508717537, dist_loss: 0.813301146030426
recon_loss: 0.027283458039164543, dist_loss: 0.7382605075836182
recon_loss: 0.027282800525426865, dist_loss: 0.7115581035614014
recon_loss: 0.02728395350277424, dist_loss: 0.7388595342636108
recon_loss: 0.027283787727355957, dist_loss: 0.8213334679603577
recon_loss: 0.02728310599923134, dist_loss: 0.9513077735900879
recon_loss: 0.02728327177464962, dist_loss: 1.177079439163208
recon_loss: 0.027283212170004845, dist_loss: 1.2401394844055176
recon_loss: 0.02728354185819626, dist_loss: 0.4954864978790283
recon_loss: 0.02728361450135708, dist_loss: 0.39740830659866333
recon_loss: 0.027284130454063416, dist_loss: 0.6518453359603882
recon_loss: 0.02728424221277237, dist_loss: 0.6586058735847473
recon_loss: 0.02728479541838169, dist_loss: 0.8656825423240662
recon_loss: 0.02728433720767498, dist_loss: 0.3920893967151642
recon_loss: 0.027284620329737663, dist_loss: 0.34269341826438904
recon_loss: 0.02728431671857834, dist_loss: 1.0818419456481934
recon_loss: 0.027284326031804085, dist_loss: 0.6595578193664551
recon_loss: 0.027284549549221992, dist_loss: 0.7197099328041077
recon_loss: 0.02728482335805893, dist_loss: 0.7936438918113708
recon_loss: 0.027285264804959297, dist_loss: 0.4994017481803894
recon_loss: 0.027284756302833557, dist_loss: 0.5714445114135742
recon_loss: 0.027285370975732803, dist_loss: 0.47900447249412537
recon_loss: 0.027285434305667877, dist_loss: 0.43801307678222656
recon_loss: 0.027285929769277573, dist_loss: 0.660294771194458
recon_loss: 0.027286404743790627, dist_loss: 0.5878885388374329
recon_loss: 0.02728571556508541, dist_loss: 0.5414234399795532
recon_loss: 0.027285130694508553, dist_loss: 0.4256356358528137
recon_loss: 0.0272842887789011, dist_loss: 0.6808146238327026
recon_loss: 0.02728465385735035, dist_loss: 0.5044406056404114
recon_loss: 0.027284875512123108, dist_loss: 0.48596540093421936
recon_loss: 0.027285480871796608, dist_loss: 0.3411185145378113
recon_loss: 0.027285471558570862, dist_loss: 0.30551719665527344
recon_loss: 0.027285557240247726, dist_loss: 0.5764241814613342
recon_loss: 0.027286207303404808, dist_loss: 0.48033881187438965
recon_loss: 0.027285136282444, dist_loss: 0.7985116243362427
recon_loss: 0.02728625014424324, dist_loss: 0.8208327293395996
recon_loss: 0.027283724397420883, dist_loss: 0.8503925800323486
recon_loss: 0.02728544920682907, dist_loss: 0.6972339153289795
recon_loss: 0.027284616604447365, dist_loss: 0.5247736573219299
recon_loss: 0.02728399820625782, dist_loss: 0.4254299998283386
recon_loss: 0.027285611256957054, dist_loss: 0.48436614871025085
recon_loss: 0.027284352108836174, dist_loss: 0.7045939564704895
recon_loss: 0.02728506363928318, dist_loss: 0.46618568897247314
recon_loss: 0.027285350486636162, dist_loss: 0.5526286959648132
recon_loss: 0.027285275980830193, dist_loss: 0.6518328785896301
recon_loss: 0.02728704735636711, dist_loss: 0.43328267335891724
recon_loss: 0.027285831049084663, dist_loss: 0.8631769418716431
recon_loss: 0.027288144454360008, dist_loss: 0.6441354155540466
recon_loss: 0.027287226170301437, dist_loss: 0.7499614953994751
recon_loss: 0.027287809178233147, dist_loss: 1.588046908378601
recon_loss: 0.027286840602755547, dist_loss: 0.6164969205856323
recon_loss: 0.027284996584057808, dist_loss: 0.5987793207168579
recon_loss: 0.027285099029541016, dist_loss: 0.7300919890403748
recon_loss: 0.027283914387226105, dist_loss: 0.694562554359436
recon_loss: 0.027284154668450356, dist_loss: 0.5920055508613586
recon_loss: 0.027284754440188408, dist_loss: 0.7112301588058472
recon_loss: 0.027284542098641396, dist_loss: 0.731105625629425
recon_loss: 0.027284396812319756, dist_loss: 0.9392743706703186
recon_loss: 0.027284400537610054, dist_loss: 0.23711054027080536
recon_loss: 0.02728448249399662, dist_loss: 0.6776129603385925
recon_loss: 0.027284786105155945, dist_loss: 0.39454102516174316
Pre-training Epoch 112:  72%|███████▏  | 266/367 [00:01<00:00, 161.00it/s]Pre-training Epoch 112:  78%|███████▊  | 285/367 [00:01<00:00, 167.60it/s]Pre-training Epoch 112:  83%|████████▎ | 305/367 [00:01<00:00, 174.98it/s]Pre-training Epoch 112:  89%|████████▊ | 325/367 [00:01<00:00, 179.39it/s]Pre-training Epoch 112:  93%|█████████▎| 343/367 [00:02<00:00, 170.83it/s]Pre-training Epoch 112:  98%|█████████▊| 361/367 [00:02<00:00, 165.12it/s]Pre-training Epoch 112: 100%|██████████| 367/367 [00:02<00:00, 161.77it/s]
recon_loss: 0.027283787727355957, dist_loss: 0.5399448871612549
recon_loss: 0.027282631024718285, dist_loss: 0.4454231858253479
recon_loss: 0.027282126247882843, dist_loss: 0.4219461679458618
recon_loss: 0.027281729504466057, dist_loss: 0.33073461055755615
recon_loss: 0.02728220261633396, dist_loss: 1.0113260746002197
recon_loss: 0.027282366529107094, dist_loss: 0.30456119775772095
recon_loss: 0.027283620089292526, dist_loss: 0.5270507335662842
recon_loss: 0.02728455886244774, dist_loss: 0.5654695630073547
recon_loss: 0.02728636935353279, dist_loss: 0.36991044878959656
recon_loss: 0.02728750929236412, dist_loss: 0.5336378812789917
recon_loss: 0.027288338169455528, dist_loss: 0.7099299430847168
recon_loss: 0.02728881873190403, dist_loss: 0.7730095386505127
recon_loss: 0.027287261560559273, dist_loss: 0.9439684748649597
recon_loss: 0.027286192402243614, dist_loss: 0.5581681132316589
recon_loss: 0.027285819873213768, dist_loss: 0.5488905906677246
recon_loss: 0.027285583317279816, dist_loss: 0.7757890820503235
recon_loss: 0.027286004275083542, dist_loss: 0.8333730697631836
recon_loss: 0.02728515863418579, dist_loss: 0.5362988114356995
recon_loss: 0.02728470042347908, dist_loss: 0.40284761786460876
recon_loss: 0.02728399820625782, dist_loss: 0.7441637516021729
recon_loss: 0.027283867821097374, dist_loss: 0.5311942100524902
recon_loss: 0.027284249663352966, dist_loss: 0.30749619007110596
recon_loss: 0.027284465730190277, dist_loss: 0.6482237577438354
recon_loss: 0.027286728844046593, dist_loss: 0.5664317607879639
recon_loss: 0.02728867717087269, dist_loss: 0.6014405488967896
recon_loss: 0.02729046903550625, dist_loss: 0.5932919383049011
recon_loss: 0.0272930096834898, dist_loss: 0.56788170337677
recon_loss: 0.02729387953877449, dist_loss: 0.5016909241676331
recon_loss: 0.027295667678117752, dist_loss: 0.407078355550766
recon_loss: 0.02729552611708641, dist_loss: 0.6929290294647217
recon_loss: 0.02729349210858345, dist_loss: 0.3548399806022644
recon_loss: 0.02729148231446743, dist_loss: 0.6031807065010071
recon_loss: 0.027289805933833122, dist_loss: 0.36628490686416626
recon_loss: 0.027288276702165604, dist_loss: 0.7612642049789429
recon_loss: 0.027286604046821594, dist_loss: 0.85064697265625
recon_loss: 0.027285244315862656, dist_loss: 0.7448137998580933
recon_loss: 0.027284475043416023, dist_loss: 0.3466084897518158
recon_loss: 0.02728353440761566, dist_loss: 0.7766834497451782
recon_loss: 0.027283398434519768, dist_loss: 0.9911811351776123
recon_loss: 0.027283256873488426, dist_loss: 0.6926084756851196
recon_loss: 0.027283666655421257, dist_loss: 0.578228235244751
recon_loss: 0.027283236384391785, dist_loss: 0.6307408809661865
recon_loss: 0.027282731607556343, dist_loss: 0.5006120204925537
recon_loss: 0.027282143011689186, dist_loss: 1.2586745023727417
recon_loss: 0.027281703427433968, dist_loss: 0.6024506092071533
recon_loss: 0.02728159911930561, dist_loss: 0.7919363379478455
recon_loss: 0.02728157863020897, dist_loss: 0.5341880917549133
recon_loss: 0.02728140354156494, dist_loss: 0.9841946363449097
recon_loss: 0.02728247456252575, dist_loss: 0.38992172479629517
recon_loss: 0.02728317677974701, dist_loss: 0.5495348572731018
recon_loss: 0.027284475043416023, dist_loss: 0.5675251483917236
recon_loss: 0.027285752817988396, dist_loss: 0.5463560223579407
recon_loss: 0.027286512777209282, dist_loss: 0.442891001701355
recon_loss: 0.02728678286075592, dist_loss: 0.3319311738014221
recon_loss: 0.02728775329887867, dist_loss: 0.5112125873565674
recon_loss: 0.02728794887661934, dist_loss: 0.4344070553779602
recon_loss: 0.02728835865855217, dist_loss: 0.8697839975357056
recon_loss: 0.027287840843200684, dist_loss: 0.5888702869415283
recon_loss: 0.02728704735636711, dist_loss: 0.5771894454956055
recon_loss: 0.02728608064353466, dist_loss: 0.9038115739822388
recon_loss: 0.027285035699605942, dist_loss: 0.5836218595504761
recon_loss: 0.027284104377031326, dist_loss: 0.6514077186584473
recon_loss: 0.027283798903226852, dist_loss: 0.7295990586280823
recon_loss: 0.027284428477287292, dist_loss: 0.8250105381011963
recon_loss: 0.027285898104310036, dist_loss: 0.43546921014785767
recon_loss: 0.02728736773133278, dist_loss: 0.7211620807647705
recon_loss: 0.02728930301964283, dist_loss: 0.45718279480934143
recon_loss: 0.027290288358926773, dist_loss: 0.8791732788085938
recon_loss: 0.027290325611829758, dist_loss: 0.6599624156951904
recon_loss: 0.027289995923638344, dist_loss: 0.5311838984489441
recon_loss: 0.027290578931570053, dist_loss: 0.8782092332839966
recon_loss: 0.02729012444615364, dist_loss: 0.4455563426017761
recon_loss: 0.027289964258670807, dist_loss: 0.5289590954780579
recon_loss: 0.027289101853966713, dist_loss: 0.6644546985626221
recon_loss: 0.027287395671010017, dist_loss: 0.43965908885002136
recon_loss: 0.027286257594823837, dist_loss: 0.42639443278312683
recon_loss: 0.027285153046250343, dist_loss: 0.6023979187011719
recon_loss: 0.027283979579806328, dist_loss: 0.6639221906661987
recon_loss: 0.027283059433102608, dist_loss: 0.38747549057006836
recon_loss: 0.027283035218715668, dist_loss: 0.567827045917511
recon_loss: 0.027284199371933937, dist_loss: 0.6866159439086914
recon_loss: 0.02728581428527832, dist_loss: 0.531114935874939
recon_loss: 0.027288231998682022, dist_loss: 0.3361375629901886
recon_loss: 0.02729063108563423, dist_loss: 0.5315823554992676
recon_loss: 0.027292544022202492, dist_loss: 0.4539756774902344
recon_loss: 0.027293138206005096, dist_loss: 0.3762094974517822
recon_loss: 0.027293667197227478, dist_loss: 0.5498505234718323
recon_loss: 0.02729305624961853, dist_loss: 0.6293203830718994
recon_loss: 0.027292098850011826, dist_loss: 0.650653600692749
recon_loss: 0.027290530502796173, dist_loss: 0.8469000458717346
recon_loss: 0.02728777565062046, dist_loss: 0.8098716139793396
recon_loss: 0.02728569321334362, dist_loss: 0.9226536750793457
recon_loss: 0.02728446014225483, dist_loss: 0.8479099869728088
recon_loss: 0.027284540235996246, dist_loss: 0.4269218146800995
recon_loss: 0.02728467620909214, dist_loss: 0.650335431098938
recon_loss: 0.027285123243927956, dist_loss: 0.9657953977584839
recon_loss: 0.027285488322377205, dist_loss: 0.8192369341850281
recon_loss: 0.027285784482955933, dist_loss: 0.4494321644306183
recon_loss: 0.027285706251859665, dist_loss: 0.5246213674545288
recon_loss: 0.027285555377602577, dist_loss: 0.6646497845649719
recon_loss: 0.027284426614642143, dist_loss: 0.6068750619888306
recon_loss: 0.027282627299427986, dist_loss: 0.4737727642059326
recon_loss: 0.027281126007437706, dist_loss: 0.4252479076385498
recon_loss: 0.02727997489273548, dist_loss: 0.5772507190704346
recon_loss: 0.027279337868094444, dist_loss: 0.8215978741645813
recon_loss: 0.027278931811451912, dist_loss: 1.0034098625183105
recon_loss: 0.027278773486614227, dist_loss: 0.9814069867134094
recon_loss: 0.027278995141386986, dist_loss: 0.66319739818573
recon_loss: 0.027278868481516838, dist_loss: 0.7584719657897949
recon_loss: 0.027279121801257133, dist_loss: 0.5889060497283936
recon_loss: 0.02727872133255005, dist_loss: 0.8007022738456726
Pre-training Epoch 113:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 113:   4%|▍         | 14/367 [00:00<00:02, 137.95it/s]Pre-training Epoch 113:   8%|▊         | 29/367 [00:00<00:02, 141.90it/s]Pre-training Epoch 113:  12%|█▏        | 44/367 [00:00<00:02, 142.34it/s]Pre-training Epoch 113:  16%|█▌        | 59/367 [00:00<00:02, 141.94it/s]Pre-training Epoch 113:  20%|██        | 74/367 [00:00<00:02, 144.66it/s]Pre-training Epoch 113:  24%|██▍       | 89/367 [00:00<00:01, 142.20it/s]Pre-training Epoch 113:  28%|██▊       | 104/367 [00:00<00:01, 143.05it/s]Pre-training Epoch 113:  32%|███▏      | 119/367 [00:00<00:01, 142.51it/s]recon_loss: 0.027280643582344055, dist_loss: 0.7541740536689758
recon_loss: 0.027279356494545937, dist_loss: 0.7988922595977783
recon_loss: 0.027280310168862343, dist_loss: 0.6630565524101257
recon_loss: 0.027280788868665695, dist_loss: 0.6344255208969116
recon_loss: 0.027279166504740715, dist_loss: 0.47072306275367737
recon_loss: 0.027279691770672798, dist_loss: 0.5719262957572937
recon_loss: 0.027278412133455276, dist_loss: 0.433197021484375
recon_loss: 0.02727930247783661, dist_loss: 0.5283317565917969
recon_loss: 0.027278060093522072, dist_loss: 0.8786835670471191
recon_loss: 0.027278289198875427, dist_loss: 0.7253444194793701
recon_loss: 0.027278222143650055, dist_loss: 0.5269593000411987
recon_loss: 0.027277788147330284, dist_loss: 0.6819428205490112
recon_loss: 0.027277830988168716, dist_loss: 0.4638567566871643
recon_loss: 0.02727724052965641, dist_loss: 1.1450895071029663
recon_loss: 0.027277594432234764, dist_loss: 0.6902320384979248
recon_loss: 0.027277326211333275, dist_loss: 0.49869662523269653
recon_loss: 0.027277646586298943, dist_loss: 0.5282630324363708
recon_loss: 0.027277592569589615, dist_loss: 0.7447028756141663
recon_loss: 0.027277681976556778, dist_loss: 0.5536966323852539
recon_loss: 0.02727794088423252, dist_loss: 0.8061090111732483
recon_loss: 0.027278533205389977, dist_loss: 1.0945671796798706
recon_loss: 0.027279842644929886, dist_loss: 0.5654635429382324
recon_loss: 0.027280937880277634, dist_loss: 0.3394140601158142
recon_loss: 0.027281198650598526, dist_loss: 0.37987685203552246
recon_loss: 0.027281641960144043, dist_loss: 0.6778618097305298
recon_loss: 0.027280928567051888, dist_loss: 0.6536643505096436
recon_loss: 0.02728060819208622, dist_loss: 0.982462465763092
recon_loss: 0.02728085406124592, dist_loss: 0.34536609053611755
recon_loss: 0.027281207963824272, dist_loss: 0.3926401734352112
recon_loss: 0.027281446382403374, dist_loss: 0.4704533815383911
recon_loss: 0.027281366288661957, dist_loss: 0.3100925087928772
recon_loss: 0.02728094346821308, dist_loss: 0.6713153719902039
recon_loss: 0.027280226349830627, dist_loss: 0.36542487144470215
recon_loss: 0.02727963589131832, dist_loss: 1.0930360555648804
recon_loss: 0.02727913297712803, dist_loss: 0.7432177662849426
recon_loss: 0.02727852202951908, dist_loss: 0.8697271943092346
recon_loss: 0.0272779930382967, dist_loss: 0.9342764616012573
recon_loss: 0.02727723866701126, dist_loss: 0.38085222244262695
recon_loss: 0.027276868000626564, dist_loss: 0.709252119064331
recon_loss: 0.02727629244327545, dist_loss: 0.6752824187278748
recon_loss: 0.02727636694908142, dist_loss: 0.8780996799468994
recon_loss: 0.02727656252682209, dist_loss: 0.3701512813568115
recon_loss: 0.027276651933789253, dist_loss: 0.28085798025131226
recon_loss: 0.027276253327727318, dist_loss: 0.6851667165756226
recon_loss: 0.02727651223540306, dist_loss: 0.7911478877067566
recon_loss: 0.02727680653333664, dist_loss: 0.9525226354598999
recon_loss: 0.027277523651719093, dist_loss: 0.45393943786621094
recon_loss: 0.027278587222099304, dist_loss: 0.4991343021392822
recon_loss: 0.027278326451778412, dist_loss: 0.5764678716659546
recon_loss: 0.027277624234557152, dist_loss: 0.4788183569908142
recon_loss: 0.027276938781142235, dist_loss: 0.5065240859985352
recon_loss: 0.02727649174630642, dist_loss: 0.8898348808288574
recon_loss: 0.02727600932121277, dist_loss: 0.914411723613739
recon_loss: 0.027276257053017616, dist_loss: 0.645926833152771
recon_loss: 0.02727629989385605, dist_loss: 0.5568625330924988
recon_loss: 0.027275968343019485, dist_loss: 0.2797706127166748
recon_loss: 0.027275359258055687, dist_loss: 0.3086181879043579
recon_loss: 0.02727477438747883, dist_loss: 0.46882688999176025
recon_loss: 0.02727426402270794, dist_loss: 0.4808647632598877
recon_loss: 0.027273811399936676, dist_loss: 0.48322057723999023
recon_loss: 0.02727332152426243, dist_loss: 0.627318799495697
recon_loss: 0.0272733923047781, dist_loss: 0.6072134971618652
recon_loss: 0.02727423794567585, dist_loss: 0.5345725417137146
recon_loss: 0.02727619744837284, dist_loss: 0.6010644435882568
recon_loss: 0.027278294786810875, dist_loss: 1.0285180807113647
recon_loss: 0.02728135511279106, dist_loss: 0.5118958950042725
recon_loss: 0.027283521369099617, dist_loss: 0.6670201420783997
recon_loss: 0.027284665033221245, dist_loss: 0.5684041976928711
recon_loss: 0.027285199612379074, dist_loss: 0.7115733623504639
recon_loss: 0.027285603806376457, dist_loss: 0.5897905826568604
recon_loss: 0.02728632092475891, dist_loss: 0.7540947198867798
recon_loss: 0.027286624535918236, dist_loss: 0.8764322400093079
recon_loss: 0.027286604046821594, dist_loss: 1.1128919124603271
recon_loss: 0.02728564292192459, dist_loss: 0.9820402264595032
recon_loss: 0.027284612879157066, dist_loss: 0.9562113285064697
recon_loss: 0.027282368391752243, dist_loss: 0.783413290977478
recon_loss: 0.027280054986476898, dist_loss: 0.4589357376098633
recon_loss: 0.02727801539003849, dist_loss: 0.5800698399543762
recon_loss: 0.027278194203972816, dist_loss: 0.47504132986068726
recon_loss: 0.027276083827018738, dist_loss: 1.0090739727020264
recon_loss: 0.0272788405418396, dist_loss: 0.3842225670814514
recon_loss: 0.027277711778879166, dist_loss: 0.6483216285705566
recon_loss: 0.027280550450086594, dist_loss: 0.45926833152770996
recon_loss: 0.02728225477039814, dist_loss: 0.651056706905365
recon_loss: 0.027285806834697723, dist_loss: 0.5105608701705933
recon_loss: 0.02729283832013607, dist_loss: 0.42225778102874756
recon_loss: 0.027294732630252838, dist_loss: 0.45066943764686584
recon_loss: 0.027300285175442696, dist_loss: 0.7860744595527649
recon_loss: 0.027300402522087097, dist_loss: 0.6847147941589355
recon_loss: 0.027302052825689316, dist_loss: 0.6002427339553833
recon_loss: 0.027298999950289726, dist_loss: 0.5152497291564941
recon_loss: 0.027296949177980423, dist_loss: 0.6171904802322388
recon_loss: 0.02729366533458233, dist_loss: 0.6002346277236938
recon_loss: 0.02728912979364395, dist_loss: 0.774420440196991
recon_loss: 0.027286624535918236, dist_loss: 0.6921136379241943
recon_loss: 0.027282940223813057, dist_loss: 0.6081607341766357
recon_loss: 0.027283305302262306, dist_loss: 0.7875320911407471
recon_loss: 0.02728123590350151, dist_loss: 0.7792013883590698
recon_loss: 0.02728196047246456, dist_loss: 0.5220712423324585
recon_loss: 0.02728305384516716, dist_loss: 0.5324387550354004
recon_loss: 0.0272848941385746, dist_loss: 0.3586568832397461
recon_loss: 0.027286536991596222, dist_loss: 0.9174917936325073
recon_loss: 0.02728622779250145, dist_loss: 0.8747301697731018
recon_loss: 0.02728559821844101, dist_loss: 0.8981655836105347
recon_loss: 0.02728317864239216, dist_loss: 0.7342697381973267
recon_loss: 0.02728452906012535, dist_loss: 0.6180726885795593
recon_loss: 0.027280837297439575, dist_loss: 0.8173905611038208
recon_loss: 0.0272807814180851, dist_loss: 1.1648502349853516
recon_loss: 0.02727644331753254, dist_loss: 0.596785306930542
recon_loss: 0.027274999767541885, dist_loss: 0.6254234313964844
recon_loss: 0.02727578766644001, dist_loss: 0.4411281943321228
recon_loss: 0.02727414295077324, dist_loss: 0.42652177810668945
recon_loss: 0.027276398614048958, dist_loss: 0.974365234375
recon_loss: 0.027274630963802338, dist_loss: 0.19910553097724915
recon_loss: 0.027276691049337387, dist_loss: 0.38824260234832764
recon_loss: 0.027274684980511665, dist_loss: 0.46233993768692017
recon_loss: 0.027274439111351967, dist_loss: 0.5872719883918762
recon_loss: 0.027274252846837044, dist_loss: 0.5339564085006714
recon_loss: 0.027272460982203484, dist_loss: 0.5187983512878418
recon_loss: 0.027273092418909073, dist_loss: 0.783653974533081
recon_loss: 0.02727040834724903, dist_loss: 0.6327621936798096
recon_loss: 0.027271196246147156, dist_loss: 0.7942341566085815
recon_loss: 0.027270212769508362, dist_loss: 0.665857195854187
recon_loss: 0.027270536869764328, dist_loss: 0.7197924852371216
recon_loss: 0.02727089449763298, dist_loss: 0.5436583757400513
recon_loss: 0.02726997621357441, dist_loss: 0.4672905206680298
recon_loss: 0.027271006256341934, dist_loss: 0.5610682964324951
recon_loss: 0.027269309386610985, dist_loss: 0.8825377225875854
Pre-training Epoch 113:  37%|███▋      | 134/367 [00:00<00:01, 143.61it/s]Pre-training Epoch 113:  41%|████      | 149/367 [00:01<00:01, 144.47it/s]Pre-training Epoch 113:  45%|████▍     | 164/367 [00:01<00:01, 144.16it/s]Pre-training Epoch 113:  49%|████▉     | 179/367 [00:01<00:01, 144.30it/s]Pre-training Epoch 113:  53%|█████▎    | 194/367 [00:01<00:01, 145.29it/s]Pre-training Epoch 113:  57%|█████▋    | 209/367 [00:01<00:01, 143.21it/s]Pre-training Epoch 113:  61%|██████    | 224/367 [00:01<00:01, 142.77it/s]Pre-training Epoch 113:  65%|██████▌   | 239/367 [00:01<00:00, 143.19it/s]Pre-training Epoch 113:  69%|██████▉   | 254/367 [00:01<00:00, 144.20it/s]recon_loss: 0.02727024257183075, dist_loss: 0.9715208411216736
recon_loss: 0.027269495651125908, dist_loss: 0.5079901218414307
recon_loss: 0.027270155027508736, dist_loss: 0.6055859327316284
recon_loss: 0.02726965956389904, dist_loss: 1.1949807405471802
recon_loss: 0.027269231155514717, dist_loss: 0.32618311047554016
recon_loss: 0.027269314974546432, dist_loss: 0.5020474791526794
recon_loss: 0.027268728241324425, dist_loss: 0.841029942035675
recon_loss: 0.0272692684084177, dist_loss: 0.5722723007202148
recon_loss: 0.027268702164292336, dist_loss: 0.865888237953186
recon_loss: 0.0272687878459692, dist_loss: 0.749010443687439
recon_loss: 0.02726866863667965, dist_loss: 0.3459470272064209
recon_loss: 0.02726905234158039, dist_loss: 1.032573938369751
recon_loss: 0.0272686704993248, dist_loss: 0.37683600187301636
recon_loss: 0.027268266305327415, dist_loss: 1.2545509338378906
recon_loss: 0.02726857177913189, dist_loss: 0.4137798249721527
recon_loss: 0.02726922556757927, dist_loss: 0.8500718474388123
recon_loss: 0.027268491685390472, dist_loss: 0.6966718435287476
recon_loss: 0.02726777270436287, dist_loss: 0.43013378977775574
recon_loss: 0.027267299592494965, dist_loss: 1.0530214309692383
recon_loss: 0.027267443016171455, dist_loss: 0.982456386089325
recon_loss: 0.027267569676041603, dist_loss: 0.27413439750671387
recon_loss: 0.027268145233392715, dist_loss: 0.5943955183029175
recon_loss: 0.027268730103969574, dist_loss: 0.7978296875953674
recon_loss: 0.027270227670669556, dist_loss: 0.927143931388855
recon_loss: 0.0272710882127285, dist_loss: 0.8674100041389465
recon_loss: 0.027271434664726257, dist_loss: 0.5649605989456177
recon_loss: 0.027271857485175133, dist_loss: 0.9988477826118469
recon_loss: 0.027272460982203484, dist_loss: 0.4680289626121521
recon_loss: 0.027272922918200493, dist_loss: 0.3939743638038635
recon_loss: 0.027272358536720276, dist_loss: 0.4755769968032837
recon_loss: 0.02727101743221283, dist_loss: 0.5168684720993042
recon_loss: 0.027270112186670303, dist_loss: 0.7106481194496155
recon_loss: 0.02726934477686882, dist_loss: 0.453529417514801
recon_loss: 0.02726847678422928, dist_loss: 0.8661614656448364
recon_loss: 0.027267789468169212, dist_loss: 0.36199086904525757
recon_loss: 0.027267668396234512, dist_loss: 0.46402865648269653
recon_loss: 0.027268346399068832, dist_loss: 0.9856964945793152
recon_loss: 0.027268564328551292, dist_loss: 0.5443761348724365
recon_loss: 0.027268359437584877, dist_loss: 0.3790671229362488
recon_loss: 0.02726799063384533, dist_loss: 0.7763437628746033
recon_loss: 0.027267852798104286, dist_loss: 0.7013546228408813
recon_loss: 0.027267392724752426, dist_loss: 0.616092324256897
recon_loss: 0.027267415076494217, dist_loss: 0.8249013423919678
recon_loss: 0.02726716361939907, dist_loss: 0.9885437488555908
recon_loss: 0.0272668544203043, dist_loss: 0.6846857070922852
recon_loss: 0.027266621589660645, dist_loss: 0.3630000352859497
recon_loss: 0.027266543358564377, dist_loss: 0.859825074672699
recon_loss: 0.027267005294561386, dist_loss: 0.6627341508865356
recon_loss: 0.02726696990430355, dist_loss: 0.5401254296302795
recon_loss: 0.027267711237072945, dist_loss: 0.7078409194946289
recon_loss: 0.02726759947836399, dist_loss: 0.7701945900917053
recon_loss: 0.027268674224615097, dist_loss: 0.5707705020904541
recon_loss: 0.02726772613823414, dist_loss: 0.8712302446365356
recon_loss: 0.027267711237072945, dist_loss: 0.6973142623901367
recon_loss: 0.027266595512628555, dist_loss: 0.649880588054657
recon_loss: 0.027266478165984154, dist_loss: 0.6968039274215698
recon_loss: 0.02726544626057148, dist_loss: 0.44976961612701416
recon_loss: 0.027265720069408417, dist_loss: 0.8483244776725769
recon_loss: 0.027265185490250587, dist_loss: 0.31021392345428467
recon_loss: 0.027265725657343864, dist_loss: 0.6920870542526245
recon_loss: 0.02726641111075878, dist_loss: 0.37776315212249756
recon_loss: 0.027266906574368477, dist_loss: 0.3843480944633484
recon_loss: 0.02726779878139496, dist_loss: 0.9130021333694458
recon_loss: 0.02726861834526062, dist_loss: 0.8916727304458618
recon_loss: 0.0272691547870636, dist_loss: 0.5197346210479736
recon_loss: 0.0272684246301651, dist_loss: 0.6491124629974365
recon_loss: 0.027268799021840096, dist_loss: 0.8979096412658691
recon_loss: 0.027267897501587868, dist_loss: 0.6199977397918701
recon_loss: 0.02726670727133751, dist_loss: 0.7183470726013184
recon_loss: 0.027266433462500572, dist_loss: 0.4765724539756775
recon_loss: 0.027264663949608803, dist_loss: 0.8347430229187012
recon_loss: 0.027264926582574844, dist_loss: 0.6351941823959351
recon_loss: 0.027264077216386795, dist_loss: 0.7383921146392822
recon_loss: 0.027264656499028206, dist_loss: 0.6506255865097046
recon_loss: 0.02726418897509575, dist_loss: 0.3931080102920532
recon_loss: 0.02726534754037857, dist_loss: 0.797710657119751
recon_loss: 0.02726549096405506, dist_loss: 0.4919589161872864
recon_loss: 0.027265086770057678, dist_loss: 0.6381953358650208
recon_loss: 0.027265194803476334, dist_loss: 0.92198646068573
recon_loss: 0.02726483717560768, dist_loss: 0.5471895337104797
recon_loss: 0.027265286073088646, dist_loss: 0.5268218517303467
recon_loss: 0.02726464346051216, dist_loss: 0.7459985017776489
recon_loss: 0.027264414355158806, dist_loss: 0.5211108326911926
recon_loss: 0.027264053001999855, dist_loss: 0.5676536560058594
recon_loss: 0.027264026924967766, dist_loss: 0.6370635628700256
recon_loss: 0.027264157310128212, dist_loss: 0.45762211084365845
recon_loss: 0.027264483273029327, dist_loss: 0.7320339679718018
recon_loss: 0.02726433053612709, dist_loss: 0.5561506748199463
recon_loss: 0.02726425603032112, dist_loss: 0.7706465125083923
recon_loss: 0.027264077216386795, dist_loss: 0.6031839847564697
recon_loss: 0.02726382575929165, dist_loss: 0.6180638074874878
recon_loss: 0.027263982221484184, dist_loss: 0.6486369371414185
recon_loss: 0.02726408652961254, dist_loss: 0.6461714506149292
recon_loss: 0.0272649135440588, dist_loss: 0.9143934845924377
recon_loss: 0.027265558019280434, dist_loss: 0.7604016065597534
recon_loss: 0.027264827862381935, dist_loss: 1.1717087030410767
recon_loss: 0.02726481482386589, dist_loss: 0.5861958861351013
recon_loss: 0.027264293283224106, dist_loss: 0.46569496393203735
recon_loss: 0.02726403810083866, dist_loss: 0.84360671043396
recon_loss: 0.027263779193162918, dist_loss: 0.6767115592956543
recon_loss: 0.027262961491942406, dist_loss: 0.4584287106990814
recon_loss: 0.027263063937425613, dist_loss: 0.4954689145088196
recon_loss: 0.02726341038942337, dist_loss: 0.8293007612228394
recon_loss: 0.027263781055808067, dist_loss: 0.37453392148017883
recon_loss: 0.02726397104561329, dist_loss: 0.48215025663375854
recon_loss: 0.027264192700386047, dist_loss: 0.2974361181259155
recon_loss: 0.027264602482318878, dist_loss: 0.8008319735527039
recon_loss: 0.027264747768640518, dist_loss: 0.9691664576530457
recon_loss: 0.027265537530183792, dist_loss: 0.5610417127609253
recon_loss: 0.027266578748822212, dist_loss: 0.7752417325973511
recon_loss: 0.027266865596175194, dist_loss: 0.8791947364807129
recon_loss: 0.02726639434695244, dist_loss: 0.4043998718261719
recon_loss: 0.0272651519626379, dist_loss: 1.0660767555236816
recon_loss: 0.027264254167675972, dist_loss: 0.4740647077560425
recon_loss: 0.02726304717361927, dist_loss: 0.7632032632827759
recon_loss: 0.027262849733233452, dist_loss: 0.6908925771713257
recon_loss: 0.027262555435299873, dist_loss: 0.42695990204811096
recon_loss: 0.027262544259428978, dist_loss: 0.4909425377845764
recon_loss: 0.02726231887936592, dist_loss: 0.7121690511703491
recon_loss: 0.02726205252110958, dist_loss: 0.8167665004730225
recon_loss: 0.027262432500720024, dist_loss: 0.4792933464050293
recon_loss: 0.027262644842267036, dist_loss: 0.33998557925224304
recon_loss: 0.02726304717361927, dist_loss: 0.4703750014305115
recon_loss: 0.027262799441814423, dist_loss: 0.38838863372802734
recon_loss: 0.027262700721621513, dist_loss: 1.1636245250701904
recon_loss: 0.027262486517429352, dist_loss: 0.4352540969848633
recon_loss: 0.027262693271040916, dist_loss: 0.6739330291748047
recon_loss: 0.027262264862656593, dist_loss: 0.8047704696655273
Pre-training Epoch 113:  73%|███████▎  | 269/367 [00:01<00:00, 141.86it/s]Pre-training Epoch 113:  77%|███████▋  | 284/367 [00:01<00:00, 142.90it/s]Pre-training Epoch 113:  81%|████████▏ | 299/367 [00:02<00:00, 143.90it/s]Pre-training Epoch 113:  86%|████████▌ | 314/367 [00:02<00:00, 144.82it/s]Pre-training Epoch 113:  90%|████████▉ | 329/367 [00:02<00:00, 144.41it/s]Pre-training Epoch 113:  94%|█████████▎| 344/367 [00:02<00:00, 145.27it/s]Pre-training Epoch 113:  98%|█████████▊| 359/367 [00:02<00:00, 145.84it/s]Pre-training Epoch 113: 100%|██████████| 367/367 [00:02<00:00, 144.21it/s]
recon_loss: 0.027262216433882713, dist_loss: 0.373137891292572
recon_loss: 0.027262065559625626, dist_loss: 0.46618199348449707
recon_loss: 0.027261588722467422, dist_loss: 0.5649393796920776
recon_loss: 0.027261804789304733, dist_loss: 0.6024312376976013
recon_loss: 0.027261685580015182, dist_loss: 0.7811986804008484
recon_loss: 0.027263205498456955, dist_loss: 0.6787731647491455
recon_loss: 0.02726331539452076, dist_loss: 0.5083639025688171
recon_loss: 0.027264771983027458, dist_loss: 0.48100942373275757
recon_loss: 0.027264637872576714, dist_loss: 0.6272957921028137
recon_loss: 0.027264486998319626, dist_loss: 0.6420125961303711
recon_loss: 0.027265043929219246, dist_loss: 0.7452191114425659
recon_loss: 0.027263682335615158, dist_loss: 1.1922979354858398
recon_loss: 0.027264144271612167, dist_loss: 0.4523070454597473
recon_loss: 0.027263127267360687, dist_loss: 1.2357184886932373
recon_loss: 0.027262412011623383, dist_loss: 0.33701291680336
recon_loss: 0.027261938899755478, dist_loss: 0.6818018555641174
recon_loss: 0.027261681854724884, dist_loss: 1.104618787765503
recon_loss: 0.02726173959672451, dist_loss: 0.5992475748062134
recon_loss: 0.027261659502983093, dist_loss: 0.8254231810569763
recon_loss: 0.027262171730399132, dist_loss: 0.6015650033950806
recon_loss: 0.02726154960691929, dist_loss: 0.7896276712417603
recon_loss: 0.027261920273303986, dist_loss: 0.5069588422775269
recon_loss: 0.02726121060550213, dist_loss: 0.6343230605125427
recon_loss: 0.02726106159389019, dist_loss: 0.4556539058685303
recon_loss: 0.027261091396212578, dist_loss: 0.46858566999435425
recon_loss: 0.027260446920990944, dist_loss: 0.4757688045501709
recon_loss: 0.02726035937666893, dist_loss: 0.5231044888496399
recon_loss: 0.027260230854153633, dist_loss: 0.4214528799057007
recon_loss: 0.027260279282927513, dist_loss: 0.4522140920162201
recon_loss: 0.02726045809686184, dist_loss: 0.6474446058273315
recon_loss: 0.027260560542345047, dist_loss: 0.8363237977027893
recon_loss: 0.027260797098279, dist_loss: 0.547147274017334
recon_loss: 0.027261339128017426, dist_loss: 0.668647050857544
recon_loss: 0.027261950075626373, dist_loss: 0.8256220817565918
recon_loss: 0.027262672781944275, dist_loss: 1.1886714696884155
recon_loss: 0.027262821793556213, dist_loss: 0.5204519033432007
recon_loss: 0.02726210281252861, dist_loss: 0.7095651626586914
recon_loss: 0.027261700481176376, dist_loss: 0.5137007236480713
recon_loss: 0.02726096659898758, dist_loss: 0.705990195274353
recon_loss: 0.02726101316511631, dist_loss: 1.2228952646255493
recon_loss: 0.027260934934020042, dist_loss: 0.8250691294670105
recon_loss: 0.02726166695356369, dist_loss: 0.5801973342895508
recon_loss: 0.02726234681904316, dist_loss: 0.49443843960762024
recon_loss: 0.02726331725716591, dist_loss: 1.559523344039917
recon_loss: 0.027265150099992752, dist_loss: 0.32461273670196533
recon_loss: 0.02726738527417183, dist_loss: 0.47088438272476196
recon_loss: 0.027269257232546806, dist_loss: 0.505445122718811
recon_loss: 0.027269277721643448, dist_loss: 0.5359985828399658
recon_loss: 0.027268899604678154, dist_loss: 1.2945408821105957
recon_loss: 0.02726917713880539, dist_loss: 0.35016363859176636
recon_loss: 0.027268650010228157, dist_loss: 0.5578081607818604
recon_loss: 0.027267782017588615, dist_loss: 0.4782803952693939
recon_loss: 0.027265973389148712, dist_loss: 0.4585852026939392
recon_loss: 0.027264386415481567, dist_loss: 0.752439558506012
recon_loss: 0.027263564988970757, dist_loss: 0.6394274234771729
recon_loss: 0.027263011783361435, dist_loss: 0.6510860919952393
recon_loss: 0.027263570576906204, dist_loss: 0.6828046441078186
recon_loss: 0.027263958007097244, dist_loss: 0.839602530002594
recon_loss: 0.02726457081735134, dist_loss: 0.5037015676498413
recon_loss: 0.02726428210735321, dist_loss: 0.23935237526893616
recon_loss: 0.027263710275292397, dist_loss: 1.0849609375
recon_loss: 0.027262983843684196, dist_loss: 0.40875792503356934
recon_loss: 0.02726224809885025, dist_loss: 0.3932158052921295
recon_loss: 0.02726161852478981, dist_loss: 0.5047306418418884
recon_loss: 0.027261042967438698, dist_loss: 0.6853286027908325
recon_loss: 0.027260588482022285, dist_loss: 0.31873267889022827
recon_loss: 0.02726031467318535, dist_loss: 0.37578487396240234
recon_loss: 0.02725990302860737, dist_loss: 0.18735527992248535
recon_loss: 0.027259724214673042, dist_loss: 0.46544474363327026
recon_loss: 0.027259349822998047, dist_loss: 0.6881334185600281
recon_loss: 0.027259303256869316, dist_loss: 0.6675127744674683
recon_loss: 0.027259010821580887, dist_loss: 0.6030223965644836
recon_loss: 0.02725895307958126, dist_loss: 0.5775434970855713
recon_loss: 0.02725873328745365, dist_loss: 0.4703832268714905
recon_loss: 0.02725863642990589, dist_loss: 0.3891904950141907
recon_loss: 0.027258476242423058, dist_loss: 0.36879727244377136
recon_loss: 0.027258502319455147, dist_loss: 1.345761775970459
recon_loss: 0.02725854143500328, dist_loss: 0.6499315500259399
recon_loss: 0.02725866809487343, dist_loss: 0.6274653077125549
recon_loss: 0.027259044349193573, dist_loss: 0.45298251509666443
recon_loss: 0.027259662747383118, dist_loss: 0.45808807015419006
recon_loss: 0.027260232716798782, dist_loss: 0.4904915690422058
recon_loss: 0.027260834351181984, dist_loss: 1.0278576612472534
recon_loss: 0.027261413633823395, dist_loss: 1.022218942642212
recon_loss: 0.02726200595498085, dist_loss: 0.5211244821548462
recon_loss: 0.027262570336461067, dist_loss: 0.9847382307052612
recon_loss: 0.027263162657618523, dist_loss: 0.43182337284088135
recon_loss: 0.027263689786195755, dist_loss: 0.4314766824245453
recon_loss: 0.027263779193162918, dist_loss: 0.6196187138557434
recon_loss: 0.027264034375548363, dist_loss: 0.6697044968605042
recon_loss: 0.02726423181593418, dist_loss: 0.3378340005874634
recon_loss: 0.02726452238857746, dist_loss: 0.3964933156967163
recon_loss: 0.02726481482386589, dist_loss: 0.45384475588798523
recon_loss: 0.02726462297141552, dist_loss: 0.5237109065055847
recon_loss: 0.02726406790316105, dist_loss: 0.9023559093475342
recon_loss: 0.0272633358836174, dist_loss: 0.2705940902233124
recon_loss: 0.027262141928076744, dist_loss: 0.9920055866241455
recon_loss: 0.027261406183242798, dist_loss: 0.5901914238929749
recon_loss: 0.027260929346084595, dist_loss: 0.5138586163520813
recon_loss: 0.02726101130247116, dist_loss: 0.6107852458953857
recon_loss: 0.02726146951317787, dist_loss: 0.6671144962310791
recon_loss: 0.02726231887936592, dist_loss: 0.5186484456062317
recon_loss: 0.027262846007943153, dist_loss: 0.651984691619873
recon_loss: 0.027264155447483063, dist_loss: 0.854778528213501
recon_loss: 0.027265138924121857, dist_loss: 0.6245914697647095
recon_loss: 0.02726665511727333, dist_loss: 0.7861855030059814
recon_loss: 0.027267826721072197, dist_loss: 0.5535179376602173
recon_loss: 0.02726874127984047, dist_loss: 0.5716038942337036
recon_loss: 0.02726934477686882, dist_loss: 0.8007780313491821
recon_loss: 0.027269724756479263, dist_loss: 1.3311405181884766
recon_loss: 0.027270127087831497, dist_loss: 0.7023431658744812
Pre-training Epoch 114:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 114:   5%|▍         | 17/367 [00:00<00:02, 163.03it/s]Pre-training Epoch 114:   9%|▉         | 34/367 [00:00<00:02, 155.08it/s]Pre-training Epoch 114:  14%|█▎        | 50/367 [00:00<00:02, 147.97it/s]Pre-training Epoch 114:  18%|█▊        | 65/367 [00:00<00:02, 146.22it/s]Pre-training Epoch 114:  22%|██▏       | 80/367 [00:00<00:01, 146.76it/s]Pre-training Epoch 114:  26%|██▌       | 95/367 [00:00<00:01, 143.86it/s]Pre-training Epoch 114:  30%|██▉       | 110/367 [00:00<00:01, 143.65it/s]Pre-training Epoch 114:  35%|███▍      | 127/367 [00:00<00:01, 149.82it/s]recon_loss: 0.027270695194602013, dist_loss: 0.8122014999389648
recon_loss: 0.027270758524537086, dist_loss: 0.5612833499908447
recon_loss: 0.02727164886891842, dist_loss: 0.7824204564094543
recon_loss: 0.027271755039691925, dist_loss: 0.5852304100990295
recon_loss: 0.027272282168269157, dist_loss: 0.3634086847305298
recon_loss: 0.027272678911685944, dist_loss: 0.38310688734054565
recon_loss: 0.027272216975688934, dist_loss: 0.4144083857536316
recon_loss: 0.027272891253232956, dist_loss: 0.35954874753952026
recon_loss: 0.02727297507226467, dist_loss: 0.44321590662002563
recon_loss: 0.027273986488580704, dist_loss: 0.662131130695343
recon_loss: 0.027273127809166908, dist_loss: 0.6780796051025391
recon_loss: 0.027273373678326607, dist_loss: 0.4539092779159546
recon_loss: 0.02727239765226841, dist_loss: 0.6083623170852661
recon_loss: 0.027269838377833366, dist_loss: 0.5900425910949707
recon_loss: 0.0272677019238472, dist_loss: 1.088234543800354
recon_loss: 0.027266407385468483, dist_loss: 0.46097689867019653
recon_loss: 0.027265479788184166, dist_loss: 0.5292324423789978
recon_loss: 0.02726578153669834, dist_loss: 0.4831911027431488
recon_loss: 0.02726573869585991, dist_loss: 0.8059972524642944
recon_loss: 0.02726624347269535, dist_loss: 0.5400988459587097
recon_loss: 0.027265505865216255, dist_loss: 0.36676305532455444
recon_loss: 0.027265513315796852, dist_loss: 0.37566477060317993
recon_loss: 0.027264650911092758, dist_loss: 0.9928200840950012
recon_loss: 0.027264554053544998, dist_loss: 0.9678174257278442
recon_loss: 0.027263043448328972, dist_loss: 0.5221041440963745
recon_loss: 0.02726162038743496, dist_loss: 0.5439109802246094
recon_loss: 0.027261482551693916, dist_loss: 0.7259025573730469
recon_loss: 0.027261782437562943, dist_loss: 0.5332943201065063
recon_loss: 0.027262112125754356, dist_loss: 0.5630660653114319
recon_loss: 0.027262035757303238, dist_loss: 0.7960836887359619
recon_loss: 0.027262412011623383, dist_loss: 0.9111881852149963
recon_loss: 0.027262719348073006, dist_loss: 0.4457341134548187
recon_loss: 0.027262836694717407, dist_loss: 0.5417947173118591
recon_loss: 0.027262523770332336, dist_loss: 1.0680217742919922
recon_loss: 0.027262194082140923, dist_loss: 0.69492107629776
recon_loss: 0.027260661125183105, dist_loss: 0.8988906145095825
recon_loss: 0.02726064994931221, dist_loss: 1.0373475551605225
recon_loss: 0.027260692790150642, dist_loss: 0.6822140216827393
recon_loss: 0.02726118080317974, dist_loss: 0.5203072428703308
recon_loss: 0.027261586859822273, dist_loss: 1.0441124439239502
recon_loss: 0.027261212468147278, dist_loss: 0.7936238050460815
recon_loss: 0.027260776609182358, dist_loss: 0.4238666892051697
recon_loss: 0.027260160073637962, dist_loss: 0.9328348636627197
recon_loss: 0.02725980430841446, dist_loss: 0.47482720017433167
recon_loss: 0.02725915051996708, dist_loss: 0.860350489616394
recon_loss: 0.02725830115377903, dist_loss: 0.699614405632019
recon_loss: 0.027257824316620827, dist_loss: 0.5163032412528992
recon_loss: 0.027257418259978294, dist_loss: 1.3675020933151245
recon_loss: 0.027256779372692108, dist_loss: 0.5328545570373535
recon_loss: 0.027256399393081665, dist_loss: 0.5905525088310242
recon_loss: 0.027256540954113007, dist_loss: 0.434567928314209
recon_loss: 0.027256540954113007, dist_loss: 0.5675944089889526
recon_loss: 0.027256906032562256, dist_loss: 0.6194336414337158
recon_loss: 0.02725669927895069, dist_loss: 0.7255624532699585
recon_loss: 0.02725655399262905, dist_loss: 0.7427159547805786
recon_loss: 0.02725657820701599, dist_loss: 0.8472718596458435
recon_loss: 0.02725689671933651, dist_loss: 0.6848702430725098
recon_loss: 0.027257099747657776, dist_loss: 0.9724993109703064
recon_loss: 0.027257246896624565, dist_loss: 0.577283501625061
recon_loss: 0.02725720778107643, dist_loss: 0.8545398712158203
recon_loss: 0.02725677378475666, dist_loss: 0.6406832337379456
recon_loss: 0.027255890890955925, dist_loss: 0.7877064943313599
recon_loss: 0.027255520224571228, dist_loss: 0.5986083745956421
recon_loss: 0.02725498378276825, dist_loss: 0.8885867595672607
recon_loss: 0.0272553488612175, dist_loss: 1.0483570098876953
recon_loss: 0.027256999164819717, dist_loss: 1.0001755952835083
recon_loss: 0.02725895307958126, dist_loss: 1.0353401899337769
recon_loss: 0.0272603128105402, dist_loss: 0.4481610655784607
recon_loss: 0.02726171538233757, dist_loss: 0.7570052742958069
recon_loss: 0.02725975029170513, dist_loss: 0.6987137198448181
recon_loss: 0.027261115610599518, dist_loss: 0.8165401220321655
recon_loss: 0.02725929580628872, dist_loss: 0.36705830693244934
recon_loss: 0.02725989930331707, dist_loss: 0.4036080241203308
recon_loss: 0.027257507666945457, dist_loss: 0.6628147959709167
recon_loss: 0.027257824316620827, dist_loss: 0.7524968981742859
recon_loss: 0.027256593108177185, dist_loss: 0.6286807656288147
recon_loss: 0.027256716042757034, dist_loss: 0.46357619762420654
recon_loss: 0.027256587520241737, dist_loss: 0.4945191740989685
recon_loss: 0.027256228029727936, dist_loss: 0.6633174419403076
recon_loss: 0.027256039902567863, dist_loss: 0.5840011835098267
recon_loss: 0.02725536748766899, dist_loss: 0.6709805727005005
recon_loss: 0.027255482971668243, dist_loss: 0.879090428352356
recon_loss: 0.027254687622189522, dist_loss: 0.6654312610626221
recon_loss: 0.027255183085799217, dist_loss: 0.5453495383262634
recon_loss: 0.027254775166511536, dist_loss: 0.8842824697494507
recon_loss: 0.02725624293088913, dist_loss: 0.8306243419647217
recon_loss: 0.027255941182374954, dist_loss: 0.4133762717247009
recon_loss: 0.027257492765784264, dist_loss: 0.37583762407302856
recon_loss: 0.027256108820438385, dist_loss: 0.5139720439910889
recon_loss: 0.027256689965724945, dist_loss: 0.5966271162033081
recon_loss: 0.02725747600197792, dist_loss: 0.6236950159072876
recon_loss: 0.027256207540631294, dist_loss: 0.4484807848930359
recon_loss: 0.02725658379495144, dist_loss: 0.6332197189331055
recon_loss: 0.027256134897470474, dist_loss: 0.7367029190063477
recon_loss: 0.02725629135966301, dist_loss: 0.41020214557647705
recon_loss: 0.027255387976765633, dist_loss: 0.7002249956130981
recon_loss: 0.027255328372120857, dist_loss: 0.7628483176231384
recon_loss: 0.027253994718194008, dist_loss: 0.5484848618507385
recon_loss: 0.02725418284535408, dist_loss: 0.35226213932037354
recon_loss: 0.027253707870841026, dist_loss: 0.5013681650161743
recon_loss: 0.02725381590425968, dist_loss: 1.1990712881088257
recon_loss: 0.02725442685186863, dist_loss: 0.6206166744232178
recon_loss: 0.027255423367023468, dist_loss: 0.6296504139900208
recon_loss: 0.02725740149617195, dist_loss: 0.7461143732070923
recon_loss: 0.027259673923254013, dist_loss: 0.7563751339912415
recon_loss: 0.027261395007371902, dist_loss: 0.39977583289146423
recon_loss: 0.02726280316710472, dist_loss: 0.7333633899688721
recon_loss: 0.027263155207037926, dist_loss: 0.7952638864517212
recon_loss: 0.02726278081536293, dist_loss: 0.9831476211547852
recon_loss: 0.027260882779955864, dist_loss: 0.5681354999542236
recon_loss: 0.027260703966021538, dist_loss: 0.6486135721206665
recon_loss: 0.02725939452648163, dist_loss: 0.7158834934234619
recon_loss: 0.027258964255452156, dist_loss: 0.4749373197555542
recon_loss: 0.027257582172751427, dist_loss: 0.8068544864654541
recon_loss: 0.0272564385086298, dist_loss: 0.5742506980895996
recon_loss: 0.027256406843662262, dist_loss: 0.4910793900489807
recon_loss: 0.027257099747657776, dist_loss: 0.5347719192504883
recon_loss: 0.027260446920990944, dist_loss: 0.3623290956020355
recon_loss: 0.027261583134531975, dist_loss: 0.4569597840309143
recon_loss: 0.027264518663287163, dist_loss: 0.5270310044288635
recon_loss: 0.02726520597934723, dist_loss: 1.1337922811508179
recon_loss: 0.027266357094049454, dist_loss: 0.6637703776359558
recon_loss: 0.027265651151537895, dist_loss: 0.7790843844413757
recon_loss: 0.027265258133411407, dist_loss: 0.8852947354316711
recon_loss: 0.027264483273029327, dist_loss: 0.40081173181533813
recon_loss: 0.02726287767291069, dist_loss: 0.6368451118469238
recon_loss: 0.027261052280664444, dist_loss: 0.5785007476806641
recon_loss: 0.02725999616086483, dist_loss: 0.5537214279174805
Pre-training Epoch 114:  39%|███▉      | 144/367 [00:00<00:01, 154.49it/s]Pre-training Epoch 114:  44%|████▍     | 161/367 [00:01<00:01, 157.63it/s]Pre-training Epoch 114:  49%|████▉     | 179/367 [00:01<00:01, 161.88it/s]Pre-training Epoch 114:  53%|█████▎    | 196/367 [00:01<00:01, 163.65it/s]Pre-training Epoch 114:  58%|█████▊    | 213/367 [00:01<00:00, 157.93it/s]Pre-training Epoch 114:  62%|██████▏   | 229/367 [00:01<00:00, 153.05it/s]Pre-training Epoch 114:  67%|██████▋   | 245/367 [00:01<00:00, 149.53it/s]recon_loss: 0.02725958079099655, dist_loss: 1.084943413734436
recon_loss: 0.027260666713118553, dist_loss: 0.7120916247367859
recon_loss: 0.02726302668452263, dist_loss: 0.4569550156593323
recon_loss: 0.02726532518863678, dist_loss: 0.37450531125068665
recon_loss: 0.027266863733530045, dist_loss: 0.6263794302940369
recon_loss: 0.02726799249649048, dist_loss: 0.4541590213775635
recon_loss: 0.027268460020422935, dist_loss: 0.9036409854888916
recon_loss: 0.027268769219517708, dist_loss: 0.43414026498794556
recon_loss: 0.027267826721072197, dist_loss: 0.6780747771263123
recon_loss: 0.02726665697991848, dist_loss: 0.5198310613632202
recon_loss: 0.0272645503282547, dist_loss: 0.4876851439476013
recon_loss: 0.027262872084975243, dist_loss: 0.5992847084999084
recon_loss: 0.027261225506663322, dist_loss: 1.236724615097046
recon_loss: 0.027259839698672295, dist_loss: 0.3971729278564453
recon_loss: 0.027258403599262238, dist_loss: 0.4640096426010132
recon_loss: 0.02725694142282009, dist_loss: 0.3088207244873047
recon_loss: 0.027256865054368973, dist_loss: 0.43461012840270996
recon_loss: 0.027256986126303673, dist_loss: 0.7009180784225464
recon_loss: 0.027258293703198433, dist_loss: 0.5087564587593079
recon_loss: 0.027259357273578644, dist_loss: 0.6292819380760193
recon_loss: 0.027260491624474525, dist_loss: 0.7660639882087708
recon_loss: 0.02726156823337078, dist_loss: 0.7292286157608032
recon_loss: 0.027263205498456955, dist_loss: 0.9925957322120667
recon_loss: 0.027263306081295013, dist_loss: 0.5417628288269043
recon_loss: 0.027263155207037926, dist_loss: 0.7000991106033325
recon_loss: 0.027263374999165535, dist_loss: 0.358529269695282
recon_loss: 0.02726275846362114, dist_loss: 0.9708299040794373
recon_loss: 0.027262147516012192, dist_loss: 0.4366194009780884
recon_loss: 0.027261381968855858, dist_loss: 0.8454606533050537
recon_loss: 0.02726125717163086, dist_loss: 0.559501051902771
recon_loss: 0.027260733768343925, dist_loss: 0.7633638978004456
recon_loss: 0.02725983038544655, dist_loss: 0.5674550533294678
recon_loss: 0.02725876122713089, dist_loss: 0.8751459121704102
recon_loss: 0.02725793421268463, dist_loss: 0.6036869883537292
recon_loss: 0.027257164940238, dist_loss: 0.6850938200950623
recon_loss: 0.027256514877080917, dist_loss: 0.39124926924705505
recon_loss: 0.027256552129983902, dist_loss: 0.4107277989387512
recon_loss: 0.02725651115179062, dist_loss: 0.8108809590339661
recon_loss: 0.02725611813366413, dist_loss: 0.753862738609314
recon_loss: 0.027255672961473465, dist_loss: 0.46194034814834595
recon_loss: 0.027254832908511162, dist_loss: 0.8218235969543457
recon_loss: 0.027254190295934677, dist_loss: 0.6140905618667603
recon_loss: 0.027253244072198868, dist_loss: 0.7640700340270996
recon_loss: 0.027252700179815292, dist_loss: 0.44002559781074524
recon_loss: 0.027251627296209335, dist_loss: 0.8704676628112793
recon_loss: 0.02725078910589218, dist_loss: 0.3671411871910095
recon_loss: 0.027250735089182854, dist_loss: 1.0712120532989502
recon_loss: 0.02725054882466793, dist_loss: 0.5126277208328247
recon_loss: 0.027250362560153008, dist_loss: 0.5261443257331848
recon_loss: 0.027250315994024277, dist_loss: 0.901750922203064
recon_loss: 0.02725035324692726, dist_loss: 0.9185788631439209
recon_loss: 0.027250513434410095, dist_loss: 0.6824131011962891
recon_loss: 0.027250636368989944, dist_loss: 0.6088506579399109
recon_loss: 0.027250632643699646, dist_loss: 0.8843676447868347
recon_loss: 0.02725084312260151, dist_loss: 0.4168941080570221
recon_loss: 0.02725084498524666, dist_loss: 0.6302993893623352
recon_loss: 0.027250664308667183, dist_loss: 0.6966332197189331
recon_loss: 0.02725079096853733, dist_loss: 0.6563912630081177
recon_loss: 0.027251381427049637, dist_loss: 0.7182511687278748
recon_loss: 0.027251452207565308, dist_loss: 0.5556676387786865
recon_loss: 0.02725149504840374, dist_loss: 0.5059212446212769
recon_loss: 0.02725173346698284, dist_loss: 0.4191696047782898
recon_loss: 0.027251647785305977, dist_loss: 0.35817503929138184
recon_loss: 0.027251338586211205, dist_loss: 0.7005833983421326
recon_loss: 0.027251174673438072, dist_loss: 0.576472282409668
recon_loss: 0.027251198887825012, dist_loss: 0.4893244504928589
recon_loss: 0.027251064777374268, dist_loss: 0.5705375075340271
recon_loss: 0.027251046150922775, dist_loss: 0.7709528207778931
recon_loss: 0.02725072205066681, dist_loss: 0.3844318091869354
recon_loss: 0.027250537648797035, dist_loss: 0.4604882299900055
recon_loss: 0.027250193059444427, dist_loss: 0.4417741298675537
recon_loss: 0.027249589562416077, dist_loss: 0.5286216735839844
recon_loss: 0.027249155566096306, dist_loss: 0.6129128932952881
recon_loss: 0.027249284088611603, dist_loss: 0.47539830207824707
recon_loss: 0.02724963054060936, dist_loss: 0.7377076745033264
recon_loss: 0.0272501390427351, dist_loss: 0.6862195134162903
recon_loss: 0.027250593528151512, dist_loss: 0.6531941294670105
recon_loss: 0.027251608669757843, dist_loss: 0.8025328516960144
recon_loss: 0.0272518303245306, dist_loss: 0.3242812156677246
recon_loss: 0.027252191677689552, dist_loss: 0.8653959035873413
recon_loss: 0.02725105918943882, dist_loss: 0.5013598203659058
recon_loss: 0.02725084312260151, dist_loss: 0.9425424337387085
recon_loss: 0.027252772822976112, dist_loss: 0.7497084140777588
recon_loss: 0.027251260355114937, dist_loss: 0.7732295989990234
recon_loss: 0.02725294791162014, dist_loss: 0.4211561977863312
recon_loss: 0.02725152112543583, dist_loss: 0.6762862205505371
recon_loss: 0.027251586318016052, dist_loss: 0.5659505724906921
recon_loss: 0.02725032903254032, dist_loss: 0.36237549781799316
recon_loss: 0.027250556275248528, dist_loss: 0.959294319152832
recon_loss: 0.027250155806541443, dist_loss: 0.3935384452342987
recon_loss: 0.027249973267316818, dist_loss: 0.3910191059112549
recon_loss: 0.027251575142145157, dist_loss: 0.8612715005874634
recon_loss: 0.027251973748207092, dist_loss: 0.748047947883606
recon_loss: 0.0272545013576746, dist_loss: 0.2984907627105713
recon_loss: 0.027254194021224976, dist_loss: 1.188449501991272
recon_loss: 0.027255142107605934, dist_loss: 0.5423374176025391
recon_loss: 0.027253229171037674, dist_loss: 0.49711012840270996
recon_loss: 0.027252277359366417, dist_loss: 0.9215608835220337
recon_loss: 0.027252288535237312, dist_loss: 0.9219382405281067
recon_loss: 0.027249876409769058, dist_loss: 0.5735597610473633
recon_loss: 0.027250463142991066, dist_loss: 0.7261910438537598
recon_loss: 0.027248689904808998, dist_loss: 0.6415711641311646
recon_loss: 0.02724883332848549, dist_loss: 0.41265609860420227
recon_loss: 0.02724771946668625, dist_loss: 0.372068852186203
recon_loss: 0.027249107137322426, dist_loss: 0.5955134630203247
recon_loss: 0.027248382568359375, dist_loss: 0.4734192490577698
recon_loss: 0.027249416336417198, dist_loss: 0.5697673559188843
recon_loss: 0.02724931761622429, dist_loss: 0.9172464609146118
recon_loss: 0.027249202132225037, dist_loss: 0.6980202198028564
recon_loss: 0.027249731123447418, dist_loss: 0.4877249002456665
recon_loss: 0.027248911559581757, dist_loss: 0.4974402189254761
recon_loss: 0.027249068021774292, dist_loss: 0.5511422157287598
recon_loss: 0.02724846452474594, dist_loss: 0.5223006010055542
recon_loss: 0.02724865823984146, dist_loss: 0.4134127199649811
recon_loss: 0.02724861167371273, dist_loss: 0.6271759271621704
recon_loss: 0.027249373495578766, dist_loss: 0.5520504713058472
recon_loss: 0.027248939499258995, dist_loss: 0.6036840677261353
recon_loss: 0.027248675003647804, dist_loss: 0.40107017755508423
recon_loss: 0.027248598635196686, dist_loss: 0.9929877519607544
recon_loss: 0.027248961851000786, dist_loss: 0.5902936458587646
recon_loss: 0.027248520404100418, dist_loss: 1.0836588144302368
recon_loss: 0.027248170226812363, dist_loss: 0.7506989240646362
recon_loss: 0.027249105274677277, dist_loss: 0.5679153800010681
recon_loss: 0.027247987687587738, dist_loss: 0.5422846078872681
recon_loss: 0.02724887616932392, dist_loss: 1.0193650722503662
recon_loss: 0.02724754437804222, dist_loss: 0.5482834577560425
recon_loss: 0.027247672900557518, dist_loss: 0.4650224447250366
recon_loss: 0.02724703773856163, dist_loss: 0.7572613954544067
Pre-training Epoch 114:  71%|███████   | 260/367 [00:01<00:00, 141.86it/s]Pre-training Epoch 114:  75%|███████▍  | 275/367 [00:01<00:00, 139.05it/s]Pre-training Epoch 114:  79%|███████▊  | 289/367 [00:01<00:00, 138.54it/s]Pre-training Epoch 114:  83%|████████▎ | 303/367 [00:02<00:00, 138.92it/s]Pre-training Epoch 114:  87%|████████▋ | 318/367 [00:02<00:00, 140.70it/s]Pre-training Epoch 114:  91%|█████████ | 333/367 [00:02<00:00, 142.46it/s]Pre-training Epoch 114:  95%|█████████▍| 348/367 [00:02<00:00, 143.48it/s]Pre-training Epoch 114:  99%|█████████▉| 363/367 [00:02<00:00, 142.54it/s]Pre-training Epoch 114: 100%|██████████| 367/367 [00:02<00:00, 147.46it/s]
recon_loss: 0.027248064056038857, dist_loss: 0.5267645120620728
recon_loss: 0.027248192578554153, dist_loss: 0.5865837335586548
recon_loss: 0.0272492878139019, dist_loss: 1.0041218996047974
recon_loss: 0.02725084312260151, dist_loss: 0.6066312789916992
recon_loss: 0.027250375598669052, dist_loss: 0.3616598844528198
recon_loss: 0.02725023590028286, dist_loss: 0.43466049432754517
recon_loss: 0.027249231934547424, dist_loss: 0.6517735123634338
recon_loss: 0.027250170707702637, dist_loss: 0.5191718339920044
recon_loss: 0.027248432859778404, dist_loss: 0.8278723955154419
recon_loss: 0.027249641716480255, dist_loss: 1.0168440341949463
recon_loss: 0.027251163497567177, dist_loss: 0.4062536358833313
recon_loss: 0.02725103311240673, dist_loss: 0.6990819573402405
recon_loss: 0.027253644540905952, dist_loss: 0.46354371309280396
recon_loss: 0.02725307084619999, dist_loss: 0.8320816159248352
recon_loss: 0.027255304157733917, dist_loss: 0.607958197593689
recon_loss: 0.027255650609731674, dist_loss: 0.5199808478355408
recon_loss: 0.027256719768047333, dist_loss: 1.012453317642212
recon_loss: 0.027255764231085777, dist_loss: 0.5015405416488647
recon_loss: 0.027255389839410782, dist_loss: 0.4563581347465515
recon_loss: 0.027253827080130577, dist_loss: 0.6508195400238037
recon_loss: 0.027253737673163414, dist_loss: 0.6425840854644775
recon_loss: 0.027252916246652603, dist_loss: 0.770696222782135
recon_loss: 0.027252161875367165, dist_loss: 0.6416260004043579
recon_loss: 0.027252687141299248, dist_loss: 0.525925874710083
recon_loss: 0.0272520761936903, dist_loss: 0.8802899718284607
recon_loss: 0.02725248970091343, dist_loss: 0.4909203052520752
recon_loss: 0.027252163738012314, dist_loss: 0.5301200747489929
recon_loss: 0.02725272811949253, dist_loss: 0.42314979434013367
recon_loss: 0.027253279462456703, dist_loss: 1.2266452312469482
recon_loss: 0.027253685519099236, dist_loss: 0.5369611382484436
recon_loss: 0.02725435234606266, dist_loss: 0.3941745162010193
recon_loss: 0.027254443615674973, dist_loss: 0.6382013559341431
recon_loss: 0.02725404128432274, dist_loss: 0.8766305446624756
recon_loss: 0.02725321426987648, dist_loss: 0.8134417533874512
recon_loss: 0.027252154424786568, dist_loss: 1.1149812936782837
recon_loss: 0.027251966297626495, dist_loss: 0.9410510659217834
recon_loss: 0.027252135798335075, dist_loss: 0.509660005569458
recon_loss: 0.0272524394094944, dist_loss: 0.6028507947921753
recon_loss: 0.027252253144979477, dist_loss: 0.42414143681526184
recon_loss: 0.027251966297626495, dist_loss: 0.5238466858863831
recon_loss: 0.02725154720246792, dist_loss: 0.6970573663711548
recon_loss: 0.027251554653048515, dist_loss: 0.6784340143203735
recon_loss: 0.0272513460367918, dist_loss: 0.4128473997116089
recon_loss: 0.02725089155137539, dist_loss: 0.4355013966560364
recon_loss: 0.027250852435827255, dist_loss: 0.5385996103286743
recon_loss: 0.027250241488218307, dist_loss: 0.7719637751579285
recon_loss: 0.02724907360970974, dist_loss: 0.4233935475349426
recon_loss: 0.02724769152700901, dist_loss: 0.635623037815094
recon_loss: 0.02724679373204708, dist_loss: 0.757976770401001
recon_loss: 0.027246098965406418, dist_loss: 0.5762351155281067
recon_loss: 0.02724655345082283, dist_loss: 0.7776771187782288
recon_loss: 0.0272462610155344, dist_loss: 0.22412018477916718
recon_loss: 0.02724625915288925, dist_loss: 0.9171183705329895
recon_loss: 0.02724624052643776, dist_loss: 1.1975351572036743
recon_loss: 0.027246050536632538, dist_loss: 0.5860944986343384
recon_loss: 0.02724652923643589, dist_loss: 0.7712475061416626
recon_loss: 0.027246085926890373, dist_loss: 0.45501697063446045
recon_loss: 0.027245987206697464, dist_loss: 0.6624546051025391
recon_loss: 0.027245845645666122, dist_loss: 0.5657181739807129
recon_loss: 0.027245230972766876, dist_loss: 0.6764724254608154
recon_loss: 0.027244698256254196, dist_loss: 0.3441259264945984
recon_loss: 0.027244174852967262, dist_loss: 1.2831844091415405
recon_loss: 0.02724386565387249, dist_loss: 0.6553807258605957
recon_loss: 0.027243683114647865, dist_loss: 0.868148922920227
recon_loss: 0.027243467047810555, dist_loss: 0.4688558876514435
recon_loss: 0.027243483811616898, dist_loss: 0.6100006103515625
recon_loss: 0.027243517339229584, dist_loss: 0.522510826587677
recon_loss: 0.027243368327617645, dist_loss: 0.6477410197257996
recon_loss: 0.027244500815868378, dist_loss: 0.47077274322509766
recon_loss: 0.027244465425610542, dist_loss: 0.4791344106197357
recon_loss: 0.027245664969086647, dist_loss: 1.360119104385376
recon_loss: 0.027245506644248962, dist_loss: 0.647710382938385
recon_loss: 0.02724686823785305, dist_loss: 0.3177158832550049
recon_loss: 0.027246780693531036, dist_loss: 0.5549682378768921
recon_loss: 0.027247484773397446, dist_loss: 0.5374259352684021
recon_loss: 0.027246247977018356, dist_loss: 0.6617809534072876
recon_loss: 0.02724526822566986, dist_loss: 0.5506397485733032
recon_loss: 0.02724538929760456, dist_loss: 0.8771637678146362
recon_loss: 0.0272443238645792, dist_loss: 0.3546082079410553
recon_loss: 0.0272450540214777, dist_loss: 0.9422672986984253
recon_loss: 0.027243781834840775, dist_loss: 0.8536549806594849
recon_loss: 0.027244236320257187, dist_loss: 0.32290351390838623
recon_loss: 0.027243640273809433, dist_loss: 0.7457402944564819
recon_loss: 0.027243519201874733, dist_loss: 0.48491406440734863
recon_loss: 0.027243562042713165, dist_loss: 0.6153192520141602
recon_loss: 0.027242517098784447, dist_loss: 0.7595930099487305
recon_loss: 0.027242392301559448, dist_loss: 0.4316415786743164
recon_loss: 0.027242282405495644, dist_loss: 0.5552842617034912
recon_loss: 0.027242906391620636, dist_loss: 0.5980938673019409
recon_loss: 0.027244020253419876, dist_loss: 0.6254736185073853
recon_loss: 0.027244891971349716, dist_loss: 0.4478296637535095
recon_loss: 0.027246015146374702, dist_loss: 0.4976213574409485
recon_loss: 0.027246078476309776, dist_loss: 0.7543557286262512
recon_loss: 0.027245288714766502, dist_loss: 0.9352574348449707
recon_loss: 0.02724434621632099, dist_loss: 0.8590245246887207
recon_loss: 0.02724362351000309, dist_loss: 1.220588207244873
recon_loss: 0.027243169024586678, dist_loss: 0.5968652963638306
recon_loss: 0.027242297306656837, dist_loss: 0.761311411857605
recon_loss: 0.027241742238402367, dist_loss: 0.6527414917945862
recon_loss: 0.027241649106144905, dist_loss: 0.49246537685394287
recon_loss: 0.027241233736276627, dist_loss: 0.3878823220729828
recon_loss: 0.027240946888923645, dist_loss: 0.8239724636077881
recon_loss: 0.027241138741374016, dist_loss: 0.47100889682769775
recon_loss: 0.02724067121744156, dist_loss: 0.49185070395469666
recon_loss: 0.027240823954343796, dist_loss: 0.49342766404151917
recon_loss: 0.02724064141511917, dist_loss: 0.5936926603317261
recon_loss: 0.027240905910730362, dist_loss: 0.7180063128471375
recon_loss: 0.027240872383117676, dist_loss: 0.6507954597473145
recon_loss: 0.02724100463092327, dist_loss: 0.6194233894348145
recon_loss: 0.027240866795182228, dist_loss: 0.5293464660644531
recon_loss: 0.027241148054599762, dist_loss: 0.4153137803077698
Pre-training Epoch 115:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 115:   4%|▍         | 15/367 [00:00<00:02, 148.04it/s]Pre-training Epoch 115:   8%|▊         | 31/367 [00:00<00:02, 151.68it/s]Pre-training Epoch 115:  13%|█▎        | 47/367 [00:00<00:02, 152.32it/s]Pre-training Epoch 115:  17%|█▋        | 63/367 [00:00<00:02, 150.80it/s]Pre-training Epoch 115:  22%|██▏       | 79/367 [00:00<00:01, 149.98it/s]Pre-training Epoch 115:  26%|██▌       | 95/367 [00:00<00:01, 151.31it/s]Pre-training Epoch 115:  30%|███       | 111/367 [00:00<00:01, 152.27it/s]Pre-training Epoch 115:  35%|███▍      | 127/367 [00:00<00:01, 149.07it/s]recon_loss: 0.027240876108407974, dist_loss: 0.83629310131073
recon_loss: 0.027240874245762825, dist_loss: 0.39577460289001465
recon_loss: 0.027240417897701263, dist_loss: 0.41673868894577026
recon_loss: 0.02724030613899231, dist_loss: 0.6965023875236511
recon_loss: 0.02724006026983261, dist_loss: 0.6736453175544739
recon_loss: 0.027240248396992683, dist_loss: 0.7512176632881165
recon_loss: 0.02723994106054306, dist_loss: 0.8211954832077026
recon_loss: 0.027239760383963585, dist_loss: 0.7044504284858704
recon_loss: 0.027240009978413582, dist_loss: 0.7926729917526245
recon_loss: 0.027240358293056488, dist_loss: 0.8249877095222473
recon_loss: 0.027240362018346786, dist_loss: 0.49912452697753906
recon_loss: 0.02724015712738037, dist_loss: 0.6102602481842041
recon_loss: 0.02724049799144268, dist_loss: 0.47386062145233154
recon_loss: 0.027240851894021034, dist_loss: 0.48829570412635803
recon_loss: 0.027241617441177368, dist_loss: 1.1490938663482666
recon_loss: 0.0272428747266531, dist_loss: 0.5900341272354126
recon_loss: 0.02724405750632286, dist_loss: 0.6055606603622437
recon_loss: 0.027245601639151573, dist_loss: 1.232792854309082
recon_loss: 0.027245448902249336, dist_loss: 1.418637752532959
recon_loss: 0.027245795354247093, dist_loss: 0.9579794406890869
recon_loss: 0.027244804427027702, dist_loss: 0.7718824744224548
recon_loss: 0.027244219556450844, dist_loss: 0.5816439986228943
recon_loss: 0.027243996039032936, dist_loss: 1.106170415878296
recon_loss: 0.027243785560131073, dist_loss: 0.6041864156723022
recon_loss: 0.027243345975875854, dist_loss: 1.0232188701629639
recon_loss: 0.027242640033364296, dist_loss: 0.7975723743438721
recon_loss: 0.02724258229136467, dist_loss: 0.4404212534427643
recon_loss: 0.02724187634885311, dist_loss: 0.921683669090271
recon_loss: 0.027241718024015427, dist_loss: 0.7074562311172485
recon_loss: 0.027241352945566177, dist_loss: 0.5352483987808228
recon_loss: 0.027241341769695282, dist_loss: 0.404725581407547
recon_loss: 0.027241181582212448, dist_loss: 0.45557475090026855
recon_loss: 0.027240997180342674, dist_loss: 0.3065650463104248
recon_loss: 0.027240876108407974, dist_loss: 0.8792320489883423
recon_loss: 0.02724078856408596, dist_loss: 0.5398430228233337
recon_loss: 0.027240658178925514, dist_loss: 0.4254988431930542
recon_loss: 0.027240552008152008, dist_loss: 0.42570674419403076
recon_loss: 0.02724064700305462, dist_loss: 0.9702140092849731
recon_loss: 0.02724078856408596, dist_loss: 0.7912319898605347
recon_loss: 0.027240827679634094, dist_loss: 0.43913835287094116
recon_loss: 0.027240993455052376, dist_loss: 0.47584664821624756
recon_loss: 0.027241162955760956, dist_loss: 0.41338369250297546
recon_loss: 0.027240753173828125, dist_loss: 0.7629833221435547
recon_loss: 0.02724110335111618, dist_loss: 0.8515698909759521
recon_loss: 0.02724115364253521, dist_loss: 0.3362794518470764
recon_loss: 0.027240930125117302, dist_loss: 0.45181989669799805
recon_loss: 0.027240747585892677, dist_loss: 1.1138293743133545
recon_loss: 0.02724081464111805, dist_loss: 0.33588939905166626
recon_loss: 0.02723941020667553, dist_loss: 0.528026819229126
recon_loss: 0.027240321040153503, dist_loss: 0.6191724538803101
recon_loss: 0.027240090072155, dist_loss: 0.7068014144897461
recon_loss: 0.027239380404353142, dist_loss: 0.6207218170166016
recon_loss: 0.02724006399512291, dist_loss: 0.6173014640808105
recon_loss: 0.02723870798945427, dist_loss: 0.5312581062316895
recon_loss: 0.027239536866545677, dist_loss: 0.48354315757751465
recon_loss: 0.02723819948732853, dist_loss: 0.46135812997817993
recon_loss: 0.027238577604293823, dist_loss: 0.6305992603302002
recon_loss: 0.02723829820752144, dist_loss: 0.5049315094947815
recon_loss: 0.027237780392169952, dist_loss: 0.6130542159080505
recon_loss: 0.02723829448223114, dist_loss: 0.9758845567703247
recon_loss: 0.027237743139266968, dist_loss: 0.3476608693599701
recon_loss: 0.02723877504467964, dist_loss: 0.7112008929252625
recon_loss: 0.027238694950938225, dist_loss: 0.5419754981994629
recon_loss: 0.0272388719022274, dist_loss: 0.3864224851131439
recon_loss: 0.027238741517066956, dist_loss: 0.6752212047576904
recon_loss: 0.027238909155130386, dist_loss: 0.7393008470535278
recon_loss: 0.02723846770823002, dist_loss: 0.5293651819229126
recon_loss: 0.027238549664616585, dist_loss: 0.5168823003768921
recon_loss: 0.0272392388433218, dist_loss: 0.4430600702762604
recon_loss: 0.027238475158810616, dist_loss: 0.6068019866943359
recon_loss: 0.02723844349384308, dist_loss: 0.5094401836395264
recon_loss: 0.027237635105848312, dist_loss: 0.9419667720794678
recon_loss: 0.027238158509135246, dist_loss: 0.7012881636619568
recon_loss: 0.02723751775920391, dist_loss: 0.3316965699195862
recon_loss: 0.027238022536039352, dist_loss: 1.0212427377700806
recon_loss: 0.027237549424171448, dist_loss: 0.5703686475753784
recon_loss: 0.0272381529211998, dist_loss: 0.4397071301937103
recon_loss: 0.02723795548081398, dist_loss: 0.8449069261550903
recon_loss: 0.02723819948732853, dist_loss: 0.4801635146141052
recon_loss: 0.027237912639975548, dist_loss: 0.379689484834671
recon_loss: 0.027237966656684875, dist_loss: 0.9931098818778992
recon_loss: 0.027238085865974426, dist_loss: 0.4056139886379242
recon_loss: 0.02723836712539196, dist_loss: 0.6063780784606934
recon_loss: 0.027238065376877785, dist_loss: 0.3991740942001343
recon_loss: 0.027238188311457634, dist_loss: 0.5855134129524231
recon_loss: 0.027237724512815475, dist_loss: 0.7206610441207886
recon_loss: 0.027237575501203537, dist_loss: 0.36891505122184753
recon_loss: 0.027237318456172943, dist_loss: 0.8150709867477417
recon_loss: 0.027236826717853546, dist_loss: 0.8560974597930908
recon_loss: 0.02723666839301586, dist_loss: 0.5169044733047485
recon_loss: 0.027237020432949066, dist_loss: 0.5825905203819275
recon_loss: 0.027237407863140106, dist_loss: 0.44968941807746887
recon_loss: 0.027238216251134872, dist_loss: 0.7216389179229736
recon_loss: 0.027239084243774414, dist_loss: 0.7709637880325317
recon_loss: 0.027240203693509102, dist_loss: 0.6478632688522339
recon_loss: 0.02724127098917961, dist_loss: 1.032185673713684
recon_loss: 0.027242694050073624, dist_loss: 0.3596634864807129
recon_loss: 0.02724366821348667, dist_loss: 1.2522251605987549
recon_loss: 0.02724430523812771, dist_loss: 0.30498820543289185
recon_loss: 0.02724453993141651, dist_loss: 0.7936197519302368
recon_loss: 0.027244387194514275, dist_loss: 1.3398044109344482
recon_loss: 0.02724357135593891, dist_loss: 1.0856516361236572
recon_loss: 0.027243107557296753, dist_loss: 0.6447491645812988
recon_loss: 0.027242453768849373, dist_loss: 0.4282408654689789
recon_loss: 0.027241840958595276, dist_loss: 0.7597074508666992
recon_loss: 0.02724168822169304, dist_loss: 0.7204083204269409
recon_loss: 0.027241118252277374, dist_loss: 0.5096872448921204
recon_loss: 0.027241310104727745, dist_loss: 0.6103270649909973
recon_loss: 0.027241401374340057, dist_loss: 0.36182132363319397
recon_loss: 0.0272417813539505, dist_loss: 0.5430057048797607
recon_loss: 0.027241801843047142, dist_loss: 0.6294658780097961
recon_loss: 0.027241596952080727, dist_loss: 0.7444360256195068
recon_loss: 0.027241462841629982, dist_loss: 0.7217024564743042
recon_loss: 0.027241341769695282, dist_loss: 0.4244009852409363
recon_loss: 0.027241256088018417, dist_loss: 0.5584594011306763
recon_loss: 0.02724117413163185, dist_loss: 0.7453755140304565
recon_loss: 0.027241554111242294, dist_loss: 0.5585201382637024
recon_loss: 0.027241582050919533, dist_loss: 0.42359358072280884
recon_loss: 0.027241840958595276, dist_loss: 0.6407667398452759
recon_loss: 0.027241822332143784, dist_loss: 0.511370837688446
recon_loss: 0.027242617681622505, dist_loss: 0.5001236200332642
recon_loss: 0.027242498472332954, dist_loss: 0.5477929711341858
recon_loss: 0.02724282257258892, dist_loss: 0.6339044570922852
recon_loss: 0.02724289894104004, dist_loss: 0.7505475282669067
recon_loss: 0.02724308893084526, dist_loss: 0.645990252494812
recon_loss: 0.027242867276072502, dist_loss: 0.4245530962944031
recon_loss: 0.027242550626397133, dist_loss: 0.6337350010871887
recon_loss: 0.02724289894104004, dist_loss: 0.5621888637542725
Pre-training Epoch 115:  39%|███▉      | 143/367 [00:00<00:01, 151.47it/s]Pre-training Epoch 115:  43%|████▎     | 159/367 [00:01<00:01, 153.23it/s]Pre-training Epoch 115:  48%|████▊     | 175/367 [00:01<00:01, 154.07it/s]Pre-training Epoch 115:  52%|█████▏    | 191/367 [00:01<00:01, 154.62it/s]Pre-training Epoch 115:  56%|█████▋    | 207/367 [00:01<00:01, 155.23it/s]Pre-training Epoch 115:  61%|██████    | 223/367 [00:01<00:00, 153.46it/s]Pre-training Epoch 115:  65%|██████▌   | 239/367 [00:01<00:00, 153.00it/s]Pre-training Epoch 115:  69%|██████▉   | 255/367 [00:01<00:00, 152.49it/s]recon_loss: 0.027242735028266907, dist_loss: 0.7653188109397888
recon_loss: 0.02724224515259266, dist_loss: 0.9791618585586548
recon_loss: 0.027241699397563934, dist_loss: 0.6824784278869629
recon_loss: 0.02724113129079342, dist_loss: 0.4825337529182434
recon_loss: 0.027240969240665436, dist_loss: 0.4876684248447418
recon_loss: 0.027240626513957977, dist_loss: 0.46061408519744873
recon_loss: 0.02724054642021656, dist_loss: 0.7134279012680054
recon_loss: 0.027240755036473274, dist_loss: 0.5458800196647644
recon_loss: 0.027240030467510223, dist_loss: 0.8047730922698975
recon_loss: 0.02723921276628971, dist_loss: 0.685396671295166
recon_loss: 0.027238715440034866, dist_loss: 0.45197930932044983
recon_loss: 0.027238570153713226, dist_loss: 0.7905123233795166
recon_loss: 0.027238573879003525, dist_loss: 0.7624090909957886
recon_loss: 0.02723895013332367, dist_loss: 0.4253091514110565
recon_loss: 0.027239186689257622, dist_loss: 0.5237452983856201
recon_loss: 0.027239911258220673, dist_loss: 0.37229645252227783
recon_loss: 0.027239657938480377, dist_loss: 0.6723883152008057
recon_loss: 0.027240164577960968, dist_loss: 0.6672515869140625
recon_loss: 0.027239764109253883, dist_loss: 0.7037217617034912
recon_loss: 0.027239013463258743, dist_loss: 0.39269042015075684
recon_loss: 0.02723887376487255, dist_loss: 0.5562162399291992
recon_loss: 0.027238693088293076, dist_loss: 0.5829774141311646
recon_loss: 0.027238337323069572, dist_loss: 0.5369334816932678
recon_loss: 0.027238618582487106, dist_loss: 0.7109206914901733
recon_loss: 0.027238687500357628, dist_loss: 0.5323991775512695
recon_loss: 0.027238763868808746, dist_loss: 1.3778843879699707
recon_loss: 0.027238227427005768, dist_loss: 0.7747483253479004
recon_loss: 0.027237307280302048, dist_loss: 0.40923577547073364
recon_loss: 0.02723751775920391, dist_loss: 0.9656058549880981
recon_loss: 0.02723657339811325, dist_loss: 0.8042030334472656
recon_loss: 0.02723591960966587, dist_loss: 0.5992640256881714
recon_loss: 0.02723550610244274, dist_loss: 0.7119657397270203
recon_loss: 0.027236221358180046, dist_loss: 0.8380445837974548
recon_loss: 0.027235252782702446, dist_loss: 0.9120503067970276
recon_loss: 0.027236072346568108, dist_loss: 0.9889414310455322
recon_loss: 0.02723517455160618, dist_loss: 0.6539309620857239
recon_loss: 0.02723611332476139, dist_loss: 0.4550497531890869
recon_loss: 0.02723495475947857, dist_loss: 0.5794723033905029
recon_loss: 0.02723700739443302, dist_loss: 0.46305033564567566
recon_loss: 0.027234487235546112, dist_loss: 0.5704350471496582
recon_loss: 0.027236085385084152, dist_loss: 0.9381396770477295
recon_loss: 0.027234310284256935, dist_loss: 1.038084864616394
recon_loss: 0.02723662182688713, dist_loss: 0.6580135822296143
recon_loss: 0.027235113084316254, dist_loss: 0.49979710578918457
recon_loss: 0.02723631076514721, dist_loss: 0.5432671308517456
recon_loss: 0.027235491201281548, dist_loss: 0.6430741548538208
recon_loss: 0.0272353682667017, dist_loss: 0.6932204365730286
recon_loss: 0.02723519690334797, dist_loss: 0.7022218108177185
recon_loss: 0.02723456174135208, dist_loss: 0.7024825811386108
recon_loss: 0.027234505861997604, dist_loss: 0.6568577289581299
recon_loss: 0.02723434567451477, dist_loss: 0.4008767604827881
recon_loss: 0.02723536640405655, dist_loss: 0.654735803604126
recon_loss: 0.027233894914388657, dist_loss: 0.4334101974964142
recon_loss: 0.027235588058829308, dist_loss: 1.055778980255127
recon_loss: 0.027233920991420746, dist_loss: 0.38894784450531006
recon_loss: 0.02723604440689087, dist_loss: 0.5238215327262878
recon_loss: 0.027234744280576706, dist_loss: 0.7019367218017578
recon_loss: 0.02723601460456848, dist_loss: 0.8145385384559631
recon_loss: 0.027235927060246468, dist_loss: 0.32476189732551575
recon_loss: 0.02723609283566475, dist_loss: 0.6273401379585266
recon_loss: 0.02723611146211624, dist_loss: 0.9284958839416504
recon_loss: 0.027235446497797966, dist_loss: 0.8155084848403931
recon_loss: 0.02723623998463154, dist_loss: 0.4489707350730896
recon_loss: 0.02723473496735096, dist_loss: 0.8862503170967102
recon_loss: 0.02723567932844162, dist_loss: 0.9264761805534363
recon_loss: 0.027234699577093124, dist_loss: 1.0416860580444336
recon_loss: 0.027236996218562126, dist_loss: 0.5596515536308289
recon_loss: 0.027235236018896103, dist_loss: 0.37728309631347656
recon_loss: 0.0272369422018528, dist_loss: 0.555757462978363
recon_loss: 0.027236931025981903, dist_loss: 0.8755854368209839
recon_loss: 0.027238035574555397, dist_loss: 0.6347627639770508
recon_loss: 0.027238227427005768, dist_loss: 0.5648669004440308
recon_loss: 0.027237936854362488, dist_loss: 0.5925465226173401
recon_loss: 0.027239836752414703, dist_loss: 0.560406506061554
recon_loss: 0.027238180860877037, dist_loss: 0.7175748348236084
recon_loss: 0.027239026501774788, dist_loss: 0.3953087329864502
recon_loss: 0.02723720483481884, dist_loss: 0.46580010652542114
recon_loss: 0.027236731722950935, dist_loss: 0.42253443598747253
recon_loss: 0.02723575569689274, dist_loss: 0.7326865196228027
recon_loss: 0.02723565511405468, dist_loss: 0.7273069620132446
recon_loss: 0.02723633125424385, dist_loss: 0.5427904725074768
recon_loss: 0.02723640948534012, dist_loss: 0.39911848306655884
recon_loss: 0.027236364781856537, dist_loss: 0.6283353567123413
recon_loss: 0.0272370632737875, dist_loss: 0.5375603437423706
recon_loss: 0.02723746933043003, dist_loss: 0.7230190634727478
recon_loss: 0.0272373054176569, dist_loss: 0.875820517539978
recon_loss: 0.027238717302680016, dist_loss: 0.735456645488739
recon_loss: 0.027238184586167336, dist_loss: 1.0296952724456787
recon_loss: 0.02723889797925949, dist_loss: 0.5013411641120911
recon_loss: 0.02723885141313076, dist_loss: 0.44188132882118225
recon_loss: 0.027238447219133377, dist_loss: 0.9174627065658569
recon_loss: 0.02723769284784794, dist_loss: 0.6762574315071106
recon_loss: 0.02723635733127594, dist_loss: 0.2664177417755127
recon_loss: 0.027234893292188644, dist_loss: 0.5446949005126953
recon_loss: 0.027233876287937164, dist_loss: 0.31568413972854614
recon_loss: 0.02723313495516777, dist_loss: 0.2942524552345276
recon_loss: 0.02723291516304016, dist_loss: 0.6726790070533752
recon_loss: 0.027232972905039787, dist_loss: 0.9248397946357727
recon_loss: 0.02723301574587822, dist_loss: 0.4433901607990265
recon_loss: 0.02723340317606926, dist_loss: 0.6718881726264954
recon_loss: 0.027234312146902084, dist_loss: 0.5522685050964355
recon_loss: 0.027235137298703194, dist_loss: 0.8713457584381104
recon_loss: 0.02723611146211624, dist_loss: 0.8666443824768066
recon_loss: 0.02723653055727482, dist_loss: 0.5738863945007324
recon_loss: 0.02723647654056549, dist_loss: 0.9488347768783569
recon_loss: 0.027235563844442368, dist_loss: 0.7525067329406738
recon_loss: 0.027234641835093498, dist_loss: 0.5881215333938599
recon_loss: 0.02723373845219612, dist_loss: 0.7325711250305176
recon_loss: 0.027233276516199112, dist_loss: 0.3149157166481018
recon_loss: 0.027232790365815163, dist_loss: 0.4571155309677124
recon_loss: 0.027232380583882332, dist_loss: 0.5208655595779419
recon_loss: 0.027231993153691292, dist_loss: 0.5779151916503906
recon_loss: 0.02723194658756256, dist_loss: 0.5445176362991333
recon_loss: 0.027231546118855476, dist_loss: 0.38095298409461975
recon_loss: 0.027231058105826378, dist_loss: 0.49340978264808655
recon_loss: 0.02723069116473198, dist_loss: 0.8479148149490356
recon_loss: 0.027230096980929375, dist_loss: 0.41297441720962524
recon_loss: 0.027230020612478256, dist_loss: 0.9239537715911865
recon_loss: 0.027229970321059227, dist_loss: 0.5293312668800354
recon_loss: 0.027229778468608856, dist_loss: 0.6018248796463013
recon_loss: 0.027230117470026016, dist_loss: 0.7857385277748108
recon_loss: 0.027229374274611473, dist_loss: 0.7435606718063354
recon_loss: 0.027229949831962585, dist_loss: 0.5605195760726929
recon_loss: 0.02722991816699505, dist_loss: 0.496001660823822
recon_loss: 0.027229608967900276, dist_loss: 0.594426155090332
recon_loss: 0.02722976543009281, dist_loss: 0.5180295705795288
recon_loss: 0.027230432257056236, dist_loss: 0.5446999073028564
recon_loss: 0.027231404557824135, dist_loss: 0.3004603385925293
Pre-training Epoch 115:  74%|███████▍  | 271/367 [00:01<00:00, 153.67it/s]Pre-training Epoch 115:  78%|███████▊  | 287/367 [00:01<00:00, 151.88it/s]Pre-training Epoch 115:  83%|████████▎ | 303/367 [00:01<00:00, 153.62it/s]Pre-training Epoch 115:  87%|████████▋ | 319/367 [00:02<00:00, 152.79it/s]Pre-training Epoch 115:  91%|█████████▏| 335/367 [00:02<00:00, 151.78it/s]Pre-training Epoch 115:  96%|█████████▌| 351/367 [00:02<00:00, 152.30it/s]Pre-training Epoch 115: 100%|██████████| 367/367 [00:02<00:00, 150.70it/s]Pre-training Epoch 115: 100%|██████████| 367/367 [00:02<00:00, 152.16it/s]
recon_loss: 0.02723151631653309, dist_loss: 0.9578518867492676
recon_loss: 0.027231251820921898, dist_loss: 0.9302937388420105
recon_loss: 0.027230793610215187, dist_loss: 0.49605655670166016
recon_loss: 0.027230963110923767, dist_loss: 1.035973072052002
recon_loss: 0.02723044902086258, dist_loss: 0.6034075021743774
recon_loss: 0.02722996287047863, dist_loss: 0.5618313550949097
recon_loss: 0.02722948044538498, dist_loss: 0.6688413619995117
recon_loss: 0.027229562401771545, dist_loss: 0.7343599796295166
recon_loss: 0.02723008021712303, dist_loss: 0.3591289222240448
recon_loss: 0.027230802923440933, dist_loss: 0.4178224802017212
recon_loss: 0.02723109908401966, dist_loss: 0.4424484372138977
recon_loss: 0.02723236382007599, dist_loss: 0.5559148788452148
recon_loss: 0.02723044715821743, dist_loss: 0.32572323083877563
recon_loss: 0.02723119594156742, dist_loss: 0.5115286111831665
recon_loss: 0.027230139821767807, dist_loss: 0.9281677007675171
recon_loss: 0.027230016887187958, dist_loss: 0.47156038880348206
recon_loss: 0.027229567989706993, dist_loss: 0.5309845209121704
recon_loss: 0.02722887694835663, dist_loss: 0.560064971446991
recon_loss: 0.027230296283960342, dist_loss: 0.48763155937194824
recon_loss: 0.027228929102420807, dist_loss: 0.6805342435836792
recon_loss: 0.027230747044086456, dist_loss: 1.0991663932800293
recon_loss: 0.027230555191636086, dist_loss: 0.8089710474014282
recon_loss: 0.027232857421040535, dist_loss: 0.6540213227272034
recon_loss: 0.027232155203819275, dist_loss: 0.4574745297431946
recon_loss: 0.02723209373652935, dist_loss: 0.6206082105636597
recon_loss: 0.027231231331825256, dist_loss: 0.792431116104126
recon_loss: 0.027231018990278244, dist_loss: 0.7500717639923096
recon_loss: 0.027231642976403236, dist_loss: 0.8900361061096191
recon_loss: 0.027230866253376007, dist_loss: 0.9517897963523865
recon_loss: 0.027232691645622253, dist_loss: 0.4489514231681824
recon_loss: 0.027229340746998787, dist_loss: 0.8931512832641602
recon_loss: 0.02723211608827114, dist_loss: 0.49618643522262573
recon_loss: 0.027230042964220047, dist_loss: 0.6116458177566528
recon_loss: 0.02723199501633644, dist_loss: 0.7979726791381836
recon_loss: 0.02723148837685585, dist_loss: 0.5099897384643555
recon_loss: 0.027231622487306595, dist_loss: 0.6929159760475159
recon_loss: 0.02723255567252636, dist_loss: 0.4449816644191742
recon_loss: 0.02723105251789093, dist_loss: 0.7105863094329834
recon_loss: 0.027231551706790924, dist_loss: 0.6340999603271484
recon_loss: 0.02723032422363758, dist_loss: 0.7497479915618896
recon_loss: 0.027229977771639824, dist_loss: 0.8731807470321655
recon_loss: 0.027228860184550285, dist_loss: 0.8541404008865356
recon_loss: 0.027228616178035736, dist_loss: 0.5642596483230591
recon_loss: 0.027228541672229767, dist_loss: 0.8391388654708862
recon_loss: 0.027229081839323044, dist_loss: 0.5105448365211487
recon_loss: 0.027229895815253258, dist_loss: 0.5340477228164673
recon_loss: 0.027230452746152878, dist_loss: 0.5899192094802856
recon_loss: 0.027229903265833855, dist_loss: 0.47592076659202576
recon_loss: 0.027229977771639824, dist_loss: 0.5640676021575928
recon_loss: 0.027228502556681633, dist_loss: 0.8315519094467163
recon_loss: 0.027228446677327156, dist_loss: 0.46813783049583435
recon_loss: 0.027227992191910744, dist_loss: 0.5233018398284912
recon_loss: 0.027228567749261856, dist_loss: 0.8626395463943481
recon_loss: 0.027228308841586113, dist_loss: 1.148561716079712
recon_loss: 0.027228856459259987, dist_loss: 0.8791002631187439
recon_loss: 0.02722996287047863, dist_loss: 0.40428388118743896
recon_loss: 0.027231398969888687, dist_loss: 0.7021886110305786
recon_loss: 0.027232667431235313, dist_loss: 0.4177982211112976
recon_loss: 0.02723385952413082, dist_loss: 0.40786367654800415
recon_loss: 0.027234451845288277, dist_loss: 0.7492400407791138
recon_loss: 0.027233794331550598, dist_loss: 0.8996925354003906
recon_loss: 0.027232632040977478, dist_loss: 0.7224531173706055
recon_loss: 0.02723190002143383, dist_loss: 0.45920830965042114
recon_loss: 0.027231333777308464, dist_loss: 0.4713147282600403
recon_loss: 0.02723078988492489, dist_loss: 0.41724246740341187
recon_loss: 0.027230143547058105, dist_loss: 0.5831385850906372
recon_loss: 0.027229195460677147, dist_loss: 0.4774136543273926
recon_loss: 0.02722855657339096, dist_loss: 0.6186640858650208
recon_loss: 0.027228284627199173, dist_loss: 0.6775993704795837
recon_loss: 0.02722797356545925, dist_loss: 0.7231224775314331
recon_loss: 0.02722756564617157, dist_loss: 0.5932788848876953
recon_loss: 0.02722739800810814, dist_loss: 1.0862793922424316
recon_loss: 0.02722639963030815, dist_loss: 0.5928356647491455
recon_loss: 0.027226155623793602, dist_loss: 0.6122399568557739
recon_loss: 0.027225486934185028, dist_loss: 0.6177588701248169
recon_loss: 0.027226647362113, dist_loss: 0.4522528052330017
recon_loss: 0.02722589112818241, dist_loss: 0.9455847144126892
recon_loss: 0.02722763828933239, dist_loss: 0.7369780540466309
recon_loss: 0.027227945625782013, dist_loss: 0.6881225109100342
recon_loss: 0.027229705825448036, dist_loss: 0.5630601048469543
recon_loss: 0.02723017893731594, dist_loss: 0.6497136354446411
recon_loss: 0.027230463922023773, dist_loss: 0.9447640180587769
recon_loss: 0.027229946106672287, dist_loss: 0.7241508960723877
recon_loss: 0.027228517457842827, dist_loss: 0.8748173713684082
recon_loss: 0.02722875401377678, dist_loss: 0.5217019319534302
recon_loss: 0.02722809463739395, dist_loss: 0.5136630535125732
recon_loss: 0.027227459475398064, dist_loss: 0.4330662786960602
recon_loss: 0.027226991951465607, dist_loss: 0.792172908782959
recon_loss: 0.027226697653532028, dist_loss: 0.5953676700592041
recon_loss: 0.02722707763314247, dist_loss: 0.5834094285964966
recon_loss: 0.027227161452174187, dist_loss: 0.9433820247650146
recon_loss: 0.027227431535720825, dist_loss: 0.72700035572052
recon_loss: 0.027227256447076797, dist_loss: 0.6968780159950256
recon_loss: 0.02722715586423874, dist_loss: 0.6792513132095337
recon_loss: 0.027226662263274193, dist_loss: 0.57082200050354
recon_loss: 0.02722666785120964, dist_loss: 0.5667175650596619
recon_loss: 0.02722598798573017, dist_loss: 0.6732864379882812
recon_loss: 0.027225632220506668, dist_loss: 0.7489443421363831
recon_loss: 0.027225585654377937, dist_loss: 0.5776233673095703
recon_loss: 0.027225539088249207, dist_loss: 0.5088019967079163
recon_loss: 0.027225559577345848, dist_loss: 0.6464950442314148
recon_loss: 0.02722582221031189, dist_loss: 0.4735943377017975
recon_loss: 0.027226127684116364, dist_loss: 0.6100006103515625
recon_loss: 0.02722584456205368, dist_loss: 0.727677583694458
recon_loss: 0.02722584269940853, dist_loss: 0.6507710814476013
recon_loss: 0.02722625620663166, dist_loss: 0.6003004312515259
recon_loss: 0.027225594967603683, dist_loss: 1.0820194482803345
recon_loss: 0.027225233614444733, dist_loss: 0.4560135006904602
recon_loss: 0.027224620804190636, dist_loss: 0.3981669545173645
recon_loss: 0.02722441963851452, dist_loss: 0.6945818066596985
recon_loss: 0.02722392976284027, dist_loss: 0.7821810245513916
Pre-training Epoch 116:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 116:   4%|▍         | 15/367 [00:00<00:02, 141.32it/s]Pre-training Epoch 116:   8%|▊         | 30/367 [00:00<00:02, 142.04it/s]Pre-training Epoch 116:  13%|█▎        | 46/367 [00:00<00:02, 145.81it/s]Pre-training Epoch 116:  17%|█▋        | 61/367 [00:00<00:02, 145.56it/s]Pre-training Epoch 116:  21%|██        | 76/367 [00:00<00:01, 147.07it/s]Pre-training Epoch 116:  25%|██▌       | 92/367 [00:00<00:01, 149.08it/s]Pre-training Epoch 116:  29%|██▉       | 108/367 [00:00<00:01, 149.34it/s]Pre-training Epoch 116:  34%|███▎      | 123/367 [00:00<00:01, 148.93it/s]recon_loss: 0.027223948389291763, dist_loss: 0.47642409801483154
recon_loss: 0.027223845943808556, dist_loss: 1.2715909481048584
recon_loss: 0.027223879471421242, dist_loss: 0.9961889982223511
recon_loss: 0.027224048972129822, dist_loss: 0.3958541452884674
recon_loss: 0.027224233373999596, dist_loss: 0.5450891852378845
recon_loss: 0.02722434140741825, dist_loss: 0.5869096517562866
recon_loss: 0.027225136756896973, dist_loss: 0.3231571316719055
recon_loss: 0.02722611278295517, dist_loss: 0.49547451734542847
recon_loss: 0.027226993814110756, dist_loss: 0.5888217687606812
recon_loss: 0.02722751535475254, dist_loss: 0.6019459962844849
recon_loss: 0.02722804807126522, dist_loss: 0.7688674926757812
recon_loss: 0.027227850630879402, dist_loss: 0.7801833152770996
recon_loss: 0.027227329090237617, dist_loss: 0.9518749713897705
recon_loss: 0.027226125821471214, dist_loss: 0.6642919182777405
recon_loss: 0.027224931865930557, dist_loss: 0.7431408762931824
recon_loss: 0.027223965153098106, dist_loss: 1.059280514717102
recon_loss: 0.027224192395806313, dist_loss: 0.5638489723205566
recon_loss: 0.02722453698515892, dist_loss: 0.8437593579292297
recon_loss: 0.027226153761148453, dist_loss: 0.418239563703537
recon_loss: 0.027227580547332764, dist_loss: 1.0207903385162354
recon_loss: 0.02723044715821743, dist_loss: 0.3522249162197113
recon_loss: 0.027232766151428223, dist_loss: 0.9196060299873352
recon_loss: 0.02723466046154499, dist_loss: 0.42262738943099976
recon_loss: 0.02723611518740654, dist_loss: 0.6196500658988953
recon_loss: 0.02723609283566475, dist_loss: 0.5311503410339355
recon_loss: 0.02723490074276924, dist_loss: 0.6864410638809204
recon_loss: 0.027232998982071877, dist_loss: 0.5704404711723328
recon_loss: 0.02723075821995735, dist_loss: 0.5146471261978149
recon_loss: 0.02722863480448723, dist_loss: 0.6830300092697144
recon_loss: 0.027226801961660385, dist_loss: 0.571666955947876
recon_loss: 0.02722577191889286, dist_loss: 0.6210464239120483
recon_loss: 0.02722538635134697, dist_loss: 0.5363484621047974
recon_loss: 0.027226410806179047, dist_loss: 0.29831770062446594
recon_loss: 0.027228418737649918, dist_loss: 0.8170708417892456
recon_loss: 0.02723045088350773, dist_loss: 0.37058812379837036
recon_loss: 0.027231764048337936, dist_loss: 0.4976884722709656
recon_loss: 0.027232417836785316, dist_loss: 0.6997395753860474
recon_loss: 0.027232594788074493, dist_loss: 0.6676549911499023
recon_loss: 0.027233535423874855, dist_loss: 0.6748256087303162
recon_loss: 0.027233358472585678, dist_loss: 0.7301881313323975
recon_loss: 0.02723318338394165, dist_loss: 0.5564994812011719
recon_loss: 0.027232924476265907, dist_loss: 0.8265495300292969
recon_loss: 0.027231505140662193, dist_loss: 1.01457679271698
recon_loss: 0.027229981496930122, dist_loss: 0.5299612283706665
recon_loss: 0.027229106053709984, dist_loss: 0.7107968330383301
recon_loss: 0.02722839266061783, dist_loss: 0.4716005325317383
recon_loss: 0.027227753773331642, dist_loss: 0.638084888458252
recon_loss: 0.02722715586423874, dist_loss: 0.4737459123134613
recon_loss: 0.027226975187659264, dist_loss: 0.6063634157180786
recon_loss: 0.027226785197854042, dist_loss: 0.5024045705795288
recon_loss: 0.027226369827985764, dist_loss: 0.6005182266235352
recon_loss: 0.027225784957408905, dist_loss: 0.5954837799072266
recon_loss: 0.02722545526921749, dist_loss: 0.35270076990127563
recon_loss: 0.027225039899349213, dist_loss: 0.6647412180900574
recon_loss: 0.027224551886320114, dist_loss: 0.536992609500885
recon_loss: 0.027223918586969376, dist_loss: 0.3793730139732361
recon_loss: 0.027223490178585052, dist_loss: 0.5979117751121521
recon_loss: 0.02722341939806938, dist_loss: 0.9930123090744019
recon_loss: 0.027223238721489906, dist_loss: 0.497000515460968
recon_loss: 0.0272236205637455, dist_loss: 0.6044130325317383
recon_loss: 0.027223967015743256, dist_loss: 0.9662914276123047
recon_loss: 0.027224205434322357, dist_loss: 0.5325667262077332
recon_loss: 0.027223994955420494, dist_loss: 0.5258835554122925
recon_loss: 0.027223901823163033, dist_loss: 0.5092338919639587
recon_loss: 0.027224021032452583, dist_loss: 0.439954549074173
recon_loss: 0.027223845943808556, dist_loss: 0.41217753291130066
recon_loss: 0.02722335048019886, dist_loss: 0.5584110617637634
recon_loss: 0.02722295932471752, dist_loss: 0.5194804668426514
recon_loss: 0.027222229167819023, dist_loss: 0.9079742431640625
recon_loss: 0.027221549302339554, dist_loss: 1.0034589767456055
recon_loss: 0.027220740914344788, dist_loss: 0.5120205879211426
recon_loss: 0.027219761162996292, dist_loss: 0.7572330832481384
recon_loss: 0.02721977047622204, dist_loss: 0.42431947588920593
recon_loss: 0.02721976861357689, dist_loss: 0.7794166207313538
recon_loss: 0.02722022868692875, dist_loss: 0.6970271468162537
recon_loss: 0.027220655232667923, dist_loss: 0.7435705065727234
recon_loss: 0.027221541851758957, dist_loss: 0.466841459274292
recon_loss: 0.027223337441682816, dist_loss: 0.5540155172348022
recon_loss: 0.027225084602832794, dist_loss: 0.6722975969314575
recon_loss: 0.02722654491662979, dist_loss: 0.696182370185852
recon_loss: 0.027227124199271202, dist_loss: 0.7321499586105347
recon_loss: 0.027227113023400307, dist_loss: 0.443045049905777
recon_loss: 0.027226706966757774, dist_loss: 0.5868070125579834
recon_loss: 0.027225427329540253, dist_loss: 0.20082665979862213
recon_loss: 0.027224505320191383, dist_loss: 0.4860837161540985
recon_loss: 0.027223780751228333, dist_loss: 0.5510976314544678
recon_loss: 0.027223337441682816, dist_loss: 0.6104894876480103
recon_loss: 0.027223000302910805, dist_loss: 1.1936242580413818
recon_loss: 0.027222493663430214, dist_loss: 0.5354717969894409
recon_loss: 0.027223072946071625, dist_loss: 0.6792761087417603
recon_loss: 0.02722318470478058, dist_loss: 0.9558865427970886
recon_loss: 0.027223676443099976, dist_loss: 0.8296071887016296
recon_loss: 0.027223488315939903, dist_loss: 0.773373007774353
recon_loss: 0.027223683893680573, dist_loss: 0.2542373836040497
recon_loss: 0.027223432436585426, dist_loss: 0.7856548428535461
recon_loss: 0.027222145348787308, dist_loss: 0.41717684268951416
recon_loss: 0.02722134441137314, dist_loss: 0.6583378314971924
recon_loss: 0.027220934629440308, dist_loss: 0.5513391494750977
recon_loss: 0.027221741154789925, dist_loss: 0.6890868544578552
recon_loss: 0.02722076140344143, dist_loss: 0.5264476537704468
recon_loss: 0.027220575138926506, dist_loss: 0.4805639386177063
recon_loss: 0.027220651507377625, dist_loss: 0.6368962526321411
recon_loss: 0.027220547199249268, dist_loss: 0.5073630809783936
recon_loss: 0.027220623567700386, dist_loss: 0.5144886374473572
recon_loss: 0.027220340445637703, dist_loss: 0.6012916564941406
recon_loss: 0.027220536023378372, dist_loss: 0.914862334728241
recon_loss: 0.027220526710152626, dist_loss: 0.5665512084960938
recon_loss: 0.027220459654927254, dist_loss: 0.7244059443473816
recon_loss: 0.0272203478962183, dist_loss: 0.43886592984199524
recon_loss: 0.027220219373703003, dist_loss: 0.4087679386138916
recon_loss: 0.027219995856285095, dist_loss: 0.6057093739509583
recon_loss: 0.0272201057523489, dist_loss: 0.7929710149765015
recon_loss: 0.027219749987125397, dist_loss: 0.4862814247608185
recon_loss: 0.02721974439918995, dist_loss: 0.8490008115768433
recon_loss: 0.027219846844673157, dist_loss: 0.6835935711860657
recon_loss: 0.02722025476396084, dist_loss: 1.0212210416793823
recon_loss: 0.0272208284586668, dist_loss: 1.2244644165039062
recon_loss: 0.02722126804292202, dist_loss: 0.5499961376190186
recon_loss: 0.027221953496336937, dist_loss: 0.9039812088012695
recon_loss: 0.027221692726016045, dist_loss: 0.5229734182357788
recon_loss: 0.0272220466285944, dist_loss: 0.6291865110397339
recon_loss: 0.027221601456403732, dist_loss: 0.7647784352302551
recon_loss: 0.027222460135817528, dist_loss: 0.40977758169174194
recon_loss: 0.027221856638789177, dist_loss: 0.9598931074142456
recon_loss: 0.02722300961613655, dist_loss: 0.5977957248687744
recon_loss: 0.027223626151680946, dist_loss: 0.6370372772216797
recon_loss: 0.027223682031035423, dist_loss: 0.4052089750766754
recon_loss: 0.027224915102124214, dist_loss: 1.099841833114624
Pre-training Epoch 116:  38%|███▊      | 138/367 [00:00<00:01, 148.24it/s]Pre-training Epoch 116:  42%|████▏     | 154/367 [00:01<00:01, 149.70it/s]Pre-training Epoch 116:  46%|████▌     | 169/367 [00:01<00:01, 149.38it/s]Pre-training Epoch 116:  50%|█████     | 185/367 [00:01<00:01, 150.17it/s]Pre-training Epoch 116:  55%|█████▍    | 201/367 [00:01<00:01, 150.34it/s]Pre-training Epoch 116:  59%|█████▉    | 217/367 [00:01<00:00, 151.70it/s]Pre-training Epoch 116:  63%|██████▎   | 233/367 [00:01<00:00, 153.76it/s]Pre-training Epoch 116:  68%|██████▊   | 249/367 [00:01<00:00, 153.14it/s]recon_loss: 0.02722516469657421, dist_loss: 0.6668758988380432
recon_loss: 0.02722795680165291, dist_loss: 0.6464929580688477
recon_loss: 0.02723095938563347, dist_loss: 0.5559983253479004
recon_loss: 0.0272320918738842, dist_loss: 0.811098039150238
recon_loss: 0.027232645079493523, dist_loss: 0.5669815540313721
recon_loss: 0.027234233915805817, dist_loss: 0.4854377210140228
recon_loss: 0.027234632521867752, dist_loss: 0.6042039394378662
recon_loss: 0.027234099805355072, dist_loss: 0.9459973573684692
recon_loss: 0.0272328183054924, dist_loss: 0.6786534786224365
recon_loss: 0.027230344712734222, dist_loss: 0.5190821886062622
recon_loss: 0.02722739614546299, dist_loss: 0.7541261315345764
recon_loss: 0.027225010097026825, dist_loss: 0.5184969902038574
recon_loss: 0.02722325176000595, dist_loss: 0.31270745396614075
recon_loss: 0.027222512289881706, dist_loss: 0.8869061470031738
recon_loss: 0.02722199261188507, dist_loss: 1.0196967124938965
recon_loss: 0.02722177468240261, dist_loss: 0.8481279015541077
recon_loss: 0.027222279459238052, dist_loss: 0.6483315229415894
recon_loss: 0.02722247503697872, dist_loss: 0.5363926291465759
recon_loss: 0.027223028242588043, dist_loss: 0.6029418706893921
recon_loss: 0.027223538607358932, dist_loss: 0.5180251002311707
recon_loss: 0.027224453166127205, dist_loss: 1.19428288936615
recon_loss: 0.02722460962831974, dist_loss: 0.7308299541473389
recon_loss: 0.027224520221352577, dist_loss: 0.4028210937976837
recon_loss: 0.027224214747548103, dist_loss: 0.5386500358581543
recon_loss: 0.02722414955496788, dist_loss: 0.7837430238723755
recon_loss: 0.02722303383052349, dist_loss: 0.5343998670578003
recon_loss: 0.027222223579883575, dist_loss: 0.6837908029556274
recon_loss: 0.027221109718084335, dist_loss: 0.9683480262756348
recon_loss: 0.0272208321839571, dist_loss: 0.6634734869003296
recon_loss: 0.027220817282795906, dist_loss: 0.6332406997680664
recon_loss: 0.027221491560339928, dist_loss: 0.7278459072113037
recon_loss: 0.027222765609622, dist_loss: 1.6007170677185059
recon_loss: 0.02722439169883728, dist_loss: 0.4293280243873596
recon_loss: 0.02722720429301262, dist_loss: 0.8547225594520569
recon_loss: 0.02723044343292713, dist_loss: 0.5473027229309082
recon_loss: 0.027232684195041656, dist_loss: 0.7050157785415649
recon_loss: 0.02723171003162861, dist_loss: 0.503931999206543
recon_loss: 0.027231020852923393, dist_loss: 0.6343212127685547
recon_loss: 0.027230115607380867, dist_loss: 0.3489679992198944
recon_loss: 0.027228884398937225, dist_loss: 0.7187556028366089
recon_loss: 0.027228493243455887, dist_loss: 0.6675629019737244
recon_loss: 0.02722698263823986, dist_loss: 0.7738946676254272
recon_loss: 0.02722563035786152, dist_loss: 0.5906754732131958
recon_loss: 0.027224209159612656, dist_loss: 0.9042987823486328
recon_loss: 0.02722291089594364, dist_loss: 0.7214453220367432
recon_loss: 0.027222024276852608, dist_loss: 0.5192071199417114
recon_loss: 0.02722107246518135, dist_loss: 0.541644275188446
recon_loss: 0.027220919728279114, dist_loss: 0.6559092402458191
recon_loss: 0.02722124010324478, dist_loss: 0.4660038650035858
recon_loss: 0.027222568169236183, dist_loss: 0.6093689203262329
recon_loss: 0.027224110439419746, dist_loss: 0.8485754728317261
recon_loss: 0.02722558192908764, dist_loss: 0.44851475954055786
recon_loss: 0.02722603641450405, dist_loss: 0.5868319869041443
recon_loss: 0.027226820588111877, dist_loss: 0.8095602989196777
recon_loss: 0.027228014543652534, dist_loss: 0.5845939517021179
recon_loss: 0.027226697653532028, dist_loss: 0.6362956762313843
recon_loss: 0.02722555585205555, dist_loss: 0.48591744899749756
recon_loss: 0.027224699035286903, dist_loss: 0.6822076439857483
recon_loss: 0.027224071323871613, dist_loss: 0.6783907413482666
recon_loss: 0.027223462238907814, dist_loss: 0.7995373010635376
recon_loss: 0.027223147451877594, dist_loss: 0.6807771325111389
recon_loss: 0.027222124859690666, dist_loss: 0.46855399012565613
recon_loss: 0.027221743017435074, dist_loss: 0.5179101824760437
recon_loss: 0.027221664786338806, dist_loss: 0.6380438208580017
recon_loss: 0.0272208321839571, dist_loss: 0.5444589853286743
recon_loss: 0.02722085639834404, dist_loss: 0.48298871517181396
recon_loss: 0.027220388874411583, dist_loss: 0.5928590297698975
recon_loss: 0.0272195003926754, dist_loss: 0.518774688243866
recon_loss: 0.02721901424229145, dist_loss: 0.4996851682662964
recon_loss: 0.027218399569392204, dist_loss: 0.3733590543270111
recon_loss: 0.02721821889281273, dist_loss: 0.4371701776981354
recon_loss: 0.02721780724823475, dist_loss: 0.6552648544311523
recon_loss: 0.027217978611588478, dist_loss: 0.5178115367889404
recon_loss: 0.027217822149395943, dist_loss: 0.5978308320045471
recon_loss: 0.027218347415328026, dist_loss: 0.6981856822967529
recon_loss: 0.027218099683523178, dist_loss: 0.40344592928886414
recon_loss: 0.027217896655201912, dist_loss: 0.7287193536758423
recon_loss: 0.027217289432883263, dist_loss: 0.5089071989059448
recon_loss: 0.027217306196689606, dist_loss: 1.0538616180419922
recon_loss: 0.027216559275984764, dist_loss: 0.8972762227058411
recon_loss: 0.027216216549277306, dist_loss: 0.47801220417022705
recon_loss: 0.027216454967856407, dist_loss: 0.614350438117981
recon_loss: 0.027216078713536263, dist_loss: 0.6329001188278198
recon_loss: 0.02721644565463066, dist_loss: 0.37188947200775146
recon_loss: 0.027215681970119476, dist_loss: 0.5285466909408569
recon_loss: 0.027216065675020218, dist_loss: 0.6338010430335999
recon_loss: 0.02721528895199299, dist_loss: 0.5767911672592163
recon_loss: 0.027215566486120224, dist_loss: 0.48210442066192627
recon_loss: 0.027215296402573586, dist_loss: 0.7032405138015747
recon_loss: 0.027215028181672096, dist_loss: 0.5911537408828735
recon_loss: 0.027215510606765747, dist_loss: 0.40027284622192383
recon_loss: 0.027215465903282166, dist_loss: 0.6398350596427917
recon_loss: 0.027216285467147827, dist_loss: 0.8030771613121033
recon_loss: 0.027216283604502678, dist_loss: 0.5115567445755005
recon_loss: 0.027216650545597076, dist_loss: 0.6818139553070068
recon_loss: 0.02721717581152916, dist_loss: 0.7154779434204102
recon_loss: 0.027217896655201912, dist_loss: 0.434126615524292
recon_loss: 0.027217593044042587, dist_loss: 1.0943117141723633
recon_loss: 0.02721700444817543, dist_loss: 0.6251177191734314
recon_loss: 0.02721698023378849, dist_loss: 0.5456255674362183
recon_loss: 0.0272150170058012, dist_loss: 0.3970838785171509
recon_loss: 0.02721490152180195, dist_loss: 1.3728293180465698
recon_loss: 0.027214709669351578, dist_loss: 1.0017341375350952
recon_loss: 0.027215849608182907, dist_loss: 0.5935108661651611
recon_loss: 0.02721625752747059, dist_loss: 0.5187087059020996
recon_loss: 0.027216531336307526, dist_loss: 0.7010138630867004
recon_loss: 0.027216283604502678, dist_loss: 0.47071152925491333
recon_loss: 0.027216201648116112, dist_loss: 0.6102003455162048
recon_loss: 0.02721557393670082, dist_loss: 0.6002938747406006
recon_loss: 0.02721545845270157, dist_loss: 0.7203261256217957
recon_loss: 0.027214964851737022, dist_loss: 0.6375705003738403
recon_loss: 0.027214033529162407, dist_loss: 0.43373119831085205
recon_loss: 0.02721356973052025, dist_loss: 0.4866762161254883
recon_loss: 0.027213169261813164, dist_loss: 0.738550066947937
recon_loss: 0.027213335037231445, dist_loss: 1.304223895072937
recon_loss: 0.027213601395487785, dist_loss: 0.5494741201400757
recon_loss: 0.027214044705033302, dist_loss: 0.5449866056442261
recon_loss: 0.02721456252038479, dist_loss: 0.2933209538459778
recon_loss: 0.027214614674448967, dist_loss: 0.4155828356742859
recon_loss: 0.02721497043967247, dist_loss: 0.6044390201568604
recon_loss: 0.02721475623548031, dist_loss: 0.4850499629974365
recon_loss: 0.02721494249999523, dist_loss: 0.3329489231109619
recon_loss: 0.027214499190449715, dist_loss: 0.49277907609939575
recon_loss: 0.02721414901316166, dist_loss: 0.5739020109176636
recon_loss: 0.027213601395487785, dist_loss: 0.9326528310775757
recon_loss: 0.027213245630264282, dist_loss: 0.8800486922264099
recon_loss: 0.02721305564045906, dist_loss: 0.5671659111976624
recon_loss: 0.027212675660848618, dist_loss: 0.691753625869751
Pre-training Epoch 116:  72%|███████▏  | 265/367 [00:01<00:00, 153.32it/s]Pre-training Epoch 116:  77%|███████▋  | 281/367 [00:01<00:00, 151.29it/s]Pre-training Epoch 116:  81%|████████  | 297/367 [00:01<00:00, 150.53it/s]Pre-training Epoch 116:  85%|████████▌ | 313/367 [00:02<00:00, 150.98it/s]Pre-training Epoch 116:  90%|████████▉ | 329/367 [00:02<00:00, 149.42it/s]Pre-training Epoch 116:  94%|█████████▍| 345/367 [00:02<00:00, 150.67it/s]Pre-training Epoch 116:  98%|█████████▊| 361/367 [00:02<00:00, 152.13it/s]Pre-training Epoch 116: 100%|██████████| 367/367 [00:02<00:00, 149.99it/s]
recon_loss: 0.027212439104914665, dist_loss: 0.7796902060508728
recon_loss: 0.02721233479678631, dist_loss: 0.7780112624168396
recon_loss: 0.027212360873818398, dist_loss: 0.7649120688438416
recon_loss: 0.02721233479678631, dist_loss: 0.6466224193572998
recon_loss: 0.02721213735640049, dist_loss: 0.6425695419311523
recon_loss: 0.02721242420375347, dist_loss: 0.5979160070419312
recon_loss: 0.027212046086788177, dist_loss: 0.5276274085044861
recon_loss: 0.02721225842833519, dist_loss: 1.0175936222076416
recon_loss: 0.027212023735046387, dist_loss: 1.2219165563583374
recon_loss: 0.027212155982851982, dist_loss: 1.1405563354492188
recon_loss: 0.02721376344561577, dist_loss: 0.24056583642959595
recon_loss: 0.027214033529162407, dist_loss: 0.6456639766693115
recon_loss: 0.027215998619794846, dist_loss: 1.4536337852478027
recon_loss: 0.027216030284762383, dist_loss: 0.39065998792648315
recon_loss: 0.027217166498303413, dist_loss: 0.7137068510055542
recon_loss: 0.027216704562306404, dist_loss: 0.5693144798278809
recon_loss: 0.027216143906116486, dist_loss: 0.5838176012039185
recon_loss: 0.027216145768761635, dist_loss: 0.7214178442955017
recon_loss: 0.027215125039219856, dist_loss: 1.3422998189926147
recon_loss: 0.02721521072089672, dist_loss: 1.0884170532226562
recon_loss: 0.02721387706696987, dist_loss: 0.7937499284744263
recon_loss: 0.02721560001373291, dist_loss: 0.758405327796936
recon_loss: 0.02721407823264599, dist_loss: 1.25872004032135
recon_loss: 0.027215875685214996, dist_loss: 0.6487430930137634
recon_loss: 0.027215110138058662, dist_loss: 0.859458863735199
recon_loss: 0.027216272428631783, dist_loss: 0.5074447393417358
recon_loss: 0.027217071503400803, dist_loss: 0.4646250605583191
recon_loss: 0.027217604219913483, dist_loss: 0.7813252210617065
recon_loss: 0.027217872440814972, dist_loss: 0.8478838801383972
recon_loss: 0.027217619121074677, dist_loss: 0.8594026565551758
recon_loss: 0.027217470109462738, dist_loss: 0.3623782694339752
recon_loss: 0.027217401191592216, dist_loss: 0.7800112962722778
recon_loss: 0.027217956259846687, dist_loss: 0.8368921279907227
recon_loss: 0.02721669338643551, dist_loss: 0.7571656107902527
recon_loss: 0.0272162314504385, dist_loss: 0.4758003354072571
recon_loss: 0.02721477672457695, dist_loss: 0.764518141746521
recon_loss: 0.027214735746383667, dist_loss: 0.6626906991004944
recon_loss: 0.02721317671239376, dist_loss: 0.7442253232002258
recon_loss: 0.0272132009267807, dist_loss: 0.5828744173049927
recon_loss: 0.02721281163394451, dist_loss: 0.43962791562080383
recon_loss: 0.02721373923122883, dist_loss: 0.44221997261047363
recon_loss: 0.027212874963879585, dist_loss: 0.4795825183391571
recon_loss: 0.027212603017687798, dist_loss: 0.4140926003456116
recon_loss: 0.027212483808398247, dist_loss: 0.36699408292770386
recon_loss: 0.027212802320718765, dist_loss: 0.9908022880554199
recon_loss: 0.027212271466851234, dist_loss: 0.5192310810089111
recon_loss: 0.02721208520233631, dist_loss: 1.0027143955230713
recon_loss: 0.0272113885730505, dist_loss: 0.4527246356010437
recon_loss: 0.02721167914569378, dist_loss: 0.38430774211883545
recon_loss: 0.027211716398596764, dist_loss: 0.6341593265533447
recon_loss: 0.027211323380470276, dist_loss: 0.43239712715148926
recon_loss: 0.027211016044020653, dist_loss: 0.38365837931632996
recon_loss: 0.027211366221308708, dist_loss: 0.4960207939147949
recon_loss: 0.027210529893636703, dist_loss: 0.5937919616699219
recon_loss: 0.02721097320318222, dist_loss: 0.4120703637599945
recon_loss: 0.027210764586925507, dist_loss: 0.7206434011459351
recon_loss: 0.027210310101509094, dist_loss: 0.5955918431282043
recon_loss: 0.02721165493130684, dist_loss: 0.4390232264995575
recon_loss: 0.02721140719950199, dist_loss: 0.5101242661476135
recon_loss: 0.027212120592594147, dist_loss: 0.4127048850059509
recon_loss: 0.027212105691432953, dist_loss: 0.5455925464630127
recon_loss: 0.027212385088205338, dist_loss: 1.2798166275024414
recon_loss: 0.027212364599108696, dist_loss: 0.6892394423484802
recon_loss: 0.02721155248582363, dist_loss: 0.41010475158691406
recon_loss: 0.02721169777214527, dist_loss: 0.32359349727630615
recon_loss: 0.027211157605051994, dist_loss: 0.5340216159820557
recon_loss: 0.027211355045437813, dist_loss: 0.5250054597854614
recon_loss: 0.027210528030991554, dist_loss: 0.4832989573478699
recon_loss: 0.02721080556511879, dist_loss: 0.6333819627761841
recon_loss: 0.027210645377635956, dist_loss: 0.4103085994720459
recon_loss: 0.027211753651499748, dist_loss: 0.3719642758369446
recon_loss: 0.027211572974920273, dist_loss: 0.694340705871582
recon_loss: 0.027211185544729233, dist_loss: 0.7103720903396606
recon_loss: 0.027210796251893044, dist_loss: 0.5921075344085693
recon_loss: 0.027211202308535576, dist_loss: 0.3662267327308655
recon_loss: 0.027211520820856094, dist_loss: 0.48559924960136414
recon_loss: 0.02721136435866356, dist_loss: 0.7559556365013123
recon_loss: 0.02721218392252922, dist_loss: 0.732590913772583
recon_loss: 0.02721363492310047, dist_loss: 1.0790029764175415
recon_loss: 0.027214158326387405, dist_loss: 0.6883525848388672
recon_loss: 0.02721388079226017, dist_loss: 0.8430345058441162
recon_loss: 0.027213938534259796, dist_loss: 0.4531024098396301
recon_loss: 0.027213335037231445, dist_loss: 0.7184250354766846
recon_loss: 0.027213066816329956, dist_loss: 0.5887385606765747
recon_loss: 0.027212150394916534, dist_loss: 0.34843742847442627
recon_loss: 0.027211394160985947, dist_loss: 0.7955220937728882
recon_loss: 0.02721145935356617, dist_loss: 0.9846854209899902
recon_loss: 0.02721097692847252, dist_loss: 0.8331683874130249
recon_loss: 0.027211599051952362, dist_loss: 0.7438116669654846
recon_loss: 0.027209710329771042, dist_loss: 0.8225241303443909
recon_loss: 0.02721068449318409, dist_loss: 0.8374553322792053
recon_loss: 0.027209816500544548, dist_loss: 0.5700603723526001
recon_loss: 0.02721143141388893, dist_loss: 0.889701247215271
recon_loss: 0.027210962027311325, dist_loss: 0.2785583436489105
recon_loss: 0.02721128799021244, dist_loss: 0.30618369579315186
recon_loss: 0.0272112637758255, dist_loss: 0.6250232458114624
recon_loss: 0.027210528030991554, dist_loss: 0.8129795789718628
recon_loss: 0.027210617437958717, dist_loss: 0.48607727885246277
recon_loss: 0.027210203930735588, dist_loss: 0.4615749716758728
recon_loss: 0.02721036598086357, dist_loss: 0.44724714756011963
recon_loss: 0.027210082858800888, dist_loss: 0.8279774188995361
recon_loss: 0.027209963649511337, dist_loss: 0.507760226726532
recon_loss: 0.027209162712097168, dist_loss: 0.5760672092437744
recon_loss: 0.027208665385842323, dist_loss: 0.6473580598831177
recon_loss: 0.027208199724555016, dist_loss: 1.0608487129211426
recon_loss: 0.02720782347023487, dist_loss: 0.41340553760528564
recon_loss: 0.027207612991333008, dist_loss: 0.3616318106651306
recon_loss: 0.027207495644688606, dist_loss: 0.311892032623291
recon_loss: 0.027207624167203903, dist_loss: 0.754706621170044
recon_loss: 0.027207760140299797, dist_loss: 0.61033695936203
recon_loss: 0.02720845863223076, dist_loss: 0.346236914396286
Pre-training Epoch 117:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 117:   4%|▍         | 16/367 [00:00<00:02, 155.38it/s]Pre-training Epoch 117:   9%|▊         | 32/367 [00:00<00:02, 152.71it/s]Pre-training Epoch 117:  13%|█▎        | 48/367 [00:00<00:02, 150.57it/s]Pre-training Epoch 117:  17%|█▋        | 64/367 [00:00<00:02, 149.76it/s]Pre-training Epoch 117:  22%|██▏       | 79/367 [00:00<00:01, 149.40it/s]Pre-training Epoch 117:  26%|██▌       | 95/367 [00:00<00:01, 149.84it/s]Pre-training Epoch 117:  30%|███       | 111/367 [00:00<00:01, 149.54it/s]Pre-training Epoch 117:  34%|███▍      | 126/367 [00:00<00:01, 147.02it/s]recon_loss: 0.027210744097828865, dist_loss: 0.688380777835846
recon_loss: 0.02721027471125126, dist_loss: 0.5390890836715698
recon_loss: 0.02721172198653221, dist_loss: 0.540140688419342
recon_loss: 0.027211379259824753, dist_loss: 0.4648652672767639
recon_loss: 0.02721256949007511, dist_loss: 0.5337522029876709
recon_loss: 0.02721160277724266, dist_loss: 0.7429769039154053
recon_loss: 0.027211347594857216, dist_loss: 0.7774746417999268
recon_loss: 0.027211323380470276, dist_loss: 1.001490831375122
recon_loss: 0.02721012942492962, dist_loss: 0.7366028428077698
recon_loss: 0.027209604158997536, dist_loss: 0.38736414909362793
recon_loss: 0.027209319174289703, dist_loss: 0.8003607988357544
recon_loss: 0.027209313586354256, dist_loss: 0.5781917572021484
recon_loss: 0.027209768071770668, dist_loss: 0.351951003074646
recon_loss: 0.02721068076789379, dist_loss: 0.42273521423339844
recon_loss: 0.0272116269916296, dist_loss: 0.6057607531547546
recon_loss: 0.02721233479678631, dist_loss: 0.725265622138977
recon_loss: 0.027213536202907562, dist_loss: 0.7752257585525513
recon_loss: 0.027214540168642998, dist_loss: 0.5016580820083618
recon_loss: 0.027214014902710915, dist_loss: 0.9137151837348938
recon_loss: 0.02721347287297249, dist_loss: 0.9923643469810486
recon_loss: 0.027212606742978096, dist_loss: 0.5585101842880249
recon_loss: 0.027211520820856094, dist_loss: 0.41819703578948975
recon_loss: 0.027210768312215805, dist_loss: 0.9511064291000366
recon_loss: 0.027210058644413948, dist_loss: 0.7083569765090942
recon_loss: 0.027210041880607605, dist_loss: 0.6718965172767639
recon_loss: 0.027210313826799393, dist_loss: 0.8051427602767944
recon_loss: 0.027211951091885567, dist_loss: 0.39620035886764526
recon_loss: 0.02721414528787136, dist_loss: 0.814612090587616
recon_loss: 0.02721591852605343, dist_loss: 0.8990857005119324
recon_loss: 0.02721756510436535, dist_loss: 0.6892570853233337
recon_loss: 0.027218185365200043, dist_loss: 0.38734063506126404
recon_loss: 0.027219494804739952, dist_loss: 0.8046643733978271
recon_loss: 0.02721981331706047, dist_loss: 0.6581765413284302
recon_loss: 0.0272193755954504, dist_loss: 1.0730359554290771
recon_loss: 0.027219196781516075, dist_loss: 0.6214002966880798
recon_loss: 0.027217643335461617, dist_loss: 0.7883106470108032
recon_loss: 0.027216101065278053, dist_loss: 0.5244492292404175
recon_loss: 0.027214599773287773, dist_loss: 0.8855674862861633
recon_loss: 0.027213813737034798, dist_loss: 0.5989959239959717
recon_loss: 0.027213450521230698, dist_loss: 0.704170823097229
recon_loss: 0.02721293829381466, dist_loss: 0.5206146240234375
recon_loss: 0.027212535962462425, dist_loss: 0.569710373878479
recon_loss: 0.027212101966142654, dist_loss: 0.37597525119781494
recon_loss: 0.027212271466851234, dist_loss: 0.7214150428771973
recon_loss: 0.027211692184209824, dist_loss: 0.5028426647186279
recon_loss: 0.027212072163820267, dist_loss: 0.9178504943847656
recon_loss: 0.02721157856285572, dist_loss: 0.5015873312950134
recon_loss: 0.027211667969822884, dist_loss: 0.8975832462310791
recon_loss: 0.02721230685710907, dist_loss: 0.7523843050003052
recon_loss: 0.027211865410208702, dist_loss: 0.5242006182670593
recon_loss: 0.02721192128956318, dist_loss: 1.1255173683166504
recon_loss: 0.027212176471948624, dist_loss: 0.6650572419166565
recon_loss: 0.027212388813495636, dist_loss: 0.7327760457992554
recon_loss: 0.027211923152208328, dist_loss: 0.48471009731292725
recon_loss: 0.02721361070871353, dist_loss: 0.6907891035079956
recon_loss: 0.027214229106903076, dist_loss: 0.5741448402404785
recon_loss: 0.02721509151160717, dist_loss: 0.5388588905334473
recon_loss: 0.027213994413614273, dist_loss: 0.6166796684265137
recon_loss: 0.027212029322981834, dist_loss: 0.4877367913722992
recon_loss: 0.02721145749092102, dist_loss: 0.719834566116333
recon_loss: 0.027210477739572525, dist_loss: 0.8721268177032471
recon_loss: 0.027211662381887436, dist_loss: 0.4151850938796997
recon_loss: 0.02721036598086357, dist_loss: 0.6214492321014404
recon_loss: 0.027211513370275497, dist_loss: 0.7232038378715515
recon_loss: 0.027210397645831108, dist_loss: 0.5945116281509399
recon_loss: 0.027212226763367653, dist_loss: 0.4599286913871765
recon_loss: 0.027212437242269516, dist_loss: 0.42701995372772217
recon_loss: 0.027214763686060905, dist_loss: 0.46209031343460083
recon_loss: 0.02721627801656723, dist_loss: 0.3745548725128174
recon_loss: 0.027216466143727303, dist_loss: 0.7329785823822021
recon_loss: 0.027215631678700447, dist_loss: 0.5499540567398071
recon_loss: 0.02721509151160717, dist_loss: 0.5198277831077576
recon_loss: 0.027213936671614647, dist_loss: 0.4552963972091675
recon_loss: 0.02721349522471428, dist_loss: 0.5187514424324036
recon_loss: 0.02721291407942772, dist_loss: 0.6847745180130005
recon_loss: 0.027212167158722878, dist_loss: 0.6668626070022583
recon_loss: 0.02721252106130123, dist_loss: 0.9218524694442749
recon_loss: 0.027211537584662437, dist_loss: 0.6147034168243408
recon_loss: 0.027211753651499748, dist_loss: 0.8669491410255432
recon_loss: 0.027210881933569908, dist_loss: 0.9817830324172974
recon_loss: 0.02721143141388893, dist_loss: 0.3647404909133911
recon_loss: 0.027210243046283722, dist_loss: 0.7678893804550171
recon_loss: 0.027210401371121407, dist_loss: 0.6160281896591187
recon_loss: 0.027209339663386345, dist_loss: 0.7487178444862366
recon_loss: 0.027207903563976288, dist_loss: 0.7495548725128174
recon_loss: 0.02720756083726883, dist_loss: 1.0867712497711182
recon_loss: 0.02720707096159458, dist_loss: 0.6472153067588806
recon_loss: 0.027207357808947563, dist_loss: 0.9458749294281006
recon_loss: 0.027208013460040092, dist_loss: 0.6236447691917419
recon_loss: 0.027208629995584488, dist_loss: 1.0697972774505615
recon_loss: 0.027208473533391953, dist_loss: 0.6188582181930542
recon_loss: 0.027207685634493828, dist_loss: 0.7299025058746338
recon_loss: 0.02720649167895317, dist_loss: 0.9788995385169983
recon_loss: 0.027205688878893852, dist_loss: 0.9682891368865967
recon_loss: 0.02720555290579796, dist_loss: 0.9219852685928345
recon_loss: 0.027206063270568848, dist_loss: 0.489126056432724
recon_loss: 0.027205608785152435, dist_loss: 0.4941502809524536
recon_loss: 0.02720595709979534, dist_loss: 0.6872152090072632
recon_loss: 0.027205605059862137, dist_loss: 0.38612985610961914
recon_loss: 0.027205606922507286, dist_loss: 0.5208936333656311
recon_loss: 0.02720540389418602, dist_loss: 0.7435674667358398
recon_loss: 0.027205081656575203, dist_loss: 1.068894386291504
recon_loss: 0.027204900979995728, dist_loss: 0.6259570717811584
recon_loss: 0.027204174548387527, dist_loss: 0.8541874885559082
recon_loss: 0.027203841134905815, dist_loss: 0.5070490837097168
recon_loss: 0.027203744277358055, dist_loss: 0.5083462595939636
recon_loss: 0.02720421925187111, dist_loss: 0.7188906669616699
recon_loss: 0.027205465361475945, dist_loss: 1.2039721012115479
recon_loss: 0.02720797434449196, dist_loss: 0.35117897391319275
recon_loss: 0.027210203930735588, dist_loss: 0.731462836265564
recon_loss: 0.027210643514990807, dist_loss: 0.646340012550354
recon_loss: 0.027210170403122902, dist_loss: 1.1693700551986694
recon_loss: 0.0272101778537035, dist_loss: 0.5078293085098267
recon_loss: 0.027208490297198296, dist_loss: 0.3887070119380951
recon_loss: 0.027207031846046448, dist_loss: 0.6562199592590332
recon_loss: 0.02720550447702408, dist_loss: 0.6444249153137207
recon_loss: 0.02720428630709648, dist_loss: 0.7408696413040161
recon_loss: 0.02720366232097149, dist_loss: 0.5436908006668091
recon_loss: 0.0272042378783226, dist_loss: 0.7941396236419678
recon_loss: 0.02720663696527481, dist_loss: 0.410231351852417
recon_loss: 0.027209250256419182, dist_loss: 0.3842090666294098
recon_loss: 0.0272125992923975, dist_loss: 0.6704598665237427
recon_loss: 0.027213802561163902, dist_loss: 0.6441731452941895
recon_loss: 0.027216101065278053, dist_loss: 0.9402564764022827
recon_loss: 0.02721562795341015, dist_loss: 0.41334885358810425
recon_loss: 0.027215201407670975, dist_loss: 0.7917594909667969
recon_loss: 0.027212854474782944, dist_loss: 0.7309025526046753
recon_loss: 0.027211982756853104, dist_loss: 0.6168394088745117
Pre-training Epoch 117:  38%|███▊      | 141/367 [00:00<00:01, 145.98it/s]Pre-training Epoch 117:  43%|████▎     | 159/367 [00:01<00:01, 155.52it/s]Pre-training Epoch 117:  48%|████▊     | 176/367 [00:01<00:01, 159.36it/s]Pre-training Epoch 117:  53%|█████▎    | 194/367 [00:01<00:01, 164.58it/s]Pre-training Epoch 117:  58%|█████▊    | 213/367 [00:01<00:00, 169.68it/s]Pre-training Epoch 117:  63%|██████▎   | 232/367 [00:01<00:00, 172.91it/s]Pre-training Epoch 117:  68%|██████▊   | 250/367 [00:01<00:00, 174.33it/s]recon_loss: 0.027210010215640068, dist_loss: 0.669831395149231
recon_loss: 0.02720893733203411, dist_loss: 0.9323060512542725
recon_loss: 0.02720724791288376, dist_loss: 0.45376837253570557
recon_loss: 0.027206046506762505, dist_loss: 0.8377667665481567
recon_loss: 0.02720567397773266, dist_loss: 0.6292754411697388
recon_loss: 0.027205606922507286, dist_loss: 0.5827609300613403
recon_loss: 0.02720567025244236, dist_loss: 0.402682363986969
recon_loss: 0.027205660939216614, dist_loss: 0.6906376481056213
recon_loss: 0.027206119149923325, dist_loss: 0.5191421508789062
recon_loss: 0.027205713093280792, dist_loss: 0.8500940799713135
recon_loss: 0.02720620110630989, dist_loss: 0.4454132914543152
recon_loss: 0.027205511927604675, dist_loss: 0.8603121638298035
recon_loss: 0.027206195518374443, dist_loss: 0.43309587240219116
recon_loss: 0.027205200865864754, dist_loss: 0.6206313371658325
recon_loss: 0.02720547653734684, dist_loss: 1.506284236907959
recon_loss: 0.027206100523471832, dist_loss: 0.49537375569343567
recon_loss: 0.027206409722566605, dist_loss: 1.23225998878479
recon_loss: 0.02720639295876026, dist_loss: 0.46781665086746216
recon_loss: 0.027204478159546852, dist_loss: 0.6415059566497803
recon_loss: 0.027203405275940895, dist_loss: 0.7744475603103638
recon_loss: 0.027202848345041275, dist_loss: 0.6754176616668701
recon_loss: 0.027203518897294998, dist_loss: 0.5387813448905945
recon_loss: 0.027204480022192, dist_loss: 0.6348844170570374
recon_loss: 0.027205632999539375, dist_loss: 0.8380569815635681
recon_loss: 0.027206575497984886, dist_loss: 0.7087498903274536
recon_loss: 0.027205973863601685, dist_loss: 0.5735186338424683
recon_loss: 0.02720530703663826, dist_loss: 0.7037492990493774
recon_loss: 0.02720441110432148, dist_loss: 0.8385106325149536
recon_loss: 0.02720382809638977, dist_loss: 0.29042574763298035
recon_loss: 0.02720404975116253, dist_loss: 0.673460841178894
recon_loss: 0.027206076309084892, dist_loss: 0.5691061019897461
recon_loss: 0.027209075167775154, dist_loss: 0.620682418346405
recon_loss: 0.027212202548980713, dist_loss: 0.5480847954750061
recon_loss: 0.027214882895350456, dist_loss: 0.5151505470275879
recon_loss: 0.027215544134378433, dist_loss: 1.048611044883728
recon_loss: 0.027216579765081406, dist_loss: 0.5980738401412964
recon_loss: 0.02721550129354, dist_loss: 0.4772323966026306
recon_loss: 0.027214394882321358, dist_loss: 0.30514365434646606
recon_loss: 0.02721293456852436, dist_loss: 0.49244874715805054
recon_loss: 0.027211932465434074, dist_loss: 0.5482159852981567
recon_loss: 0.027210509404540062, dist_loss: 0.5307135581970215
recon_loss: 0.027208570390939713, dist_loss: 0.5101356506347656
recon_loss: 0.027206506580114365, dist_loss: 0.8975973725318909
recon_loss: 0.027204805985093117, dist_loss: 0.6676425933837891
recon_loss: 0.027203436940908432, dist_loss: 0.5176167488098145
recon_loss: 0.027202807366847992, dist_loss: 0.4264081120491028
recon_loss: 0.02720283716917038, dist_loss: 0.6429357528686523
recon_loss: 0.02720385231077671, dist_loss: 0.5921713709831238
recon_loss: 0.027206068858504295, dist_loss: 0.44220322370529175
recon_loss: 0.027208033949136734, dist_loss: 0.7566397786140442
recon_loss: 0.02721133641898632, dist_loss: 0.4997454881668091
recon_loss: 0.027215078473091125, dist_loss: 0.5732666254043579
recon_loss: 0.027219856157898903, dist_loss: 0.5329974889755249
recon_loss: 0.02722161076962948, dist_loss: 0.6766021251678467
recon_loss: 0.027223585173487663, dist_loss: 0.5691789388656616
recon_loss: 0.027222955599427223, dist_loss: 0.8187700510025024
recon_loss: 0.027220306918025017, dist_loss: 0.5347065925598145
recon_loss: 0.027216492220759392, dist_loss: 0.6402669548988342
recon_loss: 0.027212677523493767, dist_loss: 0.5315006971359253
recon_loss: 0.027210773900151253, dist_loss: 0.4000453054904938
recon_loss: 0.027209926396608353, dist_loss: 0.5086457133293152
recon_loss: 0.02721000276505947, dist_loss: 0.8436542749404907
recon_loss: 0.027209989726543427, dist_loss: 0.6018045544624329
recon_loss: 0.02720976248383522, dist_loss: 0.7552103996276855
recon_loss: 0.027209559455513954, dist_loss: 0.7978177070617676
recon_loss: 0.027209511026740074, dist_loss: 0.9148287773132324
recon_loss: 0.027210596948862076, dist_loss: 0.7458319664001465
recon_loss: 0.027210930362343788, dist_loss: 0.46192237734794617
recon_loss: 0.027211040258407593, dist_loss: 0.48723894357681274
recon_loss: 0.027210498228669167, dist_loss: 0.6234182119369507
recon_loss: 0.027209646999835968, dist_loss: 0.6144286394119263
recon_loss: 0.027208726853132248, dist_loss: 1.1412492990493774
recon_loss: 0.02720753103494644, dist_loss: 0.9159749746322632
recon_loss: 0.02720705047249794, dist_loss: 0.8448476791381836
recon_loss: 0.02720709517598152, dist_loss: 0.9442185163497925
recon_loss: 0.027206439524888992, dist_loss: 0.4508683681488037
recon_loss: 0.027206100523471832, dist_loss: 0.7510954141616821
recon_loss: 0.027205072343349457, dist_loss: 0.36328795552253723
recon_loss: 0.02720443159341812, dist_loss: 0.6707257032394409
recon_loss: 0.027204526588320732, dist_loss: 0.6835787296295166
recon_loss: 0.027203574776649475, dist_loss: 1.3002171516418457
recon_loss: 0.02720363810658455, dist_loss: 0.22555480897426605
recon_loss: 0.02720274031162262, dist_loss: 0.748592734336853
recon_loss: 0.027202216908335686, dist_loss: 0.631818950176239
recon_loss: 0.027201997116208076, dist_loss: 0.705459475517273
recon_loss: 0.02720084972679615, dist_loss: 0.7810243964195251
recon_loss: 0.027200283482670784, dist_loss: 0.5976544618606567
recon_loss: 0.027200130745768547, dist_loss: 0.9451384544372559
recon_loss: 0.02720043808221817, dist_loss: 0.5932037830352783
recon_loss: 0.02720060385763645, dist_loss: 0.30527788400650024
recon_loss: 0.02720045857131481, dist_loss: 0.4854815900325775
recon_loss: 0.02720019407570362, dist_loss: 0.7818681001663208
recon_loss: 0.027200480923056602, dist_loss: 0.7089424729347229
recon_loss: 0.02720026858150959, dist_loss: 0.39695650339126587
recon_loss: 0.02719995379447937, dist_loss: 0.5673911571502686
recon_loss: 0.027200158685445786, dist_loss: 0.20601774752140045
recon_loss: 0.02719971165060997, dist_loss: 0.5044011473655701
recon_loss: 0.027199774980545044, dist_loss: 0.5257408618927002
recon_loss: 0.027199650183320045, dist_loss: 0.47190359234809875
recon_loss: 0.027199579402804375, dist_loss: 0.5688601732254028
recon_loss: 0.027199527248740196, dist_loss: 0.7998864650726318
recon_loss: 0.02719993330538273, dist_loss: 0.6739364862442017
recon_loss: 0.027200698852539062, dist_loss: 0.42394500970840454
recon_loss: 0.02720133401453495, dist_loss: 0.3037513494491577
recon_loss: 0.027202151715755463, dist_loss: 0.5446182489395142
recon_loss: 0.02720019966363907, dist_loss: 0.3199043273925781
recon_loss: 0.02719937451183796, dist_loss: 0.31940436363220215
recon_loss: 0.02719879522919655, dist_loss: 0.6908799409866333
recon_loss: 0.027198754251003265, dist_loss: 0.7056883573532104
recon_loss: 0.02719908021390438, dist_loss: 0.7839181423187256
recon_loss: 0.027199937030673027, dist_loss: 0.3992578983306885
recon_loss: 0.027200847864151, dist_loss: 0.7360392808914185
recon_loss: 0.0271998830139637, dist_loss: 0.5537163019180298
recon_loss: 0.027200480923056602, dist_loss: 0.5488707423210144
recon_loss: 0.02719964273273945, dist_loss: 0.4219714403152466
recon_loss: 0.027200035750865936, dist_loss: 0.9140669107437134
recon_loss: 0.027199288830161095, dist_loss: 0.7102140188217163
recon_loss: 0.027199340984225273, dist_loss: 0.7766499519348145
recon_loss: 0.027198761701583862, dist_loss: 0.904020369052887
recon_loss: 0.027199607342481613, dist_loss: 0.6536344885826111
recon_loss: 0.027199069038033485, dist_loss: 0.6323890089988708
recon_loss: 0.027199605479836464, dist_loss: 0.6390111446380615
recon_loss: 0.027199700474739075, dist_loss: 0.7519702911376953
recon_loss: 0.02719990536570549, dist_loss: 0.8526216149330139
recon_loss: 0.027200380340218544, dist_loss: 0.7731285095214844
recon_loss: 0.027200056239962578, dist_loss: 0.43545931577682495
recon_loss: 0.027200371026992798, dist_loss: 0.6499972343444824
recon_loss: 0.02720043808221817, dist_loss: 0.561321496963501
Pre-training Epoch 117:  73%|███████▎  | 269/367 [00:01<00:00, 176.41it/s]Pre-training Epoch 117:  78%|███████▊  | 287/367 [00:01<00:00, 175.14it/s]Pre-training Epoch 117:  83%|████████▎ | 305/367 [00:01<00:00, 171.61it/s]Pre-training Epoch 117:  88%|████████▊ | 323/367 [00:02<00:00, 164.11it/s]Pre-training Epoch 117:  93%|█████████▎| 340/367 [00:02<00:00, 160.12it/s]Pre-training Epoch 117:  98%|█████████▊| 358/367 [00:02<00:00, 165.06it/s]Pre-training Epoch 117: 100%|██████████| 367/367 [00:02<00:00, 161.60it/s]
recon_loss: 0.027199896052479744, dist_loss: 0.39283615350723267
recon_loss: 0.02719876728951931, dist_loss: 0.45416826009750366
recon_loss: 0.02719852887094021, dist_loss: 0.41857022047042847
recon_loss: 0.02719821222126484, dist_loss: 0.7576253414154053
recon_loss: 0.02719821035861969, dist_loss: 0.5143102407455444
recon_loss: 0.02719779498875141, dist_loss: 0.41229891777038574
recon_loss: 0.027197372168302536, dist_loss: 0.29823189973831177
recon_loss: 0.027197668328881264, dist_loss: 0.8853286504745483
recon_loss: 0.027197906747460365, dist_loss: 0.9197266101837158
recon_loss: 0.027197957038879395, dist_loss: 0.7498340606689453
recon_loss: 0.02719837799668312, dist_loss: 0.6332809925079346
recon_loss: 0.02719784714281559, dist_loss: 0.3783719539642334
recon_loss: 0.02719789557158947, dist_loss: 0.8514863848686218
recon_loss: 0.02719748392701149, dist_loss: 0.4323950707912445
recon_loss: 0.027197422459721565, dist_loss: 0.6689779758453369
recon_loss: 0.02719692699611187, dist_loss: 0.3733054995536804
recon_loss: 0.02719690650701523, dist_loss: 0.9628193974494934
recon_loss: 0.027196433395147324, dist_loss: 0.7361422777175903
recon_loss: 0.02719677798449993, dist_loss: 0.5819249153137207
recon_loss: 0.02719719335436821, dist_loss: 0.48165029287338257
recon_loss: 0.027200348675251007, dist_loss: 0.9881447553634644
recon_loss: 0.027204325422644615, dist_loss: 0.6364233493804932
recon_loss: 0.027209393680095673, dist_loss: 0.47141706943511963
recon_loss: 0.027213728055357933, dist_loss: 0.6356440782546997
recon_loss: 0.027216488495469093, dist_loss: 0.30935007333755493
recon_loss: 0.027219869196414948, dist_loss: 0.6282284259796143
recon_loss: 0.027222467586398125, dist_loss: 0.5298014283180237
recon_loss: 0.027223117649555206, dist_loss: 0.5538713335990906
recon_loss: 0.027222026139497757, dist_loss: 0.4248844087123871
recon_loss: 0.02721969597041607, dist_loss: 0.5871376991271973
recon_loss: 0.027217449620366096, dist_loss: 0.6977708339691162
recon_loss: 0.02721465192735195, dist_loss: 0.6263874173164368
recon_loss: 0.027211450040340424, dist_loss: 0.49144095182418823
recon_loss: 0.027208833023905754, dist_loss: 0.7550389170646667
recon_loss: 0.027206964790821075, dist_loss: 0.5857688784599304
recon_loss: 0.027206135913729668, dist_loss: 0.34914788603782654
recon_loss: 0.027205973863601685, dist_loss: 0.5929129123687744
recon_loss: 0.027206897735595703, dist_loss: 0.6679390668869019
recon_loss: 0.027207626029849052, dist_loss: 0.6728971004486084
recon_loss: 0.02720869891345501, dist_loss: 0.7396120429039001
recon_loss: 0.02721027471125126, dist_loss: 0.4461875557899475
recon_loss: 0.027210839092731476, dist_loss: 0.46775391697883606
recon_loss: 0.027211008593440056, dist_loss: 0.7822461128234863
recon_loss: 0.027212027460336685, dist_loss: 0.4436665177345276
recon_loss: 0.027213426306843758, dist_loss: 1.0798392295837402
recon_loss: 0.02721388451755047, dist_loss: 0.47815486788749695
recon_loss: 0.02721438556909561, dist_loss: 0.31447261571884155
recon_loss: 0.027215657755732536, dist_loss: 0.5438748598098755
recon_loss: 0.027215147390961647, dist_loss: 0.43715158104896545
recon_loss: 0.027213910594582558, dist_loss: 0.665772557258606
recon_loss: 0.027212444692850113, dist_loss: 0.6300554275512695
recon_loss: 0.027210017666220665, dist_loss: 0.41641509532928467
recon_loss: 0.0272073857486248, dist_loss: 0.6840533018112183
recon_loss: 0.027205655351281166, dist_loss: 0.42781710624694824
recon_loss: 0.027204569429159164, dist_loss: 0.3723173141479492
recon_loss: 0.02720460668206215, dist_loss: 0.5965077877044678
recon_loss: 0.02720438316464424, dist_loss: 0.38649940490722656
recon_loss: 0.027205420657992363, dist_loss: 0.6126645803451538
recon_loss: 0.02720803953707218, dist_loss: 0.6493080854415894
recon_loss: 0.02720886655151844, dist_loss: 0.7040383219718933
recon_loss: 0.02721085213124752, dist_loss: 0.8076131343841553
recon_loss: 0.027209999039769173, dist_loss: 0.8406003713607788
recon_loss: 0.027209395542740822, dist_loss: 0.6365426778793335
recon_loss: 0.027208495885133743, dist_loss: 0.9800499677658081
recon_loss: 0.027207622304558754, dist_loss: 0.6617710590362549
recon_loss: 0.027205651625990868, dist_loss: 0.6767711639404297
recon_loss: 0.027203436940908432, dist_loss: 0.4223054051399231
recon_loss: 0.027202000841498375, dist_loss: 0.6315615177154541
recon_loss: 0.027200737968087196, dist_loss: 0.5891834497451782
recon_loss: 0.027200082316994667, dist_loss: 0.4330636262893677
recon_loss: 0.027199285104870796, dist_loss: 0.8836342096328735
recon_loss: 0.027198832482099533, dist_loss: 0.6636995077133179
recon_loss: 0.0271985474973917, dist_loss: 0.5987775921821594
recon_loss: 0.02719792351126671, dist_loss: 0.5652729272842407
recon_loss: 0.027197880670428276, dist_loss: 0.8936251401901245
recon_loss: 0.02719692327082157, dist_loss: 0.6065990924835205
recon_loss: 0.02719670534133911, dist_loss: 0.6121747493743896
recon_loss: 0.027195995673537254, dist_loss: 0.9947160482406616
recon_loss: 0.02719593234360218, dist_loss: 0.6973192691802979
recon_loss: 0.027195747941732407, dist_loss: 0.9637125134468079
recon_loss: 0.027195684611797333, dist_loss: 0.4174872040748596
recon_loss: 0.027196386829018593, dist_loss: 0.5538753271102905
recon_loss: 0.02719588205218315, dist_loss: 1.163318395614624
recon_loss: 0.02719690278172493, dist_loss: 0.811943769454956
recon_loss: 0.027196142822504044, dist_loss: 0.5292837619781494
recon_loss: 0.027197377756237984, dist_loss: 0.7785917520523071
recon_loss: 0.027196552604436874, dist_loss: 0.4475579261779785
recon_loss: 0.02719639614224434, dist_loss: 0.48892083764076233
recon_loss: 0.02719658799469471, dist_loss: 0.6905818581581116
recon_loss: 0.027195820584893227, dist_loss: 0.43008285760879517
recon_loss: 0.027195913717150688, dist_loss: 0.852349579334259
recon_loss: 0.027195045724511147, dist_loss: 0.7923874855041504
recon_loss: 0.02719426527619362, dist_loss: 1.0850448608398438
recon_loss: 0.027194852009415627, dist_loss: 0.8248927593231201
recon_loss: 0.027196038514375687, dist_loss: 0.7449921369552612
recon_loss: 0.027196848765015602, dist_loss: 0.3272364139556885
recon_loss: 0.027198249474167824, dist_loss: 1.1535935401916504
recon_loss: 0.02719828113913536, dist_loss: 0.7907480001449585
recon_loss: 0.027198277413845062, dist_loss: 0.48705166578292847
recon_loss: 0.027197841554880142, dist_loss: 0.4203003942966461
recon_loss: 0.02719673328101635, dist_loss: 0.7161552906036377
recon_loss: 0.027196718379855156, dist_loss: 0.4627242684364319
recon_loss: 0.027196519076824188, dist_loss: 0.45993709564208984
recon_loss: 0.02719642035663128, dist_loss: 0.6764808893203735
recon_loss: 0.02719634771347046, dist_loss: 0.5212637186050415
recon_loss: 0.027195977047085762, dist_loss: 0.8327972292900085
recon_loss: 0.02719554677605629, dist_loss: 0.303267240524292
recon_loss: 0.027194807305932045, dist_loss: 0.5180609822273254
recon_loss: 0.027193931862711906, dist_loss: 0.5644861459732056
recon_loss: 0.02719300054013729, dist_loss: 0.8522214889526367
recon_loss: 0.0271929744631052, dist_loss: 0.8925415873527527
Pre-training Epoch 118:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 118:   4%|▍         | 16/367 [00:00<00:02, 159.42it/s]Pre-training Epoch 118:   9%|▉         | 34/367 [00:00<00:01, 170.76it/s]Pre-training Epoch 118:  14%|█▍        | 52/367 [00:00<00:01, 162.97it/s]Pre-training Epoch 118:  19%|█▉        | 69/367 [00:00<00:01, 160.29it/s]Pre-training Epoch 118:  23%|██▎       | 86/367 [00:00<00:01, 158.60it/s]Pre-training Epoch 118:  28%|██▊       | 102/367 [00:00<00:01, 156.28it/s]Pre-training Epoch 118:  32%|███▏      | 118/367 [00:00<00:01, 155.58it/s]recon_loss: 0.02719207853078842, dist_loss: 1.328688621520996
recon_loss: 0.0271922554820776, dist_loss: 0.9789453148841858
recon_loss: 0.027191346511244774, dist_loss: 0.5674773454666138
recon_loss: 0.027191627770662308, dist_loss: 0.5586845874786377
recon_loss: 0.027191422879695892, dist_loss: 0.5398094654083252
recon_loss: 0.02719169296324253, dist_loss: 0.9108485579490662
recon_loss: 0.027191655710339546, dist_loss: 0.7841014862060547
recon_loss: 0.02719070576131344, dist_loss: 0.6533378958702087
recon_loss: 0.027190882712602615, dist_loss: 1.052827000617981
recon_loss: 0.02719099074602127, dist_loss: 0.7355265617370605
recon_loss: 0.027191493660211563, dist_loss: 0.5400381088256836
recon_loss: 0.027192099019885063, dist_loss: 0.7327777147293091
recon_loss: 0.0271922517567873, dist_loss: 0.6856334805488586
recon_loss: 0.027192872017621994, dist_loss: 0.7358448505401611
recon_loss: 0.02719300240278244, dist_loss: 0.8358847498893738
recon_loss: 0.027193479239940643, dist_loss: 0.3973546028137207
recon_loss: 0.027193624526262283, dist_loss: 0.6223984360694885
recon_loss: 0.02719307690858841, dist_loss: 0.6076880693435669
recon_loss: 0.027193257585167885, dist_loss: 0.8288127183914185
recon_loss: 0.02719341777265072, dist_loss: 0.42615973949432373
recon_loss: 0.027193637564778328, dist_loss: 0.7397105693817139
recon_loss: 0.027194000780582428, dist_loss: 0.6241232752799988
recon_loss: 0.027194427326321602, dist_loss: 0.633548378944397
recon_loss: 0.027195550501346588, dist_loss: 0.5114713907241821
recon_loss: 0.027194947004318237, dist_loss: 0.44661450386047363
recon_loss: 0.027195574715733528, dist_loss: 0.603649377822876
recon_loss: 0.027195090427994728, dist_loss: 0.6934342980384827
recon_loss: 0.027195574715733528, dist_loss: 0.569244921207428
recon_loss: 0.02719503827393055, dist_loss: 1.095491647720337
recon_loss: 0.027194581925868988, dist_loss: 1.2998359203338623
recon_loss: 0.02719401754438877, dist_loss: 0.4976204037666321
recon_loss: 0.02719266340136528, dist_loss: 0.9421730637550354
recon_loss: 0.02719172090291977, dist_loss: 0.4359982907772064
recon_loss: 0.02719159424304962, dist_loss: 0.6475890278816223
recon_loss: 0.027192186564207077, dist_loss: 0.5052162408828735
recon_loss: 0.027192873880267143, dist_loss: 0.4395439922809601
recon_loss: 0.027193740010261536, dist_loss: 0.6214529275894165
recon_loss: 0.027194295078516006, dist_loss: 0.5356056690216064
recon_loss: 0.027195068076252937, dist_loss: 0.4963814318180084
recon_loss: 0.027195267379283905, dist_loss: 0.42956802248954773
recon_loss: 0.02719532698392868, dist_loss: 0.5647880434989929
recon_loss: 0.02719435840845108, dist_loss: 0.6726142764091492
recon_loss: 0.027193542569875717, dist_loss: 0.8834618330001831
recon_loss: 0.027192262932658195, dist_loss: 0.7734703421592712
recon_loss: 0.02719123661518097, dist_loss: 0.7348102331161499
recon_loss: 0.02719119004905224, dist_loss: 0.8713343739509583
recon_loss: 0.02719174697995186, dist_loss: 0.5938917398452759
recon_loss: 0.02719324640929699, dist_loss: 0.6631677150726318
recon_loss: 0.027195896953344345, dist_loss: 0.43020355701446533
recon_loss: 0.027197495102882385, dist_loss: 0.60858553647995
recon_loss: 0.02719883620738983, dist_loss: 0.4748944044113159
recon_loss: 0.027198271825909615, dist_loss: 0.6197465062141418
recon_loss: 0.027197981253266335, dist_loss: 0.5756704807281494
recon_loss: 0.027196351438760757, dist_loss: 0.6208655834197998
recon_loss: 0.02719520404934883, dist_loss: 0.7649009227752686
recon_loss: 0.027193404734134674, dist_loss: 0.8611331582069397
recon_loss: 0.027192339301109314, dist_loss: 0.6440415978431702
recon_loss: 0.02719094231724739, dist_loss: 0.4719003438949585
recon_loss: 0.027191387489438057, dist_loss: 0.7200149893760681
recon_loss: 0.027190377935767174, dist_loss: 0.7794679999351501
recon_loss: 0.027192482724785805, dist_loss: 0.6497615575790405
recon_loss: 0.027191950008273125, dist_loss: 0.5687727928161621
recon_loss: 0.027194803580641747, dist_loss: 0.5743526220321655
recon_loss: 0.027192307636141777, dist_loss: 0.6705317497253418
recon_loss: 0.027193769812583923, dist_loss: 0.47194504737854004
recon_loss: 0.027191679924726486, dist_loss: 0.47455060482025146
recon_loss: 0.027192125096917152, dist_loss: 0.3622328042984009
recon_loss: 0.027190441265702248, dist_loss: 0.45498475432395935
recon_loss: 0.02719069831073284, dist_loss: 0.43136483430862427
recon_loss: 0.027190059423446655, dist_loss: 0.6037179231643677
recon_loss: 0.02718997932970524, dist_loss: 0.8069655895233154
recon_loss: 0.027189765125513077, dist_loss: 0.7119344472885132
recon_loss: 0.027189085260033607, dist_loss: 0.4905470013618469
recon_loss: 0.02718903310596943, dist_loss: 0.6785592436790466
recon_loss: 0.027188314124941826, dist_loss: 0.5922095775604248
recon_loss: 0.027187982574105263, dist_loss: 0.7827284336090088
recon_loss: 0.027187766507267952, dist_loss: 0.631023645401001
recon_loss: 0.027187619358301163, dist_loss: 0.45357128977775574
recon_loss: 0.027188077569007874, dist_loss: 0.8806513547897339
recon_loss: 0.027188492938876152, dist_loss: 0.4626733660697937
recon_loss: 0.027189195156097412, dist_loss: 0.39110419154167175
recon_loss: 0.027189509943127632, dist_loss: 0.6365492343902588
recon_loss: 0.027190575376152992, dist_loss: 0.6886829137802124
recon_loss: 0.027189964428544044, dist_loss: 0.49907827377319336
recon_loss: 0.027190664783120155, dist_loss: 0.6560111045837402
recon_loss: 0.027189765125513077, dist_loss: 0.5695961713790894
recon_loss: 0.027189794927835464, dist_loss: 0.3490951359272003
recon_loss: 0.02718883566558361, dist_loss: 0.7183936238288879
recon_loss: 0.0271891038864851, dist_loss: 0.843514084815979
recon_loss: 0.027188492938876152, dist_loss: 0.6013498306274414
recon_loss: 0.02718949504196644, dist_loss: 0.4070204496383667
recon_loss: 0.02718890830874443, dist_loss: 0.7910683751106262
recon_loss: 0.027187887579202652, dist_loss: 0.6392179727554321
recon_loss: 0.027187883853912354, dist_loss: 0.8735366463661194
recon_loss: 0.027187466621398926, dist_loss: 0.6220369338989258
recon_loss: 0.02718798629939556, dist_loss: 0.6491226553916931
recon_loss: 0.02718772552907467, dist_loss: 1.2609471082687378
recon_loss: 0.02718830481171608, dist_loss: 0.7626111507415771
recon_loss: 0.02718835324048996, dist_loss: 0.795419454574585
recon_loss: 0.027188334614038467, dist_loss: 0.49456727504730225
recon_loss: 0.02718832716345787, dist_loss: 0.9189702272415161
recon_loss: 0.02718859165906906, dist_loss: 0.9125641584396362
recon_loss: 0.027189945802092552, dist_loss: 0.4450911283493042
recon_loss: 0.02718985639512539, dist_loss: 0.7059078812599182
recon_loss: 0.027190061286091805, dist_loss: 0.7235757112503052
recon_loss: 0.027189793065190315, dist_loss: 0.5012681484222412
recon_loss: 0.027190107852220535, dist_loss: 0.6777255535125732
recon_loss: 0.027189798653125763, dist_loss: 0.5873126983642578
recon_loss: 0.027189237996935844, dist_loss: 0.5142660140991211
recon_loss: 0.027187729254364967, dist_loss: 0.26338663697242737
recon_loss: 0.027187658473849297, dist_loss: 0.9541221857070923
recon_loss: 0.027187485247850418, dist_loss: 0.7377257347106934
recon_loss: 0.02718774415552616, dist_loss: 0.6530992984771729
recon_loss: 0.027187734842300415, dist_loss: 1.1061056852340698
recon_loss: 0.02718760073184967, dist_loss: 0.7301565408706665
recon_loss: 0.027187678962945938, dist_loss: 0.5116749405860901
recon_loss: 0.0271877720952034, dist_loss: 0.9100673794746399
recon_loss: 0.027187690138816833, dist_loss: 0.4735456109046936
recon_loss: 0.027187226340174675, dist_loss: 0.50569748878479
recon_loss: 0.027187220752239227, dist_loss: 0.3369157612323761
recon_loss: 0.02718738093972206, dist_loss: 0.654733419418335
recon_loss: 0.027187449857592583, dist_loss: 0.5776137113571167
recon_loss: 0.02718697115778923, dist_loss: 0.5652648210525513
recon_loss: 0.027187256142497063, dist_loss: 0.6287728548049927
recon_loss: 0.027186917141079903, dist_loss: 0.8596727252006531
recon_loss: 0.027187630534172058, dist_loss: 0.47230544686317444
recon_loss: 0.027187295258045197, dist_loss: 0.4938638508319855
recon_loss: 0.0271872840821743, dist_loss: 0.700495719909668
Pre-training Epoch 118:  37%|███▋      | 134/367 [00:00<00:01, 156.14it/s]Pre-training Epoch 118:  41%|████      | 150/367 [00:00<00:01, 152.20it/s]Pre-training Epoch 118:  45%|████▌     | 166/367 [00:01<00:01, 150.28it/s]Pre-training Epoch 118:  50%|████▉     | 182/367 [00:01<00:01, 150.50it/s]Pre-training Epoch 118:  54%|█████▍    | 198/367 [00:01<00:01, 150.16it/s]Pre-training Epoch 118:  58%|█████▊    | 214/367 [00:01<00:01, 150.60it/s]Pre-training Epoch 118:  63%|██████▎   | 230/367 [00:01<00:00, 151.05it/s]Pre-training Epoch 118:  67%|██████▋   | 246/367 [00:01<00:00, 151.73it/s]recon_loss: 0.027187224477529526, dist_loss: 0.3099275827407837
recon_loss: 0.027187136933207512, dist_loss: 0.8341279029846191
recon_loss: 0.027187205851078033, dist_loss: 0.7317598462104797
recon_loss: 0.02718709409236908, dist_loss: 0.6611034274101257
recon_loss: 0.027187226340174675, dist_loss: 0.7180277109146118
recon_loss: 0.027187302708625793, dist_loss: 0.7316562533378601
recon_loss: 0.027187153697013855, dist_loss: 0.8560498952865601
recon_loss: 0.027187015861272812, dist_loss: 0.760576605796814
recon_loss: 0.027186857536435127, dist_loss: 0.535893440246582
recon_loss: 0.027186784893274307, dist_loss: 0.6317391991615295
recon_loss: 0.02718653529882431, dist_loss: 0.5130138397216797
recon_loss: 0.027187276631593704, dist_loss: 0.5143283605575562
recon_loss: 0.027186807245016098, dist_loss: 0.5295198559761047
recon_loss: 0.027187325060367584, dist_loss: 0.6660946607589722
recon_loss: 0.027187954634428024, dist_loss: 0.8056875467300415
recon_loss: 0.027188314124941826, dist_loss: 0.8354336023330688
recon_loss: 0.027189917862415314, dist_loss: 0.7254273891448975
recon_loss: 0.027189327403903008, dist_loss: 0.744455873966217
recon_loss: 0.027189772576093674, dist_loss: 0.33084216713905334
recon_loss: 0.02718876115977764, dist_loss: 0.740436315536499
recon_loss: 0.027188843116164207, dist_loss: 0.5536355376243591
recon_loss: 0.027188874781131744, dist_loss: 0.5883440971374512
recon_loss: 0.02718885987997055, dist_loss: 0.7039395570755005
recon_loss: 0.027188537642359734, dist_loss: 0.7458962202072144
recon_loss: 0.02718811109662056, dist_loss: 0.6670461893081665
recon_loss: 0.0271878931671381, dist_loss: 0.6259191036224365
recon_loss: 0.02718762494623661, dist_loss: 0.7574164271354675
recon_loss: 0.027188051491975784, dist_loss: 0.34656476974487305
recon_loss: 0.02718866616487503, dist_loss: 0.4617592990398407
recon_loss: 0.027189379557967186, dist_loss: 0.8184704780578613
recon_loss: 0.027188561856746674, dist_loss: 0.5537877082824707
recon_loss: 0.027187149971723557, dist_loss: 0.632514238357544
recon_loss: 0.02718685381114483, dist_loss: 0.8341524004936218
recon_loss: 0.027186747640371323, dist_loss: 0.6219758987426758
recon_loss: 0.02718757651746273, dist_loss: 0.425697922706604
recon_loss: 0.02718779817223549, dist_loss: 0.5456801652908325
recon_loss: 0.027189534157514572, dist_loss: 0.6136516332626343
recon_loss: 0.02719046361744404, dist_loss: 0.499459445476532
recon_loss: 0.02719396911561489, dist_loss: 0.8086289167404175
recon_loss: 0.027196362614631653, dist_loss: 0.8993585705757141
recon_loss: 0.027199869975447655, dist_loss: 0.5953625440597534
recon_loss: 0.027204155921936035, dist_loss: 0.43620985746383667
recon_loss: 0.02720595709979534, dist_loss: 0.6074637174606323
recon_loss: 0.027205362915992737, dist_loss: 0.362570196390152
recon_loss: 0.027204181998968124, dist_loss: 0.6282392740249634
recon_loss: 0.027201199904084206, dist_loss: 0.7507004737854004
recon_loss: 0.027197618037462234, dist_loss: 0.6882023811340332
recon_loss: 0.027195625007152557, dist_loss: 0.382333904504776
recon_loss: 0.027192942798137665, dist_loss: 0.5363262295722961
recon_loss: 0.0271922517567873, dist_loss: 0.6729368567466736
recon_loss: 0.0271917637437582, dist_loss: 0.9634685516357422
recon_loss: 0.02719264291226864, dist_loss: 0.825592041015625
recon_loss: 0.027193455025553703, dist_loss: 0.5249602794647217
recon_loss: 0.02719595469534397, dist_loss: 0.4569859206676483
recon_loss: 0.02719753049314022, dist_loss: 0.49338769912719727
recon_loss: 0.02719992958009243, dist_loss: 0.627662181854248
recon_loss: 0.027203300967812538, dist_loss: 0.5436365604400635
recon_loss: 0.02720414660871029, dist_loss: 0.8904926776885986
recon_loss: 0.02720499224960804, dist_loss: 0.7492281198501587
recon_loss: 0.02720409817993641, dist_loss: 0.5777240991592407
recon_loss: 0.027203073725104332, dist_loss: 0.5707821846008301
recon_loss: 0.027200110256671906, dist_loss: 0.5461224317550659
recon_loss: 0.027196761220693588, dist_loss: 0.38630372285842896
recon_loss: 0.027194960042834282, dist_loss: 0.4259324371814728
recon_loss: 0.02719276025891304, dist_loss: 0.7015674114227295
recon_loss: 0.0271918885409832, dist_loss: 0.5066691637039185
recon_loss: 0.027190333232283592, dist_loss: 0.9150147438049316
recon_loss: 0.027191435918211937, dist_loss: 0.8547125458717346
recon_loss: 0.027188772335648537, dist_loss: 0.6912325620651245
recon_loss: 0.027189355343580246, dist_loss: 0.3420684337615967
recon_loss: 0.02718799002468586, dist_loss: 0.5802323818206787
recon_loss: 0.02718779444694519, dist_loss: 1.2584418058395386
recon_loss: 0.027186792343854904, dist_loss: 0.3678852915763855
recon_loss: 0.027186565101146698, dist_loss: 0.6038318872451782
recon_loss: 0.027186065912246704, dist_loss: 0.49123436212539673
recon_loss: 0.02718598209321499, dist_loss: 1.006929636001587
recon_loss: 0.02718573622405529, dist_loss: 0.2630274295806885
recon_loss: 0.027185611426830292, dist_loss: 0.43937161564826965
recon_loss: 0.027185138314962387, dist_loss: 0.41921281814575195
recon_loss: 0.02718479558825493, dist_loss: 0.7515232563018799
recon_loss: 0.02718447521328926, dist_loss: 0.7182101011276245
recon_loss: 0.027184275910258293, dist_loss: 0.6222084164619446
recon_loss: 0.027183935046195984, dist_loss: 0.7212091684341431
recon_loss: 0.02718386985361576, dist_loss: 0.5276474952697754
recon_loss: 0.02718338556587696, dist_loss: 0.34777191281318665
recon_loss: 0.02718336693942547, dist_loss: 0.3474159240722656
recon_loss: 0.027183150872588158, dist_loss: 0.45853492617607117
recon_loss: 0.027183426544070244, dist_loss: 0.5072916746139526
recon_loss: 0.027183011174201965, dist_loss: 0.8829049468040466
recon_loss: 0.027183284983038902, dist_loss: 0.84023118019104
recon_loss: 0.027183201164007187, dist_loss: 0.5213529467582703
recon_loss: 0.02718345820903778, dist_loss: 0.5420398712158203
recon_loss: 0.027183733880519867, dist_loss: 0.5423274040222168
recon_loss: 0.02718397043645382, dist_loss: 0.5149143934249878
recon_loss: 0.027183489874005318, dist_loss: 0.904482901096344
recon_loss: 0.027182642370462418, dist_loss: 0.4689447283744812
recon_loss: 0.027182284742593765, dist_loss: 0.41576629877090454
recon_loss: 0.027182016521692276, dist_loss: 0.560185432434082
recon_loss: 0.027182070538401604, dist_loss: 0.36295974254608154
recon_loss: 0.027181707322597504, dist_loss: 0.7290271520614624
recon_loss: 0.02718156762421131, dist_loss: 1.0846285820007324
recon_loss: 0.02718181349337101, dist_loss: 0.4897942543029785
recon_loss: 0.027181919664144516, dist_loss: 0.585113525390625
recon_loss: 0.027181923389434814, dist_loss: 0.802058219909668
recon_loss: 0.027181649580597878, dist_loss: 0.4088181257247925
recon_loss: 0.02718224562704563, dist_loss: 0.7340655326843262
recon_loss: 0.02718173712491989, dist_loss: 0.685539722442627
recon_loss: 0.02718176133930683, dist_loss: 0.39274346828460693
recon_loss: 0.027182234451174736, dist_loss: 0.6977130174636841
recon_loss: 0.027182776480913162, dist_loss: 0.692487359046936
recon_loss: 0.02718321792781353, dist_loss: 0.9019804000854492
recon_loss: 0.027183756232261658, dist_loss: 0.9031469821929932
recon_loss: 0.02718447521328926, dist_loss: 0.7078772783279419
recon_loss: 0.027184315025806427, dist_loss: 0.8392561674118042
recon_loss: 0.027184249833226204, dist_loss: 0.44487178325653076
recon_loss: 0.027184121310710907, dist_loss: 0.44569963216781616
recon_loss: 0.0271840188652277, dist_loss: 0.31790947914123535
recon_loss: 0.02718387171626091, dist_loss: 0.33850768208503723
recon_loss: 0.02718392014503479, dist_loss: 0.5568826198577881
recon_loss: 0.027184344828128815, dist_loss: 0.4349100589752197
recon_loss: 0.02718508429825306, dist_loss: 0.5006511211395264
recon_loss: 0.027185935527086258, dist_loss: 0.5821698307991028
recon_loss: 0.0271864403039217, dist_loss: 0.3347911834716797
recon_loss: 0.027186991646885872, dist_loss: 0.4084721803665161
recon_loss: 0.02718762680888176, dist_loss: 0.4476253390312195
recon_loss: 0.02718811109662056, dist_loss: 0.6746017932891846
recon_loss: 0.027187233790755272, dist_loss: 0.8192760944366455
recon_loss: 0.027186382561922073, dist_loss: 0.439207524061203
Pre-training Epoch 118:  71%|███████▏  | 262/367 [00:01<00:00, 151.11it/s]Pre-training Epoch 118:  76%|███████▌  | 278/367 [00:01<00:00, 149.19it/s]Pre-training Epoch 118:  80%|████████  | 294/367 [00:01<00:00, 150.26it/s]Pre-training Epoch 118:  84%|████████▍ | 310/367 [00:02<00:00, 147.80it/s]Pre-training Epoch 118:  89%|████████▊ | 325/367 [00:02<00:00, 148.36it/s]Pre-training Epoch 118:  93%|█████████▎| 341/367 [00:02<00:00, 150.95it/s]Pre-training Epoch 118:  97%|█████████▋| 357/367 [00:02<00:00, 150.01it/s]Pre-training Epoch 118: 100%|██████████| 367/367 [00:02<00:00, 152.55it/s]
recon_loss: 0.02718491293489933, dist_loss: 0.5922623872756958
recon_loss: 0.027184337377548218, dist_loss: 0.6450886130332947
recon_loss: 0.02718350477516651, dist_loss: 0.6435067653656006
recon_loss: 0.02718348242342472, dist_loss: 0.3209526836872101
recon_loss: 0.02718261256814003, dist_loss: 1.2387876510620117
recon_loss: 0.027183378115296364, dist_loss: 0.44562965631484985
recon_loss: 0.027182474732398987, dist_loss: 0.7648782730102539
recon_loss: 0.027182267978787422, dist_loss: 1.0017597675323486
recon_loss: 0.027183523401618004, dist_loss: 1.0049574375152588
recon_loss: 0.027182558551430702, dist_loss: 0.5042068958282471
recon_loss: 0.027184072881937027, dist_loss: 1.096008539199829
recon_loss: 0.02718297392129898, dist_loss: 0.4869217574596405
recon_loss: 0.027183568105101585, dist_loss: 1.0613566637039185
recon_loss: 0.02718241512775421, dist_loss: 0.7480449676513672
recon_loss: 0.027182098478078842, dist_loss: 0.8233919143676758
recon_loss: 0.027181804180145264, dist_loss: 0.7676559090614319
recon_loss: 0.027181515470147133, dist_loss: 0.4601705074310303
recon_loss: 0.027181558310985565, dist_loss: 0.36909055709838867
recon_loss: 0.027181079611182213, dist_loss: 0.884223461151123
recon_loss: 0.027181725949048996, dist_loss: 1.1310169696807861
recon_loss: 0.027181515470147133, dist_loss: 0.3834749162197113
recon_loss: 0.027181796729564667, dist_loss: 0.508630633354187
recon_loss: 0.027182314544916153, dist_loss: 0.48638230562210083
recon_loss: 0.027182281017303467, dist_loss: 1.0971893072128296
recon_loss: 0.02718297392129898, dist_loss: 1.0258170366287231
recon_loss: 0.027183137834072113, dist_loss: 0.5968906879425049
recon_loss: 0.02718348056077957, dist_loss: 0.7253894209861755
recon_loss: 0.027183212339878082, dist_loss: 0.49772709608078003
recon_loss: 0.02718318998813629, dist_loss: 0.8835500478744507
recon_loss: 0.027182120829820633, dist_loss: 0.7590736150741577
recon_loss: 0.02718125283718109, dist_loss: 0.5094509124755859
recon_loss: 0.02718079835176468, dist_loss: 1.235234260559082
recon_loss: 0.027180349454283714, dist_loss: 0.40641099214553833
recon_loss: 0.02718033827841282, dist_loss: 0.6342264413833618
recon_loss: 0.027180379256606102, dist_loss: 0.5115294456481934
recon_loss: 0.02718081884086132, dist_loss: 0.44025734066963196
recon_loss: 0.02718072012066841, dist_loss: 0.523154616355896
recon_loss: 0.02718021534383297, dist_loss: 0.8415871858596802
recon_loss: 0.027179650962352753, dist_loss: 0.4157206416130066
recon_loss: 0.027179203927516937, dist_loss: 0.5196176767349243
recon_loss: 0.02717909775674343, dist_loss: 0.5716562867164612
recon_loss: 0.0271796602755785, dist_loss: 0.4404717981815338
recon_loss: 0.027180178090929985, dist_loss: 0.5221134424209595
recon_loss: 0.027181347832083702, dist_loss: 0.5594874620437622
recon_loss: 0.02718222327530384, dist_loss: 0.31093376874923706
recon_loss: 0.02718287706375122, dist_loss: 1.0179287195205688
recon_loss: 0.027182670310139656, dist_loss: 0.8529287576675415
recon_loss: 0.02718200720846653, dist_loss: 0.9146867990493774
recon_loss: 0.027182964608073235, dist_loss: 0.8364346027374268
recon_loss: 0.027182750403881073, dist_loss: 0.7608681917190552
recon_loss: 0.027183307334780693, dist_loss: 0.5324190855026245
recon_loss: 0.027183812111616135, dist_loss: 0.7993506789207458
recon_loss: 0.02718333899974823, dist_loss: 0.6896958351135254
recon_loss: 0.027184033766388893, dist_loss: 0.5656566619873047
recon_loss: 0.02718377858400345, dist_loss: 0.5427520275115967
recon_loss: 0.027183709666132927, dist_loss: 0.6851797103881836
recon_loss: 0.02718314714729786, dist_loss: 0.34047913551330566
recon_loss: 0.027182573452591896, dist_loss: 0.7392136454582214
recon_loss: 0.027181707322597504, dist_loss: 0.8971232175827026
recon_loss: 0.027181196957826614, dist_loss: 0.6318904161453247
recon_loss: 0.02718057669699192, dist_loss: 0.6139200925827026
recon_loss: 0.027181290090084076, dist_loss: 0.6468592286109924
recon_loss: 0.027181949466466904, dist_loss: 0.4390467405319214
recon_loss: 0.027182869613170624, dist_loss: 0.7773216366767883
recon_loss: 0.02718385122716427, dist_loss: 0.533071756362915
recon_loss: 0.02718515507876873, dist_loss: 0.44111934304237366
recon_loss: 0.02718646079301834, dist_loss: 0.4888751804828644
recon_loss: 0.027188988402485847, dist_loss: 0.7554544806480408
recon_loss: 0.027190282940864563, dist_loss: 0.48173555731773376
recon_loss: 0.027190180495381355, dist_loss: 0.40050092339515686
recon_loss: 0.027189746499061584, dist_loss: 0.522087812423706
recon_loss: 0.027188491076231003, dist_loss: 0.4273717701435089
recon_loss: 0.02718690223991871, dist_loss: 0.3949514627456665
recon_loss: 0.02718471735715866, dist_loss: 0.4259146451950073
recon_loss: 0.027182981371879578, dist_loss: 1.0446994304656982
recon_loss: 0.02718208357691765, dist_loss: 0.4949571490287781
recon_loss: 0.027181634679436684, dist_loss: 0.4260684847831726
recon_loss: 0.027181224897503853, dist_loss: 0.6056167483329773
recon_loss: 0.02718127891421318, dist_loss: 0.7245010137557983
recon_loss: 0.0271812342107296, dist_loss: 0.7897301912307739
recon_loss: 0.027181047946214676, dist_loss: 0.4500865936279297
recon_loss: 0.027181241661310196, dist_loss: 0.6241855621337891
recon_loss: 0.027180558070540428, dist_loss: 0.6889016628265381
recon_loss: 0.027181295678019524, dist_loss: 0.38914474844932556
recon_loss: 0.02718052640557289, dist_loss: 0.6447668075561523
recon_loss: 0.02718113549053669, dist_loss: 0.8305906057357788
recon_loss: 0.02718106284737587, dist_loss: 0.43463024497032166
recon_loss: 0.027179788798093796, dist_loss: 0.9749466180801392
recon_loss: 0.02718001790344715, dist_loss: 0.7289386987686157
recon_loss: 0.027178293094038963, dist_loss: 0.4176296591758728
recon_loss: 0.0271791722625494, dist_loss: 0.981791079044342
recon_loss: 0.02717777155339718, dist_loss: 0.7474548816680908
recon_loss: 0.02717926725745201, dist_loss: 0.754467785358429
recon_loss: 0.02717776410281658, dist_loss: 0.415791779756546
recon_loss: 0.027178511023521423, dist_loss: 0.3096909523010254
recon_loss: 0.0271782036870718, dist_loss: 0.6340118646621704
recon_loss: 0.02717837132513523, dist_loss: 0.8625316619873047
recon_loss: 0.02717914618551731, dist_loss: 0.5513218641281128
recon_loss: 0.027179382741451263, dist_loss: 0.8552761673927307
recon_loss: 0.027179870754480362, dist_loss: 0.4846953749656677
recon_loss: 0.02717900089919567, dist_loss: 1.0131021738052368
recon_loss: 0.02717815898358822, dist_loss: 0.9570186138153076
recon_loss: 0.027178123593330383, dist_loss: 0.4361659288406372
recon_loss: 0.027178825810551643, dist_loss: 1.1272406578063965
recon_loss: 0.027179867029190063, dist_loss: 0.7219268679618835
recon_loss: 0.027180593460798264, dist_loss: 1.1524237394332886
recon_loss: 0.027182092890143394, dist_loss: 0.9308377504348755
recon_loss: 0.02718171291053295, dist_loss: 0.4929286241531372
recon_loss: 0.02718103863298893, dist_loss: 0.6791831851005554
recon_loss: 0.02718045935034752, dist_loss: 0.9222742915153503
recon_loss: 0.027180001139640808, dist_loss: 0.8389512300491333
Pre-training Epoch 119:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 119:   5%|▍         | 17/367 [00:00<00:02, 168.47it/s]Pre-training Epoch 119:  10%|▉         | 35/367 [00:00<00:01, 172.36it/s]Pre-training Epoch 119:  14%|█▍        | 53/367 [00:00<00:01, 175.11it/s]Pre-training Epoch 119:  20%|█▉        | 72/367 [00:00<00:01, 177.26it/s]Pre-training Epoch 119:  25%|██▍       | 90/367 [00:00<00:01, 177.45it/s]Pre-training Epoch 119:  29%|██▉       | 108/367 [00:00<00:01, 177.46it/s]Pre-training Epoch 119:  34%|███▍      | 126/367 [00:00<00:01, 177.43it/s]recon_loss: 0.027179446071386337, dist_loss: 0.5126047134399414
recon_loss: 0.027178924530744553, dist_loss: 0.5808131098747253
recon_loss: 0.027178682386875153, dist_loss: 0.5961706042289734
recon_loss: 0.027178719639778137, dist_loss: 0.3566066324710846
recon_loss: 0.02717885933816433, dist_loss: 0.5257375240325928
recon_loss: 0.027179578319191933, dist_loss: 0.42525118589401245
recon_loss: 0.027179822325706482, dist_loss: 0.674638032913208
recon_loss: 0.02718035690486431, dist_loss: 0.53856360912323
recon_loss: 0.027180084958672523, dist_loss: 0.5389697551727295
recon_loss: 0.027179831638932228, dist_loss: 0.596811056137085
recon_loss: 0.027179712429642677, dist_loss: 0.7453344464302063
recon_loss: 0.027180099859833717, dist_loss: 0.8584729433059692
recon_loss: 0.027180414646863937, dist_loss: 0.644181489944458
recon_loss: 0.027180790901184082, dist_loss: 0.6371097564697266
recon_loss: 0.027181215584278107, dist_loss: 0.6729660630226135
recon_loss: 0.027181511744856834, dist_loss: 0.8434568643569946
recon_loss: 0.02718072012066841, dist_loss: 1.0215907096862793
recon_loss: 0.027179285883903503, dist_loss: 0.5429447889328003
recon_loss: 0.027178313583135605, dist_loss: 0.4718613624572754
recon_loss: 0.027179360389709473, dist_loss: 0.8377271890640259
recon_loss: 0.02718142233788967, dist_loss: 0.5503214597702026
recon_loss: 0.027183087542653084, dist_loss: 0.8423129916191101
recon_loss: 0.027184585109353065, dist_loss: 0.44944286346435547
recon_loss: 0.027185745537281036, dist_loss: 0.7476193904876709
recon_loss: 0.027187323197722435, dist_loss: 0.6632792949676514
recon_loss: 0.02718745917081833, dist_loss: 0.40911179780960083
recon_loss: 0.027187010273337364, dist_loss: 0.414376437664032
recon_loss: 0.02718442492187023, dist_loss: 0.8733915090560913
recon_loss: 0.027182841673493385, dist_loss: 0.41778770089149475
recon_loss: 0.027182454243302345, dist_loss: 0.47403663396835327
recon_loss: 0.02718169242143631, dist_loss: 0.3253539502620697
recon_loss: 0.02718127705156803, dist_loss: 1.01125168800354
recon_loss: 0.027180250734090805, dist_loss: 0.6348053216934204
recon_loss: 0.02718062326312065, dist_loss: 0.9106249809265137
recon_loss: 0.02717975713312626, dist_loss: 0.535007119178772
recon_loss: 0.027179308235645294, dist_loss: 0.9450674057006836
recon_loss: 0.027178332209587097, dist_loss: 0.49378231167793274
recon_loss: 0.027178091928362846, dist_loss: 0.8446057438850403
recon_loss: 0.027177397161722183, dist_loss: 0.2969842553138733
recon_loss: 0.02717709168791771, dist_loss: 0.9082304835319519
recon_loss: 0.027176517993211746, dist_loss: 0.607332706451416
recon_loss: 0.027176031842827797, dist_loss: 0.39507579803466797
recon_loss: 0.027176236733794212, dist_loss: 0.919389009475708
recon_loss: 0.02717655524611473, dist_loss: 0.5744390487670898
recon_loss: 0.027177423238754272, dist_loss: 0.7222476601600647
recon_loss: 0.027178307995200157, dist_loss: 0.4269322454929352
recon_loss: 0.027178604155778885, dist_loss: 0.31694042682647705
recon_loss: 0.027178578078746796, dist_loss: 1.1378839015960693
recon_loss: 0.027177950367331505, dist_loss: 0.7985308170318604
recon_loss: 0.027177080512046814, dist_loss: 0.6216468214988708
recon_loss: 0.02717655524611473, dist_loss: 1.0228683948516846
recon_loss: 0.02717648074030876, dist_loss: 0.931679904460907
recon_loss: 0.027176881209015846, dist_loss: 0.8921165466308594
recon_loss: 0.027177583426237106, dist_loss: 0.7423481941223145
recon_loss: 0.02717895619571209, dist_loss: 0.30937838554382324
recon_loss: 0.02718118578195572, dist_loss: 0.769103467464447
recon_loss: 0.02718335948884487, dist_loss: 0.8063546419143677
recon_loss: 0.027185188606381416, dist_loss: 0.5548020601272583
recon_loss: 0.02718675695359707, dist_loss: 0.6418339610099792
recon_loss: 0.027188049629330635, dist_loss: 0.44406333565711975
recon_loss: 0.02718866989016533, dist_loss: 0.3482263684272766
recon_loss: 0.02718782052397728, dist_loss: 0.46024277806282043
recon_loss: 0.02718617022037506, dist_loss: 0.4095785617828369
recon_loss: 0.027184389531612396, dist_loss: 0.45550042390823364
recon_loss: 0.027182869613170624, dist_loss: 0.8783811330795288
recon_loss: 0.027181141078472137, dist_loss: 0.39474231004714966
recon_loss: 0.027179544791579247, dist_loss: 0.8434219360351562
recon_loss: 0.02717897854745388, dist_loss: 0.7458438873291016
recon_loss: 0.027178209275007248, dist_loss: 0.8396755456924438
recon_loss: 0.02717892825603485, dist_loss: 0.9594916701316833
recon_loss: 0.027179311960935593, dist_loss: 0.37944719195365906
recon_loss: 0.027181090787053108, dist_loss: 0.7768855094909668
recon_loss: 0.027182944118976593, dist_loss: 0.6430076956748962
recon_loss: 0.02718743123114109, dist_loss: 0.4949498772621155
recon_loss: 0.027191344648599625, dist_loss: 0.6039623022079468
recon_loss: 0.027196457609534264, dist_loss: 0.9237063527107239
recon_loss: 0.027200276032090187, dist_loss: 0.9244681596755981
recon_loss: 0.027200035750865936, dist_loss: 0.8759287595748901
recon_loss: 0.027200881391763687, dist_loss: 0.42319953441619873
recon_loss: 0.027202585712075233, dist_loss: 0.8891408443450928
recon_loss: 0.02720349282026291, dist_loss: 0.6544852256774902
recon_loss: 0.02720225788652897, dist_loss: 0.9366085529327393
recon_loss: 0.027199480682611465, dist_loss: 0.9163963198661804
recon_loss: 0.027197139337658882, dist_loss: 0.4497688412666321
recon_loss: 0.027195077389478683, dist_loss: 1.24152672290802
recon_loss: 0.02719387412071228, dist_loss: 0.519347071647644
recon_loss: 0.027192281559109688, dist_loss: 0.689699649810791
recon_loss: 0.027188897132873535, dist_loss: 0.8683562874794006
recon_loss: 0.027187181636691093, dist_loss: 0.4076084494590759
recon_loss: 0.027185168117284775, dist_loss: 0.39790356159210205
recon_loss: 0.02718406915664673, dist_loss: 0.5241364240646362
recon_loss: 0.027183078229427338, dist_loss: 0.5592656135559082
recon_loss: 0.027183400467038155, dist_loss: 0.7236868739128113
recon_loss: 0.027186056599020958, dist_loss: 0.555300235748291
recon_loss: 0.02718999609351158, dist_loss: 0.9344232082366943
recon_loss: 0.02719338797032833, dist_loss: 0.5929003953933716
recon_loss: 0.027195317670702934, dist_loss: 0.315235435962677
recon_loss: 0.02719547599554062, dist_loss: 1.083240270614624
recon_loss: 0.027195116505026817, dist_loss: 0.5916618704795837
recon_loss: 0.02719287946820259, dist_loss: 0.6313055753707886
recon_loss: 0.027191130444407463, dist_loss: 0.8700022101402283
recon_loss: 0.02718924544751644, dist_loss: 0.4187065362930298
recon_loss: 0.027187557891011238, dist_loss: 0.6737974882125854
recon_loss: 0.027186134830117226, dist_loss: 1.00588059425354
recon_loss: 0.02718457207083702, dist_loss: 0.6238173246383667
recon_loss: 0.027183247730135918, dist_loss: 0.5623553395271301
recon_loss: 0.027181828394532204, dist_loss: 1.1451592445373535
recon_loss: 0.027181679382920265, dist_loss: 1.1703544855117798
recon_loss: 0.02718307077884674, dist_loss: 0.5055612921714783
recon_loss: 0.027184324339032173, dist_loss: 0.7231311202049255
recon_loss: 0.027186967432498932, dist_loss: 0.49619144201278687
recon_loss: 0.027189351618289948, dist_loss: 0.7337227463722229
recon_loss: 0.02719121053814888, dist_loss: 0.48810625076293945
recon_loss: 0.027190538123250008, dist_loss: 0.5145595669746399
recon_loss: 0.027188805863261223, dist_loss: 0.6089590787887573
recon_loss: 0.027188027277588844, dist_loss: 0.5388814210891724
recon_loss: 0.027186181396245956, dist_loss: 0.34573888778686523
recon_loss: 0.027185363695025444, dist_loss: 0.3426368534564972
recon_loss: 0.0271829292178154, dist_loss: 0.43437856435775757
recon_loss: 0.027181997895240784, dist_loss: 0.4815511107444763
recon_loss: 0.027180777862668037, dist_loss: 0.4533937871456146
recon_loss: 0.027181342244148254, dist_loss: 0.7995179891586304
recon_loss: 0.0271809883415699, dist_loss: 0.6520774364471436
recon_loss: 0.02718215249478817, dist_loss: 0.3091644048690796
recon_loss: 0.02718290686607361, dist_loss: 0.6180293560028076
recon_loss: 0.02718471549451351, dist_loss: 0.3956701457500458
recon_loss: 0.02718501165509224, dist_loss: 0.7258272171020508
recon_loss: 0.02718556858599186, dist_loss: 0.39300698041915894
Pre-training Epoch 119:  39%|███▉      | 144/367 [00:00<00:01, 172.15it/s]Pre-training Epoch 119:  44%|████▍     | 162/367 [00:00<00:01, 163.72it/s]Pre-training Epoch 119:  49%|████▉     | 179/367 [00:01<00:01, 161.73it/s]Pre-training Epoch 119:  53%|█████▎    | 196/367 [00:01<00:01, 160.05it/s]Pre-training Epoch 119:  58%|█████▊    | 213/367 [00:01<00:00, 154.72it/s]Pre-training Epoch 119:  62%|██████▏   | 229/367 [00:01<00:00, 155.07it/s]Pre-training Epoch 119:  67%|██████▋   | 245/367 [00:01<00:00, 154.62it/s]recon_loss: 0.02718566358089447, dist_loss: 0.31968510150909424
recon_loss: 0.02718469314277172, dist_loss: 0.5155321359634399
recon_loss: 0.027183884754776955, dist_loss: 0.7407790422439575
recon_loss: 0.02718201093375683, dist_loss: 0.6031836867332458
recon_loss: 0.027181454002857208, dist_loss: 0.4809108376502991
recon_loss: 0.027179889380931854, dist_loss: 0.6088826656341553
recon_loss: 0.027180079370737076, dist_loss: 0.6592531800270081
recon_loss: 0.027178211137652397, dist_loss: 0.4537564516067505
recon_loss: 0.0271785669028759, dist_loss: 0.42162778973579407
recon_loss: 0.027177104726433754, dist_loss: 0.5655551552772522
recon_loss: 0.027175936847925186, dist_loss: 0.7057807445526123
recon_loss: 0.02717442438006401, dist_loss: 0.7688136696815491
recon_loss: 0.027173571288585663, dist_loss: 0.6781776547431946
recon_loss: 0.027173154056072235, dist_loss: 0.5304949283599854
recon_loss: 0.027172766625881195, dist_loss: 0.5441035628318787
recon_loss: 0.02717297151684761, dist_loss: 0.8038632869720459
recon_loss: 0.027173960581421852, dist_loss: 0.3926819860935211
recon_loss: 0.027174536138772964, dist_loss: 0.9747626781463623
recon_loss: 0.027176005765795708, dist_loss: 0.9802194833755493
recon_loss: 0.027176247909665108, dist_loss: 0.5320510864257812
recon_loss: 0.027173571288585663, dist_loss: 0.41877326369285583
recon_loss: 0.027173001319169998, dist_loss: 0.5336050391197205
recon_loss: 0.027171621099114418, dist_loss: 0.6296374797821045
recon_loss: 0.02717224881052971, dist_loss: 0.7291203737258911
recon_loss: 0.027172645553946495, dist_loss: 0.7246063351631165
recon_loss: 0.02717260830104351, dist_loss: 1.1245567798614502
recon_loss: 0.02717570587992668, dist_loss: 0.5991622805595398
recon_loss: 0.027174195274710655, dist_loss: 0.6216737031936646
recon_loss: 0.02717665396630764, dist_loss: 0.9514249563217163
recon_loss: 0.02717435173690319, dist_loss: 0.319970965385437
recon_loss: 0.027175014838576317, dist_loss: 0.8354917764663696
recon_loss: 0.027172410860657692, dist_loss: 0.5194324254989624
recon_loss: 0.027172481641173363, dist_loss: 0.7050266265869141
recon_loss: 0.02717045322060585, dist_loss: 0.4282599687576294
recon_loss: 0.027171384543180466, dist_loss: 0.3057968020439148
recon_loss: 0.027170658111572266, dist_loss: 0.5109773874282837
recon_loss: 0.027172181755304337, dist_loss: 0.39312469959259033
recon_loss: 0.027173325419425964, dist_loss: 0.5027146935462952
recon_loss: 0.02717570587992668, dist_loss: 0.35699695348739624
recon_loss: 0.027177968993782997, dist_loss: 0.48995256423950195
recon_loss: 0.02717854455113411, dist_loss: 0.8892908096313477
recon_loss: 0.02717847377061844, dist_loss: 0.5618394613265991
recon_loss: 0.027176447212696075, dist_loss: 0.5498960614204407
recon_loss: 0.02717421017587185, dist_loss: 0.4460940957069397
recon_loss: 0.027172058820724487, dist_loss: 0.5418570041656494
recon_loss: 0.027170728892087936, dist_loss: 0.6364668607711792
recon_loss: 0.027169277891516685, dist_loss: 0.7164066433906555
recon_loss: 0.027168693020939827, dist_loss: 0.4365196228027344
recon_loss: 0.027168406173586845, dist_loss: 0.4068969786167145
recon_loss: 0.02716846391558647, dist_loss: 1.3575292825698853
recon_loss: 0.027168821543455124, dist_loss: 0.7816962599754333
recon_loss: 0.027169175446033478, dist_loss: 0.34604549407958984
recon_loss: 0.027168862521648407, dist_loss: 0.9724170565605164
recon_loss: 0.02716999128460884, dist_loss: 0.7374671697616577
recon_loss: 0.027168869972229004, dist_loss: 0.7478876709938049
recon_loss: 0.027169233188033104, dist_loss: 0.6461331248283386
recon_loss: 0.02716948837041855, dist_loss: 0.6637730598449707
recon_loss: 0.02717066928744316, dist_loss: 0.5479987859725952
recon_loss: 0.02717127837240696, dist_loss: 0.5347999334335327
recon_loss: 0.02717134915292263, dist_loss: 0.6802204847335815
recon_loss: 0.027170931920409203, dist_loss: 0.32508498430252075
recon_loss: 0.02716892398893833, dist_loss: 0.5910035967826843
recon_loss: 0.027168432250618935, dist_loss: 0.42030099034309387
recon_loss: 0.027167316526174545, dist_loss: 0.9191814064979553
recon_loss: 0.027167603373527527, dist_loss: 0.655710756778717
recon_loss: 0.027168070897459984, dist_loss: 0.49500155448913574
recon_loss: 0.02716788463294506, dist_loss: 0.5583757162094116
recon_loss: 0.02716832607984543, dist_loss: 0.3146149218082428
recon_loss: 0.027168000116944313, dist_loss: 0.7711872458457947
recon_loss: 0.027168167755007744, dist_loss: 0.9254307150840759
recon_loss: 0.027167923748493195, dist_loss: 0.6930321455001831
recon_loss: 0.027168452739715576, dist_loss: 0.804832935333252
recon_loss: 0.027167482301592827, dist_loss: 0.5943713784217834
recon_loss: 0.027167320251464844, dist_loss: 0.8291582465171814
recon_loss: 0.027166228741407394, dist_loss: 0.709061861038208
recon_loss: 0.027166103944182396, dist_loss: 0.3416411876678467
recon_loss: 0.027165750041604042, dist_loss: 1.0211353302001953
recon_loss: 0.027166353538632393, dist_loss: 0.651899516582489
recon_loss: 0.02716662734746933, dist_loss: 0.5209981203079224
recon_loss: 0.02716764062643051, dist_loss: 0.46898704767227173
recon_loss: 0.027168307453393936, dist_loss: 0.6590718030929565
recon_loss: 0.027168355882167816, dist_loss: 0.5737077593803406
recon_loss: 0.02716800570487976, dist_loss: 0.44778168201446533
recon_loss: 0.027166591957211494, dist_loss: 0.6635845303535461
recon_loss: 0.027166305109858513, dist_loss: 0.6859021782875061
recon_loss: 0.02716527320444584, dist_loss: 0.47453948855400085
recon_loss: 0.027165403589606285, dist_loss: 0.7694932222366333
recon_loss: 0.027164548635482788, dist_loss: 0.5154379606246948
recon_loss: 0.027165547013282776, dist_loss: 0.8198102712631226
recon_loss: 0.027165338397026062, dist_loss: 0.7516969442367554
recon_loss: 0.027165893465280533, dist_loss: 0.5833591222763062
recon_loss: 0.027166346088051796, dist_loss: 0.6080853343009949
recon_loss: 0.02716701105237007, dist_loss: 0.9491462707519531
recon_loss: 0.02716721035540104, dist_loss: 0.6146973967552185
recon_loss: 0.02716740220785141, dist_loss: 0.6012422442436218
recon_loss: 0.0271675493568182, dist_loss: 0.5791992545127869
recon_loss: 0.02716711536049843, dist_loss: 1.0380258560180664
recon_loss: 0.027168527245521545, dist_loss: 1.0234590768814087
recon_loss: 0.02716553583741188, dist_loss: 0.4795736074447632
recon_loss: 0.027166571468114853, dist_loss: 0.4371984004974365
recon_loss: 0.027165086939930916, dist_loss: 0.6767710447311401
recon_loss: 0.02716599963605404, dist_loss: 0.3915950059890747
recon_loss: 0.027165576815605164, dist_loss: 0.600954532623291
recon_loss: 0.027166850864887238, dist_loss: 0.42531490325927734
recon_loss: 0.02716817520558834, dist_loss: 0.4390432834625244
recon_loss: 0.027170274406671524, dist_loss: 0.48924753069877625
recon_loss: 0.027171306312084198, dist_loss: 0.6950754523277283
recon_loss: 0.027172842994332314, dist_loss: 0.7828255295753479
recon_loss: 0.02717290259897709, dist_loss: 0.729117751121521
recon_loss: 0.027171669527888298, dist_loss: 0.8092561960220337
recon_loss: 0.027169082313776016, dist_loss: 0.754041314125061
recon_loss: 0.0271676667034626, dist_loss: 0.696486234664917
recon_loss: 0.027166180312633514, dist_loss: 0.699192225933075
recon_loss: 0.027166176587343216, dist_loss: 0.49811866879463196
recon_loss: 0.027165403589606285, dist_loss: 1.150277853012085
recon_loss: 0.027165157720446587, dist_loss: 0.6286001205444336
recon_loss: 0.027165163308382034, dist_loss: 0.8692814111709595
recon_loss: 0.0271653700619936, dist_loss: 0.7776222825050354
recon_loss: 0.02716558612883091, dist_loss: 0.3267548084259033
recon_loss: 0.02716555818915367, dist_loss: 0.8535944819450378
recon_loss: 0.027165191248059273, dist_loss: 0.36739060282707214
recon_loss: 0.027164695784449577, dist_loss: 0.5103340744972229
recon_loss: 0.02716502733528614, dist_loss: 0.6464556455612183
recon_loss: 0.027164461091160774, dist_loss: 0.4351363182067871
recon_loss: 0.02716509811580181, dist_loss: 0.732822835445404
recon_loss: 0.027164889499545097, dist_loss: 0.4678974151611328
recon_loss: 0.027165532112121582, dist_loss: 1.0023094415664673
recon_loss: 0.02716551348567009, dist_loss: 1.0777318477630615
Pre-training Epoch 119:  71%|███████   | 261/367 [00:01<00:00, 154.34it/s]Pre-training Epoch 119:  75%|███████▌  | 277/367 [00:01<00:00, 153.29it/s]Pre-training Epoch 119:  80%|███████▉  | 293/367 [00:01<00:00, 154.39it/s]Pre-training Epoch 119:  84%|████████▍ | 309/367 [00:01<00:00, 155.46it/s]Pre-training Epoch 119:  89%|████████▊ | 325/367 [00:02<00:00, 154.60it/s]Pre-training Epoch 119:  93%|█████████▎| 343/367 [00:02<00:00, 160.65it/s]Pre-training Epoch 119:  98%|█████████▊| 361/367 [00:02<00:00, 165.52it/s]Pre-training Epoch 119: 100%|██████████| 367/367 [00:02<00:00, 162.95it/s]
recon_loss: 0.027165904641151428, dist_loss: 0.4071162939071655
recon_loss: 0.027165912091732025, dist_loss: 0.561894416809082
recon_loss: 0.027166275307536125, dist_loss: 0.9033148884773254
recon_loss: 0.02716618962585926, dist_loss: 0.6099083423614502
recon_loss: 0.02716573141515255, dist_loss: 0.6346465349197388
recon_loss: 0.02716553397476673, dist_loss: 0.547001838684082
recon_loss: 0.02716575562953949, dist_loss: 0.49266302585601807
recon_loss: 0.02716629020869732, dist_loss: 1.0120915174484253
recon_loss: 0.027166519314050674, dist_loss: 0.734195351600647
recon_loss: 0.027166463434696198, dist_loss: 0.6543287634849548
recon_loss: 0.027165520936250687, dist_loss: 0.8750953674316406
recon_loss: 0.027164751663804054, dist_loss: 0.6183935403823853
recon_loss: 0.02716478519141674, dist_loss: 0.9937809705734253
recon_loss: 0.02716447040438652, dist_loss: 0.7436130046844482
recon_loss: 0.02716420590877533, dist_loss: 0.5237593650817871
recon_loss: 0.02716384455561638, dist_loss: 1.1984883546829224
recon_loss: 0.027163947001099586, dist_loss: 0.7658320665359497
recon_loss: 0.0271642804145813, dist_loss: 0.5165557265281677
recon_loss: 0.027164416387677193, dist_loss: 0.5579928159713745
recon_loss: 0.027164172381162643, dist_loss: 0.9077619910240173
recon_loss: 0.027164114639163017, dist_loss: 0.7560330629348755
recon_loss: 0.02716386877000332, dist_loss: 0.5153521299362183
recon_loss: 0.027163395658135414, dist_loss: 0.5745402574539185
recon_loss: 0.027163047343492508, dist_loss: 0.4874737858772278
recon_loss: 0.027162734419107437, dist_loss: 0.4867255687713623
recon_loss: 0.02716245874762535, dist_loss: 0.4888307750225067
recon_loss: 0.027162406593561172, dist_loss: 1.1362700462341309
recon_loss: 0.02716260962188244, dist_loss: 0.4527297914028168
recon_loss: 0.0271625816822052, dist_loss: 0.6471923589706421
recon_loss: 0.027162546291947365, dist_loss: 0.7056859731674194
recon_loss: 0.02716241404414177, dist_loss: 0.7561041116714478
recon_loss: 0.02716246247291565, dist_loss: 0.534653902053833
recon_loss: 0.02716280333697796, dist_loss: 0.7966052293777466
recon_loss: 0.02716268040239811, dist_loss: 1.099776268005371
recon_loss: 0.02716243453323841, dist_loss: 0.6137762665748596
recon_loss: 0.027162417769432068, dist_loss: 0.5740206241607666
recon_loss: 0.027162402868270874, dist_loss: 0.6116378903388977
recon_loss: 0.02716248854994774, dist_loss: 0.3263402581214905
recon_loss: 0.027162518352270126, dist_loss: 0.6830204725265503
recon_loss: 0.0271623395383358, dist_loss: 0.5187007188796997
recon_loss: 0.027162624523043633, dist_loss: 0.279183566570282
recon_loss: 0.02716258354485035, dist_loss: 0.7085835933685303
recon_loss: 0.02716291882097721, dist_loss: 0.5142500400543213
recon_loss: 0.027163278311491013, dist_loss: 0.9350181818008423
recon_loss: 0.027164725586771965, dist_loss: 0.3783237040042877
recon_loss: 0.027165185660123825, dist_loss: 0.37956997752189636
recon_loss: 0.02716626226902008, dist_loss: 0.5087699294090271
recon_loss: 0.02716626226902008, dist_loss: 0.48720797896385193
recon_loss: 0.027166476473212242, dist_loss: 0.9053903222084045
recon_loss: 0.027165964245796204, dist_loss: 0.7297236919403076
recon_loss: 0.027165178209543228, dist_loss: 0.44652119278907776
recon_loss: 0.027164431288838387, dist_loss: 0.6876526474952698
recon_loss: 0.027163714170455933, dist_loss: 0.4744721055030823
recon_loss: 0.027163276448845863, dist_loss: 0.41896891593933105
recon_loss: 0.027163149788975716, dist_loss: 0.5598973035812378
recon_loss: 0.02716301567852497, dist_loss: 0.6389685869216919
recon_loss: 0.02716306783258915, dist_loss: 1.2081525325775146
recon_loss: 0.02716316655278206, dist_loss: 0.40076857805252075
recon_loss: 0.02716325782239437, dist_loss: 0.41335752606391907
recon_loss: 0.02716336026787758, dist_loss: 1.3416367769241333
recon_loss: 0.02716326154768467, dist_loss: 0.3213031589984894
recon_loss: 0.027163051068782806, dist_loss: 0.48324504494667053
recon_loss: 0.027162935584783554, dist_loss: 1.0721920728683472
recon_loss: 0.027162516489624977, dist_loss: 0.3767140507698059
recon_loss: 0.02716219238936901, dist_loss: 0.7782777547836304
recon_loss: 0.02716175466775894, dist_loss: 0.36596810817718506
recon_loss: 0.02716134302318096, dist_loss: 0.6082163453102112
recon_loss: 0.027161147445440292, dist_loss: 0.7029519081115723
recon_loss: 0.02716073766350746, dist_loss: 0.3823041319847107
recon_loss: 0.02716064453125, dist_loss: 0.7736192345619202
recon_loss: 0.02716098167002201, dist_loss: 1.0429010391235352
recon_loss: 0.027161285281181335, dist_loss: 0.9957946538925171
recon_loss: 0.02716142311692238, dist_loss: 0.6462417244911194
recon_loss: 0.027161847800016403, dist_loss: 0.5222766995429993
recon_loss: 0.027162371203303337, dist_loss: 1.0000158548355103
recon_loss: 0.027162661775946617, dist_loss: 0.45128095149993896
recon_loss: 0.027162615209817886, dist_loss: 0.7272338271141052
recon_loss: 0.02716234140098095, dist_loss: 0.5889361500740051
recon_loss: 0.02716238424181938, dist_loss: 0.31373533606529236
recon_loss: 0.027162108570337296, dist_loss: 0.5496590733528137
recon_loss: 0.02716253511607647, dist_loss: 1.0722901821136475
recon_loss: 0.027162503451108932, dist_loss: 0.5672618746757507
recon_loss: 0.027162732556462288, dist_loss: 0.8680762052536011
recon_loss: 0.02716280333697796, dist_loss: 0.597365140914917
recon_loss: 0.027163198217749596, dist_loss: 0.5150480270385742
recon_loss: 0.02716306410729885, dist_loss: 0.7644491195678711
recon_loss: 0.027162574231624603, dist_loss: 0.28319913148880005
recon_loss: 0.027162283658981323, dist_loss: 0.4145468473434448
recon_loss: 0.02716227062046528, dist_loss: 0.43022871017456055
recon_loss: 0.027161961421370506, dist_loss: 0.4813538193702698
recon_loss: 0.027162179350852966, dist_loss: 1.3151928186416626
recon_loss: 0.027162587270140648, dist_loss: 0.41591641306877136
recon_loss: 0.02716296911239624, dist_loss: 0.6525152921676636
recon_loss: 0.02716357633471489, dist_loss: 0.5339613556861877
recon_loss: 0.02716413140296936, dist_loss: 0.7710530757904053
recon_loss: 0.027164733037352562, dist_loss: 0.9552216529846191
recon_loss: 0.027166089043021202, dist_loss: 0.4484785497188568
recon_loss: 0.02716634050011635, dist_loss: 0.5519765615463257
recon_loss: 0.027167072519659996, dist_loss: 0.5616070628166199
recon_loss: 0.027166567742824554, dist_loss: 0.6146332621574402
recon_loss: 0.02716541476547718, dist_loss: 0.7543622255325317
recon_loss: 0.027163682505488396, dist_loss: 0.746752142906189
recon_loss: 0.027163127437233925, dist_loss: 0.38771599531173706
recon_loss: 0.02716223895549774, dist_loss: 0.5825076103210449
recon_loss: 0.02716280333697796, dist_loss: 0.7277910709381104
recon_loss: 0.02716294676065445, dist_loss: 0.7673772573471069
recon_loss: 0.027163544669747353, dist_loss: 0.6861730813980103
recon_loss: 0.027165275067090988, dist_loss: 0.5390727519989014
recon_loss: 0.027167225256562233, dist_loss: 0.8564995527267456
recon_loss: 0.02716902084648609, dist_loss: 0.7121201753616333
recon_loss: 0.027168644592165947, dist_loss: 1.1111472845077515
Pre-training Epoch 120:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 120:   5%|▍         | 17/367 [00:00<00:02, 169.06it/s]Pre-training Epoch 120:  10%|▉         | 35/367 [00:00<00:01, 173.00it/s]Pre-training Epoch 120:  15%|█▍        | 54/367 [00:00<00:01, 176.47it/s]Pre-training Epoch 120:  20%|█▉        | 72/367 [00:00<00:01, 177.47it/s]Pre-training Epoch 120:  25%|██▍       | 90/367 [00:00<00:01, 171.07it/s]Pre-training Epoch 120:  29%|██▉       | 108/367 [00:00<00:01, 172.93it/s]Pre-training Epoch 120:  34%|███▍      | 126/367 [00:00<00:01, 173.57it/s]recon_loss: 0.027167463675141335, dist_loss: 0.5215076208114624
recon_loss: 0.027166835963726044, dist_loss: 0.7885450720787048
recon_loss: 0.027165520936250687, dist_loss: 0.6669125556945801
recon_loss: 0.02716446854174137, dist_loss: 0.8893675804138184
recon_loss: 0.0271633081138134, dist_loss: 0.5872459411621094
recon_loss: 0.027162451297044754, dist_loss: 1.0856410264968872
recon_loss: 0.027161920443177223, dist_loss: 0.7649365663528442
recon_loss: 0.02716170996427536, dist_loss: 0.43839675188064575
recon_loss: 0.027161801233887672, dist_loss: 0.7294096946716309
recon_loss: 0.027162183076143265, dist_loss: 1.2606070041656494
recon_loss: 0.027163304388523102, dist_loss: 0.6618224382400513
recon_loss: 0.027164002880454063, dist_loss: 0.7713685035705566
recon_loss: 0.027164023369550705, dist_loss: 0.5519099831581116
recon_loss: 0.02716415748000145, dist_loss: 0.9968026876449585
recon_loss: 0.02716384083032608, dist_loss: 0.7653666734695435
recon_loss: 0.027163317427039146, dist_loss: 1.0461496114730835
recon_loss: 0.027162933722138405, dist_loss: 0.801953911781311
recon_loss: 0.02716268040239811, dist_loss: 0.9128122329711914
recon_loss: 0.02716234140098095, dist_loss: 0.7334768772125244
recon_loss: 0.027161642909049988, dist_loss: 0.897695004940033
recon_loss: 0.027161413803696632, dist_loss: 0.37668153643608093
recon_loss: 0.027161212638020515, dist_loss: 0.5205926895141602
recon_loss: 0.02716154046356678, dist_loss: 0.9208201169967651
recon_loss: 0.027161752805113792, dist_loss: 0.3308711647987366
recon_loss: 0.027162285521626472, dist_loss: 0.5475950241088867
recon_loss: 0.02716193161904812, dist_loss: 0.3363220691680908
recon_loss: 0.02716158702969551, dist_loss: 0.49065789580345154
recon_loss: 0.027161113917827606, dist_loss: 0.6945087909698486
recon_loss: 0.027161430567502975, dist_loss: 0.7981622815132141
recon_loss: 0.027161750942468643, dist_loss: 0.447897732257843
recon_loss: 0.027161816135048866, dist_loss: 0.6330550909042358
recon_loss: 0.02716130018234253, dist_loss: 0.6974552869796753
recon_loss: 0.027160722762346268, dist_loss: 0.773373544216156
recon_loss: 0.02716030552983284, dist_loss: 0.5590066313743591
recon_loss: 0.027159757912158966, dist_loss: 0.7218707799911499
recon_loss: 0.027159037068486214, dist_loss: 0.5620442628860474
recon_loss: 0.02715875208377838, dist_loss: 0.7210888266563416
recon_loss: 0.027159247547388077, dist_loss: 0.8678703308105469
recon_loss: 0.02715974673628807, dist_loss: 0.7670686841011047
recon_loss: 0.027160245925188065, dist_loss: 0.5621672868728638
recon_loss: 0.02716073952615261, dist_loss: 0.6643306016921997
recon_loss: 0.027160732075572014, dist_loss: 0.781031608581543
recon_loss: 0.027160244062542915, dist_loss: 0.5579526424407959
recon_loss: 0.02715984173119068, dist_loss: 0.8865851759910583
recon_loss: 0.02715941146016121, dist_loss: 0.4570702016353607
recon_loss: 0.027158789336681366, dist_loss: 0.8625823855400085
recon_loss: 0.0271585863083601, dist_loss: 0.3986763656139374
recon_loss: 0.027158189564943314, dist_loss: 0.550373911857605
recon_loss: 0.02715802937746048, dist_loss: 0.8203501105308533
recon_loss: 0.027157409116625786, dist_loss: 0.6192805767059326
recon_loss: 0.02715732902288437, dist_loss: 0.6408388614654541
recon_loss: 0.02715722844004631, dist_loss: 0.819685697555542
recon_loss: 0.027157016098499298, dist_loss: 1.3067882061004639
recon_loss: 0.02715710550546646, dist_loss: 0.3900045156478882
recon_loss: 0.02715730480849743, dist_loss: 0.9492268562316895
recon_loss: 0.027157725766301155, dist_loss: 0.5167748928070068
recon_loss: 0.027158286422491074, dist_loss: 0.48152491450309753
recon_loss: 0.027157887816429138, dist_loss: 0.25346022844314575
recon_loss: 0.027159063145518303, dist_loss: 0.4705519378185272
recon_loss: 0.02715841867029667, dist_loss: 0.6679275631904602
recon_loss: 0.027158483862876892, dist_loss: 0.5661299824714661
recon_loss: 0.027157871052622795, dist_loss: 0.6228242516517639
recon_loss: 0.027157289907336235, dist_loss: 0.33698907494544983
recon_loss: 0.02715691365301609, dist_loss: 0.3023639917373657
recon_loss: 0.027156975120306015, dist_loss: 0.8130955696105957
recon_loss: 0.027157260105013847, dist_loss: 0.4607834815979004
recon_loss: 0.027157457545399666, dist_loss: 1.6416704654693604
recon_loss: 0.027157384902238846, dist_loss: 0.8562487363815308
recon_loss: 0.027157455682754517, dist_loss: 0.8235200643539429
recon_loss: 0.027159230783581734, dist_loss: 0.6455929279327393
recon_loss: 0.02715781331062317, dist_loss: 0.568152666091919
recon_loss: 0.027158210054039955, dist_loss: 0.7334491014480591
recon_loss: 0.027158314362168312, dist_loss: 0.3175773024559021
recon_loss: 0.027158180251717567, dist_loss: 0.6355562806129456
recon_loss: 0.02715916931629181, dist_loss: 0.8348114490509033
recon_loss: 0.027159208431839943, dist_loss: 0.5398864150047302
recon_loss: 0.027160847559571266, dist_loss: 0.6187310218811035
recon_loss: 0.027160722762346268, dist_loss: 0.8871856331825256
recon_loss: 0.027162184938788414, dist_loss: 0.33510375022888184
recon_loss: 0.027162108570337296, dist_loss: 0.6282576322555542
recon_loss: 0.027163513004779816, dist_loss: 0.5904598236083984
recon_loss: 0.027163296937942505, dist_loss: 1.0387296676635742
recon_loss: 0.027162134647369385, dist_loss: 0.9029771089553833
recon_loss: 0.02716083824634552, dist_loss: 0.7610529661178589
recon_loss: 0.02716013975441456, dist_loss: 0.48062464594841003
recon_loss: 0.02716010808944702, dist_loss: 0.9822185039520264
recon_loss: 0.02716008760035038, dist_loss: 0.6980209350585938
recon_loss: 0.027160519734025, dist_loss: 0.7301980257034302
recon_loss: 0.027161315083503723, dist_loss: 0.47019460797309875
recon_loss: 0.02716362662613392, dist_loss: 0.5362297296524048
recon_loss: 0.02716522477567196, dist_loss: 0.38181963562965393
recon_loss: 0.027167262509465218, dist_loss: 0.43904632329940796
recon_loss: 0.027166243642568588, dist_loss: 0.43420302867889404
recon_loss: 0.027164625003933907, dist_loss: 0.5855240821838379
recon_loss: 0.02716316096484661, dist_loss: 0.762100100517273
recon_loss: 0.027161860838532448, dist_loss: 1.1049833297729492
recon_loss: 0.027161546051502228, dist_loss: 0.9580339193344116
recon_loss: 0.027159765362739563, dist_loss: 1.0016751289367676
recon_loss: 0.027158599346876144, dist_loss: 1.039381504058838
recon_loss: 0.027158686891198158, dist_loss: 0.575660228729248
recon_loss: 0.02715868502855301, dist_loss: 0.4295807480812073
recon_loss: 0.027160977944731712, dist_loss: 0.7084678411483765
recon_loss: 0.027161234989762306, dist_loss: 0.682305097579956
recon_loss: 0.02716338261961937, dist_loss: 0.3925435543060303
recon_loss: 0.027164224535226822, dist_loss: 0.5806686282157898
recon_loss: 0.027166366577148438, dist_loss: 0.643751323223114
recon_loss: 0.027164816856384277, dist_loss: 0.7592160701751709
recon_loss: 0.027163734659552574, dist_loss: 0.6027617454528809
recon_loss: 0.02716151438653469, dist_loss: 0.4662347137928009
recon_loss: 0.027160506695508957, dist_loss: 0.5934288501739502
recon_loss: 0.027159204706549644, dist_loss: 0.6730449199676514
recon_loss: 0.027158865705132484, dist_loss: 0.44290652871131897
recon_loss: 0.02715805359184742, dist_loss: 0.7901241779327393
recon_loss: 0.02715831995010376, dist_loss: 0.5963740348815918
recon_loss: 0.027158766984939575, dist_loss: 0.6845341324806213
recon_loss: 0.02716122567653656, dist_loss: 0.7073574066162109
recon_loss: 0.027163950726389885, dist_loss: 0.8476237058639526
recon_loss: 0.027169225737452507, dist_loss: 0.5988559722900391
recon_loss: 0.02717464789748192, dist_loss: 0.9612207412719727
recon_loss: 0.027179792523384094, dist_loss: 0.636796236038208
recon_loss: 0.02718406543135643, dist_loss: 0.4122195243835449
recon_loss: 0.027183987200260162, dist_loss: 0.7472440004348755
recon_loss: 0.027180004864931107, dist_loss: 0.45972028374671936
recon_loss: 0.027177290990948677, dist_loss: 0.6592377424240112
recon_loss: 0.02717496268451214, dist_loss: 1.1400213241577148
recon_loss: 0.027172058820724487, dist_loss: 0.6082870364189148
recon_loss: 0.027167443186044693, dist_loss: 0.5237176418304443
recon_loss: 0.027164798229932785, dist_loss: 0.5433829426765442
Pre-training Epoch 120:  39%|███▉      | 144/367 [00:00<00:01, 175.14it/s]Pre-training Epoch 120:  44%|████▍     | 162/367 [00:00<00:01, 175.78it/s]Pre-training Epoch 120:  49%|████▉     | 180/367 [00:01<00:01, 176.88it/s]Pre-training Epoch 120:  54%|█████▍    | 199/367 [00:01<00:00, 178.10it/s]Pre-training Epoch 120:  59%|█████▉    | 217/367 [00:01<00:00, 178.57it/s]Pre-training Epoch 120:  64%|██████▍   | 236/367 [00:01<00:00, 178.88it/s]Pre-training Epoch 120:  69%|██████▉   | 254/367 [00:01<00:00, 178.56it/s]recon_loss: 0.027163105085492134, dist_loss: 0.37696918845176697
recon_loss: 0.02716221660375595, dist_loss: 0.291969358921051
recon_loss: 0.02716209925711155, dist_loss: 0.6454611420631409
recon_loss: 0.027162306010723114, dist_loss: 0.4418887495994568
recon_loss: 0.027164172381162643, dist_loss: 0.4709748327732086
recon_loss: 0.027165956795215607, dist_loss: 0.9956305027008057
recon_loss: 0.027168720960617065, dist_loss: 0.48403453826904297
recon_loss: 0.027171561494469643, dist_loss: 0.9139574766159058
recon_loss: 0.027175527065992355, dist_loss: 0.6803898215293884
recon_loss: 0.02717689797282219, dist_loss: 0.6045448184013367
recon_loss: 0.02717953734099865, dist_loss: 0.903285801410675
recon_loss: 0.027179528027772903, dist_loss: 0.5771200656890869
recon_loss: 0.027179650962352753, dist_loss: 0.419323593378067
recon_loss: 0.027176013216376305, dist_loss: 0.6665841341018677
recon_loss: 0.02717476524412632, dist_loss: 0.7415170669555664
recon_loss: 0.027170047163963318, dist_loss: 0.4740414321422577
recon_loss: 0.027168110013008118, dist_loss: 0.8064274787902832
recon_loss: 0.027164913713932037, dist_loss: 0.8427950739860535
recon_loss: 0.027164386585354805, dist_loss: 0.5543423891067505
recon_loss: 0.027161596342921257, dist_loss: 0.7955418229103088
recon_loss: 0.02716141939163208, dist_loss: 0.7609559297561646
recon_loss: 0.02716069482266903, dist_loss: 0.4065982699394226
recon_loss: 0.02716096304357052, dist_loss: 0.8927255868911743
recon_loss: 0.027160566300153732, dist_loss: 0.7085543274879456
recon_loss: 0.027161238715052605, dist_loss: 0.560737133026123
recon_loss: 0.02716056816279888, dist_loss: 0.42291057109832764
recon_loss: 0.02716025337576866, dist_loss: 0.7107932567596436
recon_loss: 0.02715991996228695, dist_loss: 0.727454662322998
recon_loss: 0.027159366756677628, dist_loss: 0.8085629940032959
recon_loss: 0.027159174904227257, dist_loss: 1.0082616806030273
recon_loss: 0.02715850993990898, dist_loss: 0.30322474241256714
recon_loss: 0.02715802937746048, dist_loss: 0.5405656099319458
recon_loss: 0.027157464995980263, dist_loss: 0.48958852887153625
recon_loss: 0.02715705893933773, dist_loss: 0.4392472505569458
recon_loss: 0.027156246826052666, dist_loss: 0.6232213973999023
recon_loss: 0.027155887335538864, dist_loss: 0.701927900314331
recon_loss: 0.027154970914125443, dist_loss: 0.8064770102500916
recon_loss: 0.027154607698321342, dist_loss: 0.8966062068939209
recon_loss: 0.027154449373483658, dist_loss: 0.42570650577545166
recon_loss: 0.02715451829135418, dist_loss: 0.7003489136695862
recon_loss: 0.027153965085744858, dist_loss: 0.7268615365028381
recon_loss: 0.027154061943292618, dist_loss: 0.3855172395706177
recon_loss: 0.027154596522450447, dist_loss: 0.6068822741508484
recon_loss: 0.02715662121772766, dist_loss: 0.7086013555526733
recon_loss: 0.02715781331062317, dist_loss: 0.39330244064331055
recon_loss: 0.027159688994288445, dist_loss: 0.7293121814727783
recon_loss: 0.027159379795193672, dist_loss: 0.6818719506263733
recon_loss: 0.027158377692103386, dist_loss: 0.5844006538391113
recon_loss: 0.0271576177328825, dist_loss: 1.1580419540405273
recon_loss: 0.027156846597790718, dist_loss: 0.4396457374095917
recon_loss: 0.02715643309056759, dist_loss: 0.8096391558647156
recon_loss: 0.027156176045536995, dist_loss: 0.514466404914856
recon_loss: 0.027155689895153046, dist_loss: 0.5440115928649902
recon_loss: 0.027155611664056778, dist_loss: 0.40110981464385986
recon_loss: 0.027153728529810905, dist_loss: 0.5568557381629944
recon_loss: 0.027153780683875084, dist_loss: 0.47806161642074585
recon_loss: 0.027152281254529953, dist_loss: 0.5109409093856812
recon_loss: 0.027152160182595253, dist_loss: 0.6934740543365479
recon_loss: 0.027151599526405334, dist_loss: 0.600104570388794
recon_loss: 0.027151262387633324, dist_loss: 1.0747225284576416
recon_loss: 0.027151042595505714, dist_loss: 0.985602617263794
recon_loss: 0.02715117298066616, dist_loss: 0.8524643182754517
recon_loss: 0.02715100347995758, dist_loss: 0.6659753918647766
recon_loss: 0.0271508377045393, dist_loss: 0.749177873134613
recon_loss: 0.02715064398944378, dist_loss: 0.6193546056747437
recon_loss: 0.02715054526925087, dist_loss: 0.37056487798690796
recon_loss: 0.027150487527251244, dist_loss: 0.4810764491558075
recon_loss: 0.027150453999638557, dist_loss: 0.525629997253418
recon_loss: 0.027150465175509453, dist_loss: 0.9110522270202637
recon_loss: 0.02715047262609005, dist_loss: 0.9393907785415649
recon_loss: 0.02715056762099266, dist_loss: 0.6109591722488403
recon_loss: 0.027150558307766914, dist_loss: 0.22861260175704956
recon_loss: 0.02715112827718258, dist_loss: 0.7782859206199646
recon_loss: 0.02715127356350422, dist_loss: 0.8411255478858948
recon_loss: 0.027150921523571014, dist_loss: 0.49922388792037964
recon_loss: 0.027151042595505714, dist_loss: 0.9481951594352722
recon_loss: 0.027150729671120644, dist_loss: 0.5155879259109497
recon_loss: 0.027150027453899384, dist_loss: 0.6707316637039185
recon_loss: 0.027149677276611328, dist_loss: 0.786352276802063
recon_loss: 0.027149712666869164, dist_loss: 0.6816485524177551
recon_loss: 0.027149632573127747, dist_loss: 0.5287584066390991
recon_loss: 0.02715001255273819, dist_loss: 0.5919471383094788
recon_loss: 0.027150819078087807, dist_loss: 0.47067683935165405
recon_loss: 0.027152005583047867, dist_loss: 0.7448486089706421
recon_loss: 0.027152318507432938, dist_loss: 0.6732416152954102
recon_loss: 0.027152806520462036, dist_loss: 0.7247408628463745
recon_loss: 0.027152447029948235, dist_loss: 0.6726888418197632
recon_loss: 0.027152899652719498, dist_loss: 0.568504810333252
recon_loss: 0.027152488008141518, dist_loss: 0.490959107875824
recon_loss: 0.027151942253112793, dist_loss: 0.4670320749282837
recon_loss: 0.027151988819241524, dist_loss: 0.7458716630935669
recon_loss: 0.027151156216859818, dist_loss: 0.4832649827003479
recon_loss: 0.027150653302669525, dist_loss: 0.515039324760437
recon_loss: 0.02715017832815647, dist_loss: 0.56777024269104
recon_loss: 0.02715020254254341, dist_loss: 0.4584307074546814
recon_loss: 0.027149571105837822, dist_loss: 0.6114425659179688
recon_loss: 0.027149470522999763, dist_loss: 0.9244566559791565
recon_loss: 0.02714892104268074, dist_loss: 0.4705890715122223
recon_loss: 0.02714899554848671, dist_loss: 1.1415047645568848
recon_loss: 0.02714894339442253, dist_loss: 0.4848872423171997
recon_loss: 0.02714969404041767, dist_loss: 0.3059554696083069
recon_loss: 0.02715029940009117, dist_loss: 0.4076152741909027
recon_loss: 0.027150914072990417, dist_loss: 0.6433790922164917
recon_loss: 0.027150386944413185, dist_loss: 0.2878933846950531
recon_loss: 0.027150288224220276, dist_loss: 0.5242651104927063
recon_loss: 0.027149666100740433, dist_loss: 0.6716458797454834
recon_loss: 0.02714942768216133, dist_loss: 0.545575737953186
recon_loss: 0.02714972011744976, dist_loss: 0.5813202857971191
recon_loss: 0.027149828150868416, dist_loss: 1.1055339574813843
recon_loss: 0.0271505955606699, dist_loss: 0.4784035086631775
recon_loss: 0.027150703594088554, dist_loss: 0.6113594770431519
recon_loss: 0.027151741087436676, dist_loss: 0.5283817648887634
recon_loss: 0.02715255692601204, dist_loss: 0.5807719826698303
recon_loss: 0.027153417468070984, dist_loss: 0.789799690246582
recon_loss: 0.02715403214097023, dist_loss: 0.9667615294456482
recon_loss: 0.027156131342053413, dist_loss: 0.32499998807907104
recon_loss: 0.027158131822943687, dist_loss: 0.6075454950332642
recon_loss: 0.02715923637151718, dist_loss: 0.40001624822616577
recon_loss: 0.027158506214618683, dist_loss: 0.5884811878204346
recon_loss: 0.027159560471773148, dist_loss: 0.42905914783477783
recon_loss: 0.02715836837887764, dist_loss: 0.5451633930206299
recon_loss: 0.027158085256814957, dist_loss: 0.7420772314071655
recon_loss: 0.027155650779604912, dist_loss: 0.6783807277679443
recon_loss: 0.027153782546520233, dist_loss: 0.48434603214263916
recon_loss: 0.027153311297297478, dist_loss: 0.7444874048233032
recon_loss: 0.027153104543685913, dist_loss: 0.3523443937301636
recon_loss: 0.02715296857059002, dist_loss: 0.5659754276275635
recon_loss: 0.027152923867106438, dist_loss: 0.3220116198062897
Pre-training Epoch 120:  74%|███████▍  | 272/367 [00:01<00:00, 162.77it/s]Pre-training Epoch 120:  79%|███████▊  | 289/367 [00:01<00:00, 160.90it/s]Pre-training Epoch 120:  83%|████████▎ | 306/367 [00:01<00:00, 157.89it/s]Pre-training Epoch 120:  88%|████████▊ | 324/367 [00:01<00:00, 162.01it/s]Pre-training Epoch 120:  93%|█████████▎| 342/367 [00:02<00:00, 166.79it/s]Pre-training Epoch 120:  98%|█████████▊| 360/367 [00:02<00:00, 170.53it/s]Pre-training Epoch 120: 100%|██████████| 367/367 [00:02<00:00, 171.43it/s]
recon_loss: 0.027152489870786667, dist_loss: 0.5453057289123535
recon_loss: 0.027152100577950478, dist_loss: 1.122944712638855
recon_loss: 0.027151795104146004, dist_loss: 0.3925131559371948
recon_loss: 0.027151567861437798, dist_loss: 0.32353782653808594
recon_loss: 0.027151642367243767, dist_loss: 0.760390043258667
recon_loss: 0.027150489389896393, dist_loss: 0.9455351829528809
recon_loss: 0.027151674032211304, dist_loss: 0.5422149300575256
recon_loss: 0.027150267735123634, dist_loss: 0.6453669667243958
recon_loss: 0.027151495218276978, dist_loss: 0.3525141477584839
recon_loss: 0.0271508377045393, dist_loss: 0.37960317730903625
recon_loss: 0.027152031660079956, dist_loss: 1.0720617771148682
recon_loss: 0.027150439098477364, dist_loss: 0.37631481885910034
recon_loss: 0.02715039998292923, dist_loss: 0.5847384929656982
recon_loss: 0.027149634435772896, dist_loss: 1.0523872375488281
recon_loss: 0.027148539200425148, dist_loss: 0.5824980139732361
recon_loss: 0.027148060500621796, dist_loss: 0.6556563973426819
recon_loss: 0.027147682383656502, dist_loss: 0.6443215608596802
recon_loss: 0.027147868648171425, dist_loss: 0.3466523587703705
recon_loss: 0.027147620916366577, dist_loss: 0.48651427030563354
recon_loss: 0.027148058637976646, dist_loss: 0.6651304364204407
recon_loss: 0.027148351073265076, dist_loss: 0.40866437554359436
recon_loss: 0.02714906632900238, dist_loss: 0.5048561692237854
recon_loss: 0.02714916504919529, dist_loss: 0.5682375431060791
recon_loss: 0.02714935690164566, dist_loss: 0.722075343132019
recon_loss: 0.027150481939315796, dist_loss: 0.2633984684944153
recon_loss: 0.027152232825756073, dist_loss: 0.6094276905059814
recon_loss: 0.027153484523296356, dist_loss: 0.4383131265640259
recon_loss: 0.027153847739100456, dist_loss: 0.3958142399787903
recon_loss: 0.027153993025422096, dist_loss: 0.7659896612167358
recon_loss: 0.02715286985039711, dist_loss: 0.3294640779495239
recon_loss: 0.0271516852080822, dist_loss: 0.7277226448059082
recon_loss: 0.02715100720524788, dist_loss: 0.6566356420516968
recon_loss: 0.027149764820933342, dist_loss: 1.109184741973877
recon_loss: 0.02714935876429081, dist_loss: 0.8045250773429871
recon_loss: 0.027149053290486336, dist_loss: 0.6356109976768494
recon_loss: 0.027150072157382965, dist_loss: 0.4355488419532776
recon_loss: 0.027151433750987053, dist_loss: 0.49570661783218384
recon_loss: 0.027152419090270996, dist_loss: 0.5643106698989868
recon_loss: 0.027153974398970604, dist_loss: 0.4549766778945923
recon_loss: 0.027155034244060516, dist_loss: 0.5198056697845459
recon_loss: 0.027155354619026184, dist_loss: 0.8753696084022522
recon_loss: 0.027155572548508644, dist_loss: 0.46307724714279175
recon_loss: 0.027154119685292244, dist_loss: 0.5743471384048462
recon_loss: 0.027153262868523598, dist_loss: 0.5497716069221497
recon_loss: 0.02715192921459675, dist_loss: 1.0256297588348389
recon_loss: 0.027150921523571014, dist_loss: 0.5364300012588501
recon_loss: 0.02714991383254528, dist_loss: 0.8029723167419434
recon_loss: 0.027149565517902374, dist_loss: 0.5782924890518188
recon_loss: 0.027149660512804985, dist_loss: 0.6305211782455444
recon_loss: 0.02715015783905983, dist_loss: 0.6561387777328491
recon_loss: 0.027150919660925865, dist_loss: 0.6736923456192017
recon_loss: 0.027151666581630707, dist_loss: 0.19352343678474426
recon_loss: 0.02715211547911167, dist_loss: 0.25616157054901123
recon_loss: 0.02715354599058628, dist_loss: 0.529483437538147
recon_loss: 0.027153510600328445, dist_loss: 0.31974440813064575
recon_loss: 0.027153819799423218, dist_loss: 0.6477080583572388
recon_loss: 0.027152899652719498, dist_loss: 0.8252383470535278
recon_loss: 0.027152378112077713, dist_loss: 0.587563157081604
recon_loss: 0.02715061604976654, dist_loss: 0.9095951318740845
recon_loss: 0.027149243280291557, dist_loss: 0.43707406520843506
recon_loss: 0.027148492634296417, dist_loss: 0.5080195665359497
recon_loss: 0.02714829333126545, dist_loss: 0.6716411709785461
recon_loss: 0.027148442342877388, dist_loss: 0.950257420539856
recon_loss: 0.027147896587848663, dist_loss: 0.7267789840698242
recon_loss: 0.027147648856043816, dist_loss: 0.8115366697311401
recon_loss: 0.027147525921463966, dist_loss: 0.5335954427719116
recon_loss: 0.02714739367365837, dist_loss: 0.7000409364700317
recon_loss: 0.02714712917804718, dist_loss: 0.6933290362358093
recon_loss: 0.027147311717271805, dist_loss: 0.7771119475364685
recon_loss: 0.027147142216563225, dist_loss: 1.2040008306503296
recon_loss: 0.027147574350237846, dist_loss: 0.6187069416046143
recon_loss: 0.02714797668159008, dist_loss: 0.7685937285423279
recon_loss: 0.027149027213454247, dist_loss: 0.8728817701339722
recon_loss: 0.027150260284543037, dist_loss: 0.39360249042510986
recon_loss: 0.027150698006153107, dist_loss: 0.6840009689331055
recon_loss: 0.027150604873895645, dist_loss: 0.5868794918060303
recon_loss: 0.027150793001055717, dist_loss: 0.7597099542617798
recon_loss: 0.027149753645062447, dist_loss: 0.36898237466812134
recon_loss: 0.02714877761900425, dist_loss: 0.5811922550201416
recon_loss: 0.027147553861141205, dist_loss: 0.4702253043651581
recon_loss: 0.02714668959379196, dist_loss: 1.5455090999603271
recon_loss: 0.027147546410560608, dist_loss: 0.47363805770874023
recon_loss: 0.027146508917212486, dist_loss: 0.6368657350540161
recon_loss: 0.02714836411178112, dist_loss: 0.5070433616638184
recon_loss: 0.027148714289069176, dist_loss: 0.38268300890922546
recon_loss: 0.027150975540280342, dist_loss: 0.8307853937149048
recon_loss: 0.027151355519890785, dist_loss: 0.39163118600845337
recon_loss: 0.027151890099048615, dist_loss: 1.100242018699646
recon_loss: 0.02715114876627922, dist_loss: 0.4586801528930664
recon_loss: 0.02714962512254715, dist_loss: 0.2280270904302597
recon_loss: 0.027148636057972908, dist_loss: 0.6338652968406677
recon_loss: 0.02714724652469158, dist_loss: 0.6040356159210205
recon_loss: 0.0271465927362442, dist_loss: 0.4810541272163391
recon_loss: 0.02714633382856846, dist_loss: 0.6659690141677856
recon_loss: 0.027146290987730026, dist_loss: 0.799246072769165
recon_loss: 0.02714543789625168, dist_loss: 0.39053401350975037
recon_loss: 0.02714534103870392, dist_loss: 0.5152544379234314
recon_loss: 0.02714533917605877, dist_loss: 0.42665883898735046
recon_loss: 0.027145033702254295, dist_loss: 0.5608159899711609
recon_loss: 0.027145443484187126, dist_loss: 0.6364544034004211
recon_loss: 0.027145644649863243, dist_loss: 0.7816705703735352
recon_loss: 0.027146685868501663, dist_loss: 0.6566716432571411
recon_loss: 0.027146557345986366, dist_loss: 1.0401811599731445
recon_loss: 0.027145983651280403, dist_loss: 0.5485473275184631
recon_loss: 0.02714499831199646, dist_loss: 0.5247894525527954
recon_loss: 0.027144765481352806, dist_loss: 0.5016680955886841
recon_loss: 0.027144422754645348, dist_loss: 0.8520660400390625
recon_loss: 0.027144838124513626, dist_loss: 0.347187340259552
recon_loss: 0.027144603431224823, dist_loss: 0.7235136032104492
recon_loss: 0.027145100757479668, dist_loss: 0.47373831272125244
recon_loss: 0.027146363630890846, dist_loss: 0.5343732237815857
Pre-train Epoch: 120
Train - Total Loss: 0.0914, Recon Loss: 0.0272, Dist Loss: 0.6424, l1 regularization: 0.0000
Val - Total Loss: 0.0961, Recon Loss: 0.0271, Dist Loss: 0.6898, l1 regularization: 0.0000
Pre-training Epoch 121:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 121:   5%|▍         | 18/367 [00:00<00:02, 170.61it/s]Pre-training Epoch 121:  10%|▉         | 36/367 [00:00<00:01, 174.36it/s]Pre-training Epoch 121:  15%|█▍        | 54/367 [00:00<00:01, 176.48it/s]Pre-training Epoch 121:  20%|█▉        | 73/367 [00:00<00:01, 178.58it/s]Pre-training Epoch 121:  25%|██▍       | 91/367 [00:00<00:01, 178.06it/s]Pre-training Epoch 121:  30%|██▉       | 109/367 [00:00<00:01, 167.54it/s]Pre-training Epoch 121:  34%|███▍      | 126/367 [00:00<00:01, 164.28it/s]recon_loss: 0.027147768065333366, dist_loss: 0.3941011428833008
recon_loss: 0.027149394154548645, dist_loss: 0.43588656187057495
recon_loss: 0.027151139453053474, dist_loss: 0.4038962423801422
recon_loss: 0.02715264819562435, dist_loss: 0.6709563136100769
recon_loss: 0.02715243399143219, dist_loss: 0.5131047368049622
recon_loss: 0.02715102955698967, dist_loss: 0.5404506921768188
recon_loss: 0.027150051668286324, dist_loss: 0.9110355377197266
recon_loss: 0.02714979462325573, dist_loss: 0.8948957324028015
recon_loss: 0.027148595079779625, dist_loss: 0.3805106580257416
recon_loss: 0.027147239074110985, dist_loss: 0.7192023992538452
recon_loss: 0.02714606001973152, dist_loss: 0.32318413257598877
recon_loss: 0.02714516408741474, dist_loss: 0.6276048421859741
recon_loss: 0.027144700288772583, dist_loss: 0.7053076028823853
recon_loss: 0.02714443765580654, dist_loss: 0.6290407776832581
recon_loss: 0.027144353836774826, dist_loss: 0.6903930902481079
recon_loss: 0.027144655585289, dist_loss: 0.5441781282424927
recon_loss: 0.027145203202962875, dist_loss: 0.49832284450531006
recon_loss: 0.02714572474360466, dist_loss: 0.40363216400146484
recon_loss: 0.0271465927362442, dist_loss: 0.5279523134231567
recon_loss: 0.027146868407726288, dist_loss: 0.9644391536712646
recon_loss: 0.02714652009308338, dist_loss: 0.679016649723053
recon_loss: 0.027146071195602417, dist_loss: 0.9178084135055542
recon_loss: 0.02714614011347294, dist_loss: 0.822446346282959
recon_loss: 0.02714557759463787, dist_loss: 0.4425535500049591
recon_loss: 0.027145978063344955, dist_loss: 0.8189297318458557
recon_loss: 0.027144145220518112, dist_loss: 0.8191696405410767
recon_loss: 0.0271446630358696, dist_loss: 0.46914535760879517
recon_loss: 0.027144024148583412, dist_loss: 0.6930394172668457
recon_loss: 0.027145542204380035, dist_loss: 0.8950480222702026
recon_loss: 0.027145175263285637, dist_loss: 0.38671600818634033
recon_loss: 0.02714628353714943, dist_loss: 0.3621375262737274
recon_loss: 0.0271452683955431, dist_loss: 0.7143496870994568
recon_loss: 0.027146274223923683, dist_loss: 0.3923567533493042
recon_loss: 0.027145978063344955, dist_loss: 0.9081646203994751
recon_loss: 0.02714633196592331, dist_loss: 0.6652891635894775
recon_loss: 0.02714613825082779, dist_loss: 0.8164429664611816
recon_loss: 0.027145380154252052, dist_loss: 0.3884641230106354
recon_loss: 0.027146533131599426, dist_loss: 0.5229905843734741
recon_loss: 0.027145706117153168, dist_loss: 0.4123076796531677
recon_loss: 0.02714843861758709, dist_loss: 0.670752763748169
recon_loss: 0.02714754268527031, dist_loss: 0.6766741871833801
recon_loss: 0.027149200439453125, dist_loss: 0.562267541885376
recon_loss: 0.027148619294166565, dist_loss: 0.4804195761680603
recon_loss: 0.0271488968282938, dist_loss: 0.8886943459510803
recon_loss: 0.027148770168423653, dist_loss: 0.8111146092414856
recon_loss: 0.027147790417075157, dist_loss: 0.4297782778739929
recon_loss: 0.027147740125656128, dist_loss: 0.6161244511604309
recon_loss: 0.027147555723786354, dist_loss: 0.6103562116622925
recon_loss: 0.02714819274842739, dist_loss: 0.9002453088760376
recon_loss: 0.027146922424435616, dist_loss: 0.5465371608734131
recon_loss: 0.027146857231855392, dist_loss: 0.3113325834274292
recon_loss: 0.027145544067025185, dist_loss: 0.7004002332687378
recon_loss: 0.0271455068141222, dist_loss: 0.8552447557449341
recon_loss: 0.02714538387954235, dist_loss: 0.617997944355011
recon_loss: 0.02714540809392929, dist_loss: 0.639321506023407
recon_loss: 0.027145616710186005, dist_loss: 0.506679117679596
recon_loss: 0.02714519202709198, dist_loss: 0.5845571160316467
recon_loss: 0.027145039290189743, dist_loss: 0.9146454930305481
recon_loss: 0.027144208550453186, dist_loss: 0.8614732623100281
recon_loss: 0.02714453637599945, dist_loss: 0.9420375823974609
recon_loss: 0.027143804356455803, dist_loss: 0.7003612518310547
recon_loss: 0.027144571766257286, dist_loss: 1.1066627502441406
recon_loss: 0.027144910767674446, dist_loss: 1.0334182977676392
recon_loss: 0.02714565582573414, dist_loss: 0.8336451649665833
recon_loss: 0.027145622298121452, dist_loss: 0.7505700588226318
recon_loss: 0.02714538387954235, dist_loss: 0.38658642768859863
recon_loss: 0.027144933119416237, dist_loss: 0.3156052529811859
recon_loss: 0.027144305408000946, dist_loss: 0.6873407959938049
recon_loss: 0.02714350074529648, dist_loss: 0.7425926923751831
recon_loss: 0.027142945677042007, dist_loss: 0.4433091878890991
recon_loss: 0.027142439037561417, dist_loss: 1.2290887832641602
recon_loss: 0.027142299339175224, dist_loss: 0.44652259349823
recon_loss: 0.02714177779853344, dist_loss: 0.6202499270439148
recon_loss: 0.027141869068145752, dist_loss: 0.7374977469444275
recon_loss: 0.02714161016047001, dist_loss: 0.43154439330101013
recon_loss: 0.027141882106661797, dist_loss: 0.6964443922042847
recon_loss: 0.027141069993376732, dist_loss: 0.6544924378395081
recon_loss: 0.02714092656970024, dist_loss: 0.4362812042236328
recon_loss: 0.027140598744153976, dist_loss: 0.8289018869400024
recon_loss: 0.027141017839312553, dist_loss: 0.4165409207344055
recon_loss: 0.027140585705637932, dist_loss: 0.9044358730316162
recon_loss: 0.027141250669956207, dist_loss: 0.8457159996032715
recon_loss: 0.027140798047184944, dist_loss: 0.40130653977394104
recon_loss: 0.027140945196151733, dist_loss: 0.5258654356002808
recon_loss: 0.027140432968735695, dist_loss: 0.9589786529541016
recon_loss: 0.027141183614730835, dist_loss: 0.8449593186378479
recon_loss: 0.027141649276018143, dist_loss: 0.5449180603027344
recon_loss: 0.027142515406012535, dist_loss: 1.1490588188171387
recon_loss: 0.027144620195031166, dist_loss: 0.8283746838569641
recon_loss: 0.02714548632502556, dist_loss: 0.31070876121520996
recon_loss: 0.02714678645133972, dist_loss: 0.3631089925765991
recon_loss: 0.027147194370627403, dist_loss: 0.5667903423309326
recon_loss: 0.02714870125055313, dist_loss: 0.5418813824653625
recon_loss: 0.027147334069013596, dist_loss: 0.6068923473358154
recon_loss: 0.02714703045785427, dist_loss: 1.220569133758545
recon_loss: 0.027145618572831154, dist_loss: 0.6672041416168213
recon_loss: 0.02714555896818638, dist_loss: 0.6307737827301025
recon_loss: 0.02714359387755394, dist_loss: 0.7072026133537292
recon_loss: 0.027143042534589767, dist_loss: 0.4887049198150635
recon_loss: 0.02714201994240284, dist_loss: 0.34637096524238586
recon_loss: 0.027141442522406578, dist_loss: 0.5475350618362427
recon_loss: 0.027141518890857697, dist_loss: 0.8033108115196228
recon_loss: 0.027141248807311058, dist_loss: 0.45100468397140503
recon_loss: 0.027141353115439415, dist_loss: 0.37897273898124695
recon_loss: 0.027141977101564407, dist_loss: 0.5028183460235596
recon_loss: 0.02714208886027336, dist_loss: 0.8192232847213745
recon_loss: 0.02714288793504238, dist_loss: 0.9031378030776978
recon_loss: 0.027142543345689774, dist_loss: 0.72153639793396
recon_loss: 0.027142221108078957, dist_loss: 0.7309319972991943
recon_loss: 0.027141274884343147, dist_loss: 0.754725456237793
recon_loss: 0.027140337973833084, dist_loss: 0.4720127582550049
recon_loss: 0.027139421552419662, dist_loss: 0.6553155779838562
recon_loss: 0.02714013308286667, dist_loss: 0.8872219324111938
recon_loss: 0.0271393284201622, dist_loss: 0.8317563533782959
recon_loss: 0.02713962458074093, dist_loss: 0.7098076343536377
recon_loss: 0.02713942527770996, dist_loss: 0.6226644515991211
recon_loss: 0.027140561491250992, dist_loss: 0.5377292037010193
recon_loss: 0.027140676975250244, dist_loss: 0.7270262837409973
recon_loss: 0.027142386883497238, dist_loss: 0.49561113119125366
recon_loss: 0.027141591534018517, dist_loss: 0.9310033321380615
recon_loss: 0.02714117057621479, dist_loss: 0.5465245246887207
recon_loss: 0.027140360325574875, dist_loss: 0.8189511299133301
recon_loss: 0.027139244601130486, dist_loss: 0.38333016633987427
recon_loss: 0.027138132601976395, dist_loss: 0.615201473236084
recon_loss: 0.027137603610754013, dist_loss: 0.5309355854988098
recon_loss: 0.02713753655552864, dist_loss: 0.5746210813522339
recon_loss: 0.02713780291378498, dist_loss: 0.4562002122402191
recon_loss: 0.02713806927204132, dist_loss: 0.8329970836639404
Pre-training Epoch 121:  39%|███▉      | 144/367 [00:00<00:01, 168.58it/s]Pre-training Epoch 121:  44%|████▍     | 161/367 [00:00<00:01, 164.46it/s]Pre-training Epoch 121:  49%|████▊     | 178/367 [00:01<00:01, 161.67it/s]Pre-training Epoch 121:  53%|█████▎    | 195/367 [00:01<00:01, 159.72it/s]Pre-training Epoch 121:  58%|█████▊    | 212/367 [00:01<00:00, 158.06it/s]Pre-training Epoch 121:  62%|██████▏   | 228/367 [00:01<00:00, 156.11it/s]Pre-training Epoch 121:  66%|██████▋   | 244/367 [00:01<00:00, 154.29it/s]recon_loss: 0.027139192447066307, dist_loss: 0.7954481840133667
recon_loss: 0.027141014114022255, dist_loss: 0.3884006440639496
recon_loss: 0.027142951264977455, dist_loss: 0.6400876045227051
recon_loss: 0.027144497260451317, dist_loss: 0.8092203736305237
recon_loss: 0.02714480459690094, dist_loss: 0.6334353685379028
recon_loss: 0.027144864201545715, dist_loss: 0.6449549198150635
recon_loss: 0.027143826708197594, dist_loss: 0.7003806829452515
recon_loss: 0.02714378945529461, dist_loss: 0.3964933753013611
recon_loss: 0.027142606675624847, dist_loss: 0.4350188374519348
recon_loss: 0.027142144739627838, dist_loss: 1.3036112785339355
recon_loss: 0.027141675353050232, dist_loss: 0.5753173232078552
recon_loss: 0.027141205966472626, dist_loss: 0.6853317618370056
recon_loss: 0.027139855548739433, dist_loss: 0.9714528322219849
recon_loss: 0.027139076963067055, dist_loss: 1.0237762928009033
recon_loss: 0.027139604091644287, dist_loss: 0.8438822031021118
recon_loss: 0.027140164747834206, dist_loss: 0.5266098976135254
recon_loss: 0.02714128978550434, dist_loss: 0.7423603534698486
recon_loss: 0.027142556384205818, dist_loss: 0.589931845664978
recon_loss: 0.0271439328789711, dist_loss: 0.3765937089920044
recon_loss: 0.02714408189058304, dist_loss: 0.5113255977630615
recon_loss: 0.027143653482198715, dist_loss: 1.0065827369689941
recon_loss: 0.027142234146595, dist_loss: 0.1944185495376587
recon_loss: 0.02714122273027897, dist_loss: 0.589653730392456
recon_loss: 0.02713974379003048, dist_loss: 0.721311092376709
recon_loss: 0.027138669043779373, dist_loss: 0.5047539472579956
recon_loss: 0.027138102799654007, dist_loss: 0.6479870676994324
recon_loss: 0.027138100937008858, dist_loss: 1.0042107105255127
recon_loss: 0.027138084173202515, dist_loss: 0.41988611221313477
recon_loss: 0.02713806927204132, dist_loss: 0.5245859622955322
recon_loss: 0.02713826298713684, dist_loss: 0.4267933666706085
recon_loss: 0.02713809534907341, dist_loss: 0.5811017155647278
recon_loss: 0.027138376608490944, dist_loss: 0.42083972692489624
recon_loss: 0.027138957753777504, dist_loss: 0.726986289024353
recon_loss: 0.027139833196997643, dist_loss: 0.7595292329788208
recon_loss: 0.02714010886847973, dist_loss: 0.5099092721939087
recon_loss: 0.02714097872376442, dist_loss: 0.6434489488601685
recon_loss: 0.027140794321894646, dist_loss: 0.4561259150505066
recon_loss: 0.02714281715452671, dist_loss: 1.1535789966583252
recon_loss: 0.02714235894382, dist_loss: 0.5488002300262451
recon_loss: 0.027142906561493874, dist_loss: 0.8911975622177124
recon_loss: 0.027141161262989044, dist_loss: 0.42574235796928406
recon_loss: 0.027140729129314423, dist_loss: 0.6652130484580994
recon_loss: 0.0271388441324234, dist_loss: 0.42418962717056274
recon_loss: 0.027139678597450256, dist_loss: 0.6022823452949524
recon_loss: 0.02713777869939804, dist_loss: 0.5780268907546997
recon_loss: 0.02713887020945549, dist_loss: 0.41101956367492676
recon_loss: 0.027137592434883118, dist_loss: 0.5594038963317871
recon_loss: 0.027139099314808846, dist_loss: 0.41577577590942383
recon_loss: 0.027137475088238716, dist_loss: 0.5433965921401978
recon_loss: 0.027138417586684227, dist_loss: 0.6711283922195435
recon_loss: 0.027137726545333862, dist_loss: 0.6786143779754639
recon_loss: 0.027138344943523407, dist_loss: 0.7211514115333557
recon_loss: 0.027138076722621918, dist_loss: 0.7059875130653381
recon_loss: 0.027138279750943184, dist_loss: 0.5584092140197754
recon_loss: 0.027138425037264824, dist_loss: 0.6752021312713623
recon_loss: 0.027137793600559235, dist_loss: 0.9327564239501953
recon_loss: 0.02713901363313198, dist_loss: 0.5391525626182556
recon_loss: 0.027137838304042816, dist_loss: 0.9800307750701904
recon_loss: 0.02713909186422825, dist_loss: 0.4571637213230133
recon_loss: 0.027137696743011475, dist_loss: 0.5949371457099915
recon_loss: 0.027138298377394676, dist_loss: 0.44300222396850586
recon_loss: 0.027137216180562973, dist_loss: 0.4163908064365387
recon_loss: 0.027138369157910347, dist_loss: 0.5797344446182251
recon_loss: 0.027137450873851776, dist_loss: 0.7366609573364258
recon_loss: 0.02713782899081707, dist_loss: 0.845319390296936
recon_loss: 0.027137180790305138, dist_loss: 0.24280354380607605
recon_loss: 0.027137391269207, dist_loss: 0.8793830871582031
recon_loss: 0.02713727578520775, dist_loss: 0.6268312335014343
recon_loss: 0.0271369069814682, dist_loss: 0.5867270231246948
recon_loss: 0.027138356119394302, dist_loss: 1.1702954769134521
recon_loss: 0.0271384846419096, dist_loss: 0.5168341398239136
recon_loss: 0.027141036465764046, dist_loss: 0.9484288692474365
recon_loss: 0.02714119851589203, dist_loss: 0.8952900767326355
recon_loss: 0.02714262530207634, dist_loss: 0.4788611829280853
recon_loss: 0.02714078687131405, dist_loss: 0.5341684818267822
recon_loss: 0.027140337973833084, dist_loss: 0.4308943748474121
recon_loss: 0.027139266952872276, dist_loss: 0.7246674299240112
recon_loss: 0.027138754725456238, dist_loss: 1.355677843093872
recon_loss: 0.027138283476233482, dist_loss: 0.4544985890388489
recon_loss: 0.027138741686940193, dist_loss: 0.7858714461326599
recon_loss: 0.02714044600725174, dist_loss: 0.5502628087997437
recon_loss: 0.02714243344962597, dist_loss: 0.541438102722168
recon_loss: 0.02714548073709011, dist_loss: 0.4657577872276306
recon_loss: 0.02714715152978897, dist_loss: 0.6480718851089478
recon_loss: 0.02714943327009678, dist_loss: 0.3460702896118164
recon_loss: 0.027147747576236725, dist_loss: 0.7080326080322266
recon_loss: 0.027146736159920692, dist_loss: 0.9455345273017883
recon_loss: 0.02714475803077221, dist_loss: 0.8410046100616455
recon_loss: 0.027143778279423714, dist_loss: 0.5053539276123047
recon_loss: 0.02714281901717186, dist_loss: 1.0258476734161377
recon_loss: 0.02714124135673046, dist_loss: 0.7946372628211975
recon_loss: 0.0271406639367342, dist_loss: 0.7025806903839111
recon_loss: 0.027140188962221146, dist_loss: 0.7390254139900208
recon_loss: 0.027141408994793892, dist_loss: 0.8630408048629761
recon_loss: 0.027142591774463654, dist_loss: 0.5914055109024048
recon_loss: 0.027145689353346825, dist_loss: 0.5071980953216553
recon_loss: 0.02714678645133972, dist_loss: 0.5716457366943359
recon_loss: 0.027148082852363586, dist_loss: 1.2090907096862793
recon_loss: 0.02714652381837368, dist_loss: 0.6462279558181763
recon_loss: 0.02714541368186474, dist_loss: 0.49749666452407837
recon_loss: 0.027143385261297226, dist_loss: 0.4640478789806366
recon_loss: 0.027142230421304703, dist_loss: 0.4344342350959778
recon_loss: 0.027141720056533813, dist_loss: 1.024394154548645
recon_loss: 0.02714097499847412, dist_loss: 0.9766346216201782
recon_loss: 0.027140546590089798, dist_loss: 0.4806581437587738
recon_loss: 0.02713950164616108, dist_loss: 0.6626111268997192
recon_loss: 0.02713940292596817, dist_loss: 0.32238030433654785
recon_loss: 0.02713928557932377, dist_loss: 0.7410392165184021
recon_loss: 0.027139490470290184, dist_loss: 0.7202214002609253
recon_loss: 0.02714073285460472, dist_loss: 0.3597974181175232
recon_loss: 0.027141554281115532, dist_loss: 0.4960654079914093
recon_loss: 0.027143631130456924, dist_loss: 0.6617367267608643
recon_loss: 0.027143685147166252, dist_loss: 0.6953000426292419
recon_loss: 0.027146300300955772, dist_loss: 0.3933113217353821
recon_loss: 0.027146991342306137, dist_loss: 0.5513815879821777
recon_loss: 0.027150414884090424, dist_loss: 0.7421875596046448
recon_loss: 0.02715006284415722, dist_loss: 0.7759283781051636
recon_loss: 0.0271510798484087, dist_loss: 1.0623936653137207
recon_loss: 0.02715146727859974, dist_loss: 0.6976206302642822
recon_loss: 0.027150463312864304, dist_loss: 0.5819591283798218
recon_loss: 0.02715012989938259, dist_loss: 0.45544931292533875
recon_loss: 0.027147384360432625, dist_loss: 0.3563891649246216
recon_loss: 0.02714560180902481, dist_loss: 0.8286349177360535
recon_loss: 0.027143355458974838, dist_loss: 0.5183455944061279
recon_loss: 0.027142425999045372, dist_loss: 0.5387468338012695
recon_loss: 0.027140656486153603, dist_loss: 0.27189165353775024
recon_loss: 0.027139758691191673, dist_loss: 0.49261319637298584
recon_loss: 0.027138810604810715, dist_loss: 0.3092237710952759
Pre-training Epoch 121:  71%|███████   | 260/367 [00:01<00:00, 153.27it/s]Pre-training Epoch 121:  75%|███████▌  | 276/367 [00:01<00:00, 153.86it/s]Pre-training Epoch 121:  80%|███████▉  | 292/367 [00:01<00:00, 154.39it/s]Pre-training Epoch 121:  84%|████████▍ | 308/367 [00:01<00:00, 152.01it/s]Pre-training Epoch 121:  88%|████████▊ | 324/367 [00:02<00:00, 153.15it/s]Pre-training Epoch 121:  93%|█████████▎| 340/367 [00:02<00:00, 153.98it/s]Pre-training Epoch 121:  97%|█████████▋| 356/367 [00:02<00:00, 154.22it/s]Pre-training Epoch 121: 100%|██████████| 367/367 [00:02<00:00, 160.09it/s]
recon_loss: 0.02713944762945175, dist_loss: 0.3144419193267822
recon_loss: 0.02713967300951481, dist_loss: 0.809050440788269
recon_loss: 0.02714093215763569, dist_loss: 0.8367875814437866
recon_loss: 0.0271423552185297, dist_loss: 0.5528039932250977
recon_loss: 0.02714403346180916, dist_loss: 0.700677216053009
recon_loss: 0.027144255116581917, dist_loss: 0.9948161244392395
recon_loss: 0.02714432403445244, dist_loss: 0.3811434507369995
recon_loss: 0.027143755927681923, dist_loss: 0.5591599941253662
recon_loss: 0.02714378573000431, dist_loss: 0.580632209777832
recon_loss: 0.027144191786646843, dist_loss: 0.7216958403587341
recon_loss: 0.027144618332386017, dist_loss: 0.5315855145454407
recon_loss: 0.027143707498908043, dist_loss: 0.49718594551086426
recon_loss: 0.02714281901717186, dist_loss: 0.7046589851379395
recon_loss: 0.027142036706209183, dist_loss: 1.0563673973083496
recon_loss: 0.02714136615395546, dist_loss: 1.0355268716812134
recon_loss: 0.027140535414218903, dist_loss: 0.5086796283721924
recon_loss: 0.027140270918607712, dist_loss: 0.4255172610282898
recon_loss: 0.027140308171510696, dist_loss: 0.4988686740398407
recon_loss: 0.02714056521654129, dist_loss: 0.6587409377098083
recon_loss: 0.027140676975250244, dist_loss: 0.6553718447685242
recon_loss: 0.027140453457832336, dist_loss: 0.495440274477005
recon_loss: 0.027139805257320404, dist_loss: 0.5221753120422363
recon_loss: 0.027139244601130486, dist_loss: 0.6938149929046631
recon_loss: 0.027138717472553253, dist_loss: 0.5845074653625488
recon_loss: 0.027138778939843178, dist_loss: 1.3938279151916504
recon_loss: 0.027139518409967422, dist_loss: 0.9463321566581726
recon_loss: 0.02713990956544876, dist_loss: 0.5786457061767578
recon_loss: 0.02714042365550995, dist_loss: 0.5865637063980103
recon_loss: 0.02713998779654503, dist_loss: 0.5227919816970825
recon_loss: 0.02714025042951107, dist_loss: 0.6240259408950806
recon_loss: 0.027139632031321526, dist_loss: 0.6075913310050964
recon_loss: 0.02713968977332115, dist_loss: 0.5271643996238708
recon_loss: 0.027140311896800995, dist_loss: 0.9064303636550903
recon_loss: 0.027140608057379723, dist_loss: 0.6262718439102173
recon_loss: 0.0271401796489954, dist_loss: 0.4185793995857239
recon_loss: 0.027139706537127495, dist_loss: 0.3699489235877991
recon_loss: 0.027139393612742424, dist_loss: 0.8324289917945862
recon_loss: 0.027138877660036087, dist_loss: 0.6240805983543396
recon_loss: 0.027138739824295044, dist_loss: 0.7669275999069214
recon_loss: 0.027139628306031227, dist_loss: 0.511167049407959
recon_loss: 0.027141403406858444, dist_loss: 0.7444536089897156
recon_loss: 0.027142472565174103, dist_loss: 0.2886660099029541
recon_loss: 0.02714221552014351, dist_loss: 0.44789499044418335
recon_loss: 0.027143150568008423, dist_loss: 0.8440602421760559
recon_loss: 0.02714373916387558, dist_loss: 0.8476181626319885
recon_loss: 0.02714395709335804, dist_loss: 0.5676621794700623
recon_loss: 0.027142897248268127, dist_loss: 0.5846140384674072
recon_loss: 0.027140211313962936, dist_loss: 0.5166376233100891
recon_loss: 0.02713794633746147, dist_loss: 0.4903216063976288
recon_loss: 0.027136433869600296, dist_loss: 0.539770245552063
recon_loss: 0.027135685086250305, dist_loss: 0.44809943437576294
recon_loss: 0.0271354578435421, dist_loss: 0.31618380546569824
recon_loss: 0.02713523991405964, dist_loss: 0.5108293294906616
recon_loss: 0.027135472744703293, dist_loss: 0.4790727496147156
recon_loss: 0.027135612443089485, dist_loss: 0.7448422908782959
recon_loss: 0.02713623084127903, dist_loss: 0.9389318227767944
recon_loss: 0.027135852724313736, dist_loss: 0.6665279865264893
recon_loss: 0.0271358173340559, dist_loss: 0.7152315974235535
recon_loss: 0.02713511325418949, dist_loss: 0.5763621926307678
recon_loss: 0.027134448289871216, dist_loss: 0.589685320854187
recon_loss: 0.027134211733937263, dist_loss: 0.7405470609664917
recon_loss: 0.027134263888001442, dist_loss: 0.937900960445404
recon_loss: 0.027134230360388756, dist_loss: 0.7590153217315674
recon_loss: 0.027134031057357788, dist_loss: 0.45182785391807556
recon_loss: 0.02713359147310257, dist_loss: 0.8645271062850952
recon_loss: 0.02713342383503914, dist_loss: 0.9200940728187561
recon_loss: 0.02713283896446228, dist_loss: 0.8801535367965698
recon_loss: 0.0271326694637537, dist_loss: 0.6026675701141357
recon_loss: 0.027132822200655937, dist_loss: 0.6161895394325256
recon_loss: 0.02713341824710369, dist_loss: 0.5869734287261963
recon_loss: 0.027133986353874207, dist_loss: 0.4773458242416382
recon_loss: 0.027134262025356293, dist_loss: 0.5218901038169861
recon_loss: 0.027134045958518982, dist_loss: 0.8571145534515381
recon_loss: 0.02713397890329361, dist_loss: 0.5153481960296631
recon_loss: 0.02713346853852272, dist_loss: 0.5289781093597412
recon_loss: 0.027133459225296974, dist_loss: 0.7046655416488647
recon_loss: 0.027132365852594376, dist_loss: 0.7719570398330688
recon_loss: 0.027132652699947357, dist_loss: 0.5054123997688293
recon_loss: 0.02713201940059662, dist_loss: 0.907912015914917
recon_loss: 0.0271327942609787, dist_loss: 0.4996165335178375
recon_loss: 0.02713252231478691, dist_loss: 0.8445839285850525
recon_loss: 0.02713315561413765, dist_loss: 0.47805607318878174
recon_loss: 0.027133550494909286, dist_loss: 0.47107869386672974
recon_loss: 0.027133038267493248, dist_loss: 0.6017010807991028
recon_loss: 0.027132926508784294, dist_loss: 1.0478625297546387
recon_loss: 0.027132384479045868, dist_loss: 0.8679015636444092
recon_loss: 0.0271323099732399, dist_loss: 0.5709198117256165
recon_loss: 0.027131710201501846, dist_loss: 0.526140570640564
recon_loss: 0.027131101116538048, dist_loss: 0.26009973883628845
recon_loss: 0.02713032066822052, dist_loss: 0.8422574996948242
recon_loss: 0.027130329981446266, dist_loss: 0.2892920970916748
recon_loss: 0.02712959609925747, dist_loss: 0.9751577973365784
recon_loss: 0.02712998539209366, dist_loss: 0.5587729215621948
recon_loss: 0.027129370719194412, dist_loss: 0.4193704128265381
recon_loss: 0.02713000401854515, dist_loss: 0.7958210110664368
recon_loss: 0.027129800990223885, dist_loss: 0.43517476320266724
recon_loss: 0.027130335569381714, dist_loss: 1.0049391984939575
recon_loss: 0.027129773050546646, dist_loss: 0.45573481917381287
recon_loss: 0.02713024988770485, dist_loss: 0.46570953726768494
recon_loss: 0.027129823341965675, dist_loss: 0.6048052310943604
recon_loss: 0.027129430323839188, dist_loss: 0.497730553150177
recon_loss: 0.0271286778151989, dist_loss: 0.690400242805481
recon_loss: 0.027128761634230614, dist_loss: 0.5790959596633911
recon_loss: 0.027128048241138458, dist_loss: 0.48769611120224
recon_loss: 0.02712811529636383, dist_loss: 0.7050649523735046
recon_loss: 0.027127504348754883, dist_loss: 0.574016273021698
recon_loss: 0.02712765894830227, dist_loss: 0.4781453609466553
recon_loss: 0.027127476409077644, dist_loss: 0.8154921531677246
recon_loss: 0.027127567678689957, dist_loss: 0.5138592720031738
recon_loss: 0.027127468958497047, dist_loss: 0.6446123123168945
recon_loss: 0.027127254754304886, dist_loss: 0.2544132173061371
Pre-training Epoch 122:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 122:   5%|▍         | 18/367 [00:00<00:02, 170.78it/s]Pre-training Epoch 122:  10%|▉         | 36/367 [00:00<00:01, 174.90it/s]Pre-training Epoch 122:  15%|█▍        | 54/367 [00:00<00:01, 174.73it/s]Pre-training Epoch 122:  20%|█▉        | 72/367 [00:00<00:01, 176.05it/s]Pre-training Epoch 122:  25%|██▍       | 90/367 [00:00<00:01, 177.23it/s]Pre-training Epoch 122:  29%|██▉       | 108/367 [00:00<00:01, 175.33it/s]Pre-training Epoch 122:  34%|███▍      | 126/367 [00:00<00:01, 164.12it/s]recon_loss: 0.027127504348754883, dist_loss: 0.3616243898868561
recon_loss: 0.027127837762236595, dist_loss: 0.6787636280059814
recon_loss: 0.027128025889396667, dist_loss: 0.4091246724128723
recon_loss: 0.027128780260682106, dist_loss: 0.4377806782722473
recon_loss: 0.027129728347063065, dist_loss: 0.6195138692855835
recon_loss: 0.02713022567331791, dist_loss: 0.8525409698486328
recon_loss: 0.027130121365189552, dist_loss: 0.4457712769508362
recon_loss: 0.02712908945977688, dist_loss: 0.42053189873695374
recon_loss: 0.02712886407971382, dist_loss: 0.5184051990509033
recon_loss: 0.027128376066684723, dist_loss: 0.7605839967727661
recon_loss: 0.02712792530655861, dist_loss: 0.6751139760017395
recon_loss: 0.02712726779282093, dist_loss: 1.3942413330078125
recon_loss: 0.027127275243401527, dist_loss: 0.49823033809661865
recon_loss: 0.02712753601372242, dist_loss: 0.9214293956756592
recon_loss: 0.02712835557758808, dist_loss: 0.7408262491226196
recon_loss: 0.027129288762807846, dist_loss: 0.49149131774902344
recon_loss: 0.02712949551641941, dist_loss: 0.8496862053871155
recon_loss: 0.02713015489280224, dist_loss: 0.5136224031448364
recon_loss: 0.027130478993058205, dist_loss: 0.4844517409801483
recon_loss: 0.027131572365760803, dist_loss: 0.3695526719093323
recon_loss: 0.027133090421557426, dist_loss: 0.6637030839920044
recon_loss: 0.027132762596011162, dist_loss: 0.7484163045883179
recon_loss: 0.027132989838719368, dist_loss: 0.8509119749069214
recon_loss: 0.02713228203356266, dist_loss: 0.6129729747772217
recon_loss: 0.02713155746459961, dist_loss: 1.0611017942428589
recon_loss: 0.02713089808821678, dist_loss: 0.8890756368637085
recon_loss: 0.02713051810860634, dist_loss: 0.6566063165664673
recon_loss: 0.02713051252067089, dist_loss: 1.0211491584777832
recon_loss: 0.02713109739124775, dist_loss: 0.5513077974319458
recon_loss: 0.027132296934723854, dist_loss: 0.7030956745147705
recon_loss: 0.027132131159305573, dist_loss: 0.8635902404785156
recon_loss: 0.027132337912917137, dist_loss: 0.5607304573059082
recon_loss: 0.0271320603787899, dist_loss: 0.6372374892234802
recon_loss: 0.027132084593176842, dist_loss: 0.5695606470108032
recon_loss: 0.027130864560604095, dist_loss: 0.22057130932807922
recon_loss: 0.027130167931318283, dist_loss: 0.4927692115306854
recon_loss: 0.027128994464874268, dist_loss: 0.5834423303604126
recon_loss: 0.02712864801287651, dist_loss: 0.5075157880783081
recon_loss: 0.027127647772431374, dist_loss: 0.6425864696502686
recon_loss: 0.02712729200720787, dist_loss: 0.5468446016311646
recon_loss: 0.02712673507630825, dist_loss: 1.0044312477111816
recon_loss: 0.027126533910632133, dist_loss: 0.6568515300750732
recon_loss: 0.027127062901854515, dist_loss: 0.6928678750991821
recon_loss: 0.027127444744110107, dist_loss: 1.1096450090408325
recon_loss: 0.027127817273139954, dist_loss: 0.6962335109710693
recon_loss: 0.027128273621201515, dist_loss: 0.6579552888870239
recon_loss: 0.02712883986532688, dist_loss: 0.7504186630249023
recon_loss: 0.02712911367416382, dist_loss: 1.1235363483428955
recon_loss: 0.027129052206873894, dist_loss: 0.544574499130249
recon_loss: 0.02712886407971382, dist_loss: 0.7372382879257202
recon_loss: 0.0271285530179739, dist_loss: 0.8898752927780151
recon_loss: 0.027128415182232857, dist_loss: 1.0006308555603027
recon_loss: 0.027128152549266815, dist_loss: 0.4732694625854492
recon_loss: 0.0271278228610754, dist_loss: 0.7404663562774658
recon_loss: 0.027127232402563095, dist_loss: 0.4883168935775757
recon_loss: 0.02712695114314556, dist_loss: 1.078500747680664
recon_loss: 0.027126824483275414, dist_loss: 0.528843879699707
recon_loss: 0.027126725763082504, dist_loss: 0.5320782661437988
recon_loss: 0.027127012610435486, dist_loss: 0.3241417109966278
recon_loss: 0.027127394452691078, dist_loss: 0.5995795726776123
recon_loss: 0.02712765708565712, dist_loss: 0.6456549167633057
recon_loss: 0.027127552777528763, dist_loss: 0.483844518661499
recon_loss: 0.027127090841531754, dist_loss: 0.8617962598800659
recon_loss: 0.027126669883728027, dist_loss: 0.7888404130935669
recon_loss: 0.027126578614115715, dist_loss: 0.6092885136604309
recon_loss: 0.027126088738441467, dist_loss: 0.6992336511611938
recon_loss: 0.027125736698508263, dist_loss: 0.5418808460235596
recon_loss: 0.0271257683634758, dist_loss: 0.5209405422210693
recon_loss: 0.027126995846629143, dist_loss: 0.5997570157051086
recon_loss: 0.02712906152009964, dist_loss: 0.5665909051895142
recon_loss: 0.027131840586662292, dist_loss: 0.43597084283828735
recon_loss: 0.027133852243423462, dist_loss: 0.3838822841644287
recon_loss: 0.027136748656630516, dist_loss: 0.598841667175293
recon_loss: 0.027137435972690582, dist_loss: 0.6094522476196289
recon_loss: 0.0271378755569458, dist_loss: 0.5388781428337097
recon_loss: 0.027136661112308502, dist_loss: 0.4019804298877716
recon_loss: 0.027135642245411873, dist_loss: 0.5159937143325806
recon_loss: 0.02713373489677906, dist_loss: 0.4956058859825134
recon_loss: 0.027132146060466766, dist_loss: 0.5548041462898254
recon_loss: 0.02713075466454029, dist_loss: 0.41283074021339417
recon_loss: 0.027131497859954834, dist_loss: 0.8025883436203003
recon_loss: 0.02713419497013092, dist_loss: 0.3635788559913635
recon_loss: 0.027137111872434616, dist_loss: 0.6734824180603027
recon_loss: 0.027140002697706223, dist_loss: 0.8225921392440796
recon_loss: 0.027144143357872963, dist_loss: 0.56844562292099
recon_loss: 0.02714800089597702, dist_loss: 0.7190821170806885
recon_loss: 0.027149295434355736, dist_loss: 0.8096571564674377
recon_loss: 0.027148794382810593, dist_loss: 0.5582453012466431
recon_loss: 0.027147140353918076, dist_loss: 1.040554165840149
recon_loss: 0.027144577354192734, dist_loss: 0.8193478584289551
recon_loss: 0.027141230180859566, dist_loss: 0.3884696066379547
recon_loss: 0.02713773027062416, dist_loss: 0.5403293371200562
recon_loss: 0.02713705413043499, dist_loss: 0.4472734034061432
recon_loss: 0.027136873453855515, dist_loss: 0.8476603031158447
recon_loss: 0.027137285098433495, dist_loss: 0.2783479690551758
recon_loss: 0.027137720957398415, dist_loss: 0.880768895149231
recon_loss: 0.027136879041790962, dist_loss: 1.1176815032958984
recon_loss: 0.027135781943798065, dist_loss: 0.6113026142120361
recon_loss: 0.02713371068239212, dist_loss: 0.6287007331848145
recon_loss: 0.02713221125304699, dist_loss: 0.6043459177017212
recon_loss: 0.027130423113703728, dist_loss: 0.3559759557247162
recon_loss: 0.02712957002222538, dist_loss: 0.6196448802947998
recon_loss: 0.02712799794971943, dist_loss: 0.6110649704933167
recon_loss: 0.027127867564558983, dist_loss: 0.7897669076919556
recon_loss: 0.02712675742805004, dist_loss: 0.8463476300239563
recon_loss: 0.027126671746373177, dist_loss: 0.8354246020317078
recon_loss: 0.0271257683634758, dist_loss: 0.45286089181900024
recon_loss: 0.027125878259539604, dist_loss: 0.7186103463172913
recon_loss: 0.027125731110572815, dist_loss: 0.5192126035690308
recon_loss: 0.027125539258122444, dist_loss: 0.7168200016021729
recon_loss: 0.027125859633088112, dist_loss: 0.8930259943008423
recon_loss: 0.027125772088766098, dist_loss: 0.4167199730873108
recon_loss: 0.027125585824251175, dist_loss: 0.4868302345275879
recon_loss: 0.027125699445605278, dist_loss: 0.6564015746116638
recon_loss: 0.027126552537083626, dist_loss: 0.7760508060455322
recon_loss: 0.02712651900947094, dist_loss: 0.6304901838302612
recon_loss: 0.02712787128984928, dist_loss: 0.5052716732025146
recon_loss: 0.027128344401717186, dist_loss: 0.6667578220367432
recon_loss: 0.027128271758556366, dist_loss: 0.8538574576377869
recon_loss: 0.02712886594235897, dist_loss: 0.6237511038780212
recon_loss: 0.027128182351589203, dist_loss: 0.9489578604698181
recon_loss: 0.02712814137339592, dist_loss: 0.9670777320861816
recon_loss: 0.027127886191010475, dist_loss: 0.49871402978897095
recon_loss: 0.027128083631396294, dist_loss: 0.8326034545898438
recon_loss: 0.02712792158126831, dist_loss: 0.6729916334152222
recon_loss: 0.027127835899591446, dist_loss: 0.27627527713775635
recon_loss: 0.027127519249916077, dist_loss: 0.5399433374404907
recon_loss: 0.02712707780301571, dist_loss: 0.4889700412750244
Pre-training Epoch 122:  39%|███▉      | 143/367 [00:00<00:01, 159.58it/s]Pre-training Epoch 122:  44%|████▎     | 160/367 [00:00<00:01, 155.17it/s]Pre-training Epoch 122:  48%|████▊     | 176/367 [00:01<00:01, 155.37it/s]Pre-training Epoch 122:  53%|█████▎    | 194/367 [00:01<00:01, 161.97it/s]Pre-training Epoch 122:  58%|█████▊    | 212/367 [00:01<00:00, 165.12it/s]Pre-training Epoch 122:  62%|██████▏   | 229/367 [00:01<00:00, 163.07it/s]Pre-training Epoch 122:  67%|██████▋   | 246/367 [00:01<00:00, 160.33it/s]recon_loss: 0.027126584202051163, dist_loss: 0.33852526545524597
recon_loss: 0.027126433327794075, dist_loss: 0.6743948459625244
recon_loss: 0.027125943452119827, dist_loss: 0.6503733396530151
recon_loss: 0.027125617489218712, dist_loss: 0.9523015022277832
recon_loss: 0.027125049382448196, dist_loss: 0.6506903767585754
recon_loss: 0.02712485007941723, dist_loss: 0.6546995639801025
recon_loss: 0.027124548330903053, dist_loss: 0.7124576568603516
recon_loss: 0.027124544605612755, dist_loss: 0.7135907411575317
recon_loss: 0.02712494693696499, dist_loss: 0.47494569420814514
recon_loss: 0.027125602588057518, dist_loss: 0.6919260025024414
recon_loss: 0.027126038447022438, dist_loss: 0.5348079204559326
recon_loss: 0.027127105742692947, dist_loss: 0.6779330968856812
recon_loss: 0.027127450332045555, dist_loss: 0.6921193599700928
recon_loss: 0.027127940207719803, dist_loss: 0.34048524498939514
recon_loss: 0.027128159999847412, dist_loss: 0.5908979177474976
recon_loss: 0.027128515765070915, dist_loss: 0.46476688981056213
recon_loss: 0.02712767757475376, dist_loss: 0.6023403406143188
recon_loss: 0.02712693065404892, dist_loss: 0.4042399525642395
recon_loss: 0.027125800028443336, dist_loss: 0.7822499871253967
recon_loss: 0.02712552435696125, dist_loss: 0.7602667808532715
recon_loss: 0.027124540880322456, dist_loss: 0.9525619745254517
recon_loss: 0.027124466374516487, dist_loss: 0.7150098085403442
recon_loss: 0.027123965322971344, dist_loss: 0.928497314453125
recon_loss: 0.02712380699813366, dist_loss: 0.5151607990264893
recon_loss: 0.02712373621761799, dist_loss: 0.5584203004837036
recon_loss: 0.027123551815748215, dist_loss: 0.38503435254096985
recon_loss: 0.027123531326651573, dist_loss: 0.5897510051727295
recon_loss: 0.027122920379042625, dist_loss: 0.8245866298675537
recon_loss: 0.02712246961891651, dist_loss: 0.46491748094558716
recon_loss: 0.027122540399432182, dist_loss: 0.5161214470863342
recon_loss: 0.02712303213775158, dist_loss: 0.48504966497421265
recon_loss: 0.02712375670671463, dist_loss: 0.9896784424781799
recon_loss: 0.027124039828777313, dist_loss: 0.4720023274421692
recon_loss: 0.027124036103487015, dist_loss: 0.8009756207466125
recon_loss: 0.027123456820845604, dist_loss: 0.567752480506897
recon_loss: 0.027124088257551193, dist_loss: 0.8829255104064941
recon_loss: 0.02712331898510456, dist_loss: 0.5337597131729126
recon_loss: 0.027124201878905296, dist_loss: 0.5357680320739746
recon_loss: 0.02712341770529747, dist_loss: 0.3139779567718506
recon_loss: 0.027125848457217216, dist_loss: 0.35442981123924255
recon_loss: 0.027124343439936638, dist_loss: 0.4591262638568878
recon_loss: 0.027126118540763855, dist_loss: 0.8361366987228394
recon_loss: 0.02712378278374672, dist_loss: 0.6774172186851501
recon_loss: 0.027123937383294106, dist_loss: 0.32003793120384216
recon_loss: 0.027122927829623222, dist_loss: 0.5163105130195618
recon_loss: 0.027122702449560165, dist_loss: 0.5730741620063782
recon_loss: 0.027122583240270615, dist_loss: 0.31875815987586975
recon_loss: 0.027122395113110542, dist_loss: 0.5038982033729553
recon_loss: 0.027122214436531067, dist_loss: 0.6368553638458252
recon_loss: 0.02712208218872547, dist_loss: 1.0470417737960815
recon_loss: 0.027122311294078827, dist_loss: 0.6346762180328369
recon_loss: 0.027122238650918007, dist_loss: 0.38399291038513184
recon_loss: 0.027122247964143753, dist_loss: 1.0018435716629028
recon_loss: 0.02712254598736763, dist_loss: 1.5924901962280273
recon_loss: 0.027124086394906044, dist_loss: 0.6937148571014404
recon_loss: 0.02712724730372429, dist_loss: 0.34930697083473206
recon_loss: 0.027130845934152603, dist_loss: 0.4767342805862427
recon_loss: 0.027134191244840622, dist_loss: 0.652503490447998
recon_loss: 0.027137383818626404, dist_loss: 0.3897613286972046
recon_loss: 0.02713862434029579, dist_loss: 0.6219083070755005
recon_loss: 0.0271394494920969, dist_loss: 0.4299018681049347
recon_loss: 0.02713898941874504, dist_loss: 1.0941087007522583
recon_loss: 0.027139514684677124, dist_loss: 0.5426737070083618
recon_loss: 0.027138710021972656, dist_loss: 0.6773502826690674
recon_loss: 0.027138883247971535, dist_loss: 0.515030026435852
recon_loss: 0.027135111391544342, dist_loss: 1.2380473613739014
recon_loss: 0.027133308351039886, dist_loss: 0.6467429995536804
recon_loss: 0.027131030336022377, dist_loss: 0.5767243504524231
recon_loss: 0.0271303690969944, dist_loss: 0.4051624536514282
recon_loss: 0.027128158137202263, dist_loss: 0.6860569715499878
recon_loss: 0.027127938345074654, dist_loss: 0.6420646905899048
recon_loss: 0.02712767757475376, dist_loss: 0.639094352722168
recon_loss: 0.02712731808423996, dist_loss: 0.513674795627594
recon_loss: 0.027128543704748154, dist_loss: 0.5812209844589233
recon_loss: 0.027127357199788094, dist_loss: 0.712502658367157
recon_loss: 0.027128685265779495, dist_loss: 0.6160027980804443
recon_loss: 0.027127204462885857, dist_loss: 0.5391590595245361
recon_loss: 0.027127522975206375, dist_loss: 0.6188123226165771
recon_loss: 0.027126621454954147, dist_loss: 0.48038867115974426
recon_loss: 0.027126342058181763, dist_loss: 1.0195045471191406
recon_loss: 0.02712518721818924, dist_loss: 0.7402762174606323
recon_loss: 0.02712411805987358, dist_loss: 0.5544945001602173
recon_loss: 0.027123427018523216, dist_loss: 0.6799628734588623
recon_loss: 0.027122652158141136, dist_loss: 0.5460907220840454
recon_loss: 0.02712261490523815, dist_loss: 0.6927385330200195
recon_loss: 0.0271220151335001, dist_loss: 0.5325130224227905
recon_loss: 0.02712201699614525, dist_loss: 0.6549123525619507
recon_loss: 0.02712186798453331, dist_loss: 0.9608068466186523
recon_loss: 0.027122681960463524, dist_loss: 0.896892786026001
recon_loss: 0.027122877538204193, dist_loss: 0.8349129557609558
recon_loss: 0.02712334133684635, dist_loss: 0.5238159894943237
recon_loss: 0.02712330035865307, dist_loss: 0.5342590808868408
recon_loss: 0.027123061940073967, dist_loss: 0.6202816963195801
recon_loss: 0.027122817933559418, dist_loss: 0.7041378617286682
recon_loss: 0.02712305076420307, dist_loss: 0.667205810546875
recon_loss: 0.027123017236590385, dist_loss: 0.4809226393699646
recon_loss: 0.027123956009745598, dist_loss: 1.0601584911346436
recon_loss: 0.027124714106321335, dist_loss: 0.8543264865875244
recon_loss: 0.02712470479309559, dist_loss: 0.3707115948200226
recon_loss: 0.027125686407089233, dist_loss: 0.9727694988250732
recon_loss: 0.027126988396048546, dist_loss: 0.9543185830116272
recon_loss: 0.02712755836546421, dist_loss: 0.5853999853134155
recon_loss: 0.027128905057907104, dist_loss: 0.7866358160972595
recon_loss: 0.027129212394356728, dist_loss: 0.9925848841667175
recon_loss: 0.027129773050546646, dist_loss: 0.39539626240730286
recon_loss: 0.027128778398036957, dist_loss: 0.7795323133468628
recon_loss: 0.027128370478749275, dist_loss: 0.6982952356338501
recon_loss: 0.027127692475914955, dist_loss: 0.5805275440216064
recon_loss: 0.02712688222527504, dist_loss: 0.5227026343345642
recon_loss: 0.027126086875796318, dist_loss: 0.4677209258079529
recon_loss: 0.027125919237732887, dist_loss: 0.5660470128059387
recon_loss: 0.027126241475343704, dist_loss: 0.41053831577301025
recon_loss: 0.027126040309667587, dist_loss: 1.266961693763733
recon_loss: 0.027125483378767967, dist_loss: 0.7527722716331482
recon_loss: 0.027124637737870216, dist_loss: 0.294402539730072
recon_loss: 0.027124186977744102, dist_loss: 0.6132625341415405
recon_loss: 0.027123847976326942, dist_loss: 0.4346604347229004
recon_loss: 0.027123697102069855, dist_loss: 1.1274863481521606
recon_loss: 0.02712339535355568, dist_loss: 0.6678063273429871
recon_loss: 0.027123948559165, dist_loss: 0.7184228301048279
recon_loss: 0.027125371620059013, dist_loss: 0.4798714816570282
recon_loss: 0.027127373963594437, dist_loss: 0.45634934306144714
recon_loss: 0.02712973766028881, dist_loss: 0.7053446769714355
recon_loss: 0.02713119424879551, dist_loss: 0.6719121932983398
recon_loss: 0.027131831273436546, dist_loss: 0.9931648969650269
recon_loss: 0.027131391689181328, dist_loss: 0.3089301288127899
recon_loss: 0.027132242918014526, dist_loss: 0.5335196256637573
recon_loss: 0.027131767943501472, dist_loss: 0.4153224229812622
Pre-training Epoch 122:  72%|███████▏  | 263/367 [00:01<00:00, 159.45it/s]Pre-training Epoch 122:  76%|███████▌  | 279/367 [00:01<00:00, 150.83it/s]Pre-training Epoch 122:  80%|████████  | 295/367 [00:01<00:00, 152.77it/s]Pre-training Epoch 122:  85%|████████▍ | 311/367 [00:01<00:00, 150.47it/s]Pre-training Epoch 122:  90%|████████▉ | 329/367 [00:02<00:00, 157.72it/s]Pre-training Epoch 122:  95%|█████████▍| 347/367 [00:02<00:00, 163.59it/s]Pre-training Epoch 122:  99%|█████████▉| 365/367 [00:02<00:00, 168.11it/s]Pre-training Epoch 122: 100%|██████████| 367/367 [00:02<00:00, 163.05it/s]
recon_loss: 0.027132347226142883, dist_loss: 0.49632105231285095
recon_loss: 0.027132095769047737, dist_loss: 0.6932641267776489
recon_loss: 0.027130793780088425, dist_loss: 1.0279182195663452
recon_loss: 0.02712932601571083, dist_loss: 0.8643099069595337
recon_loss: 0.027127930894494057, dist_loss: 0.29308557510375977
recon_loss: 0.027126682922244072, dist_loss: 0.6432795524597168
recon_loss: 0.02712584286928177, dist_loss: 0.5810426473617554
recon_loss: 0.027126604691147804, dist_loss: 0.5903064012527466
recon_loss: 0.02712799236178398, dist_loss: 0.3825089633464813
recon_loss: 0.027130570262670517, dist_loss: 0.5382312536239624
recon_loss: 0.02713189460337162, dist_loss: 0.6499089002609253
recon_loss: 0.02713312953710556, dist_loss: 0.5319932699203491
recon_loss: 0.0271336417645216, dist_loss: 0.7824758291244507
recon_loss: 0.027132119983434677, dist_loss: 0.6384977698326111
recon_loss: 0.0271303653717041, dist_loss: 0.48328685760498047
recon_loss: 0.027128349989652634, dist_loss: 0.423504114151001
recon_loss: 0.027126459404826164, dist_loss: 1.1313769817352295
recon_loss: 0.027124688029289246, dist_loss: 0.8052135705947876
recon_loss: 0.027122851461172104, dist_loss: 0.33496275544166565
recon_loss: 0.02712174877524376, dist_loss: 0.9903607368469238
recon_loss: 0.027121076360344887, dist_loss: 0.5861722230911255
recon_loss: 0.027121152728796005, dist_loss: 0.3683640956878662
recon_loss: 0.027121704071760178, dist_loss: 0.6536391973495483
recon_loss: 0.027123041450977325, dist_loss: 0.8637837171554565
recon_loss: 0.02712300792336464, dist_loss: 0.6236346960067749
recon_loss: 0.02712426148355007, dist_loss: 0.704347550868988
recon_loss: 0.02712388150393963, dist_loss: 0.6887891292572021
recon_loss: 0.02712324820458889, dist_loss: 0.38936468958854675
recon_loss: 0.027121033519506454, dist_loss: 0.5134121775627136
recon_loss: 0.027121474966406822, dist_loss: 0.5953922271728516
recon_loss: 0.02711995504796505, dist_loss: 0.808463454246521
recon_loss: 0.02712193690240383, dist_loss: 0.35429197549819946
recon_loss: 0.02712068520486355, dist_loss: 0.46142101287841797
recon_loss: 0.02712390199303627, dist_loss: 0.8610155582427979
recon_loss: 0.027122709900140762, dist_loss: 0.38785433769226074
recon_loss: 0.027125241234898567, dist_loss: 1.236402988433838
recon_loss: 0.027124932035803795, dist_loss: 0.6311546564102173
recon_loss: 0.027126692235469818, dist_loss: 0.4724101424217224
recon_loss: 0.02712613344192505, dist_loss: 0.4997364282608032
recon_loss: 0.02712639980018139, dist_loss: 0.8246450424194336
recon_loss: 0.02712596207857132, dist_loss: 0.5705901384353638
recon_loss: 0.027123574167490005, dist_loss: 0.5881513357162476
recon_loss: 0.027123434469103813, dist_loss: 0.45687055587768555
recon_loss: 0.02712082490324974, dist_loss: 0.7202675938606262
recon_loss: 0.027120662853121758, dist_loss: 0.2884189486503601
recon_loss: 0.02712033875286579, dist_loss: 0.3458276391029358
recon_loss: 0.02712179534137249, dist_loss: 0.6904272437095642
recon_loss: 0.02712247706949711, dist_loss: 0.6529075503349304
recon_loss: 0.027124198153614998, dist_loss: 0.7962197065353394
recon_loss: 0.027124350890517235, dist_loss: 0.5848491191864014
recon_loss: 0.027124321088194847, dist_loss: 0.4907079339027405
recon_loss: 0.027123942971229553, dist_loss: 0.38949304819107056
recon_loss: 0.027123846113681793, dist_loss: 0.41526854038238525
recon_loss: 0.02712342143058777, dist_loss: 0.6635309457778931
recon_loss: 0.02712355926632881, dist_loss: 0.3127756714820862
recon_loss: 0.02712344564497471, dist_loss: 0.47033417224884033
recon_loss: 0.027123652398586273, dist_loss: 0.40256255865097046
recon_loss: 0.027122963219881058, dist_loss: 0.7738827466964722
recon_loss: 0.027122734114527702, dist_loss: 0.4709511697292328
recon_loss: 0.027121083810925484, dist_loss: 0.6476947665214539
recon_loss: 0.02711944840848446, dist_loss: 0.8622952103614807
recon_loss: 0.027118591591715813, dist_loss: 1.144129991531372
recon_loss: 0.027118545025587082, dist_loss: 1.2706878185272217
recon_loss: 0.02711820788681507, dist_loss: 0.8941361904144287
recon_loss: 0.027117963880300522, dist_loss: 0.781869113445282
recon_loss: 0.02711780183017254, dist_loss: 0.3145817518234253
recon_loss: 0.027117010205984116, dist_loss: 0.36073100566864014
recon_loss: 0.027117041870951653, dist_loss: 0.4496711492538452
recon_loss: 0.02711743302643299, dist_loss: 0.6314104795455933
recon_loss: 0.027117367833852768, dist_loss: 0.5068567991256714
recon_loss: 0.027118559926748276, dist_loss: 0.7532756924629211
recon_loss: 0.027118666097521782, dist_loss: 0.5240461230278015
recon_loss: 0.027120035141706467, dist_loss: 0.5885279178619385
recon_loss: 0.027119826525449753, dist_loss: 0.5154724717140198
recon_loss: 0.027120521292090416, dist_loss: 0.7928386926651001
recon_loss: 0.027120547369122505, dist_loss: 0.9643808603286743
recon_loss: 0.027121080085635185, dist_loss: 0.5175423622131348
recon_loss: 0.02712041325867176, dist_loss: 0.683832049369812
recon_loss: 0.027119046077132225, dist_loss: 0.5577400922775269
recon_loss: 0.027118325233459473, dist_loss: 1.3211098909378052
recon_loss: 0.027117716148495674, dist_loss: 0.6747504472732544
recon_loss: 0.027117587625980377, dist_loss: 0.7166606187820435
recon_loss: 0.027117731049656868, dist_loss: 0.5643863081932068
recon_loss: 0.027118491008877754, dist_loss: 0.5534306168556213
recon_loss: 0.027119573205709457, dist_loss: 0.3263883590698242
recon_loss: 0.027120333164930344, dist_loss: 1.007753610610962
recon_loss: 0.02712072990834713, dist_loss: 0.9420978426933289
recon_loss: 0.02712038718163967, dist_loss: 0.4837820827960968
recon_loss: 0.027119632810354233, dist_loss: 0.4013362228870392
recon_loss: 0.02711937204003334, dist_loss: 0.5002622604370117
recon_loss: 0.027119183912873268, dist_loss: 0.7968504428863525
recon_loss: 0.027119910344481468, dist_loss: 0.43764054775238037
recon_loss: 0.02712072990834713, dist_loss: 0.8259771466255188
recon_loss: 0.027121050283312798, dist_loss: 0.7359158396720886
recon_loss: 0.02712019346654415, dist_loss: 0.42866969108581543
recon_loss: 0.02711944840848446, dist_loss: 0.48869940638542175
recon_loss: 0.027118274942040443, dist_loss: 0.4310463070869446
recon_loss: 0.02711792103946209, dist_loss: 0.37010887265205383
recon_loss: 0.02711651846766472, dist_loss: 0.881445050239563
recon_loss: 0.027117107063531876, dist_loss: 0.798529326915741
recon_loss: 0.02711634896695614, dist_loss: 0.8843958377838135
recon_loss: 0.027116626501083374, dist_loss: 0.6810810565948486
recon_loss: 0.02711624838411808, dist_loss: 0.6169146299362183
recon_loss: 0.027116969227790833, dist_loss: 0.6966903209686279
recon_loss: 0.02711724303662777, dist_loss: 0.767486035823822
recon_loss: 0.027117403224110603, dist_loss: 0.537814736366272
recon_loss: 0.027118517085909843, dist_loss: 0.706344723701477
recon_loss: 0.027118254452943802, dist_loss: 1.0807976722717285
recon_loss: 0.027118820697069168, dist_loss: 0.479861319065094
recon_loss: 0.027118880301713943, dist_loss: 0.3067677617073059
recon_loss: 0.027119187638163567, dist_loss: 0.4999605119228363
Pre-training Epoch 123:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 123:   5%|▍         | 18/367 [00:00<00:02, 171.99it/s]Pre-training Epoch 123:  10%|▉         | 36/367 [00:00<00:02, 162.33it/s]Pre-training Epoch 123:  15%|█▍        | 54/367 [00:00<00:01, 169.07it/s]Pre-training Epoch 123:  20%|█▉        | 72/367 [00:00<00:01, 171.48it/s]Pre-training Epoch 123:  25%|██▍       | 90/367 [00:00<00:01, 172.49it/s]Pre-training Epoch 123:  29%|██▉       | 108/367 [00:00<00:01, 174.11it/s]Pre-training Epoch 123:  34%|███▍      | 126/367 [00:00<00:01, 175.73it/s]recon_loss: 0.027119433507323265, dist_loss: 0.7257148027420044
recon_loss: 0.027121009305119514, dist_loss: 0.9642793536186218
recon_loss: 0.027121778577566147, dist_loss: 0.9152112603187561
recon_loss: 0.027122467756271362, dist_loss: 0.5395060777664185
recon_loss: 0.027123482897877693, dist_loss: 0.6784712076187134
recon_loss: 0.027122773230075836, dist_loss: 0.3172285556793213
recon_loss: 0.027122708037495613, dist_loss: 0.7940253019332886
recon_loss: 0.027121014893054962, dist_loss: 0.5108975172042847
recon_loss: 0.0271200742572546, dist_loss: 0.5451745390892029
recon_loss: 0.027118593454360962, dist_loss: 0.8481251001358032
recon_loss: 0.027118928730487823, dist_loss: 0.4951055347919464
recon_loss: 0.027117833495140076, dist_loss: 0.7225837707519531
recon_loss: 0.027119074016809464, dist_loss: 1.0469290018081665
recon_loss: 0.02711714804172516, dist_loss: 0.8715291023254395
recon_loss: 0.02711956761777401, dist_loss: 0.7625269293785095
recon_loss: 0.027117224410176277, dist_loss: 0.7982453107833862
recon_loss: 0.027119509875774384, dist_loss: 0.5560997724533081
recon_loss: 0.02711636759340763, dist_loss: 0.380226731300354
recon_loss: 0.027118008583784103, dist_loss: 0.6243719458580017
recon_loss: 0.027115650475025177, dist_loss: 0.8628615736961365
recon_loss: 0.027119407430291176, dist_loss: 0.4229797124862671
recon_loss: 0.027117842808365822, dist_loss: 0.6628086566925049
recon_loss: 0.02712084725499153, dist_loss: 0.24853366613388062
recon_loss: 0.02712005004286766, dist_loss: 0.6288744211196899
recon_loss: 0.02712184377014637, dist_loss: 0.5927327871322632
recon_loss: 0.027122121304273605, dist_loss: 0.7613530158996582
recon_loss: 0.027120161801576614, dist_loss: 0.642798900604248
recon_loss: 0.027121473103761673, dist_loss: 0.5321125984191895
recon_loss: 0.02711767517030239, dist_loss: 0.7433645725250244
recon_loss: 0.027118079364299774, dist_loss: 0.6928116083145142
recon_loss: 0.02711552195250988, dist_loss: 0.5063498020172119
recon_loss: 0.02711677737534046, dist_loss: 0.5992718935012817
recon_loss: 0.02711438201367855, dist_loss: 0.8453795909881592
recon_loss: 0.027113979682326317, dist_loss: 0.602076530456543
recon_loss: 0.027113666757941246, dist_loss: 0.8742507696151733
recon_loss: 0.02711307629942894, dist_loss: 0.44891515374183655
recon_loss: 0.027113163843750954, dist_loss: 0.5843716859817505
recon_loss: 0.027112802490592003, dist_loss: 0.716626763343811
recon_loss: 0.027112871408462524, dist_loss: 0.6723185181617737
recon_loss: 0.027112862095236778, dist_loss: 0.6279881000518799
recon_loss: 0.027113035321235657, dist_loss: 0.6903295516967773
recon_loss: 0.027112996205687523, dist_loss: 0.4694467782974243
recon_loss: 0.02711317129433155, dist_loss: 0.6822279691696167
recon_loss: 0.027112523093819618, dist_loss: 0.43874192237854004
recon_loss: 0.027112092822790146, dist_loss: 0.8174331188201904
recon_loss: 0.027111472561955452, dist_loss: 0.5658889412879944
recon_loss: 0.027111448347568512, dist_loss: 0.7221440076828003
recon_loss: 0.02711167186498642, dist_loss: 0.6123452186584473
recon_loss: 0.027111690491437912, dist_loss: 0.9657467603683472
recon_loss: 0.027112077921628952, dist_loss: 0.554535984992981
recon_loss: 0.02711300179362297, dist_loss: 0.38455599546432495
recon_loss: 0.027113458141684532, dist_loss: 0.4595945477485657
recon_loss: 0.02711440622806549, dist_loss: 0.34614238142967224
recon_loss: 0.027114396914839745, dist_loss: 1.0241143703460693
recon_loss: 0.027116065844893456, dist_loss: 0.7627302408218384
recon_loss: 0.0271157119423151, dist_loss: 0.9733766913414001
recon_loss: 0.027116451412439346, dist_loss: 1.0677675008773804
recon_loss: 0.0271148718893528, dist_loss: 0.7431074976921082
recon_loss: 0.027116117998957634, dist_loss: 0.33498048782348633
recon_loss: 0.027117541059851646, dist_loss: 1.115924596786499
recon_loss: 0.027117794379591942, dist_loss: 0.5803619623184204
recon_loss: 0.027118457481265068, dist_loss: 0.7185913324356079
recon_loss: 0.02711898647248745, dist_loss: 0.3685181140899658
recon_loss: 0.027119822800159454, dist_loss: 0.5562096834182739
recon_loss: 0.027120240032672882, dist_loss: 0.4986193776130676
recon_loss: 0.027121566236019135, dist_loss: 0.6063575744628906
recon_loss: 0.027121171355247498, dist_loss: 0.5583568811416626
recon_loss: 0.02712181955575943, dist_loss: 0.4514770805835724
recon_loss: 0.027121953666210175, dist_loss: 0.42684119939804077
recon_loss: 0.027121135964989662, dist_loss: 0.8157103061676025
recon_loss: 0.027120323851704597, dist_loss: 1.1771395206451416
recon_loss: 0.027118930593132973, dist_loss: 0.9013007879257202
recon_loss: 0.027117278426885605, dist_loss: 0.7924283742904663
recon_loss: 0.027115952223539352, dist_loss: 0.6090031266212463
recon_loss: 0.027115745469927788, dist_loss: 0.47903159260749817
recon_loss: 0.027116233482956886, dist_loss: 1.1602230072021484
recon_loss: 0.02711677923798561, dist_loss: 1.1290714740753174
recon_loss: 0.027116598561406136, dist_loss: 0.7970324754714966
recon_loss: 0.027117328718304634, dist_loss: 0.8407665491104126
recon_loss: 0.027116544544696808, dist_loss: 0.8191031217575073
recon_loss: 0.02711733616888523, dist_loss: 0.6949822902679443
recon_loss: 0.02711661159992218, dist_loss: 0.5718286037445068
recon_loss: 0.02711627073585987, dist_loss: 0.550440788269043
recon_loss: 0.027114329859614372, dist_loss: 0.914492666721344
recon_loss: 0.02711392007768154, dist_loss: 0.5932815074920654
recon_loss: 0.027112634852528572, dist_loss: 0.6006725430488586
recon_loss: 0.027112845331430435, dist_loss: 0.7134147882461548
recon_loss: 0.02711198292672634, dist_loss: 0.7155625224113464
recon_loss: 0.027111966162919998, dist_loss: 0.7823798656463623
recon_loss: 0.02711103856563568, dist_loss: 0.43982142210006714
recon_loss: 0.027110695838928223, dist_loss: 0.254219651222229
recon_loss: 0.02711048163473606, dist_loss: 0.27754414081573486
recon_loss: 0.02711002342402935, dist_loss: 0.9964157342910767
recon_loss: 0.027110086753964424, dist_loss: 0.3605765402317047
recon_loss: 0.02710932120680809, dist_loss: 0.5695667862892151
recon_loss: 0.02710949443280697, dist_loss: 0.6422843933105469
recon_loss: 0.027109436690807343, dist_loss: 0.6994355916976929
recon_loss: 0.027109811082482338, dist_loss: 0.7105662226676941
recon_loss: 0.027109742164611816, dist_loss: 0.39550065994262695
recon_loss: 0.027110006660223007, dist_loss: 0.662539005279541
recon_loss: 0.027109814807772636, dist_loss: 0.6376199126243591
recon_loss: 0.027110258117318153, dist_loss: 0.7620072364807129
recon_loss: 0.027109887450933456, dist_loss: 0.5281995534896851
recon_loss: 0.027109935879707336, dist_loss: 0.6578829288482666
recon_loss: 0.027109453454613686, dist_loss: 0.6780494451522827
recon_loss: 0.02710997872054577, dist_loss: 0.6327850222587585
recon_loss: 0.02710966393351555, dist_loss: 0.6528729200363159
recon_loss: 0.02711014449596405, dist_loss: 0.6797059774398804
recon_loss: 0.027109770104289055, dist_loss: 0.7685737609863281
recon_loss: 0.027109922841191292, dist_loss: 0.7157967686653137
recon_loss: 0.027109315618872643, dist_loss: 0.8607626557350159
recon_loss: 0.027109570801258087, dist_loss: 0.30365946888923645
recon_loss: 0.027109429240226746, dist_loss: 0.5748151540756226
recon_loss: 0.027109481394290924, dist_loss: 0.6146626472473145
recon_loss: 0.027109365910291672, dist_loss: 0.698341965675354
recon_loss: 0.02710958942770958, dist_loss: 0.6871823668479919
recon_loss: 0.02710963971912861, dist_loss: 0.34086671471595764
recon_loss: 0.027109984308481216, dist_loss: 0.4668787717819214
recon_loss: 0.02711050771176815, dist_loss: 0.29116854071617126
recon_loss: 0.027110986411571503, dist_loss: 0.5751321315765381
recon_loss: 0.027111131697893143, dist_loss: 0.3505554795265198
recon_loss: 0.027111418545246124, dist_loss: 0.500333845615387
recon_loss: 0.02711298130452633, dist_loss: 0.5266115665435791
recon_loss: 0.02711445279419422, dist_loss: 0.7008836269378662
recon_loss: 0.02711593173444271, dist_loss: 0.7915563583374023
recon_loss: 0.027117254212498665, dist_loss: 0.48323237895965576
recon_loss: 0.0271187461912632, dist_loss: 0.8785419464111328
recon_loss: 0.02711860090494156, dist_loss: 0.654249370098114
Pre-training Epoch 123:  40%|███▉      | 145/367 [00:00<00:01, 177.13it/s]Pre-training Epoch 123:  44%|████▍     | 163/367 [00:00<00:01, 177.62it/s]Pre-training Epoch 123:  49%|████▉     | 181/367 [00:01<00:01, 177.49it/s]Pre-training Epoch 123:  54%|█████▍    | 199/367 [00:01<00:00, 176.38it/s]Pre-training Epoch 123:  59%|█████▉    | 217/367 [00:01<00:00, 175.26it/s]Pre-training Epoch 123:  65%|██████▍   | 237/367 [00:01<00:00, 181.00it/s]Pre-training Epoch 123:  70%|██████▉   | 256/367 [00:01<00:00, 176.33it/s]recon_loss: 0.027117226272821426, dist_loss: 0.6417731642723083
recon_loss: 0.02711595594882965, dist_loss: 0.7827398777008057
recon_loss: 0.027113834396004677, dist_loss: 0.6775913834571838
recon_loss: 0.027112551033496857, dist_loss: 0.6726648807525635
recon_loss: 0.027112144976854324, dist_loss: 0.2619526982307434
recon_loss: 0.027111932635307312, dist_loss: 0.46654677391052246
recon_loss: 0.027111994102597237, dist_loss: 0.4695301353931427
recon_loss: 0.027112092822790146, dist_loss: 0.8134889602661133
recon_loss: 0.027112331241369247, dist_loss: 0.3681379556655884
recon_loss: 0.027113331481814384, dist_loss: 0.47229039669036865
recon_loss: 0.02711445838212967, dist_loss: 0.8083888292312622
recon_loss: 0.027115827426314354, dist_loss: 0.5713385343551636
recon_loss: 0.027116641402244568, dist_loss: 0.42859530448913574
recon_loss: 0.0271169301122427, dist_loss: 0.4319855570793152
recon_loss: 0.02711675688624382, dist_loss: 0.7018821835517883
recon_loss: 0.027117226272821426, dist_loss: 0.8822040557861328
recon_loss: 0.027117731049656868, dist_loss: 0.6832789182662964
recon_loss: 0.027117423713207245, dist_loss: 1.7537550926208496
recon_loss: 0.027116559445858, dist_loss: 0.5442549586296082
recon_loss: 0.027115408331155777, dist_loss: 0.406099796295166
recon_loss: 0.027114473283290863, dist_loss: 0.7186676859855652
recon_loss: 0.027112800627946854, dist_loss: 0.30399245023727417
recon_loss: 0.027112197130918503, dist_loss: 0.6438409090042114
recon_loss: 0.027111122384667397, dist_loss: 0.5189105272293091
recon_loss: 0.02711104229092598, dist_loss: 0.5295000076293945
recon_loss: 0.027110621333122253, dist_loss: 0.6420242786407471
recon_loss: 0.02711084671318531, dist_loss: 0.5496861934661865
recon_loss: 0.027109840884804726, dist_loss: 0.768966555595398
recon_loss: 0.027109630405902863, dist_loss: 0.5748540759086609
recon_loss: 0.027109937742352486, dist_loss: 0.5804818868637085
recon_loss: 0.027109673246741295, dist_loss: 0.6671985387802124
recon_loss: 0.027109626680612564, dist_loss: 0.4183509647846222
recon_loss: 0.027109043672680855, dist_loss: 0.7644378542900085
recon_loss: 0.027109362185001373, dist_loss: 0.7747363448143005
recon_loss: 0.02710878476500511, dist_loss: 0.6235592365264893
recon_loss: 0.027108531445264816, dist_loss: 0.8273601531982422
recon_loss: 0.027107512578368187, dist_loss: 0.4624488651752472
recon_loss: 0.027107220143079758, dist_loss: 0.43840116262435913
recon_loss: 0.02710658870637417, dist_loss: 1.2634305953979492
recon_loss: 0.02710684947669506, dist_loss: 0.7266796827316284
recon_loss: 0.027107493951916695, dist_loss: 0.9543260335922241
recon_loss: 0.027107972651720047, dist_loss: 0.5865724682807922
recon_loss: 0.027108917012810707, dist_loss: 0.7020910978317261
recon_loss: 0.027109019458293915, dist_loss: 0.4261559545993805
recon_loss: 0.027109339833259583, dist_loss: 0.7501325011253357
recon_loss: 0.02711031772196293, dist_loss: 0.627770185470581
recon_loss: 0.02711091749370098, dist_loss: 0.8809998035430908
recon_loss: 0.027112120762467384, dist_loss: 0.44616565108299255
recon_loss: 0.027112534269690514, dist_loss: 0.8252862691879272
recon_loss: 0.027112875133752823, dist_loss: 0.577652096748352
recon_loss: 0.02711249329149723, dist_loss: 0.670464277267456
recon_loss: 0.027112428098917007, dist_loss: 0.40819039940834045
recon_loss: 0.027111485600471497, dist_loss: 0.6213588714599609
recon_loss: 0.0271107517182827, dist_loss: 0.5420913696289062
recon_loss: 0.02711014449596405, dist_loss: 0.47020071744918823
recon_loss: 0.027109837159514427, dist_loss: 0.6560813188552856
recon_loss: 0.027109777554869652, dist_loss: 0.8146029710769653
recon_loss: 0.027110116556286812, dist_loss: 0.8248637914657593
recon_loss: 0.027110444381833076, dist_loss: 0.6469539403915405
recon_loss: 0.027110973373055458, dist_loss: 0.4608323276042938
recon_loss: 0.027111362665891647, dist_loss: 1.1142833232879639
recon_loss: 0.02711089886724949, dist_loss: 0.7000506520271301
recon_loss: 0.02711171843111515, dist_loss: 0.4834825396537781
recon_loss: 0.02711140364408493, dist_loss: 1.0076630115509033
recon_loss: 0.027111580595374107, dist_loss: 0.9535928964614868
recon_loss: 0.027111364528536797, dist_loss: 0.4826641082763672
recon_loss: 0.027111424133181572, dist_loss: 0.844371497631073
recon_loss: 0.027110425755381584, dist_loss: 0.5563318729400635
recon_loss: 0.027109762653708458, dist_loss: 0.43557560443878174
recon_loss: 0.027109188959002495, dist_loss: 0.5398656725883484
recon_loss: 0.027109114453196526, dist_loss: 0.44352269172668457
recon_loss: 0.02710963971912861, dist_loss: 0.4493044912815094
recon_loss: 0.027109351009130478, dist_loss: 0.7919055223464966
recon_loss: 0.027108917012810707, dist_loss: 0.6673255562782288
recon_loss: 0.027108097448945045, dist_loss: 0.6772769689559937
recon_loss: 0.027108144015073776, dist_loss: 0.3947588801383972
recon_loss: 0.02710765041410923, dist_loss: 0.6408137083053589
recon_loss: 0.02710719034075737, dist_loss: 0.776626467704773
recon_loss: 0.027106627821922302, dist_loss: 0.2549792528152466
recon_loss: 0.02710646018385887, dist_loss: 0.8528169989585876
recon_loss: 0.02710629813373089, dist_loss: 0.3861662447452545
recon_loss: 0.02710655704140663, dist_loss: 0.4166334271430969
recon_loss: 0.02710679918527603, dist_loss: 0.34528887271881104
recon_loss: 0.0271073579788208, dist_loss: 0.47317659854888916
recon_loss: 0.027107957750558853, dist_loss: 0.37710341811180115
recon_loss: 0.0271084513515234, dist_loss: 1.0108187198638916
recon_loss: 0.027108140289783478, dist_loss: 0.8279467821121216
recon_loss: 0.02710748091340065, dist_loss: 0.5808783769607544
recon_loss: 0.027107233181595802, dist_loss: 0.4946209788322449
recon_loss: 0.02710731141269207, dist_loss: 0.5738431215286255
recon_loss: 0.027107512578368187, dist_loss: 0.9247080683708191
recon_loss: 0.027108263224363327, dist_loss: 0.974297821521759
recon_loss: 0.027109390124678612, dist_loss: 0.9983311295509338
recon_loss: 0.027110630646348, dist_loss: 0.7240152955055237
recon_loss: 0.027111714705824852, dist_loss: 0.5304909944534302
recon_loss: 0.0271123219281435, dist_loss: 0.7159348726272583
recon_loss: 0.02711317129433155, dist_loss: 0.5048593282699585
recon_loss: 0.02711356431245804, dist_loss: 0.5932591557502747
recon_loss: 0.027113817632198334, dist_loss: 0.5471794605255127
recon_loss: 0.02711419016122818, dist_loss: 0.6514745950698853
recon_loss: 0.027114391326904297, dist_loss: 0.33369308710098267
recon_loss: 0.027114203199744225, dist_loss: 0.5960853099822998
recon_loss: 0.02711361274123192, dist_loss: 0.5577516555786133
recon_loss: 0.02711259387433529, dist_loss: 0.7788663506507874
recon_loss: 0.02711176499724388, dist_loss: 0.7176586985588074
recon_loss: 0.027110708877444267, dist_loss: 0.6540043354034424
recon_loss: 0.027109231799840927, dist_loss: 0.7420227527618408
recon_loss: 0.027108414098620415, dist_loss: 0.6985002756118774
recon_loss: 0.027107825502753258, dist_loss: 0.735836386680603
recon_loss: 0.027108317241072655, dist_loss: 0.6266653537750244
recon_loss: 0.02710839919745922, dist_loss: 0.5436969995498657
recon_loss: 0.027109362185001373, dist_loss: 0.39807045459747314
recon_loss: 0.02710958756506443, dist_loss: 0.699596107006073
recon_loss: 0.027109816670417786, dist_loss: 0.38447195291519165
recon_loss: 0.027110373601317406, dist_loss: 0.5031682252883911
recon_loss: 0.027110930532217026, dist_loss: 0.3053857088088989
recon_loss: 0.02711062878370285, dist_loss: 0.5899674892425537
recon_loss: 0.027109844610095024, dist_loss: 0.5533186197280884
recon_loss: 0.027109084650874138, dist_loss: 1.3278889656066895
recon_loss: 0.02710864506661892, dist_loss: 0.7990715503692627
recon_loss: 0.02710779942572117, dist_loss: 0.770857572555542
recon_loss: 0.02710755169391632, dist_loss: 0.5478194952011108
recon_loss: 0.027107441797852516, dist_loss: 0.6120243072509766
recon_loss: 0.027107469737529755, dist_loss: 0.9425317049026489
recon_loss: 0.02710805833339691, dist_loss: 0.7805122137069702
recon_loss: 0.027108583599328995, dist_loss: 0.6014059782028198
recon_loss: 0.02710922434926033, dist_loss: 0.4307355582714081
recon_loss: 0.02710932120680809, dist_loss: 0.5572546124458313
Pre-training Epoch 123:  75%|███████▍  | 274/367 [00:01<00:00, 174.24it/s]Pre-training Epoch 123:  80%|███████▉  | 292/367 [00:01<00:00, 173.58it/s]Pre-training Epoch 123:  84%|████████▍ | 310/367 [00:01<00:00, 173.37it/s]Pre-training Epoch 123:  89%|████████▉ | 328/367 [00:01<00:00, 172.87it/s]Pre-training Epoch 123:  94%|█████████▍| 346/367 [00:01<00:00, 172.04it/s]Pre-training Epoch 123:  99%|█████████▉| 364/367 [00:02<00:00, 171.13it/s]Pre-training Epoch 123: 100%|██████████| 367/367 [00:02<00:00, 173.84it/s]
recon_loss: 0.0271089319139719, dist_loss: 0.8683486580848694
recon_loss: 0.027109919115900993, dist_loss: 0.4505690932273865
recon_loss: 0.027109229937195778, dist_loss: 0.6715766787528992
recon_loss: 0.02710907906293869, dist_loss: 0.6295151710510254
recon_loss: 0.02710762247443199, dist_loss: 0.6060758233070374
recon_loss: 0.027107078582048416, dist_loss: 0.7127672433853149
recon_loss: 0.027106327936053276, dist_loss: 0.35783469676971436
recon_loss: 0.027106186375021935, dist_loss: 0.3971348702907562
recon_loss: 0.02710515446960926, dist_loss: 1.0317872762680054
recon_loss: 0.027104975655674934, dist_loss: 0.9162826538085938
recon_loss: 0.027104724198579788, dist_loss: 0.6694815754890442
recon_loss: 0.027105409651994705, dist_loss: 0.4260462522506714
recon_loss: 0.02710535004734993, dist_loss: 0.7090627551078796
recon_loss: 0.02710580639541149, dist_loss: 1.0053097009658813
recon_loss: 0.027105994522571564, dist_loss: 0.9679943323135376
recon_loss: 0.027107488363981247, dist_loss: 0.388438880443573
recon_loss: 0.0271085724234581, dist_loss: 0.754840075969696
recon_loss: 0.027109062299132347, dist_loss: 0.9091160893440247
recon_loss: 0.027110056951642036, dist_loss: 0.7431948184967041
recon_loss: 0.027109378948807716, dist_loss: 0.7689852714538574
recon_loss: 0.027107233181595802, dist_loss: 0.5866401195526123
recon_loss: 0.027105681598186493, dist_loss: 0.5156289339065552
recon_loss: 0.02710505574941635, dist_loss: 0.5263029336929321
recon_loss: 0.027105823159217834, dist_loss: 0.6022771596908569
recon_loss: 0.027107354253530502, dist_loss: 0.5204533338546753
recon_loss: 0.027108946815133095, dist_loss: 0.4477232098579407
recon_loss: 0.02711031213402748, dist_loss: 0.49877285957336426
recon_loss: 0.027111738920211792, dist_loss: 0.6597000360488892
recon_loss: 0.02711431495845318, dist_loss: 0.9415706992149353
recon_loss: 0.027115579694509506, dist_loss: 0.5887953042984009
recon_loss: 0.02711491659283638, dist_loss: 0.7880423665046692
recon_loss: 0.027112582698464394, dist_loss: 0.6196686625480652
recon_loss: 0.027111491188406944, dist_loss: 0.5401538610458374
recon_loss: 0.027107713744044304, dist_loss: 0.55428147315979
recon_loss: 0.027107607573270798, dist_loss: 0.3777245879173279
recon_loss: 0.027104508131742477, dist_loss: 0.4351602792739868
recon_loss: 0.02710643596947193, dist_loss: 0.35424724221229553
recon_loss: 0.02710687927901745, dist_loss: 0.7986960411071777
recon_loss: 0.02710939571261406, dist_loss: 0.37957578897476196
recon_loss: 0.027111217379570007, dist_loss: 0.2809588313102722
recon_loss: 0.027113215997815132, dist_loss: 0.6696735620498657
recon_loss: 0.027114413678646088, dist_loss: 0.9008523225784302
recon_loss: 0.027114545926451683, dist_loss: 0.47695356607437134
recon_loss: 0.027114540338516235, dist_loss: 0.5945438742637634
recon_loss: 0.02711554616689682, dist_loss: 1.2055573463439941
recon_loss: 0.027116330340504646, dist_loss: 0.7183211445808411
recon_loss: 0.027116114273667336, dist_loss: 0.5210992097854614
recon_loss: 0.027115635573863983, dist_loss: 0.5708422660827637
recon_loss: 0.0271136611700058, dist_loss: 0.7536712884902954
recon_loss: 0.027111530303955078, dist_loss: 0.4533008337020874
recon_loss: 0.027109229937195778, dist_loss: 0.7072869539260864
recon_loss: 0.027107754722237587, dist_loss: 0.46077048778533936
recon_loss: 0.027107225731015205, dist_loss: 0.4727616012096405
recon_loss: 0.027107717469334602, dist_loss: 0.7510093450546265
recon_loss: 0.02710888348519802, dist_loss: 0.714914083480835
recon_loss: 0.027111293748021126, dist_loss: 0.7896491289138794
recon_loss: 0.02711300551891327, dist_loss: 0.7359980940818787
recon_loss: 0.027114061638712883, dist_loss: 0.5767447352409363
recon_loss: 0.027114368975162506, dist_loss: 1.2797081470489502
recon_loss: 0.02711302414536476, dist_loss: 0.6359369158744812
recon_loss: 0.02711089327931404, dist_loss: 0.8796790838241577
recon_loss: 0.02710942178964615, dist_loss: 0.5137792229652405
recon_loss: 0.027108030393719673, dist_loss: 0.5011208057403564
recon_loss: 0.027107369154691696, dist_loss: 0.5187042951583862
recon_loss: 0.027106795459985733, dist_loss: 0.46358418464660645
recon_loss: 0.027106305584311485, dist_loss: 0.47814708948135376
recon_loss: 0.027106106281280518, dist_loss: 0.7333608865737915
recon_loss: 0.027106696739792824, dist_loss: 0.6642937064170837
recon_loss: 0.027108607813715935, dist_loss: 0.6160193681716919
recon_loss: 0.027112053707242012, dist_loss: 0.383070170879364
recon_loss: 0.027114449068903923, dist_loss: 0.589117705821991
recon_loss: 0.027116408571600914, dist_loss: 0.616997241973877
recon_loss: 0.027117203921079636, dist_loss: 0.6698153018951416
recon_loss: 0.02711685188114643, dist_loss: 0.6784030795097351
recon_loss: 0.0271168053150177, dist_loss: 0.9308189153671265
recon_loss: 0.02711549773812294, dist_loss: 0.5814810395240784
recon_loss: 0.027113601565361023, dist_loss: 0.5410255789756775
recon_loss: 0.027110302820801735, dist_loss: 0.5304406881332397
recon_loss: 0.02710798755288124, dist_loss: 1.1293573379516602
recon_loss: 0.027107998728752136, dist_loss: 0.7060544490814209
recon_loss: 0.027108073234558105, dist_loss: 0.8442341089248657
recon_loss: 0.027109619230031967, dist_loss: 0.3819146156311035
recon_loss: 0.027110986411571503, dist_loss: 0.6882236003875732
recon_loss: 0.027112670242786407, dist_loss: 0.6554818153381348
recon_loss: 0.027114946395158768, dist_loss: 0.8787117004394531
recon_loss: 0.027115395292639732, dist_loss: 0.5299156904220581
recon_loss: 0.02711452916264534, dist_loss: 0.366269052028656
recon_loss: 0.02711310051381588, dist_loss: 0.5814715027809143
recon_loss: 0.027111204341053963, dist_loss: 0.5591385364532471
recon_loss: 0.027109863236546516, dist_loss: 0.7117077112197876
recon_loss: 0.027109403163194656, dist_loss: 0.8379504084587097
recon_loss: 0.027109336107969284, dist_loss: 0.4029363989830017
recon_loss: 0.027109501883387566, dist_loss: 0.5850877165794373
recon_loss: 0.027109380811452866, dist_loss: 0.5814228653907776
recon_loss: 0.02710954286158085, dist_loss: 0.29165613651275635
recon_loss: 0.027109619230031967, dist_loss: 0.8012615442276001
recon_loss: 0.027109434828162193, dist_loss: 0.5132158994674683
recon_loss: 0.027109013870358467, dist_loss: 0.7644531726837158
recon_loss: 0.02710750140249729, dist_loss: 0.3919295370578766
recon_loss: 0.027107784524559975, dist_loss: 0.8495133519172668
recon_loss: 0.027107233181595802, dist_loss: 0.3886919617652893
recon_loss: 0.027107682079076767, dist_loss: 0.5072539448738098
recon_loss: 0.027107268571853638, dist_loss: 0.4382699131965637
recon_loss: 0.02710718847811222, dist_loss: 0.6834656000137329
recon_loss: 0.02710830047726631, dist_loss: 0.38922619819641113
recon_loss: 0.02710893377661705, dist_loss: 0.39903321862220764
recon_loss: 0.027109505608677864, dist_loss: 0.5768178105354309
recon_loss: 0.02710891328752041, dist_loss: 0.691139817237854
recon_loss: 0.027109844610095024, dist_loss: 0.6757908463478088
recon_loss: 0.027110613882541656, dist_loss: 0.572665810585022
recon_loss: 0.027109872549772263, dist_loss: 1.4459911584854126
Pre-training Epoch 124:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 124:   5%|▍         | 17/367 [00:00<00:02, 160.61it/s]Pre-training Epoch 124:   9%|▉         | 34/367 [00:00<00:02, 164.92it/s]Pre-training Epoch 124:  14%|█▍        | 52/367 [00:00<00:01, 167.90it/s]Pre-training Epoch 124:  19%|█▉        | 70/367 [00:00<00:01, 168.57it/s]Pre-training Epoch 124:  24%|██▍       | 88/367 [00:00<00:01, 169.82it/s]Pre-training Epoch 124:  29%|██▊       | 105/367 [00:00<00:01, 169.87it/s]Pre-training Epoch 124:  34%|███▎      | 123/367 [00:00<00:01, 172.82it/s]recon_loss: 0.02710980735719204, dist_loss: 0.7389723062515259
recon_loss: 0.027110964059829712, dist_loss: 0.7716503739356995
recon_loss: 0.02711077593266964, dist_loss: 1.0837322473526
recon_loss: 0.02710917219519615, dist_loss: 0.32616251707077026
recon_loss: 0.027108754962682724, dist_loss: 0.29971981048583984
recon_loss: 0.027108293026685715, dist_loss: 0.5238984823226929
recon_loss: 0.027107970789074898, dist_loss: 0.7584288120269775
recon_loss: 0.027107927948236465, dist_loss: 0.8481360077857971
recon_loss: 0.027107922360301018, dist_loss: 1.113763451576233
recon_loss: 0.027107618749141693, dist_loss: 0.9293878078460693
recon_loss: 0.02710677497088909, dist_loss: 0.583418607711792
recon_loss: 0.027106447145342827, dist_loss: 0.8701736927032471
recon_loss: 0.02710573747754097, dist_loss: 0.596495509147644
recon_loss: 0.027105487883090973, dist_loss: 0.7049052715301514
recon_loss: 0.027104344218969345, dist_loss: 0.7451189756393433
recon_loss: 0.027104157954454422, dist_loss: 0.39633288979530334
recon_loss: 0.027103586122393608, dist_loss: 0.49642306566238403
recon_loss: 0.027103697881102562, dist_loss: 0.855141282081604
recon_loss: 0.027102921158075333, dist_loss: 0.821772575378418
recon_loss: 0.02710275538265705, dist_loss: 0.31772273778915405
recon_loss: 0.027102841064333916, dist_loss: 0.680668830871582
recon_loss: 0.02710307016968727, dist_loss: 0.9461755752563477
recon_loss: 0.02710270881652832, dist_loss: 0.7487549781799316
recon_loss: 0.027102099731564522, dist_loss: 0.6447464823722839
recon_loss: 0.027101358398795128, dist_loss: 0.8619091510772705
recon_loss: 0.02710242010653019, dist_loss: 1.038137435913086
recon_loss: 0.027102196589112282, dist_loss: 0.4408847689628601
recon_loss: 0.027102593332529068, dist_loss: 0.47345471382141113
recon_loss: 0.027102114632725716, dist_loss: 1.1140952110290527
recon_loss: 0.027103040367364883, dist_loss: 0.5405449867248535
recon_loss: 0.02710338495671749, dist_loss: 0.7606141567230225
recon_loss: 0.027104590088129044, dist_loss: 0.48223352432250977
recon_loss: 0.027104636654257774, dist_loss: 0.439389705657959
recon_loss: 0.027103841304779053, dist_loss: 0.3758205473423004
recon_loss: 0.027103524655103683, dist_loss: 0.6606875658035278
recon_loss: 0.02710351161658764, dist_loss: 0.6013362407684326
recon_loss: 0.027102770283818245, dist_loss: 0.5212895274162292
recon_loss: 0.02710152044892311, dist_loss: 0.4190462827682495
recon_loss: 0.027100695297122, dist_loss: 0.6583627462387085
recon_loss: 0.027100710198283195, dist_loss: 0.49770402908325195
recon_loss: 0.02710021287202835, dist_loss: 0.4817606210708618
recon_loss: 0.027100345119833946, dist_loss: 0.8581684827804565
recon_loss: 0.027101216837763786, dist_loss: 0.8108638525009155
recon_loss: 0.027102215215563774, dist_loss: 0.5524593591690063
recon_loss: 0.027103085070848465, dist_loss: 0.8259212374687195
recon_loss: 0.0271036084741354, dist_loss: 0.6879208087921143
recon_loss: 0.027105815708637238, dist_loss: 1.0001596212387085
recon_loss: 0.027107900008559227, dist_loss: 0.570968508720398
recon_loss: 0.027109269052743912, dist_loss: 0.9462224841117859
recon_loss: 0.027110613882541656, dist_loss: 0.6369445323944092
recon_loss: 0.027112172916531563, dist_loss: 1.0861848592758179
recon_loss: 0.027111344039440155, dist_loss: 0.7286147475242615
recon_loss: 0.027109406888484955, dist_loss: 0.7711994647979736
recon_loss: 0.02710815705358982, dist_loss: 0.3195028603076935
recon_loss: 0.027106348425149918, dist_loss: 0.7550408840179443
recon_loss: 0.02710486575961113, dist_loss: 0.4753105640411377
recon_loss: 0.027103465050458908, dist_loss: 0.8639802932739258
recon_loss: 0.027102384716272354, dist_loss: 0.5122743844985962
recon_loss: 0.02710176445543766, dist_loss: 0.6515501141548157
recon_loss: 0.027100861072540283, dist_loss: 0.8101762533187866
recon_loss: 0.027101291343569756, dist_loss: 0.44579458236694336
recon_loss: 0.027099713683128357, dist_loss: 0.5112899541854858
recon_loss: 0.027100684121251106, dist_loss: 0.7000532150268555
recon_loss: 0.027099309489130974, dist_loss: 0.46978506445884705
recon_loss: 0.02710006758570671, dist_loss: 0.7139410972595215
recon_loss: 0.027099594473838806, dist_loss: 0.5689758062362671
recon_loss: 0.02710089273750782, dist_loss: 0.7467290163040161
recon_loss: 0.027100808918476105, dist_loss: 0.6681478023529053
recon_loss: 0.027101803570985794, dist_loss: 0.6921829581260681
recon_loss: 0.027100948616862297, dist_loss: 0.597946286201477
recon_loss: 0.027102939784526825, dist_loss: 0.6698755025863647
recon_loss: 0.02710111252963543, dist_loss: 0.4276909828186035
recon_loss: 0.02710345759987831, dist_loss: 0.7715970277786255
recon_loss: 0.027100268751382828, dist_loss: 0.7007404565811157
recon_loss: 0.027100790292024612, dist_loss: 0.4908227324485779
recon_loss: 0.027099017053842545, dist_loss: 0.7967584133148193
recon_loss: 0.027099983766674995, dist_loss: 0.7554362416267395
recon_loss: 0.027098562568426132, dist_loss: 0.5278789401054382
recon_loss: 0.027099108323454857, dist_loss: 0.5647696852684021
recon_loss: 0.027098577469587326, dist_loss: 0.8036510944366455
recon_loss: 0.027097729966044426, dist_loss: 1.0314480066299438
recon_loss: 0.027098461985588074, dist_loss: 0.672871470451355
recon_loss: 0.027097167447209358, dist_loss: 0.4939349889755249
recon_loss: 0.027098651975393295, dist_loss: 0.5421260595321655
recon_loss: 0.027098217979073524, dist_loss: 0.42326444387435913
recon_loss: 0.027099139988422394, dist_loss: 0.6017260551452637
recon_loss: 0.027098393067717552, dist_loss: 0.6361711025238037
recon_loss: 0.027099253609776497, dist_loss: 0.3421124815940857
recon_loss: 0.027099071070551872, dist_loss: 0.43932515382766724
recon_loss: 0.02709953859448433, dist_loss: 0.8302828073501587
recon_loss: 0.027099188417196274, dist_loss: 0.6475833654403687
recon_loss: 0.027099139988422394, dist_loss: 0.6424250602722168
recon_loss: 0.027099251747131348, dist_loss: 0.7534966468811035
recon_loss: 0.027099192142486572, dist_loss: 0.5034692287445068
recon_loss: 0.02709892950952053, dist_loss: 0.5036343336105347
recon_loss: 0.02709849923849106, dist_loss: 0.5170761346817017
recon_loss: 0.027098193764686584, dist_loss: 0.5149528384208679
recon_loss: 0.027098583057522774, dist_loss: 0.4359138011932373
recon_loss: 0.027098944410681725, dist_loss: 0.5552592277526855
recon_loss: 0.02709943614900112, dist_loss: 0.7104495763778687
recon_loss: 0.027099264785647392, dist_loss: 0.4025254249572754
recon_loss: 0.02709878608584404, dist_loss: 0.36434680223464966
recon_loss: 0.027097923681139946, dist_loss: 0.6694536209106445
recon_loss: 0.027097860351204872, dist_loss: 0.6864925026893616
recon_loss: 0.02709704078733921, dist_loss: 0.38771581649780273
recon_loss: 0.027097180485725403, dist_loss: 0.8516066074371338
recon_loss: 0.027096791192889214, dist_loss: 0.9321898221969604
recon_loss: 0.02709675393998623, dist_loss: 0.4656006991863251
recon_loss: 0.027096932753920555, dist_loss: 0.5631130933761597
recon_loss: 0.027096379548311234, dist_loss: 0.5814439058303833
recon_loss: 0.027096867561340332, dist_loss: 1.01215660572052
recon_loss: 0.02709599956870079, dist_loss: 0.539494514465332
recon_loss: 0.027096165344119072, dist_loss: 0.43729913234710693
recon_loss: 0.027095859870314598, dist_loss: 0.7497636079788208
recon_loss: 0.027097277343273163, dist_loss: 0.6352709531784058
recon_loss: 0.02709706500172615, dist_loss: 0.9539319276809692
recon_loss: 0.02709841914474964, dist_loss: 1.0159595012664795
recon_loss: 0.027098162099719048, dist_loss: 0.6443800926208496
recon_loss: 0.027098288759589195, dist_loss: 0.8111275434494019
recon_loss: 0.027098430320620537, dist_loss: 0.4998682141304016
recon_loss: 0.027098432183265686, dist_loss: 0.6743844151496887
recon_loss: 0.027097731828689575, dist_loss: 0.7485623359680176
recon_loss: 0.027097566053271294, dist_loss: 0.39714089035987854
recon_loss: 0.027096973732113838, dist_loss: 0.6410989761352539
recon_loss: 0.02709655649960041, dist_loss: 0.6095750331878662
recon_loss: 0.027096109464764595, dist_loss: 0.6407789587974548
recon_loss: 0.027095580473542213, dist_loss: 0.6760976314544678
recon_loss: 0.027095692232251167, dist_loss: 0.506975531578064
Pre-training Epoch 124:  38%|███▊      | 141/367 [00:00<00:01, 171.01it/s]Pre-training Epoch 124:  43%|████▎     | 159/367 [00:00<00:01, 173.09it/s]Pre-training Epoch 124:  48%|████▊     | 177/367 [00:01<00:01, 173.15it/s]Pre-training Epoch 124:  53%|█████▎    | 195/367 [00:01<00:00, 172.38it/s]Pre-training Epoch 124:  58%|█████▊    | 213/367 [00:01<00:00, 174.08it/s]Pre-training Epoch 124:  63%|██████▎   | 231/367 [00:01<00:00, 175.28it/s]Pre-training Epoch 124:  68%|██████▊   | 249/367 [00:01<00:00, 175.55it/s]recon_loss: 0.027095472440123558, dist_loss: 0.5218042731285095
recon_loss: 0.027096085250377655, dist_loss: 0.5627509355545044
recon_loss: 0.027095522731542587, dist_loss: 0.6613359451293945
recon_loss: 0.027095817029476166, dist_loss: 0.8217089772224426
recon_loss: 0.027095448225736618, dist_loss: 0.5365819334983826
recon_loss: 0.02709541842341423, dist_loss: 0.2360130399465561
recon_loss: 0.027095329016447067, dist_loss: 1.119736671447754
recon_loss: 0.02709515392780304, dist_loss: 0.6501254439353943
recon_loss: 0.027094818651676178, dist_loss: 1.3460466861724854
recon_loss: 0.027094971388578415, dist_loss: 0.37630075216293335
recon_loss: 0.027094559744000435, dist_loss: 0.6497462391853333
recon_loss: 0.027094965800642967, dist_loss: 0.6921818256378174
recon_loss: 0.027094146236777306, dist_loss: 0.9387935400009155
recon_loss: 0.027094125747680664, dist_loss: 0.4118104875087738
recon_loss: 0.02709364704787731, dist_loss: 0.4677119255065918
recon_loss: 0.027094047516584396, dist_loss: 0.702475905418396
recon_loss: 0.027093684300780296, dist_loss: 0.6348562240600586
recon_loss: 0.027094269171357155, dist_loss: 0.31439346075057983
recon_loss: 0.027094583958387375, dist_loss: 0.7511789202690125
recon_loss: 0.027094628661870956, dist_loss: 0.39907732605934143
recon_loss: 0.027094766497612, dist_loss: 0.3946536183357239
recon_loss: 0.027094710618257523, dist_loss: 0.7360754013061523
recon_loss: 0.027094641700387, dist_loss: 0.42207103967666626
recon_loss: 0.027095895260572433, dist_loss: 0.7896314859390259
recon_loss: 0.027095625177025795, dist_loss: 0.37985795736312866
recon_loss: 0.02709701843559742, dist_loss: 0.5939205884933472
recon_loss: 0.027096401900053024, dist_loss: 0.6698699593544006
recon_loss: 0.027096189558506012, dist_loss: 0.41826748847961426
recon_loss: 0.027096383273601532, dist_loss: 0.41680946946144104
recon_loss: 0.027095919474959373, dist_loss: 0.5916317105293274
recon_loss: 0.027095966041088104, dist_loss: 0.942807674407959
recon_loss: 0.027095351368188858, dist_loss: 0.9566232562065125
recon_loss: 0.027095545083284378, dist_loss: 0.6990395784378052
recon_loss: 0.02709496021270752, dist_loss: 0.759867787361145
recon_loss: 0.027095763012766838, dist_loss: 0.35353630781173706
recon_loss: 0.02709607221186161, dist_loss: 0.5647460222244263
recon_loss: 0.027095964178442955, dist_loss: 0.6461078524589539
recon_loss: 0.027095435187220573, dist_loss: 0.8172542452812195
recon_loss: 0.02709510549902916, dist_loss: 0.7253932952880859
recon_loss: 0.02709495648741722, dist_loss: 0.798236608505249
recon_loss: 0.02709539420902729, dist_loss: 0.49221986532211304
recon_loss: 0.0270957350730896, dist_loss: 0.7632962465286255
recon_loss: 0.027097191661596298, dist_loss: 0.9390491843223572
recon_loss: 0.027099085971713066, dist_loss: 0.671064019203186
recon_loss: 0.02710096351802349, dist_loss: 0.5677350759506226
recon_loss: 0.027103208005428314, dist_loss: 0.5874373912811279
recon_loss: 0.02710624970495701, dist_loss: 0.46381378173828125
recon_loss: 0.02710820361971855, dist_loss: 0.4389539361000061
recon_loss: 0.02710822783410549, dist_loss: 0.9902313947677612
recon_loss: 0.027108384296298027, dist_loss: 0.7933791279792786
recon_loss: 0.027107123285531998, dist_loss: 0.7622461318969727
recon_loss: 0.027105260640382767, dist_loss: 0.4035581350326538
recon_loss: 0.027102749794721603, dist_loss: 0.3211533725261688
recon_loss: 0.02710057608783245, dist_loss: 0.8451922535896301
recon_loss: 0.027098383754491806, dist_loss: 1.1784316301345825
recon_loss: 0.027097409591078758, dist_loss: 0.5791897177696228
recon_loss: 0.0270965788513422, dist_loss: 0.7995108366012573
recon_loss: 0.027095939964056015, dist_loss: 1.1141761541366577
recon_loss: 0.027095887809991837, dist_loss: 0.7742608785629272
recon_loss: 0.027095802128314972, dist_loss: 0.3880004286766052
recon_loss: 0.027095593512058258, dist_loss: 0.3976859450340271
recon_loss: 0.027095306664705276, dist_loss: 0.4858091473579407
recon_loss: 0.027094777673482895, dist_loss: 0.635130763053894
recon_loss: 0.027094047516584396, dist_loss: 0.6522817611694336
recon_loss: 0.027093594893813133, dist_loss: 0.9372539520263672
recon_loss: 0.0270934347063303, dist_loss: 0.4871707260608673
recon_loss: 0.027093714103102684, dist_loss: 0.4704572856426239
recon_loss: 0.027094069868326187, dist_loss: 0.470928430557251
recon_loss: 0.027093961834907532, dist_loss: 0.850966215133667
recon_loss: 0.0270940363407135, dist_loss: 0.5009180903434753
recon_loss: 0.02709386870265007, dist_loss: 0.24870003759860992
recon_loss: 0.02709375135600567, dist_loss: 0.9384581446647644
recon_loss: 0.02709377557039261, dist_loss: 0.5603803992271423
recon_loss: 0.027095241472125053, dist_loss: 0.49771228432655334
recon_loss: 0.02709563821554184, dist_loss: 0.8907307386398315
recon_loss: 0.02709677815437317, dist_loss: 0.65208899974823
recon_loss: 0.027096597477793694, dist_loss: 0.7871358394622803
recon_loss: 0.027096590027213097, dist_loss: 0.6685444116592407
recon_loss: 0.027096863836050034, dist_loss: 0.4716653823852539
recon_loss: 0.027096815407276154, dist_loss: 0.4420068562030792
recon_loss: 0.027097227051854134, dist_loss: 0.531882643699646
recon_loss: 0.02709684707224369, dist_loss: 0.7832967042922974
recon_loss: 0.027095835655927658, dist_loss: 0.40298545360565186
recon_loss: 0.027095098048448563, dist_loss: 0.784289538860321
recon_loss: 0.027094034478068352, dist_loss: 0.7258965969085693
recon_loss: 0.027093570679426193, dist_loss: 0.5959993600845337
recon_loss: 0.027093252167105675, dist_loss: 0.5660866498947144
recon_loss: 0.027093715965747833, dist_loss: 0.38422685861587524
recon_loss: 0.027093440294265747, dist_loss: 0.46797969937324524
recon_loss: 0.027093548327684402, dist_loss: 0.5417596101760864
recon_loss: 0.0270929466933012, dist_loss: 0.3383282423019409
recon_loss: 0.02709243819117546, dist_loss: 0.9387524127960205
recon_loss: 0.027091382071375847, dist_loss: 0.5225204825401306
recon_loss: 0.027091024443507195, dist_loss: 0.43162769079208374
recon_loss: 0.027090616524219513, dist_loss: 0.554004430770874
recon_loss: 0.027090976014733315, dist_loss: 0.37913957238197327
recon_loss: 0.027091769501566887, dist_loss: 1.0754318237304688
recon_loss: 0.027091795578598976, dist_loss: 0.388020783662796
recon_loss: 0.02709154225885868, dist_loss: 0.5897791981697083
recon_loss: 0.02709144726395607, dist_loss: 0.649803638458252
recon_loss: 0.027090897783637047, dist_loss: 0.6615804433822632
recon_loss: 0.027090562507510185, dist_loss: 0.5599751472473145
recon_loss: 0.027090441435575485, dist_loss: 0.6115926504135132
recon_loss: 0.02709050104022026, dist_loss: 0.5053907632827759
recon_loss: 0.027090616524219513, dist_loss: 0.3823842704296112
recon_loss: 0.027090992778539658, dist_loss: 0.5031715035438538
recon_loss: 0.027091510593891144, dist_loss: 0.7211017608642578
recon_loss: 0.027091369032859802, dist_loss: 1.1040294170379639
recon_loss: 0.027090977877378464, dist_loss: 0.758573591709137
recon_loss: 0.02709181420505047, dist_loss: 0.7581744194030762
recon_loss: 0.027091197669506073, dist_loss: 0.7459073066711426
recon_loss: 0.02709195204079151, dist_loss: 0.4616249203681946
recon_loss: 0.027091877534985542, dist_loss: 0.7082631587982178
recon_loss: 0.027092402800917625, dist_loss: 0.7435469627380371
recon_loss: 0.027092061936855316, dist_loss: 0.5539942979812622
recon_loss: 0.027092300355434418, dist_loss: 0.8394090533256531
recon_loss: 0.027091622352600098, dist_loss: 0.2522861063480377
recon_loss: 0.027091750875115395, dist_loss: 0.5359989404678345
recon_loss: 0.02709151804447174, dist_loss: 0.432089626789093
recon_loss: 0.02709161303937435, dist_loss: 0.5222719311714172
recon_loss: 0.02709157019853592, dist_loss: 0.5213289260864258
recon_loss: 0.02709188498556614, dist_loss: 0.4399903118610382
recon_loss: 0.027091404423117638, dist_loss: 0.9448052644729614
recon_loss: 0.027091912925243378, dist_loss: 0.5057111978530884
recon_loss: 0.027091631665825844, dist_loss: 0.5382595658302307
recon_loss: 0.02709226682782173, dist_loss: 0.49881893396377563
recon_loss: 0.0270923413336277, dist_loss: 0.9695611000061035
recon_loss: 0.027093064039945602, dist_loss: 0.7335523366928101
Pre-training Epoch 124:  73%|███████▎  | 267/367 [00:01<00:00, 176.81it/s]Pre-training Epoch 124:  78%|███████▊  | 286/367 [00:01<00:00, 177.96it/s]Pre-training Epoch 124:  83%|████████▎ | 304/367 [00:01<00:00, 177.99it/s]Pre-training Epoch 124:  88%|████████▊ | 322/367 [00:01<00:00, 171.50it/s]Pre-training Epoch 124:  93%|█████████▎| 340/367 [00:01<00:00, 172.62it/s]Pre-training Epoch 124:  98%|█████████▊| 358/367 [00:02<00:00, 172.53it/s]Pre-training Epoch 124: 100%|██████████| 367/367 [00:02<00:00, 172.56it/s]
recon_loss: 0.027092790231108665, dist_loss: 0.5708599090576172
recon_loss: 0.027092959731817245, dist_loss: 0.6804004907608032
recon_loss: 0.02709299698472023, dist_loss: 0.6446088552474976
recon_loss: 0.02709251269698143, dist_loss: 0.8046184778213501
recon_loss: 0.02709239348769188, dist_loss: 0.786270260810852
recon_loss: 0.027092361822724342, dist_loss: 0.7908946871757507
recon_loss: 0.02709266170859337, dist_loss: 0.9772742986679077
recon_loss: 0.02709239535033703, dist_loss: 0.3226627707481384
recon_loss: 0.027091896161437035, dist_loss: 0.5955771207809448
recon_loss: 0.02709147147834301, dist_loss: 0.7185038328170776
recon_loss: 0.027090953662991524, dist_loss: 0.6033400893211365
recon_loss: 0.027090219780802727, dist_loss: 0.4013620913028717
recon_loss: 0.02708984538912773, dist_loss: 0.5179405212402344
recon_loss: 0.027089443057775497, dist_loss: 0.34045886993408203
recon_loss: 0.027088871225714684, dist_loss: 0.559446394443512
recon_loss: 0.027088196948170662, dist_loss: 0.4232522249221802
recon_loss: 0.02708805724978447, dist_loss: 0.68181312084198
recon_loss: 0.027088046073913574, dist_loss: 0.4598274230957031
recon_loss: 0.02708836831152439, dist_loss: 0.7923661470413208
recon_loss: 0.027088334783911705, dist_loss: 0.8298898935317993
recon_loss: 0.02708825096487999, dist_loss: 1.0527420043945312
recon_loss: 0.02708837017416954, dist_loss: 0.5103639364242554
recon_loss: 0.027088377624750137, dist_loss: 0.5613982081413269
recon_loss: 0.027088800445199013, dist_loss: 0.9307901263237
recon_loss: 0.02708905003964901, dist_loss: 0.545777440071106
recon_loss: 0.027089225128293037, dist_loss: 0.6908726692199707
recon_loss: 0.02708878554403782, dist_loss: 0.639676570892334
recon_loss: 0.027088752016425133, dist_loss: 0.559002161026001
recon_loss: 0.027088554576039314, dist_loss: 0.5889880657196045
recon_loss: 0.02708854340016842, dist_loss: 0.30627989768981934
recon_loss: 0.02708858624100685, dist_loss: 0.6873514652252197
recon_loss: 0.027088593691587448, dist_loss: 0.3063270151615143
recon_loss: 0.02708887681365013, dist_loss: 0.8070903420448303
recon_loss: 0.02708902396261692, dist_loss: 0.31920361518859863
recon_loss: 0.027089372277259827, dist_loss: 0.5968403816223145
recon_loss: 0.027089005336165428, dist_loss: 0.5299402475357056
recon_loss: 0.027089128270745277, dist_loss: 0.889418363571167
recon_loss: 0.027089333161711693, dist_loss: 0.5138413906097412
recon_loss: 0.02708994783461094, dist_loss: 0.826653242111206
recon_loss: 0.027090096846222878, dist_loss: 0.6624237895011902
recon_loss: 0.02709016017615795, dist_loss: 0.5759404301643372
recon_loss: 0.027090519666671753, dist_loss: 0.8769389390945435
recon_loss: 0.027090443298220634, dist_loss: 0.5264915227890015
recon_loss: 0.027091698721051216, dist_loss: 0.6330152750015259
recon_loss: 0.02709275670349598, dist_loss: 0.36618492007255554
recon_loss: 0.027093447744846344, dist_loss: 0.3850548267364502
recon_loss: 0.02709302119910717, dist_loss: 0.48677629232406616
recon_loss: 0.02709278091788292, dist_loss: 0.48245733976364136
recon_loss: 0.027093077078461647, dist_loss: 0.6813802719116211
recon_loss: 0.027092693373560905, dist_loss: 1.2904568910598755
recon_loss: 0.027092156931757927, dist_loss: 0.471091628074646
recon_loss: 0.02709176577627659, dist_loss: 0.8803682327270508
recon_loss: 0.02709115855395794, dist_loss: 0.5309473276138306
recon_loss: 0.027090800926089287, dist_loss: 0.8302329778671265
recon_loss: 0.027090370655059814, dist_loss: 0.42396560311317444
recon_loss: 0.02709018997848034, dist_loss: 0.6183674931526184
recon_loss: 0.027090420946478844, dist_loss: 0.5791465640068054
recon_loss: 0.027091074734926224, dist_loss: 0.8024548888206482
recon_loss: 0.027090763673186302, dist_loss: 0.32070279121398926
recon_loss: 0.027092505246400833, dist_loss: 0.518956184387207
recon_loss: 0.02709297463297844, dist_loss: 0.698312520980835
recon_loss: 0.027094800025224686, dist_loss: 0.801426112651825
recon_loss: 0.027094421908259392, dist_loss: 0.4567210078239441
recon_loss: 0.027094654738903046, dist_loss: 1.280805230140686
recon_loss: 0.027092982083559036, dist_loss: 0.48642146587371826
recon_loss: 0.02709282375872135, dist_loss: 0.8539618253707886
recon_loss: 0.027091240510344505, dist_loss: 0.6044217944145203
recon_loss: 0.027091724798083305, dist_loss: 0.9409684538841248
recon_loss: 0.027089107781648636, dist_loss: 0.7539076805114746
recon_loss: 0.027089722454547882, dist_loss: 0.9704188108444214
recon_loss: 0.02708750031888485, dist_loss: 0.40952974557876587
recon_loss: 0.0270888302475214, dist_loss: 1.079162359237671
recon_loss: 0.027087366208434105, dist_loss: 0.4293196201324463
recon_loss: 0.027089722454547882, dist_loss: 0.5791487097740173
recon_loss: 0.027090663090348244, dist_loss: 0.3197978734970093
recon_loss: 0.02709319442510605, dist_loss: 0.9183580875396729
recon_loss: 0.02709275111556053, dist_loss: 0.6793967485427856
recon_loss: 0.027093134820461273, dist_loss: 0.5857822895050049
recon_loss: 0.02709173783659935, dist_loss: 0.6047426462173462
recon_loss: 0.027092281728982925, dist_loss: 0.5652869343757629
recon_loss: 0.027092820033431053, dist_loss: 0.5834853649139404
recon_loss: 0.0270927082747221, dist_loss: 0.6417922377586365
recon_loss: 0.02709370292723179, dist_loss: 0.5257934927940369
recon_loss: 0.027090460062026978, dist_loss: 0.5311658978462219
recon_loss: 0.027091221883893013, dist_loss: 0.5443835854530334
recon_loss: 0.027089031413197517, dist_loss: 0.43915337324142456
recon_loss: 0.02709018811583519, dist_loss: 0.6563454866409302
recon_loss: 0.027088342234492302, dist_loss: 0.8170114159584045
recon_loss: 0.027090074494481087, dist_loss: 0.3267027735710144
recon_loss: 0.027088047936558723, dist_loss: 0.3490830957889557
recon_loss: 0.02708887867629528, dist_loss: 0.6278508901596069
recon_loss: 0.02708701230585575, dist_loss: 0.5175939798355103
recon_loss: 0.02708788774907589, dist_loss: 0.4441279172897339
recon_loss: 0.027086447924375534, dist_loss: 1.3938074111938477
recon_loss: 0.027086656540632248, dist_loss: 1.0941307544708252
recon_loss: 0.027086928486824036, dist_loss: 0.5923870801925659
recon_loss: 0.027087347581982613, dist_loss: 0.36098796129226685
recon_loss: 0.02708791196346283, dist_loss: 1.1637310981750488
recon_loss: 0.027087721973657608, dist_loss: 0.5407562255859375
recon_loss: 0.027088133618235588, dist_loss: 0.6643732190132141
recon_loss: 0.027087999507784843, dist_loss: 1.1343662738800049
recon_loss: 0.027088480070233345, dist_loss: 0.5986482501029968
recon_loss: 0.027088526636362076, dist_loss: 0.5071432590484619
recon_loss: 0.027088962495326996, dist_loss: 0.6800386309623718
recon_loss: 0.027089020237326622, dist_loss: 0.7782329320907593
recon_loss: 0.02708948589861393, dist_loss: 0.4738858938217163
recon_loss: 0.027089297771453857, dist_loss: 0.7686864137649536
recon_loss: 0.027087729424238205, dist_loss: 0.5516239404678345
recon_loss: 0.02708733081817627, dist_loss: 0.47057878971099854
recon_loss: 0.02708631381392479, dist_loss: 0.6234679818153381
recon_loss: 0.027086298912763596, dist_loss: 0.4394085109233856
Pre-training Epoch 125:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 125:   5%|▍         | 17/367 [00:00<00:02, 161.69it/s]Pre-training Epoch 125:   9%|▉         | 34/367 [00:00<00:02, 155.46it/s]Pre-training Epoch 125:  14%|█▎        | 50/367 [00:00<00:02, 147.05it/s]Pre-training Epoch 125:  19%|█▊        | 68/367 [00:00<00:01, 157.64it/s]Pre-training Epoch 125:  23%|██▎       | 86/367 [00:00<00:01, 163.70it/s]Pre-training Epoch 125:  29%|██▊       | 105/367 [00:00<00:01, 171.59it/s]Pre-training Epoch 125:  34%|███▍      | 125/367 [00:00<00:01, 178.74it/s]recon_loss: 0.0270860455930233, dist_loss: 0.8229745030403137
recon_loss: 0.02708585560321808, dist_loss: 0.8112570643424988
recon_loss: 0.027085108682513237, dist_loss: 0.628806471824646
recon_loss: 0.02708471193909645, dist_loss: 0.3519350588321686
recon_loss: 0.027084089815616608, dist_loss: 0.5519782900810242
recon_loss: 0.027083903551101685, dist_loss: 0.9118901491165161
recon_loss: 0.02708422765135765, dist_loss: 0.6520437002182007
recon_loss: 0.027085091918706894, dist_loss: 0.4291517734527588
recon_loss: 0.02708492986857891, dist_loss: 0.6475300192832947
recon_loss: 0.02708606980741024, dist_loss: 0.5144151449203491
recon_loss: 0.02708486281335354, dist_loss: 0.6309877634048462
recon_loss: 0.02708510309457779, dist_loss: 0.7512338757514954
recon_loss: 0.027084672823548317, dist_loss: 0.576172947883606
recon_loss: 0.027085188776254654, dist_loss: 0.42976537346839905
recon_loss: 0.027085019275546074, dist_loss: 1.535037636756897
recon_loss: 0.027085741981863976, dist_loss: 0.5303215980529785
recon_loss: 0.027084562927484512, dist_loss: 0.8401067852973938
recon_loss: 0.02708476036787033, dist_loss: 0.5588415861129761
recon_loss: 0.027083445340394974, dist_loss: 0.775885820388794
recon_loss: 0.027083713561296463, dist_loss: 0.5042974948883057
recon_loss: 0.0270831361413002, dist_loss: 0.5323275327682495
recon_loss: 0.027083247900009155, dist_loss: 0.8858539462089539
recon_loss: 0.027083074674010277, dist_loss: 0.5094143748283386
recon_loss: 0.027083346620202065, dist_loss: 0.47690635919570923
recon_loss: 0.027083950117230415, dist_loss: 0.8275898098945618
recon_loss: 0.027084507048130035, dist_loss: 0.5505234003067017
recon_loss: 0.027085155248641968, dist_loss: 0.2816508412361145
recon_loss: 0.027085453271865845, dist_loss: 0.43233054876327515
recon_loss: 0.02708533965051174, dist_loss: 0.5493545532226562
recon_loss: 0.027085553854703903, dist_loss: 0.4153122305870056
recon_loss: 0.027085622772574425, dist_loss: 0.4329116642475128
recon_loss: 0.027085280045866966, dist_loss: 0.9425666928291321
recon_loss: 0.027085525915026665, dist_loss: 0.7614582180976868
recon_loss: 0.02708418108522892, dist_loss: 0.6358216404914856
recon_loss: 0.02708444371819496, dist_loss: 0.9232687950134277
recon_loss: 0.027083655819296837, dist_loss: 0.6710976362228394
recon_loss: 0.027084164321422577, dist_loss: 0.7565978765487671
recon_loss: 0.027084333822131157, dist_loss: 0.4334898889064789
recon_loss: 0.027084849774837494, dist_loss: 0.8034377098083496
recon_loss: 0.02708602137863636, dist_loss: 0.46413204073905945
recon_loss: 0.02708665281534195, dist_loss: 1.1407901048660278
recon_loss: 0.027088260278105736, dist_loss: 0.5912865400314331
recon_loss: 0.027088165283203125, dist_loss: 0.6621872186660767
recon_loss: 0.02708875760436058, dist_loss: 0.4568995237350464
recon_loss: 0.027087679132819176, dist_loss: 0.5375114679336548
recon_loss: 0.0270867720246315, dist_loss: 0.7072961330413818
recon_loss: 0.027085481211543083, dist_loss: 0.7711207866668701
recon_loss: 0.0270853154361248, dist_loss: 0.5797601938247681
recon_loss: 0.027086028829216957, dist_loss: 0.6836193203926086
recon_loss: 0.027087612077593803, dist_loss: 0.584829568862915
recon_loss: 0.027086660265922546, dist_loss: 0.8791253566741943
recon_loss: 0.027087315917015076, dist_loss: 0.6232877969741821
recon_loss: 0.027085652574896812, dist_loss: 0.6490483283996582
recon_loss: 0.027085525915026665, dist_loss: 0.5492644309997559
recon_loss: 0.027084065601229668, dist_loss: 0.5406398773193359
recon_loss: 0.027083618566393852, dist_loss: 0.6878899931907654
recon_loss: 0.027083508670330048, dist_loss: 0.5869077444076538
recon_loss: 0.027083035558462143, dist_loss: 0.6665651798248291
recon_loss: 0.0270829014480114, dist_loss: 0.8600249290466309
recon_loss: 0.0270831435918808, dist_loss: 0.9320065975189209
recon_loss: 0.02708384022116661, dist_loss: 0.5320680737495422
recon_loss: 0.027084458619356155, dist_loss: 0.7772436738014221
recon_loss: 0.02708522230386734, dist_loss: 0.7690045237541199
recon_loss: 0.027086153626441956, dist_loss: 0.7539498805999756
recon_loss: 0.027086369693279266, dist_loss: 0.42578214406967163
recon_loss: 0.027086393907666206, dist_loss: 0.4872419238090515
recon_loss: 0.02708521857857704, dist_loss: 0.4103601276874542
recon_loss: 0.02708394266664982, dist_loss: 0.4790016710758209
recon_loss: 0.02708279900252819, dist_loss: 1.0954492092132568
recon_loss: 0.02708258293569088, dist_loss: 0.43125903606414795
recon_loss: 0.027083149179816246, dist_loss: 0.7362172603607178
recon_loss: 0.02708475850522518, dist_loss: 0.6434141397476196
recon_loss: 0.027086669579148293, dist_loss: 0.3483658730983734
recon_loss: 0.02708892710506916, dist_loss: 0.49012476205825806
recon_loss: 0.02709037810564041, dist_loss: 1.0162227153778076
recon_loss: 0.027091076597571373, dist_loss: 0.682931125164032
recon_loss: 0.027091462165117264, dist_loss: 0.5897552371025085
recon_loss: 0.027090396732091904, dist_loss: 0.3850129544734955
recon_loss: 0.02708934247493744, dist_loss: 0.42448458075523376
recon_loss: 0.02708735130727291, dist_loss: 0.6364783644676208
recon_loss: 0.0270855650305748, dist_loss: 0.4840364158153534
recon_loss: 0.027084119617938995, dist_loss: 0.3536912202835083
recon_loss: 0.027083955705165863, dist_loss: 1.1454732418060303
recon_loss: 0.02708454243838787, dist_loss: 0.6177695393562317
recon_loss: 0.027086278423666954, dist_loss: 1.1813533306121826
recon_loss: 0.027086913585662842, dist_loss: 0.4096846282482147
recon_loss: 0.027089443057775497, dist_loss: 0.8633325099945068
recon_loss: 0.02708938531577587, dist_loss: 0.5661524534225464
recon_loss: 0.027090881019830704, dist_loss: 0.5483013987541199
recon_loss: 0.027089620009064674, dist_loss: 0.8281819820404053
recon_loss: 0.027089865878224373, dist_loss: 1.1865386962890625
recon_loss: 0.027089202776551247, dist_loss: 0.8663849234580994
recon_loss: 0.027089951559901237, dist_loss: 0.5331161022186279
recon_loss: 0.027088727802038193, dist_loss: 0.4534182548522949
recon_loss: 0.02708827517926693, dist_loss: 0.7427548170089722
recon_loss: 0.027086958289146423, dist_loss: 0.6640968322753906
recon_loss: 0.02708633430302143, dist_loss: 0.6895878314971924
recon_loss: 0.027085740119218826, dist_loss: 0.9467710852622986
recon_loss: 0.02708577737212181, dist_loss: 0.4124763011932373
recon_loss: 0.027085931971669197, dist_loss: 0.7278620600700378
recon_loss: 0.027086669579148293, dist_loss: 1.7156070470809937
recon_loss: 0.02708645910024643, dist_loss: 0.6302167177200317
recon_loss: 0.027086876332759857, dist_loss: 0.5390638113021851
recon_loss: 0.02708674781024456, dist_loss: 0.6687127351760864
recon_loss: 0.02708647958934307, dist_loss: 0.5973485708236694
recon_loss: 0.02708645910024643, dist_loss: 0.7069177627563477
recon_loss: 0.027086175978183746, dist_loss: 0.7584599256515503
recon_loss: 0.027085766196250916, dist_loss: 0.747660219669342
recon_loss: 0.02708541415631771, dist_loss: 0.7714996337890625
recon_loss: 0.027084559202194214, dist_loss: 0.7558441162109375
recon_loss: 0.027083631604909897, dist_loss: 0.4970599114894867
recon_loss: 0.02708270400762558, dist_loss: 0.6612050533294678
recon_loss: 0.027082178741693497, dist_loss: 0.7545549869537354
recon_loss: 0.027081774547696114, dist_loss: 0.422216534614563
recon_loss: 0.027081910520792007, dist_loss: 0.5265092849731445
recon_loss: 0.02708328887820244, dist_loss: 0.2844325602054596
recon_loss: 0.02708510309457779, dist_loss: 0.3351154923439026
recon_loss: 0.027087394148111343, dist_loss: 0.614755392074585
recon_loss: 0.027089616283774376, dist_loss: 0.5915589332580566
recon_loss: 0.027092255651950836, dist_loss: 0.4887445569038391
recon_loss: 0.02709301747381687, dist_loss: 0.8131174445152283
recon_loss: 0.027094082906842232, dist_loss: 0.739377498626709
recon_loss: 0.027090787887573242, dist_loss: 0.6514500975608826
recon_loss: 0.027088401839137077, dist_loss: 0.5089759230613708
recon_loss: 0.02708684280514717, dist_loss: 0.3559436798095703
recon_loss: 0.02708614058792591, dist_loss: 0.5289099216461182
recon_loss: 0.02708578109741211, dist_loss: 1.1860532760620117
recon_loss: 0.02708565443754196, dist_loss: 0.301321804523468
Pre-training Epoch 125:  40%|███▉      | 145/367 [00:00<00:01, 183.20it/s]Pre-training Epoch 125:  45%|████▍     | 165/367 [00:00<00:01, 186.35it/s]Pre-training Epoch 125:  50%|█████     | 185/367 [00:01<00:00, 188.62it/s]Pre-training Epoch 125:  56%|█████▌    | 204/367 [00:01<00:00, 182.88it/s]Pre-training Epoch 125:  61%|██████    | 223/367 [00:01<00:00, 173.85it/s]Pre-training Epoch 125:  66%|██████▌   | 241/367 [00:01<00:00, 165.16it/s]recon_loss: 0.02708553709089756, dist_loss: 0.7022345066070557
recon_loss: 0.02708565816283226, dist_loss: 0.313583105802536
recon_loss: 0.027085788547992706, dist_loss: 0.9065864682197571
recon_loss: 0.02708548866212368, dist_loss: 0.877966046333313
recon_loss: 0.027084816247224808, dist_loss: 0.5836952328681946
recon_loss: 0.02708408050239086, dist_loss: 0.9629349708557129
recon_loss: 0.02708377316594124, dist_loss: 0.46256816387176514
recon_loss: 0.027083706110715866, dist_loss: 0.7213202118873596
recon_loss: 0.02708376757800579, dist_loss: 0.8408238887786865
recon_loss: 0.02708413079380989, dist_loss: 0.4644484519958496
recon_loss: 0.027084559202194214, dist_loss: 0.4876950681209564
recon_loss: 0.027084890753030777, dist_loss: 0.5317927002906799
recon_loss: 0.027084816247224808, dist_loss: 0.38746848702430725
recon_loss: 0.0270838662981987, dist_loss: 0.6098449230194092
recon_loss: 0.02708270773291588, dist_loss: 0.6602510213851929
recon_loss: 0.027082273736596107, dist_loss: 0.9588438272476196
recon_loss: 0.027082376182079315, dist_loss: 0.9692832827568054
recon_loss: 0.02708197385072708, dist_loss: 0.6625531315803528
recon_loss: 0.02708166092634201, dist_loss: 0.5305774211883545
recon_loss: 0.027081221342086792, dist_loss: 0.8561167120933533
recon_loss: 0.027081383392214775, dist_loss: 0.5077576637268066
recon_loss: 0.027081260457634926, dist_loss: 0.6518452167510986
recon_loss: 0.027080833911895752, dist_loss: 0.6478231549263
recon_loss: 0.027080180123448372, dist_loss: 0.5898292660713196
recon_loss: 0.027079442515969276, dist_loss: 0.5553262233734131
recon_loss: 0.02707916684448719, dist_loss: 0.3446269929409027
recon_loss: 0.02707860805094242, dist_loss: 0.6325182914733887
recon_loss: 0.02707863412797451, dist_loss: 0.5176538228988647
recon_loss: 0.02707851678133011, dist_loss: 0.9380340576171875
recon_loss: 0.027079274877905846, dist_loss: 0.6193510293960571
recon_loss: 0.0270791407674551, dist_loss: 0.6507577896118164
recon_loss: 0.027079787105321884, dist_loss: 0.5756264925003052
recon_loss: 0.027079220861196518, dist_loss: 0.6364097595214844
recon_loss: 0.027080396190285683, dist_loss: 0.7813128232955933
recon_loss: 0.027079517021775246, dist_loss: 0.7210735082626343
recon_loss: 0.027080051600933075, dist_loss: 0.5666952133178711
recon_loss: 0.02707969769835472, dist_loss: 0.6840131878852844
recon_loss: 0.02708207070827484, dist_loss: 0.9343053102493286
recon_loss: 0.02708292379975319, dist_loss: 1.0248503684997559
recon_loss: 0.027087226510047913, dist_loss: 0.8457112312316895
recon_loss: 0.027089262381196022, dist_loss: 0.447456419467926
recon_loss: 0.027094107121229172, dist_loss: 0.627338171005249
recon_loss: 0.027095813304185867, dist_loss: 0.4430934488773346
recon_loss: 0.02709861658513546, dist_loss: 0.5778912901878357
recon_loss: 0.027096452191472054, dist_loss: 0.5531747341156006
recon_loss: 0.027095280587673187, dist_loss: 0.5274739265441895
recon_loss: 0.027094000950455666, dist_loss: 0.7959050536155701
recon_loss: 0.027092929929494858, dist_loss: 0.7983425855636597
recon_loss: 0.027090488001704216, dist_loss: 0.7041102051734924
recon_loss: 0.027087995782494545, dist_loss: 0.5628173351287842
recon_loss: 0.027085093781352043, dist_loss: 0.5788194537162781
recon_loss: 0.02708393894135952, dist_loss: 0.6568281650543213
recon_loss: 0.02708275616168976, dist_loss: 0.656800389289856
recon_loss: 0.02708241529762745, dist_loss: 0.4839983582496643
recon_loss: 0.027083776891231537, dist_loss: 0.5477664470672607
recon_loss: 0.02708473429083824, dist_loss: 0.5387617349624634
recon_loss: 0.027086570858955383, dist_loss: 0.49394384026527405
recon_loss: 0.027086222544312477, dist_loss: 0.6918649077415466
recon_loss: 0.027086665853857994, dist_loss: 0.8384201526641846
recon_loss: 0.027083521708846092, dist_loss: 0.5667949914932251
recon_loss: 0.027081981301307678, dist_loss: 0.41319605708122253
recon_loss: 0.02707957848906517, dist_loss: 1.0621850490570068
recon_loss: 0.027080044150352478, dist_loss: 0.5091820359230042
recon_loss: 0.027078036218881607, dist_loss: 0.3733604848384857
recon_loss: 0.027079207822680473, dist_loss: 0.37326252460479736
recon_loss: 0.027078529819846153, dist_loss: 0.27487245202064514
recon_loss: 0.02707972377538681, dist_loss: 0.3682359755039215
recon_loss: 0.027079612016677856, dist_loss: 0.5393267273902893
recon_loss: 0.027080371975898743, dist_loss: 0.5738474726676941
recon_loss: 0.027079200372099876, dist_loss: 0.4043612480163574
recon_loss: 0.027078494429588318, dist_loss: 0.9532906413078308
recon_loss: 0.02707812376320362, dist_loss: 0.6907102465629578
recon_loss: 0.02707764506340027, dist_loss: 0.46145400404930115
recon_loss: 0.027077622711658478, dist_loss: 0.9419261813163757
recon_loss: 0.027077047154307365, dist_loss: 0.3438931107521057
recon_loss: 0.027077311649918556, dist_loss: 0.9157148599624634
recon_loss: 0.02707670070230961, dist_loss: 0.5286102294921875
recon_loss: 0.027077943086624146, dist_loss: 0.7174263596534729
recon_loss: 0.027077551931142807, dist_loss: 0.494724839925766
recon_loss: 0.02707943506538868, dist_loss: 0.8921176791191101
recon_loss: 0.027078865095973015, dist_loss: 0.4172612428665161
recon_loss: 0.02708117663860321, dist_loss: 0.5131635069847107
recon_loss: 0.027079615741968155, dist_loss: 0.7696694731712341
recon_loss: 0.02708064392209053, dist_loss: 0.497374951839447
recon_loss: 0.027077827602624893, dist_loss: 0.4620635509490967
recon_loss: 0.027079351246356964, dist_loss: 0.7734559774398804
recon_loss: 0.02707814611494541, dist_loss: 0.7720963954925537
recon_loss: 0.027077192440629005, dist_loss: 0.3649889826774597
recon_loss: 0.027076944708824158, dist_loss: 0.40590253472328186
recon_loss: 0.027076056227087975, dist_loss: 0.43641629815101624
recon_loss: 0.027076711878180504, dist_loss: 0.6322564482688904
recon_loss: 0.02707647904753685, dist_loss: 0.8600407242774963
recon_loss: 0.027077484875917435, dist_loss: 0.45564261078834534
recon_loss: 0.027077361941337585, dist_loss: 0.5553101897239685
recon_loss: 0.027078859508037567, dist_loss: 0.8726052045822144
recon_loss: 0.027077563107013702, dist_loss: 0.4126089811325073
recon_loss: 0.0270784180611372, dist_loss: 0.5167715549468994
recon_loss: 0.027077626436948776, dist_loss: 0.3772352337837219
recon_loss: 0.027078604325652122, dist_loss: 0.5524166822433472
recon_loss: 0.027077816426753998, dist_loss: 0.7841833829879761
recon_loss: 0.02707790955901146, dist_loss: 1.0926179885864258
recon_loss: 0.027077408507466316, dist_loss: 0.29713955521583557
recon_loss: 0.027077579870820045, dist_loss: 0.44486939907073975
recon_loss: 0.027077507227659225, dist_loss: 0.3961241543292999
recon_loss: 0.027077259495854378, dist_loss: 1.1439125537872314
recon_loss: 0.02707688882946968, dist_loss: 0.4700670838356018
recon_loss: 0.027076872065663338, dist_loss: 0.3228532075881958
recon_loss: 0.027076901867985725, dist_loss: 0.30539199709892273
recon_loss: 0.02707624062895775, dist_loss: 0.4459071755409241
recon_loss: 0.027075937017798424, dist_loss: 0.4894248843193054
recon_loss: 0.027075745165348053, dist_loss: 0.9665510654449463
recon_loss: 0.02707596868276596, dist_loss: 0.4197489619255066
recon_loss: 0.027076277881860733, dist_loss: 0.47618868947029114
recon_loss: 0.027076808735728264, dist_loss: 0.661704421043396
recon_loss: 0.02707734704017639, dist_loss: 0.7384015321731567
recon_loss: 0.027077874168753624, dist_loss: 0.7469848990440369
recon_loss: 0.0270782969892025, dist_loss: 0.6687384247779846
recon_loss: 0.02707858383655548, dist_loss: 0.6290656328201294
recon_loss: 0.027078377082943916, dist_loss: 1.0191007852554321
recon_loss: 0.02707809768617153, dist_loss: 0.6533414125442505
recon_loss: 0.02707788720726967, dist_loss: 0.7885512709617615
recon_loss: 0.027077650651335716, dist_loss: 0.527681827545166
recon_loss: 0.027076998725533485, dist_loss: 0.6062033176422119
recon_loss: 0.02707693539559841, dist_loss: 0.6671431064605713
recon_loss: 0.02707686647772789, dist_loss: 0.4963899850845337
recon_loss: 0.02707667648792267, dist_loss: 0.611968994140625
recon_loss: 0.027076754719018936, dist_loss: 0.7050048112869263
recon_loss: 0.027078112587332726, dist_loss: 0.5207412242889404
Pre-training Epoch 125:  70%|███████   | 258/367 [00:01<00:00, 160.43it/s]Pre-training Epoch 125:  75%|███████▍  | 275/367 [00:01<00:00, 157.35it/s]Pre-training Epoch 125:  79%|███████▉  | 291/367 [00:01<00:00, 156.07it/s]Pre-training Epoch 125:  84%|████████▎ | 307/367 [00:01<00:00, 153.17it/s]Pre-training Epoch 125:  88%|████████▊ | 323/367 [00:01<00:00, 151.28it/s]Pre-training Epoch 125:  92%|█████████▏| 339/367 [00:02<00:00, 153.51it/s]Pre-training Epoch 125:  97%|█████████▋| 355/367 [00:02<00:00, 153.58it/s]Pre-training Epoch 125: 100%|██████████| 367/367 [00:02<00:00, 163.05it/s]
recon_loss: 0.027077801525592804, dist_loss: 0.7258094549179077
recon_loss: 0.027078310027718544, dist_loss: 0.4140232503414154
recon_loss: 0.027078164741396904, dist_loss: 0.5647715926170349
recon_loss: 0.02707892842590809, dist_loss: 0.5205911993980408
recon_loss: 0.02707902155816555, dist_loss: 0.7452758550643921
recon_loss: 0.027080785483121872, dist_loss: 0.8541104793548584
recon_loss: 0.02708330564200878, dist_loss: 0.2889437675476074
recon_loss: 0.027085376903414726, dist_loss: 0.6233991384506226
recon_loss: 0.027085965499281883, dist_loss: 0.9827369451522827
recon_loss: 0.027087977156043053, dist_loss: 1.1324211359024048
recon_loss: 0.027088381350040436, dist_loss: 0.48669689893722534
recon_loss: 0.027088139206171036, dist_loss: 0.6051926612854004
recon_loss: 0.027086835354566574, dist_loss: 0.5226356387138367
recon_loss: 0.027084751054644585, dist_loss: 0.6789587736129761
recon_loss: 0.02708161622285843, dist_loss: 0.5465331673622131
recon_loss: 0.027079978957772255, dist_loss: 0.6665061712265015
recon_loss: 0.027079228311777115, dist_loss: 0.7341669201850891
recon_loss: 0.027080565690994263, dist_loss: 0.42739632725715637
recon_loss: 0.027082543820142746, dist_loss: 0.5785344243049622
recon_loss: 0.02708602324128151, dist_loss: 0.32641738653182983
recon_loss: 0.02708926610648632, dist_loss: 0.6207395792007446
recon_loss: 0.027090325951576233, dist_loss: 0.44201770424842834
recon_loss: 0.027090566232800484, dist_loss: 0.7930571436882019
recon_loss: 0.027088627219200134, dist_loss: 0.6772701740264893
recon_loss: 0.027086623013019562, dist_loss: 0.5004764199256897
recon_loss: 0.027084525674581528, dist_loss: 0.692846417427063
recon_loss: 0.027082564309239388, dist_loss: 0.48316431045532227
recon_loss: 0.027081428095698357, dist_loss: 0.3480547070503235
recon_loss: 0.027080636471509933, dist_loss: 0.7904592752456665
recon_loss: 0.02708042785525322, dist_loss: 0.4823806881904602
recon_loss: 0.02708015963435173, dist_loss: 0.6068576574325562
recon_loss: 0.027080770581960678, dist_loss: 0.8512455224990845
recon_loss: 0.02708239108324051, dist_loss: 0.5334491729736328
recon_loss: 0.027083566412329674, dist_loss: 0.5389720797538757
recon_loss: 0.02708459459245205, dist_loss: 0.4559633433818817
recon_loss: 0.027085816487669945, dist_loss: 0.8420625925064087
recon_loss: 0.027087414637207985, dist_loss: 0.5794953107833862
recon_loss: 0.027087947353720665, dist_loss: 0.9525712728500366
recon_loss: 0.027088642120361328, dist_loss: 0.7686514854431152
recon_loss: 0.02708894945681095, dist_loss: 0.3094122111797333
recon_loss: 0.027087710797786713, dist_loss: 0.5967599749565125
recon_loss: 0.027086352929472923, dist_loss: 0.8324887752532959
recon_loss: 0.02708347700536251, dist_loss: 0.43006348609924316
recon_loss: 0.027081705629825592, dist_loss: 0.7778404951095581
recon_loss: 0.02708008512854576, dist_loss: 0.7085663080215454
recon_loss: 0.02708009071648121, dist_loss: 0.4839509427547455
recon_loss: 0.027079826220870018, dist_loss: 0.6375293135643005
recon_loss: 0.027081619948148727, dist_loss: 0.2856740355491638
recon_loss: 0.027081681415438652, dist_loss: 0.5397063493728638
recon_loss: 0.027084363624453545, dist_loss: 0.516665518283844
recon_loss: 0.02708514593541622, dist_loss: 0.48125189542770386
recon_loss: 0.0270867757499218, dist_loss: 0.7581712007522583
recon_loss: 0.027084030210971832, dist_loss: 0.8487921357154846
recon_loss: 0.02708340249955654, dist_loss: 0.5153219699859619
recon_loss: 0.02708020806312561, dist_loss: 0.680637776851654
recon_loss: 0.027079081162810326, dist_loss: 0.6562222242355347
recon_loss: 0.027077436447143555, dist_loss: 0.5599321126937866
recon_loss: 0.02707691304385662, dist_loss: 0.4547802805900574
recon_loss: 0.02707679755985737, dist_loss: 0.5816301107406616
recon_loss: 0.027077412232756615, dist_loss: 0.8023430705070496
recon_loss: 0.027078265324234962, dist_loss: 0.9493903517723083
recon_loss: 0.027080046012997627, dist_loss: 0.8895255327224731
recon_loss: 0.02708262763917446, dist_loss: 1.5639808177947998
recon_loss: 0.027084164321422577, dist_loss: 0.7492650151252747
recon_loss: 0.027085529640316963, dist_loss: 0.7302252054214478
recon_loss: 0.027086252346634865, dist_loss: 0.48109495639801025
recon_loss: 0.02708492986857891, dist_loss: 0.44632062315940857
recon_loss: 0.027081629261374474, dist_loss: 0.9935524463653564
recon_loss: 0.02708134800195694, dist_loss: 1.0700106620788574
recon_loss: 0.027080750092864037, dist_loss: 0.3493499755859375
recon_loss: 0.02708139829337597, dist_loss: 0.6143993735313416
recon_loss: 0.027080653235316277, dist_loss: 0.782072126865387
recon_loss: 0.027079058811068535, dist_loss: 1.0547524690628052
recon_loss: 0.027080075815320015, dist_loss: 1.0019481182098389
recon_loss: 0.027079109102487564, dist_loss: 0.6267416477203369
recon_loss: 0.027080900967121124, dist_loss: 0.3745071291923523
recon_loss: 0.02708018384873867, dist_loss: 0.6828325986862183
recon_loss: 0.02708093263208866, dist_loss: 0.5156214237213135
recon_loss: 0.027080899104475975, dist_loss: 0.5640380382537842
recon_loss: 0.027081521227955818, dist_loss: 0.6215783357620239
recon_loss: 0.02708285115659237, dist_loss: 0.7355220317840576
recon_loss: 0.027084052562713623, dist_loss: 0.5648317933082581
recon_loss: 0.027085959911346436, dist_loss: 0.8354870676994324
recon_loss: 0.027089593932032585, dist_loss: 0.2819257974624634
recon_loss: 0.02709125727415085, dist_loss: 0.3413941562175751
recon_loss: 0.027091775089502335, dist_loss: 0.97642582654953
recon_loss: 0.02708967588841915, dist_loss: 0.7307137846946716
recon_loss: 0.027087392285466194, dist_loss: 0.6198813915252686
recon_loss: 0.02708517387509346, dist_loss: 1.0624659061431885
recon_loss: 0.027083268389105797, dist_loss: 0.3155824542045593
recon_loss: 0.027081256732344627, dist_loss: 0.42208072543144226
recon_loss: 0.027080152183771133, dist_loss: 0.43609562516212463
recon_loss: 0.02707963064312935, dist_loss: 0.6694756150245667
recon_loss: 0.02707936242222786, dist_loss: 0.4594619870185852
recon_loss: 0.027078965678811073, dist_loss: 0.5303711891174316
recon_loss: 0.027078190818428993, dist_loss: 0.6431883573532104
recon_loss: 0.027077732607722282, dist_loss: 0.6194015741348267
recon_loss: 0.027077030390501022, dist_loss: 1.0260686874389648
recon_loss: 0.02707715891301632, dist_loss: 0.46540990471839905
recon_loss: 0.02707626111805439, dist_loss: 0.49370354413986206
recon_loss: 0.02707660011947155, dist_loss: 1.1628754138946533
recon_loss: 0.02707638032734394, dist_loss: 0.6279205083847046
recon_loss: 0.02707676589488983, dist_loss: 0.4971989393234253
recon_loss: 0.027076076716184616, dist_loss: 0.42646998167037964
recon_loss: 0.027075830847024918, dist_loss: 1.0525330305099487
recon_loss: 0.027075359597802162, dist_loss: 0.8369429111480713
recon_loss: 0.02707601897418499, dist_loss: 0.5862408876419067
recon_loss: 0.027075788006186485, dist_loss: 0.8946553468704224
recon_loss: 0.027076207101345062, dist_loss: 0.400373637676239
recon_loss: 0.027074532583355904, dist_loss: 0.46340858936309814
recon_loss: 0.027074074372649193, dist_loss: 0.7994667291641235
Pre-training Epoch 126:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 126:   4%|▍         | 15/367 [00:00<00:02, 147.20it/s]Pre-training Epoch 126:   8%|▊         | 30/367 [00:00<00:02, 148.76it/s]Pre-training Epoch 126:  13%|█▎        | 46/367 [00:00<00:02, 149.69it/s]Pre-training Epoch 126:  17%|█▋        | 62/367 [00:00<00:02, 150.05it/s]Pre-training Epoch 126:  21%|██▏       | 78/367 [00:00<00:01, 151.48it/s]Pre-training Epoch 126:  26%|██▌       | 95/367 [00:00<00:01, 155.67it/s]Pre-training Epoch 126:  31%|███▏      | 115/367 [00:00<00:01, 167.56it/s]recon_loss: 0.027075089514255524, dist_loss: 1.1882233619689941
recon_loss: 0.02707655355334282, dist_loss: 0.8450844883918762
recon_loss: 0.027078138664364815, dist_loss: 1.5563361644744873
recon_loss: 0.02707967720925808, dist_loss: 0.6280219554901123
recon_loss: 0.027080925181508064, dist_loss: 0.486588716506958
recon_loss: 0.02708139829337597, dist_loss: 0.4912703037261963
recon_loss: 0.027082249522209167, dist_loss: 0.5523725152015686
recon_loss: 0.02708308957517147, dist_loss: 0.51513671875
recon_loss: 0.027083689346909523, dist_loss: 0.9253178834915161
recon_loss: 0.0270837415009737, dist_loss: 0.453347384929657
recon_loss: 0.027082262560725212, dist_loss: 0.31817877292633057
recon_loss: 0.027081118896603584, dist_loss: 0.8480092287063599
recon_loss: 0.027079341933131218, dist_loss: 0.6775897741317749
recon_loss: 0.027078114449977875, dist_loss: 0.325989305973053
recon_loss: 0.027077719569206238, dist_loss: 0.7214013934135437
recon_loss: 0.027077902108430862, dist_loss: 0.5107112526893616
recon_loss: 0.027078190818428993, dist_loss: 0.6423757672309875
recon_loss: 0.027078861370682716, dist_loss: 0.7031804323196411
recon_loss: 0.02707994356751442, dist_loss: 0.6114917993545532
recon_loss: 0.02708231471478939, dist_loss: 0.49680641293525696
recon_loss: 0.02708345465362072, dist_loss: 0.31689757108688354
recon_loss: 0.027084683999419212, dist_loss: 0.6368231773376465
recon_loss: 0.027085663750767708, dist_loss: 0.7026676535606384
recon_loss: 0.02708675153553486, dist_loss: 0.9985072016716003
recon_loss: 0.0270891971886158, dist_loss: 0.4818611145019531
recon_loss: 0.027089891955256462, dist_loss: 0.6820165514945984
recon_loss: 0.027090473100543022, dist_loss: 0.45028313994407654
recon_loss: 0.027089720591902733, dist_loss: 0.45109620690345764
recon_loss: 0.027088159695267677, dist_loss: 0.6124844551086426
recon_loss: 0.027086254209280014, dist_loss: 0.4837374985218048
recon_loss: 0.027084089815616608, dist_loss: 1.06260347366333
recon_loss: 0.02708308771252632, dist_loss: 0.4236298203468323
recon_loss: 0.02708163857460022, dist_loss: 0.5384266972541809
recon_loss: 0.027081094682216644, dist_loss: 0.4972180128097534
recon_loss: 0.027079612016677856, dist_loss: 0.9603362083435059
recon_loss: 0.027080455794930458, dist_loss: 0.7902997732162476
recon_loss: 0.02707943134009838, dist_loss: 0.6311312913894653
recon_loss: 0.027080103754997253, dist_loss: 0.47217538952827454
recon_loss: 0.02707774192094803, dist_loss: 0.44684672355651855
recon_loss: 0.027079150080680847, dist_loss: 0.6888051629066467
recon_loss: 0.027076518163084984, dist_loss: 0.7338975667953491
recon_loss: 0.027077937498688698, dist_loss: 0.6282564401626587
recon_loss: 0.027076512575149536, dist_loss: 1.314042568206787
recon_loss: 0.027078064158558846, dist_loss: 0.5636357665061951
recon_loss: 0.027077563107013702, dist_loss: 0.8972141742706299
recon_loss: 0.02707831561565399, dist_loss: 0.550936222076416
recon_loss: 0.02707791142165661, dist_loss: 0.7729842662811279
recon_loss: 0.02707844413816929, dist_loss: 0.5277954339981079
recon_loss: 0.02707860805094242, dist_loss: 0.32754969596862793
recon_loss: 0.027078378945589066, dist_loss: 0.7363926768302917
recon_loss: 0.027077844366431236, dist_loss: 0.8032136559486389
recon_loss: 0.027077041566371918, dist_loss: 0.5081696510314941
recon_loss: 0.02707650326192379, dist_loss: 0.5437013506889343
recon_loss: 0.027076290920376778, dist_loss: 0.5955790281295776
recon_loss: 0.02707602083683014, dist_loss: 0.524911642074585
recon_loss: 0.02707603946328163, dist_loss: 1.2048518657684326
recon_loss: 0.02707670070230961, dist_loss: 0.48511403799057007
recon_loss: 0.02707776054739952, dist_loss: 1.0695505142211914
recon_loss: 0.027078045532107353, dist_loss: 0.7487781047821045
recon_loss: 0.027078017592430115, dist_loss: 0.734373927116394
recon_loss: 0.027078211307525635, dist_loss: 0.5996979475021362
recon_loss: 0.027079405263066292, dist_loss: 0.6656716465950012
recon_loss: 0.027080681174993515, dist_loss: 0.62547767162323
recon_loss: 0.027081528678536415, dist_loss: 0.4073093831539154
recon_loss: 0.02708168886601925, dist_loss: 0.8220056295394897
recon_loss: 0.027081182226538658, dist_loss: 0.5466234087944031
recon_loss: 0.027080314233899117, dist_loss: 0.7070673704147339
recon_loss: 0.027079524472355843, dist_loss: 0.3317541480064392
recon_loss: 0.02707856148481369, dist_loss: 0.7973567843437195
recon_loss: 0.027078205719590187, dist_loss: 1.037224531173706
recon_loss: 0.0270763598382473, dist_loss: 0.3974047303199768
recon_loss: 0.02707853727042675, dist_loss: 0.700680673122406
recon_loss: 0.02707582712173462, dist_loss: 0.8183773159980774
recon_loss: 0.027077147737145424, dist_loss: 0.6413724422454834
recon_loss: 0.027075355872511864, dist_loss: 0.8216461539268494
recon_loss: 0.02707688882946968, dist_loss: 0.3522602319717407
recon_loss: 0.02707664482295513, dist_loss: 0.5931681394577026
recon_loss: 0.02707873098552227, dist_loss: 0.4663631021976471
recon_loss: 0.027079561725258827, dist_loss: 0.533014178276062
recon_loss: 0.02708008885383606, dist_loss: 0.6608948111534119
recon_loss: 0.027078645303845406, dist_loss: 0.2727646827697754
recon_loss: 0.027076711878180504, dist_loss: 0.6831259727478027
recon_loss: 0.027077089995145798, dist_loss: 0.7577623128890991
recon_loss: 0.02707512490451336, dist_loss: 0.6209249496459961
recon_loss: 0.027077993378043175, dist_loss: 0.4535481929779053
recon_loss: 0.02707574889063835, dist_loss: 0.5389630198478699
recon_loss: 0.02707527205348015, dist_loss: 0.9160460829734802
recon_loss: 0.027073420584201813, dist_loss: 0.4615304172039032
recon_loss: 0.027073435485363007, dist_loss: 0.6785909533500671
recon_loss: 0.02707221731543541, dist_loss: 0.7531320452690125
recon_loss: 0.027071956545114517, dist_loss: 0.7437090873718262
recon_loss: 0.027071740478277206, dist_loss: 0.5335690975189209
recon_loss: 0.027073102071881294, dist_loss: 1.015945553779602
recon_loss: 0.027073141187429428, dist_loss: 0.5571305751800537
recon_loss: 0.02707388624548912, dist_loss: 0.9239721298217773
recon_loss: 0.027073010802268982, dist_loss: 0.9987320303916931
recon_loss: 0.027073562145233154, dist_loss: 0.32145804166793823
recon_loss: 0.027073243632912636, dist_loss: 0.4748316705226898
recon_loss: 0.027073398232460022, dist_loss: 0.5436347126960754
recon_loss: 0.02707364223897457, dist_loss: 0.658772349357605
recon_loss: 0.027073267847299576, dist_loss: 0.6951172351837158
recon_loss: 0.02707263082265854, dist_loss: 1.0410443544387817
recon_loss: 0.027071718126535416, dist_loss: 0.8337742686271667
recon_loss: 0.02707122638821602, dist_loss: 0.7269552946090698
recon_loss: 0.0270696934312582, dist_loss: 0.6557657718658447
recon_loss: 0.02706942893564701, dist_loss: 0.7191710472106934
recon_loss: 0.02706926129758358, dist_loss: 0.7523982524871826
recon_loss: 0.027068760246038437, dist_loss: 0.7003303170204163
recon_loss: 0.027068980038166046, dist_loss: 0.29033514857292175
recon_loss: 0.02706829458475113, dist_loss: 0.9735709428787231
recon_loss: 0.027068287134170532, dist_loss: 0.9765373468399048
recon_loss: 0.0270683616399765, dist_loss: 0.7254058122634888
recon_loss: 0.027069276198744774, dist_loss: 0.36309486627578735
recon_loss: 0.0270694550126791, dist_loss: 0.8271363973617554
recon_loss: 0.027070792391896248, dist_loss: 0.6111797094345093
recon_loss: 0.02707025781273842, dist_loss: 0.4987372159957886
recon_loss: 0.0270713958889246, dist_loss: 0.5789840221405029
recon_loss: 0.027070552110671997, dist_loss: 0.8975772857666016
recon_loss: 0.027070900425314903, dist_loss: 0.5170217752456665
recon_loss: 0.027071183547377586, dist_loss: 0.43593358993530273
recon_loss: 0.02707136981189251, dist_loss: 0.5080275535583496
recon_loss: 0.02707134187221527, dist_loss: 0.4379138946533203
recon_loss: 0.027071217074990273, dist_loss: 0.672330379486084
recon_loss: 0.0270709116011858, dist_loss: 0.6822065114974976
recon_loss: 0.027070311829447746, dist_loss: 0.49672073125839233
recon_loss: 0.027069643139839172, dist_loss: 0.6357964277267456
recon_loss: 0.027068661525845528, dist_loss: 0.3843514323234558
recon_loss: 0.027068698778748512, dist_loss: 0.6813706159591675
recon_loss: 0.027069665491580963, dist_loss: 0.5312232971191406
Pre-training Epoch 126:  36%|███▌      | 133/367 [00:00<00:01, 169.32it/s]Pre-training Epoch 126:  41%|████      | 150/367 [00:00<00:01, 167.31it/s]Pre-training Epoch 126:  46%|████▌     | 167/367 [00:01<00:01, 166.64it/s]Pre-training Epoch 126:  50%|█████     | 184/367 [00:01<00:01, 166.54it/s]Pre-training Epoch 126:  55%|█████▍    | 201/367 [00:01<00:00, 166.40it/s]Pre-training Epoch 126:  60%|█████▉    | 219/367 [00:01<00:00, 169.94it/s]Pre-training Epoch 126:  65%|██████▌   | 239/367 [00:01<00:00, 176.97it/s]recon_loss: 0.027071818709373474, dist_loss: 0.7452166080474854
recon_loss: 0.02707485668361187, dist_loss: 0.6259952783584595
recon_loss: 0.02707756496965885, dist_loss: 0.7598202228546143
recon_loss: 0.027080046012997627, dist_loss: 0.5323628187179565
recon_loss: 0.02708251029253006, dist_loss: 0.6157750487327576
recon_loss: 0.027084866538643837, dist_loss: 0.6960294246673584
recon_loss: 0.02708618715405464, dist_loss: 0.847027063369751
recon_loss: 0.027084410190582275, dist_loss: 0.7755428552627563
recon_loss: 0.027080580592155457, dist_loss: 0.6423022747039795
recon_loss: 0.02707982063293457, dist_loss: 0.5381438732147217
recon_loss: 0.027078859508037567, dist_loss: 0.5112099051475525
recon_loss: 0.027079591527581215, dist_loss: 0.5451529026031494
recon_loss: 0.027079060673713684, dist_loss: 0.6273174285888672
recon_loss: 0.027079975232481956, dist_loss: 0.46336764097213745
recon_loss: 0.027079595252871513, dist_loss: 0.5847759246826172
recon_loss: 0.02707999385893345, dist_loss: 0.5250650644302368
recon_loss: 0.027079131454229355, dist_loss: 0.6631781458854675
recon_loss: 0.027078913524746895, dist_loss: 0.5285247564315796
recon_loss: 0.02707936242222786, dist_loss: 0.5210494995117188
recon_loss: 0.02707989700138569, dist_loss: 0.844249427318573
recon_loss: 0.027081934735178947, dist_loss: 0.9699547290802002
recon_loss: 0.027083028107881546, dist_loss: 0.349448025226593
recon_loss: 0.02708272449672222, dist_loss: 0.4621567130088806
recon_loss: 0.027080664411187172, dist_loss: 1.1555691957473755
recon_loss: 0.027079414576292038, dist_loss: 0.32543548941612244
recon_loss: 0.027075937017798424, dist_loss: 0.4546012282371521
recon_loss: 0.027074988931417465, dist_loss: 0.6772263050079346
recon_loss: 0.02707255259156227, dist_loss: 0.8607044219970703
recon_loss: 0.027072880417108536, dist_loss: 0.4933488965034485
recon_loss: 0.027072587981820107, dist_loss: 0.4672025442123413
recon_loss: 0.027074022218585014, dist_loss: 0.8804571628570557
recon_loss: 0.02707410790026188, dist_loss: 0.27524447441101074
recon_loss: 0.027075329795479774, dist_loss: 0.42461928725242615
recon_loss: 0.027075238525867462, dist_loss: 0.6466403007507324
recon_loss: 0.0270767230540514, dist_loss: 0.7018457651138306
recon_loss: 0.027077073231339455, dist_loss: 0.3316326439380646
recon_loss: 0.0270779337733984, dist_loss: 0.8972722291946411
recon_loss: 0.027077289298176765, dist_loss: 0.48421651124954224
recon_loss: 0.027075238525867462, dist_loss: 0.5607097744941711
recon_loss: 0.027073349803686142, dist_loss: 0.6721668243408203
recon_loss: 0.027072351425886154, dist_loss: 0.41295331716537476
recon_loss: 0.027072079479694366, dist_loss: 0.5988165736198425
recon_loss: 0.027070902287960052, dist_loss: 0.5732993483543396
recon_loss: 0.02707085758447647, dist_loss: 0.9247942566871643
recon_loss: 0.0270701814442873, dist_loss: 0.9000699520111084
recon_loss: 0.027070095762610435, dist_loss: 0.4888790249824524
recon_loss: 0.027069995179772377, dist_loss: 0.5096568465232849
recon_loss: 0.02706964872777462, dist_loss: 0.6286938190460205
recon_loss: 0.02706936001777649, dist_loss: 0.6457036733627319
recon_loss: 0.027068763971328735, dist_loss: 0.8881148099899292
recon_loss: 0.027068430557847023, dist_loss: 0.5277174711227417
recon_loss: 0.02706892602145672, dist_loss: 0.455970823764801
recon_loss: 0.02706807851791382, dist_loss: 0.9747702479362488
recon_loss: 0.027068400755524635, dist_loss: 0.40911489725112915
recon_loss: 0.02706839330494404, dist_loss: 0.7271608114242554
recon_loss: 0.027068907395005226, dist_loss: 0.5915898680686951
recon_loss: 0.027069292962551117, dist_loss: 1.0307276248931885
recon_loss: 0.027071159332990646, dist_loss: 0.5661168694496155
recon_loss: 0.027072517201304436, dist_loss: 0.7483869791030884
recon_loss: 0.02707299217581749, dist_loss: 1.0128815174102783
recon_loss: 0.027072617784142494, dist_loss: 0.791172981262207
recon_loss: 0.02707422897219658, dist_loss: 0.2363080084323883
recon_loss: 0.027076080441474915, dist_loss: 0.8629370927810669
recon_loss: 0.027077089995145798, dist_loss: 0.31611156463623047
recon_loss: 0.027076764032244682, dist_loss: 0.4941040277481079
recon_loss: 0.027076568454504013, dist_loss: 0.7792575359344482
recon_loss: 0.027075814083218575, dist_loss: 0.5601899027824402
recon_loss: 0.027073999866843224, dist_loss: 0.48950642347335815
recon_loss: 0.027071109041571617, dist_loss: 0.6398400068283081
recon_loss: 0.027069536969065666, dist_loss: 0.6162148714065552
recon_loss: 0.027068722993135452, dist_loss: 0.49154096841812134
recon_loss: 0.027068359777331352, dist_loss: 0.6136392951011658
recon_loss: 0.027069002389907837, dist_loss: 0.7575146555900574
recon_loss: 0.02706991322338581, dist_loss: 0.5137697458267212
recon_loss: 0.0270719975233078, dist_loss: 0.7822490930557251
recon_loss: 0.027074217796325684, dist_loss: 0.5136006474494934
recon_loss: 0.02707575634121895, dist_loss: 0.7240715026855469
recon_loss: 0.027075914666056633, dist_loss: 0.40764689445495605
recon_loss: 0.027075467631220818, dist_loss: 1.1862086057662964
recon_loss: 0.027073757722973824, dist_loss: 0.7050826549530029
recon_loss: 0.027073079720139503, dist_loss: 0.7871466875076294
recon_loss: 0.02707289159297943, dist_loss: 0.32165807485580444
recon_loss: 0.027073431760072708, dist_loss: 0.5510704517364502
recon_loss: 0.027073536068201065, dist_loss: 0.6556271314620972
recon_loss: 0.027073901146650314, dist_loss: 0.6803221702575684
recon_loss: 0.027073469012975693, dist_loss: 0.6725716590881348
recon_loss: 0.027072446420788765, dist_loss: 0.4145556092262268
recon_loss: 0.02707161009311676, dist_loss: 0.7065558433532715
recon_loss: 0.027071287855505943, dist_loss: 0.36909303069114685
recon_loss: 0.027070635929703712, dist_loss: 0.6711792349815369
recon_loss: 0.027069518342614174, dist_loss: 0.3585556447505951
recon_loss: 0.02706882916390896, dist_loss: 0.8230599164962769
recon_loss: 0.027067605406045914, dist_loss: 0.6680570840835571
recon_loss: 0.027067145332694054, dist_loss: 0.5624038577079773
recon_loss: 0.027066577225923538, dist_loss: 0.947754979133606
recon_loss: 0.027066748589277267, dist_loss: 0.4823837876319885
recon_loss: 0.027066485956311226, dist_loss: 0.3909149765968323
recon_loss: 0.027066323906183243, dist_loss: 0.9765082001686096
recon_loss: 0.027065623551607132, dist_loss: 0.9311833381652832
recon_loss: 0.027064397931098938, dist_loss: 0.5578896999359131
recon_loss: 0.027063937857747078, dist_loss: 0.8613762259483337
recon_loss: 0.02706356905400753, dist_loss: 0.48177775740623474
recon_loss: 0.027063343673944473, dist_loss: 1.0014152526855469
recon_loss: 0.02706298604607582, dist_loss: 0.6785105466842651
recon_loss: 0.02706279419362545, dist_loss: 0.5605997443199158
recon_loss: 0.02706277184188366, dist_loss: 0.5577186942100525
recon_loss: 0.027062702924013138, dist_loss: 0.7210080623626709
recon_loss: 0.02706282027065754, dist_loss: 0.6753650903701782
recon_loss: 0.027062438428401947, dist_loss: 0.5667962431907654
recon_loss: 0.02706236019730568, dist_loss: 0.7064862251281738
recon_loss: 0.027061907574534416, dist_loss: 0.4557085633277893
recon_loss: 0.027061566710472107, dist_loss: 0.39887601137161255
recon_loss: 0.027061378583312035, dist_loss: 0.4149763882160187
recon_loss: 0.027061551809310913, dist_loss: 0.7333500981330872
recon_loss: 0.027061715722084045, dist_loss: 0.9317260980606079
recon_loss: 0.027062667533755302, dist_loss: 0.2585037052631378
recon_loss: 0.02706332691013813, dist_loss: 0.8469650745391846
recon_loss: 0.027064887806773186, dist_loss: 0.5783887505531311
recon_loss: 0.027067342773079872, dist_loss: 0.5751984119415283
recon_loss: 0.02706950344145298, dist_loss: 0.6842077374458313
recon_loss: 0.027071120217442513, dist_loss: 0.40794914960861206
recon_loss: 0.027071792632341385, dist_loss: 1.0609692335128784
recon_loss: 0.02707263082265854, dist_loss: 0.5394697189331055
recon_loss: 0.027072153985500336, dist_loss: 0.46665140986442566
recon_loss: 0.027070434764027596, dist_loss: 0.6046727895736694
recon_loss: 0.02706880494952202, dist_loss: 0.33333784341812134
recon_loss: 0.027068011462688446, dist_loss: 0.6028592586517334
recon_loss: 0.027067987248301506, dist_loss: 0.9363209009170532
Pre-training Epoch 126:  71%|███████   | 259/367 [00:01<00:00, 181.75it/s]Pre-training Epoch 126:  76%|███████▌  | 278/367 [00:01<00:00, 177.52it/s]Pre-training Epoch 126:  81%|████████  | 296/367 [00:01<00:00, 177.98it/s]Pre-training Epoch 126:  86%|████████▌ | 314/367 [00:01<00:00, 176.30it/s]Pre-training Epoch 126:  90%|█████████ | 332/367 [00:01<00:00, 176.39it/s]Pre-training Epoch 126:  95%|█████████▌| 350/367 [00:02<00:00, 177.20it/s]Pre-training Epoch 126: 100%|██████████| 367/367 [00:02<00:00, 169.50it/s]
recon_loss: 0.027068473398685455, dist_loss: 0.6941744685173035
recon_loss: 0.027068225666880608, dist_loss: 0.493147075176239
recon_loss: 0.027068212628364563, dist_loss: 0.7424808740615845
recon_loss: 0.027067847549915314, dist_loss: 0.4199959933757782
recon_loss: 0.0270672719925642, dist_loss: 0.6822690963745117
recon_loss: 0.02706719934940338, dist_loss: 0.6708725690841675
recon_loss: 0.027066679671406746, dist_loss: 0.8440226316452026
recon_loss: 0.02706674113869667, dist_loss: 0.8349393010139465
recon_loss: 0.027065610513091087, dist_loss: 0.9055790901184082
recon_loss: 0.027064207941293716, dist_loss: 0.253373384475708
recon_loss: 0.027062874287366867, dist_loss: 1.0075597763061523
recon_loss: 0.027062756940722466, dist_loss: 0.6337032318115234
recon_loss: 0.027062172070145607, dist_loss: 0.3833600878715515
recon_loss: 0.027062654495239258, dist_loss: 0.5915073156356812
recon_loss: 0.027061879634857178, dist_loss: 0.8699646592140198
recon_loss: 0.027063017711043358, dist_loss: 0.5192887783050537
recon_loss: 0.02706272527575493, dist_loss: 0.5774236917495728
recon_loss: 0.027063975110650063, dist_loss: 0.4842361509799957
recon_loss: 0.027063144370913506, dist_loss: 0.3418189287185669
recon_loss: 0.027064252644777298, dist_loss: 0.5689100623130798
recon_loss: 0.02706393226981163, dist_loss: 1.0666497945785522
recon_loss: 0.027064701542258263, dist_loss: 0.873650312423706
recon_loss: 0.027064165100455284, dist_loss: 0.8470801115036011
recon_loss: 0.02706453949213028, dist_loss: 0.6906877756118774
recon_loss: 0.027064772322773933, dist_loss: 0.7964729070663452
recon_loss: 0.027064163237810135, dist_loss: 0.718748927116394
recon_loss: 0.027064261958003044, dist_loss: 0.7657577991485596
recon_loss: 0.027063041925430298, dist_loss: 0.6356983184814453
recon_loss: 0.027064315974712372, dist_loss: 1.0191898345947266
recon_loss: 0.027062661945819855, dist_loss: 0.7485589981079102
recon_loss: 0.027062913402915, dist_loss: 0.2949068248271942
recon_loss: 0.027062149718403816, dist_loss: 0.9128060340881348
recon_loss: 0.027061212807893753, dist_loss: 0.8082225918769836
recon_loss: 0.027060728520154953, dist_loss: 0.37469595670700073
recon_loss: 0.0270608589053154, dist_loss: 0.5440008044242859
recon_loss: 0.027060693129897118, dist_loss: 0.8151994347572327
recon_loss: 0.027061190456151962, dist_loss: 0.5660240054130554
recon_loss: 0.02706175111234188, dist_loss: 0.7529250383377075
recon_loss: 0.02706175483763218, dist_loss: 0.8074700832366943
recon_loss: 0.02706298418343067, dist_loss: 0.889778733253479
recon_loss: 0.027062399312853813, dist_loss: 0.5410726070404053
recon_loss: 0.027063041925430298, dist_loss: 0.7202156186103821
recon_loss: 0.02706216089427471, dist_loss: 0.4275692403316498
recon_loss: 0.02706255204975605, dist_loss: 0.7369343042373657
recon_loss: 0.027061399072408676, dist_loss: 0.28524214029312134
recon_loss: 0.027061492204666138, dist_loss: 0.5596224665641785
recon_loss: 0.027060680091381073, dist_loss: 0.3837481439113617
recon_loss: 0.027060527354478836, dist_loss: 0.3951733708381653
recon_loss: 0.027060464024543762, dist_loss: 0.6858510375022888
recon_loss: 0.027060121297836304, dist_loss: 0.5813307762145996
recon_loss: 0.027060242369771004, dist_loss: 0.3481646776199341
recon_loss: 0.027061348780989647, dist_loss: 0.6521924734115601
recon_loss: 0.02706109546124935, dist_loss: 0.7310450077056885
recon_loss: 0.027061982080340385, dist_loss: 0.6259669661521912
recon_loss: 0.02706187218427658, dist_loss: 0.9375203251838684
recon_loss: 0.027062196284532547, dist_loss: 0.5036089420318604
recon_loss: 0.027062654495239258, dist_loss: 0.577450692653656
recon_loss: 0.027061454951763153, dist_loss: 0.5570761561393738
recon_loss: 0.027062242850661278, dist_loss: 0.5798929333686829
recon_loss: 0.027061160653829575, dist_loss: 0.8035851120948792
recon_loss: 0.02706129662692547, dist_loss: 0.3575761616230011
recon_loss: 0.027060912922024727, dist_loss: 0.8930328488349915
recon_loss: 0.02706112526357174, dist_loss: 0.8472164273262024
recon_loss: 0.027060871943831444, dist_loss: 0.5378202795982361
recon_loss: 0.02706104703247547, dist_loss: 0.6828844547271729
recon_loss: 0.02706090174615383, dist_loss: 0.35365772247314453
recon_loss: 0.027060870081186295, dist_loss: 0.4335118532180786
recon_loss: 0.027060776948928833, dist_loss: 0.6350768208503723
recon_loss: 0.027060510590672493, dist_loss: 0.5062350630760193
recon_loss: 0.027060169726610184, dist_loss: 0.5077148079872131
recon_loss: 0.027059808373451233, dist_loss: 0.6706633567810059
recon_loss: 0.02706035040318966, dist_loss: 0.6794366836547852
recon_loss: 0.02706044912338257, dist_loss: 0.39433157444000244
recon_loss: 0.027061469852924347, dist_loss: 0.34466129541397095
recon_loss: 0.027062036097049713, dist_loss: 0.49786800146102905
recon_loss: 0.027063030749559402, dist_loss: 0.6744155287742615
recon_loss: 0.02706288918852806, dist_loss: 0.5390857458114624
recon_loss: 0.02706233225762844, dist_loss: 0.43209540843963623
recon_loss: 0.02706124074757099, dist_loss: 0.6559699773788452
recon_loss: 0.0270606130361557, dist_loss: 0.7749861478805542
recon_loss: 0.02706024795770645, dist_loss: 0.5357810258865356
recon_loss: 0.027060527354478836, dist_loss: 0.7170512676239014
recon_loss: 0.02706100419163704, dist_loss: 0.6069382429122925
recon_loss: 0.027062490582466125, dist_loss: 0.40896350145339966
recon_loss: 0.027063477784395218, dist_loss: 0.7085890769958496
recon_loss: 0.027065051719546318, dist_loss: 0.8360004425048828
recon_loss: 0.02706528827548027, dist_loss: 0.6423180103302002
recon_loss: 0.027066335082054138, dist_loss: 1.1574738025665283
recon_loss: 0.027067426592111588, dist_loss: 0.45860087871551514
recon_loss: 0.027068953961133957, dist_loss: 0.47024208307266235
recon_loss: 0.02706938050687313, dist_loss: 0.41492700576782227
recon_loss: 0.027068989351391792, dist_loss: 0.44249391555786133
recon_loss: 0.027068350464105606, dist_loss: 0.6860067844390869
recon_loss: 0.027068475261330605, dist_loss: 0.6347857117652893
recon_loss: 0.027068762108683586, dist_loss: 0.6869809627532959
recon_loss: 0.027068957686424255, dist_loss: 0.7354177832603455
recon_loss: 0.027069048956036568, dist_loss: 0.680054783821106
recon_loss: 0.027069684118032455, dist_loss: 0.8773965239524841
recon_loss: 0.02706911601126194, dist_loss: 0.7652682662010193
recon_loss: 0.027067605406045914, dist_loss: 0.47896650433540344
recon_loss: 0.027065768837928772, dist_loss: 0.21956107020378113
recon_loss: 0.02706361562013626, dist_loss: 0.5513403415679932
recon_loss: 0.02706349454820156, dist_loss: 0.6969462633132935
recon_loss: 0.02706230618059635, dist_loss: 0.36953914165496826
recon_loss: 0.027063507586717606, dist_loss: 0.6640236973762512
recon_loss: 0.027064457535743713, dist_loss: 0.4088473320007324
recon_loss: 0.027066776528954506, dist_loss: 0.9305247068405151
recon_loss: 0.027068978175520897, dist_loss: 0.763979434967041
recon_loss: 0.027071064338088036, dist_loss: 0.5457185506820679
recon_loss: 0.027069896459579468, dist_loss: 0.16792181134223938
Pre-training Epoch 127:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 127:   5%|▍         | 17/367 [00:00<00:02, 165.53it/s]Pre-training Epoch 127:  10%|▉         | 35/367 [00:00<00:01, 170.82it/s]Pre-training Epoch 127:  14%|█▍        | 53/367 [00:00<00:01, 174.20it/s]Pre-training Epoch 127:  19%|█▉        | 71/367 [00:00<00:01, 175.56it/s]Pre-training Epoch 127:  24%|██▍       | 89/367 [00:00<00:01, 176.10it/s]Pre-training Epoch 127:  29%|██▉       | 107/367 [00:00<00:01, 174.64it/s]Pre-training Epoch 127:  34%|███▍      | 125/367 [00:00<00:01, 173.92it/s]recon_loss: 0.027069784700870514, dist_loss: 0.8124743700027466
recon_loss: 0.02706895023584366, dist_loss: 0.49776798486709595
recon_loss: 0.027068432420492172, dist_loss: 0.46773865818977356
recon_loss: 0.027068093419075012, dist_loss: 0.5043284893035889
recon_loss: 0.02706749178469181, dist_loss: 0.5631183385848999
recon_loss: 0.02706679329276085, dist_loss: 0.5079366564750671
recon_loss: 0.027066214010119438, dist_loss: 0.8142298460006714
recon_loss: 0.027065802365541458, dist_loss: 0.3774604797363281
recon_loss: 0.027065357193350792, dist_loss: 0.4232073426246643
recon_loss: 0.027064980939030647, dist_loss: 0.45853742957115173
recon_loss: 0.027064286172389984, dist_loss: 0.7004688382148743
recon_loss: 0.027063289657235146, dist_loss: 0.6064801216125488
recon_loss: 0.027062635868787766, dist_loss: 0.8695797324180603
recon_loss: 0.027061723172664642, dist_loss: 0.3801617920398712
recon_loss: 0.027061592787504196, dist_loss: 0.5197545886039734
recon_loss: 0.02706080675125122, dist_loss: 0.4670795202255249
recon_loss: 0.02706109546124935, dist_loss: 0.6019738912582397
recon_loss: 0.02706065960228443, dist_loss: 0.8035778999328613
recon_loss: 0.027060644701123238, dist_loss: 0.9192590117454529
recon_loss: 0.027059905230998993, dist_loss: 0.7016451358795166
recon_loss: 0.02706008590757847, dist_loss: 0.702974796295166
recon_loss: 0.02705969847738743, dist_loss: 0.3985387086868286
recon_loss: 0.02705991081893444, dist_loss: 0.8177111148834229
recon_loss: 0.02705943025648594, dist_loss: 0.5767298340797424
recon_loss: 0.027058904990553856, dist_loss: 0.9810904264450073
recon_loss: 0.02705894410610199, dist_loss: 0.5637680888175964
recon_loss: 0.027058562263846397, dist_loss: 0.5762510299682617
recon_loss: 0.027058586478233337, dist_loss: 0.5798933506011963
recon_loss: 0.02705957181751728, dist_loss: 0.6355128288269043
recon_loss: 0.027060220018029213, dist_loss: 0.6428186893463135
recon_loss: 0.0270614605396986, dist_loss: 0.28657612204551697
recon_loss: 0.027062050998210907, dist_loss: 0.9300833344459534
recon_loss: 0.027062803506851196, dist_loss: 0.5720405578613281
recon_loss: 0.027063043788075447, dist_loss: 0.6223434805870056
recon_loss: 0.027064289897680283, dist_loss: 0.667590320110321
recon_loss: 0.027064278721809387, dist_loss: 0.3005044460296631
recon_loss: 0.02706475369632244, dist_loss: 0.40840303897857666
recon_loss: 0.027065474539995193, dist_loss: 0.5154551863670349
recon_loss: 0.02706500142812729, dist_loss: 0.5693276524543762
recon_loss: 0.027064219117164612, dist_loss: 0.6701388359069824
recon_loss: 0.02706298418343067, dist_loss: 1.1930447816848755
recon_loss: 0.027060894295573235, dist_loss: 0.42981308698654175
recon_loss: 0.027059335261583328, dist_loss: 0.6709190607070923
recon_loss: 0.027059348300099373, dist_loss: 0.596685528755188
recon_loss: 0.027062034234404564, dist_loss: 0.73563551902771
recon_loss: 0.027066126465797424, dist_loss: 0.3511894941329956
recon_loss: 0.02707039751112461, dist_loss: 0.39159640669822693
recon_loss: 0.027073493227362633, dist_loss: 0.8589863777160645
recon_loss: 0.027076715603470802, dist_loss: 1.0012143850326538
recon_loss: 0.02707674540579319, dist_loss: 0.4288327693939209
recon_loss: 0.027076877653598785, dist_loss: 0.4060296416282654
recon_loss: 0.02707556262612343, dist_loss: 0.24509531259536743
recon_loss: 0.027074133977293968, dist_loss: 0.9001136422157288
recon_loss: 0.027071719989180565, dist_loss: 0.5598350763320923
recon_loss: 0.02706918679177761, dist_loss: 0.825407862663269
recon_loss: 0.027067694813013077, dist_loss: 0.8674352169036865
recon_loss: 0.027066949754953384, dist_loss: 0.2246590554714203
recon_loss: 0.027065979316830635, dist_loss: 0.7789775133132935
recon_loss: 0.027065226808190346, dist_loss: 0.49464088678359985
recon_loss: 0.027065129950642586, dist_loss: 0.5071215629577637
recon_loss: 0.027066422626376152, dist_loss: 0.5324640274047852
recon_loss: 0.027067577466368675, dist_loss: 0.48850321769714355
recon_loss: 0.0270682405680418, dist_loss: 0.6417737007141113
recon_loss: 0.027069255709648132, dist_loss: 0.4036500155925751
recon_loss: 0.02706962823867798, dist_loss: 0.597262978553772
recon_loss: 0.02706981636583805, dist_loss: 1.2855663299560547
recon_loss: 0.027070095762610435, dist_loss: 0.691591739654541
recon_loss: 0.027069786563515663, dist_loss: 0.5478397607803345
recon_loss: 0.027068883180618286, dist_loss: 0.7261524200439453
recon_loss: 0.027068957686424255, dist_loss: 0.4481227397918701
recon_loss: 0.027068745344877243, dist_loss: 0.5043138265609741
recon_loss: 0.02706899493932724, dist_loss: 0.3314783573150635
recon_loss: 0.02706814557313919, dist_loss: 0.7112894058227539
recon_loss: 0.027066724374890327, dist_loss: 0.8119131326675415
recon_loss: 0.027064606547355652, dist_loss: 0.7453173398971558
recon_loss: 0.02706429921090603, dist_loss: 1.1678857803344727
recon_loss: 0.02706308849155903, dist_loss: 0.44106587767601013
recon_loss: 0.027063248679041862, dist_loss: 0.5471004843711853
recon_loss: 0.027063170447945595, dist_loss: 0.5383656620979309
recon_loss: 0.027063187211751938, dist_loss: 0.5205129384994507
recon_loss: 0.02706318162381649, dist_loss: 1.125421166419983
recon_loss: 0.027063066139817238, dist_loss: 0.6154059171676636
recon_loss: 0.02706308849155903, dist_loss: 0.38553643226623535
recon_loss: 0.02706219255924225, dist_loss: 1.093628168106079
recon_loss: 0.02706162817776203, dist_loss: 0.41156888008117676
recon_loss: 0.02706080488860607, dist_loss: 0.6311367154121399
recon_loss: 0.027060579508543015, dist_loss: 0.5471821427345276
recon_loss: 0.027060870081186295, dist_loss: 0.5021059513092041
recon_loss: 0.027061015367507935, dist_loss: 0.8446198105812073
recon_loss: 0.027061020955443382, dist_loss: 0.5009627342224121
recon_loss: 0.02706141583621502, dist_loss: 0.7171434760093689
recon_loss: 0.027061831206083298, dist_loss: 0.9184624552726746
recon_loss: 0.027061648666858673, dist_loss: 0.4353786110877991
recon_loss: 0.027061596512794495, dist_loss: 0.3345617353916168
recon_loss: 0.027061425149440765, dist_loss: 0.47000253200531006
recon_loss: 0.02706049010157585, dist_loss: 0.3537881374359131
recon_loss: 0.027059804648160934, dist_loss: 0.3064414858818054
recon_loss: 0.027059845626354218, dist_loss: 0.7053648829460144
recon_loss: 0.027059653773903847, dist_loss: 1.0137207508087158
recon_loss: 0.02705957181751728, dist_loss: 1.177889108657837
recon_loss: 0.0270597692579031, dist_loss: 0.5602248907089233
recon_loss: 0.027059871703386307, dist_loss: 0.8368459343910217
recon_loss: 0.02705983631312847, dist_loss: 0.3921717405319214
recon_loss: 0.02705942466855049, dist_loss: 0.5406152009963989
recon_loss: 0.027059461921453476, dist_loss: 0.4765319228172302
recon_loss: 0.027059277519583702, dist_loss: 0.6517389416694641
recon_loss: 0.027058927342295647, dist_loss: 0.7072693109512329
recon_loss: 0.027057979255914688, dist_loss: 0.593908429145813
recon_loss: 0.027057206258177757, dist_loss: 0.6162067651748657
recon_loss: 0.027056585997343063, dist_loss: 0.7130988836288452
recon_loss: 0.027056632563471794, dist_loss: 0.5042247176170349
recon_loss: 0.027056898921728134, dist_loss: 0.388462096452713
recon_loss: 0.027057349681854248, dist_loss: 0.6021365523338318
recon_loss: 0.027057288214564323, dist_loss: 0.6331645250320435
recon_loss: 0.02705664560198784, dist_loss: 0.29818010330200195
recon_loss: 0.027055732905864716, dist_loss: 0.6224870085716248
recon_loss: 0.027055056765675545, dist_loss: 0.8221263885498047
recon_loss: 0.027054937556385994, dist_loss: 0.614352822303772
recon_loss: 0.02705466002225876, dist_loss: 0.6499918699264526
recon_loss: 0.027054885402321815, dist_loss: 1.0204288959503174
recon_loss: 0.027055472135543823, dist_loss: 0.6650978922843933
recon_loss: 0.027055351063609123, dist_loss: 0.5348783731460571
recon_loss: 0.02705550007522106, dist_loss: 0.8575490117073059
recon_loss: 0.027055326849222183, dist_loss: 0.5596527457237244
recon_loss: 0.02705499529838562, dist_loss: 0.7906384468078613
recon_loss: 0.027054958045482635, dist_loss: 0.4838672876358032
recon_loss: 0.02705436944961548, dist_loss: 0.4516661763191223
recon_loss: 0.02705397829413414, dist_loss: 1.0347343683242798
Pre-training Epoch 127:  39%|███▉      | 143/367 [00:00<00:01, 175.15it/s]Pre-training Epoch 127:  44%|████▍     | 161/367 [00:00<00:01, 169.16it/s]Pre-training Epoch 127:  49%|████▊     | 178/367 [00:01<00:01, 163.29it/s]Pre-training Epoch 127:  53%|█████▎    | 195/367 [00:01<00:01, 158.20it/s]Pre-training Epoch 127:  57%|█████▋    | 211/367 [00:01<00:00, 157.25it/s]Pre-training Epoch 127:  62%|██████▏   | 227/367 [00:01<00:00, 156.14it/s]Pre-training Epoch 127:  66%|██████▌   | 243/367 [00:01<00:00, 155.02it/s]recon_loss: 0.0270535871386528, dist_loss: 0.6736930012702942
recon_loss: 0.027053343132138252, dist_loss: 0.7687088251113892
recon_loss: 0.027053218334913254, dist_loss: 0.4132292866706848
recon_loss: 0.02705371379852295, dist_loss: 0.5049400925636292
recon_loss: 0.027054013684391975, dist_loss: 0.5094966888427734
recon_loss: 0.02705465257167816, dist_loss: 0.6331113576889038
recon_loss: 0.027054833248257637, dist_loss: 0.6303660869598389
recon_loss: 0.02705385722219944, dist_loss: 0.8422855138778687
recon_loss: 0.027053674682974815, dist_loss: 0.5169179439544678
recon_loss: 0.02705373987555504, dist_loss: 0.5736793279647827
recon_loss: 0.027054857462644577, dist_loss: 0.8593690395355225
recon_loss: 0.027054745703935623, dist_loss: 0.6773308515548706
recon_loss: 0.027055086567997932, dist_loss: 0.6708941459655762
recon_loss: 0.027055004611611366, dist_loss: 0.8387099504470825
recon_loss: 0.027054715901613235, dist_loss: 0.5257991552352905
recon_loss: 0.027054211124777794, dist_loss: 1.0771526098251343
recon_loss: 0.027053669095039368, dist_loss: 0.5970680713653564
recon_loss: 0.027052773162722588, dist_loss: 0.7347461581230164
recon_loss: 0.0270532239228487, dist_loss: 0.3166748881340027
recon_loss: 0.0270523801445961, dist_loss: 0.6036702990531921
recon_loss: 0.02705252170562744, dist_loss: 0.597254753112793
recon_loss: 0.0270528607070446, dist_loss: 0.6616969108581543
recon_loss: 0.02705266885459423, dist_loss: 1.2884457111358643
recon_loss: 0.027053115889430046, dist_loss: 0.6024575233459473
recon_loss: 0.0270531065762043, dist_loss: 0.3538022041320801
recon_loss: 0.02705320343375206, dist_loss: 0.47050905227661133
recon_loss: 0.02705264277756214, dist_loss: 1.2811915874481201
recon_loss: 0.0270544420927763, dist_loss: 0.5822418928146362
recon_loss: 0.027054088190197945, dist_loss: 0.9674926400184631
recon_loss: 0.02705587074160576, dist_loss: 0.7482273578643799
recon_loss: 0.027055855840444565, dist_loss: 0.8638278245925903
recon_loss: 0.027056556195020676, dist_loss: 0.49662429094314575
recon_loss: 0.027056505903601646, dist_loss: 0.8484222888946533
recon_loss: 0.027057116851210594, dist_loss: 0.6550858020782471
recon_loss: 0.02705616131424904, dist_loss: 0.5697046518325806
recon_loss: 0.027057768777012825, dist_loss: 0.3571217656135559
recon_loss: 0.0270575862377882, dist_loss: 0.2758582532405853
recon_loss: 0.027058076113462448, dist_loss: 0.9289575219154358
recon_loss: 0.02705617994070053, dist_loss: 0.34936201572418213
recon_loss: 0.027056194841861725, dist_loss: 0.6551908254623413
recon_loss: 0.027054568752646446, dist_loss: 0.6803103089332581
recon_loss: 0.02705342508852482, dist_loss: 0.7593061923980713
recon_loss: 0.027052659541368484, dist_loss: 0.8730170726776123
recon_loss: 0.027052616700530052, dist_loss: 0.6090853810310364
recon_loss: 0.02705387957394123, dist_loss: 0.3225801885128021
recon_loss: 0.027055490761995316, dist_loss: 0.6560921669006348
recon_loss: 0.027057334780693054, dist_loss: 0.6118589639663696
recon_loss: 0.02705683559179306, dist_loss: 0.7211839556694031
recon_loss: 0.0270571019500494, dist_loss: 0.8564890027046204
recon_loss: 0.027056213468313217, dist_loss: 0.9076225757598877
recon_loss: 0.027056748047471046, dist_loss: 0.6955389976501465
recon_loss: 0.027056746184825897, dist_loss: 0.7451999187469482
recon_loss: 0.027058258652687073, dist_loss: 0.7331621050834656
recon_loss: 0.027056943625211716, dist_loss: 0.908722996711731
recon_loss: 0.027057964354753494, dist_loss: 0.47010549902915955
recon_loss: 0.02705696038901806, dist_loss: 0.5251649618148804
recon_loss: 0.0270574688911438, dist_loss: 1.2440216541290283
recon_loss: 0.027057645842432976, dist_loss: 0.5856758952140808
recon_loss: 0.027056321501731873, dist_loss: 0.7107934951782227
recon_loss: 0.027056701481342316, dist_loss: 0.7142849564552307
recon_loss: 0.027055250480771065, dist_loss: 0.402133584022522
recon_loss: 0.02705509029328823, dist_loss: 0.5753975510597229
recon_loss: 0.027054250240325928, dist_loss: 0.8851754665374756
recon_loss: 0.027052778750658035, dist_loss: 0.8155859708786011
recon_loss: 0.02705201879143715, dist_loss: 0.7941761016845703
recon_loss: 0.027051616460084915, dist_loss: 0.34367144107818604
recon_loss: 0.027051882818341255, dist_loss: 0.3973724842071533
recon_loss: 0.027052752673625946, dist_loss: 0.45192962884902954
recon_loss: 0.02705335058271885, dist_loss: 0.39264243841171265
recon_loss: 0.02705407701432705, dist_loss: 0.5112215280532837
recon_loss: 0.02705445885658264, dist_loss: 0.6408683061599731
recon_loss: 0.027055149897933006, dist_loss: 0.5004006028175354
recon_loss: 0.027055030688643456, dist_loss: 1.0635895729064941
recon_loss: 0.027054358273744583, dist_loss: 0.6888593435287476
recon_loss: 0.02705363556742668, dist_loss: 0.5610584020614624
recon_loss: 0.02705298364162445, dist_loss: 0.8877118825912476
recon_loss: 0.027052661404013634, dist_loss: 0.7928391695022583
recon_loss: 0.027052314952015877, dist_loss: 0.6932843923568726
recon_loss: 0.02705240063369274, dist_loss: 0.8489277362823486
recon_loss: 0.027052143588662148, dist_loss: 0.4249439835548401
recon_loss: 0.027052132412791252, dist_loss: 0.6665328741073608
recon_loss: 0.027051957324147224, dist_loss: 0.4356091618537903
recon_loss: 0.02705126814544201, dist_loss: 0.5294057130813599
recon_loss: 0.027050383388996124, dist_loss: 0.742682933807373
recon_loss: 0.027049794793128967, dist_loss: 0.6482616066932678
recon_loss: 0.02704937383532524, dist_loss: 0.40845364332199097
recon_loss: 0.02704925276339054, dist_loss: 0.5422718524932861
recon_loss: 0.02704923041164875, dist_loss: 0.6719673871994019
recon_loss: 0.027049129828810692, dist_loss: 0.7910932302474976
recon_loss: 0.027049293741583824, dist_loss: 0.4965916872024536
recon_loss: 0.027049433439970016, dist_loss: 0.8162770867347717
recon_loss: 0.02704959362745285, dist_loss: 0.6983593106269836
recon_loss: 0.027050014585256577, dist_loss: 0.7123443484306335
recon_loss: 0.027049459517002106, dist_loss: 0.7217317819595337
recon_loss: 0.027049705386161804, dist_loss: 0.503585696220398
recon_loss: 0.02705022506415844, dist_loss: 0.8418160676956177
recon_loss: 0.02705041505396366, dist_loss: 0.8976570963859558
recon_loss: 0.02705046534538269, dist_loss: 0.6263686418533325
recon_loss: 0.027050746604800224, dist_loss: 0.3520857095718384
recon_loss: 0.02705107443034649, dist_loss: 0.5914270877838135
recon_loss: 0.02705083228647709, dist_loss: 0.7452090382575989
recon_loss: 0.02705068141222, dist_loss: 0.7439379692077637
recon_loss: 0.02704986184835434, dist_loss: 0.5244481563568115
recon_loss: 0.027049453929066658, dist_loss: 0.3752225935459137
recon_loss: 0.02704928256571293, dist_loss: 0.5054114460945129
recon_loss: 0.027048896998167038, dist_loss: 0.606421947479248
recon_loss: 0.02704874612390995, dist_loss: 0.5193878412246704
recon_loss: 0.027048500254750252, dist_loss: 0.6084238290786743
recon_loss: 0.027048557996749878, dist_loss: 0.8250647783279419
recon_loss: 0.02704860270023346, dist_loss: 0.49734026193618774
recon_loss: 0.02704801596701145, dist_loss: 0.439003586769104
recon_loss: 0.027048027142882347, dist_loss: 0.9927577972412109
recon_loss: 0.02704791910946369, dist_loss: 0.9269529581069946
recon_loss: 0.027048425748944283, dist_loss: 0.7779533267021179
recon_loss: 0.027048014104366302, dist_loss: 0.2969070076942444
recon_loss: 0.027048202231526375, dist_loss: 0.9790455102920532
recon_loss: 0.02704784646630287, dist_loss: 0.513085663318634
recon_loss: 0.02704865112900734, dist_loss: 0.502173900604248
recon_loss: 0.02704852819442749, dist_loss: 0.837178111076355
recon_loss: 0.02705000899732113, dist_loss: 0.5840685963630676
recon_loss: 0.027050044387578964, dist_loss: 0.5403679609298706
recon_loss: 0.027051396667957306, dist_loss: 0.8602516055107117
recon_loss: 0.02705141343176365, dist_loss: 0.498740553855896
recon_loss: 0.027051903307437897, dist_loss: 0.4640258550643921
recon_loss: 0.02705148607492447, dist_loss: 0.39637941122055054
recon_loss: 0.027049729600548744, dist_loss: 0.5799303650856018
recon_loss: 0.02704901434481144, dist_loss: 0.5608953237533569
recon_loss: 0.027047818526625633, dist_loss: 0.7539710402488708
recon_loss: 0.02704789489507675, dist_loss: 0.6091315746307373
Pre-training Epoch 127:  71%|███████   | 259/367 [00:01<00:00, 154.36it/s]Pre-training Epoch 127:  75%|███████▍  | 275/367 [00:01<00:00, 153.94it/s]Pre-training Epoch 127:  79%|███████▉  | 291/367 [00:01<00:00, 153.70it/s]Pre-training Epoch 127:  84%|████████▎ | 307/367 [00:01<00:00, 153.93it/s]Pre-training Epoch 127:  89%|████████▊ | 325/367 [00:01<00:00, 159.61it/s]Pre-training Epoch 127:  93%|█████████▎| 343/367 [00:02<00:00, 164.31it/s]Pre-training Epoch 127:  99%|█████████▊| 362/367 [00:02<00:00, 169.72it/s]Pre-training Epoch 127: 100%|██████████| 367/367 [00:02<00:00, 164.60it/s]
recon_loss: 0.02704760991036892, dist_loss: 1.0867788791656494
recon_loss: 0.02704891562461853, dist_loss: 0.424224317073822
recon_loss: 0.02705048769712448, dist_loss: 0.28851282596588135
recon_loss: 0.027052387595176697, dist_loss: 0.6397671103477478
recon_loss: 0.02705405466258526, dist_loss: 0.6606024503707886
recon_loss: 0.02705521509051323, dist_loss: 0.40138524770736694
recon_loss: 0.027054963633418083, dist_loss: 0.4146448075771332
recon_loss: 0.02705254592001438, dist_loss: 1.2291622161865234
recon_loss: 0.027050655335187912, dist_loss: 0.4558869004249573
recon_loss: 0.027048731222748756, dist_loss: 0.6342551708221436
recon_loss: 0.02704763039946556, dist_loss: 0.3837897479534149
recon_loss: 0.027047228068113327, dist_loss: 0.49611005187034607
recon_loss: 0.02704739384353161, dist_loss: 0.7587832808494568
recon_loss: 0.02704758755862713, dist_loss: 0.6806730628013611
recon_loss: 0.02704802341759205, dist_loss: 0.4798282980918884
recon_loss: 0.027048513293266296, dist_loss: 0.519439697265625
recon_loss: 0.027048416435718536, dist_loss: 0.6585705280303955
recon_loss: 0.02704816684126854, dist_loss: 0.28762590885162354
recon_loss: 0.027047529816627502, dist_loss: 1.1529419422149658
recon_loss: 0.027046795934438705, dist_loss: 0.6762626767158508
recon_loss: 0.027046481147408485, dist_loss: 0.8599807024002075
recon_loss: 0.027045870199799538, dist_loss: 0.3262008726596832
recon_loss: 0.02704557590186596, dist_loss: 0.6499450206756592
recon_loss: 0.02704545110464096, dist_loss: 0.3360779881477356
recon_loss: 0.02704532817006111, dist_loss: 0.40578609704971313
recon_loss: 0.0270451158285141, dist_loss: 0.5976301431655884
recon_loss: 0.02704533189535141, dist_loss: 0.41262269020080566
recon_loss: 0.02704540081322193, dist_loss: 0.5043860673904419
recon_loss: 0.027045659720897675, dist_loss: 0.9617351293563843
recon_loss: 0.027046220377087593, dist_loss: 0.3707204759120941
recon_loss: 0.027046671137213707, dist_loss: 0.5960132479667664
recon_loss: 0.027046911418437958, dist_loss: 0.5946176052093506
recon_loss: 0.02704654633998871, dist_loss: 0.446124792098999
recon_loss: 0.027047352865338326, dist_loss: 0.6959189176559448
recon_loss: 0.02704746089875698, dist_loss: 0.6356508731842041
recon_loss: 0.027048464864492416, dist_loss: 0.5815716981887817
recon_loss: 0.027048185467720032, dist_loss: 1.1920925378799438
recon_loss: 0.02704816870391369, dist_loss: 0.49482256174087524
recon_loss: 0.02704714797437191, dist_loss: 0.7428420186042786
recon_loss: 0.02704749070107937, dist_loss: 0.9051193594932556
recon_loss: 0.027046967297792435, dist_loss: 0.6242592334747314
recon_loss: 0.027047790586948395, dist_loss: 0.4887380003929138
recon_loss: 0.027047406882047653, dist_loss: 0.8298344612121582
recon_loss: 0.02704731561243534, dist_loss: 1.1781820058822632
recon_loss: 0.027048397809267044, dist_loss: 0.5184967517852783
recon_loss: 0.02704915963113308, dist_loss: 0.4766957759857178
recon_loss: 0.02705058455467224, dist_loss: 0.5290712118148804
recon_loss: 0.027049127966165543, dist_loss: 0.7437567710876465
recon_loss: 0.027051759883761406, dist_loss: 0.5586388111114502
recon_loss: 0.027050742879509926, dist_loss: 0.7928370237350464
recon_loss: 0.02705262415111065, dist_loss: 0.7790184020996094
recon_loss: 0.027051353827118874, dist_loss: 0.9825297594070435
recon_loss: 0.02705192193388939, dist_loss: 0.5803662538528442
recon_loss: 0.02704988606274128, dist_loss: 0.501961350440979
recon_loss: 0.027049729600548744, dist_loss: 0.6509943604469299
recon_loss: 0.027048438787460327, dist_loss: 0.8042672872543335
recon_loss: 0.027048995718359947, dist_loss: 0.8805224895477295
recon_loss: 0.027047647163271904, dist_loss: 0.48890137672424316
recon_loss: 0.02704833447933197, dist_loss: 0.9686641693115234
recon_loss: 0.027047542855143547, dist_loss: 0.5823264122009277
recon_loss: 0.027047976851463318, dist_loss: 1.0265806913375854
recon_loss: 0.027047133073210716, dist_loss: 0.5566710233688354
recon_loss: 0.027047038078308105, dist_loss: 0.5354247093200684
recon_loss: 0.027046363800764084, dist_loss: 0.5059696435928345
recon_loss: 0.02704576775431633, dist_loss: 0.4474136233329773
recon_loss: 0.027045398950576782, dist_loss: 0.4245796203613281
recon_loss: 0.02704564481973648, dist_loss: 0.8654202222824097
recon_loss: 0.02704571560025215, dist_loss: 0.5636375546455383
recon_loss: 0.02704571560025215, dist_loss: 0.6368643045425415
recon_loss: 0.027045682072639465, dist_loss: 0.8079161643981934
recon_loss: 0.027045344933867455, dist_loss: 0.6470894813537598
recon_loss: 0.02704589068889618, dist_loss: 0.7241678237915039
recon_loss: 0.027045464143157005, dist_loss: 0.36986443400382996
recon_loss: 0.027046047151088715, dist_loss: 0.4004644751548767
recon_loss: 0.027045823633670807, dist_loss: 0.2639347314834595
recon_loss: 0.027046794071793556, dist_loss: 0.4189073443412781
recon_loss: 0.027046820148825645, dist_loss: 0.6811438798904419
recon_loss: 0.027047913521528244, dist_loss: 0.7516974806785583
recon_loss: 0.027048122137784958, dist_loss: 0.5192596316337585
recon_loss: 0.027048414573073387, dist_loss: 0.16439586877822876
recon_loss: 0.02704823575913906, dist_loss: 0.9338490962982178
recon_loss: 0.027047758921980858, dist_loss: 0.5036669969558716
recon_loss: 0.02704705111682415, dist_loss: 0.563556969165802
recon_loss: 0.027046864852309227, dist_loss: 0.9438580274581909
recon_loss: 0.0270466897636652, dist_loss: 0.8439660668373108
recon_loss: 0.027046581730246544, dist_loss: 0.6354917287826538
recon_loss: 0.027045853435993195, dist_loss: 0.4977355897426605
recon_loss: 0.027045635506510735, dist_loss: 0.4578384459018707
recon_loss: 0.027044959366321564, dist_loss: 0.719960629940033
recon_loss: 0.02704496495425701, dist_loss: 0.3871917724609375
recon_loss: 0.027044737711548805, dist_loss: 0.6526880264282227
recon_loss: 0.027045227587223053, dist_loss: 0.6516196727752686
recon_loss: 0.027045711874961853, dist_loss: 0.8148932456970215
recon_loss: 0.027046943083405495, dist_loss: 0.9183294177055359
recon_loss: 0.02704782411456108, dist_loss: 0.5461121797561646
recon_loss: 0.027048569172620773, dist_loss: 1.096334457397461
recon_loss: 0.027049973607063293, dist_loss: 0.772345781326294
recon_loss: 0.027051299810409546, dist_loss: 1.03044593334198
recon_loss: 0.027053700760006905, dist_loss: 0.5244341492652893
recon_loss: 0.02705499343574047, dist_loss: 0.6235872507095337
recon_loss: 0.027054648846387863, dist_loss: 0.9211885929107666
recon_loss: 0.027053596451878548, dist_loss: 0.583246648311615
recon_loss: 0.0270527470856905, dist_loss: 0.7181617617607117
recon_loss: 0.02704990655183792, dist_loss: 0.3467969596385956
recon_loss: 0.027048055082559586, dist_loss: 0.45375511050224304
recon_loss: 0.027047526091337204, dist_loss: 0.5669845342636108
recon_loss: 0.027047885581851006, dist_loss: 0.5219325423240662
recon_loss: 0.027048980817198753, dist_loss: 0.5217834115028381
recon_loss: 0.027050506323575974, dist_loss: 0.7112380266189575
recon_loss: 0.027051031589508057, dist_loss: 0.6152712106704712
Pre-training Epoch 128:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 128:   4%|▍         | 16/367 [00:00<00:02, 150.53it/s]Pre-training Epoch 128:   9%|▊         | 32/367 [00:00<00:02, 153.44it/s]Pre-training Epoch 128:  13%|█▎        | 48/367 [00:00<00:02, 151.82it/s]Pre-training Epoch 128:  17%|█▋        | 64/367 [00:00<00:01, 152.84it/s]Pre-training Epoch 128:  22%|██▏       | 80/367 [00:00<00:01, 154.53it/s]Pre-training Epoch 128:  26%|██▌       | 96/367 [00:00<00:01, 153.75it/s]Pre-training Epoch 128:  31%|███       | 112/367 [00:00<00:01, 154.17it/s]Pre-training Epoch 128:  35%|███▍      | 128/367 [00:00<00:01, 154.14it/s]recon_loss: 0.02705228514969349, dist_loss: 0.45444294810295105
recon_loss: 0.027053579688072205, dist_loss: 0.6811114549636841
recon_loss: 0.027054060250520706, dist_loss: 0.5695555210113525
recon_loss: 0.02705424278974533, dist_loss: 0.7357394695281982
recon_loss: 0.027055049315094948, dist_loss: 0.6044947504997253
recon_loss: 0.027054451406002045, dist_loss: 0.5009206533432007
recon_loss: 0.02705337479710579, dist_loss: 0.8455212116241455
recon_loss: 0.02705175243318081, dist_loss: 0.8053816556930542
recon_loss: 0.027050519362092018, dist_loss: 0.47838810086250305
recon_loss: 0.02704903483390808, dist_loss: 1.5591334104537964
recon_loss: 0.02704799361526966, dist_loss: 0.7125825881958008
recon_loss: 0.027047062292695045, dist_loss: 0.5037675499916077
recon_loss: 0.027046743780374527, dist_loss: 0.8823831081390381
recon_loss: 0.027046356350183487, dist_loss: 0.6858223080635071
recon_loss: 0.027046307921409607, dist_loss: 0.6276363134384155
recon_loss: 0.027046537026762962, dist_loss: 0.7002326250076294
recon_loss: 0.027046145871281624, dist_loss: 0.6076493263244629
recon_loss: 0.027045870199799538, dist_loss: 0.6339020729064941
recon_loss: 0.02704576775431633, dist_loss: 0.6524109840393066
recon_loss: 0.027046123519539833, dist_loss: 0.4185631275177002
recon_loss: 0.027045873925089836, dist_loss: 0.8059848546981812
recon_loss: 0.027045488357543945, dist_loss: 0.4641822278499603
recon_loss: 0.027044635266065598, dist_loss: 0.8588777780532837
recon_loss: 0.027044419199228287, dist_loss: 0.9874920845031738
recon_loss: 0.027043573558330536, dist_loss: 0.6831040382385254
recon_loss: 0.027043530717492104, dist_loss: 0.5223624110221863
recon_loss: 0.027043156325817108, dist_loss: 0.8491344451904297
recon_loss: 0.027043206617236137, dist_loss: 0.8009284138679504
recon_loss: 0.02704300545156002, dist_loss: 0.5502127408981323
recon_loss: 0.027043195441365242, dist_loss: 0.31054195761680603
recon_loss: 0.027043092995882034, dist_loss: 1.1236952543258667
recon_loss: 0.027043217793107033, dist_loss: 0.49923333525657654
recon_loss: 0.027043083682656288, dist_loss: 0.5129106044769287
recon_loss: 0.02704343944787979, dist_loss: 0.5567790865898132
recon_loss: 0.027042731642723083, dist_loss: 0.6805446147918701
recon_loss: 0.027043459936976433, dist_loss: 0.4788095951080322
recon_loss: 0.027043674141168594, dist_loss: 0.7095680236816406
recon_loss: 0.027045754715800285, dist_loss: 0.2832908034324646
recon_loss: 0.027046043425798416, dist_loss: 0.7490304708480835
recon_loss: 0.027047598734498024, dist_loss: 0.6317424774169922
recon_loss: 0.02704794891178608, dist_loss: 0.4621371030807495
recon_loss: 0.02704836055636406, dist_loss: 0.9336737394332886
recon_loss: 0.02704843319952488, dist_loss: 0.8303545117378235
recon_loss: 0.027048397809267044, dist_loss: 0.8429986238479614
recon_loss: 0.027047932147979736, dist_loss: 0.8094510436058044
recon_loss: 0.02704739198088646, dist_loss: 0.6743901968002319
recon_loss: 0.027047090232372284, dist_loss: 0.4810289740562439
recon_loss: 0.02704728953540325, dist_loss: 0.7105072736740112
recon_loss: 0.0270472951233387, dist_loss: 1.1574450731277466
recon_loss: 0.027048146352171898, dist_loss: 0.6762192845344543
recon_loss: 0.027049271389842033, dist_loss: 0.4570525884628296
recon_loss: 0.027051765471696854, dist_loss: 0.626812219619751
recon_loss: 0.027052955701947212, dist_loss: 0.6351131200790405
recon_loss: 0.02705276571214199, dist_loss: 0.508047878742218
recon_loss: 0.027051512151956558, dist_loss: 0.5064175128936768
recon_loss: 0.027052247896790504, dist_loss: 0.6771372556686401
recon_loss: 0.027052493765950203, dist_loss: 0.9449620842933655
recon_loss: 0.02705327980220318, dist_loss: 1.1027575731277466
recon_loss: 0.02705260179936886, dist_loss: 0.6711275577545166
recon_loss: 0.027054598554968834, dist_loss: 0.4798585772514343
recon_loss: 0.027054380625486374, dist_loss: 0.42157620191574097
recon_loss: 0.027055533602833748, dist_loss: 0.43454962968826294
recon_loss: 0.027054313570261, dist_loss: 0.5830059051513672
recon_loss: 0.027055464684963226, dist_loss: 0.627060055732727
recon_loss: 0.027054257690906525, dist_loss: 0.8117198348045349
recon_loss: 0.027056248858571053, dist_loss: 0.30475914478302
recon_loss: 0.027054641395807266, dist_loss: 0.6984772682189941
recon_loss: 0.027056779712438583, dist_loss: 0.7469369173049927
recon_loss: 0.02705656737089157, dist_loss: 0.4283269941806793
recon_loss: 0.02705969102680683, dist_loss: 0.8820518255233765
recon_loss: 0.027060071006417274, dist_loss: 0.5158393383026123
recon_loss: 0.027062073349952698, dist_loss: 0.666424036026001
recon_loss: 0.027061382308602333, dist_loss: 1.1205832958221436
recon_loss: 0.027062326669692993, dist_loss: 0.5403015613555908
recon_loss: 0.027062559500336647, dist_loss: 0.6479887962341309
recon_loss: 0.027061617001891136, dist_loss: 0.5674461126327515
recon_loss: 0.02705923654139042, dist_loss: 0.421966016292572
recon_loss: 0.02705758810043335, dist_loss: 0.6394147872924805
recon_loss: 0.027054864913225174, dist_loss: 0.6378012299537659
recon_loss: 0.027054477483034134, dist_loss: 0.816154956817627
recon_loss: 0.027051689103245735, dist_loss: 0.5672931671142578
recon_loss: 0.02705293521285057, dist_loss: 0.47706547379493713
recon_loss: 0.027051139622926712, dist_loss: 0.5981419086456299
recon_loss: 0.02705295942723751, dist_loss: 0.45196110010147095
recon_loss: 0.02705274522304535, dist_loss: 0.5552141666412354
recon_loss: 0.027055086567997932, dist_loss: 0.5528664588928223
recon_loss: 0.0270550400018692, dist_loss: 0.6954871416091919
recon_loss: 0.027054239064455032, dist_loss: 0.7658235430717468
recon_loss: 0.02705363556742668, dist_loss: 0.5498191118240356
recon_loss: 0.027051884680986404, dist_loss: 1.0662729740142822
recon_loss: 0.027049532160162926, dist_loss: 0.5976251363754272
recon_loss: 0.02704765647649765, dist_loss: 0.9214255213737488
recon_loss: 0.027047259733080864, dist_loss: 0.5394078493118286
recon_loss: 0.027047161012887955, dist_loss: 0.5430266857147217
recon_loss: 0.027047378942370415, dist_loss: 0.619520902633667
recon_loss: 0.027047643437981606, dist_loss: 0.9013540148735046
recon_loss: 0.027048030868172646, dist_loss: 0.43969017267227173
recon_loss: 0.027047839015722275, dist_loss: 0.43389052152633667
recon_loss: 0.02704773284494877, dist_loss: 0.4188331663608551
recon_loss: 0.027047554031014442, dist_loss: 0.32374584674835205
recon_loss: 0.027046779170632362, dist_loss: 0.358407199382782
recon_loss: 0.027046101167798042, dist_loss: 0.6153765320777893
recon_loss: 0.02704506926238537, dist_loss: 0.6898300647735596
recon_loss: 0.027044331654906273, dist_loss: 0.4360758364200592
recon_loss: 0.027043495327234268, dist_loss: 0.5765122175216675
recon_loss: 0.02704327180981636, dist_loss: 0.6117253303527832
recon_loss: 0.027042843401432037, dist_loss: 1.1345611810684204
recon_loss: 0.02704300545156002, dist_loss: 0.4944371283054352
recon_loss: 0.02704320289194584, dist_loss: 0.7720929384231567
recon_loss: 0.02704324573278427, dist_loss: 0.5227961540222168
recon_loss: 0.02704300545156002, dist_loss: 0.5209900140762329
recon_loss: 0.02704269252717495, dist_loss: 1.0530543327331543
recon_loss: 0.02704213187098503, dist_loss: 0.5667569041252136
recon_loss: 0.027041420340538025, dist_loss: 0.3916248679161072
recon_loss: 0.027040742337703705, dist_loss: 0.6672862768173218
recon_loss: 0.027040468528866768, dist_loss: 0.5623593330383301
recon_loss: 0.02704041637480259, dist_loss: 0.36154890060424805
recon_loss: 0.027040252462029457, dist_loss: 1.4288544654846191
recon_loss: 0.027040323242545128, dist_loss: 0.3750159740447998
recon_loss: 0.027040695771574974, dist_loss: 0.5050274729728699
recon_loss: 0.027040822431445122, dist_loss: 0.8003202676773071
recon_loss: 0.027041831985116005, dist_loss: 0.9530084133148193
recon_loss: 0.02704041637480259, dist_loss: 0.7059100866317749
recon_loss: 0.027041977271437645, dist_loss: 0.86067795753479
recon_loss: 0.0270405113697052, dist_loss: 0.6635732650756836
recon_loss: 0.027041161432862282, dist_loss: 0.385680615901947
recon_loss: 0.02704015001654625, dist_loss: 0.5131480693817139
recon_loss: 0.02704024687409401, dist_loss: 0.45490342378616333
Pre-training Epoch 128:  39%|███▉      | 144/367 [00:00<00:01, 154.33it/s]Pre-training Epoch 128:  44%|████▍     | 161/367 [00:01<00:01, 156.82it/s]Pre-training Epoch 128:  48%|████▊     | 177/367 [00:01<00:01, 153.70it/s]Pre-training Epoch 128:  53%|█████▎    | 193/367 [00:01<00:01, 152.95it/s]Pre-training Epoch 128:  57%|█████▋    | 209/367 [00:01<00:01, 152.41it/s]Pre-training Epoch 128:  62%|██████▏   | 226/367 [00:01<00:00, 156.19it/s]Pre-training Epoch 128:  66%|██████▌   | 243/367 [00:01<00:00, 158.69it/s]recon_loss: 0.027039747685194016, dist_loss: 0.45724451541900635
recon_loss: 0.02703980542719364, dist_loss: 0.9986999034881592
recon_loss: 0.02704048901796341, dist_loss: 0.576161801815033
recon_loss: 0.027040179818868637, dist_loss: 0.4431816041469574
recon_loss: 0.027040714398026466, dist_loss: 0.520842969417572
recon_loss: 0.027040034532546997, dist_loss: 0.6226979494094849
recon_loss: 0.027040496468544006, dist_loss: 0.4884142577648163
recon_loss: 0.027040066197514534, dist_loss: 0.47659510374069214
recon_loss: 0.027041079476475716, dist_loss: 0.9287986159324646
recon_loss: 0.02704121544957161, dist_loss: 0.7955133318901062
recon_loss: 0.027042832225561142, dist_loss: 0.5849482417106628
recon_loss: 0.02704358473420143, dist_loss: 0.5463421940803528
recon_loss: 0.027045870199799538, dist_loss: 0.7744153141975403
recon_loss: 0.027046050876379013, dist_loss: 0.6541023254394531
recon_loss: 0.027047352865338326, dist_loss: 0.48017311096191406
recon_loss: 0.027047334238886833, dist_loss: 0.4877503514289856
recon_loss: 0.02704772725701332, dist_loss: 0.6053526401519775
recon_loss: 0.027047747746109962, dist_loss: 0.6604689359664917
recon_loss: 0.02704891934990883, dist_loss: 0.8884903192520142
recon_loss: 0.027048733085393906, dist_loss: 0.9595327377319336
recon_loss: 0.027047758921980858, dist_loss: 0.49850165843963623
recon_loss: 0.02704688347876072, dist_loss: 0.5833449959754944
recon_loss: 0.027045931667089462, dist_loss: 0.4780372381210327
recon_loss: 0.02704508788883686, dist_loss: 0.4107237160205841
recon_loss: 0.027044087648391724, dist_loss: 0.664132833480835
recon_loss: 0.027043642476201057, dist_loss: 0.44006624817848206
recon_loss: 0.027043143287301064, dist_loss: 0.7041163444519043
recon_loss: 0.027042776346206665, dist_loss: 0.5527864098548889
recon_loss: 0.02704196609556675, dist_loss: 0.8315470814704895
recon_loss: 0.027042236179113388, dist_loss: 0.6399566531181335
recon_loss: 0.027042483910918236, dist_loss: 0.8774803876876831
recon_loss: 0.02704348787665367, dist_loss: 0.8561959266662598
recon_loss: 0.027043534442782402, dist_loss: 0.5258645415306091
recon_loss: 0.02704326994717121, dist_loss: 0.8535905480384827
recon_loss: 0.027043147012591362, dist_loss: 0.8573384284973145
recon_loss: 0.027042726054787636, dist_loss: 0.48006004095077515
recon_loss: 0.02704213373363018, dist_loss: 0.5848995447158813
recon_loss: 0.027041198685765266, dist_loss: 0.6088317036628723
recon_loss: 0.027040556073188782, dist_loss: 0.6795803308486938
recon_loss: 0.0270400233566761, dist_loss: 0.3192746043205261
recon_loss: 0.027039354667067528, dist_loss: 0.7079168558120728
recon_loss: 0.02703890949487686, dist_loss: 0.6510831117630005
recon_loss: 0.027038443833589554, dist_loss: 0.5911591649055481
recon_loss: 0.02703842520713806, dist_loss: 0.4456525444984436
recon_loss: 0.027038227766752243, dist_loss: 0.5269886255264282
recon_loss: 0.02703843265771866, dist_loss: 0.8769893646240234
recon_loss: 0.02703871764242649, dist_loss: 0.637505829334259
recon_loss: 0.02703920006752014, dist_loss: 0.6530166268348694
recon_loss: 0.027039138600230217, dist_loss: 0.4596826732158661
recon_loss: 0.027039319276809692, dist_loss: 0.655929684638977
recon_loss: 0.027038900181651115, dist_loss: 0.6803044080734253
recon_loss: 0.027039187029004097, dist_loss: 0.2798807621002197
recon_loss: 0.027039391919970512, dist_loss: 0.5038187503814697
recon_loss: 0.027039997279644012, dist_loss: 0.8930028676986694
recon_loss: 0.02703992649912834, dist_loss: 0.666236937046051
recon_loss: 0.027040505781769753, dist_loss: 1.0486699342727661
recon_loss: 0.027039511129260063, dist_loss: 0.6533380746841431
recon_loss: 0.027039123699069023, dist_loss: 0.45628803968429565
recon_loss: 0.027037961408495903, dist_loss: 0.5295764207839966
recon_loss: 0.027037817984819412, dist_loss: 0.7504496574401855
recon_loss: 0.027036866173148155, dist_loss: 0.49782299995422363
recon_loss: 0.02703726291656494, dist_loss: 0.4436318278312683
recon_loss: 0.02703758515417576, dist_loss: 0.796065628528595
recon_loss: 0.02703864313662052, dist_loss: 1.0698301792144775
recon_loss: 0.027040107175707817, dist_loss: 0.4189556837081909
recon_loss: 0.027040990069508553, dist_loss: 0.7457154989242554
recon_loss: 0.027042752131819725, dist_loss: 0.5461499691009521
recon_loss: 0.027044035494327545, dist_loss: 0.9182506799697876
recon_loss: 0.02704383060336113, dist_loss: 0.4841079115867615
recon_loss: 0.027043987065553665, dist_loss: 0.7916078567504883
recon_loss: 0.027043407782912254, dist_loss: 0.3110787868499756
recon_loss: 0.027042651548981667, dist_loss: 0.5077545642852783
recon_loss: 0.027040867134928703, dist_loss: 0.6599527597427368
recon_loss: 0.02704000659286976, dist_loss: 0.4636310636997223
recon_loss: 0.027038918808102608, dist_loss: 0.9168688654899597
recon_loss: 0.027038633823394775, dist_loss: 0.5156822204589844
recon_loss: 0.02703784592449665, dist_loss: 0.4613550901412964
recon_loss: 0.027037624269723892, dist_loss: 0.7136890888214111
recon_loss: 0.02703767456114292, dist_loss: 0.48117151856422424
recon_loss: 0.02703758515417576, dist_loss: 0.6622334122657776
recon_loss: 0.02703753113746643, dist_loss: 0.7100214958190918
recon_loss: 0.027037424966692924, dist_loss: 0.5541660189628601
recon_loss: 0.027037376537919044, dist_loss: 0.6262830495834351
recon_loss: 0.027036866173148155, dist_loss: 0.6068184971809387
recon_loss: 0.02703745849430561, dist_loss: 0.5531355142593384
recon_loss: 0.02703769877552986, dist_loss: 0.8166071772575378
recon_loss: 0.0270388200879097, dist_loss: 0.6880621910095215
recon_loss: 0.027038373053073883, dist_loss: 0.9282984733581543
recon_loss: 0.027039075270295143, dist_loss: 0.4966384172439575
recon_loss: 0.02703796699643135, dist_loss: 0.4559357166290283
recon_loss: 0.027038777247071266, dist_loss: 0.6377345323562622
recon_loss: 0.027037324383854866, dist_loss: 0.4335891604423523
recon_loss: 0.027037465944886208, dist_loss: 1.0319371223449707
recon_loss: 0.027037791907787323, dist_loss: 0.5075997710227966
recon_loss: 0.027037713676691055, dist_loss: 0.5600619316101074
recon_loss: 0.027037562802433968, dist_loss: 0.8659953474998474
recon_loss: 0.027036959305405617, dist_loss: 0.5948718786239624
recon_loss: 0.027036888524889946, dist_loss: 0.5186485052108765
recon_loss: 0.027037039399147034, dist_loss: 0.6399538516998291
recon_loss: 0.0270368792116642, dist_loss: 0.336497962474823
recon_loss: 0.027036506682634354, dist_loss: 0.6876646280288696
recon_loss: 0.027035867795348167, dist_loss: 0.3543001413345337
recon_loss: 0.0270357858389616, dist_loss: 0.5642799139022827
recon_loss: 0.02703552506864071, dist_loss: 0.9557892084121704
recon_loss: 0.027035817503929138, dist_loss: 0.6400632858276367
recon_loss: 0.027035711333155632, dist_loss: 0.6999074220657349
recon_loss: 0.027035711333155632, dist_loss: 0.6067029237747192
recon_loss: 0.02703619748353958, dist_loss: 0.5578700304031372
recon_loss: 0.027036583051085472, dist_loss: 1.056647777557373
recon_loss: 0.027037901803851128, dist_loss: 0.7942740321159363
recon_loss: 0.027039406821131706, dist_loss: 0.49716177582740784
recon_loss: 0.02704077959060669, dist_loss: 0.8993147611618042
recon_loss: 0.027041437104344368, dist_loss: 0.8635216355323792
recon_loss: 0.027043554931879044, dist_loss: 0.40172097086906433
recon_loss: 0.02704363875091076, dist_loss: 0.4313691556453705
recon_loss: 0.02704295516014099, dist_loss: 0.7381414175033569
recon_loss: 0.02704104408621788, dist_loss: 0.3450775146484375
recon_loss: 0.027039440348744392, dist_loss: 0.5201247334480286
recon_loss: 0.02703756093978882, dist_loss: 0.6612143516540527
recon_loss: 0.027037717401981354, dist_loss: 0.5436569452285767
recon_loss: 0.027039052918553352, dist_loss: 0.6986376047134399
recon_loss: 0.027042116969823837, dist_loss: 0.8753080368041992
recon_loss: 0.027042986825108528, dist_loss: 0.7681378722190857
recon_loss: 0.027042154222726822, dist_loss: 0.5843978524208069
recon_loss: 0.027040811255574226, dist_loss: 0.46140843629837036
recon_loss: 0.027040768414735794, dist_loss: 0.7070209980010986
recon_loss: 0.0270391795784235, dist_loss: 0.4793289303779602
recon_loss: 0.0270379651337862, dist_loss: 0.8413137793540955
Pre-training Epoch 128:  71%|███████   | 260/367 [00:01<00:00, 159.50it/s]Pre-training Epoch 128:  75%|███████▌  | 277/367 [00:01<00:00, 160.76it/s]Pre-training Epoch 128:  80%|████████  | 294/367 [00:01<00:00, 162.17it/s]Pre-training Epoch 128:  85%|████████▍ | 311/367 [00:01<00:00, 162.97it/s]Pre-training Epoch 128:  89%|████████▉ | 328/367 [00:02<00:00, 157.46it/s]Pre-training Epoch 128:  94%|█████████▎| 344/367 [00:02<00:00, 156.98it/s]Pre-training Epoch 128:  98%|█████████▊| 361/367 [00:02<00:00, 159.03it/s]Pre-training Epoch 128: 100%|██████████| 367/367 [00:02<00:00, 156.54it/s]
recon_loss: 0.027037126943469048, dist_loss: 0.51015305519104
recon_loss: 0.027036679908633232, dist_loss: 0.6459475755691528
recon_loss: 0.027036698535084724, dist_loss: 0.571678102016449
recon_loss: 0.027036700397729874, dist_loss: 0.5975024700164795
recon_loss: 0.027037091553211212, dist_loss: 0.6390923857688904
recon_loss: 0.02703789621591568, dist_loss: 0.726283609867096
recon_loss: 0.027038872241973877, dist_loss: 0.4629422128200531
recon_loss: 0.02704017236828804, dist_loss: 0.7225965857505798
recon_loss: 0.027041960507631302, dist_loss: 0.37395769357681274
recon_loss: 0.027043651789426804, dist_loss: 0.7210617065429688
recon_loss: 0.027043523266911507, dist_loss: 0.6758012175559998
recon_loss: 0.02704394795000553, dist_loss: 0.8011471033096313
recon_loss: 0.027044760063290596, dist_loss: 0.5139230489730835
recon_loss: 0.027044935151934624, dist_loss: 0.7076311707496643
recon_loss: 0.027044525370001793, dist_loss: 0.46058541536331177
recon_loss: 0.027043843641877174, dist_loss: 0.590437114238739
recon_loss: 0.02704162336885929, dist_loss: 1.0402708053588867
recon_loss: 0.02703963778913021, dist_loss: 0.30059942603111267
recon_loss: 0.027038199827075005, dist_loss: 0.4830687940120697
recon_loss: 0.027036815881729126, dist_loss: 0.9240407943725586
recon_loss: 0.02703605405986309, dist_loss: 0.7173899412155151
recon_loss: 0.02703564055263996, dist_loss: 1.1405432224273682
recon_loss: 0.02703525312244892, dist_loss: 0.6464324593544006
recon_loss: 0.027035214006900787, dist_loss: 0.7625417113304138
recon_loss: 0.027035469189286232, dist_loss: 0.4803526997566223
recon_loss: 0.02703665941953659, dist_loss: 0.4942896068096161
recon_loss: 0.027036895975470543, dist_loss: 0.5796429514884949
recon_loss: 0.02703838050365448, dist_loss: 0.6433460116386414
recon_loss: 0.027039706707000732, dist_loss: 0.7372943162918091
recon_loss: 0.027041053399443626, dist_loss: 0.7517019510269165
recon_loss: 0.027043025940656662, dist_loss: 0.40863120555877686
recon_loss: 0.027043839916586876, dist_loss: 0.3278040289878845
recon_loss: 0.027043581008911133, dist_loss: 0.3499407172203064
recon_loss: 0.02704235352575779, dist_loss: 0.4540531635284424
recon_loss: 0.027041327208280563, dist_loss: 0.763407826423645
recon_loss: 0.02704004757106304, dist_loss: 0.5237565636634827
recon_loss: 0.027038371190428734, dist_loss: 0.7852542996406555
recon_loss: 0.027036480605602264, dist_loss: 0.5564844608306885
recon_loss: 0.02703511156141758, dist_loss: 0.6046401262283325
recon_loss: 0.027034202590584755, dist_loss: 0.32539981603622437
recon_loss: 0.027033498510718346, dist_loss: 1.0589890480041504
recon_loss: 0.02703370340168476, dist_loss: 0.6411036252975464
recon_loss: 0.027034033089876175, dist_loss: 0.6999362707138062
recon_loss: 0.027035335078835487, dist_loss: 0.45847976207733154
recon_loss: 0.027035769075155258, dist_loss: 0.905707597732544
recon_loss: 0.027036812156438828, dist_loss: 0.4332941770553589
recon_loss: 0.027036311104893684, dist_loss: 0.7724114656448364
recon_loss: 0.02703641727566719, dist_loss: 0.6670895218849182
recon_loss: 0.027036471292376518, dist_loss: 0.6109673976898193
recon_loss: 0.02703557349741459, dist_loss: 0.6335690021514893
recon_loss: 0.02703501097857952, dist_loss: 0.8354334831237793
recon_loss: 0.027035506442189217, dist_loss: 0.5080611705780029
recon_loss: 0.027033936232328415, dist_loss: 0.38880932331085205
recon_loss: 0.02703448012471199, dist_loss: 0.6510352492332458
recon_loss: 0.02703329175710678, dist_loss: 0.3883962035179138
recon_loss: 0.027034124359488487, dist_loss: 0.4155920743942261
recon_loss: 0.027033913880586624, dist_loss: 0.6025989651679993
recon_loss: 0.027035553008317947, dist_loss: 0.5821639895439148
recon_loss: 0.027034657076001167, dist_loss: 0.44104012846946716
recon_loss: 0.027035806328058243, dist_loss: 0.3518344461917877
recon_loss: 0.027034681290388107, dist_loss: 0.7151962518692017
recon_loss: 0.027035566046833992, dist_loss: 0.342316210269928
recon_loss: 0.02703428640961647, dist_loss: 0.9243590831756592
recon_loss: 0.02703515812754631, dist_loss: 0.5644562244415283
recon_loss: 0.02703479863703251, dist_loss: 0.8543170690536499
recon_loss: 0.02703564614057541, dist_loss: 0.6395204067230225
recon_loss: 0.02703356370329857, dist_loss: 0.5604703426361084
recon_loss: 0.02703477256000042, dist_loss: 0.4595181345939636
recon_loss: 0.02703285962343216, dist_loss: 0.5361202955245972
recon_loss: 0.02703288197517395, dist_loss: 0.969280481338501
recon_loss: 0.027032475918531418, dist_loss: 0.5594571828842163
recon_loss: 0.027032915502786636, dist_loss: 0.5740469694137573
recon_loss: 0.02703254297375679, dist_loss: 0.7436891794204712
recon_loss: 0.02703242190182209, dist_loss: 0.4965741038322449
recon_loss: 0.027032233774662018, dist_loss: 0.558796763420105
recon_loss: 0.027032557874917984, dist_loss: 0.7369828224182129
recon_loss: 0.027032703161239624, dist_loss: 0.6122148036956787
recon_loss: 0.027033211663365364, dist_loss: 0.9281490445137024
recon_loss: 0.027033355087041855, dist_loss: 0.5277431011199951
recon_loss: 0.027033740654587746, dist_loss: 0.5375893115997314
recon_loss: 0.027033010497689247, dist_loss: 0.6184215545654297
recon_loss: 0.02703358791768551, dist_loss: 0.4194789528846741
recon_loss: 0.027033731341362, dist_loss: 0.548628032207489
recon_loss: 0.027034498751163483, dist_loss: 0.5453338027000427
recon_loss: 0.027033371850848198, dist_loss: 0.4723411202430725
recon_loss: 0.027033820748329163, dist_loss: 0.43487241864204407
recon_loss: 0.02703399769961834, dist_loss: 0.8060112595558167
recon_loss: 0.027035633102059364, dist_loss: 0.4886782169342041
recon_loss: 0.027035079896450043, dist_loss: 0.6407272815704346
recon_loss: 0.027035797014832497, dist_loss: 0.5340913534164429
recon_loss: 0.027035336941480637, dist_loss: 0.7022210359573364
recon_loss: 0.027034927159547806, dist_loss: 0.7589081525802612
recon_loss: 0.027033524587750435, dist_loss: 0.7965561151504517
recon_loss: 0.02703273296356201, dist_loss: 0.29332083463668823
recon_loss: 0.027031876146793365, dist_loss: 0.5462124943733215
recon_loss: 0.027031738311052322, dist_loss: 0.898689866065979
recon_loss: 0.02703104168176651, dist_loss: 0.5487442016601562
recon_loss: 0.027031036093831062, dist_loss: 1.0196621417999268
recon_loss: 0.027030840516090393, dist_loss: 0.5007078051567078
recon_loss: 0.027030669152736664, dist_loss: 0.6476631164550781
recon_loss: 0.02703065052628517, dist_loss: 0.4333575665950775
recon_loss: 0.027030957862734795, dist_loss: 0.33933502435684204
recon_loss: 0.027031440287828445, dist_loss: 0.7826988697052002
recon_loss: 0.027031706646084785, dist_loss: 0.4146597683429718
recon_loss: 0.027031851932406425, dist_loss: 0.8389115929603577
recon_loss: 0.027031689882278442, dist_loss: 0.36127424240112305
recon_loss: 0.02703102119266987, dist_loss: 0.5447806119918823
recon_loss: 0.027031252160668373, dist_loss: 0.5232298970222473
recon_loss: 0.027032211422920227, dist_loss: 0.5408854484558105
recon_loss: 0.027034830302000046, dist_loss: 0.5455020666122437
recon_loss: 0.027037428691983223, dist_loss: 0.5660412907600403
Pre-training Epoch 129:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 129:   4%|▍         | 14/367 [00:00<00:02, 138.52it/s]Pre-training Epoch 129:   8%|▊         | 30/367 [00:00<00:02, 148.52it/s]Pre-training Epoch 129:  13%|█▎        | 46/367 [00:00<00:02, 152.37it/s]Pre-training Epoch 129:  17%|█▋        | 64/367 [00:00<00:01, 162.59it/s]Pre-training Epoch 129:  22%|██▏       | 82/367 [00:00<00:01, 168.41it/s]Pre-training Epoch 129:  27%|██▋       | 100/367 [00:00<00:01, 172.20it/s]Pre-training Epoch 129:  32%|███▏      | 118/367 [00:00<00:01, 174.62it/s]recon_loss: 0.027039209380745888, dist_loss: 0.42846453189849854
recon_loss: 0.027040153741836548, dist_loss: 0.6094797849655151
recon_loss: 0.02704004757106304, dist_loss: 0.2837423086166382
recon_loss: 0.02703932859003544, dist_loss: 0.35586175322532654
recon_loss: 0.027038441970944405, dist_loss: 0.4655788540840149
recon_loss: 0.02703816629946232, dist_loss: 0.5348213315010071
recon_loss: 0.027037441730499268, dist_loss: 0.36991286277770996
recon_loss: 0.0270369965583086, dist_loss: 0.6298466920852661
recon_loss: 0.02703581005334854, dist_loss: 0.34910279512405396
recon_loss: 0.0270353052765131, dist_loss: 0.9489073753356934
recon_loss: 0.02703600563108921, dist_loss: 0.5352071523666382
recon_loss: 0.027037475258111954, dist_loss: 0.5411118268966675
recon_loss: 0.027038566768169403, dist_loss: 0.4685390293598175
recon_loss: 0.027039118111133575, dist_loss: 0.8263609409332275
recon_loss: 0.027040058746933937, dist_loss: 0.39855825901031494
recon_loss: 0.02703987993299961, dist_loss: 0.515893280506134
recon_loss: 0.027039160951972008, dist_loss: 0.5718512535095215
recon_loss: 0.027037721127271652, dist_loss: 0.5121302008628845
recon_loss: 0.027036432176828384, dist_loss: 0.861709475517273
recon_loss: 0.027035024017095566, dist_loss: 0.7293760776519775
recon_loss: 0.02703506499528885, dist_loss: 0.8146420121192932
recon_loss: 0.027034476399421692, dist_loss: 0.528128981590271
recon_loss: 0.02703435719013214, dist_loss: 0.3721754550933838
recon_loss: 0.02703414298593998, dist_loss: 0.8279068470001221
recon_loss: 0.027034448459744453, dist_loss: 0.764500617980957
recon_loss: 0.027034731581807137, dist_loss: 0.8173948526382446
recon_loss: 0.027035115286707878, dist_loss: 0.7831443548202515
recon_loss: 0.027035465463995934, dist_loss: 0.31640154123306274
recon_loss: 0.02703532576560974, dist_loss: 1.1169410943984985
recon_loss: 0.027035480365157127, dist_loss: 0.7668384313583374
recon_loss: 0.027035769075155258, dist_loss: 0.49880021810531616
recon_loss: 0.027035845443606377, dist_loss: 0.6052427291870117
recon_loss: 0.027036400511860847, dist_loss: 0.386954128742218
recon_loss: 0.027036231011152267, dist_loss: 0.7207964062690735
recon_loss: 0.027035564184188843, dist_loss: 0.6599979400634766
recon_loss: 0.027034666389226913, dist_loss: 0.6932549476623535
recon_loss: 0.027034007012844086, dist_loss: 0.627238929271698
recon_loss: 0.027033118531107903, dist_loss: 0.7729958295822144
recon_loss: 0.027033306658267975, dist_loss: 0.5395087003707886
recon_loss: 0.027032867074012756, dist_loss: 0.6454395055770874
recon_loss: 0.027033759281039238, dist_loss: 0.9060273170471191
recon_loss: 0.027035381644964218, dist_loss: 0.36109283566474915
recon_loss: 0.02703726850450039, dist_loss: 0.6767083406448364
recon_loss: 0.027039997279644012, dist_loss: 0.4132089912891388
recon_loss: 0.027042564004659653, dist_loss: 0.8258614540100098
recon_loss: 0.027043083682656288, dist_loss: 0.49444910883903503
recon_loss: 0.02704203873872757, dist_loss: 0.5632176399230957
recon_loss: 0.02703985758125782, dist_loss: 0.600623607635498
recon_loss: 0.0270370040088892, dist_loss: 0.9036288857460022
recon_loss: 0.027035504579544067, dist_loss: 0.6493531465530396
recon_loss: 0.027034608647227287, dist_loss: 0.7482849359512329
recon_loss: 0.027033980935811996, dist_loss: 0.4834297299385071
recon_loss: 0.027033735066652298, dist_loss: 0.7754948139190674
recon_loss: 0.027033977210521698, dist_loss: 0.4789702296257019
recon_loss: 0.02703406848013401, dist_loss: 0.44312483072280884
recon_loss: 0.027034685015678406, dist_loss: 0.3389667868614197
recon_loss: 0.027034590020775795, dist_loss: 0.7048822641372681
recon_loss: 0.027034450322389603, dist_loss: 0.41550636291503906
recon_loss: 0.027033831924200058, dist_loss: 0.4271220564842224
recon_loss: 0.027032988145947456, dist_loss: 0.5064045190811157
recon_loss: 0.027032600715756416, dist_loss: 0.46972253918647766
recon_loss: 0.02703295648097992, dist_loss: 0.6614982485771179
recon_loss: 0.027033628895878792, dist_loss: 0.5228071212768555
recon_loss: 0.027033908292651176, dist_loss: 0.9561492800712585
recon_loss: 0.027033518999814987, dist_loss: 0.5145313143730164
recon_loss: 0.02703326754271984, dist_loss: 0.6282756924629211
recon_loss: 0.02703269012272358, dist_loss: 1.2601494789123535
recon_loss: 0.027032053098082542, dist_loss: 0.6954379677772522
recon_loss: 0.02703125588595867, dist_loss: 0.587653398513794
recon_loss: 0.027030684053897858, dist_loss: 0.6686549186706543
recon_loss: 0.027030792087316513, dist_loss: 0.5688767433166504
recon_loss: 0.02703162655234337, dist_loss: 0.5706909894943237
recon_loss: 0.027032265439629555, dist_loss: 0.7591170072555542
recon_loss: 0.027033569291234016, dist_loss: 0.4578785300254822
recon_loss: 0.02703527733683586, dist_loss: 0.7202792167663574
recon_loss: 0.02703521028161049, dist_loss: 0.4184512495994568
recon_loss: 0.02703460305929184, dist_loss: 0.41734471917152405
recon_loss: 0.027034614235162735, dist_loss: 0.6964772343635559
recon_loss: 0.027034271508455276, dist_loss: 0.7890216112136841
recon_loss: 0.027033189311623573, dist_loss: 0.6893302798271179
recon_loss: 0.02703220397233963, dist_loss: 0.2826522886753082
recon_loss: 0.027031326666474342, dist_loss: 0.6853949427604675
recon_loss: 0.02703077159821987, dist_loss: 0.5704304575920105
recon_loss: 0.02703060768544674, dist_loss: 0.5809159278869629
recon_loss: 0.027030838653445244, dist_loss: 0.4118228554725647
recon_loss: 0.027031030505895615, dist_loss: 0.560938835144043
recon_loss: 0.02703068219125271, dist_loss: 0.837436854839325
recon_loss: 0.02703060209751129, dist_loss: 0.5740954875946045
recon_loss: 0.0270299781113863, dist_loss: 0.9699255228042603
recon_loss: 0.027029510587453842, dist_loss: 0.543736457824707
recon_loss: 0.02702944539487362, dist_loss: 1.0643131732940674
recon_loss: 0.02702905423939228, dist_loss: 0.32250455021858215
recon_loss: 0.027029290795326233, dist_loss: 1.0813257694244385
recon_loss: 0.027029529213905334, dist_loss: 0.6639581918716431
recon_loss: 0.02703017182648182, dist_loss: 0.5634632706642151
recon_loss: 0.027029361575841904, dist_loss: 0.5958800315856934
recon_loss: 0.0270293727517128, dist_loss: 0.7375187873840332
recon_loss: 0.027028463780879974, dist_loss: 0.5349504947662354
recon_loss: 0.027028385549783707, dist_loss: 0.4335971474647522
recon_loss: 0.027027204632759094, dist_loss: 0.6395455598831177
recon_loss: 0.027028849348425865, dist_loss: 0.5981013178825378
recon_loss: 0.027027815580368042, dist_loss: 0.6441096663475037
recon_loss: 0.027028657495975494, dist_loss: 0.41452300548553467
recon_loss: 0.027027692645788193, dist_loss: 0.44573429226875305
recon_loss: 0.02702859416604042, dist_loss: 0.6708881258964539
recon_loss: 0.027027593925595284, dist_loss: 0.4486783742904663
recon_loss: 0.027028383687138557, dist_loss: 0.7074071764945984
recon_loss: 0.027027057483792305, dist_loss: 0.7432906031608582
recon_loss: 0.027027353644371033, dist_loss: 0.6009459495544434
recon_loss: 0.027026915922760963, dist_loss: 0.49993255734443665
recon_loss: 0.027028175070881844, dist_loss: 0.39145731925964355
recon_loss: 0.027027681469917297, dist_loss: 0.6563431620597839
recon_loss: 0.027028560638427734, dist_loss: 0.5467620491981506
recon_loss: 0.02702767215669155, dist_loss: 0.6058050990104675
recon_loss: 0.027029037475585938, dist_loss: 0.6670238971710205
recon_loss: 0.027027836069464684, dist_loss: 0.5895144939422607
recon_loss: 0.027028635144233704, dist_loss: 0.5429444313049316
recon_loss: 0.027027418836951256, dist_loss: 0.5141780972480774
recon_loss: 0.02702851966023445, dist_loss: 0.6850977540016174
recon_loss: 0.02702673338353634, dist_loss: 1.0079948902130127
recon_loss: 0.02702859230339527, dist_loss: 0.32389703392982483
recon_loss: 0.027027441188693047, dist_loss: 0.34780219197273254
recon_loss: 0.027029095217585564, dist_loss: 0.794792652130127
recon_loss: 0.02702900394797325, dist_loss: 0.36751988530158997
recon_loss: 0.02703044004738331, dist_loss: 0.8856194019317627
recon_loss: 0.027030235156416893, dist_loss: 0.8130836486816406
recon_loss: 0.0270322784781456, dist_loss: 0.6366531848907471
recon_loss: 0.027032168582081795, dist_loss: 0.5086812973022461
Pre-training Epoch 129:  37%|███▋      | 137/367 [00:00<00:01, 176.54it/s]Pre-training Epoch 129:  43%|████▎     | 156/367 [00:00<00:01, 177.78it/s]Pre-training Epoch 129:  47%|████▋     | 174/367 [00:01<00:01, 178.16it/s]Pre-training Epoch 129:  52%|█████▏    | 192/367 [00:01<00:01, 168.26it/s]Pre-training Epoch 129:  57%|█████▋    | 209/367 [00:01<00:00, 165.07it/s]Pre-training Epoch 129:  62%|██████▏   | 226/367 [00:01<00:00, 161.58it/s]Pre-training Epoch 129:  66%|██████▌   | 243/367 [00:01<00:00, 162.23it/s]recon_loss: 0.02703397162258625, dist_loss: 0.23579275608062744
recon_loss: 0.027033580467104912, dist_loss: 0.8051356077194214
recon_loss: 0.02703487128019333, dist_loss: 0.5233874320983887
recon_loss: 0.027034908533096313, dist_loss: 0.850529670715332
recon_loss: 0.027035338804125786, dist_loss: 0.6439607739448547
recon_loss: 0.02703515812754631, dist_loss: 0.6202684044837952
recon_loss: 0.02703547477722168, dist_loss: 0.8022018074989319
recon_loss: 0.027034424245357513, dist_loss: 0.4823007881641388
recon_loss: 0.027034081518650055, dist_loss: 0.6100926399230957
recon_loss: 0.027032122015953064, dist_loss: 0.7689186930656433
recon_loss: 0.02703155390918255, dist_loss: 1.0152745246887207
recon_loss: 0.0270307008177042, dist_loss: 0.5538265705108643
recon_loss: 0.027031201869249344, dist_loss: 0.6214492917060852
recon_loss: 0.02703101933002472, dist_loss: 0.5507025718688965
recon_loss: 0.027032187208533287, dist_loss: 0.7388178110122681
recon_loss: 0.027032217010855675, dist_loss: 0.46485817432403564
recon_loss: 0.02703285776078701, dist_loss: 1.0127087831497192
recon_loss: 0.027032699435949326, dist_loss: 0.7628595232963562
recon_loss: 0.02703283354640007, dist_loss: 0.4636361300945282
recon_loss: 0.027032917365431786, dist_loss: 0.4306497573852539
recon_loss: 0.027033468708395958, dist_loss: 0.5464959740638733
recon_loss: 0.027034685015678406, dist_loss: 0.6116907000541687
recon_loss: 0.02703610621392727, dist_loss: 0.5695567727088928
recon_loss: 0.02703685499727726, dist_loss: 0.8929855227470398
recon_loss: 0.027036862447857857, dist_loss: 0.5940642356872559
recon_loss: 0.027035942301154137, dist_loss: 0.5518745183944702
recon_loss: 0.02703438140451908, dist_loss: 0.7275485992431641
recon_loss: 0.027033045887947083, dist_loss: 0.9496147036552429
recon_loss: 0.027032557874917984, dist_loss: 0.7381249666213989
recon_loss: 0.02703246660530567, dist_loss: 0.5945428013801575
recon_loss: 0.02703254297375679, dist_loss: 0.7074240446090698
recon_loss: 0.02703196555376053, dist_loss: 0.3044562339782715
recon_loss: 0.027032293379306793, dist_loss: 0.5914356708526611
recon_loss: 0.027031734585762024, dist_loss: 0.48459309339523315
recon_loss: 0.027032025158405304, dist_loss: 0.4882420599460602
recon_loss: 0.027032388374209404, dist_loss: 0.45194777846336365
recon_loss: 0.027033036574721336, dist_loss: 0.9261457920074463
recon_loss: 0.027033284306526184, dist_loss: 0.3445499539375305
recon_loss: 0.02703314647078514, dist_loss: 0.6760129928588867
recon_loss: 0.02703380025923252, dist_loss: 0.7489997744560242
recon_loss: 0.027033774182200432, dist_loss: 0.5488818287849426
recon_loss: 0.0270334891974926, dist_loss: 0.34200412034988403
recon_loss: 0.02703315205872059, dist_loss: 0.551895797252655
recon_loss: 0.027032649144530296, dist_loss: 0.6555899381637573
recon_loss: 0.027032384648919106, dist_loss: 0.425938218832016
recon_loss: 0.027031555771827698, dist_loss: 0.46782800555229187
recon_loss: 0.027031876146793365, dist_loss: 0.5651273727416992
recon_loss: 0.027031583711504936, dist_loss: 0.4510789215564728
recon_loss: 0.02703213319182396, dist_loss: 0.3524484634399414
recon_loss: 0.027032222598791122, dist_loss: 0.5957435369491577
recon_loss: 0.02703346125781536, dist_loss: 0.504248321056366
recon_loss: 0.027031410485506058, dist_loss: 0.6284593343734741
recon_loss: 0.027033580467104912, dist_loss: 0.5584845542907715
recon_loss: 0.027031773701310158, dist_loss: 0.7126762866973877
recon_loss: 0.027033044025301933, dist_loss: 0.48707592487335205
recon_loss: 0.027032408863306046, dist_loss: 0.658892810344696
recon_loss: 0.02703293412923813, dist_loss: 0.7200514078140259
recon_loss: 0.02703195810317993, dist_loss: 0.7382086515426636
recon_loss: 0.027031421661376953, dist_loss: 0.49093320965766907
recon_loss: 0.027030866593122482, dist_loss: 0.5685396790504456
recon_loss: 0.027030259370803833, dist_loss: 0.9982485771179199
recon_loss: 0.02703021466732025, dist_loss: 0.7089731693267822
recon_loss: 0.027028782293200493, dist_loss: 0.6511012315750122
recon_loss: 0.02702825516462326, dist_loss: 0.53437739610672
recon_loss: 0.027027180418372154, dist_loss: 0.6813076734542847
recon_loss: 0.027026671916246414, dist_loss: 0.4779212474822998
recon_loss: 0.02702631987631321, dist_loss: 0.6085166335105896
recon_loss: 0.02702617086470127, dist_loss: 0.4855968952178955
recon_loss: 0.0270262211561203, dist_loss: 0.3931349515914917
recon_loss: 0.027026375755667686, dist_loss: 0.5276245474815369
recon_loss: 0.027026277035474777, dist_loss: 0.5046373605728149
recon_loss: 0.027026478201150894, dist_loss: 0.42740321159362793
recon_loss: 0.027026284486055374, dist_loss: 0.7338393330574036
recon_loss: 0.02702656202018261, dist_loss: 0.47452205419540405
recon_loss: 0.027026573196053505, dist_loss: 0.5712636113166809
recon_loss: 0.027026209980249405, dist_loss: 0.7995568513870239
recon_loss: 0.02702540159225464, dist_loss: 0.8504644632339478
recon_loss: 0.02702578902244568, dist_loss: 0.9313650131225586
recon_loss: 0.027024777606129646, dist_loss: 0.5391353368759155
recon_loss: 0.027025792747735977, dist_loss: 0.6810097694396973
recon_loss: 0.027024878188967705, dist_loss: 0.26688218116760254
recon_loss: 0.027026893571019173, dist_loss: 0.629051923751831
recon_loss: 0.02702554315328598, dist_loss: 0.8190906643867493
recon_loss: 0.027026565745472908, dist_loss: 0.547480046749115
recon_loss: 0.027025844901800156, dist_loss: 0.5820761322975159
recon_loss: 0.027026820927858353, dist_loss: 0.6239306926727295
recon_loss: 0.027026481926441193, dist_loss: 0.6088657975196838
recon_loss: 0.027027031406760216, dist_loss: 0.9672132730484009
recon_loss: 0.027025599032640457, dist_loss: 0.6938236951828003
recon_loss: 0.027024604380130768, dist_loss: 0.45763057470321655
recon_loss: 0.027023952454328537, dist_loss: 0.39325690269470215
recon_loss: 0.02702365256845951, dist_loss: 0.5435181856155396
recon_loss: 0.027024099603295326, dist_loss: 0.4895872175693512
recon_loss: 0.02702426351606846, dist_loss: 0.6560903191566467
recon_loss: 0.0270248856395483, dist_loss: 0.6437715888023376
recon_loss: 0.027025019749999046, dist_loss: 0.8529224395751953
recon_loss: 0.027026189491152763, dist_loss: 0.4762443006038666
recon_loss: 0.027025992050766945, dist_loss: 0.7248721122741699
recon_loss: 0.027027158066630363, dist_loss: 0.7220767140388489
recon_loss: 0.02702583186328411, dist_loss: 0.640327513217926
recon_loss: 0.02702738530933857, dist_loss: 0.581310510635376
recon_loss: 0.0270264632999897, dist_loss: 0.3234111964702606
recon_loss: 0.027026863768696785, dist_loss: 0.5418164730072021
recon_loss: 0.027026137337088585, dist_loss: 0.6697580814361572
recon_loss: 0.027026016265153885, dist_loss: 1.118974208831787
recon_loss: 0.027026453986763954, dist_loss: 0.4891566336154938
recon_loss: 0.027026107534766197, dist_loss: 0.5594823360443115
recon_loss: 0.02702605538070202, dist_loss: 0.8147186040878296
recon_loss: 0.027025792747735977, dist_loss: 1.0525550842285156
recon_loss: 0.027024900540709496, dist_loss: 0.6851564645767212
recon_loss: 0.02702520787715912, dist_loss: 0.3243800401687622
recon_loss: 0.02702500857412815, dist_loss: 0.6782945990562439
recon_loss: 0.02702501229941845, dist_loss: 1.1868126392364502
recon_loss: 0.027025125920772552, dist_loss: 0.4077441990375519
recon_loss: 0.02702583558857441, dist_loss: 0.5081247091293335
recon_loss: 0.027026034891605377, dist_loss: 0.38864266872406006
recon_loss: 0.02702622301876545, dist_loss: 0.33627548813819885
recon_loss: 0.027026502415537834, dist_loss: 0.22258904576301575
recon_loss: 0.02702709473669529, dist_loss: 0.7030905485153198
recon_loss: 0.02702869288623333, dist_loss: 1.0728763341903687
recon_loss: 0.02702861651778221, dist_loss: 0.6177741289138794
recon_loss: 0.027028460055589676, dist_loss: 0.5680769085884094
recon_loss: 0.02702794037759304, dist_loss: 0.27149704098701477
recon_loss: 0.02702707052230835, dist_loss: 0.6787113547325134
recon_loss: 0.027026241645216942, dist_loss: 0.8603586554527283
recon_loss: 0.027025947347283363, dist_loss: 0.56175696849823
recon_loss: 0.027025345712900162, dist_loss: 0.6778497099876404
recon_loss: 0.027025241404771805, dist_loss: 0.9735043048858643
Pre-training Epoch 129:  71%|███████   | 260/367 [00:01<00:00, 161.24it/s]Pre-training Epoch 129:  75%|███████▌  | 277/367 [00:01<00:00, 160.71it/s]Pre-training Epoch 129:  80%|████████  | 294/367 [00:01<00:00, 161.36it/s]Pre-training Epoch 129:  85%|████████▍ | 311/367 [00:01<00:00, 162.00it/s]Pre-training Epoch 129:  89%|████████▉ | 328/367 [00:01<00:00, 162.06it/s]Pre-training Epoch 129:  94%|█████████▍| 345/367 [00:02<00:00, 157.84it/s]Pre-training Epoch 129:  99%|█████████▊| 362/367 [00:02<00:00, 159.14it/s]Pre-training Epoch 129: 100%|██████████| 367/367 [00:02<00:00, 163.93it/s]
recon_loss: 0.02702418714761734, dist_loss: 0.9938064813613892
recon_loss: 0.027024047449231148, dist_loss: 0.5723444223403931
recon_loss: 0.02702329121530056, dist_loss: 0.7662496566772461
recon_loss: 0.02702348306775093, dist_loss: 0.8268938064575195
recon_loss: 0.027023162692785263, dist_loss: 0.371939092874527
recon_loss: 0.027023369446396828, dist_loss: 0.4335356056690216
recon_loss: 0.02702321857213974, dist_loss: 0.6256409287452698
recon_loss: 0.027023574337363243, dist_loss: 1.2031571865081787
recon_loss: 0.027023712173104286, dist_loss: 0.5693840980529785
recon_loss: 0.02702377922832966, dist_loss: 0.3379032015800476
recon_loss: 0.02702462114393711, dist_loss: 1.0733039379119873
recon_loss: 0.02702515572309494, dist_loss: 1.0518288612365723
recon_loss: 0.027027223259210587, dist_loss: 0.3787359595298767
recon_loss: 0.02702949568629265, dist_loss: 1.509577989578247
recon_loss: 0.027031727135181427, dist_loss: 0.34642261266708374
recon_loss: 0.027033165097236633, dist_loss: 0.4756588935852051
recon_loss: 0.027032963931560516, dist_loss: 0.9765821695327759
recon_loss: 0.027034278959035873, dist_loss: 0.6222842931747437
recon_loss: 0.027034180238842964, dist_loss: 0.4654695689678192
recon_loss: 0.027033988386392593, dist_loss: 0.6077524423599243
recon_loss: 0.027031512930989265, dist_loss: 0.4982208013534546
recon_loss: 0.027030471712350845, dist_loss: 0.6339367628097534
recon_loss: 0.02702946774661541, dist_loss: 0.7800645232200623
recon_loss: 0.02702910080552101, dist_loss: 0.9707701802253723
recon_loss: 0.027029043063521385, dist_loss: 0.7175689339637756
recon_loss: 0.02702982909977436, dist_loss: 0.7935551404953003
recon_loss: 0.027030767872929573, dist_loss: 0.40494677424430847
recon_loss: 0.027031533420085907, dist_loss: 0.4032720923423767
recon_loss: 0.027032475918531418, dist_loss: 0.6370736956596375
recon_loss: 0.02703373320400715, dist_loss: 1.0168343782424927
recon_loss: 0.02703402377665043, dist_loss: 0.5654478073120117
recon_loss: 0.027033796533942223, dist_loss: 0.32516470551490784
recon_loss: 0.027034100145101547, dist_loss: 0.6090496182441711
recon_loss: 0.02703407034277916, dist_loss: 1.010887622833252
recon_loss: 0.02703450433909893, dist_loss: 0.7000936269760132
recon_loss: 0.027034766972064972, dist_loss: 0.2472638040781021
recon_loss: 0.02703467570245266, dist_loss: 0.5466497540473938
recon_loss: 0.027033425867557526, dist_loss: 0.3504122495651245
recon_loss: 0.027032896876335144, dist_loss: 0.5619693994522095
recon_loss: 0.02703148126602173, dist_loss: 0.22307126224040985
recon_loss: 0.027031147852540016, dist_loss: 0.46139249205589294
recon_loss: 0.027030132710933685, dist_loss: 0.6310783624649048
recon_loss: 0.027029646560549736, dist_loss: 0.39863812923431396
recon_loss: 0.027028627693653107, dist_loss: 0.5301663875579834
recon_loss: 0.027028298005461693, dist_loss: 0.25096359848976135
recon_loss: 0.02702687866985798, dist_loss: 0.6817256212234497
recon_loss: 0.02702682465314865, dist_loss: 0.6528200507164001
recon_loss: 0.027025962248444557, dist_loss: 0.8602497577667236
recon_loss: 0.027026483789086342, dist_loss: 0.7655574083328247
recon_loss: 0.02702677622437477, dist_loss: 0.7051630616188049
recon_loss: 0.027027390897274017, dist_loss: 0.6198139190673828
recon_loss: 0.027026979252696037, dist_loss: 0.5949710607528687
recon_loss: 0.027027808129787445, dist_loss: 0.4762435555458069
recon_loss: 0.027027390897274017, dist_loss: 0.9412936568260193
recon_loss: 0.027028417214751244, dist_loss: 0.45734092593193054
recon_loss: 0.02702787145972252, dist_loss: 0.8790280222892761
recon_loss: 0.02702847495675087, dist_loss: 0.75761878490448
recon_loss: 0.02702982723712921, dist_loss: 0.6388245820999146
recon_loss: 0.027031851932406425, dist_loss: 0.8185766339302063
recon_loss: 0.02703314647078514, dist_loss: 0.8837052583694458
recon_loss: 0.02703448385000229, dist_loss: 0.8298191428184509
recon_loss: 0.027034929022192955, dist_loss: 0.6440593004226685
recon_loss: 0.027035098522901535, dist_loss: 0.6520964503288269
recon_loss: 0.02703397162258625, dist_loss: 0.3981184661388397
recon_loss: 0.027032891288399696, dist_loss: 0.6272977590560913
recon_loss: 0.027031386271119118, dist_loss: 0.4148392975330353
recon_loss: 0.027030181139707565, dist_loss: 0.6750364899635315
recon_loss: 0.027028845623135567, dist_loss: 0.40245288610458374
recon_loss: 0.02702724002301693, dist_loss: 0.5708156824111938
recon_loss: 0.027024995535612106, dist_loss: 1.0806682109832764
recon_loss: 0.02702561393380165, dist_loss: 0.47892555594444275
recon_loss: 0.027025554329156876, dist_loss: 0.7206875085830688
recon_loss: 0.027027921751141548, dist_loss: 0.7354877591133118
recon_loss: 0.02702663652598858, dist_loss: 0.9880344867706299
recon_loss: 0.027027741074562073, dist_loss: 0.5840564966201782
recon_loss: 0.027026891708374023, dist_loss: 0.451871395111084
recon_loss: 0.027028046548366547, dist_loss: 0.4139498472213745
recon_loss: 0.0270276740193367, dist_loss: 0.6433119773864746
recon_loss: 0.027028322219848633, dist_loss: 1.0742018222808838
recon_loss: 0.027027850970625877, dist_loss: 0.6189102530479431
recon_loss: 0.027027808129787445, dist_loss: 0.4269182085990906
recon_loss: 0.027026813477277756, dist_loss: 0.5690439343452454
recon_loss: 0.027025815099477768, dist_loss: 0.6972059011459351
recon_loss: 0.02702460251748562, dist_loss: 0.5471605062484741
recon_loss: 0.02702350728213787, dist_loss: 0.5614162683486938
recon_loss: 0.027023188769817352, dist_loss: 0.5694521069526672
recon_loss: 0.02702292986214161, dist_loss: 0.6011218428611755
recon_loss: 0.027022939175367355, dist_loss: 0.6243909597396851
recon_loss: 0.02702290564775467, dist_loss: 0.7311024069786072
recon_loss: 0.02702275477349758, dist_loss: 0.7348184585571289
recon_loss: 0.027022695168852806, dist_loss: 0.7808794975280762
recon_loss: 0.02702111192047596, dist_loss: 0.6273317933082581
recon_loss: 0.027021614834666252, dist_loss: 0.6622117757797241
recon_loss: 0.027020610868930817, dist_loss: 0.5583617091178894
recon_loss: 0.027022024616599083, dist_loss: 0.5187986493110657
recon_loss: 0.027019904926419258, dist_loss: 0.8700382709503174
recon_loss: 0.027021633461117744, dist_loss: 0.5132614374160767
recon_loss: 0.027019625529646873, dist_loss: 0.41494274139404297
recon_loss: 0.02702092006802559, dist_loss: 0.9885053634643555
recon_loss: 0.027019217610359192, dist_loss: 0.6619672179222107
recon_loss: 0.027020437642931938, dist_loss: 0.43536245822906494
recon_loss: 0.027018975466489792, dist_loss: 0.48796546459198
recon_loss: 0.027019057422876358, dist_loss: 0.928634524345398
recon_loss: 0.02701873518526554, dist_loss: 0.5261744856834412
recon_loss: 0.027018699795007706, dist_loss: 0.551831066608429
recon_loss: 0.027019957080483437, dist_loss: 0.6681654453277588
recon_loss: 0.02701854519546032, dist_loss: 1.0014803409576416
recon_loss: 0.02702048234641552, dist_loss: 1.1887071132659912
recon_loss: 0.027018696069717407, dist_loss: 0.8459720611572266
recon_loss: 0.027019936591386795, dist_loss: 0.4854363799095154
recon_loss: 0.027021022513508797, dist_loss: 0.8819783329963684
Pre-training Epoch 130:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 130:   4%|▍         | 16/367 [00:00<00:02, 156.53it/s]Pre-training Epoch 130:  10%|▉         | 35/367 [00:00<00:01, 174.28it/s]Pre-training Epoch 130:  15%|█▍        | 54/367 [00:00<00:01, 180.62it/s]Pre-training Epoch 130:  20%|█▉        | 73/367 [00:00<00:01, 172.98it/s]Pre-training Epoch 130:  25%|██▌       | 93/367 [00:00<00:01, 179.08it/s]Pre-training Epoch 130:  31%|███       | 112/367 [00:00<00:01, 181.42it/s]recon_loss: 0.027024343609809875, dist_loss: 0.5367807745933533
recon_loss: 0.027024704962968826, dist_loss: 1.0473295450210571
recon_loss: 0.027027331292629242, dist_loss: 0.4311578869819641
recon_loss: 0.02702910825610161, dist_loss: 0.6845451593399048
recon_loss: 0.027030663564801216, dist_loss: 0.9990651607513428
recon_loss: 0.02703051082789898, dist_loss: 0.2621158957481384
recon_loss: 0.027029646560549736, dist_loss: 0.7419223785400391
recon_loss: 0.027029026299715042, dist_loss: 0.3728812038898468
recon_loss: 0.02702939324080944, dist_loss: 0.5648825764656067
recon_loss: 0.027030689641833305, dist_loss: 0.49286743998527527
recon_loss: 0.027029328048229218, dist_loss: 0.6422697305679321
recon_loss: 0.027030322700738907, dist_loss: 1.0406911373138428
recon_loss: 0.027028948068618774, dist_loss: 0.5312638282775879
recon_loss: 0.027029240503907204, dist_loss: 0.47440555691719055
recon_loss: 0.027027124539017677, dist_loss: 0.698090672492981
recon_loss: 0.027026735246181488, dist_loss: 0.5029650926589966
recon_loss: 0.027026932686567307, dist_loss: 0.8034651279449463
recon_loss: 0.027028100565075874, dist_loss: 0.28885701298713684
recon_loss: 0.027028242126107216, dist_loss: 0.3611229360103607
recon_loss: 0.027028126642107964, dist_loss: 0.3553360402584076
recon_loss: 0.02702898532152176, dist_loss: 0.6332826614379883
recon_loss: 0.027028236538171768, dist_loss: 0.48325106501579285
recon_loss: 0.027027791365981102, dist_loss: 0.9667391777038574
recon_loss: 0.027027994394302368, dist_loss: 0.9426602125167847
recon_loss: 0.027028854936361313, dist_loss: 0.9127515554428101
recon_loss: 0.02702832780778408, dist_loss: 0.4217090606689453
recon_loss: 0.02702678181231022, dist_loss: 0.6619536280632019
recon_loss: 0.02702503465116024, dist_loss: 0.8569636344909668
recon_loss: 0.027024205774068832, dist_loss: 0.5332649946212769
recon_loss: 0.02702477015554905, dist_loss: 0.5306064486503601
recon_loss: 0.027025947347283363, dist_loss: 0.5406378507614136
recon_loss: 0.027028730139136314, dist_loss: 0.7161076068878174
recon_loss: 0.027031343430280685, dist_loss: 0.7242053747177124
recon_loss: 0.027033761143684387, dist_loss: 0.6351274847984314
recon_loss: 0.02703465335071087, dist_loss: 0.5199064016342163
recon_loss: 0.027034416794776917, dist_loss: 0.3151589632034302
recon_loss: 0.02703320048749447, dist_loss: 0.7222063541412354
recon_loss: 0.027030963450670242, dist_loss: 0.5622107982635498
recon_loss: 0.027029892429709435, dist_loss: 0.9360125660896301
recon_loss: 0.027027634903788567, dist_loss: 0.8256902694702148
recon_loss: 0.027026548981666565, dist_loss: 0.7845510244369507
recon_loss: 0.027023492380976677, dist_loss: 0.46451336145401
recon_loss: 0.027023030444979668, dist_loss: 0.5421453714370728
recon_loss: 0.027023542672395706, dist_loss: 0.5214530825614929
recon_loss: 0.02702479250729084, dist_loss: 0.35181939601898193
recon_loss: 0.02702673338353634, dist_loss: 0.6458447575569153
recon_loss: 0.027027539908885956, dist_loss: 0.7359256744384766
recon_loss: 0.02702871896326542, dist_loss: 0.760198712348938
recon_loss: 0.02702847309410572, dist_loss: 0.656186580657959
recon_loss: 0.027027444913983345, dist_loss: 0.4404240846633911
recon_loss: 0.02702603116631508, dist_loss: 0.42037051916122437
recon_loss: 0.02702358178794384, dist_loss: 0.5230312347412109
recon_loss: 0.027021335437893867, dist_loss: 0.6845596432685852
recon_loss: 0.027019470930099487, dist_loss: 0.6433276534080505
recon_loss: 0.02701854519546032, dist_loss: 0.5974644422531128
recon_loss: 0.02701876498758793, dist_loss: 0.5878382921218872
recon_loss: 0.02701878361403942, dist_loss: 0.5599462985992432
recon_loss: 0.027019452303647995, dist_loss: 0.497749924659729
recon_loss: 0.027019361034035683, dist_loss: 0.6703411936759949
recon_loss: 0.027019912376999855, dist_loss: 0.39308983087539673
recon_loss: 0.027019182220101357, dist_loss: 0.5574259757995605
recon_loss: 0.027019033208489418, dist_loss: 0.7138303518295288
recon_loss: 0.027018284425139427, dist_loss: 0.7114548683166504
recon_loss: 0.02701737731695175, dist_loss: 0.9669301509857178
recon_loss: 0.02701648138463497, dist_loss: 0.6090291738510132
recon_loss: 0.027016429230570793, dist_loss: 0.909525454044342
recon_loss: 0.02701680175960064, dist_loss: 0.2936917245388031
recon_loss: 0.02701772004365921, dist_loss: 0.5086460113525391
recon_loss: 0.027018172666430473, dist_loss: 0.4512370228767395
recon_loss: 0.027018968015909195, dist_loss: 0.3211982250213623
recon_loss: 0.027019226923584938, dist_loss: 0.6022953987121582
recon_loss: 0.027020186185836792, dist_loss: 1.009021282196045
recon_loss: 0.02702159807085991, dist_loss: 0.5939306020736694
recon_loss: 0.027022995054721832, dist_loss: 0.44888681173324585
recon_loss: 0.027023665606975555, dist_loss: 0.46371030807495117
recon_loss: 0.027024149894714355, dist_loss: 0.44766196608543396
recon_loss: 0.027023890987038612, dist_loss: 0.6696420907974243
recon_loss: 0.02702316828072071, dist_loss: 0.39978325366973877
recon_loss: 0.027021482586860657, dist_loss: 0.3666783571243286
recon_loss: 0.027020730078220367, dist_loss: 0.7475177645683289
recon_loss: 0.027019940316677094, dist_loss: 0.774124264717102
recon_loss: 0.027020148932933807, dist_loss: 0.42868149280548096
recon_loss: 0.027020137757062912, dist_loss: 0.5566697120666504
recon_loss: 0.02702118270099163, dist_loss: 0.47907036542892456
recon_loss: 0.027022214606404305, dist_loss: 0.6907060146331787
recon_loss: 0.02702399529516697, dist_loss: 0.7012006044387817
recon_loss: 0.02702387422323227, dist_loss: 0.4469139277935028
recon_loss: 0.027024971321225166, dist_loss: 0.5168612003326416
recon_loss: 0.02702583558857441, dist_loss: 0.8016931414604187
recon_loss: 0.027026664465665817, dist_loss: 0.44779661297798157
recon_loss: 0.027025965973734856, dist_loss: 0.8416469097137451
recon_loss: 0.027025990188121796, dist_loss: 0.37998929619789124
recon_loss: 0.027026217430830002, dist_loss: 0.4970023036003113
recon_loss: 0.02702591009438038, dist_loss: 0.5440506935119629
recon_loss: 0.027025850489735603, dist_loss: 0.9159454703330994
recon_loss: 0.02702591009438038, dist_loss: 0.9669531583786011
recon_loss: 0.027027642354369164, dist_loss: 0.5959709286689758
recon_loss: 0.027027148753404617, dist_loss: 0.6116371750831604
recon_loss: 0.027028020471334457, dist_loss: 0.8681562542915344
recon_loss: 0.027026008814573288, dist_loss: 0.3301868140697479
recon_loss: 0.027026653289794922, dist_loss: 0.39302510023117065
recon_loss: 0.027024410665035248, dist_loss: 0.7216252684593201
recon_loss: 0.02702447958290577, dist_loss: 0.6520366072654724
recon_loss: 0.027023019269108772, dist_loss: 0.5821837186813354
recon_loss: 0.027023369446396828, dist_loss: 0.52275550365448
recon_loss: 0.027022071182727814, dist_loss: 0.6419968008995056
recon_loss: 0.027022570371627808, dist_loss: 0.5928778052330017
recon_loss: 0.027022162452340126, dist_loss: 0.3427782952785492
recon_loss: 0.027023185044527054, dist_loss: 0.6665089130401611
recon_loss: 0.027022283524274826, dist_loss: 0.4935060441493988
recon_loss: 0.027023471891880035, dist_loss: 0.8994935750961304
recon_loss: 0.027022982016205788, dist_loss: 0.43005242943763733
recon_loss: 0.027023306116461754, dist_loss: 0.48637306690216064
recon_loss: 0.02702387422323227, dist_loss: 0.230763241648674
recon_loss: 0.02702336572110653, dist_loss: 0.3689366579055786
recon_loss: 0.02702275477349758, dist_loss: 0.2837289571762085
recon_loss: 0.02702293172478676, dist_loss: 0.8533328175544739
recon_loss: 0.027022600173950195, dist_loss: 0.5890785455703735
recon_loss: 0.0270218662917614, dist_loss: 0.6428148746490479
recon_loss: 0.027020689100027084, dist_loss: 0.963254451751709
recon_loss: 0.027020061388611794, dist_loss: 1.005723237991333
recon_loss: 0.02702062390744686, dist_loss: 0.8448494672775269
recon_loss: 0.027021123096346855, dist_loss: 0.5771681070327759
recon_loss: 0.027021635323762894, dist_loss: 0.6621996760368347
recon_loss: 0.027020946145057678, dist_loss: 0.5980464816093445
recon_loss: 0.027021193876862526, dist_loss: 0.7208222150802612
recon_loss: 0.02702050283551216, dist_loss: 0.4862944483757019
recon_loss: 0.027020545676350594, dist_loss: 0.6545301675796509
Pre-training Epoch 130:  36%|███▌      | 131/367 [00:00<00:01, 177.39it/s]Pre-training Epoch 130:  41%|████      | 149/367 [00:00<00:01, 173.36it/s]Pre-training Epoch 130:  46%|████▌     | 167/367 [00:00<00:01, 169.82it/s]Pre-training Epoch 130:  50%|█████     | 185/367 [00:01<00:01, 168.07it/s]Pre-training Epoch 130:  55%|█████▌    | 202/367 [00:01<00:00, 166.27it/s]Pre-training Epoch 130:  60%|█████▉    | 219/367 [00:01<00:00, 165.84it/s]Pre-training Epoch 130:  64%|██████▍   | 236/367 [00:01<00:00, 162.51it/s]Pre-training Epoch 130:  69%|██████▉   | 253/367 [00:01<00:00, 162.84it/s]recon_loss: 0.02702026255428791, dist_loss: 0.30381250381469727
recon_loss: 0.027020074427127838, dist_loss: 0.36068886518478394
recon_loss: 0.027020566165447235, dist_loss: 0.6419274806976318
recon_loss: 0.027020461857318878, dist_loss: 0.280224084854126
recon_loss: 0.027020437642931938, dist_loss: 0.3413037061691284
recon_loss: 0.02702035941183567, dist_loss: 0.7024866342544556
recon_loss: 0.027020646259188652, dist_loss: 0.7756162881851196
recon_loss: 0.0270206518471241, dist_loss: 0.6229906678199768
recon_loss: 0.027019893750548363, dist_loss: 0.510578989982605
recon_loss: 0.027019085362553596, dist_loss: 1.0989636182785034
recon_loss: 0.027018269523978233, dist_loss: 0.5770175457000732
recon_loss: 0.027017617598176003, dist_loss: 0.4780171513557434
recon_loss: 0.02701738104224205, dist_loss: 0.5936874151229858
recon_loss: 0.027018019929528236, dist_loss: 0.7401979565620422
recon_loss: 0.02701905183494091, dist_loss: 0.42913806438446045
recon_loss: 0.02702062390744686, dist_loss: 0.4725430905818939
recon_loss: 0.02702062949538231, dist_loss: 0.37971097230911255
recon_loss: 0.02702084742486477, dist_loss: 0.639630138874054
recon_loss: 0.027020497247576714, dist_loss: 0.7737141847610474
recon_loss: 0.02702118642628193, dist_loss: 0.5227081775665283
recon_loss: 0.027020178735256195, dist_loss: 0.7789613008499146
recon_loss: 0.027021324262022972, dist_loss: 0.8079203963279724
recon_loss: 0.02702014520764351, dist_loss: 0.9084118008613586
recon_loss: 0.02702031284570694, dist_loss: 0.8489830493927002
recon_loss: 0.027019569650292397, dist_loss: 0.4003763496875763
recon_loss: 0.02702004835009575, dist_loss: 0.4062560796737671
recon_loss: 0.02701910398900509, dist_loss: 0.5978396534919739
recon_loss: 0.027019530534744263, dist_loss: 0.31420648097991943
recon_loss: 0.027018891647458076, dist_loss: 0.7036484479904175
recon_loss: 0.027020437642931938, dist_loss: 0.849449872970581
recon_loss: 0.027018221095204353, dist_loss: 0.7047713994979858
recon_loss: 0.027019480243325233, dist_loss: 0.6484363675117493
recon_loss: 0.027017347514629364, dist_loss: 0.5074474215507507
recon_loss: 0.027018874883651733, dist_loss: 0.434613436460495
recon_loss: 0.02701757848262787, dist_loss: 0.8147232532501221
recon_loss: 0.027019206434488297, dist_loss: 0.566397488117218
recon_loss: 0.027018679305911064, dist_loss: 0.6805024147033691
recon_loss: 0.0270218662917614, dist_loss: 0.7865578532218933
recon_loss: 0.027020705863833427, dist_loss: 0.8985805511474609
recon_loss: 0.027022283524274826, dist_loss: 0.8219207525253296
recon_loss: 0.027022099122405052, dist_loss: 0.36355409026145935
recon_loss: 0.02702183835208416, dist_loss: 0.3088764548301697
recon_loss: 0.027021203190088272, dist_loss: 0.4259963631629944
recon_loss: 0.027020610868930817, dist_loss: 0.8178069591522217
recon_loss: 0.027020296081900597, dist_loss: 0.5007830858230591
recon_loss: 0.027019057422876358, dist_loss: 0.4730634093284607
recon_loss: 0.027019139379262924, dist_loss: 1.1557536125183105
recon_loss: 0.02701866254210472, dist_loss: 1.320801019668579
recon_loss: 0.027019964531064034, dist_loss: 0.7837456464767456
recon_loss: 0.027020109817385674, dist_loss: 0.6347208023071289
recon_loss: 0.02702120877802372, dist_loss: 1.2900723218917847
recon_loss: 0.027021657675504684, dist_loss: 0.36391422152519226
recon_loss: 0.02702341042459011, dist_loss: 0.5182725787162781
recon_loss: 0.02702568657696247, dist_loss: 0.9551805853843689
recon_loss: 0.02702738158404827, dist_loss: 0.8581143617630005
recon_loss: 0.027029208838939667, dist_loss: 0.5431880950927734
recon_loss: 0.027031784877181053, dist_loss: 0.4432860016822815
recon_loss: 0.02703278325498104, dist_loss: 0.8198196291923523
recon_loss: 0.02703327313065529, dist_loss: 0.620675265789032
recon_loss: 0.027032990008592606, dist_loss: 0.36668646335601807
recon_loss: 0.027031252160668373, dist_loss: 0.48880255222320557
recon_loss: 0.027030350640416145, dist_loss: 0.6909584999084473
recon_loss: 0.0270274356007576, dist_loss: 0.6352360248565674
recon_loss: 0.02702617458999157, dist_loss: 0.4297654628753662
recon_loss: 0.027023306116461754, dist_loss: 0.5095641613006592
recon_loss: 0.02702038362622261, dist_loss: 1.1689555644989014
recon_loss: 0.027019144967198372, dist_loss: 0.6967051029205322
recon_loss: 0.027018552646040916, dist_loss: 0.51518315076828
recon_loss: 0.027018623426556587, dist_loss: 0.5265681743621826
recon_loss: 0.027019089087843895, dist_loss: 0.6573335528373718
recon_loss: 0.02702016942203045, dist_loss: 0.37929242849349976
recon_loss: 0.027021368965506554, dist_loss: 0.7383224964141846
recon_loss: 0.027023447677493095, dist_loss: 0.5394058227539062
recon_loss: 0.02702459879219532, dist_loss: 0.7872774600982666
recon_loss: 0.02702505514025688, dist_loss: 0.6008768081665039
recon_loss: 0.027026372030377388, dist_loss: 0.533217191696167
recon_loss: 0.027025490999221802, dist_loss: 0.43026474118232727
recon_loss: 0.027025170624256134, dist_loss: 0.9341287612915039
recon_loss: 0.027025872841477394, dist_loss: 0.3748948574066162
recon_loss: 0.027024932205677032, dist_loss: 0.708217978477478
recon_loss: 0.027022454887628555, dist_loss: 0.6492767930030823
recon_loss: 0.027020195499062538, dist_loss: 0.8336131572723389
recon_loss: 0.027018355205655098, dist_loss: 0.6672613024711609
recon_loss: 0.027017490938305855, dist_loss: 0.6320094466209412
recon_loss: 0.027016673237085342, dist_loss: 0.4853372871875763
recon_loss: 0.02701740898191929, dist_loss: 0.653516411781311
recon_loss: 0.027017276734113693, dist_loss: 0.633224368095398
recon_loss: 0.027018461376428604, dist_loss: 0.46304357051849365
recon_loss: 0.027019435539841652, dist_loss: 0.5658332109451294
recon_loss: 0.027019621804356575, dist_loss: 0.5631640553474426
recon_loss: 0.027020512148737907, dist_loss: 0.7433367371559143
recon_loss: 0.027021238580346107, dist_loss: 0.48721033334732056
recon_loss: 0.02702135592699051, dist_loss: 0.43678051233291626
recon_loss: 0.027021121233701706, dist_loss: 0.9550855755805969
recon_loss: 0.027019789442420006, dist_loss: 0.516387939453125
recon_loss: 0.027018316090106964, dist_loss: 0.8141456842422485
recon_loss: 0.0270168948918581, dist_loss: 0.6454585790634155
recon_loss: 0.027015987783670425, dist_loss: 0.5334131121635437
recon_loss: 0.027015572413802147, dist_loss: 0.43718284368515015
recon_loss: 0.02701553888618946, dist_loss: 0.6685670018196106
recon_loss: 0.02701512724161148, dist_loss: 0.9700533151626587
recon_loss: 0.027015168219804764, dist_loss: 0.362484335899353
recon_loss: 0.02701522223651409, dist_loss: 0.40925610065460205
recon_loss: 0.027015242725610733, dist_loss: 0.4412446618080139
recon_loss: 0.027014682069420815, dist_loss: 0.41699808835983276
recon_loss: 0.02701435424387455, dist_loss: 0.3852660655975342
recon_loss: 0.027014434337615967, dist_loss: 0.40945756435394287
recon_loss: 0.02701478824019432, dist_loss: 0.8410475254058838
recon_loss: 0.02701500616967678, dist_loss: 0.4765220284461975
recon_loss: 0.027014879509806633, dist_loss: 0.3751331865787506
recon_loss: 0.02701558545231819, dist_loss: 1.2382651567459106
recon_loss: 0.027015291154384613, dist_loss: 0.355094313621521
recon_loss: 0.02701527625322342, dist_loss: 0.5288370847702026
recon_loss: 0.027014901861548424, dist_loss: 0.7512714266777039
recon_loss: 0.02701515145599842, dist_loss: 0.9231098890304565
recon_loss: 0.02701476775109768, dist_loss: 0.8606084585189819
recon_loss: 0.027014615014195442, dist_loss: 0.9976109266281128
recon_loss: 0.027014410123229027, dist_loss: 0.38327354192733765
recon_loss: 0.02701462432742119, dist_loss: 0.5408869385719299
recon_loss: 0.027015067636966705, dist_loss: 0.8356059789657593
recon_loss: 0.02701578475534916, dist_loss: 0.48543840646743774
recon_loss: 0.02701650559902191, dist_loss: 0.49792617559432983
recon_loss: 0.02701737731695175, dist_loss: 1.1622116565704346
recon_loss: 0.027019118890166283, dist_loss: 0.5450863838195801
recon_loss: 0.027019621804356575, dist_loss: 0.5043436288833618
recon_loss: 0.027020134031772614, dist_loss: 1.0066795349121094
recon_loss: 0.027020564302802086, dist_loss: 0.6279377341270447
recon_loss: 0.027020391076803207, dist_loss: 0.47965294122695923
Pre-training Epoch 130:  74%|███████▎  | 270/367 [00:01<00:00, 163.04it/s]Pre-training Epoch 130:  78%|███████▊  | 287/367 [00:01<00:00, 161.66it/s]Pre-training Epoch 130:  83%|████████▎ | 304/367 [00:01<00:00, 161.86it/s]Pre-training Epoch 130:  87%|████████▋ | 321/367 [00:01<00:00, 162.03it/s]Pre-training Epoch 130:  92%|█████████▏| 338/367 [00:02<00:00, 161.78it/s]Pre-training Epoch 130:  97%|█████████▋| 355/367 [00:02<00:00, 161.61it/s]Pre-training Epoch 130: 100%|██████████| 367/367 [00:02<00:00, 166.20it/s]
recon_loss: 0.027020422741770744, dist_loss: 0.529898464679718
recon_loss: 0.02702021226286888, dist_loss: 0.5962550044059753
recon_loss: 0.027019811794161797, dist_loss: 0.29624778032302856
recon_loss: 0.027019459754228592, dist_loss: 0.9290655255317688
recon_loss: 0.02701907604932785, dist_loss: 0.930595874786377
recon_loss: 0.027018750086426735, dist_loss: 0.803364634513855
recon_loss: 0.027018310502171516, dist_loss: 1.0511270761489868
recon_loss: 0.02701779454946518, dist_loss: 0.6094722747802734
recon_loss: 0.027017677202820778, dist_loss: 0.5409356951713562
recon_loss: 0.027017898857593536, dist_loss: 0.9223220348358154
recon_loss: 0.027019314467906952, dist_loss: 0.7283393144607544
recon_loss: 0.02701997570693493, dist_loss: 0.28891605138778687
recon_loss: 0.02702239900827408, dist_loss: 0.6822885870933533
recon_loss: 0.02702310122549534, dist_loss: 0.4291093945503235
recon_loss: 0.027023985981941223, dist_loss: 0.5446751713752747
recon_loss: 0.027025850489735603, dist_loss: 1.1583863496780396
recon_loss: 0.027024943381547928, dist_loss: 0.34137192368507385
recon_loss: 0.027024703100323677, dist_loss: 0.5012426972389221
recon_loss: 0.02702309377491474, dist_loss: 0.6010692119598389
recon_loss: 0.027022598311305046, dist_loss: 0.5893449783325195
recon_loss: 0.027021635323762894, dist_loss: 0.4087207317352295
recon_loss: 0.027021626010537148, dist_loss: 0.6511431932449341
recon_loss: 0.027019714936614037, dist_loss: 0.5883452892303467
recon_loss: 0.027019191533327103, dist_loss: 0.4503576159477234
recon_loss: 0.027018683031201363, dist_loss: 0.5985464453697205
recon_loss: 0.027019845321774483, dist_loss: 0.6236815452575684
recon_loss: 0.027019454166293144, dist_loss: 0.5112446546554565
recon_loss: 0.02701992727816105, dist_loss: 0.3683450222015381
recon_loss: 0.027018271386623383, dist_loss: 0.5854810476303101
recon_loss: 0.027017313987016678, dist_loss: 0.4019278287887573
recon_loss: 0.02701549045741558, dist_loss: 0.7000306844711304
recon_loss: 0.02701513282954693, dist_loss: 0.46492519974708557
recon_loss: 0.02701476588845253, dist_loss: 0.5349531173706055
recon_loss: 0.027014952152967453, dist_loss: 0.6966036558151245
recon_loss: 0.02701459638774395, dist_loss: 0.7867540121078491
recon_loss: 0.02701732888817787, dist_loss: 0.42782843112945557
recon_loss: 0.02701920084655285, dist_loss: 0.6306969523429871
recon_loss: 0.027021506801247597, dist_loss: 0.6794710755348206
recon_loss: 0.027021022513508797, dist_loss: 0.963719367980957
recon_loss: 0.027020834386348724, dist_loss: 0.6862430572509766
recon_loss: 0.027020804584026337, dist_loss: 0.7168362140655518
recon_loss: 0.02701994962990284, dist_loss: 0.33782076835632324
recon_loss: 0.027018722146749496, dist_loss: 0.585014820098877
recon_loss: 0.027018239721655846, dist_loss: 0.5203413367271423
recon_loss: 0.027017544955015182, dist_loss: 0.7911702394485474
recon_loss: 0.02701736055314541, dist_loss: 0.519324541091919
recon_loss: 0.02701766975224018, dist_loss: 0.9741689562797546
recon_loss: 0.02701851725578308, dist_loss: 0.49740898609161377
recon_loss: 0.027019718661904335, dist_loss: 0.6853115558624268
recon_loss: 0.027020692825317383, dist_loss: 0.5193989872932434
recon_loss: 0.027022138237953186, dist_loss: 0.3402010202407837
recon_loss: 0.027023129165172577, dist_loss: 0.8778573274612427
recon_loss: 0.027024146169424057, dist_loss: 0.5640265941619873
recon_loss: 0.027024395763874054, dist_loss: 0.4713350236415863
recon_loss: 0.027023619040846825, dist_loss: 0.8279133439064026
recon_loss: 0.027022048830986023, dist_loss: 0.5639135241508484
recon_loss: 0.027020450681447983, dist_loss: 0.7513895034790039
recon_loss: 0.02701825089752674, dist_loss: 0.48536378145217896
recon_loss: 0.027017096057534218, dist_loss: 0.6918505430221558
recon_loss: 0.027015462517738342, dist_loss: 1.1494019031524658
recon_loss: 0.02701527811586857, dist_loss: 0.5099354982376099
recon_loss: 0.027016233652830124, dist_loss: 0.5777164697647095
recon_loss: 0.027017341926693916, dist_loss: 0.7522685527801514
recon_loss: 0.02701794169843197, dist_loss: 0.3957589864730835
recon_loss: 0.027018612250685692, dist_loss: 0.32313472032546997
recon_loss: 0.027019556611776352, dist_loss: 0.5431763529777527
recon_loss: 0.02701973356306553, dist_loss: 0.6424119472503662
recon_loss: 0.02702004835009575, dist_loss: 0.635890781879425
recon_loss: 0.027019912376999855, dist_loss: 0.5647112727165222
recon_loss: 0.02701924741268158, dist_loss: 0.6340282559394836
recon_loss: 0.02701781503856182, dist_loss: 0.5650804042816162
recon_loss: 0.027016840875148773, dist_loss: 0.5484298467636108
recon_loss: 0.02701564133167267, dist_loss: 0.44860297441482544
recon_loss: 0.027014633640646935, dist_loss: 0.5475974082946777
recon_loss: 0.027015740051865578, dist_loss: 0.5095243453979492
recon_loss: 0.027018794789910316, dist_loss: 0.5297204256057739
recon_loss: 0.02702203579246998, dist_loss: 1.097179651260376
recon_loss: 0.027026545256376266, dist_loss: 0.899061918258667
recon_loss: 0.02703050896525383, dist_loss: 0.8972454071044922
recon_loss: 0.027034010738134384, dist_loss: 0.6611654758453369
recon_loss: 0.027031896635890007, dist_loss: 0.3718072772026062
recon_loss: 0.02702902816236019, dist_loss: 0.7654541730880737
recon_loss: 0.027025887742638588, dist_loss: 0.6368480324745178
recon_loss: 0.02702394686639309, dist_loss: 0.4693422317504883
recon_loss: 0.027022257447242737, dist_loss: 0.9014942646026611
recon_loss: 0.02702123485505581, dist_loss: 0.33727216720581055
recon_loss: 0.027019862085580826, dist_loss: 0.35334742069244385
recon_loss: 0.027019314467906952, dist_loss: 0.7697924375534058
recon_loss: 0.027018873021006584, dist_loss: 0.8678497076034546
recon_loss: 0.027019077911973, dist_loss: 0.5883032083511353
recon_loss: 0.027019763365387917, dist_loss: 0.47498205304145813
recon_loss: 0.027020227164030075, dist_loss: 0.4054439663887024
recon_loss: 0.027020709589123726, dist_loss: 0.7671831250190735
recon_loss: 0.027021830901503563, dist_loss: 0.5477643609046936
recon_loss: 0.02702268213033676, dist_loss: 0.3540762960910797
recon_loss: 0.02702365629374981, dist_loss: 0.4894188940525055
recon_loss: 0.027022074908018112, dist_loss: 0.5475510358810425
recon_loss: 0.027021875604987144, dist_loss: 0.7066466808319092
recon_loss: 0.027019914239645004, dist_loss: 0.4252396523952484
recon_loss: 0.027019573375582695, dist_loss: 0.7637791037559509
recon_loss: 0.027018209919333458, dist_loss: 1.0128353834152222
recon_loss: 0.027017775923013687, dist_loss: 0.5964862108230591
recon_loss: 0.02701686881482601, dist_loss: 0.34391194581985474
recon_loss: 0.02701728232204914, dist_loss: 0.3510211706161499
recon_loss: 0.02701805904507637, dist_loss: 0.637726902961731
recon_loss: 0.027018344029784203, dist_loss: 0.5631681680679321
recon_loss: 0.02701907604932785, dist_loss: 0.9252772331237793
recon_loss: 0.027018975466489792, dist_loss: 0.8038221001625061
recon_loss: 0.027019230648875237, dist_loss: 0.5423588752746582
recon_loss: 0.02701987698674202, dist_loss: 0.48897311091423035
recon_loss: 0.027019592002034187, dist_loss: 0.6875523924827576
Pre-train Epoch: 130
Train - Total Loss: 0.0889, Recon Loss: 0.0270, Dist Loss: 0.6190, l1 regularization: 0.0000
Val - Total Loss: 0.0932, Recon Loss: 0.0270, Dist Loss: 0.6616, l1 regularization: 0.0000
Pre-training Epoch 131:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 131:   4%|▍         | 16/367 [00:00<00:02, 154.73it/s]Pre-training Epoch 131:   9%|▊         | 32/367 [00:00<00:02, 147.95it/s]Pre-training Epoch 131:  13%|█▎        | 47/367 [00:00<00:02, 146.95it/s]Pre-training Epoch 131:  17%|█▋        | 62/367 [00:00<00:02, 145.69it/s]Pre-training Epoch 131:  22%|██▏       | 79/367 [00:00<00:01, 151.14it/s]Pre-training Epoch 131:  26%|██▌       | 96/367 [00:00<00:01, 155.65it/s]Pre-training Epoch 131:  31%|███       | 113/367 [00:00<00:01, 158.44it/s]recon_loss: 0.027018200606107712, dist_loss: 0.6238902807235718
recon_loss: 0.027016906067728996, dist_loss: 0.7415621280670166
recon_loss: 0.027015818282961845, dist_loss: 0.4506258964538574
recon_loss: 0.027014974504709244, dist_loss: 0.8834962844848633
recon_loss: 0.027014441788196564, dist_loss: 0.8958426117897034
recon_loss: 0.027013789862394333, dist_loss: 0.5097072720527649
recon_loss: 0.027013735845685005, dist_loss: 0.5537227988243103
recon_loss: 0.027013778686523438, dist_loss: 0.49071645736694336
recon_loss: 0.027014421299099922, dist_loss: 0.7608839273452759
recon_loss: 0.027014657855033875, dist_loss: 0.37298107147216797
recon_loss: 0.027015434578061104, dist_loss: 0.5809963941574097
recon_loss: 0.02701704204082489, dist_loss: 0.7276408076286316
recon_loss: 0.02701822854578495, dist_loss: 0.8569416999816895
recon_loss: 0.027019064873456955, dist_loss: 0.4769049286842346
recon_loss: 0.027019834145903587, dist_loss: 0.5208715200424194
recon_loss: 0.027020271867513657, dist_loss: 0.8042796850204468
recon_loss: 0.027021287009119987, dist_loss: 0.6163134574890137
recon_loss: 0.027021439746022224, dist_loss: 0.8074992895126343
recon_loss: 0.027020541951060295, dist_loss: 0.49031808972358704
recon_loss: 0.027018969878554344, dist_loss: 0.7620145678520203
recon_loss: 0.02701750211417675, dist_loss: 0.427546888589859
recon_loss: 0.02701638452708721, dist_loss: 0.5720253586769104
recon_loss: 0.02701425366103649, dist_loss: 0.9569602012634277
recon_loss: 0.027012899518013, dist_loss: 0.3685058355331421
recon_loss: 0.027012020349502563, dist_loss: 0.5493296384811401
recon_loss: 0.027011478319764137, dist_loss: 0.5978727340698242
recon_loss: 0.027010755613446236, dist_loss: 0.317268967628479
recon_loss: 0.027010172605514526, dist_loss: 1.0762343406677246
recon_loss: 0.027010463178157806, dist_loss: 0.3587604761123657
recon_loss: 0.027011005207896233, dist_loss: 0.5723482370376587
recon_loss: 0.027012405917048454, dist_loss: 0.5926165580749512
recon_loss: 0.027013838291168213, dist_loss: 0.5090497732162476
recon_loss: 0.027013421058654785, dist_loss: 0.4041139483451843
recon_loss: 0.027011675760149956, dist_loss: 0.5396374464035034
recon_loss: 0.027010232210159302, dist_loss: 0.4742527902126312
recon_loss: 0.027009323239326477, dist_loss: 0.5457466840744019
recon_loss: 0.02700943686068058, dist_loss: 0.743041455745697
recon_loss: 0.027009671553969383, dist_loss: 0.6384073495864868
recon_loss: 0.027010373771190643, dist_loss: 0.4222438633441925
recon_loss: 0.027011413127183914, dist_loss: 0.6211452484130859
recon_loss: 0.02701272815465927, dist_loss: 0.471733033657074
recon_loss: 0.027012957260012627, dist_loss: 0.8003188967704773
recon_loss: 0.027012374252080917, dist_loss: 0.8129104375839233
recon_loss: 0.027010533958673477, dist_loss: 0.569883406162262
recon_loss: 0.02700952999293804, dist_loss: 0.5540494918823242
recon_loss: 0.02700858563184738, dist_loss: 0.5419144630432129
recon_loss: 0.027007946744561195, dist_loss: 0.42933303117752075
recon_loss: 0.027007993310689926, dist_loss: 0.7458457946777344
recon_loss: 0.027008334174752235, dist_loss: 0.48456263542175293
recon_loss: 0.02700795978307724, dist_loss: 0.7774713039398193
recon_loss: 0.027008134871721268, dist_loss: 0.3822232782840729
recon_loss: 0.027007950469851494, dist_loss: 0.41214242577552795
recon_loss: 0.027007857337594032, dist_loss: 0.5275494456291199
recon_loss: 0.02700737677514553, dist_loss: 0.32342562079429626
recon_loss: 0.02700660191476345, dist_loss: 0.9095034599304199
recon_loss: 0.02700640819966793, dist_loss: 0.5422073602676392
recon_loss: 0.02700606919825077, dist_loss: 1.1226314306259155
recon_loss: 0.027006136253476143, dist_loss: 0.844319760799408
recon_loss: 0.02700628899037838, dist_loss: 0.39383983612060547
recon_loss: 0.02700665220618248, dist_loss: 0.7678529024124146
recon_loss: 0.027006754651665688, dist_loss: 0.46192049980163574
recon_loss: 0.027006614953279495, dist_loss: 0.6354022026062012
recon_loss: 0.027006059885025024, dist_loss: 0.8096722364425659
recon_loss: 0.027005888521671295, dist_loss: 0.5645068287849426
recon_loss: 0.027005635201931, dist_loss: 0.6960321664810181
recon_loss: 0.0270053930580616, dist_loss: 0.5938279032707214
recon_loss: 0.02700488641858101, dist_loss: 0.37268146872520447
recon_loss: 0.027004806324839592, dist_loss: 0.9822995066642761
recon_loss: 0.027004826813936234, dist_loss: 0.5066864490509033
recon_loss: 0.02700469270348549, dist_loss: 0.6897296905517578
recon_loss: 0.027004951611161232, dist_loss: 0.5093928575515747
recon_loss: 0.0270049087703228, dist_loss: 0.8517695665359497
recon_loss: 0.027004767209291458, dist_loss: 0.4477003812789917
recon_loss: 0.027004564180970192, dist_loss: 0.598373293876648
recon_loss: 0.027004435658454895, dist_loss: 0.9626356959342957
recon_loss: 0.027004195377230644, dist_loss: 0.42209887504577637
recon_loss: 0.027005299925804138, dist_loss: 0.38604509830474854
recon_loss: 0.02700716070830822, dist_loss: 0.3932276666164398
recon_loss: 0.02700907550752163, dist_loss: 0.8252443075180054
recon_loss: 0.027010804042220116, dist_loss: 0.6857933402061462
recon_loss: 0.027011463418602943, dist_loss: 0.44493308663368225
recon_loss: 0.027011273428797722, dist_loss: 0.5675501823425293
recon_loss: 0.027010953053832054, dist_loss: 0.468889445066452
recon_loss: 0.027010124176740646, dist_loss: 0.4248916208744049
recon_loss: 0.02700923942029476, dist_loss: 0.4935920536518097
recon_loss: 0.02700779214501381, dist_loss: 0.7561126947402954
recon_loss: 0.027006717398762703, dist_loss: 0.884648323059082
recon_loss: 0.027005966752767563, dist_loss: 0.5966246128082275
recon_loss: 0.027006426826119423, dist_loss: 0.7356796264648438
recon_loss: 0.027005843818187714, dist_loss: 1.151593804359436
recon_loss: 0.02700645476579666, dist_loss: 0.5416691303253174
recon_loss: 0.027006864547729492, dist_loss: 0.9651398658752441
recon_loss: 0.02700795978307724, dist_loss: 0.7781869173049927
recon_loss: 0.027009114623069763, dist_loss: 0.3816688656806946
recon_loss: 0.027008693665266037, dist_loss: 0.4377145767211914
recon_loss: 0.027008341625332832, dist_loss: 0.8300484418869019
recon_loss: 0.027008559554815292, dist_loss: 0.44960078597068787
recon_loss: 0.02700844034552574, dist_loss: 0.7422046661376953
recon_loss: 0.027008317410945892, dist_loss: 0.34622064232826233
recon_loss: 0.027007954195141792, dist_loss: 0.3345724642276764
recon_loss: 0.027007682248950005, dist_loss: 0.39410674571990967
recon_loss: 0.027007417753338814, dist_loss: 0.5637069344520569
recon_loss: 0.02700773812830448, dist_loss: 0.24359142780303955
recon_loss: 0.027007680386304855, dist_loss: 0.4125303626060486
recon_loss: 0.027007780969142914, dist_loss: 0.38876408338546753
recon_loss: 0.027007846161723137, dist_loss: 0.5379295945167542
recon_loss: 0.027007320895791054, dist_loss: 0.31157296895980835
recon_loss: 0.027006719261407852, dist_loss: 1.0418381690979004
recon_loss: 0.027005363255739212, dist_loss: 0.45122843980789185
recon_loss: 0.02700483426451683, dist_loss: 0.4797157645225525
recon_loss: 0.027004076167941093, dist_loss: 1.2429656982421875
recon_loss: 0.027004890143871307, dist_loss: 0.9070667028427124
recon_loss: 0.027006058022379875, dist_loss: 0.4758700728416443
recon_loss: 0.027005963027477264, dist_loss: 0.502314567565918
recon_loss: 0.027005091309547424, dist_loss: 0.5438327789306641
recon_loss: 0.027004146948456764, dist_loss: 0.4658859670162201
recon_loss: 0.027003789320588112, dist_loss: 0.5655351877212524
recon_loss: 0.02700398676097393, dist_loss: 0.3657799959182739
recon_loss: 0.02700522169470787, dist_loss: 0.5354272723197937
recon_loss: 0.027007779106497765, dist_loss: 0.7854125499725342
recon_loss: 0.027010243386030197, dist_loss: 0.5277674198150635
recon_loss: 0.02701219916343689, dist_loss: 0.7538865804672241
recon_loss: 0.027013327926397324, dist_loss: 0.5171704292297363
recon_loss: 0.027013279497623444, dist_loss: 0.5905767679214478
recon_loss: 0.02701200731098652, dist_loss: 0.4502710700035095
recon_loss: 0.027010995894670486, dist_loss: 0.5118050575256348
recon_loss: 0.027010390534996986, dist_loss: 0.7352507710456848
recon_loss: 0.027010593563318253, dist_loss: 0.36736056208610535
Pre-training Epoch 131:  35%|███▌      | 130/367 [00:00<00:01, 159.13it/s]Pre-training Epoch 131:  40%|████      | 147/367 [00:00<00:01, 159.90it/s]Pre-training Epoch 131:  45%|████▍     | 164/367 [00:01<00:01, 160.11it/s]Pre-training Epoch 131:  49%|████▉     | 181/367 [00:01<00:01, 159.97it/s]Pre-training Epoch 131:  54%|█████▎    | 197/367 [00:01<00:01, 157.69it/s]Pre-training Epoch 131:  58%|█████▊    | 213/367 [00:01<00:00, 156.49it/s]Pre-training Epoch 131:  62%|██████▏   | 229/367 [00:01<00:00, 152.25it/s]Pre-training Epoch 131:  67%|██████▋   | 245/367 [00:01<00:00, 152.65it/s]recon_loss: 0.02701123058795929, dist_loss: 0.8872324824333191
recon_loss: 0.027012459933757782, dist_loss: 0.37377700209617615
recon_loss: 0.02701335959136486, dist_loss: 0.8043603301048279
recon_loss: 0.0270143561065197, dist_loss: 0.3454955220222473
recon_loss: 0.02701464667916298, dist_loss: 0.5011138916015625
recon_loss: 0.027014993131160736, dist_loss: 0.42978495359420776
recon_loss: 0.027016039937734604, dist_loss: 0.9174135327339172
recon_loss: 0.027015168219804764, dist_loss: 0.3304770290851593
recon_loss: 0.02701510302722454, dist_loss: 0.9147630929946899
recon_loss: 0.027015402913093567, dist_loss: 1.0327174663543701
recon_loss: 0.027014562860131264, dist_loss: 0.41811680793762207
recon_loss: 0.027012571692466736, dist_loss: 0.24867278337478638
recon_loss: 0.027011064812541008, dist_loss: 0.49345263838768005
recon_loss: 0.027010062709450722, dist_loss: 0.5553315281867981
recon_loss: 0.027010127902030945, dist_loss: 0.8975760340690613
recon_loss: 0.02701009064912796, dist_loss: 0.39216721057891846
recon_loss: 0.027011346071958542, dist_loss: 0.23840710520744324
recon_loss: 0.027012763544917107, dist_loss: 0.7193382978439331
recon_loss: 0.027014533057808876, dist_loss: 0.8046784996986389
recon_loss: 0.027014989405870438, dist_loss: 0.6525681018829346
recon_loss: 0.02701558917760849, dist_loss: 0.45726847648620605
recon_loss: 0.027014650404453278, dist_loss: 0.8540976047515869
recon_loss: 0.027013715356588364, dist_loss: 0.4333750009536743
recon_loss: 0.027013525366783142, dist_loss: 0.7537169456481934
recon_loss: 0.02701343409717083, dist_loss: 0.7458775043487549
recon_loss: 0.027012266218662262, dist_loss: 0.6886307597160339
recon_loss: 0.027011020109057426, dist_loss: 0.27991682291030884
recon_loss: 0.02701050043106079, dist_loss: 1.0649127960205078
recon_loss: 0.02701016329228878, dist_loss: 0.7642993927001953
recon_loss: 0.027010761201381683, dist_loss: 0.43246009945869446
recon_loss: 0.02701093815267086, dist_loss: 0.5528011322021484
recon_loss: 0.027012275531888008, dist_loss: 0.37739884853363037
recon_loss: 0.027013514190912247, dist_loss: 0.5904194712638855
recon_loss: 0.02701471373438835, dist_loss: 0.49553805589675903
recon_loss: 0.027016086503863335, dist_loss: 0.37747952342033386
recon_loss: 0.027017708867788315, dist_loss: 0.4810904562473297
recon_loss: 0.02701828069984913, dist_loss: 1.1148533821105957
recon_loss: 0.02701866254210472, dist_loss: 0.5844253897666931
recon_loss: 0.02701902575790882, dist_loss: 0.7772247195243835
recon_loss: 0.027019495144486427, dist_loss: 0.41014716029167175
recon_loss: 0.02701953612267971, dist_loss: 0.5141922235488892
recon_loss: 0.02701757475733757, dist_loss: 0.6229949593544006
recon_loss: 0.0270150788128376, dist_loss: 0.5915427803993225
recon_loss: 0.027013231068849564, dist_loss: 0.6858634948730469
recon_loss: 0.027012472972273827, dist_loss: 0.5784285068511963
recon_loss: 0.02701234631240368, dist_loss: 0.6284030675888062
recon_loss: 0.027012735605239868, dist_loss: 0.5576016306877136
recon_loss: 0.027014106512069702, dist_loss: 0.771806001663208
recon_loss: 0.027016887441277504, dist_loss: 0.6002039909362793
recon_loss: 0.027020500972867012, dist_loss: 0.5704719424247742
recon_loss: 0.02702302671968937, dist_loss: 0.8941028714179993
recon_loss: 0.027025070041418076, dist_loss: 0.4088325798511505
recon_loss: 0.027027109637856483, dist_loss: 0.2364065945148468
recon_loss: 0.027027780190110207, dist_loss: 0.78188556432724
recon_loss: 0.027025334537029266, dist_loss: 0.4918096959590912
recon_loss: 0.0270236749202013, dist_loss: 0.6826944351196289
recon_loss: 0.02702123112976551, dist_loss: 0.9962610006332397
recon_loss: 0.027017589658498764, dist_loss: 1.2025349140167236
recon_loss: 0.027014359831809998, dist_loss: 0.5251481533050537
recon_loss: 0.027012363076210022, dist_loss: 0.7181580066680908
recon_loss: 0.02701258286833763, dist_loss: 0.408582866191864
recon_loss: 0.02701408416032791, dist_loss: 0.6200979948043823
recon_loss: 0.027016116306185722, dist_loss: 0.563692569732666
recon_loss: 0.027019210159778595, dist_loss: 0.8798749446868896
recon_loss: 0.027021562680602074, dist_loss: 0.678871214389801
recon_loss: 0.027023091912269592, dist_loss: 0.8923211097717285
recon_loss: 0.027026254683732986, dist_loss: 0.2778073847293854
recon_loss: 0.02702912874519825, dist_loss: 0.5439153909683228
recon_loss: 0.027031565085053444, dist_loss: 0.4619596004486084
recon_loss: 0.027031488716602325, dist_loss: 0.6508209705352783
recon_loss: 0.027029922232031822, dist_loss: 1.1773905754089355
recon_loss: 0.027029860764741898, dist_loss: 0.7285417318344116
recon_loss: 0.027027543634176254, dist_loss: 0.5393615365028381
recon_loss: 0.027022339403629303, dist_loss: 1.1103312969207764
recon_loss: 0.02702104113996029, dist_loss: 0.6066410541534424
recon_loss: 0.027016395702958107, dist_loss: 0.8789870738983154
recon_loss: 0.02701667509973049, dist_loss: 0.7208849191665649
recon_loss: 0.02701313979923725, dist_loss: 0.6481935977935791
recon_loss: 0.027014294639229774, dist_loss: 0.3686674237251282
recon_loss: 0.027014438062906265, dist_loss: 0.3730013966560364
recon_loss: 0.027016472071409225, dist_loss: 0.754258394241333
recon_loss: 0.027017531916499138, dist_loss: 1.1038925647735596
recon_loss: 0.027020607143640518, dist_loss: 0.47545531392097473
recon_loss: 0.027023661881685257, dist_loss: 0.2986082136631012
recon_loss: 0.02702634409070015, dist_loss: 0.9279488325119019
recon_loss: 0.027025269344449043, dist_loss: 0.7047977447509766
recon_loss: 0.027023375034332275, dist_loss: 0.7756544351577759
recon_loss: 0.02702035754919052, dist_loss: 0.4673180878162384
recon_loss: 0.027020376175642014, dist_loss: 0.6764552593231201
recon_loss: 0.02701755054295063, dist_loss: 0.49121955037117004
recon_loss: 0.02701757475733757, dist_loss: 0.7986201047897339
recon_loss: 0.027014436200261116, dist_loss: 0.9129676818847656
recon_loss: 0.02701445482671261, dist_loss: 0.5856625437736511
recon_loss: 0.027012402191758156, dist_loss: 0.37252527475357056
recon_loss: 0.027013031765818596, dist_loss: 0.6402676105499268
recon_loss: 0.027011167258024216, dist_loss: 0.41582947969436646
recon_loss: 0.027011476457118988, dist_loss: 0.6354920864105225
recon_loss: 0.027010848745703697, dist_loss: 0.5235999226570129
recon_loss: 0.02701188065111637, dist_loss: 0.5161880254745483
recon_loss: 0.027012338861823082, dist_loss: 0.6818283796310425
recon_loss: 0.02701433002948761, dist_loss: 0.8507000207901001
recon_loss: 0.027015747502446175, dist_loss: 0.5478644967079163
recon_loss: 0.027014803141355515, dist_loss: 0.5171105861663818
recon_loss: 0.027015849947929382, dist_loss: 0.5424520969390869
recon_loss: 0.02701379358768463, dist_loss: 0.54872727394104
recon_loss: 0.027012547478079796, dist_loss: 0.7453447580337524
recon_loss: 0.027010750025510788, dist_loss: 0.605507493019104
recon_loss: 0.027010535821318626, dist_loss: 0.3554255962371826
recon_loss: 0.027010148391127586, dist_loss: 0.5091466903686523
recon_loss: 0.027010750025510788, dist_loss: 0.6035783886909485
recon_loss: 0.02701113186776638, dist_loss: 0.7832356095314026
recon_loss: 0.027011290192604065, dist_loss: 0.5702146887779236
recon_loss: 0.02701209858059883, dist_loss: 0.644406795501709
recon_loss: 0.027010038495063782, dist_loss: 0.5992522835731506
recon_loss: 0.027010172605514526, dist_loss: 0.5399384498596191
recon_loss: 0.027008607983589172, dist_loss: 0.5141494274139404
recon_loss: 0.027005862444639206, dist_loss: 0.48237261176109314
recon_loss: 0.02700507827103138, dist_loss: 0.5582252740859985
recon_loss: 0.027003243565559387, dist_loss: 0.7817773818969727
recon_loss: 0.02700413204729557, dist_loss: 0.5077502727508545
recon_loss: 0.027003053575754166, dist_loss: 0.4466674327850342
recon_loss: 0.027004186064004898, dist_loss: 0.44767946004867554
recon_loss: 0.027003277093172073, dist_loss: 0.6812413930892944
recon_loss: 0.02700401097536087, dist_loss: 0.5552645325660706
recon_loss: 0.027002941817045212, dist_loss: 0.5707964301109314
recon_loss: 0.027003716677427292, dist_loss: 0.6154947876930237
recon_loss: 0.027002975344657898, dist_loss: 0.48222842812538147
recon_loss: 0.027004681527614594, dist_loss: 0.5816484689712524
Pre-training Epoch 131:  71%|███████   | 261/367 [00:01<00:00, 153.20it/s]Pre-training Epoch 131:  75%|███████▌  | 277/367 [00:01<00:00, 153.49it/s]Pre-training Epoch 131:  80%|███████▉  | 293/367 [00:01<00:00, 153.67it/s]Pre-training Epoch 131:  84%|████████▍ | 309/367 [00:01<00:00, 153.85it/s]Pre-training Epoch 131:  89%|████████▊ | 325/367 [00:02<00:00, 154.00it/s]Pre-training Epoch 131:  93%|█████████▎| 341/367 [00:02<00:00, 153.78it/s]Pre-training Epoch 131:  98%|█████████▊| 358/367 [00:02<00:00, 156.50it/s]Pre-training Epoch 131: 100%|██████████| 367/367 [00:02<00:00, 155.61it/s]
recon_loss: 0.027003835886716843, dist_loss: 0.9007412195205688
recon_loss: 0.027005165815353394, dist_loss: 0.6790945529937744
recon_loss: 0.02700468711555004, dist_loss: 0.3683207035064697
recon_loss: 0.027004780247807503, dist_loss: 0.6975512504577637
recon_loss: 0.027004258707165718, dist_loss: 0.43795955181121826
recon_loss: 0.027003958821296692, dist_loss: 0.4936979413032532
recon_loss: 0.027003714814782143, dist_loss: 0.49587756395339966
recon_loss: 0.027003725990653038, dist_loss: 0.6384235620498657
recon_loss: 0.027003563940525055, dist_loss: 0.49034035205841064
recon_loss: 0.027002999559044838, dist_loss: 0.7362863421440125
recon_loss: 0.027002710849046707, dist_loss: 0.5097333788871765
recon_loss: 0.02700238861143589, dist_loss: 0.9202620387077332
recon_loss: 0.027003295719623566, dist_loss: 0.5970703363418579
recon_loss: 0.027002839371562004, dist_loss: 0.5266020894050598
recon_loss: 0.027003800496459007, dist_loss: 0.5735788345336914
recon_loss: 0.027002573013305664, dist_loss: 0.4714511036872864
recon_loss: 0.027002334594726562, dist_loss: 0.5148869752883911
recon_loss: 0.02700117975473404, dist_loss: 0.5473595261573792
recon_loss: 0.02700062468647957, dist_loss: 0.532884955406189
recon_loss: 0.027000537142157555, dist_loss: 0.9098114967346191
recon_loss: 0.027000490576028824, dist_loss: 0.9810988903045654
recon_loss: 0.027000533416867256, dist_loss: 0.709829568862915
recon_loss: 0.027000678703188896, dist_loss: 0.6631096601486206
recon_loss: 0.027000553905963898, dist_loss: 0.4763839840888977
recon_loss: 0.02700074017047882, dist_loss: 0.4118194282054901
recon_loss: 0.027001112699508667, dist_loss: 0.7351669073104858
recon_loss: 0.027001066133379936, dist_loss: 0.4627782702445984
recon_loss: 0.02700098417699337, dist_loss: 0.63053959608078
recon_loss: 0.027001360431313515, dist_loss: 0.36282816529273987
recon_loss: 0.02700207568705082, dist_loss: 0.7683619260787964
recon_loss: 0.02700294740498066, dist_loss: 0.38400769233703613
recon_loss: 0.02700394205749035, dist_loss: 0.6752060651779175
recon_loss: 0.027004025876522064, dist_loss: 0.851315438747406
recon_loss: 0.027004864066839218, dist_loss: 1.5584768056869507
recon_loss: 0.027006002143025398, dist_loss: 0.734775185585022
recon_loss: 0.02700646035373211, dist_loss: 0.4765737056732178
recon_loss: 0.0270061157643795, dist_loss: 0.8429335355758667
recon_loss: 0.027005091309547424, dist_loss: 0.3818153738975525
recon_loss: 0.02700437605381012, dist_loss: 0.7316607236862183
recon_loss: 0.027003677561879158, dist_loss: 0.9559699296951294
recon_loss: 0.02700365148484707, dist_loss: 0.44977933168411255
recon_loss: 0.027003638446331024, dist_loss: 0.8530087471008301
recon_loss: 0.027004055678844452, dist_loss: 0.5296235084533691
recon_loss: 0.027004577219486237, dist_loss: 0.9553946256637573
recon_loss: 0.027005208656191826, dist_loss: 0.42005449533462524
recon_loss: 0.02700619213283062, dist_loss: 0.3941482901573181
recon_loss: 0.02700798399746418, dist_loss: 0.6601161956787109
recon_loss: 0.02701004035770893, dist_loss: 1.0503143072128296
recon_loss: 0.027009950950741768, dist_loss: 0.6759016513824463
recon_loss: 0.027012014761567116, dist_loss: 0.9180073738098145
recon_loss: 0.027011090889573097, dist_loss: 0.6464969515800476
recon_loss: 0.027011197060346603, dist_loss: 0.6378459930419922
recon_loss: 0.02700834907591343, dist_loss: 0.7495030164718628
recon_loss: 0.027006054297089577, dist_loss: 0.6887660026550293
recon_loss: 0.027005959302186966, dist_loss: 0.35307449102401733
recon_loss: 0.027005990967154503, dist_loss: 0.7983757257461548
recon_loss: 0.027008824050426483, dist_loss: 0.7603634595870972
recon_loss: 0.027013059705495834, dist_loss: 0.82733154296875
recon_loss: 0.027017006650567055, dist_loss: 0.7566506862640381
recon_loss: 0.027020514011383057, dist_loss: 0.8306227326393127
recon_loss: 0.02702278085052967, dist_loss: 0.771078884601593
recon_loss: 0.027026226744055748, dist_loss: 0.8829072713851929
recon_loss: 0.027031878009438515, dist_loss: 0.7328474521636963
recon_loss: 0.027035890147089958, dist_loss: 0.40600118041038513
recon_loss: 0.027037473395466805, dist_loss: 0.24838486313819885
recon_loss: 0.027036301791667938, dist_loss: 0.7343270182609558
recon_loss: 0.027034511789679527, dist_loss: 0.6733124256134033
recon_loss: 0.027029745280742645, dist_loss: 0.40024030208587646
recon_loss: 0.027025500312447548, dist_loss: 0.6124608516693115
recon_loss: 0.027022939175367355, dist_loss: 0.3845919668674469
recon_loss: 0.027020717039704323, dist_loss: 0.5860664248466492
recon_loss: 0.027019038796424866, dist_loss: 0.7225930690765381
recon_loss: 0.02701839990913868, dist_loss: 0.43300095200538635
recon_loss: 0.027018871158361435, dist_loss: 0.6815871596336365
recon_loss: 0.02702351100742817, dist_loss: 0.6719973683357239
recon_loss: 0.027029812335968018, dist_loss: 0.5328484177589417
recon_loss: 0.027035800740122795, dist_loss: 0.9974104166030884
recon_loss: 0.027040651068091393, dist_loss: 0.7639905214309692
recon_loss: 0.02704733796417713, dist_loss: 0.49861693382263184
recon_loss: 0.02704986184835434, dist_loss: 0.5917289853096008
recon_loss: 0.027050849050283432, dist_loss: 0.3545953929424286
recon_loss: 0.027049146592617035, dist_loss: 0.5698568820953369
recon_loss: 0.027045542374253273, dist_loss: 0.6856871247291565
recon_loss: 0.027040136978030205, dist_loss: 0.5019979476928711
recon_loss: 0.027034414932131767, dist_loss: 0.4104456901550293
recon_loss: 0.02702886052429676, dist_loss: 0.4549325704574585
recon_loss: 0.027024701237678528, dist_loss: 0.5795908570289612
recon_loss: 0.027023669332265854, dist_loss: 0.6226637363433838
recon_loss: 0.027022965252399445, dist_loss: 0.43891584873199463
recon_loss: 0.027024632319808006, dist_loss: 0.6190555095672607
recon_loss: 0.027027059346437454, dist_loss: 1.1380705833435059
recon_loss: 0.02703089825809002, dist_loss: 0.8836554288864136
recon_loss: 0.02703482285141945, dist_loss: 0.5045098662376404
recon_loss: 0.027038365602493286, dist_loss: 0.6587503552436829
recon_loss: 0.02703978680074215, dist_loss: 0.482174813747406
recon_loss: 0.027037428691983223, dist_loss: 0.6705759763717651
recon_loss: 0.02703518234193325, dist_loss: 0.6431708335876465
recon_loss: 0.02703031711280346, dist_loss: 0.5465261340141296
recon_loss: 0.02702748216688633, dist_loss: 0.5356717705726624
recon_loss: 0.027022425085306168, dist_loss: 0.3546260595321655
recon_loss: 0.027021022513508797, dist_loss: 0.6840450763702393
recon_loss: 0.027018843218684196, dist_loss: 0.5175898671150208
recon_loss: 0.027019672095775604, dist_loss: 0.4169887900352478
recon_loss: 0.02701825276017189, dist_loss: 0.6860254406929016
recon_loss: 0.027019169181585312, dist_loss: 0.7660015821456909
recon_loss: 0.027017131447792053, dist_loss: 0.4204671382904053
recon_loss: 0.027015971019864082, dist_loss: 0.7884416580200195
recon_loss: 0.027014417573809624, dist_loss: 0.4672611355781555
recon_loss: 0.027012696489691734, dist_loss: 0.6829929351806641
recon_loss: 0.02701069600880146, dist_loss: 0.42966336011886597
recon_loss: 0.027009816840291023, dist_loss: 0.2694678008556366
Pre-training Epoch 132:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 132:   5%|▌         | 19/367 [00:00<00:01, 187.84it/s]Pre-training Epoch 132:  11%|█         | 39/367 [00:00<00:01, 189.62it/s]Pre-training Epoch 132:  16%|█▌        | 59/367 [00:00<00:01, 189.96it/s]Pre-training Epoch 132:  22%|██▏       | 79/367 [00:00<00:01, 190.66it/s]Pre-training Epoch 132:  27%|██▋       | 99/367 [00:00<00:01, 190.38it/s]Pre-training Epoch 132:  32%|███▏      | 119/367 [00:00<00:01, 190.87it/s]recon_loss: 0.027008019387722015, dist_loss: 0.7096955180168152
recon_loss: 0.027008119970560074, dist_loss: 0.8397402167320251
recon_loss: 0.027005745097994804, dist_loss: 0.6470483541488647
recon_loss: 0.027006808668375015, dist_loss: 0.3717527389526367
recon_loss: 0.027003908529877663, dist_loss: 0.5908598899841309
recon_loss: 0.0270045455545187, dist_loss: 0.30640578269958496
recon_loss: 0.027002474293112755, dist_loss: 0.4023589491844177
recon_loss: 0.027002660557627678, dist_loss: 0.4604668915271759
recon_loss: 0.02700205333530903, dist_loss: 0.3662055730819702
recon_loss: 0.027002237737178802, dist_loss: 0.7599098086357117
recon_loss: 0.027001654729247093, dist_loss: 0.6904051899909973
recon_loss: 0.027002355083823204, dist_loss: 0.5758764743804932
recon_loss: 0.0270012728869915, dist_loss: 0.6663079261779785
recon_loss: 0.027001598849892616, dist_loss: 0.8316832780838013
recon_loss: 0.02700023353099823, dist_loss: 0.7517929077148438
recon_loss: 0.027000658214092255, dist_loss: 0.6273148059844971
recon_loss: 0.027000214904546738, dist_loss: 0.5096311569213867
recon_loss: 0.02700025960803032, dist_loss: 0.5729929208755493
recon_loss: 0.027000021189451218, dist_loss: 0.7309535145759583
recon_loss: 0.026999983936548233, dist_loss: 0.7904739379882812
recon_loss: 0.02700008451938629, dist_loss: 0.32112908363342285
recon_loss: 0.027000289410352707, dist_loss: 0.7536932826042175
recon_loss: 0.027000179514288902, dist_loss: 0.4271184206008911
recon_loss: 0.02700001187622547, dist_loss: 0.4603159427642822
recon_loss: 0.026999259367585182, dist_loss: 0.9208534359931946
recon_loss: 0.02699901908636093, dist_loss: 0.36486250162124634
recon_loss: 0.02699858881533146, dist_loss: 0.7763466835021973
recon_loss: 0.02699868194758892, dist_loss: 0.4916612505912781
recon_loss: 0.026998069137334824, dist_loss: 0.2463642954826355
recon_loss: 0.02699875645339489, dist_loss: 0.47520431876182556
recon_loss: 0.026998991146683693, dist_loss: 0.7639796733856201
recon_loss: 0.027000652626156807, dist_loss: 0.5725457668304443
recon_loss: 0.02700032852590084, dist_loss: 0.573566734790802
recon_loss: 0.027002163231372833, dist_loss: 0.4742682874202728
recon_loss: 0.02700144052505493, dist_loss: 0.3494953215122223
recon_loss: 0.027002884075045586, dist_loss: 0.3717309236526489
recon_loss: 0.02700073830783367, dist_loss: 0.36131608486175537
recon_loss: 0.027000978589057922, dist_loss: 0.7066999673843384
recon_loss: 0.02699955552816391, dist_loss: 0.9098085761070251
recon_loss: 0.026999985799193382, dist_loss: 0.41195470094680786
recon_loss: 0.02699786238372326, dist_loss: 0.5851446390151978
recon_loss: 0.02699808031320572, dist_loss: 0.5662533044815063
recon_loss: 0.02699657902121544, dist_loss: 0.4717273712158203
recon_loss: 0.02699815295636654, dist_loss: 0.4190552532672882
recon_loss: 0.02699674665927887, dist_loss: 0.6124193668365479
recon_loss: 0.02699880115687847, dist_loss: 0.7176472544670105
recon_loss: 0.026999009773135185, dist_loss: 1.0265750885009766
recon_loss: 0.027002643793821335, dist_loss: 0.39442527294158936
recon_loss: 0.027004223316907883, dist_loss: 0.7407008409500122
recon_loss: 0.027008526027202606, dist_loss: 0.8606683611869812
recon_loss: 0.027012672275304794, dist_loss: 0.9434804320335388
recon_loss: 0.027016328647732735, dist_loss: 0.3942641615867615
recon_loss: 0.0270176213234663, dist_loss: 0.36291491985321045
recon_loss: 0.02701820246875286, dist_loss: 0.6312904357910156
recon_loss: 0.027017172425985336, dist_loss: 0.5445430278778076
recon_loss: 0.027012275531888008, dist_loss: 0.4933318793773651
recon_loss: 0.027009572833776474, dist_loss: 0.6466952562332153
recon_loss: 0.027004651725292206, dist_loss: 0.6231292486190796
recon_loss: 0.027003269642591476, dist_loss: 0.5105444192886353
recon_loss: 0.02700188010931015, dist_loss: 0.3949921429157257
recon_loss: 0.02700262889266014, dist_loss: 0.5167577266693115
recon_loss: 0.027003979310393333, dist_loss: 0.6135634183883667
recon_loss: 0.02700839191675186, dist_loss: 0.6706442832946777
recon_loss: 0.027013182640075684, dist_loss: 0.46078068017959595
recon_loss: 0.02701825276017189, dist_loss: 0.6527467370033264
recon_loss: 0.02702227793633938, dist_loss: 0.6664342284202576
recon_loss: 0.027025023475289345, dist_loss: 0.5880399942398071
recon_loss: 0.027026711031794548, dist_loss: 0.6033024787902832
recon_loss: 0.02702588587999344, dist_loss: 0.9108549356460571
recon_loss: 0.02702408842742443, dist_loss: 0.6341663599014282
recon_loss: 0.02702159807085991, dist_loss: 0.5487393140792847
recon_loss: 0.027018671855330467, dist_loss: 0.2614005208015442
recon_loss: 0.02701517567038536, dist_loss: 0.777523398399353
recon_loss: 0.0270108412951231, dist_loss: 1.0213119983673096
recon_loss: 0.027007199823856354, dist_loss: 0.7531311511993408
recon_loss: 0.027006471529603004, dist_loss: 0.5990952849388123
recon_loss: 0.027005573734641075, dist_loss: 1.022857427597046
recon_loss: 0.027006665244698524, dist_loss: 0.5327420234680176
recon_loss: 0.027007391676306725, dist_loss: 0.6424667835235596
recon_loss: 0.027008745819330215, dist_loss: 0.5116047859191895
recon_loss: 0.027008699253201485, dist_loss: 0.6777440309524536
recon_loss: 0.02700883522629738, dist_loss: 1.06133234500885
recon_loss: 0.027008255943655968, dist_loss: 0.30835863947868347
recon_loss: 0.027008939534425735, dist_loss: 0.6659553647041321
recon_loss: 0.02700802870094776, dist_loss: 0.5011616349220276
recon_loss: 0.027007797732949257, dist_loss: 0.3538897633552551
recon_loss: 0.027006803080439568, dist_loss: 0.7750284671783447
recon_loss: 0.027005769312381744, dist_loss: 0.8655821681022644
recon_loss: 0.027004724368453026, dist_loss: 0.8357506394386292
recon_loss: 0.027002552524209023, dist_loss: 0.47976449131965637
recon_loss: 0.027001475915312767, dist_loss: 0.3081187307834625
recon_loss: 0.02700001187622547, dist_loss: 1.3253861665725708
recon_loss: 0.026999449357390404, dist_loss: 0.48353448510169983
recon_loss: 0.026998670771718025, dist_loss: 0.6634282469749451
recon_loss: 0.02699863538146019, dist_loss: 0.5178509950637817
recon_loss: 0.026997964829206467, dist_loss: 0.5684382915496826
recon_loss: 0.026998255401849747, dist_loss: 0.9134119749069214
recon_loss: 0.026998650282621384, dist_loss: 0.4281359314918518
recon_loss: 0.02699938602745533, dist_loss: 0.7397906184196472
recon_loss: 0.026999954134225845, dist_loss: 0.8822871446609497
recon_loss: 0.027000075206160545, dist_loss: 0.626293957233429
recon_loss: 0.0270015187561512, dist_loss: 1.0670320987701416
recon_loss: 0.027001814916729927, dist_loss: 0.7004427313804626
recon_loss: 0.027002278715372086, dist_loss: 0.7040585279464722
recon_loss: 0.02700311876833439, dist_loss: 0.41570255160331726
recon_loss: 0.02700340934097767, dist_loss: 0.37704646587371826
recon_loss: 0.02700386755168438, dist_loss: 0.6384363174438477
recon_loss: 0.027003154158592224, dist_loss: 0.432691752910614
recon_loss: 0.02700292505323887, dist_loss: 0.5765589475631714
recon_loss: 0.027002956718206406, dist_loss: 0.6588912010192871
recon_loss: 0.02700413577258587, dist_loss: 0.3653795123100281
recon_loss: 0.027006378397345543, dist_loss: 0.5994623899459839
recon_loss: 0.027007825672626495, dist_loss: 0.6311968564987183
recon_loss: 0.0270079318434, dist_loss: 0.3931499719619751
recon_loss: 0.027006637305021286, dist_loss: 0.4355219602584839
recon_loss: 0.02700481005012989, dist_loss: 0.7409437894821167
recon_loss: 0.027002805843949318, dist_loss: 1.2111409902572632
recon_loss: 0.02700021304190159, dist_loss: 0.32603543996810913
recon_loss: 0.0269992146641016, dist_loss: 1.0046871900558472
recon_loss: 0.02699846588075161, dist_loss: 0.7400452494621277
recon_loss: 0.026998577639460564, dist_loss: 0.4487046003341675
recon_loss: 0.026999104768037796, dist_loss: 0.4346355199813843
recon_loss: 0.026999790221452713, dist_loss: 0.5076571702957153
recon_loss: 0.027000028640031815, dist_loss: 0.5879981517791748
recon_loss: 0.027000166475772858, dist_loss: 0.4247324466705322
recon_loss: 0.02700052782893181, dist_loss: 1.0671563148498535
recon_loss: 0.027001148089766502, dist_loss: 1.058592438697815
recon_loss: 0.027002500370144844, dist_loss: 0.4640617072582245
Pre-training Epoch 132:  38%|███▊      | 139/367 [00:00<00:01, 191.14it/s]Pre-training Epoch 132:  43%|████▎     | 159/367 [00:00<00:01, 191.40it/s]Pre-training Epoch 132:  49%|████▉     | 179/367 [00:00<00:00, 190.80it/s]Pre-training Epoch 132:  54%|█████▍    | 199/367 [00:01<00:00, 180.24it/s]Pre-training Epoch 132:  59%|█████▉    | 218/367 [00:01<00:00, 172.78it/s]Pre-training Epoch 132:  64%|██████▍   | 236/367 [00:01<00:00, 169.28it/s]Pre-training Epoch 132:  69%|██████▉   | 254/367 [00:01<00:00, 166.25it/s]recon_loss: 0.027002552524209023, dist_loss: 0.6460731029510498
recon_loss: 0.02700168266892433, dist_loss: 1.0032612085342407
recon_loss: 0.027000311762094498, dist_loss: 0.4730854630470276
recon_loss: 0.026999732479453087, dist_loss: 0.7496210336685181
recon_loss: 0.026999305933713913, dist_loss: 0.8919507265090942
recon_loss: 0.02699851058423519, dist_loss: 0.4347691535949707
recon_loss: 0.026997307315468788, dist_loss: 0.5795852541923523
recon_loss: 0.02699611522257328, dist_loss: 0.3371954560279846
recon_loss: 0.026995791122317314, dist_loss: 0.8915610909461975
recon_loss: 0.026995480060577393, dist_loss: 0.2981749176979065
recon_loss: 0.026995625346899033, dist_loss: 0.8867589235305786
recon_loss: 0.026995794847607613, dist_loss: 1.2140023708343506
recon_loss: 0.02699669450521469, dist_loss: 0.7499359846115112
recon_loss: 0.026996970176696777, dist_loss: 0.6340349316596985
recon_loss: 0.026997607201337814, dist_loss: 0.4816775619983673
recon_loss: 0.026997609063982964, dist_loss: 0.5262321829795837
recon_loss: 0.026997022330760956, dist_loss: 0.33036673069000244
recon_loss: 0.026996290311217308, dist_loss: 0.8460468053817749
recon_loss: 0.026995539665222168, dist_loss: 0.2919232249259949
recon_loss: 0.026995183899998665, dist_loss: 0.7269689440727234
recon_loss: 0.026994738727808, dist_loss: 0.6638242602348328
recon_loss: 0.026995450258255005, dist_loss: 0.4044327139854431
recon_loss: 0.026994388550519943, dist_loss: 0.7575086355209351
recon_loss: 0.026994870975613594, dist_loss: 0.6439230442047119
recon_loss: 0.026994207873940468, dist_loss: 0.3813111186027527
recon_loss: 0.02699466235935688, dist_loss: 0.6250361204147339
recon_loss: 0.026993898674845695, dist_loss: 0.4910562038421631
recon_loss: 0.02699439786374569, dist_loss: 0.6727194786071777
recon_loss: 0.026994414627552032, dist_loss: 1.150386095046997
recon_loss: 0.026993930339813232, dist_loss: 0.850566565990448
recon_loss: 0.026994753628969193, dist_loss: 0.8385744690895081
recon_loss: 0.026994314044713974, dist_loss: 0.4470100700855255
recon_loss: 0.026995237916707993, dist_loss: 0.5524730682373047
recon_loss: 0.026995116844773293, dist_loss: 0.6175196766853333
recon_loss: 0.026996083557605743, dist_loss: 0.8241350650787354
recon_loss: 0.026996217668056488, dist_loss: 0.7670952081680298
recon_loss: 0.0269952192902565, dist_loss: 0.45781779289245605
recon_loss: 0.02699420601129532, dist_loss: 0.7431303858757019
recon_loss: 0.026992978528141975, dist_loss: 0.3482271432876587
recon_loss: 0.02699277736246586, dist_loss: 0.589984118938446
recon_loss: 0.026992492377758026, dist_loss: 1.0700139999389648
recon_loss: 0.026994243264198303, dist_loss: 0.644153356552124
recon_loss: 0.026994070038199425, dist_loss: 0.4698657691478729
recon_loss: 0.026995811611413956, dist_loss: 0.48839670419692993
recon_loss: 0.026996687054634094, dist_loss: 0.47563761472702026
recon_loss: 0.026998264715075493, dist_loss: 0.6646511554718018
recon_loss: 0.026999086141586304, dist_loss: 0.5000962018966675
recon_loss: 0.026999622583389282, dist_loss: 0.5136292576789856
recon_loss: 0.026999078691005707, dist_loss: 0.6339021921157837
recon_loss: 0.02700016088783741, dist_loss: 0.6504732370376587
recon_loss: 0.02699941396713257, dist_loss: 0.39423784613609314
recon_loss: 0.02700020745396614, dist_loss: 0.4739782214164734
recon_loss: 0.026999162510037422, dist_loss: 0.789311408996582
recon_loss: 0.02699875645339489, dist_loss: 0.49149012565612793
recon_loss: 0.02699791081249714, dist_loss: 0.7784267663955688
recon_loss: 0.026997696608304977, dist_loss: 0.7459425926208496
recon_loss: 0.026997936889529228, dist_loss: 0.6767128705978394
recon_loss: 0.026998158544301987, dist_loss: 0.3910810947418213
recon_loss: 0.02699723094701767, dist_loss: 0.5931020975112915
recon_loss: 0.02699759230017662, dist_loss: 0.9776423573493958
recon_loss: 0.026997942477464676, dist_loss: 0.502271831035614
recon_loss: 0.02699919603765011, dist_loss: 0.4984320402145386
recon_loss: 0.02699955925345421, dist_loss: 0.9882456660270691
recon_loss: 0.027000367641448975, dist_loss: 0.6970317363739014
recon_loss: 0.027000660076737404, dist_loss: 0.5868142247200012
recon_loss: 0.027000607922673225, dist_loss: 0.322112113237381
recon_loss: 0.02700013481080532, dist_loss: 0.524051308631897
recon_loss: 0.02700125053524971, dist_loss: 0.3591882884502411
recon_loss: 0.027001291513442993, dist_loss: 0.651515781879425
recon_loss: 0.027002573013305664, dist_loss: 0.39769452810287476
recon_loss: 0.02700204961001873, dist_loss: 0.44850367307662964
recon_loss: 0.027002600952982903, dist_loss: 0.4766463041305542
recon_loss: 0.027001531794667244, dist_loss: 0.6292543411254883
recon_loss: 0.027001382783055305, dist_loss: 0.4652561545372009
recon_loss: 0.02700084261596203, dist_loss: 0.6288673281669617
recon_loss: 0.027000417932868004, dist_loss: 0.5361613035202026
recon_loss: 0.026999110355973244, dist_loss: 0.3382207751274109
recon_loss: 0.026996806263923645, dist_loss: 0.5046095252037048
recon_loss: 0.026997094973921776, dist_loss: 0.6378657817840576
recon_loss: 0.02699561044573784, dist_loss: 0.2603914141654968
recon_loss: 0.02699626423418522, dist_loss: 0.6210984587669373
recon_loss: 0.026995830237865448, dist_loss: 1.0849509239196777
recon_loss: 0.02699759416282177, dist_loss: 0.5908730626106262
recon_loss: 0.026998046785593033, dist_loss: 0.36782312393188477
recon_loss: 0.026999549940228462, dist_loss: 0.61939537525177
recon_loss: 0.02699870988726616, dist_loss: 0.7439959049224854
recon_loss: 0.026998648419976234, dist_loss: 0.45818841457366943
recon_loss: 0.02699754200875759, dist_loss: 0.5118812918663025
recon_loss: 0.02699657343327999, dist_loss: 0.3749282956123352
recon_loss: 0.026995347812771797, dist_loss: 0.8384938836097717
recon_loss: 0.02699512615799904, dist_loss: 0.3961392641067505
recon_loss: 0.026995068415999413, dist_loss: 0.592444658279419
recon_loss: 0.026995370164513588, dist_loss: 0.5464898943901062
recon_loss: 0.02699531801044941, dist_loss: 0.3893943130970001
recon_loss: 0.026995539665222168, dist_loss: 0.37718573212623596
recon_loss: 0.02699490264058113, dist_loss: 0.285707950592041
recon_loss: 0.02699429541826248, dist_loss: 0.8897174596786499
recon_loss: 0.02699323184788227, dist_loss: 0.7749307155609131
recon_loss: 0.02699233964085579, dist_loss: 0.9676761627197266
recon_loss: 0.02699153870344162, dist_loss: 0.5256165266036987
recon_loss: 0.02699108049273491, dist_loss: 0.6923377513885498
recon_loss: 0.026990992948412895, dist_loss: 0.6950567364692688
recon_loss: 0.026991669088602066, dist_loss: 0.6964834928512573
recon_loss: 0.026992056518793106, dist_loss: 0.9874307513237
recon_loss: 0.02699279971420765, dist_loss: 0.7962982058525085
recon_loss: 0.026992889121174812, dist_loss: 0.47581717371940613
recon_loss: 0.026994118466973305, dist_loss: 0.4615345001220703
recon_loss: 0.026994872838258743, dist_loss: 0.374873548746109
recon_loss: 0.026995113119482994, dist_loss: 0.6296742558479309
recon_loss: 0.02699684165418148, dist_loss: 0.533038318157196
recon_loss: 0.026997368782758713, dist_loss: 0.7439454793930054
recon_loss: 0.0269983671605587, dist_loss: 0.49297040700912476
recon_loss: 0.026997340843081474, dist_loss: 0.6761391162872314
recon_loss: 0.026997432112693787, dist_loss: 0.5379111766815186
recon_loss: 0.026994844898581505, dist_loss: 0.8717802166938782
recon_loss: 0.026996420696377754, dist_loss: 0.9162956476211548
recon_loss: 0.02699286676943302, dist_loss: 0.34156960248947144
recon_loss: 0.02699488401412964, dist_loss: 0.9278552532196045
recon_loss: 0.026992136612534523, dist_loss: 0.8542463183403015
recon_loss: 0.02699248492717743, dist_loss: 0.4119884669780731
recon_loss: 0.026992039754986763, dist_loss: 0.515032947063446
recon_loss: 0.026993341743946075, dist_loss: 0.972867488861084
recon_loss: 0.026992926374077797, dist_loss: 0.5538822412490845
recon_loss: 0.026993557810783386, dist_loss: 0.35804957151412964
recon_loss: 0.026992367580533028, dist_loss: 0.48090317845344543
recon_loss: 0.026992565020918846, dist_loss: 0.7912464141845703
recon_loss: 0.02699226886034012, dist_loss: 0.6357923746109009
recon_loss: 0.026993636041879654, dist_loss: 1.2607814073562622
Pre-training Epoch 132:  74%|███████▍  | 271/367 [00:01<00:00, 165.06it/s]Pre-training Epoch 132:  78%|███████▊  | 288/367 [00:01<00:00, 163.31it/s]Pre-training Epoch 132:  83%|████████▎ | 305/367 [00:01<00:00, 163.89it/s]Pre-training Epoch 132:  88%|████████▊ | 322/367 [00:01<00:00, 164.50it/s]Pre-training Epoch 132:  92%|█████████▏| 339/367 [00:01<00:00, 164.83it/s]Pre-training Epoch 132:  97%|█████████▋| 356/367 [00:02<00:00, 165.05it/s]Pre-training Epoch 132: 100%|██████████| 367/367 [00:02<00:00, 174.88it/s]
recon_loss: 0.02699298784136772, dist_loss: 0.5106455683708191
recon_loss: 0.026993893086910248, dist_loss: 0.45781761407852173
recon_loss: 0.02699297107756138, dist_loss: 0.5063962936401367
recon_loss: 0.02699214778840542, dist_loss: 0.21932485699653625
recon_loss: 0.02699136547744274, dist_loss: 0.43560895323753357
recon_loss: 0.02699182741343975, dist_loss: 0.2995268702507019
recon_loss: 0.026991432532668114, dist_loss: 0.5931711196899414
recon_loss: 0.026993243023753166, dist_loss: 0.597931981086731
recon_loss: 0.026991164311766624, dist_loss: 0.9843990206718445
recon_loss: 0.026992132887244225, dist_loss: 0.29346638917922974
recon_loss: 0.02699156478047371, dist_loss: 0.4746564030647278
recon_loss: 0.026992175728082657, dist_loss: 0.8085675239562988
recon_loss: 0.02699197269976139, dist_loss: 0.7165374159812927
recon_loss: 0.026990512385964394, dist_loss: 0.8075762987136841
recon_loss: 0.026991596445441246, dist_loss: 0.5053811073303223
recon_loss: 0.02699076011776924, dist_loss: 0.8306174874305725
recon_loss: 0.026991186663508415, dist_loss: 0.6284570097923279
recon_loss: 0.026989750564098358, dist_loss: 0.6804968118667603
recon_loss: 0.026991447433829308, dist_loss: 0.48470333218574524
recon_loss: 0.026989825069904327, dist_loss: 0.7248663902282715
recon_loss: 0.02699093148112297, dist_loss: 0.4791943430900574
recon_loss: 0.026989605277776718, dist_loss: 0.4642642140388489
recon_loss: 0.026989933103322983, dist_loss: 0.6968740820884705
recon_loss: 0.02698894776403904, dist_loss: 0.4305139183998108
recon_loss: 0.026988977566361427, dist_loss: 0.7763081192970276
recon_loss: 0.026988614350557327, dist_loss: 0.6015737056732178
recon_loss: 0.026988886296749115, dist_loss: 0.41707685589790344
recon_loss: 0.02698959968984127, dist_loss: 0.36728402972221375
recon_loss: 0.026990767568349838, dist_loss: 0.7323072552680969
recon_loss: 0.02699277363717556, dist_loss: 0.4618021547794342
recon_loss: 0.026994217187166214, dist_loss: 0.6284257173538208
recon_loss: 0.026994703337550163, dist_loss: 1.0854511260986328
recon_loss: 0.026993602514266968, dist_loss: 0.43312036991119385
recon_loss: 0.02699272148311138, dist_loss: 0.5697236061096191
recon_loss: 0.026991888880729675, dist_loss: 0.6791857481002808
recon_loss: 0.02699165791273117, dist_loss: 1.203648328781128
recon_loss: 0.026991400867700577, dist_loss: 0.9359467029571533
recon_loss: 0.02699100226163864, dist_loss: 0.7870036363601685
recon_loss: 0.0269906185567379, dist_loss: 0.8868693113327026
recon_loss: 0.0269901305437088, dist_loss: 0.4376031756401062
recon_loss: 0.026989901438355446, dist_loss: 0.5017412900924683
recon_loss: 0.02698960155248642, dist_loss: 0.5420970916748047
recon_loss: 0.0269890408962965, dist_loss: 1.0346684455871582
recon_loss: 0.02698875591158867, dist_loss: 0.8356906175613403
recon_loss: 0.0269888024777174, dist_loss: 0.8175903558731079
recon_loss: 0.02698882669210434, dist_loss: 0.816195547580719
recon_loss: 0.02698919177055359, dist_loss: 0.3669731914997101
recon_loss: 0.02698986977338791, dist_loss: 0.5667394995689392
recon_loss: 0.026990454643964767, dist_loss: 0.8022288680076599
recon_loss: 0.02699166163802147, dist_loss: 0.9021603465080261
recon_loss: 0.026990756392478943, dist_loss: 0.6299939155578613
recon_loss: 0.02699071541428566, dist_loss: 0.5718190670013428
recon_loss: 0.026989994570612907, dist_loss: 0.4714948534965515
recon_loss: 0.02698982134461403, dist_loss: 0.6892138719558716
recon_loss: 0.026989653706550598, dist_loss: 0.6801844835281372
recon_loss: 0.02699030004441738, dist_loss: 0.5952810645103455
recon_loss: 0.026990344747900963, dist_loss: 1.0138392448425293
recon_loss: 0.026991238817572594, dist_loss: 0.3598167300224304
recon_loss: 0.02699105627834797, dist_loss: 0.5163681507110596
recon_loss: 0.02699205093085766, dist_loss: 0.34342852234840393
recon_loss: 0.026992132887244225, dist_loss: 0.6567955017089844
recon_loss: 0.026992425322532654, dist_loss: 0.6086311936378479
recon_loss: 0.026991983875632286, dist_loss: 0.38222891092300415
recon_loss: 0.026991574093699455, dist_loss: 0.4218296706676483
recon_loss: 0.0269915908575058, dist_loss: 0.6720472574234009
recon_loss: 0.026989771053195, dist_loss: 0.48413532972335815
recon_loss: 0.026989301666617393, dist_loss: 0.737833559513092
recon_loss: 0.02698788419365883, dist_loss: 0.633271336555481
recon_loss: 0.02698800340294838, dist_loss: 0.3525448739528656
recon_loss: 0.02698725461959839, dist_loss: 0.3805539608001709
recon_loss: 0.026987455785274506, dist_loss: 0.31207820773124695
recon_loss: 0.026987064629793167, dist_loss: 0.773712694644928
recon_loss: 0.02698681503534317, dist_loss: 0.408595472574234
recon_loss: 0.026987047865986824, dist_loss: 0.8778296113014221
recon_loss: 0.026987332850694656, dist_loss: 0.6824565529823303
recon_loss: 0.026987846940755844, dist_loss: 0.5148885250091553
recon_loss: 0.026988066732883453, dist_loss: 0.5479030013084412
recon_loss: 0.0269879549741745, dist_loss: 0.7951498031616211
recon_loss: 0.026988117024302483, dist_loss: 0.38979679346084595
recon_loss: 0.026987001299858093, dist_loss: 0.4223611056804657
recon_loss: 0.026986749842762947, dist_loss: 0.6795276999473572
recon_loss: 0.026986075565218925, dist_loss: 0.4952240586280823
recon_loss: 0.026986610144376755, dist_loss: 0.7113176584243774
recon_loss: 0.02698642574250698, dist_loss: 0.3007948696613312
recon_loss: 0.02698683924973011, dist_loss: 0.4386117458343506
recon_loss: 0.02698688395321369, dist_loss: 0.37331175804138184
recon_loss: 0.026987317949533463, dist_loss: 0.6497138738632202
recon_loss: 0.026987260207533836, dist_loss: 0.5146511793136597
recon_loss: 0.026987316086888313, dist_loss: 0.6416130065917969
recon_loss: 0.026986878365278244, dist_loss: 0.5788561105728149
recon_loss: 0.026986034587025642, dist_loss: 0.6219609975814819
recon_loss: 0.026985596865415573, dist_loss: 0.4557693898677826
recon_loss: 0.026985904201865196, dist_loss: 0.5084683299064636
recon_loss: 0.0269869826734066, dist_loss: 0.42002013325691223
recon_loss: 0.026988299563527107, dist_loss: 0.47511377930641174
recon_loss: 0.026989873498678207, dist_loss: 0.5690520405769348
recon_loss: 0.02699083648622036, dist_loss: 0.3596949577331543
recon_loss: 0.026991665363311768, dist_loss: 0.4271479845046997
recon_loss: 0.026991747319698334, dist_loss: 0.38989007472991943
recon_loss: 0.026991959661245346, dist_loss: 0.5281765460968018
recon_loss: 0.026991069316864014, dist_loss: 1.231428623199463
recon_loss: 0.026991164311766624, dist_loss: 0.9469207525253296
recon_loss: 0.026990437880158424, dist_loss: 0.440074622631073
recon_loss: 0.026990387588739395, dist_loss: 0.5547960996627808
recon_loss: 0.026990050449967384, dist_loss: 0.6111384630203247
recon_loss: 0.02698972262442112, dist_loss: 0.7034900188446045
recon_loss: 0.026990031823515892, dist_loss: 0.4185648560523987
recon_loss: 0.02698991633951664, dist_loss: 0.7862154245376587
recon_loss: 0.0269909854978323, dist_loss: 0.9954452514648438
recon_loss: 0.02699093520641327, dist_loss: 0.47235947847366333
recon_loss: 0.026991231366991997, dist_loss: 0.8000812530517578
Pre-training Epoch 133:   0%|          | 0/367 [00:00<?, ?it/s]Pre-training Epoch 133:   5%|▌         | 19/367 [00:00<00:01, 185.67it/s]Pre-training Epoch 133:  11%|█         | 39/367 [00:00<00:01, 189.73it/s]Pre-training Epoch 133:  16%|█▌        | 59/367 [00:00<00:01, 188.39it/s]Pre-training Epoch 133:  21%|██▏       | 78/367 [00:00<00:01, 188.97it/s]Pre-training Epoch 133:  27%|██▋       | 98/367 [00:00<00:01, 190.24it/s]Pre-training Epoch 133:  32%|███▏      | 118/367 [00:00<00:01, 183.86it/s]recon_loss: 0.026990706101059914, dist_loss: 0.46235087513923645
recon_loss: 0.02699042484164238, dist_loss: 0.5615818500518799
recon_loss: 0.026990387588739395, dist_loss: 0.24866041541099548
recon_loss: 0.026990549638867378, dist_loss: 0.5256377458572388
recon_loss: 0.026989629492163658, dist_loss: 0.5643640160560608
recon_loss: 0.026988700032234192, dist_loss: 0.6576938629150391
recon_loss: 0.026987718418240547, dist_loss: 0.7407947778701782
recon_loss: 0.026987191289663315, dist_loss: 0.7309200763702393
recon_loss: 0.026986991986632347, dist_loss: 0.6771708726882935
recon_loss: 0.026987167075276375, dist_loss: 0.8423199653625488
recon_loss: 0.026987802237272263, dist_loss: 0.6002153158187866
recon_loss: 0.02698933519423008, dist_loss: 0.47408369183540344
recon_loss: 0.026991508901119232, dist_loss: 0.8334908485412598
recon_loss: 0.026994328945875168, dist_loss: 0.32277363538742065
recon_loss: 0.026997502893209457, dist_loss: 0.4856767952442169
recon_loss: 0.02700231596827507, dist_loss: 0.4626891016960144
recon_loss: 0.02700662985444069, dist_loss: 0.5590749979019165
recon_loss: 0.02700851485133171, dist_loss: 0.47536468505859375
recon_loss: 0.027007386088371277, dist_loss: 0.5635313987731934
recon_loss: 0.027004901319742203, dist_loss: 0.4479447305202484
recon_loss: 0.027001449838280678, dist_loss: 0.45249074697494507
recon_loss: 0.026998205110430717, dist_loss: 0.5440247654914856
recon_loss: 0.0269946102052927, dist_loss: 0.3465104103088379
recon_loss: 0.02699226327240467, dist_loss: 0.625700831413269
recon_loss: 0.026992011815309525, dist_loss: 0.4678608775138855
recon_loss: 0.026992816478013992, dist_loss: 1.0730464458465576
recon_loss: 0.02699391357600689, dist_loss: 0.48627811670303345
recon_loss: 0.026994550600647926, dist_loss: 0.572387158870697
recon_loss: 0.026995057240128517, dist_loss: 0.2767367959022522
recon_loss: 0.02699579857289791, dist_loss: 1.0666389465332031
recon_loss: 0.02699575386941433, dist_loss: 0.3729846775531769
recon_loss: 0.02699577622115612, dist_loss: 1.0390547513961792
recon_loss: 0.026994997635483742, dist_loss: 0.6579285264015198
recon_loss: 0.026993587613105774, dist_loss: 0.8387484550476074
recon_loss: 0.026992283761501312, dist_loss: 0.4281769096851349
recon_loss: 0.02699071727693081, dist_loss: 0.7026633024215698
recon_loss: 0.026989731937646866, dist_loss: 0.5033171772956848
recon_loss: 0.02698937989771366, dist_loss: 1.1489462852478027
recon_loss: 0.026988940313458443, dist_loss: 0.5924922823905945
recon_loss: 0.0269892867654562, dist_loss: 0.6776630878448486
recon_loss: 0.026988143101334572, dist_loss: 0.600827693939209
recon_loss: 0.026987669989466667, dist_loss: 0.9047480821609497
recon_loss: 0.026986990123987198, dist_loss: 0.5390005111694336
recon_loss: 0.026986878365278244, dist_loss: 0.5392919182777405
recon_loss: 0.026985934004187584, dist_loss: 1.3642933368682861
recon_loss: 0.026985935866832733, dist_loss: 0.34577587246894836
recon_loss: 0.026984941214323044, dist_loss: 0.7620410919189453
recon_loss: 0.02698463760316372, dist_loss: 0.47490501403808594
recon_loss: 0.02698359824717045, dist_loss: 0.6789686679840088
recon_loss: 0.026983391493558884, dist_loss: 0.5230586528778076
recon_loss: 0.02698315493762493, dist_loss: 1.156493902206421
recon_loss: 0.026983048766851425, dist_loss: 1.1240448951721191
recon_loss: 0.026983007788658142, dist_loss: 0.6258552074432373
recon_loss: 0.026983004063367844, dist_loss: 0.5461673736572266
recon_loss: 0.026983119547367096, dist_loss: 0.23694196343421936
recon_loss: 0.02698317915201187, dist_loss: 0.8736848831176758
recon_loss: 0.026983143761754036, dist_loss: 0.7316850423812866
recon_loss: 0.026983411982655525, dist_loss: 0.6119906902313232
recon_loss: 0.02698362059891224, dist_loss: 0.6320163011550903
recon_loss: 0.026983756572008133, dist_loss: 0.4499635696411133
recon_loss: 0.02698383666574955, dist_loss: 0.4217127561569214
recon_loss: 0.02698403038084507, dist_loss: 0.27092936635017395
recon_loss: 0.02698419615626335, dist_loss: 0.3932234048843384
recon_loss: 0.02698449231684208, dist_loss: 0.5294115543365479
recon_loss: 0.026985175907611847, dist_loss: 1.1438888311386108
recon_loss: 0.026986289769411087, dist_loss: 0.8780413866043091
recon_loss: 0.026986965909600258, dist_loss: 0.7013046145439148
recon_loss: 0.02698620595037937, dist_loss: 0.686266303062439
recon_loss: 0.026985732838511467, dist_loss: 0.6747608780860901
recon_loss: 0.02698669582605362, dist_loss: 0.7639340162277222
recon_loss: 0.02698628418147564, dist_loss: 0.3448229432106018
recon_loss: 0.02698637545108795, dist_loss: 0.36172065138816833
recon_loss: 0.026985371485352516, dist_loss: 0.7752289772033691
recon_loss: 0.026986585929989815, dist_loss: 0.38383060693740845
recon_loss: 0.026986436918377876, dist_loss: 0.5602226853370667
recon_loss: 0.02698897384107113, dist_loss: 0.39349547028541565
recon_loss: 0.026989636942744255, dist_loss: 0.3911704123020172
recon_loss: 0.02699279971420765, dist_loss: 0.8905937075614929
recon_loss: 0.02699373848736286, dist_loss: 0.5331902503967285
recon_loss: 0.026994213461875916, dist_loss: 1.348736047744751
recon_loss: 0.026993047446012497, dist_loss: 0.29208245873451233
recon_loss: 0.026991983875632286, dist_loss: 0.6909310221672058
recon_loss: 0.026991141960024834, dist_loss: 0.5311597585678101
recon_loss: 0.02699037455022335, dist_loss: 0.6787401437759399
recon_loss: 0.026989737525582314, dist_loss: 0.7204604744911194
recon_loss: 0.026989061385393143, dist_loss: 0.4322202801704407
recon_loss: 0.026988793164491653, dist_loss: 0.5006076097488403
recon_loss: 0.02698843739926815, dist_loss: 0.47197425365448
recon_loss: 0.02698870562016964, dist_loss: 0.602469801902771
recon_loss: 0.02698802761733532, dist_loss: 0.4609929323196411
recon_loss: 0.02698863111436367, dist_loss: 0.5162362456321716
recon_loss: 0.02699057199060917, dist_loss: 0.8375759720802307
recon_loss: 0.026991937309503555, dist_loss: 0.6871311664581299
recon_loss: 0.026993025094270706, dist_loss: 0.5940549969673157
recon_loss: 0.02699452079832554, dist_loss: 0.704039454460144
recon_loss: 0.026996398344635963, dist_loss: 0.5015608668327332
recon_loss: 0.02699793502688408, dist_loss: 0.5078983306884766
recon_loss: 0.02700040303170681, dist_loss: 0.6407328844070435
recon_loss: 0.02700364775955677, dist_loss: 0.5599310994148254
recon_loss: 0.027007531374692917, dist_loss: 0.6595339775085449
recon_loss: 0.027005041018128395, dist_loss: 0.5970643162727356
recon_loss: 0.027006447315216064, dist_loss: 0.416912317276001
recon_loss: 0.027003368362784386, dist_loss: 0.3915409445762634
recon_loss: 0.027001993730664253, dist_loss: 0.6584655046463013
recon_loss: 0.026998154819011688, dist_loss: 0.5376166105270386
recon_loss: 0.026997847482562065, dist_loss: 0.3336727023124695
recon_loss: 0.02699451334774494, dist_loss: 0.939997673034668
recon_loss: 0.02699746936559677, dist_loss: 0.4499698281288147
recon_loss: 0.026993433013558388, dist_loss: 0.6780228614807129
recon_loss: 0.02699890546500683, dist_loss: 0.6694290637969971
recon_loss: 0.026998139917850494, dist_loss: 0.5102867484092712
recon_loss: 0.02700124680995941, dist_loss: 0.607634425163269
recon_loss: 0.027000879868865013, dist_loss: 0.7348901033401489
recon_loss: 0.027003049850463867, dist_loss: 0.5581346750259399
recon_loss: 0.02700090780854225, dist_loss: 0.8306832313537598
recon_loss: 0.02700181119143963, dist_loss: 0.4825914204120636
recon_loss: 0.026999961584806442, dist_loss: 0.43543732166290283
recon_loss: 0.02700011245906353, dist_loss: 0.69533371925354
recon_loss: 0.026999015361070633, dist_loss: 0.548275887966156
recon_loss: 0.026998747140169144, dist_loss: 0.32123300433158875
recon_loss: 0.026998626068234444, dist_loss: 0.5314089059829712
recon_loss: 0.02699868381023407, dist_loss: 0.5277104377746582
recon_loss: 0.02700016461312771, dist_loss: 0.38300567865371704
recon_loss: 0.02699764259159565, dist_loss: 0.8172582387924194
recon_loss: 0.026998747140169144, dist_loss: 0.6867517232894897
recon_loss: 0.026995716616511345, dist_loss: 0.9297580718994141
recon_loss: 0.02699633128941059, dist_loss: 0.5252362489700317
recon_loss: 0.026990680024027824, dist_loss: 0.6956400871276855
Pre-training Epoch 133:  37%|███▋      | 137/367 [00:00<00:01, 177.76it/s]Pre-training Epoch 133:  42%|████▏     | 155/367 [00:00<00:01, 173.23it/s]/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [47,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [59,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [61,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [47,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [59,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [61,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [64,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [65,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [66,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [67,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [68,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [69,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [70,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [71,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [72,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [73,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [74,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [75,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [76,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [77,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [78,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [79,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [80,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [81,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [82,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [83,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [84,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [85,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [86,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [87,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [88,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [89,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [90,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [91,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [92,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [93,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [94,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [21,0,0], thread: [95,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [64,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [65,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [66,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [67,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [68,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [69,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [70,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [71,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [72,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [73,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [74,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [75,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [76,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [77,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [78,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [79,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [80,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [81,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [82,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [83,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [84,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [85,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [86,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [87,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [88,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [89,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [90,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [91,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [92,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [93,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [94,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [95,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [96,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [97,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [98,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [99,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [100,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [101,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [102,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [103,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [104,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [105,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [106,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [107,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [108,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [109,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [110,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [111,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [112,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [113,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [114,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [115,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [116,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [117,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [118,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [119,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [120,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [121,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [122,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [123,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [124,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [125,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [126,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [17,0,0], thread: [127,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [64,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [65,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [66,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [67,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [68,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [69,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [70,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [71,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [72,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [73,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [74,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [75,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [76,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [77,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [78,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [79,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [80,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [81,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [82,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [83,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [84,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [85,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [86,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [87,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [88,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [89,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [90,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [91,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [92,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [93,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [94,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [95,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [16,0,0], thread: [64,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [16,0,0], thread: [65,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [16,0,0], thread: [66,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [16,0,0], thread: [67,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [16,0,0], thread: [68,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [16,0,0], thread: [69,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [16,0,0], thread: [70,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [16,0,0], thread: [71,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [16,0,0], thread: [72,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [16,0,0], thread: [73,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [16,0,0], thread: [74,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [16,0,0], thread: [75,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [16,0,0], thread: [76,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [16,0,0], thread: [77,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [16,0,0], thread: [78,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [16,0,0], thread: [79,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [16,0,0], thread: [80,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [16,0,0], thread: [81,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [16,0,0], thread: [82,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [16,0,0], thread: [83,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [16,0,0], thread: [84,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [16,0,0], thread: [85,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [16,0,0], thread: [86,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [16,0,0], thread: [87,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [16,0,0], thread: [88,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [16,0,0], thread: [89,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [16,0,0], thread: [90,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [16,0,0], thread: [91,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [16,0,0], thread: [92,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [16,0,0], thread: [93,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [16,0,0], thread: [94,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [16,0,0], thread: [95,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [96,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [97,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [98,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [99,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [100,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [101,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [102,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [103,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [104,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [105,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [106,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [107,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [108,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [109,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [110,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [111,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [112,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [113,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [114,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [115,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [116,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [117,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [118,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [119,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [120,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [121,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [122,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [123,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [124,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [125,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [126,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [127,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [47,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [59,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [61,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [96,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [97,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [98,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [99,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [100,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [101,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [102,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [103,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [104,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [105,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [106,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [107,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [108,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [109,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [110,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [111,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [112,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [113,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [114,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [115,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [116,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [117,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [118,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [119,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [120,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [121,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [122,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [123,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [124,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [125,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [126,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [15,0,0], thread: [127,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [18,0,0], thread: [64,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [18,0,0], thread: [65,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [18,0,0], thread: [66,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [18,0,0], thread: [67,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [18,0,0], thread: [68,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [18,0,0], thread: [69,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [18,0,0], thread: [70,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [18,0,0], thread: [71,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [18,0,0], thread: [72,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [18,0,0], thread: [73,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [18,0,0], thread: [74,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [18,0,0], thread: [75,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [18,0,0], thread: [76,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [18,0,0], thread: [77,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [18,0,0], thread: [78,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [18,0,0], thread: [79,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [18,0,0], thread: [80,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [18,0,0], thread: [81,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [18,0,0], thread: [82,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [18,0,0], thread: [83,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [18,0,0], thread: [84,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [18,0,0], thread: [85,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [18,0,0], thread: [86,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [18,0,0], thread: [87,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [18,0,0], thread: [88,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [18,0,0], thread: [89,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [18,0,0], thread: [90,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [18,0,0], thread: [91,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [18,0,0], thread: [92,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [18,0,0], thread: [93,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [18,0,0], thread: [94,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [18,0,0], thread: [95,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [10,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [10,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [10,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [10,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [10,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [10,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [10,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [10,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [10,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [10,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [10,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [10,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [10,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [10,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [10,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [10,0,0], thread: [47,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [10,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [10,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [10,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [10,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [10,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [10,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [10,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [10,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [10,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [10,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [10,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [10,0,0], thread: [59,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [10,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [10,0,0], thread: [61,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [10,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [10,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [33,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [33,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [33,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [33,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [33,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [33,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [33,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [33,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [33,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [33,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [33,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [33,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [33,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [33,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [33,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [33,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [33,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [33,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [33,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [33,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [33,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [33,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [33,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [33,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [33,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [33,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [33,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [33,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [33,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [33,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [33,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [33,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [47,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [59,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [61,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [47,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [59,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [61,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [12,0,0], thread: [96,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [12,0,0], thread: [97,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [12,0,0], thread: [98,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [12,0,0], thread: [99,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [12,0,0], thread: [100,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [12,0,0], thread: [101,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [12,0,0], thread: [102,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [12,0,0], thread: [103,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [12,0,0], thread: [104,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [12,0,0], thread: [105,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [12,0,0], thread: [106,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [12,0,0], thread: [107,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [12,0,0], thread: [108,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [12,0,0], thread: [109,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [12,0,0], thread: [110,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [12,0,0], thread: [111,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [12,0,0], thread: [112,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [12,0,0], thread: [113,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [12,0,0], thread: [114,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [12,0,0], thread: [115,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [12,0,0], thread: [116,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [12,0,0], thread: [117,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [12,0,0], thread: [118,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [12,0,0], thread: [119,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [12,0,0], thread: [120,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [12,0,0], thread: [121,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [12,0,0], thread: [122,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [12,0,0], thread: [123,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [12,0,0], thread: [124,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [12,0,0], thread: [125,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [12,0,0], thread: [126,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [12,0,0], thread: [127,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [47,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [59,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [61,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [64,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [65,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [66,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [67,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [68,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [69,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [70,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [71,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [72,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [73,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [74,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [75,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [76,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [77,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [78,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [79,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [80,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [81,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [82,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [83,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [84,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [85,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [86,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [87,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [88,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [89,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [90,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [91,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [92,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [93,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [94,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [6,0,0], thread: [95,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [19,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [19,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [19,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [19,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [19,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [19,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [19,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [19,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [19,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [19,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [19,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [19,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [19,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [19,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [19,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [19,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [19,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [19,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [19,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [19,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [19,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [19,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [19,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [19,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [19,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [19,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [19,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [19,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [19,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [19,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [19,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [19,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [14,0,0], thread: [96,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [14,0,0], thread: [97,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [14,0,0], thread: [98,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [14,0,0], thread: [99,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [14,0,0], thread: [100,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [14,0,0], thread: [101,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [14,0,0], thread: [102,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [14,0,0], thread: [103,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [14,0,0], thread: [104,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [14,0,0], thread: [105,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [14,0,0], thread: [106,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [14,0,0], thread: [107,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [14,0,0], thread: [108,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [14,0,0], thread: [109,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [14,0,0], thread: [110,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [14,0,0], thread: [111,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [14,0,0], thread: [112,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [14,0,0], thread: [113,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [14,0,0], thread: [114,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [14,0,0], thread: [115,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [14,0,0], thread: [116,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [14,0,0], thread: [117,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [14,0,0], thread: [118,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [14,0,0], thread: [119,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [14,0,0], thread: [120,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [14,0,0], thread: [121,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [14,0,0], thread: [122,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [14,0,0], thread: [123,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [14,0,0], thread: [124,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [14,0,0], thread: [125,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [14,0,0], thread: [126,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [14,0,0], thread: [127,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [4,0,0], thread: [64,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [4,0,0], thread: [65,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [4,0,0], thread: [66,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [4,0,0], thread: [67,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [4,0,0], thread: [68,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [4,0,0], thread: [69,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [4,0,0], thread: [70,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [4,0,0], thread: [71,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [4,0,0], thread: [72,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [4,0,0], thread: [73,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [4,0,0], thread: [74,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [4,0,0], thread: [75,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [4,0,0], thread: [76,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [4,0,0], thread: [77,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [4,0,0], thread: [78,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [4,0,0], thread: [79,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [4,0,0], thread: [80,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [4,0,0], thread: [81,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [4,0,0], thread: [82,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [4,0,0], thread: [83,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [4,0,0], thread: [84,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [4,0,0], thread: [85,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [4,0,0], thread: [86,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [4,0,0], thread: [87,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [4,0,0], thread: [88,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [4,0,0], thread: [89,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [4,0,0], thread: [90,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [4,0,0], thread: [91,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [4,0,0], thread: [92,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [4,0,0], thread: [93,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [4,0,0], thread: [94,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [4,0,0], thread: [95,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [13,0,0], thread: [64,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [13,0,0], thread: [65,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [13,0,0], thread: [66,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [13,0,0], thread: [67,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [13,0,0], thread: [68,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [13,0,0], thread: [69,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [13,0,0], thread: [70,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [13,0,0], thread: [71,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [13,0,0], thread: [72,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [13,0,0], thread: [73,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [13,0,0], thread: [74,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [13,0,0], thread: [75,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [13,0,0], thread: [76,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [13,0,0], thread: [77,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [13,0,0], thread: [78,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [13,0,0], thread: [79,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [13,0,0], thread: [80,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [13,0,0], thread: [81,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [13,0,0], thread: [82,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [13,0,0], thread: [83,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [13,0,0], thread: [84,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [13,0,0], thread: [85,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [13,0,0], thread: [86,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [13,0,0], thread: [87,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [13,0,0], thread: [88,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [13,0,0], thread: [89,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [13,0,0], thread: [90,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [13,0,0], thread: [91,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [13,0,0], thread: [92,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [13,0,0], thread: [93,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [13,0,0], thread: [94,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [13,0,0], thread: [95,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [47,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [59,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [61,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [47,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [59,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [61,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [64,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [65,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [66,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [67,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [68,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [69,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [70,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [71,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [72,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [73,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [74,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [75,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [76,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [77,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [78,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [79,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [80,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [81,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [82,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [83,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [84,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [85,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [86,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [87,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [88,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [89,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [90,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [91,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [92,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [93,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [94,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [95,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [7,0,0], thread: [96,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [7,0,0], thread: [97,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [7,0,0], thread: [98,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [7,0,0], thread: [99,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [7,0,0], thread: [100,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [7,0,0], thread: [101,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [7,0,0], thread: [102,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [7,0,0], thread: [103,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [7,0,0], thread: [104,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [7,0,0], thread: [105,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [7,0,0], thread: [106,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [7,0,0], thread: [107,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [7,0,0], thread: [108,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [7,0,0], thread: [109,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [7,0,0], thread: [110,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [7,0,0], thread: [111,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [7,0,0], thread: [112,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [7,0,0], thread: [113,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [7,0,0], thread: [114,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [7,0,0], thread: [115,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [7,0,0], thread: [116,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [7,0,0], thread: [117,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [7,0,0], thread: [118,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [7,0,0], thread: [119,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [7,0,0], thread: [120,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [7,0,0], thread: [121,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [7,0,0], thread: [122,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [7,0,0], thread: [123,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [7,0,0], thread: [124,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [7,0,0], thread: [125,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [7,0,0], thread: [126,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [7,0,0], thread: [127,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [47,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [59,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [61,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [64,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [65,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [66,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [67,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [68,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [69,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [70,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [71,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [72,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [73,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [74,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [75,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [76,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [77,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [78,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [79,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [80,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [81,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [82,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [83,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [84,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [85,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [86,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [87,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [88,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [89,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [90,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [91,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [92,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [93,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [94,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [95,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [64,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [65,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [66,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [67,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [68,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [69,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [70,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [71,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [72,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [73,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [74,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [75,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [76,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [77,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [78,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [79,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [80,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [81,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [82,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [83,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [84,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [85,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [86,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [87,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [88,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [89,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [90,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [91,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [92,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [93,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [94,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [95,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [64,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [65,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [66,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [67,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [68,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [69,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [70,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [71,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [72,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [73,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [74,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [75,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [76,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [77,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [78,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [79,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [80,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [81,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [82,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [83,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [84,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [85,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [86,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [87,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [88,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [89,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [90,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [91,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [92,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [93,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [94,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [20,0,0], thread: [95,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [64,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [65,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [66,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [67,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [68,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [69,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [70,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [71,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [72,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [73,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [74,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [75,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [76,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [77,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [78,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [79,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [80,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [81,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [82,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [83,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [84,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [85,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [86,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [87,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [88,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [89,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [90,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [91,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [92,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [93,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [94,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [95,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [64,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [65,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [66,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [67,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [68,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [69,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [70,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [71,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [72,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [73,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [74,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [75,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [76,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [77,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [78,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [79,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [80,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [81,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [82,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [83,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [84,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [85,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [86,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [87,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [88,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [89,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [90,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [91,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [92,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [93,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [94,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [95,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [64,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [65,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [66,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [67,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [68,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [69,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [70,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [71,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [72,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [73,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [74,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [75,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [76,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [77,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [78,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [79,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [80,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [81,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [82,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [83,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [84,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [85,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [86,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [87,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [88,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [89,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [90,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [91,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [92,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [93,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [94,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [32,0,0], thread: [95,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [96,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [97,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [98,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [99,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [100,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [101,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [102,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [103,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [104,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [105,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [106,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [107,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [108,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [109,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [110,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [111,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [112,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [113,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [114,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [115,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [116,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [117,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [118,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [119,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [120,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [121,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [122,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [123,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [124,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [125,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [126,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [127,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [47,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [59,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [61,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [96,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [97,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [98,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [99,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [100,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [101,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [102,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [103,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [104,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [105,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [106,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [107,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [108,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [109,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [110,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [111,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [112,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [113,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [114,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [115,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [116,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [117,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [118,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [119,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [120,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [121,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [122,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [123,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [124,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [125,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [126,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [127,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [29,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [29,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [29,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [29,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [29,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [29,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [29,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [29,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [29,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [29,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [29,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [29,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [29,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [29,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [29,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [29,0,0], thread: [47,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [29,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [29,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [29,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [29,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [29,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [29,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [29,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [29,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [29,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [29,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [29,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [29,0,0], thread: [59,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [29,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [29,0,0], thread: [61,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [29,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [29,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [28,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [96,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [97,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [98,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [99,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [100,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [101,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [102,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [103,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [104,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [105,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [106,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [107,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [108,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [109,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [110,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [111,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [112,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [113,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [114,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [115,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [116,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [117,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [118,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [119,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [120,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [121,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [122,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [123,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [124,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [125,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [126,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [127,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [3,0,0], thread: [64,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [3,0,0], thread: [65,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [3,0,0], thread: [66,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [3,0,0], thread: [67,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [3,0,0], thread: [68,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [3,0,0], thread: [69,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [3,0,0], thread: [70,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [3,0,0], thread: [71,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [3,0,0], thread: [72,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [3,0,0], thread: [73,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [3,0,0], thread: [74,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [3,0,0], thread: [75,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [3,0,0], thread: [76,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [3,0,0], thread: [77,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [3,0,0], thread: [78,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [3,0,0], thread: [79,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [3,0,0], thread: [80,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [3,0,0], thread: [81,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [3,0,0], thread: [82,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [3,0,0], thread: [83,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [3,0,0], thread: [84,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [3,0,0], thread: [85,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [3,0,0], thread: [86,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [3,0,0], thread: [87,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [3,0,0], thread: [88,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [3,0,0], thread: [89,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [3,0,0], thread: [90,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [3,0,0], thread: [91,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [3,0,0], thread: [92,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [3,0,0], thread: [93,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [3,0,0], thread: [94,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [3,0,0], thread: [95,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [64,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [65,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [66,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [67,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [68,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [69,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [70,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [71,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [72,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [73,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [74,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [75,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [76,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [77,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [78,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [79,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [80,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [81,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [82,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [83,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [84,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [85,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [86,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [87,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [88,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [89,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [90,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [91,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [92,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [93,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [94,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [95,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [2,0,0], thread: [96,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [2,0,0], thread: [97,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [2,0,0], thread: [98,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [2,0,0], thread: [99,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [2,0,0], thread: [100,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [2,0,0], thread: [101,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [2,0,0], thread: [102,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [2,0,0], thread: [103,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [2,0,0], thread: [104,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [2,0,0], thread: [105,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [2,0,0], thread: [106,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [2,0,0], thread: [107,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [2,0,0], thread: [108,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [2,0,0], thread: [109,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [2,0,0], thread: [110,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [2,0,0], thread: [111,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [2,0,0], thread: [112,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [2,0,0], thread: [113,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [2,0,0], thread: [114,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [2,0,0], thread: [115,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [2,0,0], thread: [116,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [2,0,0], thread: [117,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [2,0,0], thread: [118,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [2,0,0], thread: [119,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [2,0,0], thread: [120,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [2,0,0], thread: [121,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [2,0,0], thread: [122,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [2,0,0], thread: [123,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [2,0,0], thread: [124,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [2,0,0], thread: [125,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [2,0,0], thread: [126,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [2,0,0], thread: [127,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [96,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [97,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [98,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [99,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [100,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [101,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [102,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [103,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [104,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [105,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [106,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [107,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [108,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [109,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [110,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [111,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [112,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [113,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [114,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [115,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [116,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [117,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [118,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [119,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [120,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [121,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [122,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [123,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [124,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [125,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [126,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [127,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [9,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [9,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [9,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [9,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [9,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [9,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [9,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [9,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [9,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [9,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [9,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [9,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [9,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [9,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [9,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [9,0,0], thread: [47,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [9,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [9,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [9,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [9,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [9,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [9,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [9,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [9,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [9,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [9,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [9,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [9,0,0], thread: [59,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [9,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [9,0,0], thread: [61,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [9,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [9,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [47,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [59,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [61,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [96,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [97,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [98,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [99,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [100,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [101,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [102,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [103,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [104,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [105,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [106,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [107,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [108,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [109,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [110,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [111,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [112,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [113,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [114,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [115,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [116,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [117,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [118,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [119,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [120,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [121,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [122,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [123,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [124,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [125,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [126,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [127,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [5,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [96,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [97,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [98,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [99,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [100,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [101,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [102,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [103,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [104,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [105,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [106,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [107,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [108,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [109,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [110,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [111,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [112,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [113,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [114,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [115,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [116,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [117,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [118,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [119,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [120,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [121,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [122,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [123,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [124,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [125,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [126,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [11,0,0], thread: [127,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [64,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [65,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [66,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [67,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [68,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [69,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [70,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [71,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [72,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [73,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [74,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [75,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [76,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [77,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [78,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [79,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [80,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [81,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [82,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [83,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [84,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [85,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [86,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [87,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [88,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [89,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [90,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [91,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [92,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [93,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [94,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [95,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [1,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [96,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [97,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [98,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [99,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [100,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [101,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [102,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [103,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [104,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [105,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [106,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [107,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [108,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [109,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [110,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [111,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [112,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [113,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [114,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [115,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [116,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [117,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [118,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [119,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [120,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [121,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [122,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [123,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [124,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [125,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [126,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [127,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [47,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [59,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [61,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [96,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [97,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [98,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [99,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [100,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [101,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [102,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [103,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [104,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [105,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [106,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [107,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [108,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [109,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [110,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [111,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [112,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [113,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [114,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [115,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [116,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [117,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [118,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [119,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [120,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [121,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [122,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [123,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [124,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [125,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [126,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [26,0,0], thread: [127,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [64,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [65,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [66,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [67,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [68,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [69,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [70,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [71,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [72,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [73,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [74,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [75,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [76,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [77,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [78,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [79,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [80,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [81,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [82,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [83,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [84,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [85,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [86,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [87,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [88,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [89,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [90,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [91,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [92,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [93,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [94,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [95,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [47,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [59,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [61,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [27,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [47,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [59,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [61,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [8,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [64,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [65,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [66,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [67,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [68,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [69,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [70,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [71,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [72,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [73,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [74,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [75,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [76,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [77,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [78,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [79,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [80,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [81,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [82,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [83,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [84,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [85,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [86,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [87,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [88,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [89,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [90,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [91,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [92,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [93,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [94,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [95,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [96,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [97,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [98,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [99,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [100,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [101,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [102,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [103,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [104,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [105,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [106,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [107,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [108,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [109,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [110,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [111,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [112,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [113,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [114,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [115,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [116,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [117,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [118,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [119,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [120,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [121,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [122,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [123,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [124,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [125,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [126,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [127,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [47,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [59,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [61,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [47,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [59,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [61,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [96,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [97,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [98,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [99,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [100,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [101,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [102,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [103,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [104,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [105,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [106,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [107,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [108,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [109,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [110,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [111,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [112,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [113,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [114,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [115,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [116,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [117,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [118,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [119,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [120,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [121,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [122,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [123,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [124,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [125,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [126,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [127,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [47,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [59,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [61,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [64,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [65,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [66,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [67,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [68,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [69,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [70,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [71,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [72,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [73,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [74,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [75,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [76,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [77,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [78,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [79,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [80,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [81,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [82,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [83,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [84,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [85,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [86,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [87,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [88,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [89,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [90,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [91,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [92,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [93,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [94,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [95,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [64,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [65,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [66,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [67,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [68,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [69,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [70,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [71,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [72,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [73,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [74,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [75,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [76,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [77,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [78,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [79,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [80,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [81,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [82,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [83,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [84,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [85,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [86,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [87,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [88,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [89,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [90,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [91,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [92,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [93,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [94,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [95,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [64,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [65,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [66,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [67,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [68,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [69,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [70,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [71,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [72,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [73,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [74,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [75,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [76,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [77,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [78,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [79,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [80,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [81,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [82,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [83,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [84,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [85,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [86,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [87,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [88,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [89,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [90,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [91,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [92,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [93,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [94,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [95,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [1,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [2,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [3,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [4,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [5,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [6,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [7,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [8,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [9,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [10,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [11,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [12,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [13,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [14,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [15,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [16,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [17,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [18,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [19,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [20,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [21,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [22,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [23,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [24,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [25,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [26,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [27,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [28,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [29,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [30,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [31,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [47,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [59,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [61,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [23,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [64,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [65,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [66,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [67,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [68,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [69,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [70,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [71,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [72,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [73,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [74,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [75,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [76,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [77,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [78,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [79,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [80,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [81,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [82,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [83,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [84,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [85,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [86,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [87,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [88,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [89,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [90,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [91,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [92,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [93,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [94,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [30,0,0], thread: [95,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [96,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [97,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [98,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [99,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [100,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [101,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [102,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [103,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [104,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [105,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [106,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [107,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [108,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [109,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [110,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [111,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [112,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [113,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [114,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [115,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [116,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [117,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [118,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [119,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [120,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [121,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [122,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [123,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [124,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [125,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [126,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [22,0,0], thread: [127,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [96,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [97,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [98,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [99,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [100,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [101,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [102,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [103,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [104,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [105,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [106,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [107,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [108,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [109,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [110,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [111,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [112,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [113,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [114,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [115,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [116,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [117,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [118,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [119,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [120,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [121,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [122,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [123,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [124,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [125,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [126,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [25,0,0], thread: [127,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [96,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [97,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [98,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [99,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [100,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [101,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [102,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [103,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [104,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [105,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [106,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [107,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [108,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [109,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [110,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [111,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [112,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [113,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [114,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [115,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [116,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [117,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [118,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [119,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [120,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [121,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [122,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [123,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [124,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [125,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [126,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [24,0,0], thread: [127,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [47,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [59,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [61,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.
/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [31,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.
Pre-training Epoch 133:  46%|████▌     | 169/367 [00:01<00:01, 166.61it/s]
recon_loss: 0.026992788538336754, dist_loss: 0.6391831636428833
recon_loss: 0.026989201083779335, dist_loss: 0.6866123676300049
recon_loss: 0.026992550119757652, dist_loss: 0.457202672958374
recon_loss: 0.02698933705687523, dist_loss: 0.5605242252349854
recon_loss: 0.026991281658411026, dist_loss: 0.5260213017463684
recon_loss: 0.026989731937646866, dist_loss: 0.4807325005531311
recon_loss: 0.026991277933120728, dist_loss: 0.36159390211105347
recon_loss: 0.026990259066224098, dist_loss: 0.5343849658966064
recon_loss: 0.026991063728928566, dist_loss: 0.9031423330307007
recon_loss: 0.02699020504951477, dist_loss: 0.5048989057540894
recon_loss: 0.026990041136741638, dist_loss: 0.5913995504379272
recon_loss: 0.02698877640068531, dist_loss: 0.7726836800575256
recon_loss: 0.026988094672560692, dist_loss: 0.41743868589401245
recon_loss: 0.026986831799149513, dist_loss: 1.0640983581542969
recon_loss: 0.026985883712768555, dist_loss: 0.6485227346420288
recon_loss: 0.0269856546074152, dist_loss: 0.784629225730896
recon_loss: 0.02698594331741333, dist_loss: 0.6249279975891113
recon_loss: 0.026986606419086456, dist_loss: 0.3942500948905945
recon_loss: 0.026986297219991684, dist_loss: 0.4550982713699341
recon_loss: 0.026988191530108452, dist_loss: 0.41539978981018066
recon_loss: 0.026987915858626366, dist_loss: 0.46166470646858215
recon_loss: 0.026988724246621132, dist_loss: 0.23331612348556519
recon_loss: 0.026987692341208458, dist_loss: 0.6404137015342712
recon_loss: 0.026987886056303978, dist_loss: 0.608900785446167
recon_loss: 0.026987601071596146, dist_loss: 0.6499266028404236
recon_loss: 0.02698737196624279, dist_loss: 0.47961390018463135
recon_loss: 0.0269875880330801, dist_loss: 0.6734978556632996
recon_loss: 0.026987673714756966, dist_loss: 0.6793919801712036
recon_loss: 0.026986906304955482, dist_loss: 0.3659491240978241
recon_loss: 0.026986273005604744, dist_loss: 0.4363251030445099
recon_loss: 0.026985928416252136, dist_loss: 0.4953033924102783
recon_loss: 0.026985498145222664, dist_loss: 0.5819293260574341
recon_loss: 0.02698490396142006, dist_loss: 1.0039907693862915
recon_loss: 0.026985032483935356, dist_loss: 0.6351182460784912
recon_loss: 0.02698439359664917, dist_loss: 0.3537615239620209
recon_loss: 0.026986416429281235, dist_loss: 0.609765887260437
recon_loss: 0.0269866231828928, dist_loss: 0.8546188473701477
recon_loss: 0.026989126577973366, dist_loss: 0.6861515641212463
recon_loss: 0.0269890446215868, dist_loss: 0.5031670928001404
recon_loss: 0.026989713311195374, dist_loss: 0.8348699808120728
recon_loss: 0.026990395039319992, dist_loss: 0.4906022548675537
Traceback (most recent call last):
  File "/home/qirui/WiMU-demo/train_two_stage.py", line 128, in pre_train
    print(f"recon_loss: {recon_loss.item()}, dist_loss: {dist_loss.item()}")
                         ^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/qirui/WiMU-demo/train_two_stage.py", line 573, in <module>
    pre_train(args)
  File "/home/qirui/WiMU-demo/train_two_stage.py", line 138, in pre_train
    print(recon_A.cpu().detach().numpy())
          ^^^^^^^^^^^^^
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

